{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /root/anaconda/lib/python3.8/site-packages (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_local = '/home/jovyan/docker/src/python/temp_test/DJGrad'\n",
    "fp_data = os.path.join(fp_local, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from copy import deepcopy\n",
    "\n",
    "class DistMLP(keras.Model):\n",
    "    def __init__(self,):\n",
    "        super(DistMLP, self).__init__()\n",
    "        self.mod1 = Sequential([\n",
    "            layers.Rescaling(1./255, input_shape=(*x.shape[1:],)),\n",
    "            layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Flatten(),\n",
    "#             layers.Dropout(0.9),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(num_classes, 'softmax')\n",
    "        ])\n",
    "        \n",
    "        self.mod2 = tf.keras.models.clone_model(self.mod1)\n",
    "        self.mod3 = tf.keras.models.clone_model(self.mod1)\n",
    "#         self.mod4 = tf.keras.models.clone_model(self.mod1)\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.mod1(data)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x,y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred1 = self.mod1(x,training=True)\n",
    "            y_pred2 = self.mod2(x,training=True)\n",
    "            y_pred3 = self.mod3(x,training=True)\n",
    "#             y_pred4 = self.mod4(x,training=True)\n",
    "            loss1 = self.compiled_loss(y,y_pred1)\n",
    "            loss2 = self.compiled_loss(y,y_pred2)\n",
    "            loss3 = self.compiled_loss(y,y_pred3)\n",
    "#             loss4 = self.compiled_loss(y,y_pred4)\n",
    "\n",
    "        grads = tape.gradient([loss1,loss2,loss3], self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(tf.concat([y,y,y],0), tf.concat([y_pred1,y_pred2,y_pred3],0))\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = DistMLP()\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    "    run_eagerly=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1000000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7507026fdaa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m m.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    851\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    844\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1284\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1285\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1286\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2847\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2849\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3632\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b5a7edfcd917>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0;31m# Create iteration if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_all_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_create_all_weights\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_slots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_create_slots\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    117\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36madd_slot\u001b[0;34m(self, var, slot_name, initializer, shape)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_vars_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m           weight = tf.Variable(\n\u001b[0m\u001b[1;32m    902\u001b[0m               \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%s/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v2_call\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maggregation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     return previous_getter(\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mgetter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcaptured_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_previous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcreator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   3545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3546\u001b[0m       \u001b[0m_require_strategy_scope_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3547\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnext_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3549\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_creator_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mgetter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcaptured_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_previous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcreator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   3545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3546\u001b[0m       \u001b[0m_require_strategy_scope_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3547\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnext_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3549\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_creator_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mgetter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcaptured_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_previous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcreator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   3545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3546\u001b[0m       \u001b[0m_require_strategy_scope_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3547\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnext_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3549\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_creator_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kws)\u001b[0m\n\u001b[1;32m    241\u001b[0m                         shape=None):\n\u001b[1;32m    242\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator_v2\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2660\u001b[0m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2662\u001b[0;31m   return resource_variable_ops.ResourceVariable(\n\u001b[0m\u001b[1;32m   2663\u001b[0m       \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2664\u001b[0m       \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1600\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1602\u001b[0;31m       self._init_from_args(\n\u001b[0m\u001b[1;32m   1603\u001b[0m           \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1738\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1740\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1741\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_PARTITION_SHAPE\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_PARTITION_SHAPE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2915\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2916\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2975\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure it's a vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2976\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2977\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mfill\u001b[0;34m(dims, value, name)\u001b[0m\n\u001b[1;32m    238\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m   \"\"\"\n\u001b[0;32m--> 240\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mfill\u001b[0;34m(dims, value, name)\u001b[0m\n\u001b[1;32m   3366\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3367\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3368\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3369\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3370\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1000000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill]"
     ]
    }
   ],
   "source": [
    "m.fit(\n",
    "    train_dataset,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try smaller Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.reshape(-1,28**2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train.reshape(60000,28**2),y_train)).shuffle(100).batch(batch_size,True)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test.reshape(10000,28**2),y_test)).shuffle(100).batch(batch_size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Dense(1024, activation='relu', input_shape=(28**2,)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(10, 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    ),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "468/468 [==============================] - 1s 3ms/step - loss: 2.1468 - accuracy: 0.4503 - val_loss: 1.3095 - val_accuracy: 0.5543\n",
      "Epoch 2/30\n",
      "468/468 [==============================] - 1s 3ms/step - loss: 1.1754 - accuracy: 0.5706 - val_loss: 1.0293 - val_accuracy: 0.6373\n",
      "Epoch 3/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.9799 - accuracy: 0.6320 - val_loss: 0.9168 - val_accuracy: 0.6564\n",
      "Epoch 4/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.7704 - accuracy: 0.7192 - val_loss: 0.6605 - val_accuracy: 0.8108\n",
      "Epoch 5/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.4285 - accuracy: 0.8838 - val_loss: 0.3577 - val_accuracy: 0.9262\n",
      "Epoch 6/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.2422 - accuracy: 0.9494 - val_loss: 0.2756 - val_accuracy: 0.9443\n",
      "Epoch 7/30\n",
      "468/468 [==============================] - 1s 3ms/step - loss: 0.1770 - accuracy: 0.9615 - val_loss: 0.2234 - val_accuracy: 0.9553\n",
      "Epoch 8/30\n",
      "468/468 [==============================] - 1s 3ms/step - loss: 0.1356 - accuracy: 0.9702 - val_loss: 0.2037 - val_accuracy: 0.9576\n",
      "Epoch 9/30\n",
      "468/468 [==============================] - 1s 3ms/step - loss: 0.1225 - accuracy: 0.9723 - val_loss: 0.1951 - val_accuracy: 0.9506\n",
      "Epoch 10/30\n",
      "468/468 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9772 - val_loss: 0.1564 - val_accuracy: 0.9654\n",
      "Epoch 11/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.0884 - accuracy: 0.9783 - val_loss: 0.1899 - val_accuracy: 0.9600\n",
      "Epoch 12/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.9798 - val_loss: 0.1680 - val_accuracy: 0.9623\n",
      "Epoch 13/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.0701 - accuracy: 0.9821 - val_loss: 0.1684 - val_accuracy: 0.9646\n",
      "Epoch 14/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.0684 - accuracy: 0.9824 - val_loss: 0.1435 - val_accuracy: 0.9683\n",
      "Epoch 15/30\n",
      "468/468 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9838 - val_loss: 0.1556 - val_accuracy: 0.9704\n",
      "Epoch 16/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.0558 - accuracy: 0.9854 - val_loss: 0.1688 - val_accuracy: 0.9654\n",
      "Epoch 17/30\n",
      "468/468 [==============================] - 1s 3ms/step - loss: 0.0626 - accuracy: 0.9850 - val_loss: 0.1508 - val_accuracy: 0.9690\n",
      "Epoch 18/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.0396 - accuracy: 0.9896 - val_loss: 0.1505 - val_accuracy: 0.9731\n",
      "Epoch 19/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.0444 - accuracy: 0.9889 - val_loss: 0.1339 - val_accuracy: 0.9720\n",
      "Epoch 20/30\n",
      "468/468 [==============================] - 1s 3ms/step - loss: 0.0400 - accuracy: 0.9894 - val_loss: 0.1398 - val_accuracy: 0.9710\n",
      "Epoch 21/30\n",
      "468/468 [==============================] - 1s 3ms/step - loss: 0.0381 - accuracy: 0.9901 - val_loss: 0.1346 - val_accuracy: 0.9736\n",
      "Epoch 22/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.0350 - accuracy: 0.9907 - val_loss: 0.1397 - val_accuracy: 0.9735\n",
      "Epoch 23/30\n",
      "468/468 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9917 - val_loss: 0.1579 - val_accuracy: 0.9704\n",
      "Epoch 24/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.0338 - accuracy: 0.9911 - val_loss: 0.1443 - val_accuracy: 0.9728\n",
      "Epoch 25/30\n",
      "468/468 [==============================] - 1s 3ms/step - loss: 0.0284 - accuracy: 0.9925 - val_loss: 0.1341 - val_accuracy: 0.9732\n",
      "Epoch 26/30\n",
      "468/468 [==============================] - 1s 3ms/step - loss: 0.0270 - accuracy: 0.9934 - val_loss: 0.1444 - val_accuracy: 0.9738\n",
      "Epoch 27/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9931 - val_loss: 0.1442 - val_accuracy: 0.9746\n",
      "Epoch 28/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.1550 - val_accuracy: 0.9736\n",
      "Epoch 29/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.0249 - accuracy: 0.9934 - val_loss: 0.1454 - val_accuracy: 0.9745\n",
      "Epoch 30/30\n",
      "468/468 [==============================] - 1s 2ms/step - loss: 0.0209 - accuracy: 0.9943 - val_loss: 0.1548 - val_accuracy: 0.9770\n"
     ]
    }
   ],
   "source": [
    "epochs=30\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "split_by_type = [x_train[np.where(y_train==x)] for x in range(10)]\n",
    "split_by_type = [x[:x.shape[0]//4*4].reshape(4,-1,28,28) for x in split_by_type]\n",
    "\n",
    "ds1  = [split_by_type[0][0:2], split_by_type[1][0:2]]\n",
    "ds2  = [split_by_type[2][0:2], split_by_type[3][0:2]]\n",
    "ds3  = [split_by_type[4][0:2], split_by_type[5][0:2]]\n",
    "ds4  = [split_by_type[6][0:2], split_by_type[7][0:2]]\n",
    "\n",
    "y1   = [0 for _ in range(np.multiply(*split_by_type[0][0:2].shape[:2]))] + [1 for _ in range(np.multiply(*split_by_type[1][0:2].shape[:2]))]\n",
    "y2   = [2 for _ in range(np.multiply(*split_by_type[2][0:2].shape[:2]))] + [3 for _ in range(np.multiply(*split_by_type[3][0:2].shape[:2]))]\n",
    "y3   = [4 for _ in range(np.multiply(*split_by_type[4][0:2].shape[:2]))] + [5 for _ in range(np.multiply(*split_by_type[5][0:2].shape[:2]))]\n",
    "y4   = [6 for _ in range(np.multiply(*split_by_type[6][0:2].shape[:2]))] + [7 for _ in range(np.multiply(*split_by_type[7][0:2].shape[:2]))]\n",
    "\n",
    "##\n",
    "\n",
    "ds1 += [split_by_type[2][2:3], split_by_type[3][2:3]]\n",
    "ds2 += [split_by_type[4][2:3], split_by_type[5][2:3]]\n",
    "ds3 += [split_by_type[6][2:3], split_by_type[7][2:3]]\n",
    "ds4 += [split_by_type[0][2:3], split_by_type[1][2:3]]\n",
    "\n",
    "y1  += [2 for _ in range(np.multiply(*split_by_type[2][2:3].shape[:2]))] + [3 for _ in range(np.multiply(*split_by_type[3][2:3].shape[:2]))]\n",
    "y2  += [4 for _ in range(np.multiply(*split_by_type[4][2:3].shape[:2]))] + [5 for _ in range(np.multiply(*split_by_type[5][2:3].shape[:2]))]\n",
    "y3  += [6 for _ in range(np.multiply(*split_by_type[6][2:3].shape[:2]))] + [7 for _ in range(np.multiply(*split_by_type[7][2:3].shape[:2]))]\n",
    "y4  += [0 for _ in range(np.multiply(*split_by_type[0][2:3].shape[:2]))] + [1 for _ in range(np.multiply(*split_by_type[1][2:3].shape[:2]))]\n",
    "\n",
    "##\n",
    "\n",
    "ds1 += [split_by_type[4][3:4], split_by_type[5][3:4]]\n",
    "ds2 += [split_by_type[6][3:4], split_by_type[7][3:4]]\n",
    "ds3 += [split_by_type[0][3:4], split_by_type[1][3:4]]\n",
    "ds4 += [split_by_type[2][3:4], split_by_type[3][3:4]]\n",
    "\n",
    "y1  += [4 for _ in range(np.multiply(*split_by_type[4][3:4].shape[:2]))] + [5 for _ in range(np.multiply(*split_by_type[5][3:4].shape[:2]))]\n",
    "y2  += [6 for _ in range(np.multiply(*split_by_type[6][3:4].shape[:2]))] + [7 for _ in range(np.multiply(*split_by_type[7][3:4].shape[:2]))]\n",
    "y3  += [0 for _ in range(np.multiply(*split_by_type[0][3:4].shape[:2]))] + [1 for _ in range(np.multiply(*split_by_type[1][3:4].shape[:2]))]\n",
    "y4  += [2 for _ in range(np.multiply(*split_by_type[2][3:4].shape[:2]))] + [3 for _ in range(np.multiply(*split_by_type[3][3:4].shape[:2]))]\n",
    "\n",
    "##\n",
    "\n",
    "ds1 += [split_by_type[8][0:1], split_by_type[9][0:1]]\n",
    "ds2 += [split_by_type[8][1:2], split_by_type[9][1:2]]\n",
    "ds3 += [split_by_type[8][2:3], split_by_type[9][2:3]]\n",
    "ds4 += [split_by_type[8][3:4], split_by_type[9][3:4]]\n",
    "\n",
    "y1  += [8 for _ in range(np.multiply(*split_by_type[8][0:1].shape[:2]))] + [9 for _ in range(np.multiply(*split_by_type[9][0:1].shape[:2]))]\n",
    "y2  += [8 for _ in range(np.multiply(*split_by_type[8][1:2].shape[:2]))] + [9 for _ in range(np.multiply(*split_by_type[9][1:2].shape[:2]))]\n",
    "y3  += [8 for _ in range(np.multiply(*split_by_type[8][2:3].shape[:2]))] + [9 for _ in range(np.multiply(*split_by_type[9][2:3].shape[:2]))]\n",
    "y4  += [8 for _ in range(np.multiply(*split_by_type[8][3:4].shape[:2]))] + [9 for _ in range(np.multiply(*split_by_type[9][3:4].shape[:2]))]\n",
    "\n",
    "##\n",
    "\n",
    "ds1 = [list(x.reshape(-1,28,28)) for x in ds1]\n",
    "ds2 = [list(x.reshape(-1,28,28)) for x in ds2]\n",
    "ds3 = [list(x.reshape(-1,28,28)) for x in ds3]\n",
    "ds4 = [list(x.reshape(-1,28,28)) for x in ds4]\n",
    "\n",
    "##\n",
    "\n",
    "ds1 = np.array([item for sublist in ds1 for item in sublist])\n",
    "ds2 = np.array([item for sublist in ds2 for item in sublist])\n",
    "ds3 = np.array([item for sublist in ds3 for item in sublist])\n",
    "ds4 = np.array([item for sublist in ds4 for item in sublist])\n",
    "\n",
    "y1 = np.array(y1)\n",
    "y2 = np.array(y2)\n",
    "y3 = np.array(y3)\n",
    "y4 = np.array(y4)\n",
    "\n",
    "##\n",
    "\n",
    "ds1,y1 = shuffle(ds1,y1)\n",
    "ds2,y2 = shuffle(ds2,y2)\n",
    "ds3,y3 = shuffle(ds3,y3)\n",
    "ds4,y4 = shuffle(ds4,y4)\n",
    "\n",
    "##\n",
    "\n",
    "m = min([x.shape[0] for x in [ds1,ds2,ds3,ds4]])\n",
    "\n",
    "ds1,y1 = ds1[:m].reshape(-1,28**2),y1[:m]\n",
    "ds2,y2 = ds2[:m].reshape(-1,28**2),y2[:m]\n",
    "ds3,y3 = ds3[:m].reshape(-1,28**2),y3[:m]\n",
    "ds4,y4 = ds4[:m].reshape(-1,28**2),y4[:m]\n",
    "\n",
    "##\n",
    "\n",
    "x_test = x_test.reshape(-1,28**2)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((ds1,y1,ds2,y2,ds3,y3,ds4,y4)).shuffle(100).batch(batch_size,True)\n",
    "validation_dataset= tf.data.Dataset.from_tensor_slices((x_test,y_test,x_test,y_test,x_test,y_test,x_test,y_test)).shuffle(100).batch(batch_size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1440., 1635., 1455., 1492.,    0.,    0., 2873., 3023., 1421.,\n",
       "        1450.]),\n",
       " array([0. , 0.9, 1.8, 2.7, 3.6, 4.5, 5.4, 6.3, 7.2, 8.1, 9. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y1)\n",
    "plt.hist(y2)\n",
    "plt.hist(y3)\n",
    "plt.hist(y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "\n",
    "class Car():\n",
    "    def __init__(self,neighbors,):\n",
    "        self.neighbors = neighbors\n",
    "        self.fwd_q = []\n",
    "        self.rec_grad = set()\n",
    "        self.new_grad = []\n",
    "        \n",
    "    def forward(self,lst_cars,):\n",
    "        for n,c in enumerate(lst_cars):\n",
    "            if n in self.neighbors:\n",
    "                print(1)\n",
    "                for grad in self.fwd_q:\n",
    "                    c.receive(grad)\n",
    "        \n",
    "    def already_rec(self,grad,):\n",
    "        bts = str(grad).encode('utf-8')#tf.io.serialize_tensor(grad)\n",
    "        hashed = hashlib.sha256(bts).digest()\n",
    "        \n",
    "        if hashed in self.rec_grad:\n",
    "            return (True,hashed)\n",
    "        else:\n",
    "            return (False,hashed)\n",
    "        \n",
    "    def apply_grad(self,grad,hashed,target,):\n",
    "        self.rec_grad.add(hashed)\n",
    "        return tf.math.add(target,grad)\n",
    "    \n",
    "    def apply_grads(self,target,):\n",
    "        self.fwd_q=[]\n",
    "        for g in self.new_grad:\n",
    "            bl,hashed = self.already_rec(g)\n",
    "            if not bl:\n",
    "                target = self.apply_grad(g,hashed,target)\n",
    "                self.fwd_q.append(g)\n",
    "#                 self.roc_grad.add(hashed)\n",
    "#                 np.math.add(target,grad)\n",
    "        self.new_grad=[]\n",
    "        return target\n",
    "    \n",
    "    def receive(self,grad,):\n",
    "        self.new_grad.append(grad)\n",
    "        \n",
    "\n",
    "lst_cars = [\n",
    "    Car([1]),\n",
    "    Car([0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([21., 21., 21., 21., 21., 21., 21., 21., 21., 21.], dtype=float32)>"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_cars[0].receive(tf.ones(10)*2)\n",
    "lst_cars[1].receive(tf.ones(10)*3)\n",
    "lst_cars[1].receive(tf.ones(10)*5)\n",
    "\n",
    "lst_cars[0].apply_grads(tf.ones(10)*7)\n",
    "lst_cars[0].forward(lst_cars)\n",
    "\n",
    "lst_cars[1].apply_grads(tf.ones(10)*11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(10,), dtype=float32, numpy=array([3., 3., 3., 3., 3., 3., 3., 3., 3., 3.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=array([5., 5., 5., 5., 5., 5., 5., 5., 5., 5.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=array([2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], dtype=float32)>]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_cars[1].fwd_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from copy import deepcopy\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "\n",
    "def gen_mask(grads,m=2):\n",
    "    mask = []\n",
    "    for g in grads:\n",
    "        size = g.shape[0]\n",
    "        assert m%1==0\n",
    "\n",
    "        split = tf.concat([tf.ones(size//m)*i for i in range(m)],0)\n",
    "        split = tf.random.shuffle(split)\n",
    "        mask.append(tf.reshape(split,(-1,1)))\n",
    "\n",
    "    return mask\n",
    "\n",
    "class DistMLP(keras.Model):\n",
    "    def __init__(self,mode='none'):\n",
    "        super(DistMLP, self).__init__()\n",
    "        self.mod1 = Sequential([\n",
    "            layers.Dense(1024, activation='relu', input_shape=(28**2,)),\n",
    "            layers.Dense(32, activation='relu'),\n",
    "            layers.Dense(16, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(10, 'softmax')\n",
    "        ])\n",
    "        \n",
    "        self.mod2 = tf.keras.models.clone_model(self.mod1)\n",
    "        self.mod3 = tf.keras.models.clone_model(self.mod1)\n",
    "        self.mod4 = tf.keras.models.clone_model(self.mod1)\n",
    "        \n",
    "        self.mode=mode\n",
    "        \n",
    "#         self.edges = [(0,1),(1,2),(2,3),(3,0),]\n",
    "        self.cars = [Car[i%2] for i in range(1,5)]\n",
    "        self.gradients = []\n",
    "#         self.seen_gradients = [set(),set(),set(),set()]\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.mod1(data)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x1,y1,x2,y2,x3,y3,x4,y4, = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred1 = self.mod1(x1,training=True)\n",
    "            y_pred2 = self.mod2(x2,training=True)\n",
    "            y_pred3 = self.mod3(x3,training=True)\n",
    "            y_pred4 = self.mod4(x4,training=True)\n",
    "            loss1 = self.compiled_loss(y1,y_pred1)\n",
    "            loss2 = self.compiled_loss(y2,y_pred2)\n",
    "            loss3 = self.compiled_loss(y3,y_pred3)\n",
    "            loss4 = self.compiled_loss(y4,y_pred4)\n",
    "\n",
    "        grads = tape.gradient([loss1,loss2,loss3,loss4], self.trainable_weights)\n",
    "        \n",
    "        if self.mode=='none':\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        elif self.mode=='simple_add':\n",
    "            temp = [tf.math.add_n([grads[n+i*(len(grads)//4)] for i in range(4)]) for n in range(len(grads)//4)]\n",
    "            self.optimizer.apply_gradients(zip([*temp,*temp,*temp,*temp], self.trainable_weights))\n",
    "        elif self.mode=='djgrad':\n",
    "#             new_grads = []\n",
    "#             self.gradients.insert(0,[[],[],[],[]])\n",
    "#             if len(self.gradients)>4:\n",
    "#                 self.gradients = self.gradients[:-1]\n",
    "            \n",
    "            grad_mask = gen_mask(grads)\n",
    "            \n",
    "            for c in self.cars:\n",
    "#                 lst_masked_grads = []\n",
    "#                 lst_forwarded_grads = []\n",
    "                for n in range(len(grads)//4):\n",
    "                    \n",
    "#                     main_gi = n+s[0]*(len(grads)//4)\n",
    "#                     other_gi = n+s[1]*(len(grads)//4)\n",
    "#                     masked_grads = tf.math.multiply(\n",
    "#                             grads[other_gi],\n",
    "#                             tf.reshape(grad_mask[other_gi],(-1,)) if len(grads[other_gi].shape)==1 else grad_mask[other_gi]\n",
    "#                         )\n",
    "                    \n",
    "#                     lst_masked_grads.append(masked_grads)\n",
    "#                     if len(self.gradients)>1 and len(self.gradients[1][s[1]])==2:\n",
    "#                         if len(self.gradients[1][s[1]][1])>0:\n",
    "#                             if np.random.random()>0.2:\n",
    "#                                 masked_grads = tf.math.add(masked_grads,self.gradients[1][s[1]][1][n])\n",
    "#                         lst_forwarded_grads.append(self.gradients[1][s[1]][0][n])\n",
    "\n",
    "#                     new_grads.append(tf.math.add_n([\n",
    "#                         grads[main_gi], # original model\n",
    "#                         masked_grads # model receiving data from\n",
    "#                     ]))\n",
    "    \n",
    "#                 self.gradients[0][s[0]].append(lst_masked_grads)\n",
    "#                 self.gradients[0][s[0]].append(lst_forwarded_grads)\n",
    "                            \n",
    "            self.optimizer.apply_gradients(zip(\n",
    "                new_grads,\n",
    "                self.trainable_weights))\n",
    "        \n",
    "        # Need a metric that gives accuracy for each model individually\n",
    "        self.compiled_metrics.update_state(tf.concat([y1,y2,y3,y4],0), tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0))\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        y_pred1 = self.mod1(x,training=False)\n",
    "        y_pred2 = self.mod2(x,training=False)\n",
    "        y_pred3 = self.mod3(x,training=False)\n",
    "        y_pred4 = self.mod4(x,training=False)\n",
    "        \n",
    "        self.compiled_loss(tf.concat([y,y,y,y,],0),tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0))\n",
    "        self.compiled_metrics.update_state(tf.concat([y,y,y,y],0),tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0))\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 3.7337 - accuracy: 0.2935 - val_loss: 2.1416 - val_accuracy: 0.2635\n",
      "Epoch 2/100\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 1.8244 - accuracy: 0.3599 - val_loss: 2.0252 - val_accuracy: 0.2724\n",
      "Epoch 3/100\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 1.7135 - accuracy: 0.3954 - val_loss: 2.1154 - val_accuracy: 0.2934\n",
      "Epoch 4/100\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.6882 - accuracy: 0.3977 - val_loss: 1.9792 - val_accuracy: 0.3003\n",
      "Epoch 5/100\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.6013 - accuracy: 0.4254 - val_loss: 2.0592 - val_accuracy: 0.3510\n",
      "Epoch 6/100\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 1.5511 - accuracy: 0.4421 - val_loss: 2.0249 - val_accuracy: 0.3338\n",
      "Epoch 7/100\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 1.5061 - accuracy: 0.4572 - val_loss: 2.1359 - val_accuracy: 0.3665\n",
      "Epoch 8/100\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 1.4376 - accuracy: 0.4807 - val_loss: 2.0697 - val_accuracy: 0.3725\n",
      "Epoch 9/100\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 1.4185 - accuracy: 0.4863 - val_loss: 2.0974 - val_accuracy: 0.3928\n",
      "Epoch 10/100\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.3269 - accuracy: 0.5181 - val_loss: 1.9803 - val_accuracy: 0.4052\n",
      "Epoch 11/100\n",
      " 82/115 [====================>.........] - ETA: 1s - loss: 1.2635 - accuracy: 0.5378"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-282-543a777c4b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m history = m.fit(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    851\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    844\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1284\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1285\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1286\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2847\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2849\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3632\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-281-95a53b846b1c>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Need a metric that gives accuracy for each model individually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1767\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1768\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1769\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1207\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1210\u001b[0m         _ctx, \"ConcatV2\", name, values, axis)\n\u001b[1;32m   1211\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('djgrad')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 3.8043 - accuracy: 0.3222 - val_loss: 1.9565 - val_accuracy: 0.2872\n",
      "Epoch 2/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 1.7270 - accuracy: 0.3944 - val_loss: 2.0787 - val_accuracy: 0.3589\n",
      "Epoch 3/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 1.6235 - accuracy: 0.4343 - val_loss: 2.0723 - val_accuracy: 0.3557\n",
      "Epoch 4/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.5608 - accuracy: 0.4480 - val_loss: 1.9192 - val_accuracy: 0.3845\n",
      "Epoch 5/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.5083 - accuracy: 0.4632 - val_loss: 1.8369 - val_accuracy: 0.4069\n",
      "Epoch 6/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.4486 - accuracy: 0.4824 - val_loss: 2.0461 - val_accuracy: 0.4198\n",
      "Epoch 7/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 1.3713 - accuracy: 0.5040 - val_loss: 2.0156 - val_accuracy: 0.4296\n",
      "Epoch 8/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.3233 - accuracy: 0.5132 - val_loss: 1.9999 - val_accuracy: 0.4581\n",
      "Epoch 9/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 1.3003 - accuracy: 0.5211 - val_loss: 2.0780 - val_accuracy: 0.4657\n",
      "Epoch 10/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.2658 - accuracy: 0.5347 - val_loss: 1.9845 - val_accuracy: 0.4804\n",
      "Epoch 11/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.2415 - accuracy: 0.5420 - val_loss: 1.9251 - val_accuracy: 0.4704\n",
      "Epoch 12/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.2235 - accuracy: 0.5474 - val_loss: 2.0327 - val_accuracy: 0.4896\n",
      "Epoch 13/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.1989 - accuracy: 0.5625 - val_loss: 2.1732 - val_accuracy: 0.5081\n",
      "Epoch 14/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.1754 - accuracy: 0.5728 - val_loss: 2.1288 - val_accuracy: 0.5250\n",
      "Epoch 15/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.1295 - accuracy: 0.5897 - val_loss: 2.1208 - val_accuracy: 0.5323\n",
      "Epoch 16/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.0846 - accuracy: 0.6056 - val_loss: 2.1638 - val_accuracy: 0.5447\n",
      "Epoch 17/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.0662 - accuracy: 0.6189 - val_loss: 2.2700 - val_accuracy: 0.5506\n",
      "Epoch 18/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.0299 - accuracy: 0.6377 - val_loss: 2.2723 - val_accuracy: 0.5639\n",
      "Epoch 19/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.0031 - accuracy: 0.6485 - val_loss: 2.2669 - val_accuracy: 0.5686\n",
      "Epoch 20/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 1.0130 - accuracy: 0.6441 - val_loss: 2.1342 - val_accuracy: 0.5667\n",
      "Epoch 21/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.9750 - accuracy: 0.6556 - val_loss: 2.3881 - val_accuracy: 0.5791\n",
      "Epoch 22/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.9671 - accuracy: 0.6589 - val_loss: 2.2228 - val_accuracy: 0.5721\n",
      "Epoch 23/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.9450 - accuracy: 0.6690 - val_loss: 2.2512 - val_accuracy: 0.5896\n",
      "Epoch 24/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.9217 - accuracy: 0.6798 - val_loss: 2.3340 - val_accuracy: 0.5904\n",
      "Epoch 25/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.9015 - accuracy: 0.6881 - val_loss: 2.3391 - val_accuracy: 0.5980\n",
      "Epoch 26/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.8694 - accuracy: 0.6967 - val_loss: 2.2170 - val_accuracy: 0.5996\n",
      "Epoch 27/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.8425 - accuracy: 0.7079 - val_loss: 2.3391 - val_accuracy: 0.6078\n",
      "Epoch 28/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.8363 - accuracy: 0.7103 - val_loss: 2.5300 - val_accuracy: 0.6019\n",
      "Epoch 29/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.8206 - accuracy: 0.7165 - val_loss: 2.5491 - val_accuracy: 0.6153\n",
      "Epoch 30/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.8252 - accuracy: 0.7146 - val_loss: 2.4207 - val_accuracy: 0.6143\n",
      "Epoch 31/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.8163 - accuracy: 0.7197 - val_loss: 2.5144 - val_accuracy: 0.6078\n",
      "Epoch 32/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7977 - accuracy: 0.7238 - val_loss: 2.5342 - val_accuracy: 0.6119\n",
      "Epoch 33/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7926 - accuracy: 0.7273 - val_loss: 2.5456 - val_accuracy: 0.6114\n",
      "Epoch 34/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7999 - accuracy: 0.7255 - val_loss: 2.5811 - val_accuracy: 0.6183\n",
      "Epoch 35/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7861 - accuracy: 0.7278 - val_loss: 2.5483 - val_accuracy: 0.6121\n",
      "Epoch 36/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7626 - accuracy: 0.7341 - val_loss: 2.4648 - val_accuracy: 0.6154\n",
      "Epoch 37/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7576 - accuracy: 0.7377 - val_loss: 2.6817 - val_accuracy: 0.6189\n",
      "Epoch 38/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7469 - accuracy: 0.7415 - val_loss: 2.6038 - val_accuracy: 0.6166\n",
      "Epoch 39/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7388 - accuracy: 0.7461 - val_loss: 2.6251 - val_accuracy: 0.6212\n",
      "Epoch 40/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7161 - accuracy: 0.7520 - val_loss: 2.6574 - val_accuracy: 0.6223\n",
      "Epoch 41/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7238 - accuracy: 0.7488 - val_loss: 2.6446 - val_accuracy: 0.6226\n",
      "Epoch 42/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7183 - accuracy: 0.7490 - val_loss: 2.6882 - val_accuracy: 0.6215\n",
      "Epoch 43/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7128 - accuracy: 0.7489 - val_loss: 2.7310 - val_accuracy: 0.6226\n",
      "Epoch 44/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7300 - accuracy: 0.7478 - val_loss: 2.6886 - val_accuracy: 0.6244\n",
      "Epoch 45/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.7022 - accuracy: 0.7557 - val_loss: 2.7780 - val_accuracy: 0.6223\n",
      "Epoch 46/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6933 - accuracy: 0.7567 - val_loss: 2.6593 - val_accuracy: 0.6237\n",
      "Epoch 47/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6834 - accuracy: 0.7592 - val_loss: 2.7189 - val_accuracy: 0.6262\n",
      "Epoch 48/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6787 - accuracy: 0.7614 - val_loss: 2.7160 - val_accuracy: 0.6257\n",
      "Epoch 49/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6739 - accuracy: 0.7636 - val_loss: 2.7686 - val_accuracy: 0.6215\n",
      "Epoch 50/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6753 - accuracy: 0.7619 - val_loss: 2.8323 - val_accuracy: 0.6249\n",
      "Epoch 51/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6604 - accuracy: 0.7670 - val_loss: 2.7692 - val_accuracy: 0.6253\n",
      "Epoch 52/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6441 - accuracy: 0.7700 - val_loss: 2.7798 - val_accuracy: 0.6241\n",
      "Epoch 53/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6457 - accuracy: 0.7696 - val_loss: 2.8843 - val_accuracy: 0.6262\n",
      "Epoch 54/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6379 - accuracy: 0.7702 - val_loss: 2.8620 - val_accuracy: 0.6247\n",
      "Epoch 55/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6472 - accuracy: 0.7677 - val_loss: 2.8867 - val_accuracy: 0.6261\n",
      "Epoch 56/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6293 - accuracy: 0.7719 - val_loss: 2.8753 - val_accuracy: 0.6254\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6295 - accuracy: 0.7734 - val_loss: 2.8120 - val_accuracy: 0.6271\n",
      "Epoch 58/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6338 - accuracy: 0.7732 - val_loss: 2.8792 - val_accuracy: 0.6250\n",
      "Epoch 59/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6251 - accuracy: 0.7740 - val_loss: 2.9505 - val_accuracy: 0.6272\n",
      "Epoch 60/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6116 - accuracy: 0.7777 - val_loss: 3.0307 - val_accuracy: 0.6286\n",
      "Epoch 61/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6144 - accuracy: 0.7778 - val_loss: 2.8377 - val_accuracy: 0.6277\n",
      "Epoch 62/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6011 - accuracy: 0.7816 - val_loss: 2.9784 - val_accuracy: 0.6269\n",
      "Epoch 63/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6014 - accuracy: 0.7835 - val_loss: 2.9789 - val_accuracy: 0.6273\n",
      "Epoch 64/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5946 - accuracy: 0.7841 - val_loss: 2.9284 - val_accuracy: 0.6298\n",
      "Epoch 65/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5929 - accuracy: 0.7856 - val_loss: 2.9584 - val_accuracy: 0.6266\n",
      "Epoch 66/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5914 - accuracy: 0.7855 - val_loss: 2.9996 - val_accuracy: 0.6291\n",
      "Epoch 67/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5968 - accuracy: 0.7868 - val_loss: 2.9801 - val_accuracy: 0.6285\n",
      "Epoch 68/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5814 - accuracy: 0.7884 - val_loss: 2.9657 - val_accuracy: 0.6302\n",
      "Epoch 69/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5738 - accuracy: 0.7907 - val_loss: 3.0217 - val_accuracy: 0.6307\n",
      "Epoch 70/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5886 - accuracy: 0.7874 - val_loss: 3.0470 - val_accuracy: 0.6307\n",
      "Epoch 71/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5910 - accuracy: 0.7872 - val_loss: 2.9655 - val_accuracy: 0.6297\n",
      "Epoch 72/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6015 - accuracy: 0.7845 - val_loss: 2.9628 - val_accuracy: 0.6306\n",
      "Epoch 73/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.6052 - accuracy: 0.7847 - val_loss: 2.9721 - val_accuracy: 0.6255\n",
      "Epoch 74/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5908 - accuracy: 0.7865 - val_loss: 2.9359 - val_accuracy: 0.6278\n",
      "Epoch 75/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5882 - accuracy: 0.7890 - val_loss: 2.9931 - val_accuracy: 0.6295\n",
      "Epoch 76/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5730 - accuracy: 0.7968 - val_loss: 3.0059 - val_accuracy: 0.6289\n",
      "Epoch 77/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5533 - accuracy: 0.8009 - val_loss: 3.0501 - val_accuracy: 0.6308\n",
      "Epoch 78/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5456 - accuracy: 0.8020 - val_loss: 2.9942 - val_accuracy: 0.6303\n",
      "Epoch 79/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5392 - accuracy: 0.8037 - val_loss: 3.0632 - val_accuracy: 0.6320\n",
      "Epoch 80/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5451 - accuracy: 0.8049 - val_loss: 3.0863 - val_accuracy: 0.6313\n",
      "Epoch 81/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5316 - accuracy: 0.8072 - val_loss: 3.0758 - val_accuracy: 0.6309\n",
      "Epoch 82/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5341 - accuracy: 0.8055 - val_loss: 2.9979 - val_accuracy: 0.6319\n",
      "Epoch 83/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5211 - accuracy: 0.8094 - val_loss: 3.0701 - val_accuracy: 0.6323\n",
      "Epoch 84/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5233 - accuracy: 0.8087 - val_loss: 3.1106 - val_accuracy: 0.6328\n",
      "Epoch 85/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5294 - accuracy: 0.8091 - val_loss: 3.0008 - val_accuracy: 0.6319\n",
      "Epoch 86/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5279 - accuracy: 0.8095 - val_loss: 3.0650 - val_accuracy: 0.6300\n",
      "Epoch 87/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5373 - accuracy: 0.8080 - val_loss: 3.0436 - val_accuracy: 0.6311\n",
      "Epoch 88/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5322 - accuracy: 0.8071 - val_loss: 3.0610 - val_accuracy: 0.6323\n",
      "Epoch 89/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5360 - accuracy: 0.8095 - val_loss: 3.0721 - val_accuracy: 0.6312\n",
      "Epoch 90/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5356 - accuracy: 0.8062 - val_loss: 3.0899 - val_accuracy: 0.6302\n",
      "Epoch 91/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5341 - accuracy: 0.8083 - val_loss: 3.0723 - val_accuracy: 0.6323\n",
      "Epoch 92/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5243 - accuracy: 0.8104 - val_loss: 3.1546 - val_accuracy: 0.6316\n",
      "Epoch 93/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5193 - accuracy: 0.8105 - val_loss: 3.0891 - val_accuracy: 0.6320\n",
      "Epoch 94/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5248 - accuracy: 0.8098 - val_loss: 3.0570 - val_accuracy: 0.6284\n",
      "Epoch 95/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5225 - accuracy: 0.8100 - val_loss: 3.1267 - val_accuracy: 0.6311\n",
      "Epoch 96/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5197 - accuracy: 0.8125 - val_loss: 3.1582 - val_accuracy: 0.6325\n",
      "Epoch 97/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5193 - accuracy: 0.8113 - val_loss: 3.1103 - val_accuracy: 0.6300\n",
      "Epoch 98/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5300 - accuracy: 0.8109 - val_loss: 3.0140 - val_accuracy: 0.6299\n",
      "Epoch 99/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5320 - accuracy: 0.8103 - val_loss: 3.0393 - val_accuracy: 0.6299\n",
      "Epoch 100/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5319 - accuracy: 0.8099 - val_loss: 3.1235 - val_accuracy: 0.6320\n",
      "Epoch 101/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5328 - accuracy: 0.8114 - val_loss: 3.1197 - val_accuracy: 0.6298\n",
      "Epoch 102/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5302 - accuracy: 0.8117 - val_loss: 3.0388 - val_accuracy: 0.6310\n",
      "Epoch 103/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5190 - accuracy: 0.8131 - val_loss: 3.1247 - val_accuracy: 0.6319\n",
      "Epoch 104/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5195 - accuracy: 0.8132 - val_loss: 3.0888 - val_accuracy: 0.6309\n",
      "Epoch 105/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5116 - accuracy: 0.8155 - val_loss: 3.1715 - val_accuracy: 0.6320\n",
      "Epoch 106/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5136 - accuracy: 0.8152 - val_loss: 3.1850 - val_accuracy: 0.6325\n",
      "Epoch 107/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5037 - accuracy: 0.8173 - val_loss: 3.1898 - val_accuracy: 0.6320\n",
      "Epoch 108/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5017 - accuracy: 0.8174 - val_loss: 3.1259 - val_accuracy: 0.6333\n",
      "Epoch 109/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5075 - accuracy: 0.8171 - val_loss: 3.1407 - val_accuracy: 0.6328\n",
      "Epoch 110/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5134 - accuracy: 0.8172 - val_loss: 3.1445 - val_accuracy: 0.6337\n",
      "Epoch 111/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5281 - accuracy: 0.8141 - val_loss: 3.1473 - val_accuracy: 0.6312\n",
      "Epoch 112/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5123 - accuracy: 0.8161 - val_loss: 3.1215 - val_accuracy: 0.6325\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5087 - accuracy: 0.8163 - val_loss: 3.2067 - val_accuracy: 0.6320\n",
      "Epoch 114/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5048 - accuracy: 0.8174 - val_loss: 3.2153 - val_accuracy: 0.6330\n",
      "Epoch 115/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5077 - accuracy: 0.8169 - val_loss: 3.2031 - val_accuracy: 0.6321\n",
      "Epoch 116/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5230 - accuracy: 0.8140 - val_loss: 3.1745 - val_accuracy: 0.6313\n",
      "Epoch 117/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5006 - accuracy: 0.8187 - val_loss: 3.1952 - val_accuracy: 0.6340\n",
      "Epoch 118/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4992 - accuracy: 0.8199 - val_loss: 3.1948 - val_accuracy: 0.6337\n",
      "Epoch 119/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5012 - accuracy: 0.8192 - val_loss: 3.1898 - val_accuracy: 0.6320\n",
      "Epoch 120/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5173 - accuracy: 0.8157 - val_loss: 3.2105 - val_accuracy: 0.6315\n",
      "Epoch 121/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5097 - accuracy: 0.8178 - val_loss: 3.2023 - val_accuracy: 0.6294\n",
      "Epoch 122/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5050 - accuracy: 0.8187 - val_loss: 3.1380 - val_accuracy: 0.6328\n",
      "Epoch 123/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5009 - accuracy: 0.8190 - val_loss: 3.2230 - val_accuracy: 0.6317\n",
      "Epoch 124/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4957 - accuracy: 0.8196 - val_loss: 3.2167 - val_accuracy: 0.6346\n",
      "Epoch 125/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5164 - accuracy: 0.8173 - val_loss: 3.2517 - val_accuracy: 0.6323\n",
      "Epoch 126/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5031 - accuracy: 0.8197 - val_loss: 3.2794 - val_accuracy: 0.6343\n",
      "Epoch 127/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5016 - accuracy: 0.8174 - val_loss: 3.1666 - val_accuracy: 0.6317\n",
      "Epoch 128/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4981 - accuracy: 0.8193 - val_loss: 3.2211 - val_accuracy: 0.6327\n",
      "Epoch 129/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5203 - accuracy: 0.8162 - val_loss: 3.2027 - val_accuracy: 0.6322\n",
      "Epoch 130/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5086 - accuracy: 0.8185 - val_loss: 3.2348 - val_accuracy: 0.6320\n",
      "Epoch 131/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5235 - accuracy: 0.8181 - val_loss: 3.2015 - val_accuracy: 0.6320\n",
      "Epoch 132/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5211 - accuracy: 0.8145 - val_loss: 3.2323 - val_accuracy: 0.6296\n",
      "Epoch 133/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5167 - accuracy: 0.8152 - val_loss: 3.2753 - val_accuracy: 0.6323\n",
      "Epoch 134/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5051 - accuracy: 0.8193 - val_loss: 3.2795 - val_accuracy: 0.6310\n",
      "Epoch 135/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5090 - accuracy: 0.8177 - val_loss: 3.2561 - val_accuracy: 0.6329\n",
      "Epoch 136/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4979 - accuracy: 0.8189 - val_loss: 3.2929 - val_accuracy: 0.6342\n",
      "Epoch 137/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5200 - accuracy: 0.8165 - val_loss: 3.3028 - val_accuracy: 0.6334\n",
      "Epoch 138/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5039 - accuracy: 0.8186 - val_loss: 3.2692 - val_accuracy: 0.6333\n",
      "Epoch 139/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4959 - accuracy: 0.8205 - val_loss: 3.2646 - val_accuracy: 0.6329\n",
      "Epoch 140/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5072 - accuracy: 0.8177 - val_loss: 3.2596 - val_accuracy: 0.6321\n",
      "Epoch 141/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5122 - accuracy: 0.8158 - val_loss: 3.2528 - val_accuracy: 0.6335\n",
      "Epoch 142/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5061 - accuracy: 0.8190 - val_loss: 3.2465 - val_accuracy: 0.6330\n",
      "Epoch 143/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5058 - accuracy: 0.8176 - val_loss: 3.2485 - val_accuracy: 0.6318\n",
      "Epoch 144/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4922 - accuracy: 0.8194 - val_loss: 3.3145 - val_accuracy: 0.6341\n",
      "Epoch 145/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4983 - accuracy: 0.8191 - val_loss: 3.2869 - val_accuracy: 0.6338\n",
      "Epoch 146/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4971 - accuracy: 0.8212 - val_loss: 3.2829 - val_accuracy: 0.6325\n",
      "Epoch 147/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5054 - accuracy: 0.8186 - val_loss: 3.3083 - val_accuracy: 0.6328\n",
      "Epoch 148/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4927 - accuracy: 0.8208 - val_loss: 3.3419 - val_accuracy: 0.6331\n",
      "Epoch 149/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5062 - accuracy: 0.8188 - val_loss: 3.3539 - val_accuracy: 0.6336\n",
      "Epoch 150/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4945 - accuracy: 0.8200 - val_loss: 3.2991 - val_accuracy: 0.6350\n",
      "Epoch 151/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4946 - accuracy: 0.8204 - val_loss: 3.3134 - val_accuracy: 0.6334\n",
      "Epoch 152/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4958 - accuracy: 0.8209 - val_loss: 3.2834 - val_accuracy: 0.6346\n",
      "Epoch 153/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5091 - accuracy: 0.8185 - val_loss: 3.2662 - val_accuracy: 0.6328\n",
      "Epoch 154/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4923 - accuracy: 0.8212 - val_loss: 3.2998 - val_accuracy: 0.6338\n",
      "Epoch 155/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4980 - accuracy: 0.8202 - val_loss: 3.3331 - val_accuracy: 0.6338\n",
      "Epoch 156/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4969 - accuracy: 0.8198 - val_loss: 3.3555 - val_accuracy: 0.6329\n",
      "Epoch 157/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5022 - accuracy: 0.8188 - val_loss: 3.3327 - val_accuracy: 0.6333\n",
      "Epoch 158/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5085 - accuracy: 0.8176 - val_loss: 3.3262 - val_accuracy: 0.6333\n",
      "Epoch 159/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4961 - accuracy: 0.8212 - val_loss: 3.3315 - val_accuracy: 0.6312\n",
      "Epoch 160/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5040 - accuracy: 0.8198 - val_loss: 3.3918 - val_accuracy: 0.6281\n",
      "Epoch 161/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5011 - accuracy: 0.8183 - val_loss: 3.3563 - val_accuracy: 0.6305\n",
      "Epoch 162/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4976 - accuracy: 0.8202 - val_loss: 3.3698 - val_accuracy: 0.6312\n",
      "Epoch 163/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4913 - accuracy: 0.8208 - val_loss: 3.3382 - val_accuracy: 0.6333\n",
      "Epoch 164/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4934 - accuracy: 0.8195 - val_loss: 3.3444 - val_accuracy: 0.6328\n",
      "Epoch 165/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4857 - accuracy: 0.8222 - val_loss: 3.3509 - val_accuracy: 0.6311\n",
      "Epoch 166/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4919 - accuracy: 0.8207 - val_loss: 3.3613 - val_accuracy: 0.6326\n",
      "Epoch 167/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4824 - accuracy: 0.8237 - val_loss: 3.3802 - val_accuracy: 0.6320\n",
      "Epoch 168/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4800 - accuracy: 0.8245 - val_loss: 3.3867 - val_accuracy: 0.6332\n",
      "Epoch 169/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4808 - accuracy: 0.8234 - val_loss: 3.4113 - val_accuracy: 0.6297\n",
      "Epoch 170/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4921 - accuracy: 0.8224 - val_loss: 3.3316 - val_accuracy: 0.6302\n",
      "Epoch 171/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4826 - accuracy: 0.8239 - val_loss: 3.3779 - val_accuracy: 0.6330\n",
      "Epoch 172/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4799 - accuracy: 0.8247 - val_loss: 3.3770 - val_accuracy: 0.6343\n",
      "Epoch 173/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4754 - accuracy: 0.8264 - val_loss: 3.3918 - val_accuracy: 0.6348\n",
      "Epoch 174/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4749 - accuracy: 0.8271 - val_loss: 3.3616 - val_accuracy: 0.6338\n",
      "Epoch 175/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4677 - accuracy: 0.8277 - val_loss: 3.3797 - val_accuracy: 0.6346\n",
      "Epoch 176/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4701 - accuracy: 0.8279 - val_loss: 3.3935 - val_accuracy: 0.6344\n",
      "Epoch 177/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4671 - accuracy: 0.8285 - val_loss: 3.4005 - val_accuracy: 0.6340\n",
      "Epoch 178/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4720 - accuracy: 0.8289 - val_loss: 3.4300 - val_accuracy: 0.6335\n",
      "Epoch 179/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4778 - accuracy: 0.8271 - val_loss: 3.4511 - val_accuracy: 0.6315\n",
      "Epoch 180/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4802 - accuracy: 0.8256 - val_loss: 3.4037 - val_accuracy: 0.6324\n",
      "Epoch 181/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4756 - accuracy: 0.8263 - val_loss: 3.4756 - val_accuracy: 0.6323\n",
      "Epoch 182/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4708 - accuracy: 0.8274 - val_loss: 3.4277 - val_accuracy: 0.6326\n",
      "Epoch 183/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4853 - accuracy: 0.8259 - val_loss: 3.4467 - val_accuracy: 0.6332\n",
      "Epoch 184/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4643 - accuracy: 0.8294 - val_loss: 3.4531 - val_accuracy: 0.6343\n",
      "Epoch 185/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4601 - accuracy: 0.8309 - val_loss: 3.4430 - val_accuracy: 0.6351\n",
      "Epoch 186/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4801 - accuracy: 0.8272 - val_loss: 3.4550 - val_accuracy: 0.6314\n",
      "Epoch 187/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4914 - accuracy: 0.8242 - val_loss: 3.4767 - val_accuracy: 0.6299\n",
      "Epoch 188/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4972 - accuracy: 0.8237 - val_loss: 3.4317 - val_accuracy: 0.6315\n",
      "Epoch 189/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4836 - accuracy: 0.8270 - val_loss: 3.4355 - val_accuracy: 0.6327\n",
      "Epoch 190/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4717 - accuracy: 0.8287 - val_loss: 3.4628 - val_accuracy: 0.6322\n",
      "Epoch 191/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4789 - accuracy: 0.8275 - val_loss: 3.4530 - val_accuracy: 0.6320\n",
      "Epoch 192/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4703 - accuracy: 0.8283 - val_loss: 3.4708 - val_accuracy: 0.6314\n",
      "Epoch 193/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4732 - accuracy: 0.8296 - val_loss: 3.4780 - val_accuracy: 0.6328\n",
      "Epoch 194/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4669 - accuracy: 0.8297 - val_loss: 3.4858 - val_accuracy: 0.6331\n",
      "Epoch 195/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4627 - accuracy: 0.8305 - val_loss: 3.4882 - val_accuracy: 0.6334\n",
      "Epoch 196/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4610 - accuracy: 0.8272 - val_loss: 3.5122 - val_accuracy: 0.6323\n",
      "Epoch 197/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4647 - accuracy: 0.8303 - val_loss: 3.4818 - val_accuracy: 0.6338\n",
      "Epoch 198/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5053 - accuracy: 0.8272 - val_loss: 3.5093 - val_accuracy: 0.6333\n",
      "Epoch 199/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4656 - accuracy: 0.8291 - val_loss: 3.4926 - val_accuracy: 0.6341\n",
      "Epoch 200/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4702 - accuracy: 0.8278 - val_loss: 3.4922 - val_accuracy: 0.6342\n",
      "Epoch 201/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4644 - accuracy: 0.8299 - val_loss: 3.5321 - val_accuracy: 0.6345\n",
      "Epoch 202/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4692 - accuracy: 0.8283 - val_loss: 3.5107 - val_accuracy: 0.6327\n",
      "Epoch 203/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4754 - accuracy: 0.8279 - val_loss: 3.5050 - val_accuracy: 0.6320\n",
      "Epoch 204/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4637 - accuracy: 0.8295 - val_loss: 3.5291 - val_accuracy: 0.6340\n",
      "Epoch 205/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5171 - accuracy: 0.8268 - val_loss: 3.5209 - val_accuracy: 0.6300\n",
      "Epoch 206/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4736 - accuracy: 0.8268 - val_loss: 3.5290 - val_accuracy: 0.6325\n",
      "Epoch 207/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4707 - accuracy: 0.8286 - val_loss: 3.5046 - val_accuracy: 0.6323\n",
      "Epoch 208/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4785 - accuracy: 0.8283 - val_loss: 3.5511 - val_accuracy: 0.6332\n",
      "Epoch 209/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4661 - accuracy: 0.8310 - val_loss: 3.5284 - val_accuracy: 0.6333\n",
      "Epoch 210/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4643 - accuracy: 0.8300 - val_loss: 3.5319 - val_accuracy: 0.6341\n",
      "Epoch 211/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4592 - accuracy: 0.8315 - val_loss: 3.5366 - val_accuracy: 0.6340\n",
      "Epoch 212/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4605 - accuracy: 0.8301 - val_loss: 3.5456 - val_accuracy: 0.6340\n",
      "Epoch 213/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4561 - accuracy: 0.8320 - val_loss: 3.5487 - val_accuracy: 0.6349\n",
      "Epoch 214/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4596 - accuracy: 0.8317 - val_loss: 3.5576 - val_accuracy: 0.6348\n",
      "Epoch 215/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4567 - accuracy: 0.8307 - val_loss: 3.5445 - val_accuracy: 0.6346\n",
      "Epoch 216/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4543 - accuracy: 0.8312 - val_loss: 3.5542 - val_accuracy: 0.6335\n",
      "Epoch 217/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4565 - accuracy: 0.8318 - val_loss: 3.5369 - val_accuracy: 0.6353\n",
      "Epoch 218/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4569 - accuracy: 0.8305 - val_loss: 3.5705 - val_accuracy: 0.6344\n",
      "Epoch 219/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4662 - accuracy: 0.8300 - val_loss: 3.5772 - val_accuracy: 0.6327\n",
      "Epoch 220/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4657 - accuracy: 0.8297 - val_loss: 3.5571 - val_accuracy: 0.6326\n",
      "Epoch 221/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4667 - accuracy: 0.8300 - val_loss: 3.5933 - val_accuracy: 0.6336\n",
      "Epoch 222/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4665 - accuracy: 0.8299 - val_loss: 3.6031 - val_accuracy: 0.6326\n",
      "Epoch 223/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4603 - accuracy: 0.8312 - val_loss: 3.5865 - val_accuracy: 0.6318\n",
      "Epoch 224/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4678 - accuracy: 0.8277 - val_loss: 3.5735 - val_accuracy: 0.6348\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4582 - accuracy: 0.8299 - val_loss: 3.5849 - val_accuracy: 0.6350\n",
      "Epoch 226/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4522 - accuracy: 0.8321 - val_loss: 3.5853 - val_accuracy: 0.6352\n",
      "Epoch 227/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4533 - accuracy: 0.8318 - val_loss: 3.6240 - val_accuracy: 0.6341\n",
      "Epoch 228/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4526 - accuracy: 0.8329 - val_loss: 3.6086 - val_accuracy: 0.6338\n",
      "Epoch 229/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4739 - accuracy: 0.8299 - val_loss: 3.6207 - val_accuracy: 0.6328\n",
      "Epoch 230/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4673 - accuracy: 0.8295 - val_loss: 3.6254 - val_accuracy: 0.6315\n",
      "Epoch 231/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4656 - accuracy: 0.8291 - val_loss: 3.5888 - val_accuracy: 0.6324\n",
      "Epoch 232/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4682 - accuracy: 0.8267 - val_loss: 3.6246 - val_accuracy: 0.6325\n",
      "Epoch 233/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4646 - accuracy: 0.8286 - val_loss: 3.6357 - val_accuracy: 0.6328\n",
      "Epoch 234/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4687 - accuracy: 0.8259 - val_loss: 3.6181 - val_accuracy: 0.6332\n",
      "Epoch 235/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4662 - accuracy: 0.8291 - val_loss: 3.6262 - val_accuracy: 0.6329\n",
      "Epoch 236/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4634 - accuracy: 0.8301 - val_loss: 3.6207 - val_accuracy: 0.6331\n",
      "Epoch 237/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4582 - accuracy: 0.8304 - val_loss: 3.6428 - val_accuracy: 0.6340\n",
      "Epoch 238/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4587 - accuracy: 0.8312 - val_loss: 3.6346 - val_accuracy: 0.6334\n",
      "Epoch 239/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4617 - accuracy: 0.8305 - val_loss: 3.6130 - val_accuracy: 0.6339\n",
      "Epoch 240/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4585 - accuracy: 0.8296 - val_loss: 3.6263 - val_accuracy: 0.6334\n",
      "Epoch 241/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4674 - accuracy: 0.8290 - val_loss: 3.5977 - val_accuracy: 0.6336\n",
      "Epoch 242/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4518 - accuracy: 0.8314 - val_loss: 3.6179 - val_accuracy: 0.6345\n",
      "Epoch 243/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4531 - accuracy: 0.8313 - val_loss: 3.6347 - val_accuracy: 0.6341\n",
      "Epoch 244/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4463 - accuracy: 0.8336 - val_loss: 3.6216 - val_accuracy: 0.6345\n",
      "Epoch 245/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4596 - accuracy: 0.8298 - val_loss: 3.6234 - val_accuracy: 0.6331\n",
      "Epoch 246/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4531 - accuracy: 0.8320 - val_loss: 3.6398 - val_accuracy: 0.6342\n",
      "Epoch 247/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4520 - accuracy: 0.8313 - val_loss: 3.6385 - val_accuracy: 0.6335\n",
      "Epoch 248/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4538 - accuracy: 0.8321 - val_loss: 3.6414 - val_accuracy: 0.6335\n",
      "Epoch 249/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4623 - accuracy: 0.8296 - val_loss: 3.6372 - val_accuracy: 0.6335\n",
      "Epoch 250/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4648 - accuracy: 0.8277 - val_loss: 3.6483 - val_accuracy: 0.6348\n",
      "Epoch 251/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4611 - accuracy: 0.8299 - val_loss: 3.6397 - val_accuracy: 0.6344\n",
      "Epoch 252/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4587 - accuracy: 0.8309 - val_loss: 3.6516 - val_accuracy: 0.6349\n",
      "Epoch 253/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4559 - accuracy: 0.8316 - val_loss: 3.6565 - val_accuracy: 0.6351\n",
      "Epoch 254/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4561 - accuracy: 0.8317 - val_loss: 3.6427 - val_accuracy: 0.6355\n",
      "Epoch 255/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4503 - accuracy: 0.8326 - val_loss: 3.6540 - val_accuracy: 0.6349\n",
      "Epoch 256/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4574 - accuracy: 0.8305 - val_loss: 3.6642 - val_accuracy: 0.6344\n",
      "Epoch 257/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4669 - accuracy: 0.8320 - val_loss: 3.6766 - val_accuracy: 0.6330\n",
      "Epoch 258/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4574 - accuracy: 0.8318 - val_loss: 3.6563 - val_accuracy: 0.6345\n",
      "Epoch 259/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4573 - accuracy: 0.8325 - val_loss: 3.6847 - val_accuracy: 0.6343\n",
      "Epoch 260/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4519 - accuracy: 0.8333 - val_loss: 3.6824 - val_accuracy: 0.6337\n",
      "Epoch 261/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4487 - accuracy: 0.8337 - val_loss: 3.6929 - val_accuracy: 0.6338\n",
      "Epoch 262/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4467 - accuracy: 0.8347 - val_loss: 3.6896 - val_accuracy: 0.6338\n",
      "Epoch 263/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4493 - accuracy: 0.8320 - val_loss: 3.6768 - val_accuracy: 0.6355\n",
      "Epoch 264/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4458 - accuracy: 0.8345 - val_loss: 3.6790 - val_accuracy: 0.6356\n",
      "Epoch 265/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4559 - accuracy: 0.8341 - val_loss: 3.7011 - val_accuracy: 0.6341\n",
      "Epoch 266/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4512 - accuracy: 0.8335 - val_loss: 3.7149 - val_accuracy: 0.6336\n",
      "Epoch 267/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4599 - accuracy: 0.8327 - val_loss: 3.7122 - val_accuracy: 0.6329\n",
      "Epoch 268/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4762 - accuracy: 0.8314 - val_loss: 3.7079 - val_accuracy: 0.6339\n",
      "Epoch 269/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4632 - accuracy: 0.8315 - val_loss: 3.7007 - val_accuracy: 0.6339\n",
      "Epoch 270/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4610 - accuracy: 0.8327 - val_loss: 3.7124 - val_accuracy: 0.6333\n",
      "Epoch 271/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4681 - accuracy: 0.8302 - val_loss: 3.7144 - val_accuracy: 0.6331\n",
      "Epoch 272/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4798 - accuracy: 0.8289 - val_loss: 3.7311 - val_accuracy: 0.6302\n",
      "Epoch 273/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4841 - accuracy: 0.8267 - val_loss: 3.6947 - val_accuracy: 0.6297\n",
      "Epoch 274/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4860 - accuracy: 0.8266 - val_loss: 3.6844 - val_accuracy: 0.6315\n",
      "Epoch 275/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4760 - accuracy: 0.8293 - val_loss: 3.6689 - val_accuracy: 0.6318\n",
      "Epoch 276/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4624 - accuracy: 0.8301 - val_loss: 3.6796 - val_accuracy: 0.6342\n",
      "Epoch 277/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4542 - accuracy: 0.8328 - val_loss: 3.6905 - val_accuracy: 0.6350\n",
      "Epoch 278/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4627 - accuracy: 0.8317 - val_loss: 3.6800 - val_accuracy: 0.6336\n",
      "Epoch 279/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4624 - accuracy: 0.8306 - val_loss: 3.7072 - val_accuracy: 0.6323\n",
      "Epoch 280/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4569 - accuracy: 0.8314 - val_loss: 3.7077 - val_accuracy: 0.6332\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4524 - accuracy: 0.8329 - val_loss: 3.7066 - val_accuracy: 0.6338\n",
      "Epoch 282/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4528 - accuracy: 0.8330 - val_loss: 3.6990 - val_accuracy: 0.6347\n",
      "Epoch 283/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4470 - accuracy: 0.8342 - val_loss: 3.7024 - val_accuracy: 0.6348\n",
      "Epoch 284/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4510 - accuracy: 0.8338 - val_loss: 3.7169 - val_accuracy: 0.6339\n",
      "Epoch 285/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4536 - accuracy: 0.8324 - val_loss: 3.7180 - val_accuracy: 0.6333\n",
      "Epoch 286/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4461 - accuracy: 0.8337 - val_loss: 3.7194 - val_accuracy: 0.6341\n",
      "Epoch 287/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4508 - accuracy: 0.8332 - val_loss: 3.7166 - val_accuracy: 0.6349\n",
      "Epoch 288/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4475 - accuracy: 0.8339 - val_loss: 3.7439 - val_accuracy: 0.6334\n",
      "Epoch 289/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4549 - accuracy: 0.8325 - val_loss: 3.7262 - val_accuracy: 0.6340\n",
      "Epoch 290/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4517 - accuracy: 0.8330 - val_loss: 3.7333 - val_accuracy: 0.6339\n",
      "Epoch 291/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4596 - accuracy: 0.8318 - val_loss: 3.7397 - val_accuracy: 0.6327\n",
      "Epoch 292/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4639 - accuracy: 0.8325 - val_loss: 3.7399 - val_accuracy: 0.6316\n",
      "Epoch 293/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4562 - accuracy: 0.8328 - val_loss: 3.7233 - val_accuracy: 0.6334\n",
      "Epoch 294/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4500 - accuracy: 0.8331 - val_loss: 3.7162 - val_accuracy: 0.6349\n",
      "Epoch 295/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4450 - accuracy: 0.8345 - val_loss: 3.7255 - val_accuracy: 0.6345\n",
      "Epoch 296/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4493 - accuracy: 0.8330 - val_loss: 3.7286 - val_accuracy: 0.6336\n",
      "Epoch 297/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4519 - accuracy: 0.8327 - val_loss: 3.7378 - val_accuracy: 0.6334\n",
      "Epoch 298/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4478 - accuracy: 0.8338 - val_loss: 3.7362 - val_accuracy: 0.6335\n",
      "Epoch 299/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4434 - accuracy: 0.8338 - val_loss: 3.7289 - val_accuracy: 0.6349\n",
      "Epoch 300/300\n",
      "115/115 [==============================] - 4s 33ms/step - loss: 0.4519 - accuracy: 0.8335 - val_loss: 3.7437 - val_accuracy: 0.6338\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('none')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=300,\n",
    "    validation_data=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 3.8987 - accuracy: 0.2592 - val_loss: 2.0182 - val_accuracy: 0.2492\n",
      "Epoch 2/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.8627 - accuracy: 0.3144 - val_loss: 1.8835 - val_accuracy: 0.3393\n",
      "Epoch 3/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.7275 - accuracy: 0.3690 - val_loss: 1.9299 - val_accuracy: 0.3279\n",
      "Epoch 4/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.6082 - accuracy: 0.4255 - val_loss: 1.9463 - val_accuracy: 0.3616\n",
      "Epoch 5/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.5139 - accuracy: 0.4604 - val_loss: 1.8006 - val_accuracy: 0.4013\n",
      "Epoch 6/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.4246 - accuracy: 0.4934 - val_loss: 1.8772 - val_accuracy: 0.4454\n",
      "Epoch 7/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.3567 - accuracy: 0.5299 - val_loss: 1.7997 - val_accuracy: 0.4612\n",
      "Epoch 8/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.2825 - accuracy: 0.5520 - val_loss: 1.7332 - val_accuracy: 0.4870\n",
      "Epoch 9/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.2198 - accuracy: 0.5716 - val_loss: 1.8169 - val_accuracy: 0.4978\n",
      "Epoch 10/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.1691 - accuracy: 0.5867 - val_loss: 1.7044 - val_accuracy: 0.5095\n",
      "Epoch 11/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.1335 - accuracy: 0.5967 - val_loss: 1.7081 - val_accuracy: 0.5229\n",
      "Epoch 12/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.1251 - accuracy: 0.5950 - val_loss: 1.8323 - val_accuracy: 0.5040\n",
      "Epoch 13/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.0936 - accuracy: 0.6002 - val_loss: 1.7221 - val_accuracy: 0.5240\n",
      "Epoch 14/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.0787 - accuracy: 0.6057 - val_loss: 1.8131 - val_accuracy: 0.5376\n",
      "Epoch 15/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.0489 - accuracy: 0.6145 - val_loss: 1.8521 - val_accuracy: 0.5333\n",
      "Epoch 16/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 1.0232 - accuracy: 0.6209 - val_loss: 1.8775 - val_accuracy: 0.5346\n",
      "Epoch 17/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.9737 - accuracy: 0.6353 - val_loss: 1.8593 - val_accuracy: 0.5601\n",
      "Epoch 18/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.9106 - accuracy: 0.6597 - val_loss: 1.9029 - val_accuracy: 0.5610\n",
      "Epoch 19/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.8823 - accuracy: 0.6735 - val_loss: 2.0620 - val_accuracy: 0.5632\n",
      "Epoch 20/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.8713 - accuracy: 0.6776 - val_loss: 1.8243 - val_accuracy: 0.5657\n",
      "Epoch 21/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.8529 - accuracy: 0.6784 - val_loss: 1.9117 - val_accuracy: 0.5698\n",
      "Epoch 22/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.8345 - accuracy: 0.6868 - val_loss: 1.9764 - val_accuracy: 0.5713\n",
      "Epoch 23/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.8199 - accuracy: 0.6901 - val_loss: 1.9815 - val_accuracy: 0.5784\n",
      "Epoch 24/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.7996 - accuracy: 0.6942 - val_loss: 1.9840 - val_accuracy: 0.5736\n",
      "Epoch 25/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.8089 - accuracy: 0.6897 - val_loss: 2.0537 - val_accuracy: 0.5691\n",
      "Epoch 26/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.7762 - accuracy: 0.6980 - val_loss: 2.0441 - val_accuracy: 0.5684\n",
      "Epoch 27/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.7566 - accuracy: 0.7041 - val_loss: 2.1216 - val_accuracy: 0.5923\n",
      "Epoch 28/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.7500 - accuracy: 0.7129 - val_loss: 2.0666 - val_accuracy: 0.5870\n",
      "Epoch 29/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.7377 - accuracy: 0.7217 - val_loss: 1.9954 - val_accuracy: 0.5962\n",
      "Epoch 30/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.7341 - accuracy: 0.7228 - val_loss: 1.9795 - val_accuracy: 0.5978\n",
      "Epoch 31/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.7305 - accuracy: 0.7219 - val_loss: 1.9940 - val_accuracy: 0.5971\n",
      "Epoch 32/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.7058 - accuracy: 0.7262 - val_loss: 2.0066 - val_accuracy: 0.5981\n",
      "Epoch 33/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.7179 - accuracy: 0.7235 - val_loss: 2.0282 - val_accuracy: 0.5954\n",
      "Epoch 34/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.6984 - accuracy: 0.7293 - val_loss: 2.1171 - val_accuracy: 0.6015\n",
      "Epoch 35/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.6962 - accuracy: 0.7288 - val_loss: 2.0231 - val_accuracy: 0.5915\n",
      "Epoch 36/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.6904 - accuracy: 0.7284 - val_loss: 1.9780 - val_accuracy: 0.5979\n",
      "Epoch 37/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.6869 - accuracy: 0.7301 - val_loss: 2.1378 - val_accuracy: 0.6018\n",
      "Epoch 38/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.6573 - accuracy: 0.7361 - val_loss: 2.1594 - val_accuracy: 0.6110\n",
      "Epoch 39/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.6346 - accuracy: 0.7427 - val_loss: 2.3351 - val_accuracy: 0.6192\n",
      "Epoch 40/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.6500 - accuracy: 0.7479 - val_loss: 2.3614 - val_accuracy: 0.6486\n",
      "Epoch 41/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.6245 - accuracy: 0.7674 - val_loss: 2.0713 - val_accuracy: 0.6497\n",
      "Epoch 42/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.6269 - accuracy: 0.7686 - val_loss: 2.0732 - val_accuracy: 0.6496\n",
      "Epoch 43/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.6255 - accuracy: 0.7708 - val_loss: 2.1002 - val_accuracy: 0.6605\n",
      "Epoch 44/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5931 - accuracy: 0.7786 - val_loss: 2.0630 - val_accuracy: 0.6514\n",
      "Epoch 45/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5895 - accuracy: 0.7805 - val_loss: 2.1940 - val_accuracy: 0.6537\n",
      "Epoch 46/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5879 - accuracy: 0.7816 - val_loss: 2.2187 - val_accuracy: 0.6455\n",
      "Epoch 47/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.6082 - accuracy: 0.7767 - val_loss: 2.0633 - val_accuracy: 0.6529\n",
      "Epoch 48/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5938 - accuracy: 0.7821 - val_loss: 2.2787 - val_accuracy: 0.6575\n",
      "Epoch 49/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5883 - accuracy: 0.7846 - val_loss: 2.2234 - val_accuracy: 0.6590\n",
      "Epoch 50/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5817 - accuracy: 0.7906 - val_loss: 2.1705 - val_accuracy: 0.6841\n",
      "Epoch 51/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5749 - accuracy: 0.7926 - val_loss: 2.2328 - val_accuracy: 0.6787\n",
      "Epoch 52/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5787 - accuracy: 0.7937 - val_loss: 2.1166 - val_accuracy: 0.6845\n",
      "Epoch 53/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5644 - accuracy: 0.7989 - val_loss: 2.3780 - val_accuracy: 0.6877\n",
      "Epoch 54/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5611 - accuracy: 0.8001 - val_loss: 2.2113 - val_accuracy: 0.6825\n",
      "Epoch 55/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5589 - accuracy: 0.8024 - val_loss: 2.1258 - val_accuracy: 0.6926\n",
      "Epoch 56/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5682 - accuracy: 0.8084 - val_loss: 2.4234 - val_accuracy: 0.6953\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5298 - accuracy: 0.8185 - val_loss: 2.2233 - val_accuracy: 0.7092\n",
      "Epoch 58/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5187 - accuracy: 0.8201 - val_loss: 2.3289 - val_accuracy: 0.7023\n",
      "Epoch 59/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5219 - accuracy: 0.8186 - val_loss: 2.1656 - val_accuracy: 0.7120\n",
      "Epoch 60/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5039 - accuracy: 0.8236 - val_loss: 2.4124 - val_accuracy: 0.7049\n",
      "Epoch 61/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5041 - accuracy: 0.8256 - val_loss: 2.2929 - val_accuracy: 0.7024\n",
      "Epoch 62/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4838 - accuracy: 0.8290 - val_loss: 2.4127 - val_accuracy: 0.7062\n",
      "Epoch 63/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4886 - accuracy: 0.8304 - val_loss: 2.4149 - val_accuracy: 0.7103\n",
      "Epoch 64/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.5217 - accuracy: 0.8229 - val_loss: 2.2751 - val_accuracy: 0.7019\n",
      "Epoch 65/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.4926 - accuracy: 0.8298 - val_loss: 2.5093 - val_accuracy: 0.7026\n",
      "Epoch 66/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.4965 - accuracy: 0.8295 - val_loss: 2.4488 - val_accuracy: 0.7078\n",
      "Epoch 67/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4963 - accuracy: 0.8316 - val_loss: 2.3732 - val_accuracy: 0.6978\n",
      "Epoch 68/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4960 - accuracy: 0.8303 - val_loss: 2.4111 - val_accuracy: 0.6992\n",
      "Epoch 69/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4864 - accuracy: 0.8319 - val_loss: 2.4894 - val_accuracy: 0.7041\n",
      "Epoch 70/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5088 - accuracy: 0.8274 - val_loss: 2.5290 - val_accuracy: 0.6962\n",
      "Epoch 71/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.5084 - accuracy: 0.8277 - val_loss: 2.4167 - val_accuracy: 0.6999\n",
      "Epoch 72/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4898 - accuracy: 0.8292 - val_loss: 2.4624 - val_accuracy: 0.7000\n",
      "Epoch 73/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4676 - accuracy: 0.8352 - val_loss: 2.4949 - val_accuracy: 0.7059\n",
      "Epoch 74/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4801 - accuracy: 0.8339 - val_loss: 2.5127 - val_accuracy: 0.7017\n",
      "Epoch 75/300\n",
      "115/115 [==============================] - 4s 34ms/step - loss: 0.4600 - accuracy: 0.8358 - val_loss: 2.4456 - val_accuracy: 0.7078\n",
      "Epoch 76/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4364 - accuracy: 0.8438 - val_loss: 2.6058 - val_accuracy: 0.6981\n",
      "Epoch 77/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4562 - accuracy: 0.8409 - val_loss: 2.6724 - val_accuracy: 0.7021\n",
      "Epoch 78/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.4552 - accuracy: 0.8394 - val_loss: 2.4980 - val_accuracy: 0.7019\n",
      "Epoch 79/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4356 - accuracy: 0.8451 - val_loss: 2.5599 - val_accuracy: 0.7046\n",
      "Epoch 80/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.4592 - accuracy: 0.8417 - val_loss: 2.6715 - val_accuracy: 0.6969\n",
      "Epoch 81/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4511 - accuracy: 0.8423 - val_loss: 2.6966 - val_accuracy: 0.7025\n",
      "Epoch 82/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.4262 - accuracy: 0.8461 - val_loss: 2.5067 - val_accuracy: 0.7055\n",
      "Epoch 83/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.4467 - accuracy: 0.8424 - val_loss: 2.5841 - val_accuracy: 0.7006\n",
      "Epoch 84/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.4274 - accuracy: 0.8456 - val_loss: 2.5976 - val_accuracy: 0.6898\n",
      "Epoch 85/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.4297 - accuracy: 0.8441 - val_loss: 2.8258 - val_accuracy: 0.6999\n",
      "Epoch 86/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.4189 - accuracy: 0.8467 - val_loss: 2.6867 - val_accuracy: 0.7021\n",
      "Epoch 87/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4147 - accuracy: 0.8464 - val_loss: 2.6831 - val_accuracy: 0.6980\n",
      "Epoch 88/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4191 - accuracy: 0.8468 - val_loss: 2.7859 - val_accuracy: 0.6950\n",
      "Epoch 89/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.4253 - accuracy: 0.8457 - val_loss: 2.7098 - val_accuracy: 0.6995\n",
      "Epoch 90/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4546 - accuracy: 0.8393 - val_loss: 2.8806 - val_accuracy: 0.6956\n",
      "Epoch 91/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4249 - accuracy: 0.8446 - val_loss: 2.7326 - val_accuracy: 0.6988\n",
      "Epoch 92/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4174 - accuracy: 0.8465 - val_loss: 2.8587 - val_accuracy: 0.7008\n",
      "Epoch 93/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4160 - accuracy: 0.8466 - val_loss: 2.4787 - val_accuracy: 0.7033\n",
      "Epoch 94/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4207 - accuracy: 0.8464 - val_loss: 2.6849 - val_accuracy: 0.7036\n",
      "Epoch 95/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4294 - accuracy: 0.8477 - val_loss: 2.8576 - val_accuracy: 0.7031\n",
      "Epoch 96/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4156 - accuracy: 0.8477 - val_loss: 2.7256 - val_accuracy: 0.7031\n",
      "Epoch 97/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4053 - accuracy: 0.8530 - val_loss: 2.8605 - val_accuracy: 0.7139\n",
      "Epoch 98/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3944 - accuracy: 0.8627 - val_loss: 2.8952 - val_accuracy: 0.7208\n",
      "Epoch 99/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4048 - accuracy: 0.8628 - val_loss: 2.7775 - val_accuracy: 0.7218\n",
      "Epoch 100/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4027 - accuracy: 0.8634 - val_loss: 2.9015 - val_accuracy: 0.7184\n",
      "Epoch 101/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.4005 - accuracy: 0.8622 - val_loss: 2.7976 - val_accuracy: 0.7198\n",
      "Epoch 102/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3997 - accuracy: 0.8650 - val_loss: 2.7878 - val_accuracy: 0.7169\n",
      "Epoch 103/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3854 - accuracy: 0.8678 - val_loss: 2.9374 - val_accuracy: 0.7183\n",
      "Epoch 104/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3802 - accuracy: 0.8666 - val_loss: 2.8743 - val_accuracy: 0.7209\n",
      "Epoch 105/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3734 - accuracy: 0.8682 - val_loss: 2.8745 - val_accuracy: 0.7257\n",
      "Epoch 106/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3997 - accuracy: 0.8620 - val_loss: 2.8917 - val_accuracy: 0.7214\n",
      "Epoch 107/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3622 - accuracy: 0.8685 - val_loss: 2.8868 - val_accuracy: 0.7222\n",
      "Epoch 108/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3742 - accuracy: 0.8664 - val_loss: 2.9476 - val_accuracy: 0.7234\n",
      "Epoch 109/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3559 - accuracy: 0.8735 - val_loss: 2.9189 - val_accuracy: 0.7245\n",
      "Epoch 110/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3812 - accuracy: 0.8695 - val_loss: 2.9622 - val_accuracy: 0.7205\n",
      "Epoch 111/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3689 - accuracy: 0.8690 - val_loss: 2.9329 - val_accuracy: 0.7250\n",
      "Epoch 112/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3750 - accuracy: 0.8693 - val_loss: 2.9345 - val_accuracy: 0.7181\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3771 - accuracy: 0.8687 - val_loss: 2.9566 - val_accuracy: 0.7227\n",
      "Epoch 114/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3743 - accuracy: 0.8701 - val_loss: 3.0628 - val_accuracy: 0.7197\n",
      "Epoch 115/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3751 - accuracy: 0.8722 - val_loss: 2.9901 - val_accuracy: 0.7207\n",
      "Epoch 116/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3793 - accuracy: 0.8682 - val_loss: 2.9067 - val_accuracy: 0.7266\n",
      "Epoch 117/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3514 - accuracy: 0.8772 - val_loss: 2.9242 - val_accuracy: 0.7250\n",
      "Epoch 118/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3536 - accuracy: 0.8749 - val_loss: 2.8208 - val_accuracy: 0.7241\n",
      "Epoch 119/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3502 - accuracy: 0.8769 - val_loss: 2.9289 - val_accuracy: 0.7268\n",
      "Epoch 120/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3577 - accuracy: 0.8749 - val_loss: 2.9636 - val_accuracy: 0.7222\n",
      "Epoch 121/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3549 - accuracy: 0.8743 - val_loss: 2.8731 - val_accuracy: 0.7276\n",
      "Epoch 122/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3358 - accuracy: 0.8778 - val_loss: 2.9356 - val_accuracy: 0.7265\n",
      "Epoch 123/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3373 - accuracy: 0.8783 - val_loss: 3.0063 - val_accuracy: 0.7259\n",
      "Epoch 124/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3665 - accuracy: 0.8727 - val_loss: 2.9321 - val_accuracy: 0.7246\n",
      "Epoch 125/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3499 - accuracy: 0.8747 - val_loss: 2.9554 - val_accuracy: 0.7259\n",
      "Epoch 126/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3380 - accuracy: 0.8787 - val_loss: 2.9221 - val_accuracy: 0.7213\n",
      "Epoch 127/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3526 - accuracy: 0.8755 - val_loss: 3.0035 - val_accuracy: 0.7193\n",
      "Epoch 128/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3573 - accuracy: 0.8743 - val_loss: 2.8079 - val_accuracy: 0.7231\n",
      "Epoch 129/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3501 - accuracy: 0.8765 - val_loss: 2.9639 - val_accuracy: 0.7224\n",
      "Epoch 130/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3513 - accuracy: 0.8755 - val_loss: 2.8364 - val_accuracy: 0.7236\n",
      "Epoch 131/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3428 - accuracy: 0.8760 - val_loss: 2.9515 - val_accuracy: 0.7249\n",
      "Epoch 132/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3363 - accuracy: 0.8785 - val_loss: 2.9328 - val_accuracy: 0.7248\n",
      "Epoch 133/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3319 - accuracy: 0.8796 - val_loss: 2.9578 - val_accuracy: 0.7268\n",
      "Epoch 134/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3356 - accuracy: 0.8788 - val_loss: 2.8802 - val_accuracy: 0.7297\n",
      "Epoch 135/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3459 - accuracy: 0.8778 - val_loss: 2.9512 - val_accuracy: 0.7248\n",
      "Epoch 136/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3406 - accuracy: 0.8766 - val_loss: 2.9308 - val_accuracy: 0.7254\n",
      "Epoch 137/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3338 - accuracy: 0.8790 - val_loss: 2.9435 - val_accuracy: 0.7274\n",
      "Epoch 138/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3401 - accuracy: 0.8802 - val_loss: 2.9203 - val_accuracy: 0.7269\n",
      "Epoch 139/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3262 - accuracy: 0.8796 - val_loss: 2.9146 - val_accuracy: 0.7247\n",
      "Epoch 140/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3521 - accuracy: 0.8751 - val_loss: 2.9757 - val_accuracy: 0.7210\n",
      "Epoch 141/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3514 - accuracy: 0.8747 - val_loss: 2.9720 - val_accuracy: 0.7261\n",
      "Epoch 142/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3305 - accuracy: 0.8796 - val_loss: 2.9500 - val_accuracy: 0.7246\n",
      "Epoch 143/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3242 - accuracy: 0.8787 - val_loss: 2.8833 - val_accuracy: 0.7263\n",
      "Epoch 144/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3195 - accuracy: 0.8796 - val_loss: 3.0154 - val_accuracy: 0.7234\n",
      "Epoch 145/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3224 - accuracy: 0.8809 - val_loss: 2.9696 - val_accuracy: 0.7266\n",
      "Epoch 146/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3264 - accuracy: 0.8796 - val_loss: 2.8122 - val_accuracy: 0.7263\n",
      "Epoch 147/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3209 - accuracy: 0.8791 - val_loss: 2.9443 - val_accuracy: 0.7275\n",
      "Epoch 148/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3256 - accuracy: 0.8806 - val_loss: 2.7882 - val_accuracy: 0.7217\n",
      "Epoch 149/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3500 - accuracy: 0.8753 - val_loss: 2.8070 - val_accuracy: 0.7252\n",
      "Epoch 150/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3248 - accuracy: 0.8797 - val_loss: 2.8748 - val_accuracy: 0.7263\n",
      "Epoch 151/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3122 - accuracy: 0.8824 - val_loss: 2.8883 - val_accuracy: 0.7267\n",
      "Epoch 152/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3053 - accuracy: 0.8830 - val_loss: 2.8757 - val_accuracy: 0.7278\n",
      "Epoch 153/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3058 - accuracy: 0.8843 - val_loss: 2.8726 - val_accuracy: 0.7261\n",
      "Epoch 154/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2988 - accuracy: 0.8853 - val_loss: 2.9632 - val_accuracy: 0.7275\n",
      "Epoch 155/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2976 - accuracy: 0.8869 - val_loss: 2.9680 - val_accuracy: 0.7259\n",
      "Epoch 156/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3228 - accuracy: 0.8821 - val_loss: 2.9909 - val_accuracy: 0.7259\n",
      "Epoch 157/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3209 - accuracy: 0.8842 - val_loss: 2.8758 - val_accuracy: 0.7246\n",
      "Epoch 158/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3153 - accuracy: 0.8826 - val_loss: 2.9281 - val_accuracy: 0.7256\n",
      "Epoch 159/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3124 - accuracy: 0.8835 - val_loss: 3.0071 - val_accuracy: 0.7262\n",
      "Epoch 160/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3750 - accuracy: 0.8752 - val_loss: 2.8770 - val_accuracy: 0.7188\n",
      "Epoch 161/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3622 - accuracy: 0.8717 - val_loss: 2.9926 - val_accuracy: 0.7199\n",
      "Epoch 162/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3360 - accuracy: 0.8798 - val_loss: 2.9844 - val_accuracy: 0.7229\n",
      "Epoch 163/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3280 - accuracy: 0.8797 - val_loss: 3.0854 - val_accuracy: 0.7250\n",
      "Epoch 164/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3171 - accuracy: 0.8823 - val_loss: 3.0687 - val_accuracy: 0.7261\n",
      "Epoch 165/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3044 - accuracy: 0.8852 - val_loss: 3.0538 - val_accuracy: 0.7247\n",
      "Epoch 166/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3085 - accuracy: 0.8852 - val_loss: 3.0133 - val_accuracy: 0.7260\n",
      "Epoch 167/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3102 - accuracy: 0.8860 - val_loss: 2.9785 - val_accuracy: 0.7270\n",
      "Epoch 168/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3093 - accuracy: 0.8847 - val_loss: 2.9355 - val_accuracy: 0.7235\n",
      "Epoch 169/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3177 - accuracy: 0.8860 - val_loss: 2.9539 - val_accuracy: 0.7222\n",
      "Epoch 170/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3242 - accuracy: 0.8842 - val_loss: 3.0157 - val_accuracy: 0.7244\n",
      "Epoch 171/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3098 - accuracy: 0.8861 - val_loss: 2.8579 - val_accuracy: 0.7249\n",
      "Epoch 172/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3092 - accuracy: 0.8836 - val_loss: 3.0065 - val_accuracy: 0.7267\n",
      "Epoch 173/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3095 - accuracy: 0.8882 - val_loss: 3.0691 - val_accuracy: 0.7230\n",
      "Epoch 174/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3325 - accuracy: 0.8837 - val_loss: 2.9079 - val_accuracy: 0.7259\n",
      "Epoch 175/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3128 - accuracy: 0.8857 - val_loss: 3.0385 - val_accuracy: 0.7260\n",
      "Epoch 176/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2976 - accuracy: 0.8892 - val_loss: 2.9429 - val_accuracy: 0.7277\n",
      "Epoch 177/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2907 - accuracy: 0.8923 - val_loss: 2.9869 - val_accuracy: 0.7250\n",
      "Epoch 178/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2964 - accuracy: 0.8914 - val_loss: 3.0758 - val_accuracy: 0.7278\n",
      "Epoch 179/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3067 - accuracy: 0.8885 - val_loss: 2.9671 - val_accuracy: 0.7279\n",
      "Epoch 180/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3043 - accuracy: 0.8890 - val_loss: 2.9475 - val_accuracy: 0.7316\n",
      "Epoch 181/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2964 - accuracy: 0.8904 - val_loss: 2.9907 - val_accuracy: 0.7259\n",
      "Epoch 182/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2913 - accuracy: 0.8926 - val_loss: 2.9625 - val_accuracy: 0.7291\n",
      "Epoch 183/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2839 - accuracy: 0.8921 - val_loss: 3.0162 - val_accuracy: 0.7301\n",
      "Epoch 184/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2961 - accuracy: 0.8926 - val_loss: 2.9312 - val_accuracy: 0.7274\n",
      "Epoch 185/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2978 - accuracy: 0.8919 - val_loss: 2.9631 - val_accuracy: 0.7267\n",
      "Epoch 186/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2932 - accuracy: 0.8914 - val_loss: 3.0291 - val_accuracy: 0.7280\n",
      "Epoch 187/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2958 - accuracy: 0.8919 - val_loss: 2.9666 - val_accuracy: 0.7249\n",
      "Epoch 188/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3014 - accuracy: 0.8905 - val_loss: 2.9794 - val_accuracy: 0.7277\n",
      "Epoch 189/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2945 - accuracy: 0.8918 - val_loss: 3.0662 - val_accuracy: 0.7254\n",
      "Epoch 190/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2865 - accuracy: 0.8937 - val_loss: 2.9449 - val_accuracy: 0.7305\n",
      "Epoch 191/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2858 - accuracy: 0.8931 - val_loss: 3.0185 - val_accuracy: 0.7307\n",
      "Epoch 192/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3030 - accuracy: 0.8888 - val_loss: 3.0635 - val_accuracy: 0.7274\n",
      "Epoch 193/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3038 - accuracy: 0.8907 - val_loss: 3.0712 - val_accuracy: 0.7255\n",
      "Epoch 194/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3105 - accuracy: 0.8888 - val_loss: 3.0377 - val_accuracy: 0.7242\n",
      "Epoch 195/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2987 - accuracy: 0.8906 - val_loss: 3.0000 - val_accuracy: 0.7237\n",
      "Epoch 196/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3124 - accuracy: 0.8878 - val_loss: 3.0191 - val_accuracy: 0.7259\n",
      "Epoch 197/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2982 - accuracy: 0.8891 - val_loss: 3.0622 - val_accuracy: 0.7269\n",
      "Epoch 198/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2947 - accuracy: 0.8901 - val_loss: 2.9787 - val_accuracy: 0.7272\n",
      "Epoch 199/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2955 - accuracy: 0.8897 - val_loss: 3.0391 - val_accuracy: 0.7248\n",
      "Epoch 200/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3038 - accuracy: 0.8900 - val_loss: 3.0343 - val_accuracy: 0.7270\n",
      "Epoch 201/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2924 - accuracy: 0.8928 - val_loss: 2.9974 - val_accuracy: 0.7296\n",
      "Epoch 202/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3147 - accuracy: 0.8892 - val_loss: 3.0345 - val_accuracy: 0.7296\n",
      "Epoch 203/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2862 - accuracy: 0.8920 - val_loss: 3.0191 - val_accuracy: 0.7288\n",
      "Epoch 204/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2969 - accuracy: 0.8913 - val_loss: 2.9965 - val_accuracy: 0.7268\n",
      "Epoch 205/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2940 - accuracy: 0.8912 - val_loss: 3.0311 - val_accuracy: 0.7263\n",
      "Epoch 206/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2856 - accuracy: 0.8937 - val_loss: 3.1199 - val_accuracy: 0.7284\n",
      "Epoch 207/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2777 - accuracy: 0.8950 - val_loss: 2.9108 - val_accuracy: 0.7303\n",
      "Epoch 208/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2847 - accuracy: 0.8937 - val_loss: 2.9864 - val_accuracy: 0.7331\n",
      "Epoch 209/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2842 - accuracy: 0.8939 - val_loss: 3.0187 - val_accuracy: 0.7299\n",
      "Epoch 210/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2950 - accuracy: 0.8918 - val_loss: 2.9814 - val_accuracy: 0.7280\n",
      "Epoch 211/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3299 - accuracy: 0.8860 - val_loss: 3.1309 - val_accuracy: 0.7266\n",
      "Epoch 212/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3179 - accuracy: 0.8874 - val_loss: 3.0520 - val_accuracy: 0.7288\n",
      "Epoch 213/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3276 - accuracy: 0.8864 - val_loss: 2.8911 - val_accuracy: 0.7285\n",
      "Epoch 214/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3069 - accuracy: 0.8890 - val_loss: 2.9144 - val_accuracy: 0.7315\n",
      "Epoch 215/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3104 - accuracy: 0.8907 - val_loss: 2.8802 - val_accuracy: 0.7269\n",
      "Epoch 216/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2990 - accuracy: 0.8912 - val_loss: 2.7598 - val_accuracy: 0.7334\n",
      "Epoch 217/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2753 - accuracy: 0.8953 - val_loss: 3.0164 - val_accuracy: 0.7337\n",
      "Epoch 218/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2983 - accuracy: 0.8924 - val_loss: 3.0419 - val_accuracy: 0.7114\n",
      "Epoch 219/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2963 - accuracy: 0.8887 - val_loss: 3.0862 - val_accuracy: 0.7291\n",
      "Epoch 220/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2844 - accuracy: 0.8915 - val_loss: 2.9657 - val_accuracy: 0.7279\n",
      "Epoch 221/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2790 - accuracy: 0.8934 - val_loss: 3.0825 - val_accuracy: 0.7304\n",
      "Epoch 222/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3155 - accuracy: 0.8907 - val_loss: 2.9701 - val_accuracy: 0.7265\n",
      "Epoch 223/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3088 - accuracy: 0.8880 - val_loss: 2.9788 - val_accuracy: 0.7292\n",
      "Epoch 224/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2833 - accuracy: 0.8930 - val_loss: 2.9553 - val_accuracy: 0.7286\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2951 - accuracy: 0.8907 - val_loss: 3.0518 - val_accuracy: 0.7275\n",
      "Epoch 226/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2849 - accuracy: 0.8921 - val_loss: 2.9357 - val_accuracy: 0.7334\n",
      "Epoch 227/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2845 - accuracy: 0.8927 - val_loss: 3.0021 - val_accuracy: 0.7274\n",
      "Epoch 228/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2955 - accuracy: 0.8919 - val_loss: 3.0538 - val_accuracy: 0.7252\n",
      "Epoch 229/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2930 - accuracy: 0.8901 - val_loss: 3.0061 - val_accuracy: 0.7283\n",
      "Epoch 230/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2870 - accuracy: 0.8923 - val_loss: 3.0244 - val_accuracy: 0.7270\n",
      "Epoch 231/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2963 - accuracy: 0.8899 - val_loss: 2.9576 - val_accuracy: 0.7276\n",
      "Epoch 232/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2933 - accuracy: 0.8904 - val_loss: 2.9882 - val_accuracy: 0.7267\n",
      "Epoch 233/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2927 - accuracy: 0.8917 - val_loss: 3.0134 - val_accuracy: 0.7271\n",
      "Epoch 234/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2742 - accuracy: 0.8949 - val_loss: 3.0125 - val_accuracy: 0.7310\n",
      "Epoch 235/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2778 - accuracy: 0.8923 - val_loss: 2.9546 - val_accuracy: 0.7283\n",
      "Epoch 236/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3068 - accuracy: 0.8895 - val_loss: 3.0836 - val_accuracy: 0.7253\n",
      "Epoch 237/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3188 - accuracy: 0.8860 - val_loss: 3.0600 - val_accuracy: 0.7269\n",
      "Epoch 238/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3095 - accuracy: 0.8881 - val_loss: 3.0122 - val_accuracy: 0.7313\n",
      "Epoch 239/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3071 - accuracy: 0.8889 - val_loss: 2.9175 - val_accuracy: 0.7267\n",
      "Epoch 240/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2941 - accuracy: 0.8899 - val_loss: 2.9680 - val_accuracy: 0.7299\n",
      "Epoch 241/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2724 - accuracy: 0.8948 - val_loss: 2.9135 - val_accuracy: 0.7321\n",
      "Epoch 242/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2754 - accuracy: 0.8944 - val_loss: 2.9596 - val_accuracy: 0.7322\n",
      "Epoch 243/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2980 - accuracy: 0.8908 - val_loss: 2.9020 - val_accuracy: 0.7283\n",
      "Epoch 244/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2786 - accuracy: 0.8936 - val_loss: 2.9648 - val_accuracy: 0.7267\n",
      "Epoch 245/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2803 - accuracy: 0.8929 - val_loss: 3.0617 - val_accuracy: 0.7288\n",
      "Epoch 246/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2732 - accuracy: 0.8943 - val_loss: 3.0215 - val_accuracy: 0.7300\n",
      "Epoch 247/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2781 - accuracy: 0.8943 - val_loss: 3.0532 - val_accuracy: 0.7302\n",
      "Epoch 248/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2708 - accuracy: 0.8939 - val_loss: 3.0316 - val_accuracy: 0.7306\n",
      "Epoch 249/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2727 - accuracy: 0.8937 - val_loss: 3.0825 - val_accuracy: 0.7324\n",
      "Epoch 250/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3192 - accuracy: 0.8892 - val_loss: 3.1823 - val_accuracy: 0.7247\n",
      "Epoch 251/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3285 - accuracy: 0.8858 - val_loss: 3.0060 - val_accuracy: 0.7230\n",
      "Epoch 252/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3179 - accuracy: 0.8846 - val_loss: 3.0585 - val_accuracy: 0.7271\n",
      "Epoch 253/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2935 - accuracy: 0.8896 - val_loss: 3.0108 - val_accuracy: 0.7269\n",
      "Epoch 254/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2895 - accuracy: 0.8912 - val_loss: 3.1031 - val_accuracy: 0.7296\n",
      "Epoch 255/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3019 - accuracy: 0.8887 - val_loss: 3.1059 - val_accuracy: 0.7259\n",
      "Epoch 256/300\n",
      "115/115 [==============================] - 4s 38ms/step - loss: 0.3145 - accuracy: 0.8892 - val_loss: 3.1034 - val_accuracy: 0.7274\n",
      "Epoch 257/300\n",
      "115/115 [==============================] - 4s 37ms/step - loss: 0.2921 - accuracy: 0.8921 - val_loss: 3.0472 - val_accuracy: 0.7264\n",
      "Epoch 258/300\n",
      "115/115 [==============================] - 4s 37ms/step - loss: 0.2838 - accuracy: 0.8921 - val_loss: 3.0284 - val_accuracy: 0.7282\n",
      "Epoch 259/300\n",
      "115/115 [==============================] - 4s 37ms/step - loss: 0.2809 - accuracy: 0.8935 - val_loss: 3.0319 - val_accuracy: 0.7297\n",
      "Epoch 260/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2923 - accuracy: 0.8905 - val_loss: 2.9989 - val_accuracy: 0.7285\n",
      "Epoch 261/300\n",
      "115/115 [==============================] - 4s 37ms/step - loss: 0.2897 - accuracy: 0.8896 - val_loss: 3.0258 - val_accuracy: 0.7253\n",
      "Epoch 262/300\n",
      "115/115 [==============================] - 4s 37ms/step - loss: 0.2883 - accuracy: 0.8904 - val_loss: 3.0667 - val_accuracy: 0.7270\n",
      "Epoch 263/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2974 - accuracy: 0.8891 - val_loss: 3.0709 - val_accuracy: 0.7290\n",
      "Epoch 264/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2755 - accuracy: 0.8915 - val_loss: 3.0953 - val_accuracy: 0.7314\n",
      "Epoch 265/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2753 - accuracy: 0.8936 - val_loss: 3.1348 - val_accuracy: 0.7307\n",
      "Epoch 266/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2676 - accuracy: 0.8940 - val_loss: 3.1404 - val_accuracy: 0.7311\n",
      "Epoch 267/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2661 - accuracy: 0.8935 - val_loss: 3.1000 - val_accuracy: 0.7313\n",
      "Epoch 268/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2910 - accuracy: 0.8939 - val_loss: 3.1067 - val_accuracy: 0.7269\n",
      "Epoch 269/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3005 - accuracy: 0.8906 - val_loss: 3.1196 - val_accuracy: 0.7279\n",
      "Epoch 270/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3148 - accuracy: 0.8874 - val_loss: 3.0345 - val_accuracy: 0.7247\n",
      "Epoch 271/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3373 - accuracy: 0.8835 - val_loss: 3.0553 - val_accuracy: 0.7301\n",
      "Epoch 272/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2965 - accuracy: 0.8899 - val_loss: 2.7778 - val_accuracy: 0.7280\n",
      "Epoch 273/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3043 - accuracy: 0.8882 - val_loss: 3.0319 - val_accuracy: 0.7294\n",
      "Epoch 274/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2950 - accuracy: 0.8903 - val_loss: 3.0905 - val_accuracy: 0.7292\n",
      "Epoch 275/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2862 - accuracy: 0.8915 - val_loss: 3.0351 - val_accuracy: 0.7297\n",
      "Epoch 276/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2720 - accuracy: 0.8941 - val_loss: 3.0552 - val_accuracy: 0.7288\n",
      "Epoch 277/300\n",
      "115/115 [==============================] - 4s 37ms/step - loss: 0.2781 - accuracy: 0.8923 - val_loss: 3.0758 - val_accuracy: 0.7300\n",
      "Epoch 278/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2859 - accuracy: 0.8910 - val_loss: 3.0131 - val_accuracy: 0.7298\n",
      "Epoch 279/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2840 - accuracy: 0.8921 - val_loss: 2.9869 - val_accuracy: 0.7295\n",
      "Epoch 280/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.3155 - accuracy: 0.8883 - val_loss: 2.9846 - val_accuracy: 0.7294\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2772 - accuracy: 0.8936 - val_loss: 2.9825 - val_accuracy: 0.7308\n",
      "Epoch 282/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2733 - accuracy: 0.8922 - val_loss: 3.0356 - val_accuracy: 0.7310\n",
      "Epoch 283/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2853 - accuracy: 0.8937 - val_loss: 2.9710 - val_accuracy: 0.7319\n",
      "Epoch 284/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2953 - accuracy: 0.8905 - val_loss: 2.9880 - val_accuracy: 0.7321\n",
      "Epoch 285/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3034 - accuracy: 0.8900 - val_loss: 3.0374 - val_accuracy: 0.7348\n",
      "Epoch 286/300\n",
      "115/115 [==============================] - 4s 35ms/step - loss: 0.2928 - accuracy: 0.8897 - val_loss: 3.0619 - val_accuracy: 0.7300\n",
      "Epoch 287/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2705 - accuracy: 0.8942 - val_loss: 3.0169 - val_accuracy: 0.7314\n",
      "Epoch 288/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2789 - accuracy: 0.8923 - val_loss: 3.1228 - val_accuracy: 0.7319\n",
      "Epoch 289/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3220 - accuracy: 0.8897 - val_loss: 3.0849 - val_accuracy: 0.7218\n",
      "Epoch 290/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2988 - accuracy: 0.8874 - val_loss: 3.0601 - val_accuracy: 0.7278\n",
      "Epoch 291/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3011 - accuracy: 0.8895 - val_loss: 3.0747 - val_accuracy: 0.7324\n",
      "Epoch 292/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2834 - accuracy: 0.8924 - val_loss: 3.0690 - val_accuracy: 0.7346\n",
      "Epoch 293/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2670 - accuracy: 0.8953 - val_loss: 2.9495 - val_accuracy: 0.7348\n",
      "Epoch 294/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2684 - accuracy: 0.8953 - val_loss: 3.0034 - val_accuracy: 0.7327\n",
      "Epoch 295/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2757 - accuracy: 0.8940 - val_loss: 3.0008 - val_accuracy: 0.7279\n",
      "Epoch 296/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2781 - accuracy: 0.8928 - val_loss: 2.9681 - val_accuracy: 0.7294\n",
      "Epoch 297/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2914 - accuracy: 0.8939 - val_loss: 3.0464 - val_accuracy: 0.7316\n",
      "Epoch 298/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.3023 - accuracy: 0.8875 - val_loss: 2.9976 - val_accuracy: 0.7313\n",
      "Epoch 299/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2752 - accuracy: 0.8957 - val_loss: 2.9550 - val_accuracy: 0.7300\n",
      "Epoch 300/300\n",
      "115/115 [==============================] - 4s 36ms/step - loss: 0.2769 - accuracy: 0.8940 - val_loss: 3.0791 - val_accuracy: 0.7278\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('simple_add')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=300,\n",
    "    validation_data=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 3.8740 - accuracy: 0.2792 - val_loss: 1.9559 - val_accuracy: 0.2710\n",
      "Epoch 2/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 1.8209 - accuracy: 0.3640 - val_loss: 1.8863 - val_accuracy: 0.3009\n",
      "Epoch 3/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.7101 - accuracy: 0.3831 - val_loss: 1.8648 - val_accuracy: 0.3225\n",
      "Epoch 4/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.6417 - accuracy: 0.4038 - val_loss: 1.7532 - val_accuracy: 0.3633\n",
      "Epoch 5/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.5430 - accuracy: 0.4376 - val_loss: 1.8644 - val_accuracy: 0.3764\n",
      "Epoch 6/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.4732 - accuracy: 0.4612 - val_loss: 1.8763 - val_accuracy: 0.3813\n",
      "Epoch 7/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.4324 - accuracy: 0.4725 - val_loss: 1.8666 - val_accuracy: 0.3993\n",
      "Epoch 8/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.3988 - accuracy: 0.4830 - val_loss: 1.7607 - val_accuracy: 0.4116\n",
      "Epoch 9/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.3630 - accuracy: 0.4965 - val_loss: 1.7912 - val_accuracy: 0.4238\n",
      "Epoch 10/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.3198 - accuracy: 0.5088 - val_loss: 1.8956 - val_accuracy: 0.4382\n",
      "Epoch 11/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.2996 - accuracy: 0.5161 - val_loss: 1.8595 - val_accuracy: 0.4428\n",
      "Epoch 12/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.2795 - accuracy: 0.5237 - val_loss: 1.9156 - val_accuracy: 0.4559\n",
      "Epoch 13/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.2429 - accuracy: 0.5359 - val_loss: 1.8954 - val_accuracy: 0.4753\n",
      "Epoch 14/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.2127 - accuracy: 0.5538 - val_loss: 1.9008 - val_accuracy: 0.4897\n",
      "Epoch 15/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 1.1551 - accuracy: 0.5736 - val_loss: 1.9373 - val_accuracy: 0.4729\n",
      "Epoch 16/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 1.1434 - accuracy: 0.5759 - val_loss: 1.9552 - val_accuracy: 0.5018\n",
      "Epoch 17/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 1.1187 - accuracy: 0.5866 - val_loss: 1.9627 - val_accuracy: 0.5142\n",
      "Epoch 18/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 1.0645 - accuracy: 0.6086 - val_loss: 1.9296 - val_accuracy: 0.5422\n",
      "Epoch 19/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 1.0264 - accuracy: 0.6224 - val_loss: 2.1005 - val_accuracy: 0.5443\n",
      "Epoch 20/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 1.0108 - accuracy: 0.6287 - val_loss: 1.9211 - val_accuracy: 0.5287\n",
      "Epoch 21/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.9637 - accuracy: 0.6463 - val_loss: 2.3127 - val_accuracy: 0.5768\n",
      "Epoch 22/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.9199 - accuracy: 0.6646 - val_loss: 2.1333 - val_accuracy: 0.5734\n",
      "Epoch 23/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.8834 - accuracy: 0.6840 - val_loss: 2.2956 - val_accuracy: 0.5946\n",
      "Epoch 24/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.8619 - accuracy: 0.6905 - val_loss: 2.2490 - val_accuracy: 0.6227\n",
      "Epoch 25/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.8247 - accuracy: 0.7012 - val_loss: 2.4106 - val_accuracy: 0.6408\n",
      "Epoch 26/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.7802 - accuracy: 0.7324 - val_loss: 2.3168 - val_accuracy: 0.6913\n",
      "Epoch 27/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.7548 - accuracy: 0.7580 - val_loss: 2.3403 - val_accuracy: 0.6969\n",
      "Epoch 28/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.7384 - accuracy: 0.7638 - val_loss: 2.5335 - val_accuracy: 0.6898\n",
      "Epoch 29/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.7196 - accuracy: 0.7720 - val_loss: 2.4070 - val_accuracy: 0.7088\n",
      "Epoch 30/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.6898 - accuracy: 0.7831 - val_loss: 2.5054 - val_accuracy: 0.7224\n",
      "Epoch 31/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.6636 - accuracy: 0.7912 - val_loss: 2.4839 - val_accuracy: 0.7246\n",
      "Epoch 32/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.6474 - accuracy: 0.7991 - val_loss: 2.3911 - val_accuracy: 0.7117\n",
      "Epoch 33/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.6252 - accuracy: 0.8059 - val_loss: 2.4151 - val_accuracy: 0.7180\n",
      "Epoch 34/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.6137 - accuracy: 0.8082 - val_loss: 2.4689 - val_accuracy: 0.7298\n",
      "Epoch 35/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.5958 - accuracy: 0.8159 - val_loss: 2.4538 - val_accuracy: 0.7487\n",
      "Epoch 36/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.5756 - accuracy: 0.8256 - val_loss: 2.5356 - val_accuracy: 0.7439\n",
      "Epoch 37/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.5713 - accuracy: 0.8258 - val_loss: 2.4812 - val_accuracy: 0.7489\n",
      "Epoch 38/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.5543 - accuracy: 0.8330 - val_loss: 2.6322 - val_accuracy: 0.7453\n",
      "Epoch 39/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.5316 - accuracy: 0.8374 - val_loss: 2.5640 - val_accuracy: 0.7420\n",
      "Epoch 40/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.5095 - accuracy: 0.8441 - val_loss: 2.6501 - val_accuracy: 0.7563\n",
      "Epoch 41/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4989 - accuracy: 0.8487 - val_loss: 2.5593 - val_accuracy: 0.7563\n",
      "Epoch 42/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4791 - accuracy: 0.8536 - val_loss: 2.6371 - val_accuracy: 0.7517\n",
      "Epoch 43/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4819 - accuracy: 0.8554 - val_loss: 2.6035 - val_accuracy: 0.7541\n",
      "Epoch 44/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4519 - accuracy: 0.8632 - val_loss: 2.6764 - val_accuracy: 0.7568\n",
      "Epoch 45/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.4402 - accuracy: 0.8725 - val_loss: 2.6940 - val_accuracy: 0.7555\n",
      "Epoch 46/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4223 - accuracy: 0.8753 - val_loss: 2.6974 - val_accuracy: 0.7581\n",
      "Epoch 47/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4047 - accuracy: 0.8813 - val_loss: 2.7498 - val_accuracy: 0.7640\n",
      "Epoch 48/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4074 - accuracy: 0.8802 - val_loss: 2.6983 - val_accuracy: 0.7624\n",
      "Epoch 49/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3942 - accuracy: 0.8842 - val_loss: 2.7296 - val_accuracy: 0.7609\n",
      "Epoch 50/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.3886 - accuracy: 0.8846 - val_loss: 2.8526 - val_accuracy: 0.7654\n",
      "Epoch 51/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.3832 - accuracy: 0.8872 - val_loss: 2.7778 - val_accuracy: 0.7606\n",
      "Epoch 52/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.4098 - accuracy: 0.8833 - val_loss: 2.9426 - val_accuracy: 0.7615\n",
      "Epoch 53/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.3945 - accuracy: 0.8870 - val_loss: 2.9192 - val_accuracy: 0.7617\n",
      "Epoch 54/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3671 - accuracy: 0.8938 - val_loss: 2.8594 - val_accuracy: 0.7634\n",
      "Epoch 55/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.3566 - accuracy: 0.8954 - val_loss: 2.8872 - val_accuracy: 0.7637\n",
      "Epoch 56/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3620 - accuracy: 0.8957 - val_loss: 2.8844 - val_accuracy: 0.7651\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3294 - accuracy: 0.9016 - val_loss: 2.9254 - val_accuracy: 0.7666\n",
      "Epoch 58/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.3287 - accuracy: 0.9032 - val_loss: 2.9980 - val_accuracy: 0.7683\n",
      "Epoch 59/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3374 - accuracy: 0.8989 - val_loss: 2.9652 - val_accuracy: 0.7668\n",
      "Epoch 60/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.3302 - accuracy: 0.8997 - val_loss: 2.9106 - val_accuracy: 0.7675\n",
      "Epoch 61/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3142 - accuracy: 0.9046 - val_loss: 2.9987 - val_accuracy: 0.7683\n",
      "Epoch 62/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3172 - accuracy: 0.9055 - val_loss: 2.9659 - val_accuracy: 0.7676\n",
      "Epoch 63/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3348 - accuracy: 0.9018 - val_loss: 2.9210 - val_accuracy: 0.7671\n",
      "Epoch 64/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3258 - accuracy: 0.9047 - val_loss: 3.0075 - val_accuracy: 0.7637\n",
      "Epoch 65/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3422 - accuracy: 0.8987 - val_loss: 2.9338 - val_accuracy: 0.7637\n",
      "Epoch 66/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3095 - accuracy: 0.9074 - val_loss: 2.9989 - val_accuracy: 0.7678\n",
      "Epoch 67/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3049 - accuracy: 0.9091 - val_loss: 2.9986 - val_accuracy: 0.7660\n",
      "Epoch 68/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3140 - accuracy: 0.9051 - val_loss: 2.9338 - val_accuracy: 0.7700\n",
      "Epoch 69/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3102 - accuracy: 0.9068 - val_loss: 2.9438 - val_accuracy: 0.7679\n",
      "Epoch 70/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.3029 - accuracy: 0.9083 - val_loss: 3.0210 - val_accuracy: 0.7688\n",
      "Epoch 71/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2915 - accuracy: 0.9104 - val_loss: 2.9884 - val_accuracy: 0.7703\n",
      "Epoch 72/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2897 - accuracy: 0.9116 - val_loss: 3.0321 - val_accuracy: 0.7701\n",
      "Epoch 73/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2915 - accuracy: 0.9140 - val_loss: 2.9123 - val_accuracy: 0.7706\n",
      "Epoch 74/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2874 - accuracy: 0.9159 - val_loss: 2.9327 - val_accuracy: 0.7688\n",
      "Epoch 75/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2830 - accuracy: 0.9167 - val_loss: 2.9812 - val_accuracy: 0.7693\n",
      "Epoch 76/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2787 - accuracy: 0.9168 - val_loss: 2.9298 - val_accuracy: 0.7696\n",
      "Epoch 77/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2552 - accuracy: 0.9233 - val_loss: 3.0054 - val_accuracy: 0.7715\n",
      "Epoch 78/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2838 - accuracy: 0.9184 - val_loss: 2.9843 - val_accuracy: 0.7685\n",
      "Epoch 79/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2709 - accuracy: 0.9199 - val_loss: 2.9330 - val_accuracy: 0.7699\n",
      "Epoch 80/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2742 - accuracy: 0.9200 - val_loss: 3.0145 - val_accuracy: 0.7710\n",
      "Epoch 81/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2561 - accuracy: 0.9226 - val_loss: 3.0463 - val_accuracy: 0.7712\n",
      "Epoch 82/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2595 - accuracy: 0.9241 - val_loss: 3.0670 - val_accuracy: 0.7719\n",
      "Epoch 83/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2483 - accuracy: 0.9251 - val_loss: 2.9959 - val_accuracy: 0.7734\n",
      "Epoch 84/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2494 - accuracy: 0.9244 - val_loss: 3.0976 - val_accuracy: 0.7721\n",
      "Epoch 85/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2668 - accuracy: 0.9212 - val_loss: 2.9132 - val_accuracy: 0.7681\n",
      "Epoch 86/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2588 - accuracy: 0.9233 - val_loss: 3.0399 - val_accuracy: 0.7687\n",
      "Epoch 87/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2702 - accuracy: 0.9205 - val_loss: 2.9268 - val_accuracy: 0.7716\n",
      "Epoch 88/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2493 - accuracy: 0.9251 - val_loss: 2.9993 - val_accuracy: 0.7715\n",
      "Epoch 89/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2324 - accuracy: 0.9286 - val_loss: 3.0217 - val_accuracy: 0.7737\n",
      "Epoch 90/300\n",
      "115/115 [==============================] - 6s 54ms/step - loss: 0.2244 - accuracy: 0.9317 - val_loss: 2.9930 - val_accuracy: 0.7714\n",
      "Epoch 91/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2442 - accuracy: 0.9279 - val_loss: 3.0194 - val_accuracy: 0.7706\n",
      "Epoch 92/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2377 - accuracy: 0.9282 - val_loss: 3.0062 - val_accuracy: 0.7718\n",
      "Epoch 93/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2297 - accuracy: 0.9295 - val_loss: 3.0669 - val_accuracy: 0.7710\n",
      "Epoch 94/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2303 - accuracy: 0.9310 - val_loss: 3.0838 - val_accuracy: 0.7726\n",
      "Epoch 95/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2363 - accuracy: 0.9309 - val_loss: 3.0902 - val_accuracy: 0.7714\n",
      "Epoch 96/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2409 - accuracy: 0.9287 - val_loss: 3.0873 - val_accuracy: 0.7696\n",
      "Epoch 97/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.2436 - accuracy: 0.9295 - val_loss: 3.1599 - val_accuracy: 0.7695\n",
      "Epoch 98/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2360 - accuracy: 0.9313 - val_loss: 3.0746 - val_accuracy: 0.7689\n",
      "Epoch 99/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2249 - accuracy: 0.9338 - val_loss: 3.0790 - val_accuracy: 0.7727\n",
      "Epoch 100/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.2219 - accuracy: 0.9348 - val_loss: 2.9987 - val_accuracy: 0.7728\n",
      "Epoch 101/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2271 - accuracy: 0.9319 - val_loss: 3.0755 - val_accuracy: 0.7704\n",
      "Epoch 102/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2377 - accuracy: 0.9310 - val_loss: 3.0574 - val_accuracy: 0.7716\n",
      "Epoch 103/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.2304 - accuracy: 0.9325 - val_loss: 3.0081 - val_accuracy: 0.7711\n",
      "Epoch 104/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2174 - accuracy: 0.9374 - val_loss: 3.0405 - val_accuracy: 0.7704\n",
      "Epoch 105/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2249 - accuracy: 0.9345 - val_loss: 3.1369 - val_accuracy: 0.7713\n",
      "Epoch 106/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2190 - accuracy: 0.9359 - val_loss: 3.0911 - val_accuracy: 0.7717\n",
      "Epoch 107/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2140 - accuracy: 0.9373 - val_loss: 3.1368 - val_accuracy: 0.7733\n",
      "Epoch 108/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.2237 - accuracy: 0.9377 - val_loss: 2.9954 - val_accuracy: 0.7712\n",
      "Epoch 109/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2059 - accuracy: 0.9402 - val_loss: 3.1155 - val_accuracy: 0.7736\n",
      "Epoch 110/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.2117 - accuracy: 0.9407 - val_loss: 2.9807 - val_accuracy: 0.7729\n",
      "Epoch 111/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2216 - accuracy: 0.9370 - val_loss: 2.9597 - val_accuracy: 0.7706\n",
      "Epoch 112/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2183 - accuracy: 0.9388 - val_loss: 3.0335 - val_accuracy: 0.7717\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2134 - accuracy: 0.9379 - val_loss: 3.1179 - val_accuracy: 0.7740\n",
      "Epoch 114/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.2073 - accuracy: 0.9414 - val_loss: 3.0801 - val_accuracy: 0.7722\n",
      "Epoch 115/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.2129 - accuracy: 0.9435 - val_loss: 3.0850 - val_accuracy: 0.7738\n",
      "Epoch 116/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1963 - accuracy: 0.9447 - val_loss: 3.1561 - val_accuracy: 0.7722\n",
      "Epoch 117/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2174 - accuracy: 0.9408 - val_loss: 3.0996 - val_accuracy: 0.7711\n",
      "Epoch 118/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2085 - accuracy: 0.9394 - val_loss: 3.1144 - val_accuracy: 0.7728\n",
      "Epoch 119/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2020 - accuracy: 0.9416 - val_loss: 3.0743 - val_accuracy: 0.7741\n",
      "Epoch 120/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1997 - accuracy: 0.9436 - val_loss: 3.1199 - val_accuracy: 0.7727\n",
      "Epoch 121/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2042 - accuracy: 0.9418 - val_loss: 3.0946 - val_accuracy: 0.7737\n",
      "Epoch 122/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.2068 - accuracy: 0.9445 - val_loss: 3.2188 - val_accuracy: 0.7705\n",
      "Epoch 123/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2058 - accuracy: 0.9402 - val_loss: 3.1655 - val_accuracy: 0.7710\n",
      "Epoch 124/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1981 - accuracy: 0.9443 - val_loss: 3.1722 - val_accuracy: 0.7719\n",
      "Epoch 125/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1909 - accuracy: 0.9448 - val_loss: 3.0949 - val_accuracy: 0.7746\n",
      "Epoch 126/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1838 - accuracy: 0.9489 - val_loss: 3.1064 - val_accuracy: 0.7738\n",
      "Epoch 127/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2009 - accuracy: 0.9472 - val_loss: 3.1565 - val_accuracy: 0.7691\n",
      "Epoch 128/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2139 - accuracy: 0.9424 - val_loss: 3.0331 - val_accuracy: 0.7723\n",
      "Epoch 129/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1946 - accuracy: 0.9441 - val_loss: 3.0714 - val_accuracy: 0.7739\n",
      "Epoch 130/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1799 - accuracy: 0.9490 - val_loss: 3.1223 - val_accuracy: 0.7730\n",
      "Epoch 131/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1920 - accuracy: 0.9475 - val_loss: 3.1342 - val_accuracy: 0.7718\n",
      "Epoch 132/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1972 - accuracy: 0.9452 - val_loss: 3.0222 - val_accuracy: 0.7713\n",
      "Epoch 133/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1780 - accuracy: 0.9483 - val_loss: 3.0254 - val_accuracy: 0.7740\n",
      "Epoch 134/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1732 - accuracy: 0.9486 - val_loss: 3.1193 - val_accuracy: 0.7739\n",
      "Epoch 135/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1799 - accuracy: 0.9475 - val_loss: 3.0773 - val_accuracy: 0.7729\n",
      "Epoch 136/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1746 - accuracy: 0.9502 - val_loss: 3.1555 - val_accuracy: 0.7742\n",
      "Epoch 137/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1708 - accuracy: 0.9509 - val_loss: 3.1078 - val_accuracy: 0.7731\n",
      "Epoch 138/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1980 - accuracy: 0.9467 - val_loss: 3.2055 - val_accuracy: 0.7709\n",
      "Epoch 139/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1796 - accuracy: 0.9489 - val_loss: 3.1512 - val_accuracy: 0.7750\n",
      "Epoch 140/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1859 - accuracy: 0.9480 - val_loss: 3.1179 - val_accuracy: 0.7725\n",
      "Epoch 141/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1750 - accuracy: 0.9500 - val_loss: 3.1441 - val_accuracy: 0.7729\n",
      "Epoch 142/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1739 - accuracy: 0.9492 - val_loss: 3.1126 - val_accuracy: 0.7754\n",
      "Epoch 143/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1695 - accuracy: 0.9498 - val_loss: 3.1672 - val_accuracy: 0.7735\n",
      "Epoch 144/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1819 - accuracy: 0.9469 - val_loss: 3.1414 - val_accuracy: 0.7689\n",
      "Epoch 145/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1835 - accuracy: 0.9469 - val_loss: 3.1182 - val_accuracy: 0.7731\n",
      "Epoch 146/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2108 - accuracy: 0.9420 - val_loss: 3.0382 - val_accuracy: 0.7724\n",
      "Epoch 147/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1966 - accuracy: 0.9450 - val_loss: 3.1219 - val_accuracy: 0.7699\n",
      "Epoch 148/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1772 - accuracy: 0.9497 - val_loss: 3.1765 - val_accuracy: 0.7741\n",
      "Epoch 149/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1837 - accuracy: 0.9483 - val_loss: 3.2445 - val_accuracy: 0.7729\n",
      "Epoch 150/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1848 - accuracy: 0.9495 - val_loss: 3.0779 - val_accuracy: 0.7735\n",
      "Epoch 151/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1873 - accuracy: 0.9458 - val_loss: 3.1700 - val_accuracy: 0.7725\n",
      "Epoch 152/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1864 - accuracy: 0.9484 - val_loss: 3.0908 - val_accuracy: 0.7698\n",
      "Epoch 153/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1849 - accuracy: 0.9474 - val_loss: 3.0562 - val_accuracy: 0.7737\n",
      "Epoch 154/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1717 - accuracy: 0.9510 - val_loss: 3.1723 - val_accuracy: 0.7751\n",
      "Epoch 155/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1811 - accuracy: 0.9507 - val_loss: 3.0889 - val_accuracy: 0.7740\n",
      "Epoch 156/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1797 - accuracy: 0.9495 - val_loss: 3.1055 - val_accuracy: 0.7731\n",
      "Epoch 157/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1841 - accuracy: 0.9487 - val_loss: 3.0484 - val_accuracy: 0.7738\n",
      "Epoch 158/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1710 - accuracy: 0.9520 - val_loss: 3.0279 - val_accuracy: 0.7740\n",
      "Epoch 159/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1614 - accuracy: 0.9529 - val_loss: 3.0895 - val_accuracy: 0.7750\n",
      "Epoch 160/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1655 - accuracy: 0.9511 - val_loss: 3.1229 - val_accuracy: 0.7754\n",
      "Epoch 161/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1613 - accuracy: 0.9535 - val_loss: 3.0184 - val_accuracy: 0.7735\n",
      "Epoch 162/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1680 - accuracy: 0.9503 - val_loss: 3.1432 - val_accuracy: 0.7742\n",
      "Epoch 163/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1570 - accuracy: 0.9531 - val_loss: 3.1039 - val_accuracy: 0.7741\n",
      "Epoch 164/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1641 - accuracy: 0.9539 - val_loss: 3.1896 - val_accuracy: 0.7745\n",
      "Epoch 165/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1640 - accuracy: 0.9522 - val_loss: 3.1414 - val_accuracy: 0.7749\n",
      "Epoch 166/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1763 - accuracy: 0.9498 - val_loss: 3.0844 - val_accuracy: 0.7719\n",
      "Epoch 167/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1834 - accuracy: 0.9505 - val_loss: 3.0684 - val_accuracy: 0.7726\n",
      "Epoch 168/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1930 - accuracy: 0.9470 - val_loss: 3.1890 - val_accuracy: 0.7717\n",
      "Epoch 169/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1959 - accuracy: 0.9469 - val_loss: 3.1945 - val_accuracy: 0.7695\n",
      "Epoch 170/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1842 - accuracy: 0.9483 - val_loss: 3.1928 - val_accuracy: 0.7736\n",
      "Epoch 171/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1967 - accuracy: 0.9466 - val_loss: 3.1445 - val_accuracy: 0.7739\n",
      "Epoch 172/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1977 - accuracy: 0.9466 - val_loss: 3.0795 - val_accuracy: 0.7711\n",
      "Epoch 173/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1849 - accuracy: 0.9485 - val_loss: 3.0523 - val_accuracy: 0.7727\n",
      "Epoch 174/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2072 - accuracy: 0.9500 - val_loss: 3.0282 - val_accuracy: 0.7709\n",
      "Epoch 175/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1838 - accuracy: 0.9497 - val_loss: 3.1254 - val_accuracy: 0.7733\n",
      "Epoch 176/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1702 - accuracy: 0.9498 - val_loss: 3.0846 - val_accuracy: 0.7719\n",
      "Epoch 177/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1845 - accuracy: 0.9488 - val_loss: 3.1256 - val_accuracy: 0.7702\n",
      "Epoch 178/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1822 - accuracy: 0.9487 - val_loss: 3.1414 - val_accuracy: 0.7744\n",
      "Epoch 179/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1836 - accuracy: 0.9482 - val_loss: 3.0560 - val_accuracy: 0.7726\n",
      "Epoch 180/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1873 - accuracy: 0.9478 - val_loss: 3.1020 - val_accuracy: 0.7746\n",
      "Epoch 181/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1739 - accuracy: 0.9487 - val_loss: 3.0703 - val_accuracy: 0.7740\n",
      "Epoch 182/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1632 - accuracy: 0.9529 - val_loss: 3.1342 - val_accuracy: 0.7741\n",
      "Epoch 183/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1622 - accuracy: 0.9508 - val_loss: 3.1542 - val_accuracy: 0.7751\n",
      "Epoch 184/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1689 - accuracy: 0.9502 - val_loss: 3.0717 - val_accuracy: 0.7723\n",
      "Epoch 185/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1713 - accuracy: 0.9505 - val_loss: 3.1348 - val_accuracy: 0.7722\n",
      "Epoch 186/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1901 - accuracy: 0.9497 - val_loss: 3.1113 - val_accuracy: 0.7712\n",
      "Epoch 187/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1811 - accuracy: 0.9498 - val_loss: 3.0609 - val_accuracy: 0.7730\n",
      "Epoch 188/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1783 - accuracy: 0.9498 - val_loss: 3.0984 - val_accuracy: 0.7743\n",
      "Epoch 189/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1724 - accuracy: 0.9512 - val_loss: 3.1241 - val_accuracy: 0.7746\n",
      "Epoch 190/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1630 - accuracy: 0.9519 - val_loss: 3.1359 - val_accuracy: 0.7748\n",
      "Epoch 191/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1682 - accuracy: 0.9529 - val_loss: 3.0764 - val_accuracy: 0.7725\n",
      "Epoch 192/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1703 - accuracy: 0.9513 - val_loss: 3.0124 - val_accuracy: 0.7736\n",
      "Epoch 193/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1904 - accuracy: 0.9489 - val_loss: 3.0490 - val_accuracy: 0.7727\n",
      "Epoch 194/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1755 - accuracy: 0.9487 - val_loss: 3.0766 - val_accuracy: 0.7749\n",
      "Epoch 195/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1635 - accuracy: 0.9528 - val_loss: 3.0742 - val_accuracy: 0.7743\n",
      "Epoch 196/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1629 - accuracy: 0.9525 - val_loss: 3.0015 - val_accuracy: 0.7750\n",
      "Epoch 197/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1585 - accuracy: 0.9530 - val_loss: 3.0940 - val_accuracy: 0.7745\n",
      "Epoch 198/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1609 - accuracy: 0.9547 - val_loss: 3.0715 - val_accuracy: 0.7728\n",
      "Epoch 199/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1655 - accuracy: 0.9523 - val_loss: 3.0658 - val_accuracy: 0.7727\n",
      "Epoch 200/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1712 - accuracy: 0.9486 - val_loss: 3.0851 - val_accuracy: 0.7739\n",
      "Epoch 201/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1923 - accuracy: 0.9492 - val_loss: 3.0631 - val_accuracy: 0.7720\n",
      "Epoch 202/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1701 - accuracy: 0.9521 - val_loss: 3.0624 - val_accuracy: 0.7733\n",
      "Epoch 203/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1563 - accuracy: 0.9538 - val_loss: 3.0755 - val_accuracy: 0.7754\n",
      "Epoch 204/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1649 - accuracy: 0.9517 - val_loss: 3.0766 - val_accuracy: 0.7742\n",
      "Epoch 205/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1787 - accuracy: 0.9495 - val_loss: 3.1401 - val_accuracy: 0.7735\n",
      "Epoch 206/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1959 - accuracy: 0.9500 - val_loss: 3.0948 - val_accuracy: 0.7720\n",
      "Epoch 207/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1749 - accuracy: 0.9493 - val_loss: 3.1377 - val_accuracy: 0.7748\n",
      "Epoch 208/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1589 - accuracy: 0.9536 - val_loss: 3.1765 - val_accuracy: 0.7762\n",
      "Epoch 209/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1563 - accuracy: 0.9538 - val_loss: 3.1653 - val_accuracy: 0.7750\n",
      "Epoch 210/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1663 - accuracy: 0.9496 - val_loss: 3.1330 - val_accuracy: 0.7727\n",
      "Epoch 211/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1690 - accuracy: 0.9498 - val_loss: 3.2378 - val_accuracy: 0.7749\n",
      "Epoch 212/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1788 - accuracy: 0.9502 - val_loss: 3.1467 - val_accuracy: 0.7749\n",
      "Epoch 213/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1654 - accuracy: 0.9522 - val_loss: 3.1403 - val_accuracy: 0.7740\n",
      "Epoch 214/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1842 - accuracy: 0.9490 - val_loss: 3.1865 - val_accuracy: 0.7728\n",
      "Epoch 215/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.2165 - accuracy: 0.9490 - val_loss: 3.1100 - val_accuracy: 0.7720\n",
      "Epoch 216/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1756 - accuracy: 0.9495 - val_loss: 3.1385 - val_accuracy: 0.7745\n",
      "Epoch 217/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1553 - accuracy: 0.9543 - val_loss: 3.1396 - val_accuracy: 0.7756\n",
      "Epoch 218/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1701 - accuracy: 0.9533 - val_loss: 3.1530 - val_accuracy: 0.7731\n",
      "Epoch 219/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1663 - accuracy: 0.9531 - val_loss: 3.1143 - val_accuracy: 0.7737\n",
      "Epoch 220/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1745 - accuracy: 0.9510 - val_loss: 3.1567 - val_accuracy: 0.7743\n",
      "Epoch 221/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1696 - accuracy: 0.9508 - val_loss: 3.1132 - val_accuracy: 0.7717\n",
      "Epoch 222/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1758 - accuracy: 0.9491 - val_loss: 3.1057 - val_accuracy: 0.7744\n",
      "Epoch 223/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1716 - accuracy: 0.9471 - val_loss: 3.1450 - val_accuracy: 0.7718\n",
      "Epoch 224/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1555 - accuracy: 0.9542 - val_loss: 3.1543 - val_accuracy: 0.7754\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1596 - accuracy: 0.9541 - val_loss: 3.1040 - val_accuracy: 0.7746\n",
      "Epoch 226/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1556 - accuracy: 0.9543 - val_loss: 3.1804 - val_accuracy: 0.7755\n",
      "Epoch 227/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1543 - accuracy: 0.9551 - val_loss: 3.0771 - val_accuracy: 0.7756\n",
      "Epoch 228/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1630 - accuracy: 0.9544 - val_loss: 3.2331 - val_accuracy: 0.7740\n",
      "Epoch 229/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1609 - accuracy: 0.9545 - val_loss: 3.1495 - val_accuracy: 0.7747\n",
      "Epoch 230/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1511 - accuracy: 0.9550 - val_loss: 3.1324 - val_accuracy: 0.7763\n",
      "Epoch 231/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1559 - accuracy: 0.9558 - val_loss: 3.1001 - val_accuracy: 0.7763\n",
      "Epoch 232/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1621 - accuracy: 0.9554 - val_loss: 3.1342 - val_accuracy: 0.7752\n",
      "Epoch 233/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1690 - accuracy: 0.9523 - val_loss: 3.0560 - val_accuracy: 0.7758\n",
      "Epoch 234/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1540 - accuracy: 0.9554 - val_loss: 3.1467 - val_accuracy: 0.7748\n",
      "Epoch 235/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1622 - accuracy: 0.9549 - val_loss: 3.1690 - val_accuracy: 0.7764\n",
      "Epoch 236/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1640 - accuracy: 0.9528 - val_loss: 3.1465 - val_accuracy: 0.7759\n",
      "Epoch 237/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.2027 - accuracy: 0.9474 - val_loss: 3.0821 - val_accuracy: 0.7689\n",
      "Epoch 238/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1952 - accuracy: 0.9469 - val_loss: 3.1090 - val_accuracy: 0.7721\n",
      "Epoch 239/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1932 - accuracy: 0.9448 - val_loss: 3.1347 - val_accuracy: 0.7737\n",
      "Epoch 240/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1819 - accuracy: 0.9514 - val_loss: 3.1050 - val_accuracy: 0.7736\n",
      "Epoch 241/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1942 - accuracy: 0.9513 - val_loss: 3.0912 - val_accuracy: 0.7728\n",
      "Epoch 242/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1855 - accuracy: 0.9530 - val_loss: 3.1231 - val_accuracy: 0.7715\n",
      "Epoch 243/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1825 - accuracy: 0.9504 - val_loss: 3.1438 - val_accuracy: 0.7728\n",
      "Epoch 244/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.2060 - accuracy: 0.9528 - val_loss: 3.1763 - val_accuracy: 0.7736\n",
      "Epoch 245/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1595 - accuracy: 0.9517 - val_loss: 3.1967 - val_accuracy: 0.7748\n",
      "Epoch 246/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1734 - accuracy: 0.9526 - val_loss: 3.1287 - val_accuracy: 0.7737\n",
      "Epoch 247/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1702 - accuracy: 0.9532 - val_loss: 3.1174 - val_accuracy: 0.7754\n",
      "Epoch 248/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1664 - accuracy: 0.9552 - val_loss: 3.1480 - val_accuracy: 0.7739\n",
      "Epoch 249/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1675 - accuracy: 0.9530 - val_loss: 3.1492 - val_accuracy: 0.7739\n",
      "Epoch 250/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1732 - accuracy: 0.9528 - val_loss: 3.1434 - val_accuracy: 0.7735\n",
      "Epoch 251/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1552 - accuracy: 0.9533 - val_loss: 3.1911 - val_accuracy: 0.7752\n",
      "Epoch 252/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1493 - accuracy: 0.9568 - val_loss: 3.1685 - val_accuracy: 0.7762\n",
      "Epoch 253/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1609 - accuracy: 0.9557 - val_loss: 3.2263 - val_accuracy: 0.7762\n",
      "Epoch 254/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1581 - accuracy: 0.9540 - val_loss: 3.1692 - val_accuracy: 0.7766\n",
      "Epoch 255/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1595 - accuracy: 0.9547 - val_loss: 3.2007 - val_accuracy: 0.7753\n",
      "Epoch 256/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1482 - accuracy: 0.9564 - val_loss: 3.2058 - val_accuracy: 0.7750\n",
      "Epoch 257/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1578 - accuracy: 0.9560 - val_loss: 3.2186 - val_accuracy: 0.7762\n",
      "Epoch 258/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1449 - accuracy: 0.9551 - val_loss: 3.1960 - val_accuracy: 0.7764\n",
      "Epoch 259/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1474 - accuracy: 0.9581 - val_loss: 3.1999 - val_accuracy: 0.7740\n",
      "Epoch 260/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1725 - accuracy: 0.9569 - val_loss: 3.1402 - val_accuracy: 0.7742\n",
      "Epoch 261/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.2044 - accuracy: 0.9497 - val_loss: 3.1173 - val_accuracy: 0.7687\n",
      "Epoch 262/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1805 - accuracy: 0.9518 - val_loss: 3.0929 - val_accuracy: 0.7731\n",
      "Epoch 263/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1640 - accuracy: 0.9515 - val_loss: 3.1598 - val_accuracy: 0.7760\n",
      "Epoch 264/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1524 - accuracy: 0.9559 - val_loss: 3.1961 - val_accuracy: 0.7757\n",
      "Epoch 265/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1435 - accuracy: 0.9573 - val_loss: 3.1879 - val_accuracy: 0.7763\n",
      "Epoch 266/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1574 - accuracy: 0.9560 - val_loss: 3.1913 - val_accuracy: 0.7756\n",
      "Epoch 267/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1612 - accuracy: 0.9549 - val_loss: 3.1617 - val_accuracy: 0.7742\n",
      "Epoch 268/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1722 - accuracy: 0.9505 - val_loss: 3.1322 - val_accuracy: 0.7722\n",
      "Epoch 269/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1661 - accuracy: 0.9523 - val_loss: 3.2034 - val_accuracy: 0.7759\n",
      "Epoch 270/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1580 - accuracy: 0.9531 - val_loss: 3.2312 - val_accuracy: 0.7754\n",
      "Epoch 271/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1576 - accuracy: 0.9553 - val_loss: 3.2439 - val_accuracy: 0.7742\n",
      "Epoch 272/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1771 - accuracy: 0.9536 - val_loss: 3.2201 - val_accuracy: 0.7748\n",
      "Epoch 273/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1588 - accuracy: 0.9541 - val_loss: 3.2553 - val_accuracy: 0.7719\n",
      "Epoch 274/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1782 - accuracy: 0.9514 - val_loss: 3.2687 - val_accuracy: 0.7736\n",
      "Epoch 275/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1577 - accuracy: 0.9552 - val_loss: 3.2845 - val_accuracy: 0.7743\n",
      "Epoch 276/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1517 - accuracy: 0.9558 - val_loss: 3.2707 - val_accuracy: 0.7747\n",
      "Epoch 277/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1618 - accuracy: 0.9530 - val_loss: 3.2407 - val_accuracy: 0.7730\n",
      "Epoch 278/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1733 - accuracy: 0.9531 - val_loss: 3.2592 - val_accuracy: 0.7730\n",
      "Epoch 279/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1582 - accuracy: 0.9538 - val_loss: 3.2859 - val_accuracy: 0.7751\n",
      "Epoch 280/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1470 - accuracy: 0.9573 - val_loss: 3.2917 - val_accuracy: 0.7751\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1602 - accuracy: 0.9551 - val_loss: 3.2481 - val_accuracy: 0.7731\n",
      "Epoch 282/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1559 - accuracy: 0.9563 - val_loss: 3.2312 - val_accuracy: 0.7746\n",
      "Epoch 283/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1453 - accuracy: 0.9580 - val_loss: 3.3052 - val_accuracy: 0.7731\n",
      "Epoch 284/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1935 - accuracy: 0.9473 - val_loss: 3.2699 - val_accuracy: 0.7672\n",
      "Epoch 285/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1834 - accuracy: 0.9461 - val_loss: 3.2462 - val_accuracy: 0.7695\n",
      "Epoch 286/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1815 - accuracy: 0.9484 - val_loss: 3.2463 - val_accuracy: 0.7716\n",
      "Epoch 287/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1791 - accuracy: 0.9516 - val_loss: 3.2839 - val_accuracy: 0.7729\n",
      "Epoch 288/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1688 - accuracy: 0.9521 - val_loss: 3.2429 - val_accuracy: 0.7738\n",
      "Epoch 289/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1741 - accuracy: 0.9527 - val_loss: 3.2806 - val_accuracy: 0.7719\n",
      "Epoch 290/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1882 - accuracy: 0.9517 - val_loss: 3.1899 - val_accuracy: 0.7708\n",
      "Epoch 291/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1878 - accuracy: 0.9508 - val_loss: 3.2135 - val_accuracy: 0.7742\n",
      "Epoch 292/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1704 - accuracy: 0.9523 - val_loss: 3.1860 - val_accuracy: 0.7743\n",
      "Epoch 293/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1565 - accuracy: 0.9535 - val_loss: 3.2067 - val_accuracy: 0.7757\n",
      "Epoch 294/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1507 - accuracy: 0.9557 - val_loss: 3.1955 - val_accuracy: 0.7755\n",
      "Epoch 295/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1473 - accuracy: 0.9563 - val_loss: 3.1891 - val_accuracy: 0.7758\n",
      "Epoch 296/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1580 - accuracy: 0.9545 - val_loss: 3.2063 - val_accuracy: 0.7770\n",
      "Epoch 297/300\n",
      "115/115 [==============================] - 6s 53ms/step - loss: 0.1521 - accuracy: 0.9548 - val_loss: 3.1749 - val_accuracy: 0.7773\n",
      "Epoch 298/300\n",
      "115/115 [==============================] - 6s 51ms/step - loss: 0.1529 - accuracy: 0.9556 - val_loss: 3.2257 - val_accuracy: 0.7768\n",
      "Epoch 299/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1599 - accuracy: 0.9565 - val_loss: 3.2897 - val_accuracy: 0.7759\n",
      "Epoch 300/300\n",
      "115/115 [==============================] - 6s 52ms/step - loss: 0.1781 - accuracy: 0.9558 - val_loss: 3.2575 - val_accuracy: 0.7748\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('djgrad')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=300,\n",
    "    validation_data=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = [tf.random.uniform(((x+1)*2,)) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1. 0. 1. 0. 0. 1.]], shape=(1, 6), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[0.21151745, 0.        , 0.855551  , 0.        , 0.        ,\n",
       "        0.26175773]], dtype=float32)>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_mask(grads):\n",
    "    mask = []\n",
    "    for g in grads:\n",
    "        size = g.shape[0]\n",
    "        m = 2\n",
    "        assert m%1==0\n",
    "\n",
    "        split = tf.concat([tf.ones(size//m)*i for i in range(m)],0)\n",
    "        split = tf.random.shuffle(split)\n",
    "        mask.append(tf.reshape(split,(1,-1)))\n",
    "\n",
    "    return mask\n",
    "    \n",
    "res = gen_mask(grads)\n",
    "print(res[2])\n",
    "tf.math.multiply(res[2],grads[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car\n",
    "#### Variables\n",
    "- queue: forwarding queue (gradients to forward)\n",
    "- set: gradients received (prevents from reapplying the same gradients multiple times)\n",
    "    - use the [hash](https://gist.github.com/nmalkin/e287f71788c57fd71bd0a7eec9345add) on [bytes](https://stackoverflow.com/questions/67076522/how-to-convert-tensorflow-tensor-to-bytes)\n",
    "- list: neighbors (cars it can share with)\n",
    "#### Functions\n",
    "- forward (Send the gradients from one vehicle to its neighbor)\n",
    "    - p (probability that each gradient will be forwarded)\n",
    "    - Forward all gradients every round, and only forward if it hasn't been seen before\n",
    "- check_gradients (see if gradients have been used before)\n",
    "- receive (update queue with new gradients)\n",
    "- apply_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
