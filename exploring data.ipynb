{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow import keras\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "fp_local = '/home/jovyan/docker/src/python/temp_test/DJGrad'\n",
    "fp_data = os.path.join(fp_local, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv(os.path.join(fp_data,'winequality-red.csv'),delimiter=';')\n",
    "wine_df = wine_df.append(pd.read_csv(os.path.join(fp_data,'winequality-white.csv'),delimiter=';'))\n",
    "wine_df = wine_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.052</td>\n",
       "      <td>19.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.79</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.082</td>\n",
       "      <td>15.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99655</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.68</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041</td>\n",
       "      <td>39.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.99004</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.37</td>\n",
       "      <td>12.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.27</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.059</td>\n",
       "      <td>23.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.99570</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.74</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.039</td>\n",
       "      <td>51.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.99770</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.43</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.28</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.049</td>\n",
       "      <td>31.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.99677</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>10.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.035</td>\n",
       "      <td>31.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99096</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.72</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.081</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0.045</td>\n",
       "      <td>53.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.99752</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.77</td>\n",
       "      <td>10.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.036</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.99100</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.42</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1198            7.7             0.260         0.26             2.0      0.052   \n",
       "1247            7.4             0.550         0.19             1.8      0.082   \n",
       "4683            6.5             0.330         0.32             1.0      0.041   \n",
       "1713            6.6             0.340         0.27             6.2      0.059   \n",
       "1282            7.4             0.310         0.74            10.7      0.039   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "3814            7.4             0.340         0.28            12.1      0.049   \n",
       "3568            7.8             0.150         0.34             1.1      0.035   \n",
       "602             7.7             0.835         0.00             2.6      0.081   \n",
       "2267            6.6             0.190         0.43            10.9      0.045   \n",
       "336             6.3             0.230         0.33             1.5      0.036   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1198                 19.0                  77.0  0.99510  3.15       0.79   \n",
       "1247                 15.0                  34.0  0.99655  3.49       0.68   \n",
       "4683                 39.0                 120.0  0.99004  3.06       0.37   \n",
       "1713                 23.0                 136.0  0.99570  3.30       0.49   \n",
       "1282                 51.0                 147.0  0.99770  3.02       0.43   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "3814                 31.0                 149.0  0.99677  3.22       0.49   \n",
       "3568                 31.0                  93.0  0.99096  3.07       0.72   \n",
       "602                   6.0                  14.0  0.99750  3.30       0.52   \n",
       "2267                 53.0                 154.0  0.99752  3.52       0.77   \n",
       "336                  15.0                 105.0  0.99100  3.32       0.42   \n",
       "\n",
       "      alcohol  quality  \n",
       "1198     10.9        6  \n",
       "1247     10.5        5  \n",
       "4683     12.2        6  \n",
       "1713     10.1        6  \n",
       "1282      8.7        5  \n",
       "...       ...      ...  \n",
       "3814     10.3        5  \n",
       "3568     11.3        7  \n",
       "602       9.3        5  \n",
       "2267     10.4        6  \n",
       "336      11.2        6  \n",
       "\n",
       "[6497 rows x 12 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda/lib/python3.8/site-packages/pandas/plotting/_matplotlib/tools.py:331: MatplotlibDeprecationWarning: \n",
      "The is_first_col function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use ax.get_subplotspec().is_first_col() instead.\n",
      "  if ax.is_first_col():\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wine_df.hist(figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbkAAAFQCAYAAAAiHwBiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABG8ElEQVR4nO3dedzlY/3H8dd7xppdJIRBg2TfskchJFsk+2gRRUVEpYXqF2kTWpBdEqWmyL5GMmMZyyCSYmyRfWwz8/79cV3HfOfMOfd97vt8v/d9zpnP0+M87vPdPt/rvu9xX+e6vtd1fWSbEEIIoReNGO4ChBBCCFWJSi6EEELPikouhBBCz4pKLoQQQs+KSi6EEELPikouhBBCz4pKLoQQwpCQdLqkpyXd0+S4JP1U0kOS7pK0Vrv3jEouhBDCUDkT2LqP49sAo/Nrf+Dn7d4wKrkQQghDwvYNwP/6OGUH4GwntwALSlq8nXvO1s7FYei9+czDlSxR888ND6oiLAALLTG5krhn/OtdlcTde4nHK4kLcOTjC1YS9xWmVBL3zK1fryQuwKGXz1dJ3KMX7+tv6OCdP2mJSuICzF5R3C/851y1G2Mgf3PmWHT5z5BaYDWn2D5lALdbEni0sP1Y3vfEAGLMICq5EEIIzU2b2vKpuUIbSKVWuajkQgghNOdpQ3m3ScBShe135X2DFs/kQgghNDdtWuuv9o0F9smjLNcHXrA96K5KiJZcCCGEPrjElpyk84HNgEUkPQZ8k/xI0vYvgEuBbYGHgMnAfu3eMyq5EEIIzZXTQgPA9u79HDfwudJuSJd0V0r6vKT7JJ0naXtJR5YQczNJfy4hzjGStugrfrHMknaUtHK79w0hhCEx9c3WXx2oW1pynwW2sP1Y3h47nIUpsv2NFs4Zy/Qy7wj8GZhYYbFCCKEcQzvwpHQd35KT9AtgOeAvkg6RNEbSSfnYHyXtk99/RtJ5+f1Wkv4m6XZJF0qaN+/fWtL9km4Hdm5yv1GSbszX3i5pw8KxIyTdLWmCpGPzvjMl7dJX/FqZc6ztgeMl3Slp+Xxu7bzRxe0QQhh2QzvwpHQd35KzfYCkrYHNbT8jaUzh8P7ATZL+BXwJWF/SIsBRpJbfK5KOAA6V9H3gVOADpIeaFzS55dPAlrZfkzQaOB9YR9I2pNn477M9WdLCxYskzdVffNs3SxoL/Nn2Rfm6FyStYftO0kPWMwb8QwohhIqUOfBkOHR8S64vtp8CvgFcC3zJ9v+A9YGVSZXfncC+wDLASsC/bD+YH26e2yTs7MCpku4GLsyxALYAzrA9Od+7flmFVuPXOw3YT9JIYDfg1/UnSNpf0nhJ4087+/wWw4YQQgmiJTfsVgWeBWpr7gi4sn4Uj6Q1Wox3CPAUsDrpQ8Br5RSzqd+RhtFeA9xm+9n6E4qrCFS1rFcIITQULbnhI2k90qrVawKHSVoWuAXYSNK78znzSFoBuB8YJWn5fHmzoawLAE84tdH3Bkbm/VeSWlxvy3EXrruu1fgvAW8t2mf7NeBy0mrb0VUZQugsXT66smsrOUlzkp6BfcL246RncqcDzwBjgPMl3QX8DVgpVyb7A5fkwR1PNwn9M2BfSRNIXZCvANi+jDRCcnzuBj2seNEA4v8GOFzSHYUK8TxgGnDFgH4IIYRQteiurJ7tUYX3Z5JyEkHqUqztLw7TvwZYt0Gcy0gVV1/3ehBYrbDriMKxY4Fj684f01/8Yplt38T053w1G5Oe97W+EmoIIQyFLu+u7IpKrpdJuhhYnjQqM4QQOkuHttBaFZXcMLO903CXIYQQmun2Dqao5EIIITQ3tZqEvEMlKrkQQgjNxTO5MJT+ueFBlcRd/uaTKokL8OE1P1tJ3FVGVvMJc+53VNc989yk1yuJ++LUaqZzPjdOlcQF+NoCL1QS9+Xn5qwk7gIV/q2/ebZXqwvergFkBu9EUcmFEEJoLlpyIYQQelaMrgwhhNCzurwl17UrnoQQQhgCU6a0/upHTkf2gKSHGiW/lrS0pGvzilB3Sdq23eJ3fCWX87vd08I5exS215H00/z+rfxzFZUvMoOHEHqWPbXlV19yppWTSesNrwzs3uBv4VHAb22vCXyctMxiW3qlu3IUsAc5TY3t8cD4obhxZAYPIfS08p7JrQc8ZPthAEm/IeXoLP4tNDB/fr8A8Hi7Nx3ylpykYyV9rrD9LUmHKTle0j05+/ZuDa5tlrX7WGCTnG37kGIrqu76RSX9TtK4/NpoAPeIzOAhhFmPp7X8Kua+zK/9C5GWBB4tbD+W9xV9C9hL0mPApcDB7RZ/OFpyFwA/ITVbAT4GfIhUKaxBWnR5EWCcpBvqrm2YtRs4EjjM9naQugqb3PsE4Me2/yppaVKKm/e0co/IDB5CmCUNoCVXzH05SLsDZ9r+oaQNgHMkreI20pMPeUvO9h3AOyQtIWl14Dnbj5JW4j/f9tSc8ft6Zs4k0Cxrd6u2AE7KqXLGAvNLmrfFe3REZvDfvvCfFsOGEEIJBtCS68ckYKnC9rvyvqJPAr8FsP03YC5So2fQhuuZ3IXALsA7adDi6UO7WbtHAOvn3G9V3WOgBpQZ/P4Vto3M4CGEoVPe2pXjgNE5ufUk0sCSPerO+Q/wQeBMSe8hVXL/beemwzW68gLSN7gLqcIDuBHYTdJISYsCmwK31l3XLGv3DNm2+3AFhT5eSWs0OCcyg4cQQk1JSVNtTwEOIv29u480ivLePEJ9+3zal4BP56TV5wNjcs/YoA1LJWf7XtIf+km2n8i7LwbuAiaQWjVftv1k3aUNs3bn66bmASGH9HHrz5Oer90laSJwQINzIjN4CCHUlJgZ3Paltlewvbzt7+Z938gj0LE90fZGtle3vYbttv8mDtsUAtur1m0bODy/ivsfAVbJ7xtm7bb9JjMnHb0uHzuT6Vm5nyE99+qrXJEZPIQQarp8xZNemSfXtRSZwUMInSzWrgztiMzgIYSOFklTQwgh9KzorgwhhNCzorsyDKWFlphcSdyqsncDXHJH22usNnTbaof1f9Ig3PD3+pWGyvNVVZMZfL65qhko/dCkt1USF+DkuarJhr3f6/NUEnfOkf2fM1h7vNrBf4qjkgshhNCz2pumNuyikgshhNBctORCCCH0rBhdGUIIoWd1eUuu4zODl0XSAZL2ye/HSFqij3MbZvsuuxx1+/vNgB5CCEPObv3VgWaZlpztXxQ2xwD30CDrrKSRrWT7LqkcIYTQ2aIl13kk7ZMXYZ4g6Zy8r5aBfBdSotXzcnbuuSU9Ium4vLDyrnXZvteVdHOOdauk+eruNa+kq3MW8bsl7dBKOfL7tfOxCcDnCCGETlPiAs3DoedacpLeCxwFbGj7mfqUOLYvknQQKZP4+HwNwLO218rbW+evc5DSAu1me5yk+YH6yT2vATvZflHSIsAtOfv3yn2VIzsDOMj2DZKOL+cnEEIIJeryFU96sSX3AeDCnHGgUQbvZholb12RlFtuXI71Ys6JVCTg/yTdBVwFLAks1l85JC0ILGj7hrzrnGYFK2YGP+fxmXpYQwihMp4yteVXJ+q5llwbXun/lIb2BBYF1rb9pqRHSNlsS1PMDP7UZpt15tPdEEJvipZcx7mG9Fzt7dAwgze0nkn8AWBxSevmWPNJqv9gsADwdK7gNgeWaaUctp8Hnpe0cd61ZwvlCSGEoTXNrb86UM9Vcjnr+HeB6/OAjh81OO1M4Be1gSd9xHqDlGT1xBzrSmZupZ1HyjZ+N7APcP8AyrEfcHLONK6Wv8kQQhgqJQ48kbS1pAckPSTpyCbnfEzSREn3Svp1u8Xvye5K22cBZ9Xt+1bh/e+A3xUOj6o7d0zh/Thg/T7u9QywwSDLcRuweuHwl5vdJ4QQhkVJoyYljQROBrYEHgPGSRpre2LhnNHAV4CNbD8n6R3t3rcnK7kQQgglmVragJL1gIdsPwwg6TfADsDEwjmfBk62/RyA7afbvWnPdVeGEEIo0QCeyRVHgufX/oVISwKPFrYfy/uKVgBWkHSTpFtq07naES25EEIIzQ1gdGVxJPggzQaMBjYD3gXcIGnVPFBvUKIlF0IIobnyRldOApYqbL8r7yt6DBhr+03b/wL+Qar0Bi1acl3mjH+9q5K4q4ysLp1GVRm8177rB5XEPXbtr1cSF+Dg9Vtdm2BgZluylRkxA7fcgtX9iTj39NkriXtjqbNUp7tnWjW/O4CdGs506gwub7muccBoScuSKrePA3vUnfMHYHfgjLyC1ArAw+3cNCq5EEIIzZU0/832lLyk4uXASOB02/dKOgYYb3tsPraVpInAVOBw28+2c9+o5EIIITRX3uhKbF8KXFq37xuF9wYOza9SRCUXQgihuQ7NLtCqqORCCCE016HLdbUqKrkQQgjNxQLNw0PSaZJWbrB/jKST2oj7cnslCyGEHtLlCzR3REtOKWup7NY/Mtj+VIVFGlaSRtruzORMIYRZSqfmiWvVsLXkJI3Kq1GfDdwDLCXpcEnjJN0l6eh83jySLpE0QdI9knbL+6+TtE5+v5+kf0i6FdiocI8zJe1S2H45f51X0tWSbpd0t6Qd+ilrszI8kudyIGkdSdfl94tKujKvon2apH8XzvuDpNvysf0L93hZ0g9zxoKGCz6HEMKQi5ZcW0YD+9q+RdJWeXs9UtqZsZI2JSUkfdz2hwEkLVAMIGlx4GhgbeAF4Frgjn7u+xqwk+0Xc+VzS14Nu9lvaeu+ytDAN4FrbH8vr732ycKxT9j+X07xM07S7/I8kHmAv9v+Un2wXBnuD7DTwuux3rxtLQAQQgiti2dybfm37Vvy+63y6w7gdmAlUqV3N7ClpOMkbWL7hboY7wOus/3fnP/tghbuK+D/JN0FXEVaJHSxPs7vrwz1NgZ+A2D7MuC5wrHP59baLaQlbmo11lRmTP/zFtun2F7H9jpRwYUQhlS05NrySuG9gO/Z/mX9SZLWArYFviPpatvHtBh/CrkilzQCmCPv35PUQlw7Z/R+hJmTob7F9j+alOGt+H1dX/g+NgO2ADawPTl3b9auey2ew4UQOo07tPJq1XC35IouBz4haV4ASUtKeoekJYDJts8FjgfWqrvu78D7Jb1d0uzAroVjj5C6MQG2B2qL5S0APJ0ruM2BZfoqWB9lKMb/aOGSm4CP5Wu3AhYq3Pe5XMGtRB/JWEMIoSNES64ctq+Q9B7gb2mwJS8DewHvBo6XNA14Eziw7ronJH0L+BvwPHBn4fCpwB9z9+BlTG85ngf8SdLdwHjg/n6Kt2qTMhwN/ErSt4HrCucfDZwvae9crieBl3IZDpB0H/AAqcsyhBA6V5ePrhy2Ss72I8AqdftOAE6oO/WfpFZe/fWbFd6fAZzR4JynmLG1dETe/wxNRjDanrfBvsublOFG0irZ9V4APpQXJN0AWNf26/nYNq3eN4QQhl2HttBa1TEtuR6zNPDb/BzwDVJK9xBC6DrNB513h6jkKmD7QWDN4S5HCCG0LVpyIYQQelZUcmEo7b3E45XEnfsd1T1cvuHvS1YSt6oM3kfe9u1K4gIcsc5XK4n7X79RSdyfrPJYJXEBdnytmn8Xm25Szf8jh49bpJK4ABNHTKksdru6fQpBVHIhhBCam9LdlVwnzZMLIYTQYTzNLb/6I2nrvGbxQ5KO7OO8j0pybX3idkRLLoQQQnMldVdKGgmcDGwJPEZau3es7Yl1580HfIG00EfboiUXQgihuWkDePVtPeAh2w/ndYZ/AzTKAPNt4DjSQvpti0ouhBBCUwPprpS0v6Txhdf+hVBLAo8Wth/L+96S1wheyvYlZZV/lqzk6vPMFfaPknTPAGMtIemiJseuK6NPOYQQhounuPVXIWNKfp3S6n3y4hk/AmZKN9aOeCbXBkmz2X4cmKnCDCGEnlBeOrlJpPRiNe/K+2rmIy31eF1ev/idpLyi29seP9ibzhItOUn75GzjEySdk3dvKulmSQ83adXNJemMnDn8jpytAEljJI2VdA1wdbH1J2luSb+RdJ+ki4G5C/G2kvS3nI38wkK2hWMlTczl+0HlP4wQQhgAT2v91Y9xwGhJy0qaA/g4MPat+9gv2F7E9ijbo0gL2LdVwcEs0JKT9F7gKGBD289IWpjUJF6clNx0JdIPur7L8XOAba+a0+JcIam2GPNawGo5w/eowjUHklLyvEfSaqTkr+Ts40cBW9h+RdIRwKGSTgZ2AlaybUkLNvke3soMfuyyK7LXYku08yMJIYTWldSSywvWH0Ra7H4kcLrteyUdA4y3PbbvCIPT85Uc8AHgwpx5gFwxAfzB9jRgoqRGWcE3Bk7M19wv6d9Mzzhwpe3/NbhmU+Cn+Zq7cuZxSJkQVgZuyveeg5SC5wXSCKJfSfoz8OdG30Du1z4FYNIGH+jumZkhhK7SQgut9Vj2pcCldfu+0eTczcq456xQyTXzeuG9BnjtK/2fMgORKsbdZzogrQd8kPRc7yBSpRxCCJ2hxEpuOMwKz+SuAXaV9HaA3F3ZihuBPfM1K5DS5zzQzzU3AHvka1YBVsv7bwE2kvTufGweSSvk53IL5E83hwCrt/xdhRDCEJg2pfVXJ+r5llzu8/0ucL2kqcAdLV76M+DnOXv4FGCM7ddzd2MzPwfOyJm/7wNuy2X4r6QxpGzhc+ZzjyJlC/+jpLlIrb1DB/bdhRBCtcrsrhwOPV/JAdg+Czirj+Pz5q+PkLOV234N2K/BuWcCZxa2i9e8Shox1Oge1wDrNji0XivfQwghDAsP9GlOZ5klKrkQQgiDEy25EEIIPcvToiUXQgihR0VLLgypIx9fsJK4z016vf+TBumrqib2wes3mqrYvqqydwMcN/7/Kok75bpfVxL3koPvqyQuwD1z9n/OYNw4bvFK4rY6LHswNillvf1qTJsaLbkQQgg9KrorQwgh9Cx3+RpLUcmFEEJoKlpyIYQQelZUciGEEHpWtw88GdDalZI+n3OlnVdVgVosx7ckHZbfryTpzpzzbfmS4j+S0+Mg6eZBxjhA0j4N9g84+3gIIQwXWy2/OtFAW3KfJeVEe6y4M2fIHq7lOXcELrL9nVYvGEh5bW84mELZ/sVgrgshhE7S7fPkWm7JSfoFsBzwF0mH5NbUOZJuAs6RtKik30kal18b5evmkXS6pFtza2uHBrEXl3RDbpHdI2mTvP/lwjm7SDqz7rptgS8CB0q6tr6VJOkwSd/K76+T9BNJ44Ev1MV5u6QrJN0r6TQKqXdqZVByfC7f3ZJ2y/tPkPSN/P5D+fsYUdfaXFspK/kEUjLWWuyROea4nBn8M63+PkIIYShMs1p+daKWKznbBwCPA5vb/nHevTKpZbc7cALwY9vrAh8FTsvnfA24xvZ6wObA8ZLmqQu/B3C57TVI6WbubLFMlwK/yPfdvIVL5rC9ju0f1u3/JvBX2+8FLial1am3M1Ar3xb5+1gc+Aqwm6TNSQlT98vJWIvOAA62XZ9K55PAC/lnti7waUnL1t9Y0v6Sxksa/+DL/2rh2wwhhHKU2V0paWtJD0h6SNKRDY4fKmli/tB/taRl2i1/u/nkxuaV9yH94T9J0p3AWGD+nC9tK+DIvP86YC5mrkTGAfvlVteqtl9qs1zNXNBk/6bAuQC2LwGea3DOxsD5tqfafgq4HljX9mTg08CVwEm2/1m8SNKCwIK2b8i7zikc3grYJ/9s/g68HRhdf2Pbp+TKeZ3R885UB4YQQmU8TS2/+iJpJHAysA2pgbS7pJXrTrsDWMf2asBFwPfbLX+7oyuLGbJHAOvnFDVvUUrA9lHbTROO2r5B0qbAh4EzJf3I9tlAcRriXC2UZwozVtz11ww0o3erVgWeBZYY4HUitfAuL79IIYTQvhJHV64HPGT7YQBJvwF2ACbWTrB9beH8W4C92r1pmZnBrwAOrm1IWiO/vRw4OFd2SFqz/sLcJH3K9qmkbs618qGnJL1H0ghgpxbK8BTwjvyMbU5guxbLXszovQ2wUINzbiR1S46UtCip9XdrLvuXgDWBbSS9r3iR7eeB5yVtnHftWTh8Oel54uz53is06MoNIYRhU+IzuSWBRwvbj+V9zXwS+EubxS91ntzngZMl3ZXj3gAcAHwb+AlwV66s/sXMlc9mwOGS3gReBmpD748E/gz8FxgPzNtXAWy/KekY4FZgEnB/i2U/mpS1+17gZuA/Dc65GNgAmEBqYX6ZVKleCRxm+3FJnyS1ROuTo+4HnC7JpA8DNacBo4Db84eA/5JGi4YQQkcYyNQASfsD+xd2nWL7lIHeU9JewDrA+wd67Uyx3O0Lk81i9l5m50p+Yc+5wiwEb7bS0zxwK29aTRaCY/6+WCVxIbIQFN0zRzVxX1Y1Y97L7PaqV1UWgo88eX7bfY13jfpIy39zVnvkT03vJ2kD4Fu2P5S3vwJg+3t1520BnAi83/bTgyp0Qax4EkIIoakSpwaMA0bnEeSTgI+THxPV5MdZvwS2LqOCg6jkQggh9KGslUxsT5F0EGkswkjgdNv35kdM422PBY4nPZa6MA/j+I/t7du5b1RyIYQQmppa4gLNeW7zpXX7vlF4v0VpN8uikusyr1DN6mkvTq0uNfF8c1XzNGO2JeerJO5//UYlcaG6Z2ezbbZH/ycNwggfVUlcgKdUzb/lyUytJG6Vz+Qen23uCqO3p1PXpGxVVHIhhBCa6tTluloVlVwIIYSmun38fVRyIYQQmoqWXAghhJ41NSq5EEIIvcp0dyXX54AhSQtK+mx/QXIet36Hd9XnexssRWbwEEIYEtPc+qsT9TcqdkFSNvD+jKJu5voQ2pGUGXzN+jQ3zUhquQXbTmbwnEkhhBC61jTU8qsT9VfJHQssn1tKxzfLjp3P2ySfd0hurdwo6fb86rOiUGQGj8zgIYSOZNTyqxP116I5ElglZ+xG0keZnh17EWCcpBvyeYfZ3i6f9zZgS9uvSRoNnE9aUbqZWmbw7yol1ntbK4W3famkXwAv2/6BpFH9XDKH7UblqGUGP0bSh0kpHuoVM4MXv/ev5Pc3kjKDb2t7Wl6SpuYM4KCcN+/4wv63MoPn1EA3SbrC9gzpv4sre6+x8GosO2/byXJDCKEl1Sx3PXQGOom/YXbsBufNDpwq6W7gQlIW2L5EZvAWM4NHBRdCGEpTUcuvTlTV6MpDSLnWVidVpH2uGRWZwSMzeAihM/V6S+4loLhAYMPs2A3OWwB4wvY0YG/SitNNKTKDR2bwEEJH6ulncraflXRTHszxF1I27BmyY9t+UtKzwNQ8sOJM4GfA7/IQ+svovwW1GZEZPDKDhxA6TolJCIZFZAbvMjsvs30lv7BnplTVkwsnz9HSOKIBW3anav7vO/B31a2RcMoP1+r/pEGoKgvBn1apLgvBlXNFFoKa9adUk4XgM4+d2/b/JH985x4t/83Z4clfd1yVGCuehBBCaKqajwxDJyq5EEIITU1TxzXOBqTKFngIIYQu5wG8+iNpa0kPSHpI0pENjs8p6YJ8/O8tzH3uV7TkusyZW79eSdznxlX3ae2hSdU8k1tuwWr++f5klccqiQtwycH3VRK3qgzeH7nnO5XEBXhz1a9XEne9dzSa5tq+0fdNrCQuwOTFG003bl8ZSyiVNYUgL/RxMrAl8BhpEY2xtos/2E8Cz9l+t6SPA8cBu80crXXRkgshhNDUNLX+6sd6wEO2H7b9BvAbYIe6c3YAzsrvLwI+KLXXXxqVXAghhKYGskCzpP0ljS+89i+EWhJ4tLD9WN5Ho3NsTwFeIK0ENWjRXRlCCKGpqQNoR9k+BTilssIMQrTkQgghNDVtAK9+TAKWKmy/K+9reI5SSrQFSEsmDlpUciGEEJoqcXTlOGC0pGUlzQF8HBhbd85YYN/8fhfgGre5YklUcg0Uc8GVFO9SpSzrLWVaDyGETlHWwJP8jO0g0pq99wG/tX2vpGMkbZ9P+xXwdkkPAYeSlnZsSzyTGwK2twXIcz4+S1rbM4QQOl6ZWQhsXwpcWrfvG4X3rwG7lnjLaMnVSPqapH9I+iuwYt63vKTLJN2mlOl8pbz/TEk/lXSzpIcl7ZL3N8tw/oikRZg50/rZknYslOE8SfVDakMIYdiU+ExuWEQlB0ham9Q/vAawLdMTwZ5Cyve2NnAYM7bAFiclUt2OVHnB9Azna5By6d1Zd6sjgX/aXsP24aSm+ZhchgWADYFLGpTvrWG5Z9xX3UTlEEKoN1WtvzpRdFcmmwAX5yzfSBpLSri6IXBhYS7inIVr/pDz5U2UtFjeN46UUmf2fPzOvm5q+3pJP8v56T4K/C73W9ef99aw3Bc/86FIGxFCGDKd2kJrVbTkmhsBPJ9bXbXXewrHi+trCVKGc1Iy1UmkvHL70L+zgb3IOefKKXoIIZSjzLUrh0NUcskNwI6S5pY0H/ARYDLwL0m7AihZva8gfWQ4r6nPoA4pyewXAerWcAshhGFX4rJewyIqOcD27cAFpKzffyF1OwLsCXwyZzy/l5nXWau3GTBB0h2kRUVPqLvPs8BNeVDK8XnfU6ThtGeU892EEEJ5un3gSTyTy2x/F/hug0NbNzh3TN32vPnrWUxfXLR4fFTh/QwpnCW9DRgNnD+IYocQQqW6PWlqtOSGkaQtSK24E22/MNzlCSGEet3eXRktuWFk+ypgmeEuRwghNNOp3ZCtikouhBBCU506arJVUcl1mUMvrx+cWY6vLVBdb+nJc71aSdxzT5+9krg7vlaf4qo898zZ/zmD8ZRmml5ZiqqydwPsfPe3K4l7/7pfqCTutQtvUElcgCffqOgfRgmmdXk1F5VcCCGEpqK7MoQQQs/q9tGVUcmFEEJoqlNHTbYqKrkQQghNxTO5EEIIPau7q7iYDD5sJF0naZ3C9ihJ9wxnmUIIoV63L+sVlVwIIYSmpuGWX+2QtLCkKyU9mL8u1OCcNST9TdK9ku6StFt/caOSq1huod2fs37fJ+mivF5lCCF0vKkDeLXpSOBq26OBq/N2vcnAPrbfS1pX+CeSFuwraDyTGxorAp+0fZOk04HP5v3nSarNlJ6Dzm3xhxBmUUM48GQHUiYXSAvdXwccUTzB9j8K7x+X9DSwKPB8s6DRkhsaj9q+Kb8/F9g4v9+zlpAV2LbZxZL2lzRe0vj7X3q44qKGEMJ0A0maWvxblV/7D+BWi9l+Ir9/Elisr5MlrUdqHPyzr/OiJTc06j8KDeijke1TgFMAPjVql24f7BRC6CID6V4q/q1qRNJVwDsbHPpaXRxLavq3TtLiwDnAvrb7LGJUckNjaUkb2P4bsAfwV1L28RBC6GgusbvS9hbNjkl6StLitp/IldjTTc6bH7gE+JrtW/q7Z3RXDo0HgM9Jug9YCPj5MJcnhBBaMgW3/GrTWGDf/H5f4I/1J0iaA7gYONv2Ra0EjZbc0Jhie6+6fZsVN2w/AqwyVAUKIYRWDOHzkWOB30r6JPBv4GMAeT7xAbY/lfdtCrxd0ph83RjbdzYLGpVcCCGEpoZqdKXtZ4EPNtg/HvhUfn8uafBey6KSq1i00EII3azb5zVFJRdCCKGpMgeeDIeo5EIIITQVLbkwpI5e/H+VxH35uTkriQuw3+vzVBL3xrkqCcummzxeTWDgxnGLVxJ3ckWpLdd7x3OVxAW4f90vVBJ3pXEnVBL3gtW+UUlcgHmndW5VMjVaciGEEHrVNEclF0IIoUd1dxUXlVwIIYQ+RGbwEEIIPavbR1fO8st6SRoj6aR2z2lwzRcjb1wIodtFZvDQzBeBqORCCF1tKtNafnWinqzkJM0j6RJJEyTdI2k3SY9IWiQfX0fSdQ2uO1PSL3IepH9I2q5weAlJl+XU7N8vXPPzfP69ko7O+z4PLAFcK+navG+rnLb9dkkXSpo37z9W0sScyv0H1f1UQghh4Lq9Jderz+S2Bh63/WEASQsAx7V47ShgPWB5UiX17rx/DWBN4HXgAUkn2n6UlO7hf5JGAldLWs32TyUdCmxu+5lcuR4FbGH7FUlHAIdKOhnYCVgp509asITvPYQQSuMun0LQky054G5gS0nHSdrE9gsDuPa3tqfZfhB4GFgp77/a9gu2XwMmAsvk/R+TdDtwB/BeYOUGMdfP+2+SdCcpjcQywAvAa8CvJO0MTG5UoGK23XOfqm6icggh1JuGW351op5sydn+h6S1gG2B70i6GpjC9Eq9r7UymmXxfr2wbyowm6RlgcOAdW0/J+nMJrEFXGl795kOpBTuHwR2AQ4CPtDg+3kr2+6kDT7Qmf+SQgg9qVO7IVvVky05SUsAk3NahuOBtYBHgLXzKR/t4/JdJY2QtDywHCnhaTPzA68AL0haDNimcOwlYL78/hZgo1rXZ35muEJ+LreA7UuBQ4DVB/BthhBC5bp94ElPtuSAVYHjJU0D3gQOBOYmdQt+G7iuj2v/A9xKqsAOsP2apIYn2p4g6Q7gfuBR4KbC4VOAyyQ9bnvznODvfEm1RSKPIlWEf5Q0F6m1d+hgvtkQQqhKtz+T68lKzvblwOUNDq3Q4NwzgTMLu66yfUBf59jervB+TJMynAicWNi+Bli3wanrNbo+hBA6QWe2z1rXk92VIYQQyuEB/NcOSQtLujJP07pS0kJ9nDu/pMdaWaQjKrkC22NsXzTc5QghhE4xhKMrjySNYh8NXJ23m/k2cEMrQaOSCyGE0JTtll9t2gE4K78/C9ix0UmS1gYWA65oJWhUciGEEJoayOjK4pze/Np/ALdazPYT+f2TpIpsBpJGAD8kTd1qSU8OPOll509aopK4C1T4dHnOkdXEvWdaNVnSDx+3SCVxARauKG5Vn1ZH3zexoshw7cIbVBK3qgzeu911TCVxAV494jOVxW7XQJKmFuf0NiLpKuCdDQ59rS6OJTW68WeBS20/1mzUe72o5EIIITRV5gQC21s0OybpKUmL235C0uLA0w1O2wDYRNJngXmBOSS9bLvp87uo5EIIITQ1hMt1jSUteXhs/vrH+hNs71l7n+cer9NXBQfxTC6EEEIfhnB05bGkNYcfBLbI27WsMacNNmi05EIIITQ11UMzHdz2s6R1fOv3jwc+1WD/mcy4kEdD0ZLrRzEP3QCvO1PSLgM4f5SkewZ6nxBCqNJQTQavSrTkQgghNNXta1dGS65A0h8k3ZazfM80v0PSPjmD9wRJ5+R9oyRdk/dfLWnpwiWbSrpZ0sO1Vp2S43PG8rsl7TZE314IIQxY5JPrLZ/IWb7nBsZJ+l3tgKT3kjIHbJizfdemPJ0InGX7LEmfAH7K9Jn6iwMbkxKvjgUuAnYmZRlfHVgk36el5WlCCGGoRUuut3xe0gRS/relgNGFYx8ALrT9DIDt2kzkDYBf5/fnkCq1mj/kLOMTmT57f2PgfNtTbT8FXE/j7ARvKa4icMvLD7bx7YUQwsB0e0suKrlM0makYasb2F4duIO+M4i3ophNvLXp+Q3YPsX2OrbXWX/e0f1fEEIIJZnqaS2/OlFUctMtADxne7KklYD1645fQ8oa/nZIaSHy/puBj+f3ewI39nOfG4HdJI2UtCiwKSlJawghdJwYXdk7LgMOkHQf8ACpy/Ittu+V9F3geklTSS29McDBwBmSDgf+C+zXz30uJnVxTiCtmPNl209KGlXi9xJCCKUYyNqVnSgqucz268A2DQ6NKpxzFtNTQdT2/Zv0vK4+3pi67XnzVwOH51fx+CPAKoMpewghVKVTW2itikouhBBCU9GSCyGE0LOiJRdCCKFndeqoyVZFJRdCCKEpRyUXhtLsFcW9ebZXK4oMe7xazT+znVRNnu2JI6ZUEhdgk9eqifv4bHNXEnfy4n2uU9CWJ9+Ys5K4806r5o9yldm75z7ul5XFblenTvJuVVRyIYQQmur2Zb2ikgshhNBUt7fkYsWTEEIITU2dNq3lVzskLSzpSkkP5q8LNTlvaUlXSLpP0sT+FtKISi6EEEJTQ7is15HA1bZHA1fn7UbOBo63/R5gPeDpvoJGJRdCCKEp2y2/2rQD01eUOovpKcveImllYDbbV+ayvWx7cl9Bo5KrQE6kek9+v46kn+b3m0nacHhLF0IIrRvCVDuL2X4iv3+S6enJilYAnpf0e0l35ATUI/sKGgNPKmZ7PDA+b24GvEzKXBBCCB1vIC00SfsD+xd2nWL7lMLxq4B3Nrj0a3X3tKRGN54N2ARYE/gPcAFpofxfNStTVHJ1JH0N2JfUz/socBuwHXCY7fGSFgHG2x6VH3ieA8yTLz/I9s118TYDDgMOAg4Apkrai5S94GxgBdtvSpqflJlgBdtvVvtdhhBCawaydmWu0E7p4/gWzY5JekrS4rafkLQ4jZ+1PQbcafvhfM0fSGnRmlZy0V1ZIGltUm64NYBt6SdjN+mXsKXttYDdgJ82OzFnGfgF8GPba9i+EbgO+HA+5ePA7xtVcMXM4DdHZvAQwhAawqSpY0kNDPLXPzY4ZxywYM7FCSkDzMS+gkYlN6NNgIttT7b9IumH3pfZgVMl3Q1cCKw8wPudxvT8c/sBZzQ6qZgZfMPIDB5CGEJDOPDkWGBLSQ8CW+Tt2riG03JZppJ6xq7Of3cFnNpX0OiubM0Upn8gmKuw/xDgKWD1fHxAizbZvikPUtkMGGn7nvaLGkII5RmqVDu2nwU+2GD/eOBThe0rgdVajRstuRndAOwoaW5J8wEfyfsfAdbO73cpnL8A8ITTCqZ7A32O8gFeAuar23c28GuatOJCCGE4DeE8uUpEJVdg+3bSaJ0JwF9I/b8APwAOlHQHsEjhkp8B+0qaAKwEvNLPLf4E7CTpTkmb5H3nAQsB55fzXYQQQnmm2S2/OlF0V9ax/V3guwCSvpX33c+MzeOj8v4H6/Yfkfc/AqyS319HGmCC7X8wczN7Y+Ai28+X+G2EEEIpYoHmMGiSTgS2IY3kDCGEjjMt8sn1Ltvfqjj+wVXGDyGEdkVLLoQQQs/q7iqOgc2BiFd3vYD9uy12t8XtxjJ3W9xuLHM3/ix69RWjK3vb/v2f0nGxuy1ulbEjbvWxuy1u1bF7TlRyIYQQelZUciGEEHpWVHK9relq4B0cu9viVhk74lYfu9viVh275yg/yAwhhBB6TrTkQggh9Kyo5EIIIfSsqORCz5E0QtKGw12OEMLwi0quh0i6TdLnJC3U6bEl3S3prmavdmI7pT46uYxyDjVJy0jaIr+vpXzq5LgfkRR/Ryokqb8UXqEP8Y+zt+wGLAGMk/QbSR+SpA6NvR0pX99l+bVnfl2aX+26WtJHS/z+3yLp+5LmlzS7pKsl/VfSXiXE/TRwEfDLvOtdwB86NW62G/Bg/pmsVEbAPj4A3d3uB6Acv9TfX9XlJf18j5e0cgmxZjkxurIH5U/W2wE/B6aSErKeYPt/nRZb0h2216zbd7vttdos50vAPKSs7q8BAmx7/nbi5th32l5D0k6kn8WhwA22V283LrAe8Pfaz0TS3bZX7cS4hfjzA7sD+5GWOjwDON/2S4OMt0ztLXAJdVk6bP978KUt//dXKG9DJZR3PuDjpJ/vCOB04De2X2wn7qwiWnI9RtJqwA+B44HfAbsCLwLXdGhsSdqosLEhJfy7tD2f7RG257A9f95uu4LLagubfxi40PYLJcV93fYbtQ1Js1HO+rhVxQUg/7G9CPgNsDiwE3C7pEFl2bD97/x6hFT2fxdfJRS51N9fXdleA1bNr1fLKK/tl2yfantDUs7KbwJPSDpL0rvbjd/rIgtBD5F0G/A88CvgSNuv50N/L1YkHRb7k8DpkhYgfXJ/DvhEO2Wtyc8PRwNz1fbZvqGE0H+WdD/wKilj/KKkP27tul7SV4G5JW0JfJaUTb5T4yJpB2AM8G7gbGA9209LehswETixjPuUrJLfn6SPkT4AXkf6t3yipMNtX9Rm3JGkCnk/YBTpg+Z5wCakrv0V2onf66K7sodIWs72w3X7lrX9r06OnWMtAFBWq0jSp4AvkJ4/3QmsD/zN9gdKir8w8ILtqZLmAeaz/WSbMUeQKv2tSH8kLwdOc5v/k1YVN8c+C/hVow8Pkj5o++pBxCx2VZ9Helb7Ftu3D7igM9+jit/fBGBL20/n7UWBq0roxn4YuJb0c7657thPbX++nfi9Liq5HtLoWZak22yv3WmxJe1l+1xJhzY6bvtHg4lbiH83sC5wS37+shLwf7Z3bidujv020nOcpW3vL2k0sKLtP7cbu9tIOs72Ef3tG2DMa+t21f5I1Z6rtvVBparfX/1zzvzhYkIJz1Q3tv3Xun0b2b6pnbiziuiu7AH5D/h7gQUkFf+Iz0+hq67DYs+Tv5YylL2B12y/JglJc9q+X9KKJcU+A7gNqM3FmwRcCAzqj2SukJt+2rS9WifFrbMl6TlR0TYN9rXM9uaQpjqQulY3Jn0fN5IGPLWr1N9fwWWSLgfOz9u7Uc5I4Z8C9QOxTmywLzQQlVxvWJE0SmxB0rD8mpeAT3dibNu/zF+PbqdwfXhM0oKkofJXSnoOKGPQAsDytneTtDuA7clS29MpAD6Xv56Tv+5FewNEqoqLpANJFdDydcPk5wPKamGcRRrY9NO8vQfpud/H2oxb9u+PHOdwSR8Fas+oT7F98WDjSdqAVBEvWtfjMT8Qc+daFN2VPUTSBrb/1k2x8zOdL9h+Pm8vBPzQdimDT3LM9wMLAJcVRxm2Ee9m4IPATbbXkrQ8acj8em3GrWo6Relx8zPUhYDvAUcWDr1UxlSVfI+Jtlfub98g4lby+ytb/ne7GXAA8IvCoZeAP9l+cDjK1W2iJdcDJH3Z9veBPWqfTovaeTBdZexstVoFl+M9J2nNPs5vSR5YUHN3LXy7cbNvkiawLyXpPNIn9zElxFXxWUtZ0ykqimvbj0j6XP0BSQuXVNHdLml927fkuO8DxpcQ91vM/Pvbr92guTv/OOAdpOeHbc3NtH09aWTsmSVNnZglRSXXG+7LX8v4AzCUsQFGSFrI9nPwVuVUxr/L24GlSFMSROpufVLSU8Cnbd822MC2r5R0O2nEpkgt0WfaL3Jl0ymqiPtrUnfobaQPD8XuPgPLtRkfYG3gZkn/ydtLAw/UnjUO9pmi7SvylJiyf3/fBz5i+75+z2yBpJ/Y/iJwkqSZPqDZ3r6M+/S66K4Mw0rSPsBXSQ/+BewCfNf2OX1e2H/cU4GLbF+et7cCPsr0FVreN4iYfXbvlTG0Pd+n1OkUVcetiipaSUTS1bY/2N++QcS9yXZb81Hr4q1t+7bcbTmT3NIL/YhKrgdI+hN9j6Ib9Ce+KmMX7vFeYPO8eY3tiSXEnGnZKkl32V5NeVmnQcSsDW2fC1gHmECqmFcDxtveYJBlrWQ6RdXTNPI9NgLutP2K0vqPawE/sf2ffi4dcpLmAt5GmnO2GdNbn/OTntcOau3Nwqjj9wPvJA12qi2WgO3fD67EoQzRXdkbfpC/7kz6n+zcvL078FQHxwbA9r2S/kuekiBp6RL+SD4h6QjSUlOQhnM/pbR6xLRBlrM2tP33wFq2787bq5Ce8wxWVdMpqp6mAWlI/+qSVge+BJxGGsXZsPUxzD4DfJG00PhtTK/kXgROaiNucdTxZNKk+xoDg6rkhmgKSM+LllwPkTTe9jr97euk2JK2Jy1TtATwNLAMcJ/t97YZdxHSAJGN866bgKOBF0iTgB9qI/a99eVrtK8MkuYoY0RoVXFrozQlfQOYZPtXZYwIrZKkg2134nJjM6iqu3ZWEy253jKPCstvSVqW6Z/mOzX2t0kDAK6yvaakzUnzuNqSBxI0WyB40BVcdpek05jeqt0TKCMFzHXAGKeFiZG0Lqll1O6yUJXEzV6S9BXS72xTpVU+Zi8hbmVsn5hb3ysz47qmZ7cTV9K7SJO0a8/lbiQNanlskOWMSqwEUcn1lkOA65TWuhOpVfSZDo/9pu1nlbJ5j7B9raSftBs0Pz9rNCKtjLUr9wMOJK2NCXAD5azE8T3Sqhk/BZYkrRzS9tD2CuNC6gbeA/ik7SclLU1apLhjSfom6ZncyqQVSbYB/kqaaN6OM0ijTnfN23vlfVu2E1TS+qTK8z3AHKSJ4K8MdmrCrCa6K3uMpDmB2gP0+z09W0BHxpZ0FbAj6Q/xIqQuy3Wd0oq0E7e4puZcpJGVU2x/uZ24VZO0GXAl8AywpttcNLjquN0oP+taHbjD9uqSFgPOtd1uZTTTgKbBDnKqizGelE/uQtKAp32AFWx/pZ24s4poyfUASR+wfY1mXFsS0pJLbY3uqjJ2tgMp5ckhpG6/BYBj2oxJg3lwN0m6tZ2Ykn5r+2PNBgS0OxBA0tdJS1ZtShqxeZ2kL9m+pBPj5tilToAeIq/aniZpilLC16dJcyrb9WweYVpbu3J34NkS4mL7IUkjbU8FzpB0BxCVXAuikusN7yclLv1Ig2ODHt01BLGx/Up+O420VmEpNOOKJyNIE4sXaDNsrXtyuz7PGry3k/KxvQr8TdJlpGdn7VZGVcWFkidAD5HxSuuankoaZfkyUMaSdZ8gdSv+mPT/xs2U0y08WdIcwJ2Svg88QSS8bll0V4aeJOlfTF+JYwrwL+AY16UsGUTckaRBMpv3e/Lg4i9GShEEcKtzbrIOjlvqBOihJmkUML/ttgcOVSWPsnyaNKDnENKHtZ+1M0J4VhKfBnqIpP/Ln1Br2wtJ+k6nx66C7WVtL5e/jra9VbsVXI47FZhWWz2kTJJ2BW4lDVz4GCnr+i6dGjcbL+kCSbtL2rn2Kil2ZSQtqbSG59LAgpI2LSHmWQ3+Hzm93bi2/237Vdsv2j7a9qFRwbUuWnI9RBWtYl9lbKWszK/anpa3RwBz2Z7cZtxdSatYvCTpKNJKHN8pY+ktSX8E1iQN5Kh1t7a9WLWqyyxdSdwc64wGu+0Ss0iUTdJxpFGhE4GpebfbXb2nyf8jM+0bRNxar8QMbJexPmjPi2dyvWWkUoLQ1wGUkk7O2eGxrwa2ID0XgbTs0hVMT2g5WF+3faGkjXP840nD/Ae8ZmUDv6fNZ5FNjKjrRnyWcnpbqoqL7bKmIgylHUmZwEsbeZxVtdh4ccGFuUgt8oWbnBvqRCXXW84Dri58ut6P8gZzVBV7Ltu1Cg7bL0t6Wwlxa5/QP0xKXnlJWd2rts/KAwFWyLsesP1mCaGryixdVVwkrUD68LCY7VUkrQZsb7tju7KBh0nPt8qu5H5IGtgzw2Lj7Qa1XT9C8ydKWRS+0W7sWUF0V/YYSduQEkICXOm8Cn+nxpZ0E3BwrRsxz287yYNc7LgQ98/AJNJE3LVI0xRuLamLbjNSBf8I6Y/ZUsC+tm8oIXYxs/SNbiOz9BDFvR44HPhlrVtO0j22VykjfpkknUjq9luSNE/uamZcSLnd3IhIWhmoLThQ1mLjxUcCI0gtuwPL+Lc8K4hKLgwrpSWmfgM8Tqow3gns1mCe20Djvg3YGrjb9oOSFgdWtX1FCWW+DdjD9gN5ewVSZum1+76y90gaZ3vd4rOnMiZAV0HSvn0dtz2onom66SqN4raVQFYzrt4zhfTh6ge2/9FO3FlFdFf2EFW4/E9VsW2Pk7QSsGLeVUrXXx648vvC9hOk+UVlmL1WweXY/5A06PUaJf3V9saSXmLGAQZtTayuKm6dZyQtX4ufR22W9XMuVbESy93NK5HK/YDbW6y6PnFs7Wctykkg++cG8beT0qZLSJnUy6KS6y0n0WD5n06MreYrqaygclZSqdJ4zbxA86Azp9veOH8tNSVOVXHrfA44BVhJ0iTSfMQ9K7xf2yRtC/wS+Cep4lhW0mds/2Uw8WwvW4i9MDCawsLPJVibNMfxj6TyfoQ0JeTBEu/Rs6K7socop75RTg6a97U9hLmK2JKOtv3NLh2CPifpj3stjc+NpMm5gxrIUFV3V5XdaJo5EevcpOdFr+TYHdu6kHQ/sF1trlluiV7iQSZNLcT9FGlVnHcBd5Kya9zs9jOO3wB82PZLeXu+XN625/bNCqIl11uqXP6n1Ni5ghsB/MX2b0sq45DIldmP8qsMxe6upYHn8vsFgf8Ayza9cnjiwvRErCsyYytjb1Iro5O9VDeZ+mHgpRLifoH0s7jF9ua5G/7/Soi7GFDsTn0j7wstiEqut+xNqngOIi3/sxRp9f2OjO20SO6XgdIquQbPn946RJvPoVRRpuZad5ekU4GLbV+at7chzekalKri5thH51g3kLKk11oZ36KcNTGrNF7SpaR/dybNOxtX6zpvo6v8NduvSSLPKb1f0or9X9avs4FbJdVGxO4InFlC3FlCdFeGYSXpWFL6lwuYcfWQtkakVUEVZ2qWdLftVfvb1ylxc5wHgNUKiwTMCdxlu4w/7pVo0kVeM+iu8lwJ7Qd8kTSN4DnSIKVtBxOvLvZawCZ58wbbd7Qbc1YRlVwYVnnJonoua8kiSe9gxuzP/ykjbhXyhO0bmXFAy6a2P9SJcXPsr5HWwyy2Mi6w/b12Y3czSe8nLaR8WZsjN0ObopILw0rSXLZf62/fIOJuT1qBYgnSCu7LAPfZfm87cXPsSnKo5YEi3yTlfTMp4/gxJcyzqiRuIX5XtDIKk8EbKmMyeOg8UcmFAZH0Nre5eHJdvJkWeW60bxBxJ5C6jK6yvaakzYG9bH+ynbg59kN0Xw61WV5Vk8FDZ4uBJz1A0p/o+xNqW6ur53tsSEq0OS+wtKTVgc/Y/uwg472TtLzS3JLWZPpE1/lJizS3603bz0oaIWmE7Wsl/aSEuABPRQXXfaISmzVFJdcbfpC/7kxaFqv27GV34KmS7vFj4EPAWADbE9ReDq4PAWNIc4qKQ/FfAr7aRtya5yXNS+qaO0/S0xQGtgxGYeL6eEkXAH9gxrUPO3kCe8jqlsl6i+0PNDg9dLnoruwhtQnb/e0bZOy/235f3RqFE9x+rrOP2v5du+VrEHce4DVSC3FP0iCA8zzziu4DiVkblVdcYqmmrQnsShnHP2/7x4ONMZRxu5nSIuA1c5Gmwkyx/eVhKlKoULTkess8kpaz/TCApGWBeUqK/WjusnRep/ELwKC77CTtZftcYFSD1TPaXjHDdrHVVko3lXPuNElnAV+w/XzeXog0yKWd2FMl7U5qMZemqrjdzDMv/n2TpE6fwB4GKSq53nIIcJ2kh0ktjWWAz5QU+wDgBNJztEmkxKafayNerfKdt81yNVQ3KXwOUv6wUharJs0Le762Yfu5/FyxXTdJOomZ5wy2m828qrhdqW65s1rqmgWGqTihYtFd2WPyZNzaGnz3D3Y9xV6itFz7DsD6to8sId4EYDPPmAH6+hImbV/bYLfbfVZUVdxuledm1rqc3ySlrjnG9l+Hs1yhGlHJ9RClHGqHAsvY/rSk0cCKtv/cRsxK5xY16/qrYoHmEher3oc0OObCvGtX4Lu2z2k3dqiepI+RJmm/KOnrpKS6355VW7a9Lrore8sZpEV5a1m1J5H+EA+6kqONFDItqqTrTzOm8Kl1SbU1wbzG9tmSxjM9A/TOLicD9Dea3O+YTozbxY6y/VtJG5N+hz8Afg68b3iLFaoQlVxvWd72bnmgAbYn5666QRuCuUUjJC1U1/VXxr/LjxTe17Ip71BCXABypdZ2xVanOFhmLmA72hjcMwRxu9XU/PXDwKm2L5H0neEsUKhOVHK95Q1JczM9S/PyFOZxDYakn9j+YrMJ5yVMNP8h8DdJM3T9tRnzrZGQ3cT2DCM0Jf0AuLxT43axSZJ+CWwJHJefY5eVkip0mHgm10MkbQV8DViZNPpxI2A/240GHrQac23bt+UFZ2di+/rBxi7cY2Wmd/1d007XXy+tT5ifT46z/e5uiNst8rPrrYG7bT8oaXFgVdtXDHPRQgWiJddDbF8h6TZSRmKRBnQ802bM2pyiNWyfUDwm6QtA25VcyV1/tWeIG5Eq+wvy9q4l3qMSmjFf3UhgUaDt52ZVxe1Wee3V3xe2nyAlAQ49KFpyPUTSOcBBtl/I28sAp9v+YAmxGy2kXMpoxSpIugXY2PaUvD07cKPt9Ye3ZDOTtKztf2nGfHVTSGtkTum0uCF0k2jJ9Za/An/PK4gsCRwOfKmdgHkQyx7AspLGFg7NB3RcYtOChUiLPdfKOG/e14kuAtampA8kQxA3hK4RlVwPsf1LSfcC15Kyba9p+8k2w95M6spZhBmXrnoJuKvN2FU6FrgjT4QWKZfat4a1RM2NkPRVYIWSlzirKm4IXSMquR4iaW/g68A+wGrApZL2sz1hsDFt/xv4N9Pn3nUF22dI+gvT5z4dUUKFX5WPkzJqz0ZqIXd63BC6RjyT6yGS/gDsb/vpvL0ecIrtNUqIvT5wIvAe0lqQIylvLcjSSFrJ9v1K2apn0smrWkjaxvZfuiVuCN0gKrkeJ2kO22+UEGc8qWVwIWn1kH2AFWx/pd3YZZJ0iu39u2m9xkZdiUWD7VasKm4I3SS6K3uApC/b/n4fc8RKmRtm+yFJI21PBc6QdAfQUZWc7f3z182HuywDUFVXYnRRhlleVHK9oTb/q8p1JidLmgO4U9L3SYNROnaVCEm7khbhfUnSUUxfhPeOYS7aTGwf3U1xQ+gmUcn1ht1IizAvWD9hu0R7k57DHUTKW7cUKaNyp/q67QvzIrxbAMcDv6CDF+HNmccbLZ3WVkaGquKG0A2ikusNa0taAviEpLNJQ+bfYrvt+Wx5lCXAq0A3tBCKi/Ce0iWL8BazRcwF7AQ83sFxQ+h4MfCkB0j6PHAgsBwpvU6xkrPt5dqIXVwSaia2Vxts7CpJ+jPpZ7ElqavyVeBW26sPa8EGQNII4K+2N+yGuCF0oqjkeoikn9s+sOSYy/R1vNDC6yi9sAivpBWBSypYoLmSuCF0ouiu7CFlV3A55luVmKTFgHXz5q21+XidKOfSexrYGHiQtGbjg8Nbqr5JeokZW81PAkd0atwQukG05EJLJH2MNHjjOlJ36CbA4bYvGs5yNSPpm6T5fCvaXiE/s7zQ9kbDXLQQwhDq2CHgoeN8DVjX9r629wHWIy0h1ql2ArYnZ8W2/TgdPm9M0kaS5snv95L0o/66i4czbgjdICq50KoRdd2Tz9LZ/37ecOqmqGVJn2eYy9OKn5PmI65Oyh7xT+DsDo4bQsfr5D9SobNcJulySWMkjQEuAS4d5jL15beSfgksKOnTwFXAqcNcpv5MyRXzDsBJtk+mnNZnVXFD6HjxTC60TNLOpIEckBKQXjyc5WlGkoB3ASsBW5GeIV5u+8phLVg/JF0PXAbsR0oN9DQwwfaqnRg3hG4QlVxoSV7s9wLbk4a7LK2QdHe3/RGX9E5Sgtpxtm+UtDSwme22uharihtCN4hKLrQkj1b8GCnT9gWkkYpPDW+pmpN0FqlrbtxwlyWEMHyikgsDImk10lqZHwUes73FMBepIUn3A+8mJXx9hdRl6U5doSWEUI2YDB4G6mnSZOJngXcMc1n68qHhLkAIYfhFSy60RNJnSd2Vi5ISp/7W9sS+rwoDJWluYGnbDwx3WULoBdGSC61aCvii7TuHuyC9StJHgB8AcwDLSloDOMb29oOM12xx7ei6DbOMaMmF0CEk3QZ8ALjO9pp536BHiXbr4tohlClaciF0jjdtv5Cm+b1l0J9CoxILIVY8CaGT3CtpD2CkpNGSTgRubjeopPUljZP0sqQ3JE2V9GL7xQ2h80UlF0LnOBh4L/A68GvgBeCLJcQ9CdidlGpobuBTwMklxA2h48UzuRA6jKS32Z5cYrzxtteRdFdtsImkO2rP/ULoZdGSC6FDSNpQ0kTg/ry9uqSflRB6sqQ5gDslfV/SIcT/+2EWEf/QQ+gcPyZNYn8WwPYE0oLK7dqb9P/6QaTVX5YCdi4hbggdLyq5EDqI7Ufrdk0tIeyOtl+z/aLto20fCmxXQtwQOl5UciF0jkclbQhY0uySDgPuKyHuvg32jSkhbggdL+bJhdA5DgBOAJYEJgFXAJ8bbDBJu5NS7CwraWzh0PykbBIh9Lyo5ELoAJJGAifY3rPEsDcDTwCLAD8s7H8JuKvE+4TQsWIKQQgdQtJfgQ/YfqOC2IsB6+bNW20/XfY9QuhEUcmF0CEknQ28BxhLGgUJgO0ftRl3V9LCz9eRFmfeBDjc9kXtxA2hG0R3ZQid45/5NQKYr8S4RwHr1lpvkhYFrgKikgs9Lyq5EIaZpHNs7w08b/uECm4xoq578lliZHWYRUQlF8LwW1vSEsAncpfljGkI7HZHQl4m6XLg/Ly9G/CXNmOG0BXimVwIw0zS54EDgeVIUweKlZxtL1fCPXYGNs6bN9q+uN2YIXSDqORC6BCSfm77wAriHmf7iP72hdCLopILocdJut32WnX73spIEEIvi2dyIfQoSQcCnwWWk1Sc/D0fcNPwlCqEoRUtuRB6lKQFgIWA7wFHFg69VMJglhC6QlRyIYQQelbMlQkhhNCzopILIYTQs6KSCyGE0LOikgshhNCz/h815zc4+LiKegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(wine_df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants = wine_df['alcohol'].quantile([0,0.25, 0.5,0.75,1.0]).to_numpy()\n",
    "res = []\n",
    "for q1, q2 in zip(quants[:-1],quants[1:]):\n",
    "    res.append(wine_df.loc[(wine_df['alcohol']>=q1) & (wine_df['alcohol']<q2)])\n",
    "    \n",
    "train_dfs = [q.sample(frac=0.8) for q in res]\n",
    "test_dfs = [q.drop(t.index) for q,t in zip(res,train_dfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_datamodel = Sequential([\n",
    "    layers.Dense(1024, activation='sigmoid', input_shape=(11,)),\n",
    "    layers.Dense(64, activation='sigmoid'),\n",
    "    layers.Dense(32, activation='sigmoid'),\n",
    "    layers.Dense(16, activation='sigmoid'),\n",
    "    layers.Dense(8, activation='sigmoid'),\n",
    "    layers.Dense(1, 'linear')\n",
    "])\n",
    "\n",
    "fp_datamodel.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(\n",
    "    ),\n",
    "#     metrics=[CWAcc1(n,name=f'cl{n}') for n in range(10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['quality'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-308-08a288ef1a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-308-08a288ef1a7e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4161\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4162\u001b[0m         \"\"\"\n\u001b[0;32m-> 4163\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4164\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4165\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3885\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3920\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3921\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5282\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5283\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['quality'] not found in axis\""
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "history = defaultdict(list)\n",
    "\n",
    "x = np.concatenate([train_dfs[i].drop('quality',axis=1).to_numpy() for i in range(4)])\n",
    "y = np.concatenate([train_dfs[i]['quality'].to_numpy() for i in range(4)])\n",
    "p = np.random.permutation(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 24.9543 - val_loss: 17.7191\n",
      "Epoch 2/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 14.8928 - val_loss: 12.1265\n",
      "Epoch 3/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 10.7069 - val_loss: 8.9244\n",
      "Epoch 4/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 7.9511 - val_loss: 6.6091\n",
      "Epoch 5/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 5.9111 - val_loss: 4.8762\n",
      "Epoch 6/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 4.3807 - val_loss: 3.5876\n",
      "Epoch 7/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 3.2443 - val_loss: 2.6407\n",
      "Epoch 8/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 2.4172 - val_loss: 1.9668\n",
      "Epoch 9/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 1.8321 - val_loss: 1.4984\n",
      "Epoch 10/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 1.4299 - val_loss: 1.1876\n",
      "Epoch 11/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 1.1631 - val_loss: 0.9885\n",
      "Epoch 12/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.9936 - val_loss: 0.8659\n",
      "Epoch 13/10000\n",
      "130/130 [==============================] - 0s 701us/step - loss: 0.8905 - val_loss: 0.7965\n",
      "Epoch 14/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.8303 - val_loss: 0.7588\n",
      "Epoch 15/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.7969 - val_loss: 0.7395\n",
      "Epoch 16/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.7793 - val_loss: 0.7311\n",
      "Epoch 17/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.7708 - val_loss: 0.7277\n",
      "Epoch 18/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.7667 - val_loss: 0.7269\n",
      "Epoch 19/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.7649 - val_loss: 0.7270\n",
      "Epoch 20/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.7642 - val_loss: 0.7273\n",
      "Epoch 21/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.7639 - val_loss: 0.7277\n",
      "Epoch 22/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.7638 - val_loss: 0.7280\n",
      "Epoch 23/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.7638 - val_loss: 0.7280\n",
      "Epoch 24/10000\n",
      "130/130 [==============================] - 0s 703us/step - loss: 0.7639 - val_loss: 0.7284\n",
      "Epoch 25/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.7638 - val_loss: 0.7282\n",
      "Epoch 26/10000\n",
      "130/130 [==============================] - 0s 706us/step - loss: 0.7638 - val_loss: 0.7282\n",
      "Epoch 27/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.7638 - val_loss: 0.7283\n",
      "Epoch 28/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.7639 - val_loss: 0.7283\n",
      "Epoch 29/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.7640 - val_loss: 0.7285\n",
      "Epoch 30/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.7639 - val_loss: 0.7284\n",
      "Epoch 31/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.7639 - val_loss: 0.7285\n",
      "Epoch 32/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.7639 - val_loss: 0.7283\n",
      "Epoch 33/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.7639 - val_loss: 0.7282\n",
      "Epoch 34/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.7639 - val_loss: 0.7280\n",
      "Epoch 35/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.7639 - val_loss: 0.7283\n",
      "Epoch 36/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.7639 - val_loss: 0.7281\n",
      "Epoch 37/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.7640 - val_loss: 0.7285\n",
      "Epoch 38/10000\n",
      "130/130 [==============================] - 0s 701us/step - loss: 0.7640 - val_loss: 0.7281\n",
      "Epoch 39/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.7639 - val_loss: 0.7280\n",
      "Epoch 40/10000\n",
      "130/130 [==============================] - 0s 704us/step - loss: 0.7640 - val_loss: 0.7285\n",
      "Epoch 41/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.7640 - val_loss: 0.7274\n",
      "Epoch 42/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.7641 - val_loss: 0.7288\n",
      "Epoch 43/10000\n",
      "130/130 [==============================] - 0s 706us/step - loss: 0.7641 - val_loss: 0.7280\n",
      "Epoch 44/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.7640 - val_loss: 0.7280\n",
      "Epoch 45/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.7639 - val_loss: 0.7284\n",
      "Epoch 46/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.7640 - val_loss: 0.7296\n",
      "Epoch 47/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.7639 - val_loss: 0.7281\n",
      "Epoch 48/10000\n",
      "130/130 [==============================] - 0s 705us/step - loss: 0.7641 - val_loss: 0.7285\n",
      "Epoch 49/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.7640 - val_loss: 0.7285\n",
      "Epoch 50/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.7641 - val_loss: 0.7289\n",
      "Epoch 51/10000\n",
      "130/130 [==============================] - 0s 705us/step - loss: 0.7640 - val_loss: 0.7291\n",
      "Epoch 52/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.7643 - val_loss: 0.7295\n",
      "Epoch 53/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.7641 - val_loss: 0.7287\n",
      "Epoch 54/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.7640 - val_loss: 0.7277\n",
      "Epoch 55/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.7640 - val_loss: 0.7283\n",
      "Epoch 56/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.7643 - val_loss: 0.7285\n",
      "Epoch 57/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.7640 - val_loss: 0.7275\n",
      "Epoch 58/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.7641 - val_loss: 0.7273\n",
      "Epoch 59/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.7641 - val_loss: 0.7290\n",
      "Epoch 60/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.7641 - val_loss: 0.7290\n",
      "Epoch 61/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.7641 - val_loss: 0.7281\n",
      "Epoch 62/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.7640 - val_loss: 0.7285\n",
      "Epoch 63/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.7642 - val_loss: 0.7285\n",
      "Epoch 64/10000\n",
      "130/130 [==============================] - 0s 701us/step - loss: 0.7640 - val_loss: 0.7276\n",
      "Epoch 65/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.7645 - val_loss: 0.7295\n",
      "Epoch 66/10000\n",
      "130/130 [==============================] - 0s 830us/step - loss: 0.7641 - val_loss: 0.7275\n",
      "Epoch 67/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.7644 - val_loss: 0.7281\n",
      "Epoch 68/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.7643 - val_loss: 0.7288\n",
      "Epoch 69/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.7642 - val_loss: 0.7294\n",
      "Epoch 70/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.7640 - val_loss: 0.7295\n",
      "Epoch 71/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.7644 - val_loss: 0.7285\n",
      "Epoch 72/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.7643 - val_loss: 0.7274\n",
      "Epoch 73/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.7641 - val_loss: 0.7300\n",
      "Epoch 74/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.7641 - val_loss: 0.7280\n",
      "Epoch 75/10000\n",
      "130/130 [==============================] - 0s 705us/step - loss: 0.7641 - val_loss: 0.7301\n",
      "Epoch 76/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.7642 - val_loss: 0.7293\n",
      "Epoch 77/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.7642 - val_loss: 0.7274\n",
      "Epoch 78/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.7640 - val_loss: 0.7285\n",
      "Epoch 79/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.7643 - val_loss: 0.7275\n",
      "Epoch 80/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.7644 - val_loss: 0.7295\n",
      "Epoch 81/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.7644 - val_loss: 0.7278\n",
      "Epoch 82/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.7643 - val_loss: 0.7276\n",
      "Epoch 83/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.7642 - val_loss: 0.7290\n",
      "Epoch 84/10000\n",
      "130/130 [==============================] - 0s 696us/step - loss: 0.7641 - val_loss: 0.7287\n",
      "Epoch 85/10000\n",
      "130/130 [==============================] - 0s 684us/step - loss: 0.7640 - val_loss: 0.7286\n",
      "Epoch 86/10000\n",
      "130/130 [==============================] - 0s 700us/step - loss: 0.7640 - val_loss: 0.7302\n",
      "Epoch 87/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.7646 - val_loss: 0.7280\n",
      "Epoch 88/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.7638 - val_loss: 0.7307\n",
      "Epoch 89/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.7643 - val_loss: 0.7295\n",
      "Epoch 90/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.7643 - val_loss: 0.7281\n",
      "Epoch 91/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.7638 - val_loss: 0.7289\n",
      "Epoch 92/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.7642 - val_loss: 0.7296\n",
      "Epoch 93/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.7629 - val_loss: 0.7230\n",
      "Epoch 94/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.7397 - val_loss: 0.7022\n",
      "Epoch 95/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.7319 - val_loss: 0.6634\n",
      "Epoch 96/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.6975 - val_loss: 0.6449\n",
      "Epoch 97/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.6614 - val_loss: 0.6075\n",
      "Epoch 98/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.6319 - val_loss: 0.5324\n",
      "Epoch 99/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.5858 - val_loss: 0.5242\n",
      "Epoch 100/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.5740 - val_loss: 0.5152\n",
      "Epoch 101/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.5821 - val_loss: 0.5020\n",
      "Epoch 102/10000\n",
      "130/130 [==============================] - 0s 851us/step - loss: 0.5778 - val_loss: 0.4960\n",
      "Epoch 103/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.5569 - val_loss: 0.5244\n",
      "Epoch 104/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.5571 - val_loss: 0.5326\n",
      "Epoch 105/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.5670 - val_loss: 0.4938\n",
      "Epoch 106/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.5489 - val_loss: 0.4919\n",
      "Epoch 107/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.5473 - val_loss: 0.4779\n",
      "Epoch 108/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5402 - val_loss: 0.5161\n",
      "Epoch 109/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.5403 - val_loss: 0.4766\n",
      "Epoch 110/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.5421 - val_loss: 0.4766\n",
      "Epoch 111/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.5427 - val_loss: 0.5265\n",
      "Epoch 112/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.5368 - val_loss: 0.4879\n",
      "Epoch 113/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.5408 - val_loss: 0.4690\n",
      "Epoch 114/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.5396 - val_loss: 0.4843\n",
      "Epoch 115/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.5356 - val_loss: 0.4903\n",
      "Epoch 116/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.5383 - val_loss: 0.5337\n",
      "Epoch 117/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.5309 - val_loss: 0.4727\n",
      "Epoch 118/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.5322 - val_loss: 0.4738\n",
      "Epoch 119/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.5319 - val_loss: 0.4823\n",
      "Epoch 120/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.5398 - val_loss: 0.4832\n",
      "Epoch 121/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.5345 - val_loss: 0.4842\n",
      "Epoch 122/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.5308 - val_loss: 0.4945\n",
      "Epoch 123/10000\n",
      "130/130 [==============================] - 0s 897us/step - loss: 0.5331 - val_loss: 0.4804\n",
      "Epoch 124/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.5090\n",
      "Epoch 125/10000\n",
      "130/130 [==============================] - 0s 825us/step - loss: 0.5300 - val_loss: 0.4747\n",
      "Epoch 126/10000\n",
      "130/130 [==============================] - 0s 823us/step - loss: 0.5304 - val_loss: 0.4728\n",
      "Epoch 127/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5304 - val_loss: 0.5138\n",
      "Epoch 128/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 0.4776\n",
      "Epoch 129/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5220 - val_loss: 0.4694\n",
      "Epoch 130/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.5226 - val_loss: 0.4817\n",
      "Epoch 131/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.5258 - val_loss: 0.4861\n",
      "Epoch 132/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.5198 - val_loss: 0.4695\n",
      "Epoch 133/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.5177 - val_loss: 0.4677\n",
      "Epoch 134/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.5311 - val_loss: 0.4907\n",
      "Epoch 135/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.5184 - val_loss: 0.4749\n",
      "Epoch 136/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.5214 - val_loss: 0.4749\n",
      "Epoch 137/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.5187 - val_loss: 0.4794\n",
      "Epoch 138/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.5283 - val_loss: 0.4830\n",
      "Epoch 139/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.5207 - val_loss: 0.4853\n",
      "Epoch 140/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.5198 - val_loss: 0.4724\n",
      "Epoch 141/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.5153 - val_loss: 0.4677\n",
      "Epoch 142/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.5111 - val_loss: 0.4726\n",
      "Epoch 143/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.5146 - val_loss: 0.4760\n",
      "Epoch 144/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.5088 - val_loss: 0.4821\n",
      "Epoch 145/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.5120 - val_loss: 0.4909\n",
      "Epoch 146/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.5112 - val_loss: 0.4696\n",
      "Epoch 147/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.5123 - val_loss: 0.4761\n",
      "Epoch 148/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.5098 - val_loss: 0.4869\n",
      "Epoch 149/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.5161 - val_loss: 0.4836\n",
      "Epoch 150/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.5092 - val_loss: 0.4765\n",
      "Epoch 151/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.5118 - val_loss: 0.4742\n",
      "Epoch 152/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.5053 - val_loss: 0.4712\n",
      "Epoch 153/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.5089 - val_loss: 0.4761\n",
      "Epoch 154/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.5076 - val_loss: 0.4732\n",
      "Epoch 155/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 740us/step - loss: 0.5025 - val_loss: 0.4691\n",
      "Epoch 156/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.5131 - val_loss: 0.5104\n",
      "Epoch 157/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.5149 - val_loss: 0.4732\n",
      "Epoch 158/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.5084 - val_loss: 0.4707\n",
      "Epoch 159/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.5062 - val_loss: 0.4690\n",
      "Epoch 160/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.5064 - val_loss: 0.4793\n",
      "Epoch 161/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.5114 - val_loss: 0.4667\n",
      "Epoch 162/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.5135 - val_loss: 0.4779\n",
      "Epoch 163/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.5027 - val_loss: 0.4803\n",
      "Epoch 164/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.5104 - val_loss: 0.4749\n",
      "Epoch 165/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.5040 - val_loss: 0.4652\n",
      "Epoch 166/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.5038 - val_loss: 0.4880\n",
      "Epoch 167/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.5060 - val_loss: 0.4699\n",
      "Epoch 168/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.5024 - val_loss: 0.4791\n",
      "Epoch 169/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.5024 - val_loss: 0.4754\n",
      "Epoch 170/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.5016 - val_loss: 0.4725\n",
      "Epoch 171/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.5012 - val_loss: 0.4739\n",
      "Epoch 172/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.4996 - val_loss: 0.5131\n",
      "Epoch 173/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4974 - val_loss: 0.4741\n",
      "Epoch 174/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.4977 - val_loss: 0.4968\n",
      "Epoch 175/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.5024 - val_loss: 0.4788\n",
      "Epoch 176/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4976 - val_loss: 0.4757\n",
      "Epoch 177/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.4960 - val_loss: 0.4779\n",
      "Epoch 178/10000\n",
      "130/130 [==============================] - 0s 946us/step - loss: 0.4990 - val_loss: 0.4998\n",
      "Epoch 179/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4997 - val_loss: 0.4883\n",
      "Epoch 180/10000\n",
      "130/130 [==============================] - 0s 908us/step - loss: 0.5006 - val_loss: 0.4896\n",
      "Epoch 181/10000\n",
      "130/130 [==============================] - 0s 908us/step - loss: 0.4951 - val_loss: 0.4813\n",
      "Epoch 182/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.5041 - val_loss: 0.4862\n",
      "Epoch 183/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.4967 - val_loss: 0.4818\n",
      "Epoch 184/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.4982 - val_loss: 0.4663\n",
      "Epoch 185/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.4922 - val_loss: 0.4682\n",
      "Epoch 186/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.4943 - val_loss: 0.4910\n",
      "Epoch 187/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.4960 - val_loss: 0.4730\n",
      "Epoch 188/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4922 - val_loss: 0.4760\n",
      "Epoch 189/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.4939 - val_loss: 0.4922\n",
      "Epoch 190/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.4975 - val_loss: 0.4637\n",
      "Epoch 191/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.4912 - val_loss: 0.4663\n",
      "Epoch 192/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.4920 - val_loss: 0.4675\n",
      "Epoch 193/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.4935 - val_loss: 0.4749\n",
      "Epoch 194/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.4908 - val_loss: 0.4700\n",
      "Epoch 195/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4905 - val_loss: 0.4769\n",
      "Epoch 196/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.4916 - val_loss: 0.4774\n",
      "Epoch 197/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.4893 - val_loss: 0.4669\n",
      "Epoch 198/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.4877 - val_loss: 0.4686\n",
      "Epoch 199/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.4911 - val_loss: 0.4659\n",
      "Epoch 200/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.4874 - val_loss: 0.4685\n",
      "Epoch 201/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4856 - val_loss: 0.4777\n",
      "Epoch 202/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.4889 - val_loss: 0.4763\n",
      "Epoch 203/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4870 - val_loss: 0.4636\n",
      "Epoch 204/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.4833 - val_loss: 0.4683\n",
      "Epoch 205/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.4822 - val_loss: 0.4657\n",
      "Epoch 206/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.4912 - val_loss: 0.4717\n",
      "Epoch 207/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4808 - val_loss: 0.4769\n",
      "Epoch 208/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.4919 - val_loss: 0.4611\n",
      "Epoch 209/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.4851 - val_loss: 0.4658\n",
      "Epoch 210/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.4879 - val_loss: 0.4774\n",
      "Epoch 211/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.4832 - val_loss: 0.4647\n",
      "Epoch 212/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.4866 - val_loss: 0.4626\n",
      "Epoch 213/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.4817 - val_loss: 0.4628\n",
      "Epoch 214/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.4796 - val_loss: 0.4625\n",
      "Epoch 215/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.4789 - val_loss: 0.4619\n",
      "Epoch 216/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.4797 - val_loss: 0.4595\n",
      "Epoch 217/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4791 - val_loss: 0.4565\n",
      "Epoch 218/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.4843 - val_loss: 0.4580\n",
      "Epoch 219/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.4885 - val_loss: 0.4617\n",
      "Epoch 220/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.4819 - val_loss: 0.4605\n",
      "Epoch 221/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.4807 - val_loss: 0.4745\n",
      "Epoch 222/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.4806 - val_loss: 0.4624\n",
      "Epoch 223/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.4776 - val_loss: 0.4813\n",
      "Epoch 224/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.4779 - val_loss: 0.4704\n",
      "Epoch 225/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.4823 - val_loss: 0.4659\n",
      "Epoch 226/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.4763 - val_loss: 0.4563\n",
      "Epoch 227/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4730 - val_loss: 0.4738\n",
      "Epoch 228/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.4703 - val_loss: 0.4641\n",
      "Epoch 229/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.4773 - val_loss: 0.4591\n",
      "Epoch 230/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.4761 - val_loss: 0.4649\n",
      "Epoch 231/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4815 - val_loss: 0.5128\n",
      "Epoch 232/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.4813 - val_loss: 0.5009\n",
      "Epoch 233/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.4851 - val_loss: 0.5046\n",
      "Epoch 234/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.4775 - val_loss: 0.4642\n",
      "Epoch 235/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4726 - val_loss: 0.4584\n",
      "Epoch 236/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.4696 - val_loss: 0.4821\n",
      "Epoch 237/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.4788 - val_loss: 0.4624\n",
      "Epoch 238/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4755 - val_loss: 0.4607\n",
      "Epoch 239/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.4752 - val_loss: 0.4909\n",
      "Epoch 240/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4710 - val_loss: 0.4613\n",
      "Epoch 241/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.4767 - val_loss: 0.4546\n",
      "Epoch 242/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.4668 - val_loss: 0.4599\n",
      "Epoch 243/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.4707 - val_loss: 0.4572\n",
      "Epoch 244/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4649 - val_loss: 0.4602\n",
      "Epoch 245/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.4778 - val_loss: 0.4735\n",
      "Epoch 246/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.4745 - val_loss: 0.4586\n",
      "Epoch 247/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.4664 - val_loss: 0.4532\n",
      "Epoch 248/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.4676 - val_loss: 0.4566\n",
      "Epoch 249/10000\n",
      "130/130 [==============================] - 0s 891us/step - loss: 0.4694 - val_loss: 0.4581\n",
      "Epoch 250/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4648 - val_loss: 0.4811\n",
      "Epoch 251/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.4674 - val_loss: 0.4627\n",
      "Epoch 252/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.4620 - val_loss: 0.4735\n",
      "Epoch 253/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.4683 - val_loss: 0.4681\n",
      "Epoch 254/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.4638 - val_loss: 0.4555\n",
      "Epoch 255/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.4687 - val_loss: 0.4659\n",
      "Epoch 256/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.4715 - val_loss: 0.4686\n",
      "Epoch 257/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.4642 - val_loss: 0.4583\n",
      "Epoch 258/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.4737 - val_loss: 0.4632\n",
      "Epoch 259/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.4692 - val_loss: 0.4803\n",
      "Epoch 260/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4816 - val_loss: 0.4658\n",
      "Epoch 261/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.4660 - val_loss: 0.4715\n",
      "Epoch 262/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.4681 - val_loss: 0.4606\n",
      "Epoch 263/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.4618 - val_loss: 0.4514\n",
      "Epoch 264/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.4616 - val_loss: 0.4587\n",
      "Epoch 265/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.4658 - val_loss: 0.4637\n",
      "Epoch 266/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.4655 - val_loss: 0.4612\n",
      "Epoch 267/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.4695 - val_loss: 0.4523\n",
      "Epoch 268/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.4595 - val_loss: 0.4973\n",
      "Epoch 269/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.4637 - val_loss: 0.4834\n",
      "Epoch 270/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.4622 - val_loss: 0.4572\n",
      "Epoch 271/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.4639 - val_loss: 0.4984\n",
      "Epoch 272/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.4634 - val_loss: 0.4616\n",
      "Epoch 273/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.4648 - val_loss: 0.4545\n",
      "Epoch 274/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.4551 - val_loss: 0.4624\n",
      "Epoch 275/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.4651 - val_loss: 0.4542\n",
      "Epoch 276/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.4620 - val_loss: 0.4562\n",
      "Epoch 277/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.4596 - val_loss: 0.4598\n",
      "Epoch 278/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.4728 - val_loss: 0.4521\n",
      "Epoch 279/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.4616 - val_loss: 0.4612\n",
      "Epoch 280/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.4525 - val_loss: 0.4528\n",
      "Epoch 281/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.4590 - val_loss: 0.4621\n",
      "Epoch 282/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.4557 - val_loss: 0.4582\n",
      "Epoch 283/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4673 - val_loss: 0.4701\n",
      "Epoch 284/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.4585 - val_loss: 0.4673\n",
      "Epoch 285/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.4563 - val_loss: 0.4731\n",
      "Epoch 286/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.4611 - val_loss: 0.4604\n",
      "Epoch 287/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.4552 - val_loss: 0.4531\n",
      "Epoch 288/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.4636 - val_loss: 0.4733\n",
      "Epoch 289/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.4723 - val_loss: 0.4578\n",
      "Epoch 290/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4580 - val_loss: 0.4496\n",
      "Epoch 291/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4539 - val_loss: 0.4522\n",
      "Epoch 292/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.4519 - val_loss: 0.4644\n",
      "Epoch 293/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.4563 - val_loss: 0.4756\n",
      "Epoch 294/10000\n",
      "130/130 [==============================] - 0s 832us/step - loss: 0.4525 - val_loss: 0.4579\n",
      "Epoch 295/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.4556 - val_loss: 0.4748\n",
      "Epoch 296/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4522 - val_loss: 0.4506\n",
      "Epoch 297/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4554 - val_loss: 0.4607\n",
      "Epoch 298/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.4562 - val_loss: 0.4767\n",
      "Epoch 299/10000\n",
      "130/130 [==============================] - 0s 927us/step - loss: 0.4506 - val_loss: 0.4492\n",
      "Epoch 300/10000\n",
      "130/130 [==============================] - 0s 929us/step - loss: 0.4513 - val_loss: 0.4729\n",
      "Epoch 301/10000\n",
      "130/130 [==============================] - 0s 970us/step - loss: 0.4685 - val_loss: 0.4522\n",
      "Epoch 302/10000\n",
      "130/130 [==============================] - 0s 830us/step - loss: 0.4514 - val_loss: 0.4730\n",
      "Epoch 303/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4547 - val_loss: 0.4616\n",
      "Epoch 304/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.4519 - val_loss: 0.4595\n",
      "Epoch 305/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.4517 - val_loss: 0.4688\n",
      "Epoch 306/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4477 - val_loss: 0.4714\n",
      "Epoch 307/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 783us/step - loss: 0.4476 - val_loss: 0.4845\n",
      "Epoch 308/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.4474 - val_loss: 0.4588\n",
      "Epoch 309/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.4490 - val_loss: 0.4951\n",
      "Epoch 310/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.4483 - val_loss: 0.4566\n",
      "Epoch 311/10000\n",
      "130/130 [==============================] - 0s 835us/step - loss: 0.4659 - val_loss: 0.4561\n",
      "Epoch 312/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.4485 - val_loss: 0.4619\n",
      "Epoch 313/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4597 - val_loss: 0.4606\n",
      "Epoch 314/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4481 - val_loss: 0.4690\n",
      "Epoch 315/10000\n",
      "130/130 [==============================] - 0s 892us/step - loss: 0.4483 - val_loss: 0.4577\n",
      "Epoch 316/10000\n",
      "130/130 [==============================] - 0s 915us/step - loss: 0.4483 - val_loss: 0.4549\n",
      "Epoch 317/10000\n",
      "130/130 [==============================] - 0s 981us/step - loss: 0.4473 - val_loss: 0.4594\n",
      "Epoch 318/10000\n",
      "130/130 [==============================] - 0s 832us/step - loss: 0.4524 - val_loss: 0.4574\n",
      "Epoch 319/10000\n",
      "130/130 [==============================] - 0s 841us/step - loss: 0.4464 - val_loss: 0.4537\n",
      "Epoch 320/10000\n",
      "130/130 [==============================] - 0s 861us/step - loss: 0.4603 - val_loss: 0.4641\n",
      "Epoch 321/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4433 - val_loss: 0.4838\n",
      "Epoch 322/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4447 - val_loss: 0.4592\n",
      "Epoch 323/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.4469 - val_loss: 0.4579\n",
      "Epoch 324/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.4589 - val_loss: 0.4691\n",
      "Epoch 325/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4536 - val_loss: 0.4538\n",
      "Epoch 326/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.4465 - val_loss: 0.4504\n",
      "Epoch 327/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.4407 - val_loss: 0.4678\n",
      "Epoch 328/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.4412 - val_loss: 0.4488\n",
      "Epoch 329/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.4466 - val_loss: 0.4564\n",
      "Epoch 330/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.4376 - val_loss: 0.4584\n",
      "Epoch 331/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.4445 - val_loss: 0.4536\n",
      "Epoch 332/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.4383 - val_loss: 0.4627\n",
      "Epoch 333/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.4399 - val_loss: 0.4488\n",
      "Epoch 334/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.4369 - val_loss: 0.4602\n",
      "Epoch 335/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.4329 - val_loss: 0.4649\n",
      "Epoch 336/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.4440 - val_loss: 0.4563\n",
      "Epoch 337/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.4400 - val_loss: 0.4535\n",
      "Epoch 338/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.4360 - val_loss: 0.4562\n",
      "Epoch 339/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.4463 - val_loss: 0.4678\n",
      "Epoch 340/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.4383 - val_loss: 0.4562\n",
      "Epoch 341/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4375 - val_loss: 0.4578\n",
      "Epoch 342/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.4353 - val_loss: 0.4946\n",
      "Epoch 343/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4390 - val_loss: 0.4407\n",
      "Epoch 344/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4407 - val_loss: 0.4526\n",
      "Epoch 345/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.4321 - val_loss: 0.4591\n",
      "Epoch 346/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.4344 - val_loss: 0.4584\n",
      "Epoch 347/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.4362 - val_loss: 0.4587\n",
      "Epoch 348/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.4344 - val_loss: 0.4825\n",
      "Epoch 349/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.4465 - val_loss: 0.4506\n",
      "Epoch 350/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.4352 - val_loss: 0.4573\n",
      "Epoch 351/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.4315 - val_loss: 0.4667\n",
      "Epoch 352/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4335 - val_loss: 0.4626\n",
      "Epoch 353/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4352 - val_loss: 0.4510\n",
      "Epoch 354/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.4320 - val_loss: 0.4477\n",
      "Epoch 355/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4293 - val_loss: 0.4534\n",
      "Epoch 356/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4373 - val_loss: 0.4765\n",
      "Epoch 357/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.4272 - val_loss: 0.4563\n",
      "Epoch 358/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.4276 - val_loss: 0.4620\n",
      "Epoch 359/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.4314 - val_loss: 0.4463\n",
      "Epoch 360/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.4292 - val_loss: 0.4573\n",
      "Epoch 361/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.4319 - val_loss: 0.4832\n",
      "Epoch 362/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4337 - val_loss: 0.4533\n",
      "Epoch 363/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.4309 - val_loss: 0.4639\n",
      "Epoch 364/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.4276 - val_loss: 0.4497\n",
      "Epoch 365/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4300 - val_loss: 0.4503\n",
      "Epoch 366/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.4308 - val_loss: 0.4571\n",
      "Epoch 367/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.4238 - val_loss: 0.4537\n",
      "Epoch 368/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4232 - val_loss: 0.4623\n",
      "Epoch 369/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4236 - val_loss: 0.4689\n",
      "Epoch 370/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.4269 - val_loss: 0.4628\n",
      "Epoch 371/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4252 - val_loss: 0.4614\n",
      "Epoch 372/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.4251 - val_loss: 0.4659\n",
      "Epoch 373/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.4263 - val_loss: 0.4575\n",
      "Epoch 374/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.4255 - val_loss: 0.4671\n",
      "Epoch 375/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.4290 - val_loss: 0.4603\n",
      "Epoch 376/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.4327 - val_loss: 0.4526\n",
      "Epoch 377/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4247 - val_loss: 0.4567\n",
      "Epoch 378/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.4185 - val_loss: 0.4483\n",
      "Epoch 379/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.4193 - val_loss: 0.4594\n",
      "Epoch 380/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.4183 - val_loss: 0.4677\n",
      "Epoch 381/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.4229 - val_loss: 0.4530\n",
      "Epoch 382/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4181 - val_loss: 0.4556\n",
      "Epoch 383/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.4242 - val_loss: 0.4587\n",
      "Epoch 384/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.4263 - val_loss: 0.4411\n",
      "Epoch 385/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.4252 - val_loss: 0.4623\n",
      "Epoch 386/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.4174 - val_loss: 0.4578\n",
      "Epoch 387/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.4240 - val_loss: 0.4559\n",
      "Epoch 388/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.4213 - val_loss: 0.5165\n",
      "Epoch 389/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4191 - val_loss: 0.4653\n",
      "Epoch 390/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4185 - val_loss: 0.4560\n",
      "Epoch 391/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.4146 - val_loss: 0.4508\n",
      "Epoch 392/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4153 - val_loss: 0.4923\n",
      "Epoch 393/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.4216 - val_loss: 0.4711\n",
      "Epoch 394/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4193 - val_loss: 0.4736\n",
      "Epoch 395/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4139 - val_loss: 0.4583\n",
      "Epoch 396/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4109 - val_loss: 0.4574\n",
      "Epoch 397/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.4119 - val_loss: 0.4578\n",
      "Epoch 398/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.4143 - val_loss: 0.4449\n",
      "Epoch 399/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.4118 - val_loss: 0.4506\n",
      "Epoch 400/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.4121 - val_loss: 0.4509\n",
      "Epoch 401/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.4246 - val_loss: 0.4833\n",
      "Epoch 402/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4140 - val_loss: 0.4850\n",
      "Epoch 403/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.4133 - val_loss: 0.4476\n",
      "Epoch 404/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.4060 - val_loss: 0.4578\n",
      "Epoch 405/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.4068 - val_loss: 0.4536\n",
      "Epoch 406/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4077 - val_loss: 0.4660\n",
      "Epoch 407/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.4154 - val_loss: 0.4603\n",
      "Epoch 408/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.4102 - val_loss: 0.4727\n",
      "Epoch 409/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.4121 - val_loss: 0.4673\n",
      "Epoch 410/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4152 - val_loss: 0.4488\n",
      "Epoch 411/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.4079 - val_loss: 0.4811\n",
      "Epoch 412/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.4058 - val_loss: 0.4507\n",
      "Epoch 413/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.4039 - val_loss: 0.4435\n",
      "Epoch 414/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.4042 - val_loss: 0.4681\n",
      "Epoch 415/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.4024 - val_loss: 0.4471\n",
      "Epoch 416/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.4032 - val_loss: 0.4564\n",
      "Epoch 417/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.4141 - val_loss: 0.4454\n",
      "Epoch 418/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4017 - val_loss: 0.4535\n",
      "Epoch 419/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4074 - val_loss: 0.4535\n",
      "Epoch 420/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3997 - val_loss: 0.4627\n",
      "Epoch 421/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.3998 - val_loss: 0.4598\n",
      "Epoch 422/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.4048 - val_loss: 0.4840\n",
      "Epoch 423/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.4017 - val_loss: 0.5119\n",
      "Epoch 424/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.4038 - val_loss: 0.4444\n",
      "Epoch 425/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.4012 - val_loss: 0.4557\n",
      "Epoch 426/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.4037 - val_loss: 0.4432\n",
      "Epoch 427/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3953 - val_loss: 0.4507\n",
      "Epoch 428/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.4011 - val_loss: 0.4569\n",
      "Epoch 429/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.4031 - val_loss: 0.4584\n",
      "Epoch 430/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.4082 - val_loss: 0.4497\n",
      "Epoch 431/10000\n",
      "130/130 [==============================] - 0s 796us/step - loss: 0.3985 - val_loss: 0.4458\n",
      "Epoch 432/10000\n",
      "130/130 [==============================] - 0s 935us/step - loss: 0.4008 - val_loss: 0.4463\n",
      "Epoch 433/10000\n",
      "130/130 [==============================] - 0s 847us/step - loss: 0.3997 - val_loss: 0.4957\n",
      "Epoch 434/10000\n",
      "130/130 [==============================] - 0s 864us/step - loss: 0.4000 - val_loss: 0.4673\n",
      "Epoch 435/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.4027 - val_loss: 0.4503\n",
      "Epoch 436/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.3945 - val_loss: 0.4779\n",
      "Epoch 437/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4043 - val_loss: 0.5266\n",
      "Epoch 438/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.3957 - val_loss: 0.4526\n",
      "Epoch 439/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3971 - val_loss: 0.4598\n",
      "Epoch 440/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.3944 - val_loss: 0.4552\n",
      "Epoch 441/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.3913 - val_loss: 0.4548\n",
      "Epoch 442/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.3915 - val_loss: 0.4577\n",
      "Epoch 443/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3882 - val_loss: 0.4705\n",
      "Epoch 444/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.4083 - val_loss: 0.4661\n",
      "Epoch 445/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.4046 - val_loss: 0.4812\n",
      "Epoch 446/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3888 - val_loss: 0.4582\n",
      "Epoch 447/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.3930 - val_loss: 0.4662\n",
      "Epoch 448/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3922 - val_loss: 0.4598\n",
      "Epoch 449/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.3862 - val_loss: 0.4523\n",
      "Epoch 450/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.3851 - val_loss: 0.5073\n",
      "Epoch 451/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.3974 - val_loss: 0.4695\n",
      "Epoch 452/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3863 - val_loss: 0.4649\n",
      "Epoch 453/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.3940 - val_loss: 0.4752\n",
      "Epoch 454/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.3846 - val_loss: 0.4614\n",
      "Epoch 455/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.3914 - val_loss: 0.4727\n",
      "Epoch 456/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3846 - val_loss: 0.4822\n",
      "Epoch 457/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.3937 - val_loss: 0.4567\n",
      "Epoch 458/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.3867 - val_loss: 0.4550\n",
      "Epoch 459/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 733us/step - loss: 0.3889 - val_loss: 0.4543\n",
      "Epoch 460/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3805 - val_loss: 0.4766\n",
      "Epoch 461/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3978 - val_loss: 0.4573\n",
      "Epoch 462/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3862 - val_loss: 0.4479\n",
      "Epoch 463/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.3852 - val_loss: 0.4654\n",
      "Epoch 464/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3878 - val_loss: 0.5184\n",
      "Epoch 465/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3833 - val_loss: 0.4565\n",
      "Epoch 466/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3970 - val_loss: 0.4924\n",
      "Epoch 467/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.3912 - val_loss: 0.4665\n",
      "Epoch 468/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3852 - val_loss: 0.4573\n",
      "Epoch 469/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3787 - val_loss: 0.4545\n",
      "Epoch 470/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.3872 - val_loss: 0.4646\n",
      "Epoch 471/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3830 - val_loss: 0.4688\n",
      "Epoch 472/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3841 - val_loss: 0.4822\n",
      "Epoch 473/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.3783 - val_loss: 0.4677\n",
      "Epoch 474/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3769 - val_loss: 0.4579\n",
      "Epoch 475/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3716 - val_loss: 0.4741\n",
      "Epoch 476/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3755 - val_loss: 0.5097\n",
      "Epoch 477/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3800 - val_loss: 0.4557\n",
      "Epoch 478/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3768 - val_loss: 0.4684\n",
      "Epoch 479/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.3747 - val_loss: 0.4726\n",
      "Epoch 480/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3741 - val_loss: 0.4787\n",
      "Epoch 481/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.3767 - val_loss: 0.4710\n",
      "Epoch 482/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3742 - val_loss: 0.4697\n",
      "Epoch 483/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.3807 - val_loss: 0.4761\n",
      "Epoch 484/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.3827 - val_loss: 0.4523\n",
      "Epoch 485/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3680 - val_loss: 0.4498\n",
      "Epoch 486/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3797 - val_loss: 0.4646\n",
      "Epoch 487/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.3702 - val_loss: 0.4701\n",
      "Epoch 488/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.3912 - val_loss: 0.4690\n",
      "Epoch 489/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.3696 - val_loss: 0.4607\n",
      "Epoch 490/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3692 - val_loss: 0.4643\n",
      "Epoch 491/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3660 - val_loss: 0.4679\n",
      "Epoch 492/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.3686 - val_loss: 0.4702\n",
      "Epoch 493/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.3725 - val_loss: 0.4856\n",
      "Epoch 494/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3697 - val_loss: 0.4728\n",
      "Epoch 495/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.3687 - val_loss: 0.4860\n",
      "Epoch 496/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3725 - val_loss: 0.4757\n",
      "Epoch 497/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3705 - val_loss: 0.4972\n",
      "Epoch 498/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3613 - val_loss: 0.4687\n",
      "Epoch 499/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3691 - val_loss: 0.4821\n",
      "Epoch 500/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3622 - val_loss: 0.4965\n",
      "Epoch 501/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.3666 - val_loss: 0.4698\n",
      "Epoch 502/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.3705 - val_loss: 0.4806\n",
      "Epoch 503/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.3770 - val_loss: 0.4615\n",
      "Epoch 504/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.3625 - val_loss: 0.4688\n",
      "Epoch 505/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3751 - val_loss: 0.4672\n",
      "Epoch 506/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.3629 - val_loss: 0.4640\n",
      "Epoch 507/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.3651 - val_loss: 0.4713\n",
      "Epoch 508/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3772 - val_loss: 0.4766\n",
      "Epoch 509/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3680 - val_loss: 0.4830\n",
      "Epoch 510/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3575 - val_loss: 0.4892\n",
      "Epoch 511/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3567 - val_loss: 0.4645\n",
      "Epoch 512/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3641 - val_loss: 0.4865\n",
      "Epoch 513/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3565 - val_loss: 0.4664\n",
      "Epoch 514/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3594 - val_loss: 0.4668\n",
      "Epoch 515/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.3683 - val_loss: 0.4685\n",
      "Epoch 516/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3646 - val_loss: 0.4590\n",
      "Epoch 517/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3584 - val_loss: 0.4791\n",
      "Epoch 518/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3640 - val_loss: 0.4842\n",
      "Epoch 519/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3598 - val_loss: 0.4811\n",
      "Epoch 520/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.3582 - val_loss: 0.4755\n",
      "Epoch 521/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.3653 - val_loss: 0.4688\n",
      "Epoch 522/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3614 - val_loss: 0.4968\n",
      "Epoch 523/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3676 - val_loss: 0.4789\n",
      "Epoch 524/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3523 - val_loss: 0.4735\n",
      "Epoch 525/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3540 - val_loss: 0.4730\n",
      "Epoch 526/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.3630 - val_loss: 0.4726\n",
      "Epoch 527/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3600 - val_loss: 0.4721\n",
      "Epoch 528/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.3586 - val_loss: 0.4717\n",
      "Epoch 529/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3503 - val_loss: 0.4752\n",
      "Epoch 530/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3493 - val_loss: 0.4737\n",
      "Epoch 531/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3576 - val_loss: 0.4735\n",
      "Epoch 532/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3501 - val_loss: 0.4739\n",
      "Epoch 533/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3562 - val_loss: 0.4713\n",
      "Epoch 534/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3580 - val_loss: 0.4866\n",
      "Epoch 535/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3580 - val_loss: 0.4627\n",
      "Epoch 536/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3491 - val_loss: 0.4615\n",
      "Epoch 537/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3605 - val_loss: 0.4602\n",
      "Epoch 538/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.3614 - val_loss: 0.4741\n",
      "Epoch 539/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3462 - val_loss: 0.4567\n",
      "Epoch 540/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3451 - val_loss: 0.4847\n",
      "Epoch 541/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3541 - val_loss: 0.4615\n",
      "Epoch 542/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3575 - val_loss: 0.4640\n",
      "Epoch 543/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3493 - val_loss: 0.4792\n",
      "Epoch 544/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3396 - val_loss: 0.4634\n",
      "Epoch 545/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3571 - val_loss: 0.4732\n",
      "Epoch 546/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3415 - val_loss: 0.4652\n",
      "Epoch 547/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3501 - val_loss: 0.4883\n",
      "Epoch 548/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3478 - val_loss: 0.4645\n",
      "Epoch 549/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.3461 - val_loss: 0.4703\n",
      "Epoch 550/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3481 - val_loss: 0.4729\n",
      "Epoch 551/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.3423 - val_loss: 0.4770\n",
      "Epoch 552/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3511 - val_loss: 0.4715\n",
      "Epoch 553/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3553 - val_loss: 0.4652\n",
      "Epoch 554/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3436 - val_loss: 0.5088\n",
      "Epoch 555/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.3465 - val_loss: 0.4634\n",
      "Epoch 556/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3418 - val_loss: 0.5365\n",
      "Epoch 557/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.3562 - val_loss: 0.4734\n",
      "Epoch 558/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3390 - val_loss: 0.4730\n",
      "Epoch 559/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3543 - val_loss: 0.4655\n",
      "Epoch 560/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3483 - val_loss: 0.4660\n",
      "Epoch 561/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3411 - val_loss: 0.4722\n",
      "Epoch 562/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3445 - val_loss: 0.4839\n",
      "Epoch 563/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.3370 - val_loss: 0.4781\n",
      "Epoch 564/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3463 - val_loss: 0.4681\n",
      "Epoch 565/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3365 - val_loss: 0.4806\n",
      "Epoch 566/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3606 - val_loss: 0.4974\n",
      "Epoch 567/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3418 - val_loss: 0.4852\n",
      "Epoch 568/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3373 - val_loss: 0.4592\n",
      "Epoch 569/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3390 - val_loss: 0.4690\n",
      "Epoch 570/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3425 - val_loss: 0.4734\n",
      "Epoch 571/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3431 - val_loss: 0.4837\n",
      "Epoch 572/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3412 - val_loss: 0.4681\n",
      "Epoch 573/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3519 - val_loss: 0.4735\n",
      "Epoch 574/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3334 - val_loss: 0.4852\n",
      "Epoch 575/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3372 - val_loss: 0.4912\n",
      "Epoch 576/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3296 - val_loss: 0.4769\n",
      "Epoch 577/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3341 - val_loss: 0.4939\n",
      "Epoch 578/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3411 - val_loss: 0.4851\n",
      "Epoch 579/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3390 - val_loss: 0.4827\n",
      "Epoch 580/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3322 - val_loss: 0.4699\n",
      "Epoch 581/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3302 - val_loss: 0.4833\n",
      "Epoch 582/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.3431 - val_loss: 0.4836\n",
      "Epoch 583/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3352 - val_loss: 0.4607\n",
      "Epoch 584/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.3359 - val_loss: 0.4973\n",
      "Epoch 585/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.3344 - val_loss: 0.4859\n",
      "Epoch 586/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.3317 - val_loss: 0.4943\n",
      "Epoch 587/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3396 - val_loss: 0.4667\n",
      "Epoch 588/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3349 - val_loss: 0.5171\n",
      "Epoch 589/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.3350 - val_loss: 0.4834\n",
      "Epoch 590/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.3296 - val_loss: 0.4692\n",
      "Epoch 591/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.3333 - val_loss: 0.4721\n",
      "Epoch 592/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.3250 - val_loss: 0.4788\n",
      "Epoch 593/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.3302 - val_loss: 0.4760\n",
      "Epoch 594/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3285 - val_loss: 0.4814\n",
      "Epoch 595/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3328 - val_loss: 0.4824\n",
      "Epoch 596/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3312 - val_loss: 0.4947\n",
      "Epoch 597/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3210 - val_loss: 0.4951\n",
      "Epoch 598/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3275 - val_loss: 0.4946\n",
      "Epoch 599/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3336 - val_loss: 0.4833\n",
      "Epoch 600/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3283 - val_loss: 0.4948\n",
      "Epoch 601/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3386 - val_loss: 0.4815\n",
      "Epoch 602/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3238 - val_loss: 0.4882\n",
      "Epoch 603/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3210 - val_loss: 0.4780\n",
      "Epoch 604/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3167 - val_loss: 0.4984\n",
      "Epoch 605/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3228 - val_loss: 0.5037\n",
      "Epoch 606/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3302 - val_loss: 0.4675\n",
      "Epoch 607/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3220 - val_loss: 0.4747\n",
      "Epoch 608/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3325 - val_loss: 0.4818\n",
      "Epoch 609/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3151 - val_loss: 0.4837\n",
      "Epoch 610/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3232 - val_loss: 0.4895\n",
      "Epoch 611/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 726us/step - loss: 0.3315 - val_loss: 0.4940\n",
      "Epoch 612/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3334 - val_loss: 0.4836\n",
      "Epoch 613/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.3219 - val_loss: 0.4875\n",
      "Epoch 614/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.3189 - val_loss: 0.4963\n",
      "Epoch 615/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3195 - val_loss: 0.4909\n",
      "Epoch 616/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3252 - val_loss: 0.4655\n",
      "Epoch 617/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3215 - val_loss: 0.4813\n",
      "Epoch 618/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3233 - val_loss: 0.4887\n",
      "Epoch 619/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3149 - val_loss: 0.4834\n",
      "Epoch 620/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3228 - val_loss: 0.4972\n",
      "Epoch 621/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3243 - val_loss: 0.4716\n",
      "Epoch 622/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3145 - val_loss: 0.5111\n",
      "Epoch 623/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3111 - val_loss: 0.4800\n",
      "Epoch 624/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3127 - val_loss: 0.4661\n",
      "Epoch 625/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3506 - val_loss: 0.5006\n",
      "Epoch 626/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3145 - val_loss: 0.4666\n",
      "Epoch 627/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3161 - val_loss: 0.4763\n",
      "Epoch 628/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.3281 - val_loss: 0.4872\n",
      "Epoch 629/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3146 - val_loss: 0.4830\n",
      "Epoch 630/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.3145 - val_loss: 0.5107\n",
      "Epoch 631/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.3202 - val_loss: 0.4909\n",
      "Epoch 632/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.3133 - val_loss: 0.4752\n",
      "Epoch 633/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.3194 - val_loss: 0.4945\n",
      "Epoch 634/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.3192 - val_loss: 0.4865\n",
      "Epoch 635/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.3152 - val_loss: 0.4975\n",
      "Epoch 636/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3112 - val_loss: 0.4942\n",
      "Epoch 637/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3161 - val_loss: 0.4825\n",
      "Epoch 638/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3069 - val_loss: 0.4787\n",
      "Epoch 639/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3229 - val_loss: 0.4771\n",
      "Epoch 640/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3034 - val_loss: 0.4839\n",
      "Epoch 641/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3061 - val_loss: 0.5247\n",
      "Epoch 642/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3147 - val_loss: 0.4815\n",
      "Epoch 643/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3147 - val_loss: 0.4980\n",
      "Epoch 644/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3041 - val_loss: 0.4850\n",
      "Epoch 645/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3037 - val_loss: 0.4935\n",
      "Epoch 646/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.3101 - val_loss: 0.5209\n",
      "Epoch 647/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3140 - val_loss: 0.4838\n",
      "Epoch 648/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3174 - val_loss: 0.4714\n",
      "Epoch 649/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3134 - val_loss: 0.5059\n",
      "Epoch 650/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3033 - val_loss: 0.4794\n",
      "Epoch 651/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3102 - val_loss: 0.4783\n",
      "Epoch 652/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.3116 - val_loss: 0.4900\n",
      "Epoch 653/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.2985 - val_loss: 0.4855\n",
      "Epoch 654/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3151 - val_loss: 0.4868\n",
      "Epoch 655/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3040 - val_loss: 0.4926\n",
      "Epoch 656/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3140 - val_loss: 0.4971\n",
      "Epoch 657/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3070 - val_loss: 0.4758\n",
      "Epoch 658/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3067 - val_loss: 0.5338\n",
      "Epoch 659/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3082 - val_loss: 0.4981\n",
      "Epoch 660/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2998 - val_loss: 0.4933\n",
      "Epoch 661/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3079 - val_loss: 0.4793\n",
      "Epoch 662/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2977 - val_loss: 0.4939\n",
      "Epoch 663/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3082 - val_loss: 0.5043\n",
      "Epoch 664/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3050 - val_loss: 0.4965\n",
      "Epoch 665/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.3037 - val_loss: 0.4863\n",
      "Epoch 666/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3047 - val_loss: 0.5174\n",
      "Epoch 667/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3059 - val_loss: 0.4621\n",
      "Epoch 668/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2999 - val_loss: 0.4803\n",
      "Epoch 669/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.3228 - val_loss: 0.4931\n",
      "Epoch 670/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.3141 - val_loss: 0.4919\n",
      "Epoch 671/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.3081 - val_loss: 0.4946\n",
      "Epoch 672/10000\n",
      "130/130 [==============================] - 0s 975us/step - loss: 0.3038 - val_loss: 0.4932\n",
      "Epoch 673/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.3041 - val_loss: 0.5275\n",
      "Epoch 674/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3035 - val_loss: 0.5080\n",
      "Epoch 675/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.2967 - val_loss: 0.4870\n",
      "Epoch 676/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2971 - val_loss: 0.4800\n",
      "Epoch 677/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3006 - val_loss: 0.4840\n",
      "Epoch 678/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2954 - val_loss: 0.4915\n",
      "Epoch 679/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.3004 - val_loss: 0.4844\n",
      "Epoch 680/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.2925 - val_loss: 0.4788\n",
      "Epoch 681/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.2997 - val_loss: 0.4984\n",
      "Epoch 682/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.3146 - val_loss: 0.5030\n",
      "Epoch 683/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3053 - val_loss: 0.4956\n",
      "Epoch 684/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2908 - val_loss: 0.5047\n",
      "Epoch 685/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3024 - val_loss: 0.4915\n",
      "Epoch 686/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2991 - val_loss: 0.5091\n",
      "Epoch 687/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3131 - val_loss: 0.4969\n",
      "Epoch 688/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3044 - val_loss: 0.4931\n",
      "Epoch 689/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2946 - val_loss: 0.4877\n",
      "Epoch 690/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2984 - val_loss: 0.4729\n",
      "Epoch 691/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2954 - val_loss: 0.4850\n",
      "Epoch 692/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2927 - val_loss: 0.4855\n",
      "Epoch 693/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2905 - val_loss: 0.4891\n",
      "Epoch 694/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2886 - val_loss: 0.4806\n",
      "Epoch 695/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2963 - val_loss: 0.4781\n",
      "Epoch 696/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2866 - val_loss: 0.5121\n",
      "Epoch 697/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2925 - val_loss: 0.5478\n",
      "Epoch 698/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3063 - val_loss: 0.5078\n",
      "Epoch 699/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.2977 - val_loss: 0.5086\n",
      "Epoch 700/10000\n",
      "130/130 [==============================] - 0s 826us/step - loss: 0.2862 - val_loss: 0.5226\n",
      "Epoch 701/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.2890 - val_loss: 0.4816\n",
      "Epoch 702/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.2965 - val_loss: 0.4880\n",
      "Epoch 703/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.4977\n",
      "Epoch 704/10000\n",
      "130/130 [==============================] - 0s 905us/step - loss: 0.2943 - val_loss: 0.4892\n",
      "Epoch 705/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.2934 - val_loss: 0.4836\n",
      "Epoch 706/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3016 - val_loss: 0.4874\n",
      "Epoch 707/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3000 - val_loss: 0.4868\n",
      "Epoch 708/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2968 - val_loss: 0.4805\n",
      "Epoch 709/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.2858 - val_loss: 0.4867\n",
      "Epoch 710/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.2830 - val_loss: 0.4965\n",
      "Epoch 711/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2933 - val_loss: 0.5232\n",
      "Epoch 712/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2899 - val_loss: 0.4921\n",
      "Epoch 713/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.2939 - val_loss: 0.5015\n",
      "Epoch 714/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2870 - val_loss: 0.4870\n",
      "Epoch 715/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2772 - val_loss: 0.4998\n",
      "Epoch 716/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.2900 - val_loss: 0.4911\n",
      "Epoch 717/10000\n",
      "130/130 [==============================] - 0s 864us/step - loss: 0.2879 - val_loss: 0.4781\n",
      "Epoch 718/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.2869 - val_loss: 0.5028\n",
      "Epoch 719/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.2935 - val_loss: 0.4961\n",
      "Epoch 720/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2941 - val_loss: 0.5255\n",
      "Epoch 721/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.2890 - val_loss: 0.4931\n",
      "Epoch 722/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2842 - val_loss: 0.4942\n",
      "Epoch 723/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2901 - val_loss: 0.5261\n",
      "Epoch 724/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2921 - val_loss: 0.5036\n",
      "Epoch 725/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2971 - val_loss: 0.4810\n",
      "Epoch 726/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2887 - val_loss: 0.4911\n",
      "Epoch 727/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2860 - val_loss: 0.4893\n",
      "Epoch 728/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2803 - val_loss: 0.4892\n",
      "Epoch 729/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2859 - val_loss: 0.4932\n",
      "Epoch 730/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2817 - val_loss: 0.5078\n",
      "Epoch 731/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2836 - val_loss: 0.4996\n",
      "Epoch 732/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2811 - val_loss: 0.4903\n",
      "Epoch 733/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2822 - val_loss: 0.4958\n",
      "Epoch 734/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2842 - val_loss: 0.5014\n",
      "Epoch 735/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.2782 - val_loss: 0.5217\n",
      "Epoch 736/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2953 - val_loss: 0.4886\n",
      "Epoch 737/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.2763 - val_loss: 0.5354\n",
      "Epoch 738/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2980 - val_loss: 0.4989\n",
      "Epoch 739/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2869 - val_loss: 0.4892\n",
      "Epoch 740/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2805 - val_loss: 0.5001\n",
      "Epoch 741/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2726 - val_loss: 0.5121\n",
      "Epoch 742/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2795 - val_loss: 0.5023\n",
      "Epoch 743/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2851 - val_loss: 0.5143\n",
      "Epoch 744/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.2758 - val_loss: 0.5031\n",
      "Epoch 745/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2762 - val_loss: 0.4891\n",
      "Epoch 746/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2738 - val_loss: 0.4935\n",
      "Epoch 747/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.2902 - val_loss: 0.5024\n",
      "Epoch 748/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2800 - val_loss: 0.5030\n",
      "Epoch 749/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2833 - val_loss: 0.5109\n",
      "Epoch 750/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2764 - val_loss: 0.4997\n",
      "Epoch 751/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2759 - val_loss: 0.5018\n",
      "Epoch 752/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2831 - val_loss: 0.4918\n",
      "Epoch 753/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2770 - val_loss: 0.4867\n",
      "Epoch 754/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2754 - val_loss: 0.4974\n",
      "Epoch 755/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2742 - val_loss: 0.4875\n",
      "Epoch 756/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2842 - val_loss: 0.5323\n",
      "Epoch 757/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2816 - val_loss: 0.5476\n",
      "Epoch 758/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2810 - val_loss: 0.5121\n",
      "Epoch 759/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.2726 - val_loss: 0.5001\n",
      "Epoch 760/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2851 - val_loss: 0.5248\n",
      "Epoch 761/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2834 - val_loss: 0.5245\n",
      "Epoch 762/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2779 - val_loss: 0.5114\n",
      "Epoch 763/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 725us/step - loss: 0.2781 - val_loss: 0.5116\n",
      "Epoch 764/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2832 - val_loss: 0.4860\n",
      "Epoch 765/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2681 - val_loss: 0.4949\n",
      "Epoch 766/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2784 - val_loss: 0.5230\n",
      "Epoch 767/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.2706 - val_loss: 0.5157\n",
      "Epoch 768/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2837 - val_loss: 0.5255\n",
      "Epoch 769/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2749 - val_loss: 0.5089\n",
      "Epoch 770/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2770 - val_loss: 0.5017\n",
      "Epoch 771/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2916 - val_loss: 0.5199\n",
      "Epoch 772/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2732 - val_loss: 0.5022\n",
      "Epoch 773/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2660 - val_loss: 0.5365\n",
      "Epoch 774/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2785 - val_loss: 0.5138\n",
      "Epoch 775/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2864 - val_loss: 0.5085\n",
      "Epoch 776/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.2722 - val_loss: 0.5278\n",
      "Epoch 777/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2726 - val_loss: 0.5082\n",
      "Epoch 778/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2648 - val_loss: 0.5236\n",
      "Epoch 779/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2699 - val_loss: 0.5153\n",
      "Epoch 780/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.2701 - val_loss: 0.4961\n",
      "Epoch 781/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2677 - val_loss: 0.5139\n",
      "Epoch 782/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2681 - val_loss: 0.5106\n",
      "Epoch 783/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.2724 - val_loss: 0.4865\n",
      "Epoch 784/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2685 - val_loss: 0.5160\n",
      "Epoch 785/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2738 - val_loss: 0.5231\n",
      "Epoch 786/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2732 - val_loss: 0.5033\n",
      "Epoch 787/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2700 - val_loss: 0.5007\n",
      "Epoch 788/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2677 - val_loss: 0.4964\n",
      "Epoch 789/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2758 - val_loss: 0.5568\n",
      "Epoch 790/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2777 - val_loss: 0.5044\n",
      "Epoch 791/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2667 - val_loss: 0.5395\n",
      "Epoch 792/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2589 - val_loss: 0.5018\n",
      "Epoch 793/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2637 - val_loss: 0.5278\n",
      "Epoch 794/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2677 - val_loss: 0.4944\n",
      "Epoch 795/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.2635 - val_loss: 0.4998\n",
      "Epoch 796/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.2624 - val_loss: 0.5044\n",
      "Epoch 797/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2698 - val_loss: 0.4919\n",
      "Epoch 798/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2685 - val_loss: 0.4989\n",
      "Epoch 799/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2596 - val_loss: 0.5095\n",
      "Epoch 800/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2652 - val_loss: 0.5091\n",
      "Epoch 801/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2644 - val_loss: 0.5241\n",
      "Epoch 802/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2638 - val_loss: 0.4998\n",
      "Epoch 803/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.2592 - val_loss: 0.5093\n",
      "Epoch 804/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2656 - val_loss: 0.5160\n",
      "Epoch 805/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2635 - val_loss: 0.5107\n",
      "Epoch 806/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2689 - val_loss: 0.5038\n",
      "Epoch 807/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.2659 - val_loss: 0.5131\n",
      "Epoch 808/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.2634 - val_loss: 0.5053\n",
      "Epoch 809/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.2575 - val_loss: 0.5129\n",
      "Epoch 810/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2631 - val_loss: 0.5439\n",
      "Epoch 811/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.2598 - val_loss: 0.5057\n",
      "Epoch 812/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2626 - val_loss: 0.5093\n",
      "Epoch 813/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.2545 - val_loss: 0.5164\n",
      "Epoch 814/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2687 - val_loss: 0.5170\n",
      "Epoch 815/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.2665 - val_loss: 0.5041\n",
      "Epoch 816/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2709 - val_loss: 0.5059\n",
      "Epoch 817/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2560 - val_loss: 0.5031\n",
      "Epoch 818/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2563 - val_loss: 0.5167\n",
      "Epoch 819/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2628 - val_loss: 0.5211\n",
      "Epoch 820/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.2570 - val_loss: 0.5183\n",
      "Epoch 821/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.2595 - val_loss: 0.5197\n",
      "Epoch 822/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2562 - val_loss: 0.5111\n",
      "Epoch 823/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2555 - val_loss: 0.5296\n",
      "Epoch 824/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2588 - val_loss: 0.5135\n",
      "Epoch 825/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2595 - val_loss: 0.5080\n",
      "Epoch 826/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2577 - val_loss: 0.5033\n",
      "Epoch 827/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2717 - val_loss: 0.5361\n",
      "Epoch 828/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2527 - val_loss: 0.5272\n",
      "Epoch 829/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.2572 - val_loss: 0.5079\n",
      "Epoch 830/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2559 - val_loss: 0.5163\n",
      "Epoch 831/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2595 - val_loss: 0.5133\n",
      "Epoch 832/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2553 - val_loss: 0.5316\n",
      "Epoch 833/10000\n",
      "130/130 [==============================] - 0s 978us/step - loss: 0.2497 - val_loss: 0.5185\n",
      "Epoch 834/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.2565 - val_loss: 0.5073\n",
      "Epoch 835/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.2602 - val_loss: 0.5122\n",
      "Epoch 836/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2474 - val_loss: 0.5034\n",
      "Epoch 837/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2602 - val_loss: 0.5034\n",
      "Epoch 838/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2576 - val_loss: 0.5248\n",
      "Epoch 839/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2542 - val_loss: 0.5204\n",
      "Epoch 840/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2575 - val_loss: 0.5088\n",
      "Epoch 841/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2551 - val_loss: 0.5296\n",
      "Epoch 842/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.2634 - val_loss: 0.5605\n",
      "Epoch 843/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.2600 - val_loss: 0.5090\n",
      "Epoch 844/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2581 - val_loss: 0.5583\n",
      "Epoch 845/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2549 - val_loss: 0.5193\n",
      "Epoch 846/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2545 - val_loss: 0.5199\n",
      "Epoch 847/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2580 - val_loss: 0.5312\n",
      "Epoch 848/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2589 - val_loss: 0.5043\n",
      "Epoch 849/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2516 - val_loss: 0.5322\n",
      "Epoch 850/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2650 - val_loss: 0.4871\n",
      "Epoch 851/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2417 - val_loss: 0.4992\n",
      "Epoch 852/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2515 - val_loss: 0.4969\n",
      "Epoch 853/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2608 - val_loss: 0.5097\n",
      "Epoch 854/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2562 - val_loss: 0.5373\n",
      "Epoch 855/10000\n",
      "130/130 [==============================] - 0s 907us/step - loss: 0.2542 - val_loss: 0.5065\n",
      "Epoch 856/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2526 - val_loss: 0.5107\n",
      "Epoch 857/10000\n",
      "130/130 [==============================] - 0s 881us/step - loss: 0.2485 - val_loss: 0.5154\n",
      "Epoch 858/10000\n",
      "130/130 [==============================] - 0s 908us/step - loss: 0.2424 - val_loss: 0.5262\n",
      "Epoch 859/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.2506 - val_loss: 0.5174\n",
      "Epoch 860/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.2521 - val_loss: 0.5450\n",
      "Epoch 861/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2523 - val_loss: 0.5414\n",
      "Epoch 862/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2646 - val_loss: 0.5116\n",
      "Epoch 863/10000\n",
      "130/130 [==============================] - 0s 852us/step - loss: 0.2421 - val_loss: 0.5072\n",
      "Epoch 864/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.2409 - val_loss: 0.5506\n",
      "Epoch 865/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.2425 - val_loss: 0.5238\n",
      "Epoch 866/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.2504 - val_loss: 0.5250\n",
      "Epoch 867/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.2464 - val_loss: 0.5101\n",
      "Epoch 868/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2431 - val_loss: 0.5220\n",
      "Epoch 869/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2499 - val_loss: 0.5179\n",
      "Epoch 870/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.2433 - val_loss: 0.5273\n",
      "Epoch 871/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.2568 - val_loss: 0.5045\n",
      "Epoch 872/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2484 - val_loss: 0.5035\n",
      "Epoch 873/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2424 - val_loss: 0.5131\n",
      "Epoch 874/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.2433 - val_loss: 0.5171\n",
      "Epoch 875/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.2393 - val_loss: 0.4928\n",
      "Epoch 876/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2454 - val_loss: 0.5180\n",
      "Epoch 877/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2448 - val_loss: 0.5298\n",
      "Epoch 878/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2424 - val_loss: 0.5341\n",
      "Epoch 879/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2521 - val_loss: 0.5462\n",
      "Epoch 880/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.2515 - val_loss: 0.5346\n",
      "Epoch 881/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2388 - val_loss: 0.4995\n",
      "Epoch 882/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2422 - val_loss: 0.5281\n",
      "Epoch 883/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2446 - val_loss: 0.5208\n",
      "Epoch 884/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2374 - val_loss: 0.5350\n",
      "Epoch 885/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2552 - val_loss: 0.5050\n",
      "Epoch 886/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2469 - val_loss: 0.5249\n",
      "Epoch 887/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.2508 - val_loss: 0.5133\n",
      "Epoch 888/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2418 - val_loss: 0.5044\n",
      "Epoch 889/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2412 - val_loss: 0.5276\n",
      "Epoch 890/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2543 - val_loss: 0.5123\n",
      "Epoch 891/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.2379 - val_loss: 0.5293\n",
      "Epoch 892/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2376 - val_loss: 0.5254\n",
      "Epoch 893/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2383 - val_loss: 0.5167\n",
      "Epoch 894/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2430 - val_loss: 0.5548\n",
      "Epoch 895/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.2414 - val_loss: 0.5207\n",
      "Epoch 896/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2351 - val_loss: 0.5308\n",
      "Epoch 897/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2512 - val_loss: 0.4970\n",
      "Epoch 898/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2387 - val_loss: 0.5165\n",
      "Epoch 899/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2415 - val_loss: 0.5424\n",
      "Epoch 900/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2540 - val_loss: 0.5306\n",
      "Epoch 901/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.2382 - val_loss: 0.5229\n",
      "Epoch 902/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2418 - val_loss: 0.5172\n",
      "Epoch 903/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2367 - val_loss: 0.5808\n",
      "Epoch 904/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2388 - val_loss: 0.5351\n",
      "Epoch 905/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2338 - val_loss: 0.5220\n",
      "Epoch 906/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2402 - val_loss: 0.5607\n",
      "Epoch 907/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2389 - val_loss: 0.5384\n",
      "Epoch 908/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2320 - val_loss: 0.5115\n",
      "Epoch 909/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.2392 - val_loss: 0.5330\n",
      "Epoch 910/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2373 - val_loss: 0.5130\n",
      "Epoch 911/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.2448 - val_loss: 0.5453\n",
      "Epoch 912/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.2287 - val_loss: 0.5248\n",
      "Epoch 913/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2286 - val_loss: 0.5286\n",
      "Epoch 914/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2360 - val_loss: 0.5286\n",
      "Epoch 915/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 737us/step - loss: 0.2336 - val_loss: 0.5345\n",
      "Epoch 916/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.2310 - val_loss: 0.5525\n",
      "Epoch 917/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2434 - val_loss: 0.5779\n",
      "Epoch 918/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2472 - val_loss: 0.5087\n",
      "Epoch 919/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2267 - val_loss: 0.5184\n",
      "Epoch 920/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2334 - val_loss: 0.5459\n",
      "Epoch 921/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2308 - val_loss: 0.5302\n",
      "Epoch 922/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2311 - val_loss: 0.5304\n",
      "Epoch 923/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2372 - val_loss: 0.5073\n",
      "Epoch 924/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2290 - val_loss: 0.5215\n",
      "Epoch 925/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.2301 - val_loss: 0.5531\n",
      "Epoch 926/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2321 - val_loss: 0.5195\n",
      "Epoch 927/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.2283 - val_loss: 0.5367\n",
      "Epoch 928/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2380 - val_loss: 0.5375\n",
      "Epoch 929/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.2278 - val_loss: 0.5166\n",
      "Epoch 930/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2332 - val_loss: 0.5326\n",
      "Epoch 931/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2384 - val_loss: 0.5238\n",
      "Epoch 932/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2336 - val_loss: 0.5193\n",
      "Epoch 933/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2303 - val_loss: 0.5544\n",
      "Epoch 934/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2293 - val_loss: 0.5221\n",
      "Epoch 935/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2365 - val_loss: 0.5423\n",
      "Epoch 936/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2247 - val_loss: 0.5260\n",
      "Epoch 937/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2400 - val_loss: 0.5436\n",
      "Epoch 938/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2323 - val_loss: 0.5395\n",
      "Epoch 939/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2389 - val_loss: 0.5178\n",
      "Epoch 940/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2303 - val_loss: 0.5156\n",
      "Epoch 941/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2236 - val_loss: 0.5318\n",
      "Epoch 942/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2377 - val_loss: 0.5178\n",
      "Epoch 943/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2266 - val_loss: 0.5171\n",
      "Epoch 944/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2241 - val_loss: 0.5235\n",
      "Epoch 945/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2371 - val_loss: 0.5059\n",
      "Epoch 946/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2229 - val_loss: 0.5174\n",
      "Epoch 947/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2255 - val_loss: 0.5196\n",
      "Epoch 948/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2211 - val_loss: 0.5160\n",
      "Epoch 949/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2322 - val_loss: 0.5244\n",
      "Epoch 950/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2215 - val_loss: 0.5347\n",
      "Epoch 951/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2272 - val_loss: 0.5360\n",
      "Epoch 952/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2346 - val_loss: 0.5400\n",
      "Epoch 953/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2183 - val_loss: 0.5624\n",
      "Epoch 954/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.2308 - val_loss: 0.5373\n",
      "Epoch 955/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2328 - val_loss: 0.5350\n",
      "Epoch 956/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2276 - val_loss: 0.5478\n",
      "Epoch 957/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2204 - val_loss: 0.5297\n",
      "Epoch 958/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2256 - val_loss: 0.5353\n",
      "Epoch 959/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2276 - val_loss: 0.5243\n",
      "Epoch 960/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2281 - val_loss: 0.5423\n",
      "Epoch 961/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2279 - val_loss: 0.5269\n",
      "Epoch 962/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2327 - val_loss: 0.5167\n",
      "Epoch 963/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2352 - val_loss: 0.5285\n",
      "Epoch 964/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2233 - val_loss: 0.5393\n",
      "Epoch 965/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2309 - val_loss: 0.5224\n",
      "Epoch 966/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.2192 - val_loss: 0.5486\n",
      "Epoch 967/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.2231 - val_loss: 0.5602\n",
      "Epoch 968/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.2173 - val_loss: 0.5284\n",
      "Epoch 969/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2168 - val_loss: 0.5540\n",
      "Epoch 970/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2253 - val_loss: 0.5278\n",
      "Epoch 971/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2387 - val_loss: 0.5083\n",
      "Epoch 972/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2193 - val_loss: 0.5391\n",
      "Epoch 973/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2185 - val_loss: 0.5232\n",
      "Epoch 974/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2182 - val_loss: 0.5662\n",
      "Epoch 975/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2298 - val_loss: 0.5380\n",
      "Epoch 976/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.2233 - val_loss: 0.5238\n",
      "Epoch 977/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.2184 - val_loss: 0.5470\n",
      "Epoch 978/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2207 - val_loss: 0.5246\n",
      "Epoch 979/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2151 - val_loss: 0.5333\n",
      "Epoch 980/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2102 - val_loss: 0.5345\n",
      "Epoch 981/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2179 - val_loss: 0.5393\n",
      "Epoch 982/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.2193 - val_loss: 0.5221\n",
      "Epoch 983/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2257 - val_loss: 0.5268\n",
      "Epoch 984/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2161 - val_loss: 0.5146\n",
      "Epoch 985/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2275 - val_loss: 0.5239\n",
      "Epoch 986/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2302 - val_loss: 0.5139\n",
      "Epoch 987/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2118 - val_loss: 0.5354\n",
      "Epoch 988/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2189 - val_loss: 0.5299\n",
      "Epoch 989/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2213 - val_loss: 0.5483\n",
      "Epoch 990/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2187 - val_loss: 0.5252\n",
      "Epoch 991/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2124 - val_loss: 0.5390\n",
      "Epoch 992/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2175 - val_loss: 0.5367\n",
      "Epoch 993/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2258 - val_loss: 0.5272\n",
      "Epoch 994/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2208 - val_loss: 0.5445\n",
      "Epoch 995/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2143 - val_loss: 0.5374\n",
      "Epoch 996/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2073 - val_loss: 0.5762\n",
      "Epoch 997/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2208 - val_loss: 0.5336\n",
      "Epoch 998/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2150 - val_loss: 0.5225\n",
      "Epoch 999/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2094 - val_loss: 0.5311\n",
      "Epoch 1000/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.2127 - val_loss: 0.5944\n",
      "Epoch 1001/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2122 - val_loss: 0.5364\n",
      "Epoch 1002/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2221 - val_loss: 0.5782\n",
      "Epoch 1003/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2230 - val_loss: 0.5308\n",
      "Epoch 1004/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2088 - val_loss: 0.5553\n",
      "Epoch 1005/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2107 - val_loss: 0.5374\n",
      "Epoch 1006/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.2112 - val_loss: 0.5658\n",
      "Epoch 1007/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2141 - val_loss: 0.5253\n",
      "Epoch 1008/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2199 - val_loss: 0.5429\n",
      "Epoch 1009/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2174 - val_loss: 0.5272\n",
      "Epoch 1010/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2183 - val_loss: 0.5193\n",
      "Epoch 1011/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2073 - val_loss: 0.5666\n",
      "Epoch 1012/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2198 - val_loss: 0.5408\n",
      "Epoch 1013/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.2175 - val_loss: 0.5091\n",
      "Epoch 1014/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2050 - val_loss: 0.5339\n",
      "Epoch 1015/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2076 - val_loss: 0.5350\n",
      "Epoch 1016/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2200 - val_loss: 0.5490\n",
      "Epoch 1017/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.2064 - val_loss: 0.5218\n",
      "Epoch 1018/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2104 - val_loss: 0.5527\n",
      "Epoch 1019/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2109 - val_loss: 0.5265\n",
      "Epoch 1020/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2198 - val_loss: 0.5528\n",
      "Epoch 1021/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2175 - val_loss: 0.5326\n",
      "Epoch 1022/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2208 - val_loss: 0.5379\n",
      "Epoch 1023/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2125 - val_loss: 0.5223\n",
      "Epoch 1024/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1999 - val_loss: 0.5641\n",
      "Epoch 1025/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2160 - val_loss: 0.5542\n",
      "Epoch 1026/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2095 - val_loss: 0.5417\n",
      "Epoch 1027/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2069 - val_loss: 0.5495\n",
      "Epoch 1028/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2050 - val_loss: 0.5644\n",
      "Epoch 1029/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2144 - val_loss: 0.5393\n",
      "Epoch 1030/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2070 - val_loss: 0.5528\n",
      "Epoch 1031/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2107 - val_loss: 0.5408\n",
      "Epoch 1032/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2117 - val_loss: 0.5644\n",
      "Epoch 1033/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2126 - val_loss: 0.5231\n",
      "Epoch 1034/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2087 - val_loss: 0.5294\n",
      "Epoch 1035/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.2036 - val_loss: 0.5346\n",
      "Epoch 1036/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2121 - val_loss: 0.5264\n",
      "Epoch 1037/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2106 - val_loss: 0.5407\n",
      "Epoch 1038/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2075 - val_loss: 0.5427\n",
      "Epoch 1039/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2101 - val_loss: 0.5520\n",
      "Epoch 1040/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2061 - val_loss: 0.5357\n",
      "Epoch 1041/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2098 - val_loss: 0.5242\n",
      "Epoch 1042/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2040 - val_loss: 0.5589\n",
      "Epoch 1043/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2105 - val_loss: 0.5646\n",
      "Epoch 1044/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2128 - val_loss: 0.5256\n",
      "Epoch 1045/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2082 - val_loss: 0.5264\n",
      "Epoch 1046/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.2008 - val_loss: 0.5325\n",
      "Epoch 1047/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2034 - val_loss: 0.5585\n",
      "Epoch 1048/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2143 - val_loss: 0.5399\n",
      "Epoch 1049/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2130 - val_loss: 0.5359\n",
      "Epoch 1050/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.2054 - val_loss: 0.5377\n",
      "Epoch 1051/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2046 - val_loss: 0.5449\n",
      "Epoch 1052/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2028 - val_loss: 0.5446\n",
      "Epoch 1053/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2116 - val_loss: 0.5233\n",
      "Epoch 1054/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1984 - val_loss: 0.5733\n",
      "Epoch 1055/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1993 - val_loss: 0.5596\n",
      "Epoch 1056/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2016 - val_loss: 0.5445\n",
      "Epoch 1057/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2128 - val_loss: 0.5648\n",
      "Epoch 1058/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2147 - val_loss: 0.5271\n",
      "Epoch 1059/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.2044 - val_loss: 0.5387\n",
      "Epoch 1060/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2015 - val_loss: 0.5515\n",
      "Epoch 1061/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2038 - val_loss: 0.5320\n",
      "Epoch 1062/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1967 - val_loss: 0.5348\n",
      "Epoch 1063/10000\n",
      "130/130 [==============================] - 0s 810us/step - loss: 0.2061 - val_loss: 0.5545\n",
      "Epoch 1064/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1990 - val_loss: 0.5521\n",
      "Epoch 1065/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2121 - val_loss: 0.5685\n",
      "Epoch 1066/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2094 - val_loss: 0.5610\n",
      "Epoch 1067/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 749us/step - loss: 0.2169 - val_loss: 0.5418\n",
      "Epoch 1068/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1991 - val_loss: 0.5401\n",
      "Epoch 1069/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1938 - val_loss: 0.5329\n",
      "Epoch 1070/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1972 - val_loss: 0.5378\n",
      "Epoch 1071/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2092 - val_loss: 0.5766\n",
      "Epoch 1072/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2070 - val_loss: 0.5528\n",
      "Epoch 1073/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2012 - val_loss: 0.5420\n",
      "Epoch 1074/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2181 - val_loss: 0.5261\n",
      "Epoch 1075/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1945 - val_loss: 0.5567\n",
      "Epoch 1076/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1986 - val_loss: 0.5680\n",
      "Epoch 1077/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2062 - val_loss: 0.5494\n",
      "Epoch 1078/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1997 - val_loss: 0.5555\n",
      "Epoch 1079/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1985 - val_loss: 0.5436\n",
      "Epoch 1080/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2017 - val_loss: 0.5388\n",
      "Epoch 1081/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1980 - val_loss: 0.5581\n",
      "Epoch 1082/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2054 - val_loss: 0.5226\n",
      "Epoch 1083/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.2093 - val_loss: 0.5468\n",
      "Epoch 1084/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1988 - val_loss: 0.5273\n",
      "Epoch 1085/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1962 - val_loss: 0.5479\n",
      "Epoch 1086/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2079 - val_loss: 0.5742\n",
      "Epoch 1087/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2025 - val_loss: 0.5603\n",
      "Epoch 1088/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2025 - val_loss: 0.5646\n",
      "Epoch 1089/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2061 - val_loss: 0.5703\n",
      "Epoch 1090/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.2019 - val_loss: 0.5374\n",
      "Epoch 1091/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1959 - val_loss: 0.5346\n",
      "Epoch 1092/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1941 - val_loss: 0.5364\n",
      "Epoch 1093/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1930 - val_loss: 0.5486\n",
      "Epoch 1094/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1971 - val_loss: 0.5259\n",
      "Epoch 1095/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1972 - val_loss: 0.5548\n",
      "Epoch 1096/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2066 - val_loss: 0.5426\n",
      "Epoch 1097/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1946 - val_loss: 0.5375\n",
      "Epoch 1098/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.1944 - val_loss: 0.5410\n",
      "Epoch 1099/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1941 - val_loss: 0.5596\n",
      "Epoch 1100/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2039 - val_loss: 0.5476\n",
      "Epoch 1101/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2033 - val_loss: 0.5364\n",
      "Epoch 1102/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1950 - val_loss: 0.5334\n",
      "Epoch 1103/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1968 - val_loss: 0.5495\n",
      "Epoch 1104/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1966 - val_loss: 0.5440\n",
      "Epoch 1105/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2047 - val_loss: 0.5290\n",
      "Epoch 1106/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1951 - val_loss: 0.5452\n",
      "Epoch 1107/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1926 - val_loss: 0.5501\n",
      "Epoch 1108/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1910 - val_loss: 0.5450\n",
      "Epoch 1109/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.2011 - val_loss: 0.5517\n",
      "Epoch 1110/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.2000 - val_loss: 0.5646\n",
      "Epoch 1111/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.1937 - val_loss: 0.5406\n",
      "Epoch 1112/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1970 - val_loss: 0.5483\n",
      "Epoch 1113/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1863 - val_loss: 0.5263\n",
      "Epoch 1114/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2023 - val_loss: 0.5466\n",
      "Epoch 1115/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1951 - val_loss: 0.5714\n",
      "Epoch 1116/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1904 - val_loss: 0.5577\n",
      "Epoch 1117/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1931 - val_loss: 0.5832\n",
      "Epoch 1118/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1966 - val_loss: 0.6057\n",
      "Epoch 1119/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2009 - val_loss: 0.5512\n",
      "Epoch 1120/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1972 - val_loss: 0.5294\n",
      "Epoch 1121/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1972 - val_loss: 0.5421\n",
      "Epoch 1122/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1835 - val_loss: 0.5417\n",
      "Epoch 1123/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1975 - val_loss: 0.5900\n",
      "Epoch 1124/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1961 - val_loss: 0.5400\n",
      "Epoch 1125/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2075 - val_loss: 0.5559\n",
      "Epoch 1126/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1834 - val_loss: 0.5681\n",
      "Epoch 1127/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1846 - val_loss: 0.5403\n",
      "Epoch 1128/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1933 - val_loss: 0.5411\n",
      "Epoch 1129/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1938 - val_loss: 0.5428\n",
      "Epoch 1130/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1927 - val_loss: 0.5556\n",
      "Epoch 1131/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1899 - val_loss: 0.5493\n",
      "Epoch 1132/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1793 - val_loss: 0.5350\n",
      "Epoch 1133/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1926 - val_loss: 0.5500\n",
      "Epoch 1134/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1915 - val_loss: 0.5533\n",
      "Epoch 1135/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1923 - val_loss: 0.5675\n",
      "Epoch 1136/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1821 - val_loss: 0.5891\n",
      "Epoch 1137/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1894 - val_loss: 0.5565\n",
      "Epoch 1138/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1866 - val_loss: 0.5429\n",
      "Epoch 1139/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1928 - val_loss: 0.5374\n",
      "Epoch 1140/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1916 - val_loss: 0.5584\n",
      "Epoch 1141/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1868 - val_loss: 0.5517\n",
      "Epoch 1142/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1936 - val_loss: 0.5328\n",
      "Epoch 1143/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 743us/step - loss: 0.1955 - val_loss: 0.5664\n",
      "Epoch 1144/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.2002 - val_loss: 0.5403\n",
      "Epoch 1145/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.1865 - val_loss: 0.5397\n",
      "Epoch 1146/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1955 - val_loss: 0.5515\n",
      "Epoch 1147/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1863 - val_loss: 0.5346\n",
      "Epoch 1148/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1924 - val_loss: 0.5675\n",
      "Epoch 1149/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1893 - val_loss: 0.5538\n",
      "Epoch 1150/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1906 - val_loss: 0.5481\n",
      "Epoch 1151/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1904 - val_loss: 0.5372\n",
      "Epoch 1152/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1809 - val_loss: 0.5653\n",
      "Epoch 1153/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1810 - val_loss: 0.5667\n",
      "Epoch 1154/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1807 - val_loss: 0.5621\n",
      "Epoch 1155/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1882 - val_loss: 0.5465\n",
      "Epoch 1156/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1828 - val_loss: 0.5508\n",
      "Epoch 1157/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1841 - val_loss: 0.5367\n",
      "Epoch 1158/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1809 - val_loss: 0.5890\n",
      "Epoch 1159/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1895 - val_loss: 0.5970\n",
      "Epoch 1160/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1845 - val_loss: 0.5573\n",
      "Epoch 1161/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1892 - val_loss: 0.5508\n",
      "Epoch 1162/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1882 - val_loss: 0.5231\n",
      "Epoch 1163/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1844 - val_loss: 0.5638\n",
      "Epoch 1164/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1857 - val_loss: 0.5338\n",
      "Epoch 1165/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1856 - val_loss: 0.5541\n",
      "Epoch 1166/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1896 - val_loss: 0.5683\n",
      "Epoch 1167/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.1788 - val_loss: 0.5447\n",
      "Epoch 1168/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1852 - val_loss: 0.5723\n",
      "Epoch 1169/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1886 - val_loss: 0.5421\n",
      "Epoch 1170/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1900 - val_loss: 0.5423\n",
      "Epoch 1171/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1860 - val_loss: 0.5580\n",
      "Epoch 1172/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1804 - val_loss: 0.5334\n",
      "Epoch 1173/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1828 - val_loss: 0.5405\n",
      "Epoch 1174/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1825 - val_loss: 0.5520\n",
      "Epoch 1175/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1858 - val_loss: 0.5444\n",
      "Epoch 1176/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1809 - val_loss: 0.5393\n",
      "Epoch 1177/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1841 - val_loss: 0.5624\n",
      "Epoch 1178/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1834 - val_loss: 0.5665\n",
      "Epoch 1179/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.1930 - val_loss: 0.5659\n",
      "Epoch 1180/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1852 - val_loss: 0.5510\n",
      "Epoch 1181/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1829 - val_loss: 0.5731\n",
      "Epoch 1182/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1817 - val_loss: 0.5363\n",
      "Epoch 1183/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1917 - val_loss: 0.5619\n",
      "Epoch 1184/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.1754 - val_loss: 0.5507\n",
      "Epoch 1185/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1944 - val_loss: 0.5488\n",
      "Epoch 1186/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1799 - val_loss: 0.5457\n",
      "Epoch 1187/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1740 - val_loss: 0.5427\n",
      "Epoch 1188/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.1827 - val_loss: 0.5456\n",
      "Epoch 1189/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1871 - val_loss: 0.5673\n",
      "Epoch 1190/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1927 - val_loss: 0.5277\n",
      "Epoch 1191/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1815 - val_loss: 0.5410\n",
      "Epoch 1192/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1832 - val_loss: 0.5444\n",
      "Epoch 1193/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1781 - val_loss: 0.5312\n",
      "Epoch 1194/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1777 - val_loss: 0.5476\n",
      "Epoch 1195/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1802 - val_loss: 0.5611\n",
      "Epoch 1196/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1822 - val_loss: 0.5425\n",
      "Epoch 1197/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1825 - val_loss: 0.5975\n",
      "Epoch 1198/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.1802 - val_loss: 0.5539\n",
      "Epoch 1199/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1752 - val_loss: 0.5263\n",
      "Epoch 1200/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1795 - val_loss: 0.5566\n",
      "Epoch 1201/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.1743 - val_loss: 0.5652\n",
      "Epoch 1202/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1834 - val_loss: 0.5518\n",
      "Epoch 1203/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1794 - val_loss: 0.5599\n",
      "Epoch 1204/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1776 - val_loss: 0.5649\n",
      "Epoch 1205/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1734 - val_loss: 0.5569\n",
      "Epoch 1206/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1792 - val_loss: 0.5618\n",
      "Epoch 1207/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1740 - val_loss: 0.5416\n",
      "Epoch 1208/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1846 - val_loss: 0.5584\n",
      "Epoch 1209/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1823 - val_loss: 0.5417\n",
      "Epoch 1210/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1821 - val_loss: 0.5652\n",
      "Epoch 1211/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1816 - val_loss: 0.5499\n",
      "Epoch 1212/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1867 - val_loss: 0.5525\n",
      "Epoch 1213/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1732 - val_loss: 0.5651\n",
      "Epoch 1214/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1774 - val_loss: 0.5591\n",
      "Epoch 1215/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1748 - val_loss: 0.5680\n",
      "Epoch 1216/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1800 - val_loss: 0.5719\n",
      "Epoch 1217/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.1876 - val_loss: 0.5558\n",
      "Epoch 1218/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1693 - val_loss: 0.5270\n",
      "Epoch 1219/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 736us/step - loss: 0.1805 - val_loss: 0.5571\n",
      "Epoch 1220/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1808 - val_loss: 0.5617\n",
      "Epoch 1221/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.1715 - val_loss: 0.5365\n",
      "Epoch 1222/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1713 - val_loss: 0.5573\n",
      "Epoch 1223/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1681 - val_loss: 0.5626\n",
      "Epoch 1224/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1776 - val_loss: 0.5627\n",
      "Epoch 1225/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1744 - val_loss: 0.5495\n",
      "Epoch 1226/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1655 - val_loss: 0.5539\n",
      "Epoch 1227/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1736 - val_loss: 0.5459\n",
      "Epoch 1228/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1782 - val_loss: 0.5522\n",
      "Epoch 1229/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1758 - val_loss: 0.5446\n",
      "Epoch 1230/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1760 - val_loss: 0.5713\n",
      "Epoch 1231/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1718 - val_loss: 0.5583\n",
      "Epoch 1232/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1798 - val_loss: 0.5519\n",
      "Epoch 1233/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1736 - val_loss: 0.5340\n",
      "Epoch 1234/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1737 - val_loss: 0.5515\n",
      "Epoch 1235/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1731 - val_loss: 0.5621\n",
      "Epoch 1236/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1787 - val_loss: 0.5450\n",
      "Epoch 1237/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1926 - val_loss: 0.5647\n",
      "Epoch 1238/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1703 - val_loss: 0.5477\n",
      "Epoch 1239/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1769 - val_loss: 0.5666\n",
      "Epoch 1240/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1690 - val_loss: 0.5665\n",
      "Epoch 1241/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1715 - val_loss: 0.5831\n",
      "Epoch 1242/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1713 - val_loss: 0.5593\n",
      "Epoch 1243/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1720 - val_loss: 0.5585\n",
      "Epoch 1244/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1722 - val_loss: 0.5711\n",
      "Epoch 1245/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1755 - val_loss: 0.5472\n",
      "Epoch 1246/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1759 - val_loss: 0.5626\n",
      "Epoch 1247/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1726 - val_loss: 0.5665\n",
      "Epoch 1248/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1700 - val_loss: 0.5872\n",
      "Epoch 1249/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1795 - val_loss: 0.5454\n",
      "Epoch 1250/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1717 - val_loss: 0.5372\n",
      "Epoch 1251/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1697 - val_loss: 0.5532\n",
      "Epoch 1252/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1808 - val_loss: 0.5399\n",
      "Epoch 1253/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1690 - val_loss: 0.5399\n",
      "Epoch 1254/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1715 - val_loss: 0.5703\n",
      "Epoch 1255/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1689 - val_loss: 0.5738\n",
      "Epoch 1256/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1665 - val_loss: 0.5882\n",
      "Epoch 1257/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1764 - val_loss: 0.5360\n",
      "Epoch 1258/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.1720 - val_loss: 0.5724\n",
      "Epoch 1259/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1800 - val_loss: 0.5430\n",
      "Epoch 1260/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1663 - val_loss: 0.5727\n",
      "Epoch 1261/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1724 - val_loss: 0.5813\n",
      "Epoch 1262/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1664 - val_loss: 0.5587\n",
      "Epoch 1263/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1686 - val_loss: 0.5802\n",
      "Epoch 1264/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1780 - val_loss: 0.5652\n",
      "Epoch 1265/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1772 - val_loss: 0.5587\n",
      "Epoch 1266/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1707 - val_loss: 0.5473\n",
      "Epoch 1267/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1681 - val_loss: 0.5612\n",
      "Epoch 1268/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1648 - val_loss: 0.5707\n",
      "Epoch 1269/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.1688 - val_loss: 0.5411\n",
      "Epoch 1270/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1641 - val_loss: 0.5829\n",
      "Epoch 1271/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1647 - val_loss: 0.5676\n",
      "Epoch 1272/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1585 - val_loss: 0.5683\n",
      "Epoch 1273/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1725 - val_loss: 0.5635\n",
      "Epoch 1274/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1782 - val_loss: 0.5528\n",
      "Epoch 1275/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1746 - val_loss: 0.5600\n",
      "Epoch 1276/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1671 - val_loss: 0.5465\n",
      "Epoch 1277/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.1641 - val_loss: 0.5479\n",
      "Epoch 1278/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1711 - val_loss: 0.5590\n",
      "Epoch 1279/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1676 - val_loss: 0.5595\n",
      "Epoch 1280/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1654 - val_loss: 0.5626\n",
      "Epoch 1281/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1644 - val_loss: 0.5813\n",
      "Epoch 1282/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1656 - val_loss: 0.5591\n",
      "Epoch 1283/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1704 - val_loss: 0.5557\n",
      "Epoch 1284/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1687 - val_loss: 0.5630\n",
      "Epoch 1285/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1695 - val_loss: 0.5488\n",
      "Epoch 1286/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1554 - val_loss: 0.5514\n",
      "Epoch 1287/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1665 - val_loss: 0.5563\n",
      "Epoch 1288/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1575 - val_loss: 0.5637\n",
      "Epoch 1289/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1611 - val_loss: 0.5374\n",
      "Epoch 1290/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1625 - val_loss: 0.5745\n",
      "Epoch 1291/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1696 - val_loss: 0.5787\n",
      "Epoch 1292/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1771 - val_loss: 0.5300\n",
      "Epoch 1293/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1627 - val_loss: 0.5522\n",
      "Epoch 1294/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1597 - val_loss: 0.5334\n",
      "Epoch 1295/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 726us/step - loss: 0.1632 - val_loss: 0.5575\n",
      "Epoch 1296/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.1664 - val_loss: 0.5645\n",
      "Epoch 1297/10000\n",
      "130/130 [==============================] - 0s 819us/step - loss: 0.1596 - val_loss: 0.5708\n",
      "Epoch 1298/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.1672 - val_loss: 0.5616\n",
      "Epoch 1299/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1633 - val_loss: 0.5569\n",
      "Epoch 1300/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.1598 - val_loss: 0.5571\n",
      "Epoch 1301/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1571 - val_loss: 0.5575\n",
      "Epoch 1302/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1611 - val_loss: 0.5611\n",
      "Epoch 1303/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.1608 - val_loss: 0.5685\n",
      "Epoch 1304/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.1566 - val_loss: 0.5661\n",
      "Epoch 1305/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1634 - val_loss: 0.6206\n",
      "Epoch 1306/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1691 - val_loss: 0.5498\n",
      "Epoch 1307/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1599 - val_loss: 0.5684\n",
      "Epoch 1308/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1578 - val_loss: 0.5558\n",
      "Epoch 1309/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1739 - val_loss: 0.5447\n",
      "Epoch 1310/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1722 - val_loss: 0.5724\n",
      "Epoch 1311/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1715 - val_loss: 0.5782\n",
      "Epoch 1312/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1575 - val_loss: 0.5649\n",
      "Epoch 1313/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1589 - val_loss: 0.5576\n",
      "Epoch 1314/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1669 - val_loss: 0.5643\n",
      "Epoch 1315/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1669 - val_loss: 0.5447\n",
      "Epoch 1316/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1593 - val_loss: 0.5596\n",
      "Epoch 1317/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1567 - val_loss: 0.5505\n",
      "Epoch 1318/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1596 - val_loss: 0.5652\n",
      "Epoch 1319/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1553 - val_loss: 0.5527\n",
      "Epoch 1320/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.1590 - val_loss: 0.5822\n",
      "Epoch 1321/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1542 - val_loss: 0.5586\n",
      "Epoch 1322/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1568 - val_loss: 0.5449\n",
      "Epoch 1323/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1559 - val_loss: 0.5756\n",
      "Epoch 1324/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1626 - val_loss: 0.5661\n",
      "Epoch 1325/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1729 - val_loss: 0.5682\n",
      "Epoch 1326/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1571 - val_loss: 0.5535\n",
      "Epoch 1327/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1626 - val_loss: 0.5552\n",
      "Epoch 1328/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1535 - val_loss: 0.5361\n",
      "Epoch 1329/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1746 - val_loss: 0.5666\n",
      "Epoch 1330/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1611 - val_loss: 0.5536\n",
      "Epoch 1331/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1557 - val_loss: 0.5719\n",
      "Epoch 1332/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.1502 - val_loss: 0.5635\n",
      "Epoch 1333/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1529 - val_loss: 0.5420\n",
      "Epoch 1334/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1606 - val_loss: 0.5875\n",
      "Epoch 1335/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1543 - val_loss: 0.5693\n",
      "Epoch 1336/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1591 - val_loss: 0.5942\n",
      "Epoch 1337/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1563 - val_loss: 0.5608\n",
      "Epoch 1338/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1597 - val_loss: 0.5548\n",
      "Epoch 1339/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1507 - val_loss: 0.5770\n",
      "Epoch 1340/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1633 - val_loss: 0.5672\n",
      "Epoch 1341/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1501 - val_loss: 0.5532\n",
      "Epoch 1342/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1486 - val_loss: 0.5572\n",
      "Epoch 1343/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1481 - val_loss: 0.5725\n",
      "Epoch 1344/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1565 - val_loss: 0.5700\n",
      "Epoch 1345/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1567 - val_loss: 0.5465\n",
      "Epoch 1346/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1571 - val_loss: 0.5648\n",
      "Epoch 1347/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1587 - val_loss: 0.5609\n",
      "Epoch 1348/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1574 - val_loss: 0.5491\n",
      "Epoch 1349/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1520 - val_loss: 0.5483\n",
      "Epoch 1350/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1539 - val_loss: 0.5718\n",
      "Epoch 1351/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1656 - val_loss: 0.5809\n",
      "Epoch 1352/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1630 - val_loss: 0.5594\n",
      "Epoch 1353/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1587 - val_loss: 0.5681\n",
      "Epoch 1354/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1552 - val_loss: 0.5683\n",
      "Epoch 1355/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1530 - val_loss: 0.5575\n",
      "Epoch 1356/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1539 - val_loss: 0.5440\n",
      "Epoch 1357/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.1532 - val_loss: 0.5611\n",
      "Epoch 1358/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1565 - val_loss: 0.5354\n",
      "Epoch 1359/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1487 - val_loss: 0.5532\n",
      "Epoch 1360/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1523 - val_loss: 0.5967\n",
      "Epoch 1361/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1569 - val_loss: 0.5704\n",
      "Epoch 1362/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1550 - val_loss: 0.5960\n",
      "Epoch 1363/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1662 - val_loss: 0.5484\n",
      "Epoch 1364/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1510 - val_loss: 0.5674\n",
      "Epoch 1365/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.1506 - val_loss: 0.5721\n",
      "Epoch 1366/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1646 - val_loss: 0.5654\n",
      "Epoch 1367/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1474 - val_loss: 0.5715\n",
      "Epoch 1368/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1508 - val_loss: 0.5713\n",
      "Epoch 1369/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.1455 - val_loss: 0.5498\n",
      "Epoch 1370/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.1508 - val_loss: 0.5920\n",
      "Epoch 1371/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 727us/step - loss: 0.1469 - val_loss: 0.5686\n",
      "Epoch 1372/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1544 - val_loss: 0.5711\n",
      "Epoch 1373/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1518 - val_loss: 0.5719\n",
      "Epoch 1374/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1510 - val_loss: 0.5739\n",
      "Epoch 1375/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1471 - val_loss: 0.5646\n",
      "Epoch 1376/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1554 - val_loss: 0.5656\n",
      "Epoch 1377/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1527 - val_loss: 0.5551\n",
      "Epoch 1378/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1524 - val_loss: 0.5554\n",
      "Epoch 1379/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1487 - val_loss: 0.5707\n",
      "Epoch 1380/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1529 - val_loss: 0.5801\n",
      "Epoch 1381/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1516 - val_loss: 0.5621\n",
      "Epoch 1382/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1464 - val_loss: 0.5765\n",
      "Epoch 1383/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1540 - val_loss: 0.5989\n",
      "Epoch 1384/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1598 - val_loss: 0.5492\n",
      "Epoch 1385/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1466 - val_loss: 0.5618\n",
      "Epoch 1386/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1409 - val_loss: 0.5490\n",
      "Epoch 1387/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1530 - val_loss: 0.5647\n",
      "Epoch 1388/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1428 - val_loss: 0.5904\n",
      "Epoch 1389/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.1505 - val_loss: 0.5634\n",
      "Epoch 1390/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.1518 - val_loss: 0.5709\n",
      "Epoch 1391/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.1588 - val_loss: 0.5699\n",
      "Epoch 1392/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.1453 - val_loss: 0.5803\n",
      "Epoch 1393/10000\n",
      "130/130 [==============================] - 0s 867us/step - loss: 0.1537 - val_loss: 0.5439\n",
      "Epoch 1394/10000\n",
      "130/130 [==============================] - 0s 840us/step - loss: 0.1552 - val_loss: 0.5553\n",
      "Epoch 1395/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1425 - val_loss: 0.5736\n",
      "Epoch 1396/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.1500 - val_loss: 0.5512\n",
      "Epoch 1397/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.1490 - val_loss: 0.5654\n",
      "Epoch 1398/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1464 - val_loss: 0.5756\n",
      "Epoch 1399/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1428 - val_loss: 0.5552\n",
      "Epoch 1400/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1471 - val_loss: 0.5634\n",
      "Epoch 1401/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1453 - val_loss: 0.5642\n",
      "Epoch 1402/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1442 - val_loss: 0.5576\n",
      "Epoch 1403/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1432 - val_loss: 0.5535\n",
      "Epoch 1404/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1463 - val_loss: 0.6021\n",
      "Epoch 1405/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1452 - val_loss: 0.6077\n",
      "Epoch 1406/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1682 - val_loss: 0.5609\n",
      "Epoch 1407/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1442 - val_loss: 0.5612\n",
      "Epoch 1408/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1433 - val_loss: 0.5833\n",
      "Epoch 1409/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1475 - val_loss: 0.5506\n",
      "Epoch 1410/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1396 - val_loss: 0.5691\n",
      "Epoch 1411/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1459 - val_loss: 0.5623\n",
      "Epoch 1412/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1500 - val_loss: 0.5763\n",
      "Epoch 1413/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.1576 - val_loss: 0.5895\n",
      "Epoch 1414/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.1447 - val_loss: 0.5818\n",
      "Epoch 1415/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1357 - val_loss: 0.5625\n",
      "Epoch 1416/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1491 - val_loss: 0.5592\n",
      "Epoch 1417/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.1546 - val_loss: 0.5646\n",
      "Epoch 1418/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1386 - val_loss: 0.5746\n",
      "Epoch 1419/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1489 - val_loss: 0.5706\n",
      "Epoch 1420/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1540 - val_loss: 0.5726\n",
      "Epoch 1421/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1442 - val_loss: 0.5583\n",
      "Epoch 1422/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1453 - val_loss: 0.5577\n",
      "Epoch 1423/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1433 - val_loss: 0.5672\n",
      "Epoch 1424/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1372 - val_loss: 0.5814\n",
      "Epoch 1425/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1485 - val_loss: 0.5568\n",
      "Epoch 1426/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1483 - val_loss: 0.5551\n",
      "Epoch 1427/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1469 - val_loss: 0.5548\n",
      "Epoch 1428/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1449 - val_loss: 0.5863\n",
      "Epoch 1429/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1407 - val_loss: 0.5870\n",
      "Epoch 1430/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.1425 - val_loss: 0.5716\n",
      "Epoch 1431/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1424 - val_loss: 0.5728\n",
      "Epoch 1432/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1380 - val_loss: 0.5653\n",
      "Epoch 1433/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1420 - val_loss: 0.5694\n",
      "Epoch 1434/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1432 - val_loss: 0.5602\n",
      "Epoch 1435/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1427 - val_loss: 0.5714\n",
      "Epoch 1436/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1408 - val_loss: 0.5818\n",
      "Epoch 1437/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1417 - val_loss: 0.5493\n",
      "Epoch 1438/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.1368 - val_loss: 0.5686\n",
      "Epoch 1439/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1397 - val_loss: 0.5883\n",
      "Epoch 1440/10000\n",
      "130/130 [==============================] - 0s 809us/step - loss: 0.1434 - val_loss: 0.5933\n",
      "Epoch 1441/10000\n",
      "130/130 [==============================] - 0s 803us/step - loss: 0.1390 - val_loss: 0.5828\n",
      "Epoch 1442/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.1459 - val_loss: 0.5695\n",
      "Epoch 1443/10000\n",
      "130/130 [==============================] - 0s 950us/step - loss: 0.1399 - val_loss: 0.5564\n",
      "Epoch 1444/10000\n",
      "130/130 [==============================] - 0s 919us/step - loss: 0.1343 - val_loss: 0.5684\n",
      "Epoch 1445/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.1432 - val_loss: 0.5657\n",
      "Epoch 1446/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.1440 - val_loss: 0.5578\n",
      "Epoch 1447/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 756us/step - loss: 0.1457 - val_loss: 0.5707\n",
      "Epoch 1448/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.1388 - val_loss: 0.5883\n",
      "Epoch 1449/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1388 - val_loss: 0.5970\n",
      "Epoch 1450/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1441 - val_loss: 0.5773\n",
      "Epoch 1451/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1367 - val_loss: 0.5704\n",
      "Epoch 1452/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1398 - val_loss: 0.5829\n",
      "Epoch 1453/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1422 - val_loss: 0.5622\n",
      "Epoch 1454/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.1336 - val_loss: 0.5686\n",
      "Epoch 1455/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.1475 - val_loss: 0.5644\n",
      "Epoch 1456/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.1477 - val_loss: 0.5494\n",
      "Epoch 1457/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1429 - val_loss: 0.5484\n",
      "Epoch 1458/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1337 - val_loss: 0.5746\n",
      "Epoch 1459/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1447 - val_loss: 0.5651\n",
      "Epoch 1460/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1376 - val_loss: 0.5710\n",
      "Epoch 1461/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1344 - val_loss: 0.5611\n",
      "Epoch 1462/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1373 - val_loss: 0.5746\n",
      "Epoch 1463/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1347 - val_loss: 0.5556\n",
      "Epoch 1464/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1350 - val_loss: 0.5842\n",
      "Epoch 1465/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1446 - val_loss: 0.6076\n",
      "Epoch 1466/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.1413 - val_loss: 0.5766\n",
      "Epoch 1467/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.1374 - val_loss: 0.5660\n",
      "Epoch 1468/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.1369 - val_loss: 0.5560\n",
      "Epoch 1469/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.1346 - val_loss: 0.5786\n",
      "Epoch 1470/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.1358 - val_loss: 0.6117\n",
      "Epoch 1471/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1361 - val_loss: 0.5789\n",
      "Epoch 1472/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1359 - val_loss: 0.5587\n",
      "Epoch 1473/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.1347 - val_loss: 0.5606\n",
      "Epoch 1474/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1456 - val_loss: 0.5769\n",
      "Epoch 1475/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.1439 - val_loss: 0.5750\n",
      "Epoch 1476/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1334 - val_loss: 0.5729\n",
      "Epoch 1477/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1344 - val_loss: 0.5865\n",
      "Epoch 1478/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1396 - val_loss: 0.5944\n",
      "Epoch 1479/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1381 - val_loss: 0.5690\n",
      "Epoch 1480/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1293 - val_loss: 0.5680\n",
      "Epoch 1481/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1365 - val_loss: 0.5690\n",
      "Epoch 1482/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1321 - val_loss: 0.5677\n",
      "Epoch 1483/10000\n",
      "130/130 [==============================] - 0s 883us/step - loss: 0.1447 - val_loss: 0.5549\n",
      "Epoch 1484/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.1383 - val_loss: 0.5780\n",
      "Epoch 1485/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1305 - val_loss: 0.5575\n",
      "Epoch 1486/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.1304 - val_loss: 0.5643\n",
      "Epoch 1487/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.1413 - val_loss: 0.5716\n",
      "Epoch 1488/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1378 - val_loss: 0.5816\n",
      "Epoch 1489/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1345 - val_loss: 0.5605\n",
      "Epoch 1490/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.1287 - val_loss: 0.5641\n",
      "Epoch 1491/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1313 - val_loss: 0.5629\n",
      "Epoch 1492/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1339 - val_loss: 0.5619\n",
      "Epoch 1493/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.1337 - val_loss: 0.5693\n",
      "Epoch 1494/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1343 - val_loss: 0.5875\n",
      "Epoch 1495/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.1414 - val_loss: 0.6014\n",
      "Epoch 1496/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1415 - val_loss: 0.5732\n",
      "Epoch 1497/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1307 - val_loss: 0.5839\n",
      "Epoch 1498/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.1350 - val_loss: 0.5647\n",
      "Epoch 1499/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1299 - val_loss: 0.5768\n",
      "Epoch 1500/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1302 - val_loss: 0.5593\n",
      "Epoch 1501/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1271 - val_loss: 0.5686\n",
      "Epoch 1502/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.1323 - val_loss: 0.5691\n",
      "Epoch 1503/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1397 - val_loss: 0.5801\n",
      "Epoch 1504/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1385 - val_loss: 0.5729\n",
      "Epoch 1505/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.1313 - val_loss: 0.5844\n",
      "Epoch 1506/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1298 - val_loss: 0.5863\n",
      "Epoch 1507/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.1334 - val_loss: 0.5646\n",
      "Epoch 1508/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1349 - val_loss: 0.5765\n",
      "Epoch 1509/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1317 - val_loss: 0.5896\n",
      "Epoch 1510/10000\n",
      "130/130 [==============================] - 0s 885us/step - loss: 0.1245 - val_loss: 0.5826\n",
      "Epoch 1511/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.1307 - val_loss: 0.5602\n",
      "Epoch 1512/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.1372 - val_loss: 0.5709\n",
      "Epoch 1513/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.1359 - val_loss: 0.5751\n",
      "Epoch 1514/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1403 - val_loss: 0.5846\n",
      "Epoch 1515/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1273 - val_loss: 0.5862\n",
      "Epoch 1516/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1295 - val_loss: 0.5678\n",
      "Epoch 1517/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1368 - val_loss: 0.5618\n",
      "Epoch 1518/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1303 - val_loss: 0.5820\n",
      "Epoch 1519/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1362 - val_loss: 0.5535\n",
      "Epoch 1520/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1289 - val_loss: 0.5741\n",
      "Epoch 1521/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1370 - val_loss: 0.5613\n",
      "Epoch 1522/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1410 - val_loss: 0.5761\n",
      "Epoch 1523/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 744us/step - loss: 0.1372 - val_loss: 0.5653\n",
      "Epoch 1524/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.1229 - val_loss: 0.5811\n",
      "Epoch 1525/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1312 - val_loss: 0.5899\n",
      "Epoch 1526/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1338 - val_loss: 0.5497\n",
      "Epoch 1527/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1323 - val_loss: 0.5780\n",
      "Epoch 1528/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1330 - val_loss: 0.5808\n",
      "Epoch 1529/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1272 - val_loss: 0.6030\n",
      "Epoch 1530/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1249 - val_loss: 0.5621\n",
      "Epoch 1531/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1300 - val_loss: 0.5799\n",
      "Epoch 1532/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1335 - val_loss: 0.5692\n",
      "Epoch 1533/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1263 - val_loss: 0.5721\n",
      "Epoch 1534/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1292 - val_loss: 0.5656\n",
      "Epoch 1535/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1402 - val_loss: 0.5821\n",
      "Epoch 1536/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1256 - val_loss: 0.5760\n",
      "Epoch 1537/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1343 - val_loss: 0.5718\n",
      "Epoch 1538/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1322 - val_loss: 0.5656\n",
      "Epoch 1539/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1266 - val_loss: 0.5686\n",
      "Epoch 1540/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1338 - val_loss: 0.5848\n",
      "Epoch 1541/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1326 - val_loss: 0.5770\n",
      "Epoch 1542/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1344 - val_loss: 0.5829\n",
      "Epoch 1543/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1281 - val_loss: 0.5622\n",
      "Epoch 1544/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1217 - val_loss: 0.5880\n",
      "Epoch 1545/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1265 - val_loss: 0.5857\n",
      "Epoch 1546/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1301 - val_loss: 0.5656\n",
      "Epoch 1547/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1229 - val_loss: 0.5812\n",
      "Epoch 1548/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1357 - val_loss: 0.5592\n",
      "Epoch 1549/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1315 - val_loss: 0.5904\n",
      "Epoch 1550/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1264 - val_loss: 0.6117\n",
      "Epoch 1551/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1308 - val_loss: 0.5716\n",
      "Epoch 1552/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1288 - val_loss: 0.5575\n",
      "Epoch 1553/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1308 - val_loss: 0.5518\n",
      "Epoch 1554/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1195 - val_loss: 0.5779\n",
      "Epoch 1555/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1305 - val_loss: 0.5786\n",
      "Epoch 1556/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.1303 - val_loss: 0.5988\n",
      "Epoch 1557/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1367 - val_loss: 0.5634\n",
      "Epoch 1558/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1241 - val_loss: 0.5843\n",
      "Epoch 1559/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.1274 - val_loss: 0.5777\n",
      "Epoch 1560/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1367 - val_loss: 0.5697\n",
      "Epoch 1561/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1176 - val_loss: 0.5652\n",
      "Epoch 1562/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1183 - val_loss: 0.5781\n",
      "Epoch 1563/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1189 - val_loss: 0.5618\n",
      "Epoch 1564/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1318 - val_loss: 0.5910\n",
      "Epoch 1565/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1355 - val_loss: 0.5569\n",
      "Epoch 1566/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1372 - val_loss: 0.5676\n",
      "Epoch 1567/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1262 - val_loss: 0.5703\n",
      "Epoch 1568/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1318 - val_loss: 0.5711\n",
      "Epoch 1569/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1356 - val_loss: 0.5767\n",
      "Epoch 1570/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1256 - val_loss: 0.5660\n",
      "Epoch 1571/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1243 - val_loss: 0.5681\n",
      "Epoch 1572/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1234 - val_loss: 0.5795\n",
      "Epoch 1573/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1270 - val_loss: 0.5673\n",
      "Epoch 1574/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1258 - val_loss: 0.5650\n",
      "Epoch 1575/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1241 - val_loss: 0.5765\n",
      "Epoch 1576/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1248 - val_loss: 0.5673\n",
      "Epoch 1577/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1346 - val_loss: 0.5811\n",
      "Epoch 1578/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1283 - val_loss: 0.5965\n",
      "Epoch 1579/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1327 - val_loss: 0.5730\n",
      "Epoch 1580/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1300 - val_loss: 0.6233\n",
      "Epoch 1581/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1238 - val_loss: 0.5517\n",
      "Epoch 1582/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1167 - val_loss: 0.5852\n",
      "Epoch 1583/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1221 - val_loss: 0.5797\n",
      "Epoch 1584/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1202 - val_loss: 0.5782\n",
      "Epoch 1585/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1171 - val_loss: 0.5904\n",
      "Epoch 1586/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.1258 - val_loss: 0.5862\n",
      "Epoch 1587/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1408 - val_loss: 0.5835\n",
      "Epoch 1588/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1315 - val_loss: 0.5865\n",
      "Epoch 1589/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1231 - val_loss: 0.5673\n",
      "Epoch 1590/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1205 - val_loss: 0.5816\n",
      "Epoch 1591/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1195 - val_loss: 0.5870\n",
      "Epoch 1592/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1158 - val_loss: 0.5937\n",
      "Epoch 1593/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1265 - val_loss: 0.5872\n",
      "Epoch 1594/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1282 - val_loss: 0.5744\n",
      "Epoch 1595/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1324 - val_loss: 0.5704\n",
      "Epoch 1596/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1163 - val_loss: 0.5653\n",
      "Epoch 1597/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1338 - val_loss: 0.5767\n",
      "Epoch 1598/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1281 - val_loss: 0.5879\n",
      "Epoch 1599/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 760us/step - loss: 0.1201 - val_loss: 0.5566\n",
      "Epoch 1600/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1242 - val_loss: 0.5844\n",
      "Epoch 1601/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1203 - val_loss: 0.5533\n",
      "Epoch 1602/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1127 - val_loss: 0.5832\n",
      "Epoch 1603/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1215 - val_loss: 0.5643\n",
      "Epoch 1604/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1262 - val_loss: 0.5772\n",
      "Epoch 1605/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1213 - val_loss: 0.5982\n",
      "Epoch 1606/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1195 - val_loss: 0.5818\n",
      "Epoch 1607/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1221 - val_loss: 0.5765\n",
      "Epoch 1608/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1144 - val_loss: 0.6074\n",
      "Epoch 1609/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1238 - val_loss: 0.5953\n",
      "Epoch 1610/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1264 - val_loss: 0.5865\n",
      "Epoch 1611/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1235 - val_loss: 0.5680\n",
      "Epoch 1612/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.1358 - val_loss: 0.5760\n",
      "Epoch 1613/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1194 - val_loss: 0.5925\n",
      "Epoch 1614/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1200 - val_loss: 0.5898\n",
      "Epoch 1615/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1227 - val_loss: 0.5801\n",
      "Epoch 1616/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1178 - val_loss: 0.5783\n",
      "Epoch 1617/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.1164 - val_loss: 0.5560\n",
      "Epoch 1618/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1186 - val_loss: 0.5683\n",
      "Epoch 1619/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.1204 - val_loss: 0.5874\n",
      "Epoch 1620/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1185 - val_loss: 0.5775\n",
      "Epoch 1621/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1302 - val_loss: 0.5974\n",
      "Epoch 1622/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1318 - val_loss: 0.5453\n",
      "Epoch 1623/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1210 - val_loss: 0.5808\n",
      "Epoch 1624/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1133 - val_loss: 0.5797\n",
      "Epoch 1625/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1140 - val_loss: 0.5758\n",
      "Epoch 1626/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1184 - val_loss: 0.5667\n",
      "Epoch 1627/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1205 - val_loss: 0.5606\n",
      "Epoch 1628/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1140 - val_loss: 0.5646\n",
      "Epoch 1629/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1135 - val_loss: 0.5872\n",
      "Epoch 1630/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.1238 - val_loss: 0.5682\n",
      "Epoch 1631/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1226 - val_loss: 0.5579\n",
      "Epoch 1632/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1184 - val_loss: 0.5612\n",
      "Epoch 1633/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.1207 - val_loss: 0.6073\n",
      "Epoch 1634/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1255 - val_loss: 0.5653\n",
      "Epoch 1635/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1174 - val_loss: 0.5952\n",
      "Epoch 1636/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1160 - val_loss: 0.5898\n",
      "Epoch 1637/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1127 - val_loss: 0.5821\n",
      "Epoch 1638/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1213 - val_loss: 0.5775\n",
      "Epoch 1639/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1213 - val_loss: 0.5799\n",
      "Epoch 1640/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1207 - val_loss: 0.5596\n",
      "Epoch 1641/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1149 - val_loss: 0.5969\n",
      "Epoch 1642/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1191 - val_loss: 0.6031\n",
      "Epoch 1643/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1439 - val_loss: 0.6045\n",
      "Epoch 1644/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1185 - val_loss: 0.5701\n",
      "Epoch 1645/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1143 - val_loss: 0.5917\n",
      "Epoch 1646/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1178 - val_loss: 0.5867\n",
      "Epoch 1647/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.1108 - val_loss: 0.5722\n",
      "Epoch 1648/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1130 - val_loss: 0.6037\n",
      "Epoch 1649/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1190 - val_loss: 0.5623\n",
      "Epoch 1650/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1109 - val_loss: 0.5890\n",
      "Epoch 1651/10000\n",
      "130/130 [==============================] - 0s 858us/step - loss: 0.1187 - val_loss: 0.5746\n",
      "Epoch 1652/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1183 - val_loss: 0.5670\n",
      "Epoch 1653/10000\n",
      "130/130 [==============================] - 0s 871us/step - loss: 0.1215 - val_loss: 0.5851\n",
      "Epoch 1654/10000\n",
      "130/130 [==============================] - 0s 803us/step - loss: 0.1170 - val_loss: 0.5670\n",
      "Epoch 1655/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1248 - val_loss: 0.5779\n",
      "Epoch 1656/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1113 - val_loss: 0.5597\n",
      "Epoch 1657/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1157 - val_loss: 0.5970\n",
      "Epoch 1658/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.1171 - val_loss: 0.5740\n",
      "Epoch 1659/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1157 - val_loss: 0.5888\n",
      "Epoch 1660/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1200 - val_loss: 0.5732\n",
      "Epoch 1661/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1106 - val_loss: 0.5786\n",
      "Epoch 1662/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.1116 - val_loss: 0.5963\n",
      "Epoch 1663/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1140 - val_loss: 0.5718\n",
      "Epoch 1664/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1258 - val_loss: 0.5923\n",
      "Epoch 1665/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1207 - val_loss: 0.5936\n",
      "Epoch 1666/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1150 - val_loss: 0.5793\n",
      "Epoch 1667/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1189 - val_loss: 0.5915\n",
      "Epoch 1668/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1147 - val_loss: 0.5836\n",
      "Epoch 1669/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1113 - val_loss: 0.5984\n",
      "Epoch 1670/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1151 - val_loss: 0.6081\n",
      "Epoch 1671/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1190 - val_loss: 0.5618\n",
      "Epoch 1672/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1140 - val_loss: 0.5670\n",
      "Epoch 1673/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1128 - val_loss: 0.6013\n",
      "Epoch 1674/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1105 - val_loss: 0.5745\n",
      "Epoch 1675/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 745us/step - loss: 0.1143 - val_loss: 0.5890\n",
      "Epoch 1676/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1176 - val_loss: 0.5641\n",
      "Epoch 1677/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1129 - val_loss: 0.5947\n",
      "Epoch 1678/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1121 - val_loss: 0.5890\n",
      "Epoch 1679/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1188 - val_loss: 0.5731\n",
      "Epoch 1680/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1138 - val_loss: 0.5815\n",
      "Epoch 1681/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1287 - val_loss: 0.5964\n",
      "Epoch 1682/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1236 - val_loss: 0.5682\n",
      "Epoch 1683/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1073 - val_loss: 0.5719\n",
      "Epoch 1684/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1115 - val_loss: 0.5845\n",
      "Epoch 1685/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1249 - val_loss: 0.5967\n",
      "Epoch 1686/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1201 - val_loss: 0.5902\n",
      "Epoch 1687/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1110 - val_loss: 0.6076\n",
      "Epoch 1688/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1403 - val_loss: 0.5895\n",
      "Epoch 1689/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1077 - val_loss: 0.5837\n",
      "Epoch 1690/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1133 - val_loss: 0.5875\n",
      "Epoch 1691/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1155 - val_loss: 0.5758\n",
      "Epoch 1692/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1151 - val_loss: 0.5648\n",
      "Epoch 1693/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1097 - val_loss: 0.5746\n",
      "Epoch 1694/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1134 - val_loss: 0.5729\n",
      "Epoch 1695/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1100 - val_loss: 0.5714\n",
      "Epoch 1696/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1139 - val_loss: 0.5939\n",
      "Epoch 1697/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1061 - val_loss: 0.5865\n",
      "Epoch 1698/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1083 - val_loss: 0.5830\n",
      "Epoch 1699/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1137 - val_loss: 0.5747\n",
      "Epoch 1700/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1125 - val_loss: 0.6047\n",
      "Epoch 1701/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1149 - val_loss: 0.6072\n",
      "Epoch 1702/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1104 - val_loss: 0.5656\n",
      "Epoch 1703/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1241 - val_loss: 0.5946\n",
      "Epoch 1704/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1126 - val_loss: 0.5864\n",
      "Epoch 1705/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1098 - val_loss: 0.5888\n",
      "Epoch 1706/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1117 - val_loss: 0.5913\n",
      "Epoch 1707/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1051 - val_loss: 0.5922\n",
      "Epoch 1708/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1076 - val_loss: 0.5775\n",
      "Epoch 1709/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1116 - val_loss: 0.5836\n",
      "Epoch 1710/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1055 - val_loss: 0.5963\n",
      "Epoch 1711/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1126 - val_loss: 0.5694\n",
      "Epoch 1712/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1130 - val_loss: 0.5623\n",
      "Epoch 1713/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1086 - val_loss: 0.5960\n",
      "Epoch 1714/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1065 - val_loss: 0.5859\n",
      "Epoch 1715/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1194 - val_loss: 0.5817\n",
      "Epoch 1716/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1088 - val_loss: 0.5756\n",
      "Epoch 1717/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1284 - val_loss: 0.6073\n",
      "Epoch 1718/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1067 - val_loss: 0.5702\n",
      "Epoch 1719/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1084 - val_loss: 0.5913\n",
      "Epoch 1720/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1098 - val_loss: 0.5782\n",
      "Epoch 1721/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1110 - val_loss: 0.5727\n",
      "Epoch 1722/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1131 - val_loss: 0.5829\n",
      "Epoch 1723/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1031 - val_loss: 0.5891\n",
      "Epoch 1724/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1045 - val_loss: 0.5983\n",
      "Epoch 1725/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1120 - val_loss: 0.5945\n",
      "Epoch 1726/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1142 - val_loss: 0.5752\n",
      "Epoch 1727/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1145 - val_loss: 0.5764\n",
      "Epoch 1728/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1098 - val_loss: 0.5730\n",
      "Epoch 1729/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1063 - val_loss: 0.5842\n",
      "Epoch 1730/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1059 - val_loss: 0.5791\n",
      "Epoch 1731/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1031 - val_loss: 0.5813\n",
      "Epoch 1732/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1122 - val_loss: 0.5937\n",
      "Epoch 1733/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1063 - val_loss: 0.5703\n",
      "Epoch 1734/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1103 - val_loss: 0.6004\n",
      "Epoch 1735/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1128 - val_loss: 0.5699\n",
      "Epoch 1736/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1074 - val_loss: 0.6009\n",
      "Epoch 1737/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1226 - val_loss: 0.5793\n",
      "Epoch 1738/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1109 - val_loss: 0.6109\n",
      "Epoch 1739/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1142 - val_loss: 0.5941\n",
      "Epoch 1740/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1050 - val_loss: 0.5910\n",
      "Epoch 1741/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.1105 - val_loss: 0.5980\n",
      "Epoch 1742/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1074 - val_loss: 0.5849\n",
      "Epoch 1743/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1121 - val_loss: 0.5808\n",
      "Epoch 1744/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1101 - val_loss: 0.5739\n",
      "Epoch 1745/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.1089 - val_loss: 0.5666\n",
      "Epoch 1746/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.1081 - val_loss: 0.5855\n",
      "Epoch 1747/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1048 - val_loss: 0.5913\n",
      "Epoch 1748/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.1061 - val_loss: 0.5799\n",
      "Epoch 1749/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1142 - val_loss: 0.5734\n",
      "Epoch 1750/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0990 - val_loss: 0.5727\n",
      "Epoch 1751/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 762us/step - loss: 0.1070 - val_loss: 0.5941\n",
      "Epoch 1752/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1118 - val_loss: 0.5838\n",
      "Epoch 1753/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1104 - val_loss: 0.6019\n",
      "Epoch 1754/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1049 - val_loss: 0.5822\n",
      "Epoch 1755/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.1081 - val_loss: 0.5995\n",
      "Epoch 1756/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1309 - val_loss: 0.5903\n",
      "Epoch 1757/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1108 - val_loss: 0.6204\n",
      "Epoch 1758/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1038 - val_loss: 0.5998\n",
      "Epoch 1759/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1014 - val_loss: 0.5693\n",
      "Epoch 1760/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1026 - val_loss: 0.5711\n",
      "Epoch 1761/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1039 - val_loss: 0.6068\n",
      "Epoch 1762/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1056 - val_loss: 0.5985\n",
      "Epoch 1763/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1147 - val_loss: 0.5730\n",
      "Epoch 1764/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1093 - val_loss: 0.5910\n",
      "Epoch 1765/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1130 - val_loss: 0.5917\n",
      "Epoch 1766/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1235 - val_loss: 0.5902\n",
      "Epoch 1767/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1072 - val_loss: 0.5942\n",
      "Epoch 1768/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.1044 - val_loss: 0.5819\n",
      "Epoch 1769/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0998 - val_loss: 0.5847\n",
      "Epoch 1770/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1132 - val_loss: 0.5802\n",
      "Epoch 1771/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1098 - val_loss: 0.6055\n",
      "Epoch 1772/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1110 - val_loss: 0.5972\n",
      "Epoch 1773/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1108 - val_loss: 0.5790\n",
      "Epoch 1774/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1042 - val_loss: 0.5839\n",
      "Epoch 1775/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1033 - val_loss: 0.5721\n",
      "Epoch 1776/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1012 - val_loss: 0.5893\n",
      "Epoch 1777/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1095 - val_loss: 0.5797\n",
      "Epoch 1778/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1098 - val_loss: 0.5810\n",
      "Epoch 1779/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1045 - val_loss: 0.5968\n",
      "Epoch 1780/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1167 - val_loss: 0.5968\n",
      "Epoch 1781/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.1079 - val_loss: 0.5738\n",
      "Epoch 1782/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.1011 - val_loss: 0.6006\n",
      "Epoch 1783/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1056 - val_loss: 0.5900\n",
      "Epoch 1784/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1062 - val_loss: 0.5927\n",
      "Epoch 1785/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1048 - val_loss: 0.5894\n",
      "Epoch 1786/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1091 - val_loss: 0.6325\n",
      "Epoch 1787/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1160 - val_loss: 0.5829\n",
      "Epoch 1788/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1056 - val_loss: 0.5922\n",
      "Epoch 1789/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1029 - val_loss: 0.5773\n",
      "Epoch 1790/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1085 - val_loss: 0.5846\n",
      "Epoch 1791/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1164 - val_loss: 0.5803\n",
      "Epoch 1792/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.1015 - val_loss: 0.5719\n",
      "Epoch 1793/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1045 - val_loss: 0.5867\n",
      "Epoch 1794/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1179 - val_loss: 0.5728\n",
      "Epoch 1795/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0968 - val_loss: 0.5936\n",
      "Epoch 1796/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1003 - val_loss: 0.5760\n",
      "Epoch 1797/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0999 - val_loss: 0.5975\n",
      "Epoch 1798/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1025 - val_loss: 0.5905\n",
      "Epoch 1799/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1017 - val_loss: 0.6030\n",
      "Epoch 1800/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1066 - val_loss: 0.5758\n",
      "Epoch 1801/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1043 - val_loss: 0.5872\n",
      "Epoch 1802/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1137 - val_loss: 0.5799\n",
      "Epoch 1803/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1077 - val_loss: 0.5802\n",
      "Epoch 1804/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1145 - val_loss: 0.6206\n",
      "Epoch 1805/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1094 - val_loss: 0.5793\n",
      "Epoch 1806/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0970 - val_loss: 0.5773\n",
      "Epoch 1807/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1004 - val_loss: 0.6278\n",
      "Epoch 1808/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1074 - val_loss: 0.5757\n",
      "Epoch 1809/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1040 - val_loss: 0.5885\n",
      "Epoch 1810/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1082 - val_loss: 0.5865\n",
      "Epoch 1811/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1002 - val_loss: 0.5708\n",
      "Epoch 1812/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0996 - val_loss: 0.6039\n",
      "Epoch 1813/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1059 - val_loss: 0.5860\n",
      "Epoch 1814/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0993 - val_loss: 0.5817\n",
      "Epoch 1815/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0975 - val_loss: 0.5976\n",
      "Epoch 1816/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1009 - val_loss: 0.5993\n",
      "Epoch 1817/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1059 - val_loss: 0.6064\n",
      "Epoch 1818/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0967 - val_loss: 0.5871\n",
      "Epoch 1819/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0985 - val_loss: 0.6112\n",
      "Epoch 1820/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1098 - val_loss: 0.5840\n",
      "Epoch 1821/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0915 - val_loss: 0.5830\n",
      "Epoch 1822/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0990 - val_loss: 0.5722\n",
      "Epoch 1823/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1092 - val_loss: 0.5964\n",
      "Epoch 1824/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1032 - val_loss: 0.5800\n",
      "Epoch 1825/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1035 - val_loss: 0.5903\n",
      "Epoch 1826/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0997 - val_loss: 0.5854\n",
      "Epoch 1827/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 748us/step - loss: 0.0991 - val_loss: 0.5978\n",
      "Epoch 1828/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1046 - val_loss: 0.5884\n",
      "Epoch 1829/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0995 - val_loss: 0.5778\n",
      "Epoch 1830/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0932 - val_loss: 0.5808\n",
      "Epoch 1831/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1063 - val_loss: 0.6084\n",
      "Epoch 1832/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1118 - val_loss: 0.6270\n",
      "Epoch 1833/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1065 - val_loss: 0.5966\n",
      "Epoch 1834/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0982 - val_loss: 0.6169\n",
      "Epoch 1835/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1013 - val_loss: 0.5960\n",
      "Epoch 1836/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1015 - val_loss: 0.5931\n",
      "Epoch 1837/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0990 - val_loss: 0.5948\n",
      "Epoch 1838/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0963 - val_loss: 0.6147\n",
      "Epoch 1839/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0987 - val_loss: 0.6096\n",
      "Epoch 1840/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0985 - val_loss: 0.5764\n",
      "Epoch 1841/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0966 - val_loss: 0.5931\n",
      "Epoch 1842/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1010 - val_loss: 0.5968\n",
      "Epoch 1843/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1022 - val_loss: 0.5869\n",
      "Epoch 1844/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0996 - val_loss: 0.5950\n",
      "Epoch 1845/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0952 - val_loss: 0.6039\n",
      "Epoch 1846/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1038 - val_loss: 0.5897\n",
      "Epoch 1847/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1170 - val_loss: 0.5856\n",
      "Epoch 1848/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1004 - val_loss: 0.5862\n",
      "Epoch 1849/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0974 - val_loss: 0.5847\n",
      "Epoch 1850/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0946 - val_loss: 0.5846\n",
      "Epoch 1851/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0956 - val_loss: 0.5936\n",
      "Epoch 1852/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1073 - val_loss: 0.5863\n",
      "Epoch 1853/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0998 - val_loss: 0.5900\n",
      "Epoch 1854/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.1029 - val_loss: 0.5920\n",
      "Epoch 1855/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0982 - val_loss: 0.6147\n",
      "Epoch 1856/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0981 - val_loss: 0.5903\n",
      "Epoch 1857/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0965 - val_loss: 0.5807\n",
      "Epoch 1858/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0956 - val_loss: 0.5776\n",
      "Epoch 1859/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0983 - val_loss: 0.5960\n",
      "Epoch 1860/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0972 - val_loss: 0.5976\n",
      "Epoch 1861/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0976 - val_loss: 0.5870\n",
      "Epoch 1862/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0949 - val_loss: 0.5838\n",
      "Epoch 1863/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1070 - val_loss: 0.5991\n",
      "Epoch 1864/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1060 - val_loss: 0.5920\n",
      "Epoch 1865/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1050 - val_loss: 0.5792\n",
      "Epoch 1866/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0912 - val_loss: 0.6020\n",
      "Epoch 1867/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1010 - val_loss: 0.5707\n",
      "Epoch 1868/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1085 - val_loss: 0.5895\n",
      "Epoch 1869/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1013 - val_loss: 0.5991\n",
      "Epoch 1870/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0996 - val_loss: 0.5853\n",
      "Epoch 1871/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1011 - val_loss: 0.6018\n",
      "Epoch 1872/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0928 - val_loss: 0.6122\n",
      "Epoch 1873/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0973 - val_loss: 0.6295\n",
      "Epoch 1874/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1148 - val_loss: 0.5838\n",
      "Epoch 1875/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0963 - val_loss: 0.6252\n",
      "Epoch 1876/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0928 - val_loss: 0.5941\n",
      "Epoch 1877/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0982 - val_loss: 0.6022\n",
      "Epoch 1878/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1078 - val_loss: 0.6112\n",
      "Epoch 1879/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0990 - val_loss: 0.5866\n",
      "Epoch 1880/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0996 - val_loss: 0.5855\n",
      "Epoch 1881/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0935 - val_loss: 0.6037\n",
      "Epoch 1882/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0945 - val_loss: 0.5779\n",
      "Epoch 1883/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1031 - val_loss: 0.5960\n",
      "Epoch 1884/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.1073 - val_loss: 0.5816\n",
      "Epoch 1885/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1009 - val_loss: 0.5844\n",
      "Epoch 1886/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0947 - val_loss: 0.5863\n",
      "Epoch 1887/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0974 - val_loss: 0.5980\n",
      "Epoch 1888/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1009 - val_loss: 0.5791\n",
      "Epoch 1889/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0904 - val_loss: 0.6052\n",
      "Epoch 1890/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0973 - val_loss: 0.5818\n",
      "Epoch 1891/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1029 - val_loss: 0.5933\n",
      "Epoch 1892/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0974 - val_loss: 0.5832\n",
      "Epoch 1893/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0962 - val_loss: 0.5921\n",
      "Epoch 1894/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0924 - val_loss: 0.5726\n",
      "Epoch 1895/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0947 - val_loss: 0.5676\n",
      "Epoch 1896/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1011 - val_loss: 0.5815\n",
      "Epoch 1897/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0976 - val_loss: 0.5909\n",
      "Epoch 1898/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0940 - val_loss: 0.5774\n",
      "Epoch 1899/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1000 - val_loss: 0.5971\n",
      "Epoch 1900/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0947 - val_loss: 0.5821\n",
      "Epoch 1901/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0907 - val_loss: 0.5832\n",
      "Epoch 1902/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0916 - val_loss: 0.6262\n",
      "Epoch 1903/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 754us/step - loss: 0.0924 - val_loss: 0.6036\n",
      "Epoch 1904/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0924 - val_loss: 0.5910\n",
      "Epoch 1905/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0980 - val_loss: 0.6025\n",
      "Epoch 1906/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0976 - val_loss: 0.5911\n",
      "Epoch 1907/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0944 - val_loss: 0.5871\n",
      "Epoch 1908/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0917 - val_loss: 0.5949\n",
      "Epoch 1909/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0937 - val_loss: 0.6020\n",
      "Epoch 1910/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0951 - val_loss: 0.5877\n",
      "Epoch 1911/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0911 - val_loss: 0.6117\n",
      "Epoch 1912/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0990 - val_loss: 0.5874\n",
      "Epoch 1913/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0892 - val_loss: 0.6070\n",
      "Epoch 1914/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0926 - val_loss: 0.5944\n",
      "Epoch 1915/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1012 - val_loss: 0.5803\n",
      "Epoch 1916/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1035 - val_loss: 0.5868\n",
      "Epoch 1917/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0957 - val_loss: 0.5960\n",
      "Epoch 1918/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0968 - val_loss: 0.6344\n",
      "Epoch 1919/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0965 - val_loss: 0.6010\n",
      "Epoch 1920/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0999 - val_loss: 0.5988\n",
      "Epoch 1921/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0963 - val_loss: 0.6007\n",
      "Epoch 1922/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1023 - val_loss: 0.5870\n",
      "Epoch 1923/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1033 - val_loss: 0.5984\n",
      "Epoch 1924/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0889 - val_loss: 0.5990\n",
      "Epoch 1925/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0891 - val_loss: 0.6080\n",
      "Epoch 1926/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0990 - val_loss: 0.6005\n",
      "Epoch 1927/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0962 - val_loss: 0.5964\n",
      "Epoch 1928/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1004 - val_loss: 0.5881\n",
      "Epoch 1929/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0987 - val_loss: 0.5825\n",
      "Epoch 1930/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0929 - val_loss: 0.6076\n",
      "Epoch 1931/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0890 - val_loss: 0.5744\n",
      "Epoch 1932/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0921 - val_loss: 0.6008\n",
      "Epoch 1933/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0895 - val_loss: 0.5873\n",
      "Epoch 1934/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0941 - val_loss: 0.5894\n",
      "Epoch 1935/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0867 - val_loss: 0.5811\n",
      "Epoch 1936/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1002 - val_loss: 0.5915\n",
      "Epoch 1937/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0976 - val_loss: 0.5996\n",
      "Epoch 1938/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0944 - val_loss: 0.6084\n",
      "Epoch 1939/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0991 - val_loss: 0.5944\n",
      "Epoch 1940/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0949 - val_loss: 0.5972\n",
      "Epoch 1941/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0947 - val_loss: 0.5764\n",
      "Epoch 1942/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0873 - val_loss: 0.5954\n",
      "Epoch 1943/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0969 - val_loss: 0.5940\n",
      "Epoch 1944/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0957 - val_loss: 0.6032\n",
      "Epoch 1945/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0976 - val_loss: 0.6077\n",
      "Epoch 1946/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0921 - val_loss: 0.5814\n",
      "Epoch 1947/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0980 - val_loss: 0.5874\n",
      "Epoch 1948/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0947 - val_loss: 0.6181\n",
      "Epoch 1949/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0969 - val_loss: 0.5718\n",
      "Epoch 1950/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0903 - val_loss: 0.5815\n",
      "Epoch 1951/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0891 - val_loss: 0.5760\n",
      "Epoch 1952/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0945 - val_loss: 0.6072\n",
      "Epoch 1953/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0935 - val_loss: 0.5766\n",
      "Epoch 1954/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0910 - val_loss: 0.6048\n",
      "Epoch 1955/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0924 - val_loss: 0.6050\n",
      "Epoch 1956/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0966 - val_loss: 0.6036\n",
      "Epoch 1957/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0868 - val_loss: 0.6021\n",
      "Epoch 1958/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0998 - val_loss: 0.5866\n",
      "Epoch 1959/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0969 - val_loss: 0.5842\n",
      "Epoch 1960/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0914 - val_loss: 0.5767\n",
      "Epoch 1961/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0854 - val_loss: 0.5992\n",
      "Epoch 1962/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0883 - val_loss: 0.5801\n",
      "Epoch 1963/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0980 - val_loss: 0.5908\n",
      "Epoch 1964/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0876 - val_loss: 0.6031\n",
      "Epoch 1965/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0926 - val_loss: 0.6040\n",
      "Epoch 1966/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.1038 - val_loss: 0.5875\n",
      "Epoch 1967/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1011 - val_loss: 0.5903\n",
      "Epoch 1968/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0939 - val_loss: 0.5889\n",
      "Epoch 1969/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0920 - val_loss: 0.6059\n",
      "Epoch 1970/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0918 - val_loss: 0.6064\n",
      "Epoch 1971/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0902 - val_loss: 0.6132\n",
      "Epoch 1972/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0845 - val_loss: 0.5982\n",
      "Epoch 1973/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0848 - val_loss: 0.6303\n",
      "Epoch 1974/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0857 - val_loss: 0.5958\n",
      "Epoch 1975/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0890 - val_loss: 0.5881\n",
      "Epoch 1976/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0857 - val_loss: 0.6139\n",
      "Epoch 1977/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0865 - val_loss: 0.5788\n",
      "Epoch 1978/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0939 - val_loss: 0.6009\n",
      "Epoch 1979/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 761us/step - loss: 0.0861 - val_loss: 0.6116\n",
      "Epoch 1980/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0908 - val_loss: 0.5783\n",
      "Epoch 1981/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0998 - val_loss: 0.6129\n",
      "Epoch 1982/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0941 - val_loss: 0.5975\n",
      "Epoch 1983/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0865 - val_loss: 0.6014\n",
      "Epoch 1984/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0864 - val_loss: 0.6662\n",
      "Epoch 1985/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0993 - val_loss: 0.6000\n",
      "Epoch 1986/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0904 - val_loss: 0.6391\n",
      "Epoch 1987/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0995 - val_loss: 0.5922\n",
      "Epoch 1988/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0916 - val_loss: 0.6043\n",
      "Epoch 1989/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0913 - val_loss: 0.6137\n",
      "Epoch 1990/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0884 - val_loss: 0.5913\n",
      "Epoch 1991/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0900 - val_loss: 0.6088\n",
      "Epoch 1992/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0893 - val_loss: 0.5893\n",
      "Epoch 1993/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0943 - val_loss: 0.5733\n",
      "Epoch 1994/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0853 - val_loss: 0.6022\n",
      "Epoch 1995/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0846 - val_loss: 0.6144\n",
      "Epoch 1996/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1004 - val_loss: 0.5789\n",
      "Epoch 1997/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0887 - val_loss: 0.6324\n",
      "Epoch 1998/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.1071 - val_loss: 0.5999\n",
      "Epoch 1999/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0863 - val_loss: 0.5981\n",
      "Epoch 2000/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0892 - val_loss: 0.6017\n",
      "Epoch 2001/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0887 - val_loss: 0.5970\n",
      "Epoch 2002/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0861 - val_loss: 0.5908\n",
      "Epoch 2003/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0912 - val_loss: 0.5985\n",
      "Epoch 2004/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0868 - val_loss: 0.6035\n",
      "Epoch 2005/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0833 - val_loss: 0.5918\n",
      "Epoch 2006/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0800 - val_loss: 0.5827\n",
      "Epoch 2007/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0991 - val_loss: 0.6085\n",
      "Epoch 2008/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0901 - val_loss: 0.5931\n",
      "Epoch 2009/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0882 - val_loss: 0.5904\n",
      "Epoch 2010/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0853 - val_loss: 0.5972\n",
      "Epoch 2011/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0842 - val_loss: 0.6059\n",
      "Epoch 2012/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0840 - val_loss: 0.6116\n",
      "Epoch 2013/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0891 - val_loss: 0.6082\n",
      "Epoch 2014/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0918 - val_loss: 0.6095\n",
      "Epoch 2015/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0861 - val_loss: 0.5967\n",
      "Epoch 2016/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0841 - val_loss: 0.5763\n",
      "Epoch 2017/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0809 - val_loss: 0.6095\n",
      "Epoch 2018/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0952 - val_loss: 0.5864\n",
      "Epoch 2019/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0922 - val_loss: 0.6219\n",
      "Epoch 2020/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0872 - val_loss: 0.6092\n",
      "Epoch 2021/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0890 - val_loss: 0.5886\n",
      "Epoch 2022/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0866 - val_loss: 0.5909\n",
      "Epoch 2023/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0855 - val_loss: 0.6124\n",
      "Epoch 2024/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0942 - val_loss: 0.5791\n",
      "Epoch 2025/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0905 - val_loss: 0.5725\n",
      "Epoch 2026/10000\n",
      "130/130 [==============================] - 0s 832us/step - loss: 0.0900 - val_loss: 0.5798\n",
      "Epoch 2027/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0821 - val_loss: 0.6134\n",
      "Epoch 2028/10000\n",
      "130/130 [==============================] - 0s 792us/step - loss: 0.0884 - val_loss: 0.6259\n",
      "Epoch 2029/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0855 - val_loss: 0.6021\n",
      "Epoch 2030/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0860 - val_loss: 0.5756\n",
      "Epoch 2031/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0931 - val_loss: 0.6000\n",
      "Epoch 2032/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0907 - val_loss: 0.5850\n",
      "Epoch 2033/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0787 - val_loss: 0.5963\n",
      "Epoch 2034/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0862 - val_loss: 0.5983\n",
      "Epoch 2035/10000\n",
      "130/130 [==============================] - 0s 821us/step - loss: 0.0831 - val_loss: 0.6180\n",
      "Epoch 2036/10000\n",
      "130/130 [==============================] - 0s 904us/step - loss: 0.0884 - val_loss: 0.6057\n",
      "Epoch 2037/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0894 - val_loss: 0.6046\n",
      "Epoch 2038/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0849 - val_loss: 0.5932\n",
      "Epoch 2039/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0905 - val_loss: 0.5757\n",
      "Epoch 2040/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0953 - val_loss: 0.6002\n",
      "Epoch 2041/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0875 - val_loss: 0.6222\n",
      "Epoch 2042/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0853 - val_loss: 0.6014\n",
      "Epoch 2043/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0872 - val_loss: 0.5841\n",
      "Epoch 2044/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0853 - val_loss: 0.5918\n",
      "Epoch 2045/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0902 - val_loss: 0.6239\n",
      "Epoch 2046/10000\n",
      "130/130 [==============================] - 0s 933us/step - loss: 0.0916 - val_loss: 0.5897\n",
      "Epoch 2047/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0883 - val_loss: 0.5973\n",
      "Epoch 2048/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0870 - val_loss: 0.6046\n",
      "Epoch 2049/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0870 - val_loss: 0.5846\n",
      "Epoch 2050/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0831 - val_loss: 0.6316\n",
      "Epoch 2051/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0899 - val_loss: 0.6150\n",
      "Epoch 2052/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0852 - val_loss: 0.6005\n",
      "Epoch 2053/10000\n",
      "130/130 [==============================] - 0s 809us/step - loss: 0.0938 - val_loss: 0.5925\n",
      "Epoch 2054/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0828 - val_loss: 0.6036\n",
      "Epoch 2055/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 812us/step - loss: 0.0822 - val_loss: 0.6294\n",
      "Epoch 2056/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0835 - val_loss: 0.5768\n",
      "Epoch 2057/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0794 - val_loss: 0.5907\n",
      "Epoch 2058/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0823 - val_loss: 0.5997\n",
      "Epoch 2059/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0922 - val_loss: 0.5797\n",
      "Epoch 2060/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0863 - val_loss: 0.6099\n",
      "Epoch 2061/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0896 - val_loss: 0.5932\n",
      "Epoch 2062/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0835 - val_loss: 0.6021\n",
      "Epoch 2063/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0822 - val_loss: 0.6086\n",
      "Epoch 2064/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0879 - val_loss: 0.5939\n",
      "Epoch 2065/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0857 - val_loss: 0.6241\n",
      "Epoch 2066/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0850 - val_loss: 0.6071\n",
      "Epoch 2067/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0934 - val_loss: 0.6035\n",
      "Epoch 2068/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0899 - val_loss: 0.5927\n",
      "Epoch 2069/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0822 - val_loss: 0.5927\n",
      "Epoch 2070/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0838 - val_loss: 0.5957\n",
      "Epoch 2071/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0838 - val_loss: 0.5996\n",
      "Epoch 2072/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0875 - val_loss: 0.5982\n",
      "Epoch 2073/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0822 - val_loss: 0.5947\n",
      "Epoch 2074/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0820 - val_loss: 0.6013\n",
      "Epoch 2075/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0959 - val_loss: 0.6095\n",
      "Epoch 2076/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0851 - val_loss: 0.6088\n",
      "Epoch 2077/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0772 - val_loss: 0.5937\n",
      "Epoch 2078/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0840 - val_loss: 0.5954\n",
      "Epoch 2079/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0767 - val_loss: 0.5978\n",
      "Epoch 2080/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0823 - val_loss: 0.5869\n",
      "Epoch 2081/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0818 - val_loss: 0.5961\n",
      "Epoch 2082/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0830 - val_loss: 0.5988\n",
      "Epoch 2083/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0853 - val_loss: 0.6166\n",
      "Epoch 2084/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0927 - val_loss: 0.5966\n",
      "Epoch 2085/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0780 - val_loss: 0.6143\n",
      "Epoch 2086/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0885 - val_loss: 0.5884\n",
      "Epoch 2087/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0746 - val_loss: 0.6052\n",
      "Epoch 2088/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0874 - val_loss: 0.6206\n",
      "Epoch 2089/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0842 - val_loss: 0.5978\n",
      "Epoch 2090/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0726 - val_loss: 0.6086\n",
      "Epoch 2091/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0897 - val_loss: 0.6186\n",
      "Epoch 2092/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0817 - val_loss: 0.5756\n",
      "Epoch 2093/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0788 - val_loss: 0.5915\n",
      "Epoch 2094/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0774 - val_loss: 0.6311\n",
      "Epoch 2095/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0868 - val_loss: 0.5981\n",
      "Epoch 2096/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0871 - val_loss: 0.6055\n",
      "Epoch 2097/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0815 - val_loss: 0.6079\n",
      "Epoch 2098/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0855 - val_loss: 0.5993\n",
      "Epoch 2099/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0859 - val_loss: 0.5964\n",
      "Epoch 2100/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0836 - val_loss: 0.5912\n",
      "Epoch 2101/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0833 - val_loss: 0.6062\n",
      "Epoch 2102/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0812 - val_loss: 0.6074\n",
      "Epoch 2103/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0845 - val_loss: 0.5923\n",
      "Epoch 2104/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0804 - val_loss: 0.6008\n",
      "Epoch 2105/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0786 - val_loss: 0.6086\n",
      "Epoch 2106/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0800 - val_loss: 0.6020\n",
      "Epoch 2107/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0790 - val_loss: 0.6247\n",
      "Epoch 2108/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0835 - val_loss: 0.6033\n",
      "Epoch 2109/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0841 - val_loss: 0.6027\n",
      "Epoch 2110/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0839 - val_loss: 0.5824\n",
      "Epoch 2111/10000\n",
      "130/130 [==============================] - 0s 816us/step - loss: 0.0896 - val_loss: 0.5871\n",
      "Epoch 2112/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0842 - val_loss: 0.5922\n",
      "Epoch 2113/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0809 - val_loss: 0.6062\n",
      "Epoch 2114/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0783 - val_loss: 0.6055\n",
      "Epoch 2115/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0828 - val_loss: 0.5970\n",
      "Epoch 2116/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0787 - val_loss: 0.5920\n",
      "Epoch 2117/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0822 - val_loss: 0.5899\n",
      "Epoch 2118/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0760 - val_loss: 0.5956\n",
      "Epoch 2119/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0917 - val_loss: 0.5741\n",
      "Epoch 2120/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0775 - val_loss: 0.6225\n",
      "Epoch 2121/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0788 - val_loss: 0.5906\n",
      "Epoch 2122/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0755 - val_loss: 0.6117\n",
      "Epoch 2123/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0791 - val_loss: 0.5956\n",
      "Epoch 2124/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0828 - val_loss: 0.6102\n",
      "Epoch 2125/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0887 - val_loss: 0.6070\n",
      "Epoch 2126/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0821 - val_loss: 0.6007\n",
      "Epoch 2127/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0802 - val_loss: 0.5976\n",
      "Epoch 2128/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0896 - val_loss: 0.6043\n",
      "Epoch 2129/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0864 - val_loss: 0.6045\n",
      "Epoch 2130/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0809 - val_loss: 0.5874\n",
      "Epoch 2131/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 737us/step - loss: 0.0814 - val_loss: 0.6125\n",
      "Epoch 2132/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0777 - val_loss: 0.6013\n",
      "Epoch 2133/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0787 - val_loss: 0.5845\n",
      "Epoch 2134/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0813 - val_loss: 0.6057\n",
      "Epoch 2135/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0833 - val_loss: 0.6056\n",
      "Epoch 2136/10000\n",
      "130/130 [==============================] - 0s 848us/step - loss: 0.0863 - val_loss: 0.6051\n",
      "Epoch 2137/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0828 - val_loss: 0.5866\n",
      "Epoch 2138/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0779 - val_loss: 0.5968\n",
      "Epoch 2139/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0771 - val_loss: 0.6080\n",
      "Epoch 2140/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0768 - val_loss: 0.5993\n",
      "Epoch 2141/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0746 - val_loss: 0.6057\n",
      "Epoch 2142/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0880 - val_loss: 0.6098\n",
      "Epoch 2143/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0806 - val_loss: 0.5784\n",
      "Epoch 2144/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0851 - val_loss: 0.6097\n",
      "Epoch 2145/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0816 - val_loss: 0.5954\n",
      "Epoch 2146/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0859 - val_loss: 0.5992\n",
      "Epoch 2147/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0741 - val_loss: 0.5868\n",
      "Epoch 2148/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0752 - val_loss: 0.6107\n",
      "Epoch 2149/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0792 - val_loss: 0.6032\n",
      "Epoch 2150/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0778 - val_loss: 0.6058\n",
      "Epoch 2151/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0768 - val_loss: 0.5863\n",
      "Epoch 2152/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0771 - val_loss: 0.5993\n",
      "Epoch 2153/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0904 - val_loss: 0.6211\n",
      "Epoch 2154/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0819 - val_loss: 0.5996\n",
      "Epoch 2155/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0762 - val_loss: 0.6034\n",
      "Epoch 2156/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0759 - val_loss: 0.5863\n",
      "Epoch 2157/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0771 - val_loss: 0.5924\n",
      "Epoch 2158/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0817 - val_loss: 0.6167\n",
      "Epoch 2159/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0807 - val_loss: 0.5862\n",
      "Epoch 2160/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0818 - val_loss: 0.5820\n",
      "Epoch 2161/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0808 - val_loss: 0.5938\n",
      "Epoch 2162/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0744 - val_loss: 0.6033\n",
      "Epoch 2163/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0863 - val_loss: 0.5960\n",
      "Epoch 2164/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0829 - val_loss: 0.6174\n",
      "Epoch 2165/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0827 - val_loss: 0.5853\n",
      "Epoch 2166/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0806 - val_loss: 0.5908\n",
      "Epoch 2167/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0806 - val_loss: 0.6163\n",
      "Epoch 2168/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0754 - val_loss: 0.6082\n",
      "Epoch 2169/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0729 - val_loss: 0.6070\n",
      "Epoch 2170/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0751 - val_loss: 0.5894\n",
      "Epoch 2171/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0758 - val_loss: 0.5976\n",
      "Epoch 2172/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0746 - val_loss: 0.5884\n",
      "Epoch 2173/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0860 - val_loss: 0.6146\n",
      "Epoch 2174/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0800 - val_loss: 0.6008\n",
      "Epoch 2175/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0777 - val_loss: 0.6117\n",
      "Epoch 2176/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0881 - val_loss: 0.6118\n",
      "Epoch 2177/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0834 - val_loss: 0.5963\n",
      "Epoch 2178/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0765 - val_loss: 0.6076\n",
      "Epoch 2179/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0822 - val_loss: 0.6084\n",
      "Epoch 2180/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0797 - val_loss: 0.6035\n",
      "Epoch 2181/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0798 - val_loss: 0.6081\n",
      "Epoch 2182/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0750 - val_loss: 0.6078\n",
      "Epoch 2183/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0767 - val_loss: 0.6057\n",
      "Epoch 2184/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0739 - val_loss: 0.6084\n",
      "Epoch 2185/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0726 - val_loss: 0.5914\n",
      "Epoch 2186/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0756 - val_loss: 0.6375\n",
      "Epoch 2187/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0805 - val_loss: 0.6128\n",
      "Epoch 2188/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0792 - val_loss: 0.5975\n",
      "Epoch 2189/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0725 - val_loss: 0.5958\n",
      "Epoch 2190/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0762 - val_loss: 0.6065\n",
      "Epoch 2191/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0789 - val_loss: 0.5996\n",
      "Epoch 2192/10000\n",
      "130/130 [==============================] - 0s 809us/step - loss: 0.0759 - val_loss: 0.6077\n",
      "Epoch 2193/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0844 - val_loss: 0.6191\n",
      "Epoch 2194/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0816 - val_loss: 0.6023\n",
      "Epoch 2195/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0685 - val_loss: 0.6110\n",
      "Epoch 2196/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0776 - val_loss: 0.5933\n",
      "Epoch 2197/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0868 - val_loss: 0.6104\n",
      "Epoch 2198/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0756 - val_loss: 0.5974\n",
      "Epoch 2199/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0724 - val_loss: 0.6280\n",
      "Epoch 2200/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0798 - val_loss: 0.6081\n",
      "Epoch 2201/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0778 - val_loss: 0.5982\n",
      "Epoch 2202/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0891 - val_loss: 0.5972\n",
      "Epoch 2203/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0815 - val_loss: 0.5822\n",
      "Epoch 2204/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0734 - val_loss: 0.6038\n",
      "Epoch 2205/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0700 - val_loss: 0.6209\n",
      "Epoch 2206/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0722 - val_loss: 0.5925\n",
      "Epoch 2207/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 726us/step - loss: 0.0743 - val_loss: 0.5873\n",
      "Epoch 2208/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0803 - val_loss: 0.5848\n",
      "Epoch 2209/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0852 - val_loss: 0.6080\n",
      "Epoch 2210/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0727 - val_loss: 0.5996\n",
      "Epoch 2211/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0711 - val_loss: 0.5947\n",
      "Epoch 2212/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0699 - val_loss: 0.6124\n",
      "Epoch 2213/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0707 - val_loss: 0.6088\n",
      "Epoch 2214/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0685 - val_loss: 0.6160\n",
      "Epoch 2215/10000\n",
      "130/130 [==============================] - 0s 814us/step - loss: 0.0684 - val_loss: 0.5989\n",
      "Epoch 2216/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0776 - val_loss: 0.5976\n",
      "Epoch 2217/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0747 - val_loss: 0.6117\n",
      "Epoch 2218/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0939 - val_loss: 0.5840\n",
      "Epoch 2219/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0794 - val_loss: 0.6079\n",
      "Epoch 2220/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0716 - val_loss: 0.5952\n",
      "Epoch 2221/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0739 - val_loss: 0.6101\n",
      "Epoch 2222/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0738 - val_loss: 0.6026\n",
      "Epoch 2223/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0762 - val_loss: 0.6047\n",
      "Epoch 2224/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0784 - val_loss: 0.5916\n",
      "Epoch 2225/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0937 - val_loss: 0.5899\n",
      "Epoch 2226/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0697 - val_loss: 0.5951\n",
      "Epoch 2227/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0718 - val_loss: 0.6222\n",
      "Epoch 2228/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0754 - val_loss: 0.5907\n",
      "Epoch 2229/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0694 - val_loss: 0.6002\n",
      "Epoch 2230/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0706 - val_loss: 0.6249\n",
      "Epoch 2231/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0736 - val_loss: 0.6017\n",
      "Epoch 2232/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0703 - val_loss: 0.5918\n",
      "Epoch 2233/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0732 - val_loss: 0.5992\n",
      "Epoch 2234/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0791 - val_loss: 0.6212\n",
      "Epoch 2235/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0764 - val_loss: 0.5998\n",
      "Epoch 2236/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0717 - val_loss: 0.6042\n",
      "Epoch 2237/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0792 - val_loss: 0.6269\n",
      "Epoch 2238/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0729 - val_loss: 0.6021\n",
      "Epoch 2239/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0756 - val_loss: 0.6057\n",
      "Epoch 2240/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0734 - val_loss: 0.6176\n",
      "Epoch 2241/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0753 - val_loss: 0.5939\n",
      "Epoch 2242/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0709 - val_loss: 0.5811\n",
      "Epoch 2243/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0829 - val_loss: 0.6086\n",
      "Epoch 2244/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0725 - val_loss: 0.5948\n",
      "Epoch 2245/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0729 - val_loss: 0.5910\n",
      "Epoch 2246/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0688 - val_loss: 0.6036\n",
      "Epoch 2247/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0748 - val_loss: 0.5991\n",
      "Epoch 2248/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0714 - val_loss: 0.6003\n",
      "Epoch 2249/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0758 - val_loss: 0.6144\n",
      "Epoch 2250/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0734 - val_loss: 0.5854\n",
      "Epoch 2251/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0712 - val_loss: 0.6031\n",
      "Epoch 2252/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0684 - val_loss: 0.6061\n",
      "Epoch 2253/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0804 - val_loss: 0.5928\n",
      "Epoch 2254/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0859 - val_loss: 0.6033\n",
      "Epoch 2255/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0724 - val_loss: 0.5868\n",
      "Epoch 2256/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0751 - val_loss: 0.6359\n",
      "Epoch 2257/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0794 - val_loss: 0.6137\n",
      "Epoch 2258/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0718 - val_loss: 0.5932\n",
      "Epoch 2259/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0692 - val_loss: 0.6014\n",
      "Epoch 2260/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0698 - val_loss: 0.6202\n",
      "Epoch 2261/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0782 - val_loss: 0.6187\n",
      "Epoch 2262/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1072 - val_loss: 0.5906\n",
      "Epoch 2263/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0781 - val_loss: 0.5884\n",
      "Epoch 2264/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0670 - val_loss: 0.6094\n",
      "Epoch 2265/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0642 - val_loss: 0.5857\n",
      "Epoch 2266/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0715 - val_loss: 0.5936\n",
      "Epoch 2267/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0688 - val_loss: 0.5881\n",
      "Epoch 2268/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0667 - val_loss: 0.6126\n",
      "Epoch 2269/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0756 - val_loss: 0.5960\n",
      "Epoch 2270/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0667 - val_loss: 0.6096\n",
      "Epoch 2271/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0697 - val_loss: 0.6291\n",
      "Epoch 2272/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0755 - val_loss: 0.6155\n",
      "Epoch 2273/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0737 - val_loss: 0.6163\n",
      "Epoch 2274/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0806 - val_loss: 0.5905\n",
      "Epoch 2275/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0692 - val_loss: 0.6338\n",
      "Epoch 2276/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0691 - val_loss: 0.5963\n",
      "Epoch 2277/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0732 - val_loss: 0.6147\n",
      "Epoch 2278/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0712 - val_loss: 0.6070\n",
      "Epoch 2279/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0730 - val_loss: 0.6062\n",
      "Epoch 2280/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0676 - val_loss: 0.5888\n",
      "Epoch 2281/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0651 - val_loss: 0.6236\n",
      "Epoch 2282/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0688 - val_loss: 0.6286\n",
      "Epoch 2283/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 750us/step - loss: 0.0768 - val_loss: 0.6011\n",
      "Epoch 2284/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0777 - val_loss: 0.6054\n",
      "Epoch 2285/10000\n",
      "130/130 [==============================] - 0s 840us/step - loss: 0.0630 - val_loss: 0.6240\n",
      "Epoch 2286/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0688 - val_loss: 0.5798\n",
      "Epoch 2287/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0704 - val_loss: 0.5893\n",
      "Epoch 2288/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0746 - val_loss: 0.6092\n",
      "Epoch 2289/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0958 - val_loss: 0.6103\n",
      "Epoch 2290/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0739 - val_loss: 0.6384\n",
      "Epoch 2291/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0774 - val_loss: 0.5816\n",
      "Epoch 2292/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0701 - val_loss: 0.6152\n",
      "Epoch 2293/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0694 - val_loss: 0.6045\n",
      "Epoch 2294/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0768 - val_loss: 0.5900\n",
      "Epoch 2295/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0688 - val_loss: 0.6118\n",
      "Epoch 2296/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0743 - val_loss: 0.6022\n",
      "Epoch 2297/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0754 - val_loss: 0.5910\n",
      "Epoch 2298/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0701 - val_loss: 0.5980\n",
      "Epoch 2299/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0700 - val_loss: 0.6136\n",
      "Epoch 2300/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0697 - val_loss: 0.5992\n",
      "Epoch 2301/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0712 - val_loss: 0.6117\n",
      "Epoch 2302/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0710 - val_loss: 0.6174\n",
      "Epoch 2303/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0746 - val_loss: 0.6310\n",
      "Epoch 2304/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0822 - val_loss: 0.6161\n",
      "Epoch 2305/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0670 - val_loss: 0.5927\n",
      "Epoch 2306/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0662 - val_loss: 0.6357\n",
      "Epoch 2307/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0789 - val_loss: 0.5903\n",
      "Epoch 2308/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0718 - val_loss: 0.6053\n",
      "Epoch 2309/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0752 - val_loss: 0.6078\n",
      "Epoch 2310/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0693 - val_loss: 0.5951\n",
      "Epoch 2311/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0729 - val_loss: 0.5984\n",
      "Epoch 2312/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0671 - val_loss: 0.6164\n",
      "Epoch 2313/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0695 - val_loss: 0.6074\n",
      "Epoch 2314/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0739 - val_loss: 0.6028\n",
      "Epoch 2315/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0705 - val_loss: 0.5762\n",
      "Epoch 2316/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0661 - val_loss: 0.5961\n",
      "Epoch 2317/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0647 - val_loss: 0.6132\n",
      "Epoch 2318/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0908 - val_loss: 0.5678\n",
      "Epoch 2319/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0709 - val_loss: 0.5963\n",
      "Epoch 2320/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0651 - val_loss: 0.6013\n",
      "Epoch 2321/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0649 - val_loss: 0.5872\n",
      "Epoch 2322/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0668 - val_loss: 0.5902\n",
      "Epoch 2323/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0646 - val_loss: 0.6126\n",
      "Epoch 2324/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0622 - val_loss: 0.6382\n",
      "Epoch 2325/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0745 - val_loss: 0.6106\n",
      "Epoch 2326/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0740 - val_loss: 0.6021\n",
      "Epoch 2327/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0675 - val_loss: 0.6033\n",
      "Epoch 2328/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0736 - val_loss: 0.6333\n",
      "Epoch 2329/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0710 - val_loss: 0.6159\n",
      "Epoch 2330/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0654 - val_loss: 0.6052\n",
      "Epoch 2331/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0698 - val_loss: 0.5944\n",
      "Epoch 2332/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0689 - val_loss: 0.5974\n",
      "Epoch 2333/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0695 - val_loss: 0.6049\n",
      "Epoch 2334/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0650 - val_loss: 0.6160\n",
      "Epoch 2335/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0658 - val_loss: 0.6243\n",
      "Epoch 2336/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0670 - val_loss: 0.6081\n",
      "Epoch 2337/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0732 - val_loss: 0.6166\n",
      "Epoch 2338/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0686 - val_loss: 0.6033\n",
      "Epoch 2339/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0720 - val_loss: 0.6034\n",
      "Epoch 2340/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0667 - val_loss: 0.5994\n",
      "Epoch 2341/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0728 - val_loss: 0.6040\n",
      "Epoch 2342/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0625 - val_loss: 0.6019\n",
      "Epoch 2343/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0719 - val_loss: 0.5964\n",
      "Epoch 2344/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0704 - val_loss: 0.6035\n",
      "Epoch 2345/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0682 - val_loss: 0.6082\n",
      "Epoch 2346/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0633 - val_loss: 0.6079\n",
      "Epoch 2347/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0713 - val_loss: 0.6292\n",
      "Epoch 2348/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0627 - val_loss: 0.6024\n",
      "Epoch 2349/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0654 - val_loss: 0.6175\n",
      "Epoch 2350/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0750 - val_loss: 0.6087\n",
      "Epoch 2351/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0654 - val_loss: 0.5929\n",
      "Epoch 2352/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0712 - val_loss: 0.6123\n",
      "Epoch 2353/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0745 - val_loss: 0.6308\n",
      "Epoch 2354/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0706 - val_loss: 0.6060\n",
      "Epoch 2355/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0717 - val_loss: 0.5973\n",
      "Epoch 2356/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0775 - val_loss: 0.6096\n",
      "Epoch 2357/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0700 - val_loss: 0.6351\n",
      "Epoch 2358/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0683 - val_loss: 0.6143\n",
      "Epoch 2359/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 775us/step - loss: 0.0644 - val_loss: 0.6423\n",
      "Epoch 2360/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0684 - val_loss: 0.6067\n",
      "Epoch 2361/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0683 - val_loss: 0.6050\n",
      "Epoch 2362/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0787 - val_loss: 0.6190\n",
      "Epoch 2363/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0716 - val_loss: 0.6193\n",
      "Epoch 2364/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0610 - val_loss: 0.6124\n",
      "Epoch 2365/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0673 - val_loss: 0.6052\n",
      "Epoch 2366/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0615 - val_loss: 0.5876\n",
      "Epoch 2367/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0667 - val_loss: 0.6130\n",
      "Epoch 2368/10000\n",
      "130/130 [==============================] - 0s 814us/step - loss: 0.0783 - val_loss: 0.6045\n",
      "Epoch 2369/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0703 - val_loss: 0.6065\n",
      "Epoch 2370/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0658 - val_loss: 0.6086\n",
      "Epoch 2371/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0656 - val_loss: 0.6189\n",
      "Epoch 2372/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0698 - val_loss: 0.6141\n",
      "Epoch 2373/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0649 - val_loss: 0.6168\n",
      "Epoch 2374/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0762 - val_loss: 0.6218\n",
      "Epoch 2375/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0773 - val_loss: 0.6032\n",
      "Epoch 2376/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0674 - val_loss: 0.6151\n",
      "Epoch 2377/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0724 - val_loss: 0.6046\n",
      "Epoch 2378/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0683 - val_loss: 0.6085\n",
      "Epoch 2379/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0640 - val_loss: 0.6097\n",
      "Epoch 2380/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0614 - val_loss: 0.6224\n",
      "Epoch 2381/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0661 - val_loss: 0.6355\n",
      "Epoch 2382/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0685 - val_loss: 0.6075\n",
      "Epoch 2383/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0665 - val_loss: 0.5941\n",
      "Epoch 2384/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0681 - val_loss: 0.6045\n",
      "Epoch 2385/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0685 - val_loss: 0.5997\n",
      "Epoch 2386/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0713 - val_loss: 0.6061\n",
      "Epoch 2387/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0636 - val_loss: 0.6010\n",
      "Epoch 2388/10000\n",
      "130/130 [==============================] - 0s 813us/step - loss: 0.0652 - val_loss: 0.6130\n",
      "Epoch 2389/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0721 - val_loss: 0.6245\n",
      "Epoch 2390/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0713 - val_loss: 0.6023\n",
      "Epoch 2391/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0640 - val_loss: 0.6246\n",
      "Epoch 2392/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0687 - val_loss: 0.5968\n",
      "Epoch 2393/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0627 - val_loss: 0.6363\n",
      "Epoch 2394/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0747 - val_loss: 0.6543\n",
      "Epoch 2395/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0866 - val_loss: 0.6099\n",
      "Epoch 2396/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0687 - val_loss: 0.6102\n",
      "Epoch 2397/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0646 - val_loss: 0.5986\n",
      "Epoch 2398/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0687 - val_loss: 0.6126\n",
      "Epoch 2399/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0651 - val_loss: 0.6020\n",
      "Epoch 2400/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0658 - val_loss: 0.6151\n",
      "Epoch 2401/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0696 - val_loss: 0.6069\n",
      "Epoch 2402/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0598 - val_loss: 0.6199\n",
      "Epoch 2403/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0619 - val_loss: 0.6095\n",
      "Epoch 2404/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0701 - val_loss: 0.6144\n",
      "Epoch 2405/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0657 - val_loss: 0.6045\n",
      "Epoch 2406/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0677 - val_loss: 0.5954\n",
      "Epoch 2407/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0655 - val_loss: 0.6183\n",
      "Epoch 2408/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0623 - val_loss: 0.6093\n",
      "Epoch 2409/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0609 - val_loss: 0.5863\n",
      "Epoch 2410/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0676 - val_loss: 0.6145\n",
      "Epoch 2411/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0702 - val_loss: 0.6346\n",
      "Epoch 2412/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0625 - val_loss: 0.6239\n",
      "Epoch 2413/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0675 - val_loss: 0.5909\n",
      "Epoch 2414/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0629 - val_loss: 0.5863\n",
      "Epoch 2415/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0625 - val_loss: 0.6110\n",
      "Epoch 2416/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0609 - val_loss: 0.6212\n",
      "Epoch 2417/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0656 - val_loss: 0.5894\n",
      "Epoch 2418/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0713 - val_loss: 0.6041\n",
      "Epoch 2419/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0647 - val_loss: 0.6253\n",
      "Epoch 2420/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0643 - val_loss: 0.6243\n",
      "Epoch 2421/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0741 - val_loss: 0.6064\n",
      "Epoch 2422/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0727 - val_loss: 0.5879\n",
      "Epoch 2423/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0639 - val_loss: 0.5968\n",
      "Epoch 2424/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0696 - val_loss: 0.6194\n",
      "Epoch 2425/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0705 - val_loss: 0.6315\n",
      "Epoch 2426/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0660 - val_loss: 0.6177\n",
      "Epoch 2427/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0727 - val_loss: 0.6105\n",
      "Epoch 2428/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0627 - val_loss: 0.5713\n",
      "Epoch 2429/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0664 - val_loss: 0.6188\n",
      "Epoch 2430/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0667 - val_loss: 0.6132\n",
      "Epoch 2431/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0587 - val_loss: 0.6154\n",
      "Epoch 2432/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0636 - val_loss: 0.5993\n",
      "Epoch 2433/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0630 - val_loss: 0.6091\n",
      "Epoch 2434/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0664 - val_loss: 0.5987\n",
      "Epoch 2435/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 744us/step - loss: 0.0703 - val_loss: 0.5872\n",
      "Epoch 2436/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0677 - val_loss: 0.6385\n",
      "Epoch 2437/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0713 - val_loss: 0.6176\n",
      "Epoch 2438/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0612 - val_loss: 0.6041\n",
      "Epoch 2439/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0828 - val_loss: 0.5880\n",
      "Epoch 2440/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0690 - val_loss: 0.6217\n",
      "Epoch 2441/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0602 - val_loss: 0.6029\n",
      "Epoch 2442/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0626 - val_loss: 0.5974\n",
      "Epoch 2443/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0561 - val_loss: 0.6193\n",
      "Epoch 2444/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0579 - val_loss: 0.6126\n",
      "Epoch 2445/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0602 - val_loss: 0.6119\n",
      "Epoch 2446/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0638 - val_loss: 0.6121\n",
      "Epoch 2447/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0591 - val_loss: 0.6187\n",
      "Epoch 2448/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0632 - val_loss: 0.5971\n",
      "Epoch 2449/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0688 - val_loss: 0.6276\n",
      "Epoch 2450/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0717 - val_loss: 0.5990\n",
      "Epoch 2451/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0690 - val_loss: 0.6340\n",
      "Epoch 2452/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0639 - val_loss: 0.5994\n",
      "Epoch 2453/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0680 - val_loss: 0.6046\n",
      "Epoch 2454/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0759 - val_loss: 0.6027\n",
      "Epoch 2455/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0715 - val_loss: 0.6034\n",
      "Epoch 2456/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0618 - val_loss: 0.6230\n",
      "Epoch 2457/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0575 - val_loss: 0.6031\n",
      "Epoch 2458/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0576 - val_loss: 0.5975\n",
      "Epoch 2459/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0619 - val_loss: 0.6119\n",
      "Epoch 2460/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0708 - val_loss: 0.5970\n",
      "Epoch 2461/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0633 - val_loss: 0.6063\n",
      "Epoch 2462/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0603 - val_loss: 0.6221\n",
      "Epoch 2463/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0615 - val_loss: 0.6096\n",
      "Epoch 2464/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0610 - val_loss: 0.6079\n",
      "Epoch 2465/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0650 - val_loss: 0.6102\n",
      "Epoch 2466/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0666 - val_loss: 0.6042\n",
      "Epoch 2467/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0648 - val_loss: 0.6280\n",
      "Epoch 2468/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0604 - val_loss: 0.6196\n",
      "Epoch 2469/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0638 - val_loss: 0.6159\n",
      "Epoch 2470/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0587 - val_loss: 0.6243\n",
      "Epoch 2471/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0616 - val_loss: 0.6153\n",
      "Epoch 2472/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0623 - val_loss: 0.6308\n",
      "Epoch 2473/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0599 - val_loss: 0.6044\n",
      "Epoch 2474/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0675 - val_loss: 0.6102\n",
      "Epoch 2475/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0637 - val_loss: 0.6266\n",
      "Epoch 2476/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0779 - val_loss: 0.6019\n",
      "Epoch 2477/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0634 - val_loss: 0.5852\n",
      "Epoch 2478/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0644 - val_loss: 0.6106\n",
      "Epoch 2479/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0715 - val_loss: 0.6346\n",
      "Epoch 2480/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0652 - val_loss: 0.6158\n",
      "Epoch 2481/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0605 - val_loss: 0.6216\n",
      "Epoch 2482/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0609 - val_loss: 0.6183\n",
      "Epoch 2483/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0654 - val_loss: 0.6162\n",
      "Epoch 2484/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0672 - val_loss: 0.6253\n",
      "Epoch 2485/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0643 - val_loss: 0.6281\n",
      "Epoch 2486/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0594 - val_loss: 0.6169\n",
      "Epoch 2487/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0540 - val_loss: 0.6282\n",
      "Epoch 2488/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0629 - val_loss: 0.6247\n",
      "Epoch 2489/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0638 - val_loss: 0.6052\n",
      "Epoch 2490/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0664 - val_loss: 0.6058\n",
      "Epoch 2491/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0656 - val_loss: 0.6139\n",
      "Epoch 2492/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0598 - val_loss: 0.6187\n",
      "Epoch 2493/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0600 - val_loss: 0.6242\n",
      "Epoch 2494/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0654 - val_loss: 0.6107\n",
      "Epoch 2495/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0556 - val_loss: 0.6252\n",
      "Epoch 2496/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0720 - val_loss: 0.6221\n",
      "Epoch 2497/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0677 - val_loss: 0.6008\n",
      "Epoch 2498/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0586 - val_loss: 0.6166\n",
      "Epoch 2499/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0571 - val_loss: 0.6205\n",
      "Epoch 2500/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0672 - val_loss: 0.5985\n",
      "Epoch 2501/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0604 - val_loss: 0.6175\n",
      "Epoch 2502/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0654 - val_loss: 0.6256\n",
      "Epoch 2503/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0547 - val_loss: 0.6217\n",
      "Epoch 2504/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0610 - val_loss: 0.6196\n",
      "Epoch 2505/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0615 - val_loss: 0.6185\n",
      "Epoch 2506/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0655 - val_loss: 0.6119\n",
      "Epoch 2507/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0619 - val_loss: 0.6045\n",
      "Epoch 2508/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0653 - val_loss: 0.6208\n",
      "Epoch 2509/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0659 - val_loss: 0.6216\n",
      "Epoch 2510/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0589 - val_loss: 0.6204\n",
      "Epoch 2511/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 757us/step - loss: 0.0585 - val_loss: 0.6120\n",
      "Epoch 2512/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0633 - val_loss: 0.6295\n",
      "Epoch 2513/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0648 - val_loss: 0.5933\n",
      "Epoch 2514/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0584 - val_loss: 0.6067\n",
      "Epoch 2515/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0646 - val_loss: 0.6261\n",
      "Epoch 2516/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0596 - val_loss: 0.6337\n",
      "Epoch 2517/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0609 - val_loss: 0.6148\n",
      "Epoch 2518/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0617 - val_loss: 0.6033\n",
      "Epoch 2519/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0603 - val_loss: 0.6122\n",
      "Epoch 2520/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0632 - val_loss: 0.6118\n",
      "Epoch 2521/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0596 - val_loss: 0.6128\n",
      "Epoch 2522/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0728 - val_loss: 0.6190\n",
      "Epoch 2523/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0668 - val_loss: 0.6203\n",
      "Epoch 2524/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0607 - val_loss: 0.6163\n",
      "Epoch 2525/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0570 - val_loss: 0.6088\n",
      "Epoch 2526/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0605 - val_loss: 0.6157\n",
      "Epoch 2527/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0578 - val_loss: 0.6028\n",
      "Epoch 2528/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0651 - val_loss: 0.6276\n",
      "Epoch 2529/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0632 - val_loss: 0.5930\n",
      "Epoch 2530/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0648 - val_loss: 0.6174\n",
      "Epoch 2531/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0623 - val_loss: 0.6174\n",
      "Epoch 2532/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0664 - val_loss: 0.6047\n",
      "Epoch 2533/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0572 - val_loss: 0.6184\n",
      "Epoch 2534/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0606 - val_loss: 0.6106\n",
      "Epoch 2535/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0595 - val_loss: 0.6327\n",
      "Epoch 2536/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0634 - val_loss: 0.6076\n",
      "Epoch 2537/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0554 - val_loss: 0.6319\n",
      "Epoch 2538/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0551 - val_loss: 0.6104\n",
      "Epoch 2539/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0602 - val_loss: 0.6108\n",
      "Epoch 2540/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0622 - val_loss: 0.6147\n",
      "Epoch 2541/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0549 - val_loss: 0.6098\n",
      "Epoch 2542/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0570 - val_loss: 0.6161\n",
      "Epoch 2543/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0660 - val_loss: 0.6173\n",
      "Epoch 2544/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0793 - val_loss: 0.6142\n",
      "Epoch 2545/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0592 - val_loss: 0.6282\n",
      "Epoch 2546/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0614 - val_loss: 0.6210\n",
      "Epoch 2547/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0599 - val_loss: 0.6169\n",
      "Epoch 2548/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0511 - val_loss: 0.6179\n",
      "Epoch 2549/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0561 - val_loss: 0.6149\n",
      "Epoch 2550/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0627 - val_loss: 0.6214\n",
      "Epoch 2551/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0634 - val_loss: 0.6224\n",
      "Epoch 2552/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0605 - val_loss: 0.6233\n",
      "Epoch 2553/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0640 - val_loss: 0.6042\n",
      "Epoch 2554/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0594 - val_loss: 0.6120\n",
      "Epoch 2555/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0676 - val_loss: 0.6287\n",
      "Epoch 2556/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0645 - val_loss: 0.6264\n",
      "Epoch 2557/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0655 - val_loss: 0.6097\n",
      "Epoch 2558/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0601 - val_loss: 0.6216\n",
      "Epoch 2559/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0520 - val_loss: 0.5971\n",
      "Epoch 2560/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0571 - val_loss: 0.6246\n",
      "Epoch 2561/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0569 - val_loss: 0.6303\n",
      "Epoch 2562/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0616 - val_loss: 0.6111\n",
      "Epoch 2563/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0581 - val_loss: 0.6233\n",
      "Epoch 2564/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0714 - val_loss: 0.6058\n",
      "Epoch 2565/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0665 - val_loss: 0.6031\n",
      "Epoch 2566/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0637 - val_loss: 0.6097\n",
      "Epoch 2567/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0637 - val_loss: 0.6225\n",
      "Epoch 2568/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0621 - val_loss: 0.6448\n",
      "Epoch 2569/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0792 - val_loss: 0.6269\n",
      "Epoch 2570/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0629 - val_loss: 0.6146\n",
      "Epoch 2571/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0605 - val_loss: 0.6277\n",
      "Epoch 2572/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0550 - val_loss: 0.6263\n",
      "Epoch 2573/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0625 - val_loss: 0.6033\n",
      "Epoch 2574/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0524 - val_loss: 0.6169\n",
      "Epoch 2575/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0604 - val_loss: 0.6143\n",
      "Epoch 2576/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0539 - val_loss: 0.6240\n",
      "Epoch 2577/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0609 - val_loss: 0.6326\n",
      "Epoch 2578/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0619 - val_loss: 0.6215\n",
      "Epoch 2579/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0550 - val_loss: 0.6162\n",
      "Epoch 2580/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0617 - val_loss: 0.6167\n",
      "Epoch 2581/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0668 - val_loss: 0.6155\n",
      "Epoch 2582/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0591 - val_loss: 0.6359\n",
      "Epoch 2583/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0644 - val_loss: 0.6033\n",
      "Epoch 2584/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0564 - val_loss: 0.6118\n",
      "Epoch 2585/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0577 - val_loss: 0.6093\n",
      "Epoch 2586/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0596 - val_loss: 0.6106\n",
      "Epoch 2587/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 741us/step - loss: 0.0554 - val_loss: 0.6399\n",
      "Epoch 2588/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0873 - val_loss: 0.6117\n",
      "Epoch 2589/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0601 - val_loss: 0.6131\n",
      "Epoch 2590/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0558 - val_loss: 0.6185\n",
      "Epoch 2591/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0583 - val_loss: 0.6349\n",
      "Epoch 2592/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0559 - val_loss: 0.6149\n",
      "Epoch 2593/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0562 - val_loss: 0.6224\n",
      "Epoch 2594/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0574 - val_loss: 0.6238\n",
      "Epoch 2595/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0560 - val_loss: 0.6090\n",
      "Epoch 2596/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0527 - val_loss: 0.6275\n",
      "Epoch 2597/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0627 - val_loss: 0.6239\n",
      "Epoch 2598/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0640 - val_loss: 0.6250\n",
      "Epoch 2599/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0584 - val_loss: 0.6314\n",
      "Epoch 2600/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0702 - val_loss: 0.5996\n",
      "Epoch 2601/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0598 - val_loss: 0.6179\n",
      "Epoch 2602/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0541 - val_loss: 0.6127\n",
      "Epoch 2603/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0559 - val_loss: 0.6152\n",
      "Epoch 2604/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0564 - val_loss: 0.6369\n",
      "Epoch 2605/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0606 - val_loss: 0.6112\n",
      "Epoch 2606/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0677 - val_loss: 0.6197\n",
      "Epoch 2607/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0651 - val_loss: 0.6184\n",
      "Epoch 2608/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0604 - val_loss: 0.6159\n",
      "Epoch 2609/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0640 - val_loss: 0.6139\n",
      "Epoch 2610/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0571 - val_loss: 0.6157\n",
      "Epoch 2611/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0567 - val_loss: 0.6142\n",
      "Epoch 2612/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0535 - val_loss: 0.6288\n",
      "Epoch 2613/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0560 - val_loss: 0.6066\n",
      "Epoch 2614/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0531 - val_loss: 0.6241\n",
      "Epoch 2615/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0576 - val_loss: 0.6170\n",
      "Epoch 2616/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0560 - val_loss: 0.6293\n",
      "Epoch 2617/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0522 - val_loss: 0.6375\n",
      "Epoch 2618/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0602 - val_loss: 0.6200\n",
      "Epoch 2619/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0579 - val_loss: 0.6144\n",
      "Epoch 2620/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0610 - val_loss: 0.6089\n",
      "Epoch 2621/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0660 - val_loss: 0.6086\n",
      "Epoch 2622/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0536 - val_loss: 0.6333\n",
      "Epoch 2623/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0546 - val_loss: 0.6354\n",
      "Epoch 2624/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0580 - val_loss: 0.6093\n",
      "Epoch 2625/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0684 - val_loss: 0.6012\n",
      "Epoch 2626/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0698 - val_loss: 0.6266\n",
      "Epoch 2627/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0567 - val_loss: 0.6519\n",
      "Epoch 2628/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0555 - val_loss: 0.6304\n",
      "Epoch 2629/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0571 - val_loss: 0.6130\n",
      "Epoch 2630/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0583 - val_loss: 0.5977\n",
      "Epoch 2631/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0583 - val_loss: 0.6256\n",
      "Epoch 2632/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0548 - val_loss: 0.6186\n",
      "Epoch 2633/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0567 - val_loss: 0.6002\n",
      "Epoch 2634/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0537 - val_loss: 0.6227\n",
      "Epoch 2635/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0556 - val_loss: 0.6100\n",
      "Epoch 2636/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0542 - val_loss: 0.6266\n",
      "Epoch 2637/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0562 - val_loss: 0.6229\n",
      "Epoch 2638/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0585 - val_loss: 0.6405\n",
      "Epoch 2639/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0613 - val_loss: 0.6214\n",
      "Epoch 2640/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0528 - val_loss: 0.6209\n",
      "Epoch 2641/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0516 - val_loss: 0.6170\n",
      "Epoch 2642/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0590 - val_loss: 0.6297\n",
      "Epoch 2643/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0600 - val_loss: 0.6089\n",
      "Epoch 2644/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0612 - val_loss: 0.6091\n",
      "Epoch 2645/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0615 - val_loss: 0.6206\n",
      "Epoch 2646/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0585 - val_loss: 0.6179\n",
      "Epoch 2647/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0534 - val_loss: 0.6191\n",
      "Epoch 2648/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0531 - val_loss: 0.6133\n",
      "Epoch 2649/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0511 - val_loss: 0.6218\n",
      "Epoch 2650/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0535 - val_loss: 0.6254\n",
      "Epoch 2651/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0543 - val_loss: 0.6146\n",
      "Epoch 2652/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0596 - val_loss: 0.6251\n",
      "Epoch 2653/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0562 - val_loss: 0.6214\n",
      "Epoch 2654/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0560 - val_loss: 0.6328\n",
      "Epoch 2655/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0671 - val_loss: 0.6205\n",
      "Epoch 2656/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0718 - val_loss: 0.6174\n",
      "Epoch 2657/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0579 - val_loss: 0.6084\n",
      "Epoch 2658/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0495 - val_loss: 0.6188\n",
      "Epoch 2659/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0495 - val_loss: 0.6224\n",
      "Epoch 2660/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0511 - val_loss: 0.6218\n",
      "Epoch 2661/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0588 - val_loss: 0.6334\n",
      "Epoch 2662/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0699 - val_loss: 0.6146\n",
      "Epoch 2663/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 731us/step - loss: 0.0605 - val_loss: 0.6177\n",
      "Epoch 2664/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0570 - val_loss: 0.6206\n",
      "Epoch 2665/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0654 - val_loss: 0.6176\n",
      "Epoch 2666/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0588 - val_loss: 0.6193\n",
      "Epoch 2667/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0537 - val_loss: 0.6174\n",
      "Epoch 2668/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0566 - val_loss: 0.6116\n",
      "Epoch 2669/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0605 - val_loss: 0.6181\n",
      "Epoch 2670/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0526 - val_loss: 0.6346\n",
      "Epoch 2671/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0580 - val_loss: 0.6252\n",
      "Epoch 2672/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0604 - val_loss: 0.6534\n",
      "Epoch 2673/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0643 - val_loss: 0.6269\n",
      "Epoch 2674/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0539 - val_loss: 0.6341\n",
      "Epoch 2675/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0521 - val_loss: 0.6310\n",
      "Epoch 2676/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0491 - val_loss: 0.6203\n",
      "Epoch 2677/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0620 - val_loss: 0.6355\n",
      "Epoch 2678/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0569 - val_loss: 0.6207\n",
      "Epoch 2679/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0501 - val_loss: 0.6205\n",
      "Epoch 2680/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0524 - val_loss: 0.6280\n",
      "Epoch 2681/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0540 - val_loss: 0.6287\n",
      "Epoch 2682/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0504 - val_loss: 0.6234\n",
      "Epoch 2683/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0568 - val_loss: 0.6467\n",
      "Epoch 2684/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0592 - val_loss: 0.6212\n",
      "Epoch 2685/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0517 - val_loss: 0.6212\n",
      "Epoch 2686/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0632 - val_loss: 0.6022\n",
      "Epoch 2687/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0552 - val_loss: 0.6299\n",
      "Epoch 2688/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0553 - val_loss: 0.6236\n",
      "Epoch 2689/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0521 - val_loss: 0.6626\n",
      "Epoch 2690/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0574 - val_loss: 0.6175\n",
      "Epoch 2691/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0524 - val_loss: 0.6447\n",
      "Epoch 2692/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0563 - val_loss: 0.6362\n",
      "Epoch 2693/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0619 - val_loss: 0.6248\n",
      "Epoch 2694/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0545 - val_loss: 0.6212\n",
      "Epoch 2695/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0491 - val_loss: 0.6216\n",
      "Epoch 2696/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0722 - val_loss: 0.6015\n",
      "Epoch 2697/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0582 - val_loss: 0.6215\n",
      "Epoch 2698/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0480 - val_loss: 0.6147\n",
      "Epoch 2699/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0566 - val_loss: 0.6226\n",
      "Epoch 2700/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0568 - val_loss: 0.6434\n",
      "Epoch 2701/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0550 - val_loss: 0.6459\n",
      "Epoch 2702/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0513 - val_loss: 0.6336\n",
      "Epoch 2703/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0563 - val_loss: 0.6261\n",
      "Epoch 2704/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0534 - val_loss: 0.6124\n",
      "Epoch 2705/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0621 - val_loss: 0.6129\n",
      "Epoch 2706/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0583 - val_loss: 0.6199\n",
      "Epoch 2707/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0517 - val_loss: 0.6249\n",
      "Epoch 2708/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0510 - val_loss: 0.6213\n",
      "Epoch 2709/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0525 - val_loss: 0.6070\n",
      "Epoch 2710/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0601 - val_loss: 0.6168\n",
      "Epoch 2711/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0556 - val_loss: 0.6155\n",
      "Epoch 2712/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0568 - val_loss: 0.6220\n",
      "Epoch 2713/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0563 - val_loss: 0.6194\n",
      "Epoch 2714/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0555 - val_loss: 0.6148\n",
      "Epoch 2715/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0536 - val_loss: 0.6215\n",
      "Epoch 2716/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0580 - val_loss: 0.6346\n",
      "Epoch 2717/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0548 - val_loss: 0.6245\n",
      "Epoch 2718/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0529 - val_loss: 0.6222\n",
      "Epoch 2719/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0511 - val_loss: 0.6230\n",
      "Epoch 2720/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0580 - val_loss: 0.6146\n",
      "Epoch 2721/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0611 - val_loss: 0.6217\n",
      "Epoch 2722/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0526 - val_loss: 0.6168\n",
      "Epoch 2723/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0512 - val_loss: 0.6375\n",
      "Epoch 2724/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0497 - val_loss: 0.6378\n",
      "Epoch 2725/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0533 - val_loss: 0.6113\n",
      "Epoch 2726/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0508 - val_loss: 0.6327\n",
      "Epoch 2727/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0627 - val_loss: 0.6345\n",
      "Epoch 2728/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0783 - val_loss: 0.6378\n",
      "Epoch 2729/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0509 - val_loss: 0.6243\n",
      "Epoch 2730/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0506 - val_loss: 0.6213\n",
      "Epoch 2731/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0477 - val_loss: 0.6237\n",
      "Epoch 2732/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0517 - val_loss: 0.6328\n",
      "Epoch 2733/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0511 - val_loss: 0.6556\n",
      "Epoch 2734/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0533 - val_loss: 0.6338\n",
      "Epoch 2735/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0516 - val_loss: 0.6346\n",
      "Epoch 2736/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0556 - val_loss: 0.6219\n",
      "Epoch 2737/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0573 - val_loss: 0.6156\n",
      "Epoch 2738/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0565 - val_loss: 0.6357\n",
      "Epoch 2739/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 728us/step - loss: 0.0486 - val_loss: 0.6293\n",
      "Epoch 2740/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0505 - val_loss: 0.6320\n",
      "Epoch 2741/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0532 - val_loss: 0.6448\n",
      "Epoch 2742/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0639 - val_loss: 0.6341\n",
      "Epoch 2743/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0561 - val_loss: 0.6168\n",
      "Epoch 2744/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0512 - val_loss: 0.6170\n",
      "Epoch 2745/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0484 - val_loss: 0.6241\n",
      "Epoch 2746/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0499 - val_loss: 0.6583\n",
      "Epoch 2747/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0544 - val_loss: 0.6246\n",
      "Epoch 2748/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0574 - val_loss: 0.6283\n",
      "Epoch 2749/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0509 - val_loss: 0.6147\n",
      "Epoch 2750/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0518 - val_loss: 0.6337\n",
      "Epoch 2751/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0721 - val_loss: 0.6698\n",
      "Epoch 2752/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0585 - val_loss: 0.6425\n",
      "Epoch 2753/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0503 - val_loss: 0.6156\n",
      "Epoch 2754/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0539 - val_loss: 0.6171\n",
      "Epoch 2755/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0509 - val_loss: 0.6171\n",
      "Epoch 2756/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0485 - val_loss: 0.6242\n",
      "Epoch 2757/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0492 - val_loss: 0.6256\n",
      "Epoch 2758/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0542 - val_loss: 0.6363\n",
      "Epoch 2759/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0516 - val_loss: 0.6361\n",
      "Epoch 2760/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0494 - val_loss: 0.6314\n",
      "Epoch 2761/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0596 - val_loss: 0.6194\n",
      "Epoch 2762/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0562 - val_loss: 0.6230\n",
      "Epoch 2763/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0507 - val_loss: 0.6217\n",
      "Epoch 2764/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0580 - val_loss: 0.6295\n",
      "Epoch 2765/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0548 - val_loss: 0.6302\n",
      "Epoch 2766/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0523 - val_loss: 0.6290\n",
      "Epoch 2767/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0558 - val_loss: 0.6167\n",
      "Epoch 2768/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0590 - val_loss: 0.6139\n",
      "Epoch 2769/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0657 - val_loss: 0.6193\n",
      "Epoch 2770/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0520 - val_loss: 0.6295\n",
      "Epoch 2771/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0505 - val_loss: 0.6183\n",
      "Epoch 2772/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0457 - val_loss: 0.6179\n",
      "Epoch 2773/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0451 - val_loss: 0.6276\n",
      "Epoch 2774/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0546 - val_loss: 0.6357\n",
      "Epoch 2775/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0497 - val_loss: 0.6224\n",
      "Epoch 2776/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0566 - val_loss: 0.6259\n",
      "Epoch 2777/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0490 - val_loss: 0.6437\n",
      "Epoch 2778/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0508 - val_loss: 0.6211\n",
      "Epoch 2779/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0494 - val_loss: 0.6359\n",
      "Epoch 2780/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0637 - val_loss: 0.6243\n",
      "Epoch 2781/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0453 - val_loss: 0.6237\n",
      "Epoch 2782/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0522 - val_loss: 0.6379\n",
      "Epoch 2783/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0482 - val_loss: 0.6424\n",
      "Epoch 2784/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0484 - val_loss: 0.6190\n",
      "Epoch 2785/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0706 - val_loss: 0.6252\n",
      "Epoch 2786/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0548 - val_loss: 0.6145\n",
      "Epoch 2787/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0583 - val_loss: 0.6073\n",
      "Epoch 2788/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0510 - val_loss: 0.6258\n",
      "Epoch 2789/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0510 - val_loss: 0.6147\n",
      "Epoch 2790/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0720 - val_loss: 0.6491\n",
      "Epoch 2791/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0517 - val_loss: 0.6387\n",
      "Epoch 2792/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0476 - val_loss: 0.6194\n",
      "Epoch 2793/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0484 - val_loss: 0.6280\n",
      "Epoch 2794/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0460 - val_loss: 0.6469\n",
      "Epoch 2795/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0447 - val_loss: 0.6261\n",
      "Epoch 2796/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0464 - val_loss: 0.6483\n",
      "Epoch 2797/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0493 - val_loss: 0.6302\n",
      "Epoch 2798/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0548 - val_loss: 0.6655\n",
      "Epoch 2799/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0557 - val_loss: 0.6176\n",
      "Epoch 2800/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0496 - val_loss: 0.6355\n",
      "Epoch 2801/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0548 - val_loss: 0.6315\n",
      "Epoch 2802/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0539 - val_loss: 0.6289\n",
      "Epoch 2803/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0557 - val_loss: 0.6550\n",
      "Epoch 2804/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0595 - val_loss: 0.6063\n",
      "Epoch 2805/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0498 - val_loss: 0.6045\n",
      "Epoch 2806/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0476 - val_loss: 0.6330\n",
      "Epoch 2807/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0555 - val_loss: 0.6253\n",
      "Epoch 2808/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0458 - val_loss: 0.6331\n",
      "Epoch 2809/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0599 - val_loss: 0.6206\n",
      "Epoch 2810/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0717 - val_loss: 0.6303\n",
      "Epoch 2811/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0501 - val_loss: 0.6331\n",
      "Epoch 2812/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0445 - val_loss: 0.6426\n",
      "Epoch 2813/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0479 - val_loss: 0.6351\n",
      "Epoch 2814/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0484 - val_loss: 0.6050\n",
      "Epoch 2815/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 737us/step - loss: 0.0596 - val_loss: 0.6184\n",
      "Epoch 2816/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0564 - val_loss: 0.6334\n",
      "Epoch 2817/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0546 - val_loss: 0.6520\n",
      "Epoch 2818/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0497 - val_loss: 0.6438\n",
      "Epoch 2819/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0576 - val_loss: 0.6417\n",
      "Epoch 2820/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0586 - val_loss: 0.6248\n",
      "Epoch 2821/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0476 - val_loss: 0.6252\n",
      "Epoch 2822/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0459 - val_loss: 0.6261\n",
      "Epoch 2823/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0467 - val_loss: 0.6431\n",
      "Epoch 2824/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0500 - val_loss: 0.6250\n",
      "Epoch 2825/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0516 - val_loss: 0.6354\n",
      "Epoch 2826/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0596 - val_loss: 0.6398\n",
      "Epoch 2827/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0506 - val_loss: 0.6434\n",
      "Epoch 2828/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0522 - val_loss: 0.6309\n",
      "Epoch 2829/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0608 - val_loss: 0.6365\n",
      "Epoch 2830/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0606 - val_loss: 0.6661\n",
      "Epoch 2831/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0536 - val_loss: 0.6275\n",
      "Epoch 2832/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0517 - val_loss: 0.6328\n",
      "Epoch 2833/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0512 - val_loss: 0.6382\n",
      "Epoch 2834/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0492 - val_loss: 0.6298\n",
      "Epoch 2835/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0470 - val_loss: 0.6600\n",
      "Epoch 2836/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0499 - val_loss: 0.6206\n",
      "Epoch 2837/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0617 - val_loss: 0.6196\n",
      "Epoch 2838/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0505 - val_loss: 0.6310\n",
      "Epoch 2839/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0504 - val_loss: 0.6317\n",
      "Epoch 2840/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0485 - val_loss: 0.6288\n",
      "Epoch 2841/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0507 - val_loss: 0.6234\n",
      "Epoch 2842/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0502 - val_loss: 0.6254\n",
      "Epoch 2843/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0544 - val_loss: 0.6314\n",
      "Epoch 2844/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0508 - val_loss: 0.6398\n",
      "Epoch 2845/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0456 - val_loss: 0.6252\n",
      "Epoch 2846/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0490 - val_loss: 0.6353\n",
      "Epoch 2847/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0478 - val_loss: 0.6091\n",
      "Epoch 2848/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0502 - val_loss: 0.6348\n",
      "Epoch 2849/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0485 - val_loss: 0.6295\n",
      "Epoch 2850/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0494 - val_loss: 0.6367\n",
      "Epoch 2851/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0564 - val_loss: 0.6326\n",
      "Epoch 2852/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0602 - val_loss: 0.6465\n",
      "Epoch 2853/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0516 - val_loss: 0.6525\n",
      "Epoch 2854/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0492 - val_loss: 0.6308\n",
      "Epoch 2855/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0501 - val_loss: 0.6512\n",
      "Epoch 2856/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0517 - val_loss: 0.6356\n",
      "Epoch 2857/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0506 - val_loss: 0.6341\n",
      "Epoch 2858/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0485 - val_loss: 0.6205\n",
      "Epoch 2859/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0508 - val_loss: 0.6488\n",
      "Epoch 2860/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0538 - val_loss: 0.6303\n",
      "Epoch 2861/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0505 - val_loss: 0.6188\n",
      "Epoch 2862/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0455 - val_loss: 0.6522\n",
      "Epoch 2863/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0484 - val_loss: 0.6385\n",
      "Epoch 2864/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0485 - val_loss: 0.6206\n",
      "Epoch 2865/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0558 - val_loss: 0.6293\n",
      "Epoch 2866/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0658 - val_loss: 0.6414\n",
      "Epoch 2867/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0529 - val_loss: 0.6336\n",
      "Epoch 2868/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0506 - val_loss: 0.6417\n",
      "Epoch 2869/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0467 - val_loss: 0.6458\n",
      "Epoch 2870/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0506 - val_loss: 0.6261\n",
      "Epoch 2871/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0464 - val_loss: 0.6417\n",
      "Epoch 2872/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0578 - val_loss: 0.6553\n",
      "Epoch 2873/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0562 - val_loss: 0.6682\n",
      "Epoch 2874/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0525 - val_loss: 0.6440\n",
      "Epoch 2875/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0432 - val_loss: 0.6226\n",
      "Epoch 2876/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0451 - val_loss: 0.6300\n",
      "Epoch 2877/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0464 - val_loss: 0.6342\n",
      "Epoch 2878/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0474 - val_loss: 0.6357\n",
      "Epoch 2879/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0503 - val_loss: 0.6490\n",
      "Epoch 2880/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0481 - val_loss: 0.6166\n",
      "Epoch 2881/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0410 - val_loss: 0.6459\n",
      "Epoch 2882/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0405 - val_loss: 0.6134\n",
      "Epoch 2883/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0594 - val_loss: 0.6290\n",
      "Epoch 2884/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0627 - val_loss: 0.6125\n",
      "Epoch 2885/10000\n",
      "130/130 [==============================] - 0s 832us/step - loss: 0.0510 - val_loss: 0.6353\n",
      "Epoch 2886/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0477 - val_loss: 0.6249\n",
      "Epoch 2887/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0478 - val_loss: 0.6236\n",
      "Epoch 2888/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0651 - val_loss: 0.6145\n",
      "Epoch 2889/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0699 - val_loss: 0.6232\n",
      "Epoch 2890/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0478 - val_loss: 0.6346\n",
      "Epoch 2891/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 741us/step - loss: 0.0510 - val_loss: 0.6295\n",
      "Epoch 2892/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0475 - val_loss: 0.6232\n",
      "Epoch 2893/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0507 - val_loss: 0.6385\n",
      "Epoch 2894/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0556 - val_loss: 0.6243\n",
      "Epoch 2895/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0472 - val_loss: 0.6406\n",
      "Epoch 2896/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0460 - val_loss: 0.6194\n",
      "Epoch 2897/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0487 - val_loss: 0.6380\n",
      "Epoch 2898/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0504 - val_loss: 0.6242\n",
      "Epoch 2899/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0442 - val_loss: 0.6268\n",
      "Epoch 2900/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0501 - val_loss: 0.6413\n",
      "Epoch 2901/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0608 - val_loss: 0.6357\n",
      "Epoch 2902/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0544 - val_loss: 0.6369\n",
      "Epoch 2903/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0468 - val_loss: 0.6285\n",
      "Epoch 2904/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0503 - val_loss: 0.6241\n",
      "Epoch 2905/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0479 - val_loss: 0.6017\n",
      "Epoch 2906/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0435 - val_loss: 0.6354\n",
      "Epoch 2907/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0467 - val_loss: 0.6181\n",
      "Epoch 2908/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0788 - val_loss: 0.6205\n",
      "Epoch 2909/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0471 - val_loss: 0.6391\n",
      "Epoch 2910/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0464 - val_loss: 0.6180\n",
      "Epoch 2911/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0605 - val_loss: 0.6120\n",
      "Epoch 2912/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0489 - val_loss: 0.6374\n",
      "Epoch 2913/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0517 - val_loss: 0.6129\n",
      "Epoch 2914/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0427 - val_loss: 0.6345\n",
      "Epoch 2915/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0541 - val_loss: 0.6113\n",
      "Epoch 2916/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0459 - val_loss: 0.6458\n",
      "Epoch 2917/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0464 - val_loss: 0.6254\n",
      "Epoch 2918/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0451 - val_loss: 0.6310\n",
      "Epoch 2919/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0446 - val_loss: 0.6292\n",
      "Epoch 2920/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0438 - val_loss: 0.6328\n",
      "Epoch 2921/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0541 - val_loss: 0.6136\n",
      "Epoch 2922/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0501 - val_loss: 0.6254\n",
      "Epoch 2923/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0450 - val_loss: 0.6384\n",
      "Epoch 2924/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0468 - val_loss: 0.6261\n",
      "Epoch 2925/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0449 - val_loss: 0.6324\n",
      "Epoch 2926/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0451 - val_loss: 0.6388\n",
      "Epoch 2927/10000\n",
      "130/130 [==============================] - 0s 830us/step - loss: 0.0485 - val_loss: 0.6300\n",
      "Epoch 2928/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0514 - val_loss: 0.6310\n",
      "Epoch 2929/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0545 - val_loss: 0.6324\n",
      "Epoch 2930/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0506 - val_loss: 0.6347\n",
      "Epoch 2931/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0455 - val_loss: 0.6149\n",
      "Epoch 2932/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0464 - val_loss: 0.6393\n",
      "Epoch 2933/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0608 - val_loss: 0.6233\n",
      "Epoch 2934/10000\n",
      "130/130 [==============================] - 0s 856us/step - loss: 0.0520 - val_loss: 0.6263\n",
      "Epoch 2935/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0452 - val_loss: 0.6232\n",
      "Epoch 2936/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0456 - val_loss: 0.6302\n",
      "Epoch 2937/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0461 - val_loss: 0.6457\n",
      "Epoch 2938/10000\n",
      "130/130 [==============================] - 0s 914us/step - loss: 0.0571 - val_loss: 0.6293\n",
      "Epoch 2939/10000\n",
      "130/130 [==============================] - 0s 878us/step - loss: 0.0596 - val_loss: 0.6111\n",
      "Epoch 2940/10000\n",
      "130/130 [==============================] - 0s 858us/step - loss: 0.0563 - val_loss: 0.6201\n",
      "Epoch 2941/10000\n",
      "130/130 [==============================] - 0s 974us/step - loss: 0.0489 - val_loss: 0.6268\n",
      "Epoch 2942/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0452 - val_loss: 0.6171\n",
      "Epoch 2943/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0469 - val_loss: 0.6587\n",
      "Epoch 2944/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0456 - val_loss: 0.6377\n",
      "Epoch 2945/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0469 - val_loss: 0.6197\n",
      "Epoch 2946/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0403 - val_loss: 0.6365\n",
      "Epoch 2947/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0401 - val_loss: 0.6445\n",
      "Epoch 2948/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0455 - val_loss: 0.6318\n",
      "Epoch 2949/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0542 - val_loss: 0.6311\n",
      "Epoch 2950/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0484 - val_loss: 0.6446\n",
      "Epoch 2951/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0493 - val_loss: 0.6225\n",
      "Epoch 2952/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0463 - val_loss: 0.6252\n",
      "Epoch 2953/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0529 - val_loss: 0.6367\n",
      "Epoch 2954/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0500 - val_loss: 0.6385\n",
      "Epoch 2955/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0550 - val_loss: 0.6285\n",
      "Epoch 2956/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0504 - val_loss: 0.6297\n",
      "Epoch 2957/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0427 - val_loss: 0.6170\n",
      "Epoch 2958/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0469 - val_loss: 0.6268\n",
      "Epoch 2959/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0503 - val_loss: 0.6306\n",
      "Epoch 2960/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0432 - val_loss: 0.6322\n",
      "Epoch 2961/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0466 - val_loss: 0.6273\n",
      "Epoch 2962/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0469 - val_loss: 0.6305\n",
      "Epoch 2963/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0478 - val_loss: 0.6183\n",
      "Epoch 2964/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0467 - val_loss: 0.6339\n",
      "Epoch 2965/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0562 - val_loss: 0.6042\n",
      "Epoch 2966/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0592 - val_loss: 0.6193\n",
      "Epoch 2967/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 715us/step - loss: 0.0445 - val_loss: 0.6176\n",
      "Epoch 2968/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0404 - val_loss: 0.6561\n",
      "Epoch 2969/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0483 - val_loss: 0.6415\n",
      "Epoch 2970/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0487 - val_loss: 0.6343\n",
      "Epoch 2971/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0440 - val_loss: 0.6423\n",
      "Epoch 2972/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0443 - val_loss: 0.6279\n",
      "Epoch 2973/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0618 - val_loss: 0.6515\n",
      "Epoch 2974/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0619 - val_loss: 0.6468\n",
      "Epoch 2975/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0596 - val_loss: 0.6205\n",
      "Epoch 2976/10000\n",
      "130/130 [==============================] - 0s 956us/step - loss: 0.0537 - val_loss: 0.6412\n",
      "Epoch 2977/10000\n",
      "130/130 [==============================] - 0s 820us/step - loss: 0.0414 - val_loss: 0.6371\n",
      "Epoch 2978/10000\n",
      "130/130 [==============================] - 0s 813us/step - loss: 0.0404 - val_loss: 0.6295\n",
      "Epoch 2979/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0394 - val_loss: 0.6415\n",
      "Epoch 2980/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0437 - val_loss: 0.6322\n",
      "Epoch 2981/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0392 - val_loss: 0.6369\n",
      "Epoch 2982/10000\n",
      "130/130 [==============================] - 0s 844us/step - loss: 0.0493 - val_loss: 0.6253\n",
      "Epoch 2983/10000\n",
      "130/130 [==============================] - 0s 882us/step - loss: 0.0580 - val_loss: 0.6209\n",
      "Epoch 2984/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0501 - val_loss: 0.6299\n",
      "Epoch 2985/10000\n",
      "130/130 [==============================] - 0s 879us/step - loss: 0.0460 - val_loss: 0.6294\n",
      "Epoch 2986/10000\n",
      "130/130 [==============================] - 0s 854us/step - loss: 0.0431 - val_loss: 0.6575\n",
      "Epoch 2987/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0558 - val_loss: 0.6282\n",
      "Epoch 2988/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0484 - val_loss: 0.6210\n",
      "Epoch 2989/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0438 - val_loss: 0.6487\n",
      "Epoch 2990/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0538 - val_loss: 0.6062\n",
      "Epoch 2991/10000\n",
      "130/130 [==============================] - 0s 848us/step - loss: 0.0489 - val_loss: 0.6429\n",
      "Epoch 2992/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0443 - val_loss: 0.6267\n",
      "Epoch 2993/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0423 - val_loss: 0.6401\n",
      "Epoch 2994/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0386 - val_loss: 0.6259\n",
      "Epoch 2995/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0455 - val_loss: 0.6253\n",
      "Epoch 2996/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0445 - val_loss: 0.6505\n",
      "Epoch 2997/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0483 - val_loss: 0.6294\n",
      "Epoch 2998/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0519 - val_loss: 0.6283\n",
      "Epoch 2999/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0468 - val_loss: 0.6443\n",
      "Epoch 3000/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0482 - val_loss: 0.6297\n",
      "Epoch 3001/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0441 - val_loss: 0.6498\n",
      "Epoch 3002/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0495 - val_loss: 0.6718\n",
      "Epoch 3003/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0648 - val_loss: 0.6339\n",
      "Epoch 3004/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0485 - val_loss: 0.6404\n",
      "Epoch 3005/10000\n",
      "130/130 [==============================] - 0s 814us/step - loss: 0.0438 - val_loss: 0.6377\n",
      "Epoch 3006/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.6235\n",
      "Epoch 3007/10000\n",
      "130/130 [==============================] - 0s 972us/step - loss: 0.0426 - val_loss: 0.6194\n",
      "Epoch 3008/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0402 - val_loss: 0.6423\n",
      "Epoch 3009/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0453 - val_loss: 0.6104\n",
      "Epoch 3010/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0417 - val_loss: 0.6296\n",
      "Epoch 3011/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0471 - val_loss: 0.6485\n",
      "Epoch 3012/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0501 - val_loss: 0.6483\n",
      "Epoch 3013/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0494 - val_loss: 0.6633\n",
      "Epoch 3014/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0493 - val_loss: 0.6415\n",
      "Epoch 3015/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0438 - val_loss: 0.6241\n",
      "Epoch 3016/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0379 - val_loss: 0.6314\n",
      "Epoch 3017/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0399 - val_loss: 0.6413\n",
      "Epoch 3018/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0508 - val_loss: 0.6353\n",
      "Epoch 3019/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0444 - val_loss: 0.6515\n",
      "Epoch 3020/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0440 - val_loss: 0.6499\n",
      "Epoch 3021/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0396 - val_loss: 0.6244\n",
      "Epoch 3022/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0463 - val_loss: 0.6349\n",
      "Epoch 3023/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0491 - val_loss: 0.6172\n",
      "Epoch 3024/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0557 - val_loss: 0.6384\n",
      "Epoch 3025/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0466 - val_loss: 0.6241\n",
      "Epoch 3026/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0452 - val_loss: 0.6546\n",
      "Epoch 3027/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0527 - val_loss: 0.6273\n",
      "Epoch 3028/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0502 - val_loss: 0.6225\n",
      "Epoch 3029/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0463 - val_loss: 0.6513\n",
      "Epoch 3030/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0398 - val_loss: 0.6373\n",
      "Epoch 3031/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0429 - val_loss: 0.6631\n",
      "Epoch 3032/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0421 - val_loss: 0.6258\n",
      "Epoch 3033/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0461 - val_loss: 0.6273\n",
      "Epoch 3034/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0436 - val_loss: 0.6463\n",
      "Epoch 3035/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0454 - val_loss: 0.6432\n",
      "Epoch 3036/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0484 - val_loss: 0.6924\n",
      "Epoch 3037/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0500 - val_loss: 0.6696\n",
      "Epoch 3038/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0479 - val_loss: 0.6351\n",
      "Epoch 3039/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0469 - val_loss: 0.6408\n",
      "Epoch 3040/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0406 - val_loss: 0.6360\n",
      "Epoch 3041/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0395 - val_loss: 0.6416\n",
      "Epoch 3042/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0400 - val_loss: 0.6356\n",
      "Epoch 3043/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 737us/step - loss: 0.0431 - val_loss: 0.6326\n",
      "Epoch 3044/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0467 - val_loss: 0.6189\n",
      "Epoch 3045/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0461 - val_loss: 0.6445\n",
      "Epoch 3046/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0492 - val_loss: 0.6072\n",
      "Epoch 3047/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0434 - val_loss: 0.6290\n",
      "Epoch 3048/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0464 - val_loss: 0.6173\n",
      "Epoch 3049/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0495 - val_loss: 0.6341\n",
      "Epoch 3050/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0499 - val_loss: 0.6351\n",
      "Epoch 3051/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0437 - val_loss: 0.6203\n",
      "Epoch 3052/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0449 - val_loss: 0.6268\n",
      "Epoch 3053/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0516 - val_loss: 0.6322\n",
      "Epoch 3054/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0464 - val_loss: 0.6420\n",
      "Epoch 3055/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0418 - val_loss: 0.6401\n",
      "Epoch 3056/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0420 - val_loss: 0.6454\n",
      "Epoch 3057/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0469 - val_loss: 0.6284\n",
      "Epoch 3058/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0422 - val_loss: 0.6363\n",
      "Epoch 3059/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0459 - val_loss: 0.6503\n",
      "Epoch 3060/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0635 - val_loss: 0.6672\n",
      "Epoch 3061/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0614 - val_loss: 0.6268\n",
      "Epoch 3062/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0476 - val_loss: 0.6566\n",
      "Epoch 3063/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0480 - val_loss: 0.6475\n",
      "Epoch 3064/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0437 - val_loss: 0.6337\n",
      "Epoch 3065/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0499 - val_loss: 0.6224\n",
      "Epoch 3066/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0368 - val_loss: 0.6387\n",
      "Epoch 3067/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0384 - val_loss: 0.6448\n",
      "Epoch 3068/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0412 - val_loss: 0.6401\n",
      "Epoch 3069/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0438 - val_loss: 0.6365\n",
      "Epoch 3070/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0458 - val_loss: 0.6233\n",
      "Epoch 3071/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0455 - val_loss: 0.6441\n",
      "Epoch 3072/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0412 - val_loss: 0.6384\n",
      "Epoch 3073/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0479 - val_loss: 0.6406\n",
      "Epoch 3074/10000\n",
      "130/130 [==============================] - 0s 804us/step - loss: 0.0428 - val_loss: 0.6275\n",
      "Epoch 3075/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0439 - val_loss: 0.6526\n",
      "Epoch 3076/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0421 - val_loss: 0.6388\n",
      "Epoch 3077/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0444 - val_loss: 0.6420\n",
      "Epoch 3078/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0438 - val_loss: 0.6408\n",
      "Epoch 3079/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0446 - val_loss: 0.6459\n",
      "Epoch 3080/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0590 - val_loss: 0.6502\n",
      "Epoch 3081/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0493 - val_loss: 0.6457\n",
      "Epoch 3082/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0406 - val_loss: 0.6414\n",
      "Epoch 3083/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0376 - val_loss: 0.6544\n",
      "Epoch 3084/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0439 - val_loss: 0.6604\n",
      "Epoch 3085/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0531 - val_loss: 0.6433\n",
      "Epoch 3086/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0460 - val_loss: 0.6365\n",
      "Epoch 3087/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0441 - val_loss: 0.6264\n",
      "Epoch 3088/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0396 - val_loss: 0.6248\n",
      "Epoch 3089/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0378 - val_loss: 0.6263\n",
      "Epoch 3090/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0456 - val_loss: 0.6394\n",
      "Epoch 3091/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0519 - val_loss: 0.6360\n",
      "Epoch 3092/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0421 - val_loss: 0.6395\n",
      "Epoch 3093/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0514 - val_loss: 0.6244\n",
      "Epoch 3094/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0463 - val_loss: 0.6242\n",
      "Epoch 3095/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0420 - val_loss: 0.6505\n",
      "Epoch 3096/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0491 - val_loss: 0.6288\n",
      "Epoch 3097/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0416 - val_loss: 0.6491\n",
      "Epoch 3098/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0438 - val_loss: 0.6540\n",
      "Epoch 3099/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0478 - val_loss: 0.6308\n",
      "Epoch 3100/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0438 - val_loss: 0.6369\n",
      "Epoch 3101/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0541 - val_loss: 0.6566\n",
      "Epoch 3102/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0537 - val_loss: 0.6394\n",
      "Epoch 3103/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0446 - val_loss: 0.6458\n",
      "Epoch 3104/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0417 - val_loss: 0.6477\n",
      "Epoch 3105/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0427 - val_loss: 0.6355\n",
      "Epoch 3106/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0429 - val_loss: 0.6215\n",
      "Epoch 3107/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0481 - val_loss: 0.6298\n",
      "Epoch 3108/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0595 - val_loss: 0.6330\n",
      "Epoch 3109/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0572 - val_loss: 0.6551\n",
      "Epoch 3110/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0412 - val_loss: 0.6372\n",
      "Epoch 3111/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0395 - val_loss: 0.6334\n",
      "Epoch 3112/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0412 - val_loss: 0.6374\n",
      "Epoch 3113/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0454 - val_loss: 0.6318\n",
      "Epoch 3114/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0420 - val_loss: 0.6365\n",
      "Epoch 3115/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0392 - val_loss: 0.6333\n",
      "Epoch 3116/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0498 - val_loss: 0.6437\n",
      "Epoch 3117/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0437 - val_loss: 0.6283\n",
      "Epoch 3118/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0390 - val_loss: 0.6364\n",
      "Epoch 3119/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 719us/step - loss: 0.0411 - val_loss: 0.6597\n",
      "Epoch 3120/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0467 - val_loss: 0.6429\n",
      "Epoch 3121/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0430 - val_loss: 0.6494\n",
      "Epoch 3122/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0427 - val_loss: 0.6330\n",
      "Epoch 3123/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0434 - val_loss: 0.6533\n",
      "Epoch 3124/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0603 - val_loss: 0.6167\n",
      "Epoch 3125/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0412 - val_loss: 0.6369\n",
      "Epoch 3126/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0419 - val_loss: 0.6516\n",
      "Epoch 3127/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0394 - val_loss: 0.6585\n",
      "Epoch 3128/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0452 - val_loss: 0.6254\n",
      "Epoch 3129/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0467 - val_loss: 0.6473\n",
      "Epoch 3130/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0457 - val_loss: 0.6559\n",
      "Epoch 3131/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0462 - val_loss: 0.6239\n",
      "Epoch 3132/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0420 - val_loss: 0.6321\n",
      "Epoch 3133/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0475 - val_loss: 0.6380\n",
      "Epoch 3134/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0478 - val_loss: 0.6348\n",
      "Epoch 3135/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0421 - val_loss: 0.6552\n",
      "Epoch 3136/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0507 - val_loss: 0.6209\n",
      "Epoch 3137/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0480 - val_loss: 0.6479\n",
      "Epoch 3138/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0427 - val_loss: 0.6334\n",
      "Epoch 3139/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0457 - val_loss: 0.6507\n",
      "Epoch 3140/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0444 - val_loss: 0.6331\n",
      "Epoch 3141/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0432 - val_loss: 0.6509\n",
      "Epoch 3142/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0439 - val_loss: 0.6463\n",
      "Epoch 3143/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0457 - val_loss: 0.6673\n",
      "Epoch 3144/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0446 - val_loss: 0.6382\n",
      "Epoch 3145/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0418 - val_loss: 0.6495\n",
      "Epoch 3146/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0448 - val_loss: 0.6388\n",
      "Epoch 3147/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0397 - val_loss: 0.6175\n",
      "Epoch 3148/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0411 - val_loss: 0.6163\n",
      "Epoch 3149/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0400 - val_loss: 0.6287\n",
      "Epoch 3150/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0459 - val_loss: 0.6586\n",
      "Epoch 3151/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0449 - val_loss: 0.6291\n",
      "Epoch 3152/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0378 - val_loss: 0.6319\n",
      "Epoch 3153/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0420 - val_loss: 0.6447\n",
      "Epoch 3154/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0408 - val_loss: 0.6270\n",
      "Epoch 3155/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0438 - val_loss: 0.6284\n",
      "Epoch 3156/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0632 - val_loss: 0.6373\n",
      "Epoch 3157/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0496 - val_loss: 0.6319\n",
      "Epoch 3158/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0380 - val_loss: 0.6217\n",
      "Epoch 3159/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0393 - val_loss: 0.6380\n",
      "Epoch 3160/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0443 - val_loss: 0.6502\n",
      "Epoch 3161/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0439 - val_loss: 0.6395\n",
      "Epoch 3162/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0397 - val_loss: 0.6430\n",
      "Epoch 3163/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0443 - val_loss: 0.6443\n",
      "Epoch 3164/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0430 - val_loss: 0.6516\n",
      "Epoch 3165/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0527 - val_loss: 0.6511\n",
      "Epoch 3166/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0385 - val_loss: 0.6607\n",
      "Epoch 3167/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0362 - val_loss: 0.6253\n",
      "Epoch 3168/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0436 - val_loss: 0.6573\n",
      "Epoch 3169/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0490 - val_loss: 0.6487\n",
      "Epoch 3170/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0506 - val_loss: 0.6375\n",
      "Epoch 3171/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0405 - val_loss: 0.6297\n",
      "Epoch 3172/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0420 - val_loss: 0.6503\n",
      "Epoch 3173/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0435 - val_loss: 0.6142\n",
      "Epoch 3174/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0419 - val_loss: 0.6243\n",
      "Epoch 3175/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0389 - val_loss: 0.6488\n",
      "Epoch 3176/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0442 - val_loss: 0.6449\n",
      "Epoch 3177/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0412 - val_loss: 0.6430\n",
      "Epoch 3178/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0475 - val_loss: 0.6389\n",
      "Epoch 3179/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0503 - val_loss: 0.6276\n",
      "Epoch 3180/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0453 - val_loss: 0.6401\n",
      "Epoch 3181/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0443 - val_loss: 0.6338\n",
      "Epoch 3182/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0437 - val_loss: 0.6511\n",
      "Epoch 3183/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0557 - val_loss: 0.6509\n",
      "Epoch 3184/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0479 - val_loss: 0.6410\n",
      "Epoch 3185/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0372 - val_loss: 0.6349\n",
      "Epoch 3186/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0351 - val_loss: 0.6376\n",
      "Epoch 3187/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0381 - val_loss: 0.6332\n",
      "Epoch 3188/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0389 - val_loss: 0.6260\n",
      "Epoch 3189/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0392 - val_loss: 0.6324\n",
      "Epoch 3190/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0399 - val_loss: 0.6487\n",
      "Epoch 3191/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0421 - val_loss: 0.6544\n",
      "Epoch 3192/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0442 - val_loss: 0.6369\n",
      "Epoch 3193/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0371 - val_loss: 0.6261\n",
      "Epoch 3194/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0497 - val_loss: 0.6404\n",
      "Epoch 3195/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 712us/step - loss: 0.0427 - val_loss: 0.6278\n",
      "Epoch 3196/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0519 - val_loss: 0.6606\n",
      "Epoch 3197/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0422 - val_loss: 0.6426\n",
      "Epoch 3198/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0399 - val_loss: 0.6602\n",
      "Epoch 3199/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0361 - val_loss: 0.6464\n",
      "Epoch 3200/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0372 - val_loss: 0.6429\n",
      "Epoch 3201/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0525 - val_loss: 0.6009\n",
      "Epoch 3202/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0616 - val_loss: 0.6391\n",
      "Epoch 3203/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0388 - val_loss: 0.6307\n",
      "Epoch 3204/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0433 - val_loss: 0.6300\n",
      "Epoch 3205/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0522 - val_loss: 0.6181\n",
      "Epoch 3206/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0371 - val_loss: 0.6315\n",
      "Epoch 3207/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0337 - val_loss: 0.6451\n",
      "Epoch 3208/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0384 - val_loss: 0.6227\n",
      "Epoch 3209/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0422 - val_loss: 0.6356\n",
      "Epoch 3210/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0384 - val_loss: 0.6306\n",
      "Epoch 3211/10000\n",
      "130/130 [==============================] - 0s 792us/step - loss: 0.0383 - val_loss: 0.6358\n",
      "Epoch 3212/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0387 - val_loss: 0.6529\n",
      "Epoch 3213/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0422 - val_loss: 0.6384\n",
      "Epoch 3214/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0460 - val_loss: 0.6246\n",
      "Epoch 3215/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0476 - val_loss: 0.6393\n",
      "Epoch 3216/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0500 - val_loss: 0.6699\n",
      "Epoch 3217/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0410 - val_loss: 0.6425\n",
      "Epoch 3218/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0411 - val_loss: 0.6410\n",
      "Epoch 3219/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0415 - val_loss: 0.6154\n",
      "Epoch 3220/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0426 - val_loss: 0.6535\n",
      "Epoch 3221/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0403 - val_loss: 0.6439\n",
      "Epoch 3222/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0396 - val_loss: 0.6609\n",
      "Epoch 3223/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0446 - val_loss: 0.6361\n",
      "Epoch 3224/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0399 - val_loss: 0.6422\n",
      "Epoch 3225/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0362 - val_loss: 0.6442\n",
      "Epoch 3226/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0451 - val_loss: 0.6268\n",
      "Epoch 3227/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0559 - val_loss: 0.6252\n",
      "Epoch 3228/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0475 - val_loss: 0.6610\n",
      "Epoch 3229/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0407 - val_loss: 0.6567\n",
      "Epoch 3230/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0386 - val_loss: 0.6409\n",
      "Epoch 3231/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0369 - val_loss: 0.6272\n",
      "Epoch 3232/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0327 - val_loss: 0.6407\n",
      "Epoch 3233/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0427 - val_loss: 0.6221\n",
      "Epoch 3234/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0435 - val_loss: 0.6365\n",
      "Epoch 3235/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0444 - val_loss: 0.6259\n",
      "Epoch 3236/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0610 - val_loss: 0.6442\n",
      "Epoch 3237/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0476 - val_loss: 0.6254\n",
      "Epoch 3238/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0355 - val_loss: 0.6342\n",
      "Epoch 3239/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0389 - val_loss: 0.6563\n",
      "Epoch 3240/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0422 - val_loss: 0.6448\n",
      "Epoch 3241/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0391 - val_loss: 0.6278\n",
      "Epoch 3242/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0349 - val_loss: 0.6511\n",
      "Epoch 3243/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0456 - val_loss: 0.6329\n",
      "Epoch 3244/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0478 - val_loss: 0.6331\n",
      "Epoch 3245/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0449 - val_loss: 0.6461\n",
      "Epoch 3246/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0384 - val_loss: 0.6304\n",
      "Epoch 3247/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0416 - val_loss: 0.6329\n",
      "Epoch 3248/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0404 - val_loss: 0.6385\n",
      "Epoch 3249/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0412 - val_loss: 0.6326\n",
      "Epoch 3250/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0409 - val_loss: 0.6368\n",
      "Epoch 3251/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0424 - val_loss: 0.6636\n",
      "Epoch 3252/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0421 - val_loss: 0.6467\n",
      "Epoch 3253/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0373 - val_loss: 0.6296\n",
      "Epoch 3254/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0413 - val_loss: 0.6372\n",
      "Epoch 3255/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0394 - val_loss: 0.6656\n",
      "Epoch 3256/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0417 - val_loss: 0.6790\n",
      "Epoch 3257/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0424 - val_loss: 0.6525\n",
      "Epoch 3258/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0372 - val_loss: 0.6423\n",
      "Epoch 3259/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0393 - val_loss: 0.6304\n",
      "Epoch 3260/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0392 - val_loss: 0.6154\n",
      "Epoch 3261/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0396 - val_loss: 0.6381\n",
      "Epoch 3262/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0449 - val_loss: 0.6353\n",
      "Epoch 3263/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0411 - val_loss: 0.6425\n",
      "Epoch 3264/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0392 - val_loss: 0.6495\n",
      "Epoch 3265/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0380 - val_loss: 0.6212\n",
      "Epoch 3266/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0400 - val_loss: 0.6185\n",
      "Epoch 3267/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0396 - val_loss: 0.6365\n",
      "Epoch 3268/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0462 - val_loss: 0.6302\n",
      "Epoch 3269/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0628 - val_loss: 0.6289\n",
      "Epoch 3270/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0422 - val_loss: 0.6436\n",
      "Epoch 3271/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 771us/step - loss: 0.0390 - val_loss: 0.6609\n",
      "Epoch 3272/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0381 - val_loss: 0.6291\n",
      "Epoch 3273/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0412 - val_loss: 0.6506\n",
      "Epoch 3274/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0397 - val_loss: 0.6479\n",
      "Epoch 3275/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0358 - val_loss: 0.6410\n",
      "Epoch 3276/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0393 - val_loss: 0.6496\n",
      "Epoch 3277/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0471 - val_loss: 0.6386\n",
      "Epoch 3278/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0396 - val_loss: 0.6421\n",
      "Epoch 3279/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0351 - val_loss: 0.6509\n",
      "Epoch 3280/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0375 - val_loss: 0.6486\n",
      "Epoch 3281/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0340 - val_loss: 0.6320\n",
      "Epoch 3282/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0503 - val_loss: 0.6304\n",
      "Epoch 3283/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0426 - val_loss: 0.6534\n",
      "Epoch 3284/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0359 - val_loss: 0.6331\n",
      "Epoch 3285/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0399 - val_loss: 0.6523\n",
      "Epoch 3286/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0383 - val_loss: 0.6540\n",
      "Epoch 3287/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0792 - val_loss: 0.6565\n",
      "Epoch 3288/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0684 - val_loss: 0.6244\n",
      "Epoch 3289/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0370 - val_loss: 0.6205\n",
      "Epoch 3290/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0355 - val_loss: 0.6505\n",
      "Epoch 3291/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0432 - val_loss: 0.6394\n",
      "Epoch 3292/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0341 - val_loss: 0.6362\n",
      "Epoch 3293/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0317 - val_loss: 0.6525\n",
      "Epoch 3294/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0402 - val_loss: 0.6171\n",
      "Epoch 3295/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0389 - val_loss: 0.6455\n",
      "Epoch 3296/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0360 - val_loss: 0.6412\n",
      "Epoch 3297/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0411 - val_loss: 0.6680\n",
      "Epoch 3298/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0356 - val_loss: 0.6439\n",
      "Epoch 3299/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0410 - val_loss: 0.6446\n",
      "Epoch 3300/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0460 - val_loss: 0.6281\n",
      "Epoch 3301/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0468 - val_loss: 0.6437\n",
      "Epoch 3302/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0359 - val_loss: 0.6348\n",
      "Epoch 3303/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0344 - val_loss: 0.6411\n",
      "Epoch 3304/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0412 - val_loss: 0.6641\n",
      "Epoch 3305/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0343 - val_loss: 0.6640\n",
      "Epoch 3306/10000\n",
      "130/130 [==============================] - 0s 706us/step - loss: 0.0386 - val_loss: 0.6393\n",
      "Epoch 3307/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0370 - val_loss: 0.6508\n",
      "Epoch 3308/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0460 - val_loss: 0.6175\n",
      "Epoch 3309/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0464 - val_loss: 0.6381\n",
      "Epoch 3310/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0341 - val_loss: 0.6442\n",
      "Epoch 3311/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0392 - val_loss: 0.6383\n",
      "Epoch 3312/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0368 - val_loss: 0.6547\n",
      "Epoch 3313/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0377 - val_loss: 0.6612\n",
      "Epoch 3314/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0415 - val_loss: 0.6485\n",
      "Epoch 3315/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0578 - val_loss: 0.6389\n",
      "Epoch 3316/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0434 - val_loss: 0.6337\n",
      "Epoch 3317/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0390 - val_loss: 0.6272\n",
      "Epoch 3318/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0430 - val_loss: 0.6379\n",
      "Epoch 3319/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0573 - val_loss: 0.6505\n",
      "Epoch 3320/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0496 - val_loss: 0.6441\n",
      "Epoch 3321/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0384 - val_loss: 0.6390\n",
      "Epoch 3322/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0437 - val_loss: 0.6411\n",
      "Epoch 3323/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0348 - val_loss: 0.6337\n",
      "Epoch 3324/10000\n",
      "130/130 [==============================] - 0s 792us/step - loss: 0.0332 - val_loss: 0.6624\n",
      "Epoch 3325/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0322 - val_loss: 0.6432\n",
      "Epoch 3326/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0381 - val_loss: 0.6317\n",
      "Epoch 3327/10000\n",
      "130/130 [==============================] - 0s 839us/step - loss: 0.0413 - val_loss: 0.6188\n",
      "Epoch 3328/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0353 - val_loss: 0.6441\n",
      "Epoch 3329/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0426 - val_loss: 0.6475\n",
      "Epoch 3330/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0339 - val_loss: 0.6529\n",
      "Epoch 3331/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0393 - val_loss: 0.6656\n",
      "Epoch 3332/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0440 - val_loss: 0.6351\n",
      "Epoch 3333/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0410 - val_loss: 0.6461\n",
      "Epoch 3334/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0356 - val_loss: 0.6455\n",
      "Epoch 3335/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0382 - val_loss: 0.6394\n",
      "Epoch 3336/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0438 - val_loss: 0.6368\n",
      "Epoch 3337/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0401 - val_loss: 0.6421\n",
      "Epoch 3338/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0425 - val_loss: 0.6349\n",
      "Epoch 3339/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0443 - val_loss: 0.6472\n",
      "Epoch 3340/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0373 - val_loss: 0.6439\n",
      "Epoch 3341/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0374 - val_loss: 0.6402\n",
      "Epoch 3342/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0408 - val_loss: 0.6394\n",
      "Epoch 3343/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0383 - val_loss: 0.6342\n",
      "Epoch 3344/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0350 - val_loss: 0.6342\n",
      "Epoch 3345/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0362 - val_loss: 0.6455\n",
      "Epoch 3346/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0364 - val_loss: 0.6495\n",
      "Epoch 3347/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 715us/step - loss: 0.0451 - val_loss: 0.6361\n",
      "Epoch 3348/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0477 - val_loss: 0.6509\n",
      "Epoch 3349/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0404 - val_loss: 0.6452\n",
      "Epoch 3350/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0400 - val_loss: 0.6352\n",
      "Epoch 3351/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0386 - val_loss: 0.6408\n",
      "Epoch 3352/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0382 - val_loss: 0.6527\n",
      "Epoch 3353/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0356 - val_loss: 0.6322\n",
      "Epoch 3354/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0369 - val_loss: 0.6538\n",
      "Epoch 3355/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0381 - val_loss: 0.6357\n",
      "Epoch 3356/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0528 - val_loss: 0.6282\n",
      "Epoch 3357/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0455 - val_loss: 0.6369\n",
      "Epoch 3358/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0414 - val_loss: 0.6411\n",
      "Epoch 3359/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0385 - val_loss: 0.6340\n",
      "Epoch 3360/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0402 - val_loss: 0.6188\n",
      "Epoch 3361/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0433 - val_loss: 0.6218\n",
      "Epoch 3362/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0501 - val_loss: 0.6641\n",
      "Epoch 3363/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0410 - val_loss: 0.6469\n",
      "Epoch 3364/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0326 - val_loss: 0.6431\n",
      "Epoch 3365/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0357 - val_loss: 0.6170\n",
      "Epoch 3366/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0408 - val_loss: 0.6348\n",
      "Epoch 3367/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0395 - val_loss: 0.6277\n",
      "Epoch 3368/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0393 - val_loss: 0.6652\n",
      "Epoch 3369/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0415 - val_loss: 0.6448\n",
      "Epoch 3370/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0453 - val_loss: 0.6318\n",
      "Epoch 3371/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0388 - val_loss: 0.6401\n",
      "Epoch 3372/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0368 - val_loss: 0.6406\n",
      "Epoch 3373/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0320 - val_loss: 0.6379\n",
      "Epoch 3374/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0387 - val_loss: 0.6370\n",
      "Epoch 3375/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0371 - val_loss: 0.6355\n",
      "Epoch 3376/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0379 - val_loss: 0.6311\n",
      "Epoch 3377/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0374 - val_loss: 0.6262\n",
      "Epoch 3378/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0410 - val_loss: 0.6396\n",
      "Epoch 3379/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0432 - val_loss: 0.6283\n",
      "Epoch 3380/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0382 - val_loss: 0.6286\n",
      "Epoch 3381/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0395 - val_loss: 0.6340\n",
      "Epoch 3382/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0354 - val_loss: 0.6431\n",
      "Epoch 3383/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0407 - val_loss: 0.6251\n",
      "Epoch 3384/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0430 - val_loss: 0.6194\n",
      "Epoch 3385/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0369 - val_loss: 0.6471\n",
      "Epoch 3386/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0361 - val_loss: 0.6505\n",
      "Epoch 3387/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0353 - val_loss: 0.6380\n",
      "Epoch 3388/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0357 - val_loss: 0.6376\n",
      "Epoch 3389/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0475 - val_loss: 0.6359\n",
      "Epoch 3390/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0473 - val_loss: 0.6398\n",
      "Epoch 3391/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0333 - val_loss: 0.6304\n",
      "Epoch 3392/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0346 - val_loss: 0.6357\n",
      "Epoch 3393/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0332 - val_loss: 0.6287\n",
      "Epoch 3394/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0357 - val_loss: 0.6546\n",
      "Epoch 3395/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0457 - val_loss: 0.6430\n",
      "Epoch 3396/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0425 - val_loss: 0.6397\n",
      "Epoch 3397/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0486 - val_loss: 0.6570\n",
      "Epoch 3398/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0404 - val_loss: 0.6318\n",
      "Epoch 3399/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0354 - val_loss: 0.6481\n",
      "Epoch 3400/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0365 - val_loss: 0.6541\n",
      "Epoch 3401/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0464 - val_loss: 0.6098\n",
      "Epoch 3402/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0457 - val_loss: 0.6406\n",
      "Epoch 3403/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0345 - val_loss: 0.6280\n",
      "Epoch 3404/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0400 - val_loss: 0.6336\n",
      "Epoch 3405/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0410 - val_loss: 0.6408\n",
      "Epoch 3406/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0486 - val_loss: 0.6514\n",
      "Epoch 3407/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0420 - val_loss: 0.6498\n",
      "Epoch 3408/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0312 - val_loss: 0.6426\n",
      "Epoch 3409/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0325 - val_loss: 0.6301\n",
      "Epoch 3410/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0349 - val_loss: 0.6269\n",
      "Epoch 3411/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0349 - val_loss: 0.6373\n",
      "Epoch 3412/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0426 - val_loss: 0.6432\n",
      "Epoch 3413/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0578 - val_loss: 0.6598\n",
      "Epoch 3414/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0616 - val_loss: 0.6284\n",
      "Epoch 3415/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0355 - val_loss: 0.6390\n",
      "Epoch 3416/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0349 - val_loss: 0.6271\n",
      "Epoch 3417/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0334 - val_loss: 0.6424\n",
      "Epoch 3418/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0324 - val_loss: 0.6539\n",
      "Epoch 3419/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0317 - val_loss: 0.6367\n",
      "Epoch 3420/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0449 - val_loss: 0.6288\n",
      "Epoch 3421/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0338 - val_loss: 0.6601\n",
      "Epoch 3422/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0343 - val_loss: 0.6356\n",
      "Epoch 3423/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 721us/step - loss: 0.0400 - val_loss: 0.6169\n",
      "Epoch 3424/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0399 - val_loss: 0.6575\n",
      "Epoch 3425/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0351 - val_loss: 0.6325\n",
      "Epoch 3426/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0355 - val_loss: 0.6305\n",
      "Epoch 3427/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0405 - val_loss: 0.6321\n",
      "Epoch 3428/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0328 - val_loss: 0.6326\n",
      "Epoch 3429/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0429 - val_loss: 0.6439\n",
      "Epoch 3430/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0365 - val_loss: 0.6496\n",
      "Epoch 3431/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0532 - val_loss: 0.6522\n",
      "Epoch 3432/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0466 - val_loss: 0.6443\n",
      "Epoch 3433/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0724 - val_loss: 0.6541\n",
      "Epoch 3434/10000\n",
      "130/130 [==============================] - 0s 706us/step - loss: 0.0359 - val_loss: 0.6529\n",
      "Epoch 3435/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0362 - val_loss: 0.6101\n",
      "Epoch 3436/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0303 - val_loss: 0.6300\n",
      "Epoch 3437/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0360 - val_loss: 0.6361\n",
      "Epoch 3438/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0332 - val_loss: 0.6427\n",
      "Epoch 3439/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0349 - val_loss: 0.6241\n",
      "Epoch 3440/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0364 - val_loss: 0.6372\n",
      "Epoch 3441/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0444 - val_loss: 0.6627\n",
      "Epoch 3442/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0401 - val_loss: 0.6248\n",
      "Epoch 3443/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0306 - val_loss: 0.6331\n",
      "Epoch 3444/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0354 - val_loss: 0.6294\n",
      "Epoch 3445/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0352 - val_loss: 0.6165\n",
      "Epoch 3446/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0326 - val_loss: 0.6188\n",
      "Epoch 3447/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0360 - val_loss: 0.6560\n",
      "Epoch 3448/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0460 - val_loss: 0.6237\n",
      "Epoch 3449/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0360 - val_loss: 0.6472\n",
      "Epoch 3450/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0358 - val_loss: 0.6406\n",
      "Epoch 3451/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0355 - val_loss: 0.6519\n",
      "Epoch 3452/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0409 - val_loss: 0.6530\n",
      "Epoch 3453/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0459 - val_loss: 0.6396\n",
      "Epoch 3454/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0362 - val_loss: 0.6293\n",
      "Epoch 3455/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0363 - val_loss: 0.6582\n",
      "Epoch 3456/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0361 - val_loss: 0.6533\n",
      "Epoch 3457/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0327 - val_loss: 0.6458\n",
      "Epoch 3458/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0403 - val_loss: 0.6445\n",
      "Epoch 3459/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0396 - val_loss: 0.6412\n",
      "Epoch 3460/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0369 - val_loss: 0.6302\n",
      "Epoch 3461/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0386 - val_loss: 0.6440\n",
      "Epoch 3462/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0401 - val_loss: 0.6302\n",
      "Epoch 3463/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0348 - val_loss: 0.6388\n",
      "Epoch 3464/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0362 - val_loss: 0.6352\n",
      "Epoch 3465/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0568 - val_loss: 0.6162\n",
      "Epoch 3466/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0463 - val_loss: 0.6329\n",
      "Epoch 3467/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0371 - val_loss: 0.6231\n",
      "Epoch 3468/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0348 - val_loss: 0.6598\n",
      "Epoch 3469/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0393 - val_loss: 0.6489\n",
      "Epoch 3470/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0431 - val_loss: 0.6334\n",
      "Epoch 3471/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0490 - val_loss: 0.6428\n",
      "Epoch 3472/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0371 - val_loss: 0.6382\n",
      "Epoch 3473/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0300 - val_loss: 0.6401\n",
      "Epoch 3474/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0301 - val_loss: 0.6387\n",
      "Epoch 3475/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0381 - val_loss: 0.6383\n",
      "Epoch 3476/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0374 - val_loss: 0.6551\n",
      "Epoch 3477/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0440 - val_loss: 0.6479\n",
      "Epoch 3478/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0505 - val_loss: 0.6301\n",
      "Epoch 3479/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0400 - val_loss: 0.6210\n",
      "Epoch 3480/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0324 - val_loss: 0.6429\n",
      "Epoch 3481/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0322 - val_loss: 0.6473\n",
      "Epoch 3482/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0339 - val_loss: 0.6361\n",
      "Epoch 3483/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0440 - val_loss: 0.6352\n",
      "Epoch 3484/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0426 - val_loss: 0.6259\n",
      "Epoch 3485/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0357 - val_loss: 0.6410\n",
      "Epoch 3486/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0360 - val_loss: 0.6565\n",
      "Epoch 3487/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0341 - val_loss: 0.6444\n",
      "Epoch 3488/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0341 - val_loss: 0.6349\n",
      "Epoch 3489/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0321 - val_loss: 0.6291\n",
      "Epoch 3490/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0305 - val_loss: 0.6355\n",
      "Epoch 3491/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0375 - val_loss: 0.6383\n",
      "Epoch 3492/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0387 - val_loss: 0.6476\n",
      "Epoch 3493/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0386 - val_loss: 0.6378\n",
      "Epoch 3494/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0486 - val_loss: 0.6480\n",
      "Epoch 3495/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0342 - val_loss: 0.6368\n",
      "Epoch 3496/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0307 - val_loss: 0.6336\n",
      "Epoch 3497/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0358 - val_loss: 0.6411\n",
      "Epoch 3498/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0329 - val_loss: 0.6522\n",
      "Epoch 3499/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 713us/step - loss: 0.0386 - val_loss: 0.6481\n",
      "Epoch 3500/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0482 - val_loss: 0.6108\n",
      "Epoch 3501/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0452 - val_loss: 0.6412\n",
      "Epoch 3502/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0424 - val_loss: 0.6548\n",
      "Epoch 3503/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0398 - val_loss: 0.6328\n",
      "Epoch 3504/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0404 - val_loss: 0.6269\n",
      "Epoch 3505/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0363 - val_loss: 0.6316\n",
      "Epoch 3506/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0331 - val_loss: 0.6466\n",
      "Epoch 3507/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0338 - val_loss: 0.6649\n",
      "Epoch 3508/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0349 - val_loss: 0.6354\n",
      "Epoch 3509/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0284 - val_loss: 0.6428\n",
      "Epoch 3510/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0429 - val_loss: 0.6442\n",
      "Epoch 3511/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0405 - val_loss: 0.6280\n",
      "Epoch 3512/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0347 - val_loss: 0.6363\n",
      "Epoch 3513/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0382 - val_loss: 0.6619\n",
      "Epoch 3514/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0443 - val_loss: 0.6417\n",
      "Epoch 3515/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0386 - val_loss: 0.6248\n",
      "Epoch 3516/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0367 - val_loss: 0.6550\n",
      "Epoch 3517/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0315 - val_loss: 0.6383\n",
      "Epoch 3518/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0334 - val_loss: 0.6389\n",
      "Epoch 3519/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0383 - val_loss: 0.6457\n",
      "Epoch 3520/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0420 - val_loss: 0.6354\n",
      "Epoch 3521/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0456 - val_loss: 0.6668\n",
      "Epoch 3522/10000\n",
      "130/130 [==============================] - 0s 706us/step - loss: 0.0406 - val_loss: 0.6194\n",
      "Epoch 3523/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0295 - val_loss: 0.6210\n",
      "Epoch 3524/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0320 - val_loss: 0.6467\n",
      "Epoch 3525/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0406 - val_loss: 0.6341\n",
      "Epoch 3526/10000\n",
      "130/130 [==============================] - 0s 703us/step - loss: 0.0446 - val_loss: 0.6535\n",
      "Epoch 3527/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0466 - val_loss: 0.6357\n",
      "Epoch 3528/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0416 - val_loss: 0.6552\n",
      "Epoch 3529/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0329 - val_loss: 0.6335\n",
      "Epoch 3530/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0395 - val_loss: 0.6237\n",
      "Epoch 3531/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0347 - val_loss: 0.6371\n",
      "Epoch 3532/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0321 - val_loss: 0.6392\n",
      "Epoch 3533/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0312 - val_loss: 0.6451\n",
      "Epoch 3534/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0376 - val_loss: 0.6486\n",
      "Epoch 3535/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0404 - val_loss: 0.6585\n",
      "Epoch 3536/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0352 - val_loss: 0.6459\n",
      "Epoch 3537/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0336 - val_loss: 0.6445\n",
      "Epoch 3538/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0327 - val_loss: 0.6289\n",
      "Epoch 3539/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0379 - val_loss: 0.6538\n",
      "Epoch 3540/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0335 - val_loss: 0.6472\n",
      "Epoch 3541/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0351 - val_loss: 0.6496\n",
      "Epoch 3542/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0390 - val_loss: 0.6329\n",
      "Epoch 3543/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0369 - val_loss: 0.6623\n",
      "Epoch 3544/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0393 - val_loss: 0.6503\n",
      "Epoch 3545/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0448 - val_loss: 0.6620\n",
      "Epoch 3546/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0394 - val_loss: 0.6424\n",
      "Epoch 3547/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0471 - val_loss: 0.6437\n",
      "Epoch 3548/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0440 - val_loss: 0.6339\n",
      "Epoch 3549/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0392 - val_loss: 0.6438\n",
      "Epoch 3550/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0336 - val_loss: 0.6411\n",
      "Epoch 3551/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0291 - val_loss: 0.6328\n",
      "Epoch 3552/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0327 - val_loss: 0.6340\n",
      "Epoch 3553/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0389 - val_loss: 0.6426\n",
      "Epoch 3554/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0368 - val_loss: 0.6164\n",
      "Epoch 3555/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0395 - val_loss: 0.6481\n",
      "Epoch 3556/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0381 - val_loss: 0.6198\n",
      "Epoch 3557/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0309 - val_loss: 0.6495\n",
      "Epoch 3558/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0318 - val_loss: 0.6675\n",
      "Epoch 3559/10000\n",
      "130/130 [==============================] - 0s 703us/step - loss: 0.0337 - val_loss: 0.6314\n",
      "Epoch 3560/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0362 - val_loss: 0.6321\n",
      "Epoch 3561/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0347 - val_loss: 0.6428\n",
      "Epoch 3562/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0370 - val_loss: 0.6419\n",
      "Epoch 3563/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0411 - val_loss: 0.6427\n",
      "Epoch 3564/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0400 - val_loss: 0.6311\n",
      "Epoch 3565/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0405 - val_loss: 0.6561\n",
      "Epoch 3566/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0364 - val_loss: 0.6499\n",
      "Epoch 3567/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0338 - val_loss: 0.6447\n",
      "Epoch 3568/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0329 - val_loss: 0.6612\n",
      "Epoch 3569/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0341 - val_loss: 0.6542\n",
      "Epoch 3570/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0498 - val_loss: 0.6650\n",
      "Epoch 3571/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0392 - val_loss: 0.6265\n",
      "Epoch 3572/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0337 - val_loss: 0.6319\n",
      "Epoch 3573/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0450 - val_loss: 0.6299\n",
      "Epoch 3574/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0358 - val_loss: 0.6553\n",
      "Epoch 3575/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 714us/step - loss: 0.0271 - val_loss: 0.6323\n",
      "Epoch 3576/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0281 - val_loss: 0.6523\n",
      "Epoch 3577/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0349 - val_loss: 0.6564\n",
      "Epoch 3578/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0433 - val_loss: 0.6387\n",
      "Epoch 3579/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0338 - val_loss: 0.6389\n",
      "Epoch 3580/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0396 - val_loss: 0.6451\n",
      "Epoch 3581/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0343 - val_loss: 0.6449\n",
      "Epoch 3582/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0327 - val_loss: 0.6342\n",
      "Epoch 3583/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0352 - val_loss: 0.6366\n",
      "Epoch 3584/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0309 - val_loss: 0.6466\n",
      "Epoch 3585/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0343 - val_loss: 0.6389\n",
      "Epoch 3586/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0318 - val_loss: 0.6357\n",
      "Epoch 3587/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0326 - val_loss: 0.6386\n",
      "Epoch 3588/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0394 - val_loss: 0.6286\n",
      "Epoch 3589/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0443 - val_loss: 0.6379\n",
      "Epoch 3590/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0533 - val_loss: 0.6187\n",
      "Epoch 3591/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0475 - val_loss: 0.6430\n",
      "Epoch 3592/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0397 - val_loss: 0.6413\n",
      "Epoch 3593/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0319 - val_loss: 0.6447\n",
      "Epoch 3594/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0315 - val_loss: 0.6316\n",
      "Epoch 3595/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0345 - val_loss: 0.6262\n",
      "Epoch 3596/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0326 - val_loss: 0.6313\n",
      "Epoch 3597/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0299 - val_loss: 0.6353\n",
      "Epoch 3598/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0328 - val_loss: 0.6566\n",
      "Epoch 3599/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0350 - val_loss: 0.6338\n",
      "Epoch 3600/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0328 - val_loss: 0.6390\n",
      "Epoch 3601/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0312 - val_loss: 0.6432\n",
      "Epoch 3602/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0490 - val_loss: 0.6450\n",
      "Epoch 3603/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0311 - val_loss: 0.6324\n",
      "Epoch 3604/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0315 - val_loss: 0.6271\n",
      "Epoch 3605/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0362 - val_loss: 0.6469\n",
      "Epoch 3606/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0366 - val_loss: 0.6307\n",
      "Epoch 3607/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0332 - val_loss: 0.6569\n",
      "Epoch 3608/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0346 - val_loss: 0.6356\n",
      "Epoch 3609/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0399 - val_loss: 0.6214\n",
      "Epoch 3610/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0429 - val_loss: 0.6381\n",
      "Epoch 3611/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0326 - val_loss: 0.6414\n",
      "Epoch 3612/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0304 - val_loss: 0.6533\n",
      "Epoch 3613/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0313 - val_loss: 0.6389\n",
      "Epoch 3614/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0310 - val_loss: 0.6383\n",
      "Epoch 3615/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0380 - val_loss: 0.6486\n",
      "Epoch 3616/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0482 - val_loss: 0.6482\n",
      "Epoch 3617/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0375 - val_loss: 0.6567\n",
      "Epoch 3618/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0621 - val_loss: 0.6428\n",
      "Epoch 3619/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0424 - val_loss: 0.6380\n",
      "Epoch 3620/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0271 - val_loss: 0.6446\n",
      "Epoch 3621/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0271 - val_loss: 0.6318\n",
      "Epoch 3622/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0291 - val_loss: 0.6364\n",
      "Epoch 3623/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0354 - val_loss: 0.6443\n",
      "Epoch 3624/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0300 - val_loss: 0.6413\n",
      "Epoch 3625/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0292 - val_loss: 0.6474\n",
      "Epoch 3626/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0281 - val_loss: 0.6440\n",
      "Epoch 3627/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0369 - val_loss: 0.6590\n",
      "Epoch 3628/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0683 - val_loss: 0.6608\n",
      "Epoch 3629/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0481 - val_loss: 0.6192\n",
      "Epoch 3630/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0362 - val_loss: 0.6304\n",
      "Epoch 3631/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0360 - val_loss: 0.6274\n",
      "Epoch 3632/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0295 - val_loss: 0.6378\n",
      "Epoch 3633/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0282 - val_loss: 0.6272\n",
      "Epoch 3634/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0299 - val_loss: 0.6477\n",
      "Epoch 3635/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0343 - val_loss: 0.6430\n",
      "Epoch 3636/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0357 - val_loss: 0.6219\n",
      "Epoch 3637/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0352 - val_loss: 0.6278\n",
      "Epoch 3638/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0369 - val_loss: 0.6217\n",
      "Epoch 3639/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0358 - val_loss: 0.6603\n",
      "Epoch 3640/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0598 - val_loss: 0.6146\n",
      "Epoch 3641/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0507 - val_loss: 0.6354\n",
      "Epoch 3642/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0373 - val_loss: 0.6328\n",
      "Epoch 3643/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0272 - val_loss: 0.6363\n",
      "Epoch 3644/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0349 - val_loss: 0.6433\n",
      "Epoch 3645/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0333 - val_loss: 0.6341\n",
      "Epoch 3646/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0329 - val_loss: 0.6469\n",
      "Epoch 3647/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0363 - val_loss: 0.6500\n",
      "Epoch 3648/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0374 - val_loss: 0.6486\n",
      "Epoch 3649/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0330 - val_loss: 0.6435\n",
      "Epoch 3650/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0297 - val_loss: 0.6392\n",
      "Epoch 3651/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 717us/step - loss: 0.0312 - val_loss: 0.6446\n",
      "Epoch 3652/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0363 - val_loss: 0.6356\n",
      "Epoch 3653/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0303 - val_loss: 0.6245\n",
      "Epoch 3654/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0472 - val_loss: 0.6448\n",
      "Epoch 3655/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0393 - val_loss: 0.6123\n",
      "Epoch 3656/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0370 - val_loss: 0.6278\n",
      "Epoch 3657/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0378 - val_loss: 0.6303\n",
      "Epoch 3658/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0313 - val_loss: 0.6298\n",
      "Epoch 3659/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0361 - val_loss: 0.6235\n",
      "Epoch 3660/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0554 - val_loss: 0.6332\n",
      "Epoch 3661/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0366 - val_loss: 0.6395\n",
      "Epoch 3662/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0316 - val_loss: 0.6261\n",
      "Epoch 3663/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0310 - val_loss: 0.6203\n",
      "Epoch 3664/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0330 - val_loss: 0.6403\n",
      "Epoch 3665/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0310 - val_loss: 0.6314\n",
      "Epoch 3666/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0354 - val_loss: 0.6501\n",
      "Epoch 3667/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0338 - val_loss: 0.6461\n",
      "Epoch 3668/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0315 - val_loss: 0.6397\n",
      "Epoch 3669/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0295 - val_loss: 0.6528\n",
      "Epoch 3670/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0295 - val_loss: 0.6552\n",
      "Epoch 3671/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0423 - val_loss: 0.6532\n",
      "Epoch 3672/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0423 - val_loss: 0.6410\n",
      "Epoch 3673/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0368 - val_loss: 0.6367\n",
      "Epoch 3674/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0308 - val_loss: 0.6324\n",
      "Epoch 3675/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0338 - val_loss: 0.6400\n",
      "Epoch 3676/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0296 - val_loss: 0.6530\n",
      "Epoch 3677/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0324 - val_loss: 0.6099\n",
      "Epoch 3678/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0354 - val_loss: 0.6390\n",
      "Epoch 3679/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0680 - val_loss: 0.6617\n",
      "Epoch 3680/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0658 - val_loss: 0.6342\n",
      "Epoch 3681/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0332 - val_loss: 0.6348\n",
      "Epoch 3682/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0275 - val_loss: 0.6322\n",
      "Epoch 3683/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0268 - val_loss: 0.6470\n",
      "Epoch 3684/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0308 - val_loss: 0.6400\n",
      "Epoch 3685/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0346 - val_loss: 0.6426\n",
      "Epoch 3686/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0356 - val_loss: 0.6225\n",
      "Epoch 3687/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0320 - val_loss: 0.6199\n",
      "Epoch 3688/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0327 - val_loss: 0.6520\n",
      "Epoch 3689/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0315 - val_loss: 0.6472\n",
      "Epoch 3690/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0331 - val_loss: 0.6446\n",
      "Epoch 3691/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0482 - val_loss: 0.6386\n",
      "Epoch 3692/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0407 - val_loss: 0.6388\n",
      "Epoch 3693/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0403 - val_loss: 0.6580\n",
      "Epoch 3694/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0287 - val_loss: 0.6412\n",
      "Epoch 3695/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0349 - val_loss: 0.6104\n",
      "Epoch 3696/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0334 - val_loss: 0.6489\n",
      "Epoch 3697/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0291 - val_loss: 0.6287\n",
      "Epoch 3698/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0318 - val_loss: 0.6427\n",
      "Epoch 3699/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0459 - val_loss: 0.6713\n",
      "Epoch 3700/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0393 - val_loss: 0.6222\n",
      "Epoch 3701/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0328 - val_loss: 0.6560\n",
      "Epoch 3702/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0364 - val_loss: 0.6277\n",
      "Epoch 3703/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0327 - val_loss: 0.6341\n",
      "Epoch 3704/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0276 - val_loss: 0.6248\n",
      "Epoch 3705/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0270 - val_loss: 0.6389\n",
      "Epoch 3706/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0323 - val_loss: 0.6297\n",
      "Epoch 3707/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0347 - val_loss: 0.6489\n",
      "Epoch 3708/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0349 - val_loss: 0.6209\n",
      "Epoch 3709/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0395 - val_loss: 0.6342\n",
      "Epoch 3710/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0331 - val_loss: 0.6463\n",
      "Epoch 3711/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0363 - val_loss: 0.6407\n",
      "Epoch 3712/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0367 - val_loss: 0.6368\n",
      "Epoch 3713/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0459 - val_loss: 0.6423\n",
      "Epoch 3714/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0426 - val_loss: 0.6218\n",
      "Epoch 3715/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0352 - val_loss: 0.6335\n",
      "Epoch 3716/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0307 - val_loss: 0.6641\n",
      "Epoch 3717/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0306 - val_loss: 0.6453\n",
      "Epoch 3718/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0306 - val_loss: 0.6394\n",
      "Epoch 3719/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0301 - val_loss: 0.6410\n",
      "Epoch 3720/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0319 - val_loss: 0.6366\n",
      "Epoch 3721/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0431 - val_loss: 0.6210\n",
      "Epoch 3722/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0307 - val_loss: 0.6372\n",
      "Epoch 3723/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0282 - val_loss: 0.6479\n",
      "Epoch 3724/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0347 - val_loss: 0.6525\n",
      "Epoch 3725/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0490 - val_loss: 0.6523\n",
      "Epoch 3726/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0342 - val_loss: 0.6344\n",
      "Epoch 3727/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 720us/step - loss: 0.0323 - val_loss: 0.6614\n",
      "Epoch 3728/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0318 - val_loss: 0.6362\n",
      "Epoch 3729/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0307 - val_loss: 0.6304\n",
      "Epoch 3730/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0352 - val_loss: 0.6425\n",
      "Epoch 3731/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0355 - val_loss: 0.6317\n",
      "Epoch 3732/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0343 - val_loss: 0.6478\n",
      "Epoch 3733/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0314 - val_loss: 0.6465\n",
      "Epoch 3734/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0258 - val_loss: 0.6481\n",
      "Epoch 3735/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0313 - val_loss: 0.6517\n",
      "Epoch 3736/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0388 - val_loss: 0.6185\n",
      "Epoch 3737/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0427 - val_loss: 0.6428\n",
      "Epoch 3738/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0364 - val_loss: 0.6323\n",
      "Epoch 3739/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0397 - val_loss: 0.6353\n",
      "Epoch 3740/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0357 - val_loss: 0.6578\n",
      "Epoch 3741/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0379 - val_loss: 0.6143\n",
      "Epoch 3742/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0404 - val_loss: 0.6271\n",
      "Epoch 3743/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0341 - val_loss: 0.6418\n",
      "Epoch 3744/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0324 - val_loss: 0.6405\n",
      "Epoch 3745/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0368 - val_loss: 0.6413\n",
      "Epoch 3746/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0338 - val_loss: 0.6344\n",
      "Epoch 3747/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0304 - val_loss: 0.6313\n",
      "Epoch 3748/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0301 - val_loss: 0.6450\n",
      "Epoch 3749/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0305 - val_loss: 0.6334\n",
      "Epoch 3750/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0344 - val_loss: 0.6273\n",
      "Epoch 3751/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0317 - val_loss: 0.6352\n",
      "Epoch 3752/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0321 - val_loss: 0.6358\n",
      "Epoch 3753/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0327 - val_loss: 0.6413\n",
      "Epoch 3754/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0310 - val_loss: 0.6324\n",
      "Epoch 3755/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0333 - val_loss: 0.6190\n",
      "Epoch 3756/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0356 - val_loss: 0.6160\n",
      "Epoch 3757/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0455 - val_loss: 0.6608\n",
      "Epoch 3758/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0336 - val_loss: 0.6338\n",
      "Epoch 3759/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0272 - val_loss: 0.6335\n",
      "Epoch 3760/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0262 - val_loss: 0.6387\n",
      "Epoch 3761/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0348 - val_loss: 0.6422\n",
      "Epoch 3762/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0371 - val_loss: 0.6605\n",
      "Epoch 3763/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0368 - val_loss: 0.6336\n",
      "Epoch 3764/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0272 - val_loss: 0.6278\n",
      "Epoch 3765/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0285 - val_loss: 0.6413\n",
      "Epoch 3766/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0315 - val_loss: 0.6229\n",
      "Epoch 3767/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0358 - val_loss: 0.6330\n",
      "Epoch 3768/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0488 - val_loss: 0.6642\n",
      "Epoch 3769/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0334 - val_loss: 0.6299\n",
      "Epoch 3770/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0308 - val_loss: 0.6211\n",
      "Epoch 3771/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0361 - val_loss: 0.6302\n",
      "Epoch 3772/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0472 - val_loss: 0.6457\n",
      "Epoch 3773/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0357 - val_loss: 0.6422\n",
      "Epoch 3774/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0260 - val_loss: 0.6487\n",
      "Epoch 3775/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0316 - val_loss: 0.6394\n",
      "Epoch 3776/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0329 - val_loss: 0.6494\n",
      "Epoch 3777/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0322 - val_loss: 0.6223\n",
      "Epoch 3778/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0299 - val_loss: 0.6331\n",
      "Epoch 3779/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0322 - val_loss: 0.6520\n",
      "Epoch 3780/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0535 - val_loss: 0.6383\n",
      "Epoch 3781/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0556 - val_loss: 0.6362\n",
      "Epoch 3782/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0389 - val_loss: 0.6226\n",
      "Epoch 3783/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0307 - val_loss: 0.6531\n",
      "Epoch 3784/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0290 - val_loss: 0.6459\n",
      "Epoch 3785/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0297 - val_loss: 0.6472\n",
      "Epoch 3786/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0267 - val_loss: 0.6486\n",
      "Epoch 3787/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0247 - val_loss: 0.6444\n",
      "Epoch 3788/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0279 - val_loss: 0.6369\n",
      "Epoch 3789/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0299 - val_loss: 0.6372\n",
      "Epoch 3790/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0404 - val_loss: 0.6636\n",
      "Epoch 3791/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0760 - val_loss: 0.5989\n",
      "Epoch 3792/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0443 - val_loss: 0.6308\n",
      "Epoch 3793/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0284 - val_loss: 0.6350\n",
      "Epoch 3794/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0259 - val_loss: 0.6569\n",
      "Epoch 3795/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0250 - val_loss: 0.6474\n",
      "Epoch 3796/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0273 - val_loss: 0.6467\n",
      "Epoch 3797/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0275 - val_loss: 0.6449\n",
      "Epoch 3798/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0299 - val_loss: 0.6421\n",
      "Epoch 3799/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0292 - val_loss: 0.6331\n",
      "Epoch 3800/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0317 - val_loss: 0.6306\n",
      "Epoch 3801/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0350 - val_loss: 0.6397\n",
      "Epoch 3802/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0446 - val_loss: 0.6271\n",
      "Epoch 3803/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 734us/step - loss: 0.0344 - val_loss: 0.6382\n",
      "Epoch 3804/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0399 - val_loss: 0.6262\n",
      "Epoch 3805/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0360 - val_loss: 0.6534\n",
      "Epoch 3806/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0293 - val_loss: 0.6307\n",
      "Epoch 3807/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0329 - val_loss: 0.6151\n",
      "Epoch 3808/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0313 - val_loss: 0.6227\n",
      "Epoch 3809/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0286 - val_loss: 0.6370\n",
      "Epoch 3810/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0342 - val_loss: 0.6389\n",
      "Epoch 3811/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0306 - val_loss: 0.6422\n",
      "Epoch 3812/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0310 - val_loss: 0.6362\n",
      "Epoch 3813/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0334 - val_loss: 0.6389\n",
      "Epoch 3814/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0370 - val_loss: 0.6267\n",
      "Epoch 3815/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0340 - val_loss: 0.6551\n",
      "Epoch 3816/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0377 - val_loss: 0.6618\n",
      "Epoch 3817/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0330 - val_loss: 0.6356\n",
      "Epoch 3818/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0306 - val_loss: 0.6311\n",
      "Epoch 3819/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0285 - val_loss: 0.6199\n",
      "Epoch 3820/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0312 - val_loss: 0.6477\n",
      "Epoch 3821/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0308 - val_loss: 0.6383\n",
      "Epoch 3822/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0354 - val_loss: 0.6605\n",
      "Epoch 3823/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0320 - val_loss: 0.6709\n",
      "Epoch 3824/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0771 - val_loss: 0.6497\n",
      "Epoch 3825/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0483 - val_loss: 0.6495\n",
      "Epoch 3826/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0351 - val_loss: 0.6192\n",
      "Epoch 3827/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0313 - val_loss: 0.6323\n",
      "Epoch 3828/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0310 - val_loss: 0.6368\n",
      "Epoch 3829/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0264 - val_loss: 0.6558\n",
      "Epoch 3830/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0282 - val_loss: 0.6529\n",
      "Epoch 3831/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0315 - val_loss: 0.6370\n",
      "Epoch 3832/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0405 - val_loss: 0.6337\n",
      "Epoch 3833/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0324 - val_loss: 0.6471\n",
      "Epoch 3834/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0301 - val_loss: 0.6400\n",
      "Epoch 3835/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0262 - val_loss: 0.6312\n",
      "Epoch 3836/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0304 - val_loss: 0.6428\n",
      "Epoch 3837/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0377 - val_loss: 0.6462\n",
      "Epoch 3838/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0362 - val_loss: 0.6457\n",
      "Epoch 3839/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0363 - val_loss: 0.6294\n",
      "Epoch 3840/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0329 - val_loss: 0.6358\n",
      "Epoch 3841/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0289 - val_loss: 0.6288\n",
      "Epoch 3842/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0286 - val_loss: 0.6430\n",
      "Epoch 3843/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0294 - val_loss: 0.6435\n",
      "Epoch 3844/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0282 - val_loss: 0.6391\n",
      "Epoch 3845/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0281 - val_loss: 0.6420\n",
      "Epoch 3846/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0377 - val_loss: 0.6593\n",
      "Epoch 3847/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0573 - val_loss: 0.6584\n",
      "Epoch 3848/10000\n",
      "130/130 [==============================] - 0s 824us/step - loss: 0.0395 - val_loss: 0.6341\n",
      "Epoch 3849/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0333 - val_loss: 0.6242\n",
      "Epoch 3850/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0364 - val_loss: 0.6243\n",
      "Epoch 3851/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0286 - val_loss: 0.6304\n",
      "Epoch 3852/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0265 - val_loss: 0.6325\n",
      "Epoch 3853/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0279 - val_loss: 0.6366\n",
      "Epoch 3854/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0270 - val_loss: 0.6280\n",
      "Epoch 3855/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0303 - val_loss: 0.6425\n",
      "Epoch 3856/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0315 - val_loss: 0.6303\n",
      "Epoch 3857/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0346 - val_loss: 0.6193\n",
      "Epoch 3858/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0402 - val_loss: 0.6396\n",
      "Epoch 3859/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0400 - val_loss: 0.6292\n",
      "Epoch 3860/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0260 - val_loss: 0.6288\n",
      "Epoch 3861/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0279 - val_loss: 0.6290\n",
      "Epoch 3862/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0316 - val_loss: 0.6534\n",
      "Epoch 3863/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0335 - val_loss: 0.6357\n",
      "Epoch 3864/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0399 - val_loss: 0.6329\n",
      "Epoch 3865/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0332 - val_loss: 0.6516\n",
      "Epoch 3866/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0277 - val_loss: 0.6348\n",
      "Epoch 3867/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0254 - val_loss: 0.6553\n",
      "Epoch 3868/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0270 - val_loss: 0.6479\n",
      "Epoch 3869/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0350 - val_loss: 0.6628\n",
      "Epoch 3870/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0507 - val_loss: 0.6468\n",
      "Epoch 3871/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0387 - val_loss: 0.6447\n",
      "Epoch 3872/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0327 - val_loss: 0.6381\n",
      "Epoch 3873/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0319 - val_loss: 0.6413\n",
      "Epoch 3874/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0269 - val_loss: 0.6430\n",
      "Epoch 3875/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0279 - val_loss: 0.6436\n",
      "Epoch 3876/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0324 - val_loss: 0.6361\n",
      "Epoch 3877/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0417 - val_loss: 0.6393\n",
      "Epoch 3878/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0353 - val_loss: 0.6389\n",
      "Epoch 3879/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 725us/step - loss: 0.0339 - val_loss: 0.6661\n",
      "Epoch 3880/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0322 - val_loss: 0.6316\n",
      "Epoch 3881/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0283 - val_loss: 0.6469\n",
      "Epoch 3882/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0271 - val_loss: 0.6365\n",
      "Epoch 3883/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0352 - val_loss: 0.6670\n",
      "Epoch 3884/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0319 - val_loss: 0.6386\n",
      "Epoch 3885/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0315 - val_loss: 0.6386\n",
      "Epoch 3886/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0318 - val_loss: 0.6419\n",
      "Epoch 3887/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0320 - val_loss: 0.6304\n",
      "Epoch 3888/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0346 - val_loss: 0.6490\n",
      "Epoch 3889/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0364 - val_loss: 0.6323\n",
      "Epoch 3890/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0321 - val_loss: 0.6344\n",
      "Epoch 3891/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0326 - val_loss: 0.6151\n",
      "Epoch 3892/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0281 - val_loss: 0.6398\n",
      "Epoch 3893/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0313 - val_loss: 0.6407\n",
      "Epoch 3894/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0249 - val_loss: 0.6553\n",
      "Epoch 3895/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0302 - val_loss: 0.6349\n",
      "Epoch 3896/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0334 - val_loss: 0.6480\n",
      "Epoch 3897/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0308 - val_loss: 0.6380\n",
      "Epoch 3898/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0274 - val_loss: 0.6457\n",
      "Epoch 3899/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0393 - val_loss: 0.6660\n",
      "Epoch 3900/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0473 - val_loss: 0.6510\n",
      "Epoch 3901/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0399 - val_loss: 0.6322\n",
      "Epoch 3902/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0334 - val_loss: 0.6493\n",
      "Epoch 3903/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0282 - val_loss: 0.6330\n",
      "Epoch 3904/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0260 - val_loss: 0.6377\n",
      "Epoch 3905/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0302 - val_loss: 0.6509\n",
      "Epoch 3906/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0344 - val_loss: 0.6258\n",
      "Epoch 3907/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0331 - val_loss: 0.6560\n",
      "Epoch 3908/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0310 - val_loss: 0.6419\n",
      "Epoch 3909/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0344 - val_loss: 0.6457\n",
      "Epoch 3910/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0297 - val_loss: 0.6440\n",
      "Epoch 3911/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0324 - val_loss: 0.6271\n",
      "Epoch 3912/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0373 - val_loss: 0.6450\n",
      "Epoch 3913/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0312 - val_loss: 0.6474\n",
      "Epoch 3914/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0316 - val_loss: 0.6310\n",
      "Epoch 3915/10000\n",
      "130/130 [==============================] - 0s 815us/step - loss: 0.0339 - val_loss: 0.6161\n",
      "Epoch 3916/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0297 - val_loss: 0.6466\n",
      "Epoch 3917/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0369 - val_loss: 0.6629\n",
      "Epoch 3918/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0428 - val_loss: 0.6389\n",
      "Epoch 3919/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0324 - val_loss: 0.6410\n",
      "Epoch 3920/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0293 - val_loss: 0.6361\n",
      "Epoch 3921/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0382 - val_loss: 0.6208\n",
      "Epoch 3922/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0326 - val_loss: 0.6306\n",
      "Epoch 3923/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0303 - val_loss: 0.6511\n",
      "Epoch 3924/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0285 - val_loss: 0.6313\n",
      "Epoch 3925/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0247 - val_loss: 0.6442\n",
      "Epoch 3926/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0312 - val_loss: 0.6395\n",
      "Epoch 3927/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0356 - val_loss: 0.6748\n",
      "Epoch 3928/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0328 - val_loss: 0.6441\n",
      "Epoch 3929/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0297 - val_loss: 0.6512\n",
      "Epoch 3930/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0308 - val_loss: 0.6476\n",
      "Epoch 3931/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0326 - val_loss: 0.6465\n",
      "Epoch 3932/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0306 - val_loss: 0.6162\n",
      "Epoch 3933/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0293 - val_loss: 0.6433\n",
      "Epoch 3934/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0356 - val_loss: 0.6434\n",
      "Epoch 3935/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0297 - val_loss: 0.6480\n",
      "Epoch 3936/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0364 - val_loss: 0.6191\n",
      "Epoch 3937/10000\n",
      "130/130 [==============================] - 0s 813us/step - loss: 0.0266 - val_loss: 0.6290\n",
      "Epoch 3938/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0334 - val_loss: 0.6411\n",
      "Epoch 3939/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0283 - val_loss: 0.6482\n",
      "Epoch 3940/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0291 - val_loss: 0.6452\n",
      "Epoch 3941/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0368 - val_loss: 0.6563\n",
      "Epoch 3942/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0346 - val_loss: 0.6341\n",
      "Epoch 3943/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0375 - val_loss: 0.6226\n",
      "Epoch 3944/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0444 - val_loss: 0.6262\n",
      "Epoch 3945/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0343 - val_loss: 0.6327\n",
      "Epoch 3946/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0285 - val_loss: 0.6254\n",
      "Epoch 3947/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0256 - val_loss: 0.6242\n",
      "Epoch 3948/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0329 - val_loss: 0.6369\n",
      "Epoch 3949/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0313 - val_loss: 0.6508\n",
      "Epoch 3950/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0271 - val_loss: 0.6515\n",
      "Epoch 3951/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0266 - val_loss: 0.6269\n",
      "Epoch 3952/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0314 - val_loss: 0.6342\n",
      "Epoch 3953/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0332 - val_loss: 0.6275\n",
      "Epoch 3954/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0476 - val_loss: 0.6222\n",
      "Epoch 3955/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 715us/step - loss: 0.0407 - val_loss: 0.6314\n",
      "Epoch 3956/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0283 - val_loss: 0.6346\n",
      "Epoch 3957/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0272 - val_loss: 0.6404\n",
      "Epoch 3958/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0292 - val_loss: 0.6242\n",
      "Epoch 3959/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0347 - val_loss: 0.6627\n",
      "Epoch 3960/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0316 - val_loss: 0.6303\n",
      "Epoch 3961/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0304 - val_loss: 0.6239\n",
      "Epoch 3962/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0365 - val_loss: 0.6354\n",
      "Epoch 3963/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0264 - val_loss: 0.6556\n",
      "Epoch 3964/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0306 - val_loss: 0.6401\n",
      "Epoch 3965/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0316 - val_loss: 0.6362\n",
      "Epoch 3966/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0342 - val_loss: 0.6435\n",
      "Epoch 3967/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0360 - val_loss: 0.6602\n",
      "Epoch 3968/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0325 - val_loss: 0.6181\n",
      "Epoch 3969/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0332 - val_loss: 0.6466\n",
      "Epoch 3970/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0311 - val_loss: 0.6418\n",
      "Epoch 3971/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0312 - val_loss: 0.6413\n",
      "Epoch 3972/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0282 - val_loss: 0.6371\n",
      "Epoch 3973/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0272 - val_loss: 0.6503\n",
      "Epoch 3974/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0288 - val_loss: 0.6232\n",
      "Epoch 3975/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0280 - val_loss: 0.6362\n",
      "Epoch 3976/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0258 - val_loss: 0.6228\n",
      "Epoch 3977/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0372 - val_loss: 0.6447\n",
      "Epoch 3978/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0293 - val_loss: 0.6576\n",
      "Epoch 3979/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0270 - val_loss: 0.6274\n",
      "Epoch 3980/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0354 - val_loss: 0.6443\n",
      "Epoch 3981/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0291 - val_loss: 0.6326\n",
      "Epoch 3982/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0317 - val_loss: 0.6429\n",
      "Epoch 3983/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0348 - val_loss: 0.6319\n",
      "Epoch 3984/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0361 - val_loss: 0.6391\n",
      "Epoch 3985/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0318 - val_loss: 0.6269\n",
      "Epoch 3986/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0324 - val_loss: 0.6168\n",
      "Epoch 3987/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0378 - val_loss: 0.6260\n",
      "Epoch 3988/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0306 - val_loss: 0.6110\n",
      "Epoch 3989/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0322 - val_loss: 0.6374\n",
      "Epoch 3990/10000\n",
      "130/130 [==============================] - 0s 921us/step - loss: 0.0294 - val_loss: 0.6368\n",
      "Epoch 3991/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0321 - val_loss: 0.6474\n",
      "Epoch 3992/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0305 - val_loss: 0.6381\n",
      "Epoch 3993/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0255 - val_loss: 0.6452\n",
      "Epoch 3994/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0260 - val_loss: 0.5936\n",
      "Epoch 3995/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0338 - val_loss: 0.6376\n",
      "Epoch 3996/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0308 - val_loss: 0.6452\n",
      "Epoch 3997/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0237 - val_loss: 0.6271\n",
      "Epoch 3998/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0298 - val_loss: 0.6242\n",
      "Epoch 3999/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0265 - val_loss: 0.6260\n",
      "Epoch 4000/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0353 - val_loss: 0.6393\n",
      "Epoch 4001/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0357 - val_loss: 0.6538\n",
      "Epoch 4002/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0385 - val_loss: 0.6273\n",
      "Epoch 4003/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0355 - val_loss: 0.6325\n",
      "Epoch 4004/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0283 - val_loss: 0.6287\n",
      "Epoch 4005/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0295 - val_loss: 0.6067\n",
      "Epoch 4006/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0270 - val_loss: 0.6224\n",
      "Epoch 4007/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0269 - val_loss: 0.6144\n",
      "Epoch 4008/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0258 - val_loss: 0.6338\n",
      "Epoch 4009/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0260 - val_loss: 0.6298\n",
      "Epoch 4010/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0373 - val_loss: 0.6709\n",
      "Epoch 4011/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0459 - val_loss: 0.6416\n",
      "Epoch 4012/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0438 - val_loss: 0.6433\n",
      "Epoch 4013/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0343 - val_loss: 0.6158\n",
      "Epoch 4014/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0316 - val_loss: 0.6275\n",
      "Epoch 4015/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0313 - val_loss: 0.6377\n",
      "Epoch 4016/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0247 - val_loss: 0.6424\n",
      "Epoch 4017/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0281 - val_loss: 0.6264\n",
      "Epoch 4018/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0247 - val_loss: 0.6444\n",
      "Epoch 4019/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0251 - val_loss: 0.6384\n",
      "Epoch 4020/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0285 - val_loss: 0.6330\n",
      "Epoch 4021/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0404 - val_loss: 0.6443\n",
      "Epoch 4022/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0334 - val_loss: 0.6250\n",
      "Epoch 4023/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0299 - val_loss: 0.6383\n",
      "Epoch 4024/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0299 - val_loss: 0.6302\n",
      "Epoch 4025/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0306 - val_loss: 0.6369\n",
      "Epoch 4026/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0348 - val_loss: 0.6263\n",
      "Epoch 4027/10000\n",
      "130/130 [==============================] - 0s 825us/step - loss: 0.0503 - val_loss: 0.6165\n",
      "Epoch 4028/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0289 - val_loss: 0.6415\n",
      "Epoch 4029/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0288 - val_loss: 0.6436\n",
      "Epoch 4030/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0298 - val_loss: 0.6243\n",
      "Epoch 4031/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 717us/step - loss: 0.0262 - val_loss: 0.6198\n",
      "Epoch 4032/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0311 - val_loss: 0.6241\n",
      "Epoch 4033/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0306 - val_loss: 0.6109\n",
      "Epoch 4034/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0246 - val_loss: 0.6475\n",
      "Epoch 4035/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0280 - val_loss: 0.6525\n",
      "Epoch 4036/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0255 - val_loss: 0.6354\n",
      "Epoch 4037/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0304 - val_loss: 0.6347\n",
      "Epoch 4038/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0287 - val_loss: 0.6220\n",
      "Epoch 4039/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0275 - val_loss: 0.6300\n",
      "Epoch 4040/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0323 - val_loss: 0.6588\n",
      "Epoch 4041/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0256 - val_loss: 0.6255\n",
      "Epoch 4042/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0375 - val_loss: 0.6457\n",
      "Epoch 4043/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0598 - val_loss: 0.6451\n",
      "Epoch 4044/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0437 - val_loss: 0.6224\n",
      "Epoch 4045/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0251 - val_loss: 0.6368\n",
      "Epoch 4046/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0250 - val_loss: 0.6327\n",
      "Epoch 4047/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0249 - val_loss: 0.6375\n",
      "Epoch 4048/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0294 - val_loss: 0.6347\n",
      "Epoch 4049/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0264 - val_loss: 0.6185\n",
      "Epoch 4050/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0386 - val_loss: 0.6455\n",
      "Epoch 4051/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0287 - val_loss: 0.6499\n",
      "Epoch 4052/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0302 - val_loss: 0.6426\n",
      "Epoch 4053/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0374 - val_loss: 0.6133\n",
      "Epoch 4054/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0318 - val_loss: 0.6438\n",
      "Epoch 4055/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0270 - val_loss: 0.6137\n",
      "Epoch 4056/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0226 - val_loss: 0.6496\n",
      "Epoch 4057/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0247 - val_loss: 0.6119\n",
      "Epoch 4058/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0300 - val_loss: 0.6409\n",
      "Epoch 4059/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0360 - val_loss: 0.6265\n",
      "Epoch 4060/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0326 - val_loss: 0.6381\n",
      "Epoch 4061/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0368 - val_loss: 0.6413\n",
      "Epoch 4062/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0365 - val_loss: 0.6212\n",
      "Epoch 4063/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0425 - val_loss: 0.6329\n",
      "Epoch 4064/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0304 - val_loss: 0.6431\n",
      "Epoch 4065/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0325 - val_loss: 0.6787\n",
      "Epoch 4066/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0325 - val_loss: 0.6580\n",
      "Epoch 4067/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0287 - val_loss: 0.6437\n",
      "Epoch 4068/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0254 - val_loss: 0.6219\n",
      "Epoch 4069/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0320 - val_loss: 0.6387\n",
      "Epoch 4070/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0323 - val_loss: 0.6331\n",
      "Epoch 4071/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0236 - val_loss: 0.6318\n",
      "Epoch 4072/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0249 - val_loss: 0.6204\n",
      "Epoch 4073/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0223 - val_loss: 0.6275\n",
      "Epoch 4074/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0280 - val_loss: 0.6476\n",
      "Epoch 4075/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0340 - val_loss: 0.6450\n",
      "Epoch 4076/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0469 - val_loss: 0.6483\n",
      "Epoch 4077/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0331 - val_loss: 0.6425\n",
      "Epoch 4078/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0256 - val_loss: 0.6261\n",
      "Epoch 4079/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0321 - val_loss: 0.6468\n",
      "Epoch 4080/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0262 - val_loss: 0.6262\n",
      "Epoch 4081/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0289 - val_loss: 0.6300\n",
      "Epoch 4082/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0285 - val_loss: 0.6245\n",
      "Epoch 4083/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0286 - val_loss: 0.6199\n",
      "Epoch 4084/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0337 - val_loss: 0.6369\n",
      "Epoch 4085/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0294 - val_loss: 0.6288\n",
      "Epoch 4086/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0260 - val_loss: 0.6263\n",
      "Epoch 4087/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0260 - val_loss: 0.6283\n",
      "Epoch 4088/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0290 - val_loss: 0.6407\n",
      "Epoch 4089/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0418 - val_loss: 0.6690\n",
      "Epoch 4090/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0328 - val_loss: 0.6233\n",
      "Epoch 4091/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0263 - val_loss: 0.6481\n",
      "Epoch 4092/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0277 - val_loss: 0.6060\n",
      "Epoch 4093/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0303 - val_loss: 0.6542\n",
      "Epoch 4094/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0332 - val_loss: 0.6531\n",
      "Epoch 4095/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0370 - val_loss: 0.6337\n",
      "Epoch 4096/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0317 - val_loss: 0.6575\n",
      "Epoch 4097/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0242 - val_loss: 0.6562\n",
      "Epoch 4098/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0261 - val_loss: 0.6372\n",
      "Epoch 4099/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0253 - val_loss: 0.6328\n",
      "Epoch 4100/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0373 - val_loss: 0.6482\n",
      "Epoch 4101/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0269 - val_loss: 0.6376\n",
      "Epoch 4102/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0386 - val_loss: 0.6506\n",
      "Epoch 4103/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0284 - val_loss: 0.6276\n",
      "Epoch 4104/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0255 - val_loss: 0.6407\n",
      "Epoch 4105/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0337 - val_loss: 0.6474\n",
      "Epoch 4106/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0283 - val_loss: 0.6219\n",
      "Epoch 4107/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 714us/step - loss: 0.0434 - val_loss: 0.6353\n",
      "Epoch 4108/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0308 - val_loss: 0.6350\n",
      "Epoch 4109/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0295 - val_loss: 0.6353\n",
      "Epoch 4110/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0266 - val_loss: 0.6325\n",
      "Epoch 4111/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0349 - val_loss: 0.6459\n",
      "Epoch 4112/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0324 - val_loss: 0.6263\n",
      "Epoch 4113/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0328 - val_loss: 0.6370\n",
      "Epoch 4114/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0290 - val_loss: 0.6296\n",
      "Epoch 4115/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0235 - val_loss: 0.6311\n",
      "Epoch 4116/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0282 - val_loss: 0.6094\n",
      "Epoch 4117/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0244 - val_loss: 0.6380\n",
      "Epoch 4118/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0302 - val_loss: 0.6281\n",
      "Epoch 4119/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0289 - val_loss: 0.6259\n",
      "Epoch 4120/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0367 - val_loss: 0.6113\n",
      "Epoch 4121/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0376 - val_loss: 0.6389\n",
      "Epoch 4122/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0318 - val_loss: 0.6222\n",
      "Epoch 4123/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0241 - val_loss: 0.6273\n",
      "Epoch 4124/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0262 - val_loss: 0.6225\n",
      "Epoch 4125/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0296 - val_loss: 0.6414\n",
      "Epoch 4126/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0312 - val_loss: 0.6381\n",
      "Epoch 4127/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0291 - val_loss: 0.6340\n",
      "Epoch 4128/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0301 - val_loss: 0.6135\n",
      "Epoch 4129/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0255 - val_loss: 0.6317\n",
      "Epoch 4130/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0387 - val_loss: 0.6251\n",
      "Epoch 4131/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0356 - val_loss: 0.6348\n",
      "Epoch 4132/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0289 - val_loss: 0.6235\n",
      "Epoch 4133/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0255 - val_loss: 0.6364\n",
      "Epoch 4134/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0259 - val_loss: 0.6282\n",
      "Epoch 4135/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0316 - val_loss: 0.6340\n",
      "Epoch 4136/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0535 - val_loss: 0.6533\n",
      "Epoch 4137/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0358 - val_loss: 0.6505\n",
      "Epoch 4138/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0253 - val_loss: 0.6325\n",
      "Epoch 4139/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0265 - val_loss: 0.6328\n",
      "Epoch 4140/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0238 - val_loss: 0.6450\n",
      "Epoch 4141/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0267 - val_loss: 0.6271\n",
      "Epoch 4142/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0271 - val_loss: 0.6280\n",
      "Epoch 4143/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0252 - val_loss: 0.6478\n",
      "Epoch 4144/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0277 - val_loss: 0.6515\n",
      "Epoch 4145/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0245 - val_loss: 0.6373\n",
      "Epoch 4146/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0287 - val_loss: 0.6135\n",
      "Epoch 4147/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0339 - val_loss: 0.6322\n",
      "Epoch 4148/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0279 - val_loss: 0.6468\n",
      "Epoch 4149/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0273 - val_loss: 0.6309\n",
      "Epoch 4150/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0317 - val_loss: 0.6256\n",
      "Epoch 4151/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0267 - val_loss: 0.6265\n",
      "Epoch 4152/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0264 - val_loss: 0.6268\n",
      "Epoch 4153/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0313 - val_loss: 0.6265\n",
      "Epoch 4154/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0295 - val_loss: 0.6467\n",
      "Epoch 4155/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0350 - val_loss: 0.6143\n",
      "Epoch 4156/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0383 - val_loss: 0.6482\n",
      "Epoch 4157/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0275 - val_loss: 0.6270\n",
      "Epoch 4158/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0284 - val_loss: 0.6289\n",
      "Epoch 4159/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0280 - val_loss: 0.6454\n",
      "Epoch 4160/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0301 - val_loss: 0.6376\n",
      "Epoch 4161/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0320 - val_loss: 0.6233\n",
      "Epoch 4162/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0243 - val_loss: 0.6076\n",
      "Epoch 4163/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0248 - val_loss: 0.6312\n",
      "Epoch 4164/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0260 - val_loss: 0.6539\n",
      "Epoch 4165/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0369 - val_loss: 0.6403\n",
      "Epoch 4166/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0566 - val_loss: 0.6415\n",
      "Epoch 4167/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0451 - val_loss: 0.6322\n",
      "Epoch 4168/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0308 - val_loss: 0.6213\n",
      "Epoch 4169/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0269 - val_loss: 0.6100\n",
      "Epoch 4170/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0245 - val_loss: 0.6420\n",
      "Epoch 4171/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0238 - val_loss: 0.6280\n",
      "Epoch 4172/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0233 - val_loss: 0.6419\n",
      "Epoch 4173/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0229 - val_loss: 0.6348\n",
      "Epoch 4174/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0250 - val_loss: 0.6395\n",
      "Epoch 4175/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0351 - val_loss: 0.6434\n",
      "Epoch 4176/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0301 - val_loss: 0.6457\n",
      "Epoch 4177/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0297 - val_loss: 0.6312\n",
      "Epoch 4178/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0290 - val_loss: 0.6434\n",
      "Epoch 4179/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0325 - val_loss: 0.6516\n",
      "Epoch 4180/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0283 - val_loss: 0.6137\n",
      "Epoch 4181/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0326 - val_loss: 0.6323\n",
      "Epoch 4182/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0340 - val_loss: 0.6261\n",
      "Epoch 4183/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 715us/step - loss: 0.0260 - val_loss: 0.6543\n",
      "Epoch 4184/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0226 - val_loss: 0.6192\n",
      "Epoch 4185/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0280 - val_loss: 0.6440\n",
      "Epoch 4186/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0301 - val_loss: 0.6286\n",
      "Epoch 4187/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0293 - val_loss: 0.6468\n",
      "Epoch 4188/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0360 - val_loss: 0.6667\n",
      "Epoch 4189/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0296 - val_loss: 0.6371\n",
      "Epoch 4190/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0269 - val_loss: 0.6221\n",
      "Epoch 4191/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0245 - val_loss: 0.6466\n",
      "Epoch 4192/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0256 - val_loss: 0.6250\n",
      "Epoch 4193/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0245 - val_loss: 0.6450\n",
      "Epoch 4194/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0311 - val_loss: 0.6261\n",
      "Epoch 4195/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0547 - val_loss: 0.6353\n",
      "Epoch 4196/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0458 - val_loss: 0.6145\n",
      "Epoch 4197/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0307 - val_loss: 0.6265\n",
      "Epoch 4198/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0307 - val_loss: 0.6142\n",
      "Epoch 4199/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0258 - val_loss: 0.6376\n",
      "Epoch 4200/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0203 - val_loss: 0.6385\n",
      "Epoch 4201/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0235 - val_loss: 0.6380\n",
      "Epoch 4202/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0258 - val_loss: 0.6276\n",
      "Epoch 4203/10000\n",
      "130/130 [==============================] - 0s 705us/step - loss: 0.0274 - val_loss: 0.6355\n",
      "Epoch 4204/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0293 - val_loss: 0.6403\n",
      "Epoch 4205/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0439 - val_loss: 0.6098\n",
      "Epoch 4206/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0405 - val_loss: 0.6382\n",
      "Epoch 4207/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0300 - val_loss: 0.6446\n",
      "Epoch 4208/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0366 - val_loss: 0.6542\n",
      "Epoch 4209/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0278 - val_loss: 0.6191\n",
      "Epoch 4210/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0245 - val_loss: 0.6206\n",
      "Epoch 4211/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0225 - val_loss: 0.6275\n",
      "Epoch 4212/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0243 - val_loss: 0.6731\n",
      "Epoch 4213/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0244 - val_loss: 0.6310\n",
      "Epoch 4214/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0295 - val_loss: 0.6171\n",
      "Epoch 4215/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0253 - val_loss: 0.6421\n",
      "Epoch 4216/10000\n",
      "130/130 [==============================] - 0s 992us/step - loss: 0.0256 - val_loss: 0.6281\n",
      "Epoch 4217/10000\n",
      "130/130 [==============================] - 0s 965us/step - loss: 0.0303 - val_loss: 0.6167\n",
      "Epoch 4218/10000\n",
      "130/130 [==============================] - 0s 822us/step - loss: 0.0251 - val_loss: 0.6358\n",
      "Epoch 4219/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.0293 - val_loss: 0.6323\n",
      "Epoch 4220/10000\n",
      "130/130 [==============================] - 0s 888us/step - loss: 0.0323 - val_loss: 0.6353\n",
      "Epoch 4221/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0279 - val_loss: 0.6422\n",
      "Epoch 4222/10000\n",
      "130/130 [==============================] - 0s 820us/step - loss: 0.0254 - val_loss: 0.6248\n",
      "Epoch 4223/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0353 - val_loss: 0.6503\n",
      "Epoch 4224/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0376 - val_loss: 0.6497\n",
      "Epoch 4225/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0347 - val_loss: 0.6352\n",
      "Epoch 4226/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0370 - val_loss: 0.6203\n",
      "Epoch 4227/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0252 - val_loss: 0.6147\n",
      "Epoch 4228/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0214 - val_loss: 0.6393\n",
      "Epoch 4229/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0227 - val_loss: 0.6312\n",
      "Epoch 4230/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0285 - val_loss: 0.6235\n",
      "Epoch 4231/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0294 - val_loss: 0.6313\n",
      "Epoch 4232/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0394 - val_loss: 0.6416\n",
      "Epoch 4233/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0342 - val_loss: 0.6291\n",
      "Epoch 4234/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0232 - val_loss: 0.6549\n",
      "Epoch 4235/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0223 - val_loss: 0.6322\n",
      "Epoch 4236/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0321 - val_loss: 0.6527\n",
      "Epoch 4237/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0323 - val_loss: 0.6274\n",
      "Epoch 4238/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0310 - val_loss: 0.6264\n",
      "Epoch 4239/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0271 - val_loss: 0.6414\n",
      "Epoch 4240/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0304 - val_loss: 0.6555\n",
      "Epoch 4241/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0273 - val_loss: 0.6301\n",
      "Epoch 4242/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0266 - val_loss: 0.6466\n",
      "Epoch 4243/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0232 - val_loss: 0.6373\n",
      "Epoch 4244/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0227 - val_loss: 0.6554\n",
      "Epoch 4245/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0317 - val_loss: 0.6344\n",
      "Epoch 4246/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0297 - val_loss: 0.6507\n",
      "Epoch 4247/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0246 - val_loss: 0.6214\n",
      "Epoch 4248/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0261 - val_loss: 0.6449\n",
      "Epoch 4249/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0534 - val_loss: 0.6241\n",
      "Epoch 4250/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0339 - val_loss: 0.6458\n",
      "Epoch 4251/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0254 - val_loss: 0.6200\n",
      "Epoch 4252/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0249 - val_loss: 0.6318\n",
      "Epoch 4253/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0216 - val_loss: 0.6426\n",
      "Epoch 4254/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0250 - val_loss: 0.6264\n",
      "Epoch 4255/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0235 - val_loss: 0.6181\n",
      "Epoch 4256/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0292 - val_loss: 0.6503\n",
      "Epoch 4257/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0281 - val_loss: 0.6629\n",
      "Epoch 4258/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0322 - val_loss: 0.6528\n",
      "Epoch 4259/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 729us/step - loss: 0.0284 - val_loss: 0.6196\n",
      "Epoch 4260/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0244 - val_loss: 0.6236\n",
      "Epoch 4261/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0293 - val_loss: 0.6556\n",
      "Epoch 4262/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0296 - val_loss: 0.6276\n",
      "Epoch 4263/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0226 - val_loss: 0.6504\n",
      "Epoch 4264/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0247 - val_loss: 0.6277\n",
      "Epoch 4265/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0271 - val_loss: 0.6216\n",
      "Epoch 4266/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0242 - val_loss: 0.6745\n",
      "Epoch 4267/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0254 - val_loss: 0.6312\n",
      "Epoch 4268/10000\n",
      "130/130 [==============================] - 0s 891us/step - loss: 0.0330 - val_loss: 0.6593\n",
      "Epoch 4269/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0538 - val_loss: 0.6136\n",
      "Epoch 4270/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0391 - val_loss: 0.6220\n",
      "Epoch 4271/10000\n",
      "130/130 [==============================] - 0s 946us/step - loss: 0.0339 - val_loss: 0.6312\n",
      "Epoch 4272/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0292 - val_loss: 0.6370\n",
      "Epoch 4273/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0235 - val_loss: 0.6412\n",
      "Epoch 4274/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0280 - val_loss: 0.6363\n",
      "Epoch 4275/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0303 - val_loss: 0.6219\n",
      "Epoch 4276/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0268 - val_loss: 0.6355\n",
      "Epoch 4277/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0250 - val_loss: 0.6427\n",
      "Epoch 4278/10000\n",
      "130/130 [==============================] - 0s 810us/step - loss: 0.0333 - val_loss: 0.6774\n",
      "Epoch 4279/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0483 - val_loss: 0.6224\n",
      "Epoch 4280/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0252 - val_loss: 0.6246\n",
      "Epoch 4281/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0219 - val_loss: 0.6302\n",
      "Epoch 4282/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0253 - val_loss: 0.6340\n",
      "Epoch 4283/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0226 - val_loss: 0.6246\n",
      "Epoch 4284/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0276 - val_loss: 0.6333\n",
      "Epoch 4285/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0233 - val_loss: 0.6317\n",
      "Epoch 4286/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0294 - val_loss: 0.6472\n",
      "Epoch 4287/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0290 - val_loss: 0.6415\n",
      "Epoch 4288/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0304 - val_loss: 0.6632\n",
      "Epoch 4289/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0368 - val_loss: 0.6196\n",
      "Epoch 4290/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0314 - val_loss: 0.6391\n",
      "Epoch 4291/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0356 - val_loss: 0.6199\n",
      "Epoch 4292/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0251 - val_loss: 0.6229\n",
      "Epoch 4293/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0216 - val_loss: 0.6334\n",
      "Epoch 4294/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0225 - val_loss: 0.6220\n",
      "Epoch 4295/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0262 - val_loss: 0.6327\n",
      "Epoch 4296/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0252 - val_loss: 0.6444\n",
      "Epoch 4297/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0268 - val_loss: 0.6192\n",
      "Epoch 4298/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0329 - val_loss: 0.6122\n",
      "Epoch 4299/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0282 - val_loss: 0.6325\n",
      "Epoch 4300/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0234 - val_loss: 0.6394\n",
      "Epoch 4301/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0244 - val_loss: 0.6402\n",
      "Epoch 4302/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0316 - val_loss: 0.6186\n",
      "Epoch 4303/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0272 - val_loss: 0.6433\n",
      "Epoch 4304/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0276 - val_loss: 0.6561\n",
      "Epoch 4305/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0272 - val_loss: 0.6441\n",
      "Epoch 4306/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0400 - val_loss: 0.6316\n",
      "Epoch 4307/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0361 - val_loss: 0.6492\n",
      "Epoch 4308/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0307 - val_loss: 0.6314\n",
      "Epoch 4309/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0253 - val_loss: 0.6364\n",
      "Epoch 4310/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0248 - val_loss: 0.6273\n",
      "Epoch 4311/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0241 - val_loss: 0.6469\n",
      "Epoch 4312/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0320 - val_loss: 0.6290\n",
      "Epoch 4313/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0380 - val_loss: 0.6100\n",
      "Epoch 4314/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0491 - val_loss: 0.6603\n",
      "Epoch 4315/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0284 - val_loss: 0.6200\n",
      "Epoch 4316/10000\n",
      "130/130 [==============================] - 0s 821us/step - loss: 0.0232 - val_loss: 0.6507\n",
      "Epoch 4317/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.6402\n",
      "Epoch 4318/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0188 - val_loss: 0.6440\n",
      "Epoch 4319/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0222 - val_loss: 0.6252\n",
      "Epoch 4320/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0246 - val_loss: 0.6258\n",
      "Epoch 4321/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0288 - val_loss: 0.6396\n",
      "Epoch 4322/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0428 - val_loss: 0.6436\n",
      "Epoch 4323/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0292 - val_loss: 0.6177\n",
      "Epoch 4324/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0247 - val_loss: 0.6286\n",
      "Epoch 4325/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0206 - val_loss: 0.6292\n",
      "Epoch 4326/10000\n",
      "130/130 [==============================] - 0s 804us/step - loss: 0.0222 - val_loss: 0.6419\n",
      "Epoch 4327/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0251 - val_loss: 0.6253\n",
      "Epoch 4328/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0286 - val_loss: 0.6397\n",
      "Epoch 4329/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0330 - val_loss: 0.6458\n",
      "Epoch 4330/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0270 - val_loss: 0.6411\n",
      "Epoch 4331/10000\n",
      "130/130 [==============================] - 0s 792us/step - loss: 0.0323 - val_loss: 0.6537\n",
      "Epoch 4332/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0416 - val_loss: 0.6184\n",
      "Epoch 4333/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0284 - val_loss: 0.6323\n",
      "Epoch 4334/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0236 - val_loss: 0.6324\n",
      "Epoch 4335/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 760us/step - loss: 0.0224 - val_loss: 0.6422\n",
      "Epoch 4336/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0275 - val_loss: 0.6173\n",
      "Epoch 4337/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0290 - val_loss: 0.6432\n",
      "Epoch 4338/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0265 - val_loss: 0.6392\n",
      "Epoch 4339/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0272 - val_loss: 0.6260\n",
      "Epoch 4340/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0312 - val_loss: 0.6518\n",
      "Epoch 4341/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0619 - val_loss: 0.6154\n",
      "Epoch 4342/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0366 - val_loss: 0.6373\n",
      "Epoch 4343/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0207 - val_loss: 0.6132\n",
      "Epoch 4344/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0197 - val_loss: 0.6092\n",
      "Epoch 4345/10000\n",
      "130/130 [==============================] - 0s 985us/step - loss: 0.0238 - val_loss: 0.6413\n",
      "Epoch 4346/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0233 - val_loss: 0.6460\n",
      "Epoch 4347/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0284 - val_loss: 0.6282\n",
      "Epoch 4348/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0228 - val_loss: 0.6353\n",
      "Epoch 4349/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0194 - val_loss: 0.6080\n",
      "Epoch 4350/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0269 - val_loss: 0.6388\n",
      "Epoch 4351/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0384 - val_loss: 0.6977\n",
      "Epoch 4352/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0399 - val_loss: 0.6384\n",
      "Epoch 4353/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0235 - val_loss: 0.6419\n",
      "Epoch 4354/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0253 - val_loss: 0.6302\n",
      "Epoch 4355/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0258 - val_loss: 0.6181\n",
      "Epoch 4356/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0243 - val_loss: 0.6343\n",
      "Epoch 4357/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0365 - val_loss: 0.6458\n",
      "Epoch 4358/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0401 - val_loss: 0.6258\n",
      "Epoch 4359/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0271 - val_loss: 0.6252\n",
      "Epoch 4360/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0270 - val_loss: 0.6091\n",
      "Epoch 4361/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0214 - val_loss: 0.6456\n",
      "Epoch 4362/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0226 - val_loss: 0.6303\n",
      "Epoch 4363/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0226 - val_loss: 0.6291\n",
      "Epoch 4364/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0337 - val_loss: 0.6513\n",
      "Epoch 4365/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0309 - val_loss: 0.6670\n",
      "Epoch 4366/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0237 - val_loss: 0.6247\n",
      "Epoch 4367/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0237 - val_loss: 0.6346\n",
      "Epoch 4368/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0269 - val_loss: 0.6356\n",
      "Epoch 4369/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0237 - val_loss: 0.6270\n",
      "Epoch 4370/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0249 - val_loss: 0.6273\n",
      "Epoch 4371/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0264 - val_loss: 0.6258\n",
      "Epoch 4372/10000\n",
      "130/130 [==============================] - 0s 816us/step - loss: 0.0304 - val_loss: 0.6476\n",
      "Epoch 4373/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0343 - val_loss: 0.6351\n",
      "Epoch 4374/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0335 - val_loss: 0.6269\n",
      "Epoch 4375/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0238 - val_loss: 0.6386\n",
      "Epoch 4376/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0256 - val_loss: 0.6355\n",
      "Epoch 4377/10000\n",
      "130/130 [==============================] - 0s 957us/step - loss: 0.0304 - val_loss: 0.6351\n",
      "Epoch 4378/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0239 - val_loss: 0.6520\n",
      "Epoch 4379/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0346 - val_loss: 0.6511\n",
      "Epoch 4380/10000\n",
      "130/130 [==============================] - 0s 830us/step - loss: 0.0265 - val_loss: 0.6268\n",
      "Epoch 4381/10000\n",
      "130/130 [==============================] - 0s 883us/step - loss: 0.0239 - val_loss: 0.6486\n",
      "Epoch 4382/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0245 - val_loss: 0.6165\n",
      "Epoch 4383/10000\n",
      "130/130 [==============================] - 0s 914us/step - loss: 0.0325 - val_loss: 0.6301\n",
      "Epoch 4384/10000\n",
      "130/130 [==============================] - 0s 897us/step - loss: 0.0322 - val_loss: 0.6275\n",
      "Epoch 4385/10000\n",
      "130/130 [==============================] - 0s 902us/step - loss: 0.0345 - val_loss: 0.6311\n",
      "Epoch 4386/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0305 - val_loss: 0.6348\n",
      "Epoch 4387/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0259 - val_loss: 0.6502\n",
      "Epoch 4388/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0234 - val_loss: 0.6231\n",
      "Epoch 4389/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0270 - val_loss: 0.6316\n",
      "Epoch 4390/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0347 - val_loss: 0.6266\n",
      "Epoch 4391/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0344 - val_loss: 0.6170\n",
      "Epoch 4392/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0233 - val_loss: 0.6230\n",
      "Epoch 4393/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0242 - val_loss: 0.6359\n",
      "Epoch 4394/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0213 - val_loss: 0.6381\n",
      "Epoch 4395/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0269 - val_loss: 0.6208\n",
      "Epoch 4396/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0271 - val_loss: 0.6235\n",
      "Epoch 4397/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0266 - val_loss: 0.6512\n",
      "Epoch 4398/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0233 - val_loss: 0.6241\n",
      "Epoch 4399/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0249 - val_loss: 0.6138\n",
      "Epoch 4400/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0303 - val_loss: 0.6408\n",
      "Epoch 4401/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0302 - val_loss: 0.6549\n",
      "Epoch 4402/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0227 - val_loss: 0.6351\n",
      "Epoch 4403/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0210 - val_loss: 0.6266\n",
      "Epoch 4404/10000\n",
      "130/130 [==============================] - 0s 805us/step - loss: 0.0215 - val_loss: 0.6473\n",
      "Epoch 4405/10000\n",
      "130/130 [==============================] - 0s 845us/step - loss: 0.0319 - val_loss: 0.6488\n",
      "Epoch 4406/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0329 - val_loss: 0.6198\n",
      "Epoch 4407/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0255 - val_loss: 0.6348\n",
      "Epoch 4408/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0271 - val_loss: 0.6509\n",
      "Epoch 4409/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0429 - val_loss: 0.6273\n",
      "Epoch 4410/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0366 - val_loss: 0.6159\n",
      "Epoch 4411/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 764us/step - loss: 0.0290 - val_loss: 0.6365\n",
      "Epoch 4412/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0280 - val_loss: 0.6341\n",
      "Epoch 4413/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0700 - val_loss: 0.6380\n",
      "Epoch 4414/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0302 - val_loss: 0.6255\n",
      "Epoch 4415/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0206 - val_loss: 0.6318\n",
      "Epoch 4416/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0232 - val_loss: 0.6352\n",
      "Epoch 4417/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0198 - val_loss: 0.6348\n",
      "Epoch 4418/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0178 - val_loss: 0.6515\n",
      "Epoch 4419/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0184 - val_loss: 0.6278\n",
      "Epoch 4420/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0291 - val_loss: 0.6395\n",
      "Epoch 4421/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0270 - val_loss: 0.6557\n",
      "Epoch 4422/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0351 - val_loss: 0.6133\n",
      "Epoch 4423/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0390 - val_loss: 0.6265\n",
      "Epoch 4424/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0225 - val_loss: 0.6255\n",
      "Epoch 4425/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0214 - val_loss: 0.6197\n",
      "Epoch 4426/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0219 - val_loss: 0.6134\n",
      "Epoch 4427/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0210 - val_loss: 0.6371\n",
      "Epoch 4428/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0250 - val_loss: 0.6153\n",
      "Epoch 4429/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0253 - val_loss: 0.6641\n",
      "Epoch 4430/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0276 - val_loss: 0.6500\n",
      "Epoch 4431/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0295 - val_loss: 0.6314\n",
      "Epoch 4432/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0300 - val_loss: 0.6277\n",
      "Epoch 4433/10000\n",
      "130/130 [==============================] - 0s 834us/step - loss: 0.0216 - val_loss: 0.6332\n",
      "Epoch 4434/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0224 - val_loss: 0.6344\n",
      "Epoch 4435/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0248 - val_loss: 0.6414\n",
      "Epoch 4436/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0519 - val_loss: 0.6114\n",
      "Epoch 4437/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0395 - val_loss: 0.6263\n",
      "Epoch 4438/10000\n",
      "130/130 [==============================] - 0s 836us/step - loss: 0.0242 - val_loss: 0.6215\n",
      "Epoch 4439/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0202 - val_loss: 0.6482\n",
      "Epoch 4440/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0217 - val_loss: 0.6375\n",
      "Epoch 4441/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0248 - val_loss: 0.6275\n",
      "Epoch 4442/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0240 - val_loss: 0.6302\n",
      "Epoch 4443/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0249 - val_loss: 0.6505\n",
      "Epoch 4444/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0439 - val_loss: 0.6347\n",
      "Epoch 4445/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0400 - val_loss: 0.6327\n",
      "Epoch 4446/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0282 - val_loss: 0.6205\n",
      "Epoch 4447/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0204 - val_loss: 0.6316\n",
      "Epoch 4448/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0217 - val_loss: 0.6338\n",
      "Epoch 4449/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0211 - val_loss: 0.6381\n",
      "Epoch 4450/10000\n",
      "130/130 [==============================] - 0s 909us/step - loss: 0.0271 - val_loss: 0.6380\n",
      "Epoch 4451/10000\n",
      "130/130 [==============================] - 0s 906us/step - loss: 0.0302 - val_loss: 0.6538\n",
      "Epoch 4452/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0271 - val_loss: 0.6424\n",
      "Epoch 4453/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0296 - val_loss: 0.6365\n",
      "Epoch 4454/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0312 - val_loss: 0.6208\n",
      "Epoch 4455/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0261 - val_loss: 0.6386\n",
      "Epoch 4456/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.6034\n",
      "Epoch 4457/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0246 - val_loss: 0.6368\n",
      "Epoch 4458/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0185 - val_loss: 0.6255\n",
      "Epoch 4459/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0208 - val_loss: 0.6381\n",
      "Epoch 4460/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0210 - val_loss: 0.6598\n",
      "Epoch 4461/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0206 - val_loss: 0.6373\n",
      "Epoch 4462/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0331 - val_loss: 0.6350\n",
      "Epoch 4463/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0940 - val_loss: 0.6267\n",
      "Epoch 4464/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0397 - val_loss: 0.6366\n",
      "Epoch 4465/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0199 - val_loss: 0.6150\n",
      "Epoch 4466/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0189 - val_loss: 0.6334\n",
      "Epoch 4467/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0186 - val_loss: 0.6180\n",
      "Epoch 4468/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0195 - val_loss: 0.6511\n",
      "Epoch 4469/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0185 - val_loss: 0.6494\n",
      "Epoch 4470/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0188 - val_loss: 0.6421\n",
      "Epoch 4471/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.6522\n",
      "Epoch 4472/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0247 - val_loss: 0.6403\n",
      "Epoch 4473/10000\n",
      "130/130 [==============================] - 0s 840us/step - loss: 0.0262 - val_loss: 0.6402\n",
      "Epoch 4474/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0292 - val_loss: 0.6171\n",
      "Epoch 4475/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0287 - val_loss: 0.6310\n",
      "Epoch 4476/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0302 - val_loss: 0.6412\n",
      "Epoch 4477/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0359 - val_loss: 0.6518\n",
      "Epoch 4478/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0247 - val_loss: 0.6175\n",
      "Epoch 4479/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0222 - val_loss: 0.6406\n",
      "Epoch 4480/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0213 - val_loss: 0.6329\n",
      "Epoch 4481/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0217 - val_loss: 0.6493\n",
      "Epoch 4482/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0218 - val_loss: 0.6444\n",
      "Epoch 4483/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0278 - val_loss: 0.6192\n",
      "Epoch 4484/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0251 - val_loss: 0.6146\n",
      "Epoch 4485/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0340 - val_loss: 0.6589\n",
      "Epoch 4486/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0448 - val_loss: 0.6576\n",
      "Epoch 4487/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 853us/step - loss: 0.0426 - val_loss: 0.6600\n",
      "Epoch 4488/10000\n",
      "130/130 [==============================] - 0s 833us/step - loss: 0.0274 - val_loss: 0.6196\n",
      "Epoch 4489/10000\n",
      "130/130 [==============================] - 0s 805us/step - loss: 0.0221 - val_loss: 0.6296\n",
      "Epoch 4490/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0251 - val_loss: 0.6511\n",
      "Epoch 4491/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0294 - val_loss: 0.6163\n",
      "Epoch 4492/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0313 - val_loss: 0.6165\n",
      "Epoch 4493/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0262 - val_loss: 0.6144\n",
      "Epoch 4494/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0227 - val_loss: 0.6266\n",
      "Epoch 4495/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0219 - val_loss: 0.6328\n",
      "Epoch 4496/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0207 - val_loss: 0.6182\n",
      "Epoch 4497/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0212 - val_loss: 0.6192\n",
      "Epoch 4498/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0303 - val_loss: 0.6500\n",
      "Epoch 4499/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0398 - val_loss: 0.6202\n",
      "Epoch 4500/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0309 - val_loss: 0.6199\n",
      "Epoch 4501/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0251 - val_loss: 0.6248\n",
      "Epoch 4502/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0287 - val_loss: 0.6258\n",
      "Epoch 4503/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0237 - val_loss: 0.6322\n",
      "Epoch 4504/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0252 - val_loss: 0.6106\n",
      "Epoch 4505/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0296 - val_loss: 0.6450\n",
      "Epoch 4506/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0277 - val_loss: 0.6273\n",
      "Epoch 4507/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0260 - val_loss: 0.6319\n",
      "Epoch 4508/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0350 - val_loss: 0.6166\n",
      "Epoch 4509/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0352 - val_loss: 0.6204\n",
      "Epoch 4510/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0434 - val_loss: 0.6705\n",
      "Epoch 4511/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0304 - val_loss: 0.6283\n",
      "Epoch 4512/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0201 - val_loss: 0.6357\n",
      "Epoch 4513/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0180 - val_loss: 0.6270\n",
      "Epoch 4514/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0201 - val_loss: 0.6221\n",
      "Epoch 4515/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0227 - val_loss: 0.6189\n",
      "Epoch 4516/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0196 - val_loss: 0.6202\n",
      "Epoch 4517/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0188 - val_loss: 0.6363\n",
      "Epoch 4518/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0225 - val_loss: 0.6324\n",
      "Epoch 4519/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0216 - val_loss: 0.6442\n",
      "Epoch 4520/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0271 - val_loss: 0.6452\n",
      "Epoch 4521/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0306 - val_loss: 0.6215\n",
      "Epoch 4522/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0357 - val_loss: 0.6176\n",
      "Epoch 4523/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0389 - val_loss: 0.6440\n",
      "Epoch 4524/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0312 - val_loss: 0.6415\n",
      "Epoch 4525/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0233 - val_loss: 0.6266\n",
      "Epoch 4526/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0260 - val_loss: 0.6139\n",
      "Epoch 4527/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0204 - val_loss: 0.6192\n",
      "Epoch 4528/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0220 - val_loss: 0.6250\n",
      "Epoch 4529/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0235 - val_loss: 0.6098\n",
      "Epoch 4530/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0239 - val_loss: 0.6446\n",
      "Epoch 4531/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0272 - val_loss: 0.6312\n",
      "Epoch 4532/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0306 - val_loss: 0.6367\n",
      "Epoch 4533/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0292 - val_loss: 0.6511\n",
      "Epoch 4534/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0727 - val_loss: 0.6329\n",
      "Epoch 4535/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0294 - val_loss: 0.6329\n",
      "Epoch 4536/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0180 - val_loss: 0.6346\n",
      "Epoch 4537/10000\n",
      "130/130 [==============================] - 0s 871us/step - loss: 0.0228 - val_loss: 0.6302\n",
      "Epoch 4538/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0272 - val_loss: 0.6107\n",
      "Epoch 4539/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0244 - val_loss: 0.6328\n",
      "Epoch 4540/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0235 - val_loss: 0.6348\n",
      "Epoch 4541/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0285 - val_loss: 0.6358\n",
      "Epoch 4542/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0238 - val_loss: 0.6397\n",
      "Epoch 4543/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0268 - val_loss: 0.6078\n",
      "Epoch 4544/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0234 - val_loss: 0.6343\n",
      "Epoch 4545/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0215 - val_loss: 0.6462\n",
      "Epoch 4546/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0209 - val_loss: 0.6473\n",
      "Epoch 4547/10000\n",
      "130/130 [==============================] - 0s 834us/step - loss: 0.0343 - val_loss: 0.6572\n",
      "Epoch 4548/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0597 - val_loss: 0.6221\n",
      "Epoch 4549/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0292 - val_loss: 0.6200\n",
      "Epoch 4550/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0192 - val_loss: 0.6238\n",
      "Epoch 4551/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0222 - val_loss: 0.6306\n",
      "Epoch 4552/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0200 - val_loss: 0.6303\n",
      "Epoch 4553/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0254 - val_loss: 0.6308\n",
      "Epoch 4554/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0301 - val_loss: 0.6427\n",
      "Epoch 4555/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0209 - val_loss: 0.6430\n",
      "Epoch 4556/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0211 - val_loss: 0.6105\n",
      "Epoch 4557/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0239 - val_loss: 0.6252\n",
      "Epoch 4558/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0280 - val_loss: 0.6275\n",
      "Epoch 4559/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0224 - val_loss: 0.6469\n",
      "Epoch 4560/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0231 - val_loss: 0.6258\n",
      "Epoch 4561/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0244 - val_loss: 0.6339\n",
      "Epoch 4562/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0255 - val_loss: 0.6182\n",
      "Epoch 4563/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 742us/step - loss: 0.0261 - val_loss: 0.6529\n",
      "Epoch 4564/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0520 - val_loss: 0.6216\n",
      "Epoch 4565/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0378 - val_loss: 0.6233\n",
      "Epoch 4566/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0251 - val_loss: 0.6364\n",
      "Epoch 4567/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0212 - val_loss: 0.6208\n",
      "Epoch 4568/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0200 - val_loss: 0.6477\n",
      "Epoch 4569/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0232 - val_loss: 0.6247\n",
      "Epoch 4570/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0226 - val_loss: 0.6213\n",
      "Epoch 4571/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0277 - val_loss: 0.6267\n",
      "Epoch 4572/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0256 - val_loss: 0.6248\n",
      "Epoch 4573/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0245 - val_loss: 0.6321\n",
      "Epoch 4574/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0303 - val_loss: 0.6465\n",
      "Epoch 4575/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0330 - val_loss: 0.6251\n",
      "Epoch 4576/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0274 - val_loss: 0.6269\n",
      "Epoch 4577/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0184 - val_loss: 0.6167\n",
      "Epoch 4578/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0197 - val_loss: 0.6143\n",
      "Epoch 4579/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0249 - val_loss: 0.6418\n",
      "Epoch 4580/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0372 - val_loss: 0.6243\n",
      "Epoch 4581/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0343 - val_loss: 0.6279\n",
      "Epoch 4582/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0226 - val_loss: 0.6371\n",
      "Epoch 4583/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0212 - val_loss: 0.6224\n",
      "Epoch 4584/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0240 - val_loss: 0.6231\n",
      "Epoch 4585/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0253 - val_loss: 0.6302\n",
      "Epoch 4586/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0243 - val_loss: 0.6553\n",
      "Epoch 4587/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0329 - val_loss: 0.6243\n",
      "Epoch 4588/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0230 - val_loss: 0.6348\n",
      "Epoch 4589/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0274 - val_loss: 0.6313\n",
      "Epoch 4590/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0270 - val_loss: 0.6271\n",
      "Epoch 4591/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0223 - val_loss: 0.6401\n",
      "Epoch 4592/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0271 - val_loss: 0.6282\n",
      "Epoch 4593/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0363 - val_loss: 0.6224\n",
      "Epoch 4594/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0309 - val_loss: 0.6256\n",
      "Epoch 4595/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0295 - val_loss: 0.6381\n",
      "Epoch 4596/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0498 - val_loss: 0.6355\n",
      "Epoch 4597/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0660 - val_loss: 0.6078\n",
      "Epoch 4598/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0279 - val_loss: 0.6195\n",
      "Epoch 4599/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0171 - val_loss: 0.6130\n",
      "Epoch 4600/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0187 - val_loss: 0.6318\n",
      "Epoch 4601/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0173 - val_loss: 0.6258\n",
      "Epoch 4602/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0176 - val_loss: 0.6351\n",
      "Epoch 4603/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0259 - val_loss: 0.6463\n",
      "Epoch 4604/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0262 - val_loss: 0.6108\n",
      "Epoch 4605/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0212 - val_loss: 0.6226\n",
      "Epoch 4606/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0213 - val_loss: 0.6183\n",
      "Epoch 4607/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0222 - val_loss: 0.6379\n",
      "Epoch 4608/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0215 - val_loss: 0.6438\n",
      "Epoch 4609/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0213 - val_loss: 0.6338\n",
      "Epoch 4610/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0250 - val_loss: 0.6172\n",
      "Epoch 4611/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0278 - val_loss: 0.6401\n",
      "Epoch 4612/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0340 - val_loss: 0.6335\n",
      "Epoch 4613/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0306 - val_loss: 0.6251\n",
      "Epoch 4614/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0304 - val_loss: 0.6336\n",
      "Epoch 4615/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0277 - val_loss: 0.6186\n",
      "Epoch 4616/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0226 - val_loss: 0.6208\n",
      "Epoch 4617/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0218 - val_loss: 0.6374\n",
      "Epoch 4618/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0285 - val_loss: 0.6240\n",
      "Epoch 4619/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0264 - val_loss: 0.6373\n",
      "Epoch 4620/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0212 - val_loss: 0.6166\n",
      "Epoch 4621/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0271 - val_loss: 0.6324\n",
      "Epoch 4622/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0325 - val_loss: 0.6631\n",
      "Epoch 4623/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0389 - val_loss: 0.6381\n",
      "Epoch 4624/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0305 - val_loss: 0.6425\n",
      "Epoch 4625/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0233 - val_loss: 0.6291\n",
      "Epoch 4626/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0246 - val_loss: 0.6326\n",
      "Epoch 4627/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0293 - val_loss: 0.6220\n",
      "Epoch 4628/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0201 - val_loss: 0.6327\n",
      "Epoch 4629/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0273 - val_loss: 0.6717\n",
      "Epoch 4630/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0475 - val_loss: 0.6222\n",
      "Epoch 4631/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0288 - val_loss: 0.6213\n",
      "Epoch 4632/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0210 - val_loss: 0.6244\n",
      "Epoch 4633/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0216 - val_loss: 0.6178\n",
      "Epoch 4634/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0206 - val_loss: 0.6147\n",
      "Epoch 4635/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0174 - val_loss: 0.6151\n",
      "Epoch 4636/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0164 - val_loss: 0.6235\n",
      "Epoch 4637/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0284 - val_loss: 0.6479\n",
      "Epoch 4638/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0276 - val_loss: 0.6398\n",
      "Epoch 4639/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 753us/step - loss: 0.0230 - val_loss: 0.6139\n",
      "Epoch 4640/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0235 - val_loss: 0.6342\n",
      "Epoch 4641/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0321 - val_loss: 0.6440\n",
      "Epoch 4642/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0456 - val_loss: 0.6505\n",
      "Epoch 4643/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0479 - val_loss: 0.6256\n",
      "Epoch 4644/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0233 - val_loss: 0.6380\n",
      "Epoch 4645/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0200 - val_loss: 0.6362\n",
      "Epoch 4646/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0203 - val_loss: 0.6226\n",
      "Epoch 4647/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0219 - val_loss: 0.6314\n",
      "Epoch 4648/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0166 - val_loss: 0.6307\n",
      "Epoch 4649/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0212 - val_loss: 0.6282\n",
      "Epoch 4650/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0290 - val_loss: 0.6301\n",
      "Epoch 4651/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0267 - val_loss: 0.6382\n",
      "Epoch 4652/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0209 - val_loss: 0.6312\n",
      "Epoch 4653/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0205 - val_loss: 0.6383\n",
      "Epoch 4654/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0196 - val_loss: 0.6336\n",
      "Epoch 4655/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0323 - val_loss: 0.6126\n",
      "Epoch 4656/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0388 - val_loss: 0.6287\n",
      "Epoch 4657/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0304 - val_loss: 0.6247\n",
      "Epoch 4658/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0261 - val_loss: 0.6402\n",
      "Epoch 4659/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0260 - val_loss: 0.6391\n",
      "Epoch 4660/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0284 - val_loss: 0.6321\n",
      "Epoch 4661/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0237 - val_loss: 0.6315\n",
      "Epoch 4662/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0291 - val_loss: 0.6271\n",
      "Epoch 4663/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0220 - val_loss: 0.6372\n",
      "Epoch 4664/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0189 - val_loss: 0.6321\n",
      "Epoch 4665/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0196 - val_loss: 0.6268\n",
      "Epoch 4666/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0213 - val_loss: 0.6136\n",
      "Epoch 4667/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0397 - val_loss: 0.6431\n",
      "Epoch 4668/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0339 - val_loss: 0.6666\n",
      "Epoch 4669/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0324 - val_loss: 0.6422\n",
      "Epoch 4670/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0211 - val_loss: 0.6256\n",
      "Epoch 4671/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0202 - val_loss: 0.6295\n",
      "Epoch 4672/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0335 - val_loss: 0.6206\n",
      "Epoch 4673/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0247 - val_loss: 0.6272\n",
      "Epoch 4674/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0221 - val_loss: 0.6247\n",
      "Epoch 4675/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0188 - val_loss: 0.6274\n",
      "Epoch 4676/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0194 - val_loss: 0.6352\n",
      "Epoch 4677/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0200 - val_loss: 0.6326\n",
      "Epoch 4678/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0243 - val_loss: 0.6306\n",
      "Epoch 4679/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0281 - val_loss: 0.6097\n",
      "Epoch 4680/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0254 - val_loss: 0.6253\n",
      "Epoch 4681/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0289 - val_loss: 0.6365\n",
      "Epoch 4682/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0332 - val_loss: 0.6345\n",
      "Epoch 4683/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0400 - val_loss: 0.6396\n",
      "Epoch 4684/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0300 - val_loss: 0.6265\n",
      "Epoch 4685/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0220 - val_loss: 0.6373\n",
      "Epoch 4686/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0197 - val_loss: 0.6225\n",
      "Epoch 4687/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0168 - val_loss: 0.6221\n",
      "Epoch 4688/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0265 - val_loss: 0.6226\n",
      "Epoch 4689/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0213 - val_loss: 0.6512\n",
      "Epoch 4690/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0201 - val_loss: 0.6289\n",
      "Epoch 4691/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0191 - val_loss: 0.6401\n",
      "Epoch 4692/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0289 - val_loss: 0.6389\n",
      "Epoch 4693/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0313 - val_loss: 0.6386\n",
      "Epoch 4694/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0290 - val_loss: 0.6252\n",
      "Epoch 4695/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0215 - val_loss: 0.6168\n",
      "Epoch 4696/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0223 - val_loss: 0.6197\n",
      "Epoch 4697/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0293 - val_loss: 0.6306\n",
      "Epoch 4698/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0288 - val_loss: 0.6510\n",
      "Epoch 4699/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0247 - val_loss: 0.6196\n",
      "Epoch 4700/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0299 - val_loss: 0.6267\n",
      "Epoch 4701/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0286 - val_loss: 0.6293\n",
      "Epoch 4702/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0242 - val_loss: 0.6334\n",
      "Epoch 4703/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0236 - val_loss: 0.6157\n",
      "Epoch 4704/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0229 - val_loss: 0.6434\n",
      "Epoch 4705/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0276 - val_loss: 0.6471\n",
      "Epoch 4706/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0248 - val_loss: 0.6477\n",
      "Epoch 4707/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0217 - val_loss: 0.6367\n",
      "Epoch 4708/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0215 - val_loss: 0.6375\n",
      "Epoch 4709/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0241 - val_loss: 0.6453\n",
      "Epoch 4710/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0199 - val_loss: 0.6346\n",
      "Epoch 4711/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0270 - val_loss: 0.6455\n",
      "Epoch 4712/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0284 - val_loss: 0.6158\n",
      "Epoch 4713/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0278 - val_loss: 0.6396\n",
      "Epoch 4714/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0311 - val_loss: 0.6131\n",
      "Epoch 4715/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 728us/step - loss: 0.0220 - val_loss: 0.6182\n",
      "Epoch 4716/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0276 - val_loss: 0.6229\n",
      "Epoch 4717/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0206 - val_loss: 0.6194\n",
      "Epoch 4718/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0193 - val_loss: 0.6287\n",
      "Epoch 4719/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0214 - val_loss: 0.6399\n",
      "Epoch 4720/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0411 - val_loss: 0.6638\n",
      "Epoch 4721/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0410 - val_loss: 0.6318\n",
      "Epoch 4722/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0303 - val_loss: 0.6216\n",
      "Epoch 4723/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0224 - val_loss: 0.6242\n",
      "Epoch 4724/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0216 - val_loss: 0.6381\n",
      "Epoch 4725/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0187 - val_loss: 0.6200\n",
      "Epoch 4726/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0209 - val_loss: 0.6215\n",
      "Epoch 4727/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0211 - val_loss: 0.6276\n",
      "Epoch 4728/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0274 - val_loss: 0.6449\n",
      "Epoch 4729/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0227 - val_loss: 0.6200\n",
      "Epoch 4730/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0230 - val_loss: 0.6317\n",
      "Epoch 4731/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0251 - val_loss: 0.6395\n",
      "Epoch 4732/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0249 - val_loss: 0.6240\n",
      "Epoch 4733/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0197 - val_loss: 0.6318\n",
      "Epoch 4734/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0194 - val_loss: 0.6537\n",
      "Epoch 4735/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0248 - val_loss: 0.6411\n",
      "Epoch 4736/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0316 - val_loss: 0.6432\n",
      "Epoch 4737/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0405 - val_loss: 0.6304\n",
      "Epoch 4738/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0481 - val_loss: 0.6172\n",
      "Epoch 4739/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0272 - val_loss: 0.6180\n",
      "Epoch 4740/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0235 - val_loss: 0.6074\n",
      "Epoch 4741/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0217 - val_loss: 0.6369\n",
      "Epoch 4742/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0235 - val_loss: 0.6248\n",
      "Epoch 4743/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0196 - val_loss: 0.6395\n",
      "Epoch 4744/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0197 - val_loss: 0.6364\n",
      "Epoch 4745/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0222 - val_loss: 0.6434\n",
      "Epoch 4746/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0315 - val_loss: 0.6451\n",
      "Epoch 4747/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0404 - val_loss: 0.6226\n",
      "Epoch 4748/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0270 - val_loss: 0.6245\n",
      "Epoch 4749/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0219 - val_loss: 0.6248\n",
      "Epoch 4750/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0198 - val_loss: 0.6318\n",
      "Epoch 4751/10000\n",
      "130/130 [==============================] - 0s 822us/step - loss: 0.0193 - val_loss: 0.6186\n",
      "Epoch 4752/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0221 - val_loss: 0.6432\n",
      "Epoch 4753/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0206 - val_loss: 0.6134\n",
      "Epoch 4754/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0239 - val_loss: 0.6352\n",
      "Epoch 4755/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0224 - val_loss: 0.6313\n",
      "Epoch 4756/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0225 - val_loss: 0.6092\n",
      "Epoch 4757/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0199 - val_loss: 0.6286\n",
      "Epoch 4758/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0257 - val_loss: 0.6444\n",
      "Epoch 4759/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0339 - val_loss: 0.6395\n",
      "Epoch 4760/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0348 - val_loss: 0.6185\n",
      "Epoch 4761/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0375 - val_loss: 0.6382\n",
      "Epoch 4762/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0246 - val_loss: 0.6250\n",
      "Epoch 4763/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0180 - val_loss: 0.6197\n",
      "Epoch 4764/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0203 - val_loss: 0.6501\n",
      "Epoch 4765/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0225 - val_loss: 0.6280\n",
      "Epoch 4766/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0208 - val_loss: 0.6532\n",
      "Epoch 4767/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0219 - val_loss: 0.6123\n",
      "Epoch 4768/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0181 - val_loss: 0.6552\n",
      "Epoch 4769/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0240 - val_loss: 0.6667\n",
      "Epoch 4770/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0286 - val_loss: 0.6432\n",
      "Epoch 4771/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0209 - val_loss: 0.6169\n",
      "Epoch 4772/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0236 - val_loss: 0.6451\n",
      "Epoch 4773/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0296 - val_loss: 0.6334\n",
      "Epoch 4774/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0287 - val_loss: 0.6293\n",
      "Epoch 4775/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0228 - val_loss: 0.6170\n",
      "Epoch 4776/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0211 - val_loss: 0.6367\n",
      "Epoch 4777/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0254 - val_loss: 0.6379\n",
      "Epoch 4778/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0269 - val_loss: 0.6306\n",
      "Epoch 4779/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0192 - val_loss: 0.6380\n",
      "Epoch 4780/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0193 - val_loss: 0.6212\n",
      "Epoch 4781/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0214 - val_loss: 0.6471\n",
      "Epoch 4782/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0262 - val_loss: 0.6527\n",
      "Epoch 4783/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0406 - val_loss: 0.6143\n",
      "Epoch 4784/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0390 - val_loss: 0.6233\n",
      "Epoch 4785/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0307 - val_loss: 0.6196\n",
      "Epoch 4786/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0214 - val_loss: 0.6305\n",
      "Epoch 4787/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0209 - val_loss: 0.6210\n",
      "Epoch 4788/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0186 - val_loss: 0.6267\n",
      "Epoch 4789/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0189 - val_loss: 0.6407\n",
      "Epoch 4790/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0191 - val_loss: 0.6318\n",
      "Epoch 4791/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 756us/step - loss: 0.0198 - val_loss: 0.6241\n",
      "Epoch 4792/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0216 - val_loss: 0.6137\n",
      "Epoch 4793/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0277 - val_loss: 0.6292\n",
      "Epoch 4794/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0302 - val_loss: 0.6597\n",
      "Epoch 4795/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0392 - val_loss: 0.6535\n",
      "Epoch 4796/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0346 - val_loss: 0.6531\n",
      "Epoch 4797/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0316 - val_loss: 0.6442\n",
      "Epoch 4798/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0221 - val_loss: 0.6124\n",
      "Epoch 4799/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0191 - val_loss: 0.6270\n",
      "Epoch 4800/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0281 - val_loss: 0.6309\n",
      "Epoch 4801/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0196 - val_loss: 0.6258\n",
      "Epoch 4802/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0231 - val_loss: 0.6259\n",
      "Epoch 4803/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0242 - val_loss: 0.6338\n",
      "Epoch 4804/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0197 - val_loss: 0.6361\n",
      "Epoch 4805/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0221 - val_loss: 0.6316\n",
      "Epoch 4806/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0299 - val_loss: 0.6592\n",
      "Epoch 4807/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0238 - val_loss: 0.6248\n",
      "Epoch 4808/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0201 - val_loss: 0.6382\n",
      "Epoch 4809/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0189 - val_loss: 0.6125\n",
      "Epoch 4810/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0538 - val_loss: 0.6103\n",
      "Epoch 4811/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0434 - val_loss: 0.6320\n",
      "Epoch 4812/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0221 - val_loss: 0.6122\n",
      "Epoch 4813/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0179 - val_loss: 0.6169\n",
      "Epoch 4814/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0200 - val_loss: 0.6222\n",
      "Epoch 4815/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0210 - val_loss: 0.6206\n",
      "Epoch 4816/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0326 - val_loss: 0.6218\n",
      "Epoch 4817/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0402 - val_loss: 0.6318\n",
      "Epoch 4818/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0256 - val_loss: 0.6159\n",
      "Epoch 4819/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0190 - val_loss: 0.6173\n",
      "Epoch 4820/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0194 - val_loss: 0.6184\n",
      "Epoch 4821/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0186 - val_loss: 0.6304\n",
      "Epoch 4822/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0156 - val_loss: 0.6436\n",
      "Epoch 4823/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0175 - val_loss: 0.6304\n",
      "Epoch 4824/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0208 - val_loss: 0.6572\n",
      "Epoch 4825/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0204 - val_loss: 0.6306\n",
      "Epoch 4826/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0225 - val_loss: 0.6320\n",
      "Epoch 4827/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0277 - val_loss: 0.6340\n",
      "Epoch 4828/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0300 - val_loss: 0.6244\n",
      "Epoch 4829/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0265 - val_loss: 0.6327\n",
      "Epoch 4830/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0238 - val_loss: 0.6334\n",
      "Epoch 4831/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0225 - val_loss: 0.6272\n",
      "Epoch 4832/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0183 - val_loss: 0.6299\n",
      "Epoch 4833/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0217 - val_loss: 0.6332\n",
      "Epoch 4834/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0275 - val_loss: 0.6321\n",
      "Epoch 4835/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0282 - val_loss: 0.6154\n",
      "Epoch 4836/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0278 - val_loss: 0.6593\n",
      "Epoch 4837/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0288 - val_loss: 0.6156\n",
      "Epoch 4838/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0244 - val_loss: 0.5907\n",
      "Epoch 4839/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0417 - val_loss: 0.6329\n",
      "Epoch 4840/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0381 - val_loss: 0.6488\n",
      "Epoch 4841/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0455 - val_loss: 0.6238\n",
      "Epoch 4842/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0254 - val_loss: 0.6194\n",
      "Epoch 4843/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0148 - val_loss: 0.6139\n",
      "Epoch 4844/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0151 - val_loss: 0.6171\n",
      "Epoch 4845/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0176 - val_loss: 0.6129\n",
      "Epoch 4846/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0184 - val_loss: 0.6174\n",
      "Epoch 4847/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0190 - val_loss: 0.6314\n",
      "Epoch 4848/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0244 - val_loss: 0.6646\n",
      "Epoch 4849/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0230 - val_loss: 0.6350\n",
      "Epoch 4850/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0207 - val_loss: 0.6330\n",
      "Epoch 4851/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0315 - val_loss: 0.6283\n",
      "Epoch 4852/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0348 - val_loss: 0.6149\n",
      "Epoch 4853/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0237 - val_loss: 0.6249\n",
      "Epoch 4854/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0244 - val_loss: 0.6055\n",
      "Epoch 4855/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0188 - val_loss: 0.6142\n",
      "Epoch 4856/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0252 - val_loss: 0.6164\n",
      "Epoch 4857/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0344 - val_loss: 0.6493\n",
      "Epoch 4858/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0627 - val_loss: 0.6327\n",
      "Epoch 4859/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0202 - val_loss: 0.6174\n",
      "Epoch 4860/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0167 - val_loss: 0.6208\n",
      "Epoch 4861/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0166 - val_loss: 0.6315\n",
      "Epoch 4862/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0184 - val_loss: 0.6276\n",
      "Epoch 4863/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0209 - val_loss: 0.6253\n",
      "Epoch 4864/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0195 - val_loss: 0.6526\n",
      "Epoch 4865/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0270 - val_loss: 0.6701\n",
      "Epoch 4866/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0454 - val_loss: 0.6340\n",
      "Epoch 4867/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 742us/step - loss: 0.0319 - val_loss: 0.6212\n",
      "Epoch 4868/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0256 - val_loss: 0.6176\n",
      "Epoch 4869/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0196 - val_loss: 0.6138\n",
      "Epoch 4870/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0161 - val_loss: 0.6431\n",
      "Epoch 4871/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0160 - val_loss: 0.6349\n",
      "Epoch 4872/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0210 - val_loss: 0.6287\n",
      "Epoch 4873/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0232 - val_loss: 0.6275\n",
      "Epoch 4874/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0270 - val_loss: 0.6182\n",
      "Epoch 4875/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0222 - val_loss: 0.6505\n",
      "Epoch 4876/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0196 - val_loss: 0.6200\n",
      "Epoch 4877/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0180 - val_loss: 0.6345\n",
      "Epoch 4878/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0304 - val_loss: 0.6424\n",
      "Epoch 4879/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0352 - val_loss: 0.6360\n",
      "Epoch 4880/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0234 - val_loss: 0.6376\n",
      "Epoch 4881/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0202 - val_loss: 0.6285\n",
      "Epoch 4882/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0211 - val_loss: 0.6175\n",
      "Epoch 4883/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0234 - val_loss: 0.6097\n",
      "Epoch 4884/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0273 - val_loss: 0.6658\n",
      "Epoch 4885/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0440 - val_loss: 0.6048\n",
      "Epoch 4886/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0237 - val_loss: 0.6279\n",
      "Epoch 4887/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0207 - val_loss: 0.6221\n",
      "Epoch 4888/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0206 - val_loss: 0.6308\n",
      "Epoch 4889/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0267 - val_loss: 0.6635\n",
      "Epoch 4890/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0224 - val_loss: 0.6350\n",
      "Epoch 4891/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0216 - val_loss: 0.6360\n",
      "Epoch 4892/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0241 - val_loss: 0.6318\n",
      "Epoch 4893/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0218 - val_loss: 0.6257\n",
      "Epoch 4894/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0221 - val_loss: 0.6569\n",
      "Epoch 4895/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0272 - val_loss: 0.6204\n",
      "Epoch 4896/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0252 - val_loss: 0.6224\n",
      "Epoch 4897/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0205 - val_loss: 0.6256\n",
      "Epoch 4898/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0202 - val_loss: 0.6373\n",
      "Epoch 4899/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0154 - val_loss: 0.6342\n",
      "Epoch 4900/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0247 - val_loss: 0.6200\n",
      "Epoch 4901/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0227 - val_loss: 0.6373\n",
      "Epoch 4902/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0224 - val_loss: 0.6365\n",
      "Epoch 4903/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0249 - val_loss: 0.6261\n",
      "Epoch 4904/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0302 - val_loss: 0.6388\n",
      "Epoch 4905/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0367 - val_loss: 0.6235\n",
      "Epoch 4906/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0428 - val_loss: 0.6332\n",
      "Epoch 4907/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0323 - val_loss: 0.6054\n",
      "Epoch 4908/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0182 - val_loss: 0.6270\n",
      "Epoch 4909/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0159 - val_loss: 0.6169\n",
      "Epoch 4910/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0171 - val_loss: 0.6239\n",
      "Epoch 4911/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0205 - val_loss: 0.6303\n",
      "Epoch 4912/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0208 - val_loss: 0.6331\n",
      "Epoch 4913/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0241 - val_loss: 0.6595\n",
      "Epoch 4914/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0219 - val_loss: 0.6288\n",
      "Epoch 4915/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0240 - val_loss: 0.6346\n",
      "Epoch 4916/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0221 - val_loss: 0.6214\n",
      "Epoch 4917/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0221 - val_loss: 0.6270\n",
      "Epoch 4918/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0211 - val_loss: 0.6158\n",
      "Epoch 4919/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0180 - val_loss: 0.6440\n",
      "Epoch 4920/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0241 - val_loss: 0.6232\n",
      "Epoch 4921/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0276 - val_loss: 0.6434\n",
      "Epoch 4922/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0360 - val_loss: 0.6351\n",
      "Epoch 4923/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0296 - val_loss: 0.6125\n",
      "Epoch 4924/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0191 - val_loss: 0.6286\n",
      "Epoch 4925/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0184 - val_loss: 0.6200\n",
      "Epoch 4926/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0176 - val_loss: 0.6214\n",
      "Epoch 4927/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0170 - val_loss: 0.6376\n",
      "Epoch 4928/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0198 - val_loss: 0.6309\n",
      "Epoch 4929/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0204 - val_loss: 0.6327\n",
      "Epoch 4930/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0298 - val_loss: 0.6404\n",
      "Epoch 4931/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0436 - val_loss: 0.6452\n",
      "Epoch 4932/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0261 - val_loss: 0.6444\n",
      "Epoch 4933/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0215 - val_loss: 0.5958\n",
      "Epoch 4934/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0248 - val_loss: 0.6363\n",
      "Epoch 4935/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0215 - val_loss: 0.6174\n",
      "Epoch 4936/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0173 - val_loss: 0.6229\n",
      "Epoch 4937/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0197 - val_loss: 0.6207\n",
      "Epoch 4938/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0177 - val_loss: 0.6170\n",
      "Epoch 4939/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0264 - val_loss: 0.6323\n",
      "Epoch 4940/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0266 - val_loss: 0.6307\n",
      "Epoch 4941/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0269 - val_loss: 0.6165\n",
      "Epoch 4942/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0241 - val_loss: 0.6169\n",
      "Epoch 4943/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 731us/step - loss: 0.0259 - val_loss: 0.6346\n",
      "Epoch 4944/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0249 - val_loss: 0.6337\n",
      "Epoch 4945/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0230 - val_loss: 0.6415\n",
      "Epoch 4946/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0225 - val_loss: 0.6115\n",
      "Epoch 4947/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0217 - val_loss: 0.6511\n",
      "Epoch 4948/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0263 - val_loss: 0.6312\n",
      "Epoch 4949/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0290 - val_loss: 0.6343\n",
      "Epoch 4950/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0273 - val_loss: 0.6287\n",
      "Epoch 4951/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0194 - val_loss: 0.6366\n",
      "Epoch 4952/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0178 - val_loss: 0.6265\n",
      "Epoch 4953/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0212 - val_loss: 0.6284\n",
      "Epoch 4954/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0347 - val_loss: 0.6312\n",
      "Epoch 4955/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0348 - val_loss: 0.6312\n",
      "Epoch 4956/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0195 - val_loss: 0.6136\n",
      "Epoch 4957/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0275 - val_loss: 0.6304\n",
      "Epoch 4958/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0267 - val_loss: 0.6307\n",
      "Epoch 4959/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0192 - val_loss: 0.6317\n",
      "Epoch 4960/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0200 - val_loss: 0.6321\n",
      "Epoch 4961/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0189 - val_loss: 0.6351\n",
      "Epoch 4962/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0230 - val_loss: 0.6317\n",
      "Epoch 4963/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0293 - val_loss: 0.6329\n",
      "Epoch 4964/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0221 - val_loss: 0.6248\n",
      "Epoch 4965/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0226 - val_loss: 0.6411\n",
      "Epoch 4966/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0212 - val_loss: 0.6368\n",
      "Epoch 4967/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0282 - val_loss: 0.6270\n",
      "Epoch 4968/10000\n",
      "130/130 [==============================] - 0s 934us/step - loss: 0.0194 - val_loss: 0.6274\n",
      "Epoch 4969/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0195 - val_loss: 0.6231\n",
      "Epoch 4970/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0200 - val_loss: 0.6229\n",
      "Epoch 4971/10000\n",
      "130/130 [==============================] - 0s 947us/step - loss: 0.0216 - val_loss: 0.6423\n",
      "Epoch 4972/10000\n",
      "130/130 [==============================] - 0s 824us/step - loss: 0.0232 - val_loss: 0.6253\n",
      "Epoch 4973/10000\n",
      "130/130 [==============================] - 0s 803us/step - loss: 0.0223 - val_loss: 0.6165\n",
      "Epoch 4974/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0331 - val_loss: 0.6434\n",
      "Epoch 4975/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0347 - val_loss: 0.6291\n",
      "Epoch 4976/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0181 - val_loss: 0.6316\n",
      "Epoch 4977/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0153 - val_loss: 0.6166\n",
      "Epoch 4978/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0156 - val_loss: 0.6113\n",
      "Epoch 4979/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0226 - val_loss: 0.6226\n",
      "Epoch 4980/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0269 - val_loss: 0.6527\n",
      "Epoch 4981/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0189 - val_loss: 0.6171\n",
      "Epoch 4982/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0192 - val_loss: 0.6474\n",
      "Epoch 4983/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0433 - val_loss: 0.6157\n",
      "Epoch 4984/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0389 - val_loss: 0.6309\n",
      "Epoch 4985/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0250 - val_loss: 0.6156\n",
      "Epoch 4986/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0179 - val_loss: 0.6231\n",
      "Epoch 4987/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0206 - val_loss: 0.6315\n",
      "Epoch 4988/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0188 - val_loss: 0.6353\n",
      "Epoch 4989/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0360 - val_loss: 0.6340\n",
      "Epoch 4990/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0215 - val_loss: 0.6110\n",
      "Epoch 4991/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0157 - val_loss: 0.6178\n",
      "Epoch 4992/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0270 - val_loss: 0.6338\n",
      "Epoch 4993/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0193 - val_loss: 0.6368\n",
      "Epoch 4994/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0179 - val_loss: 0.6308\n",
      "Epoch 4995/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0204 - val_loss: 0.6419\n",
      "Epoch 4996/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0247 - val_loss: 0.6208\n",
      "Epoch 4997/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0273 - val_loss: 0.6107\n",
      "Epoch 4998/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0328 - val_loss: 0.6296\n",
      "Epoch 4999/10000\n",
      "130/130 [==============================] - 0s 906us/step - loss: 0.0268 - val_loss: 0.6196\n",
      "Epoch 5000/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0259 - val_loss: 0.6270\n",
      "Epoch 5001/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0213 - val_loss: 0.6342\n",
      "Epoch 5002/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0169 - val_loss: 0.6336\n",
      "Epoch 5003/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0163 - val_loss: 0.6120\n",
      "Epoch 5004/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0196 - val_loss: 0.6305\n",
      "Epoch 5005/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0349 - val_loss: 0.6175\n",
      "Epoch 5006/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0248 - val_loss: 0.6201\n",
      "Epoch 5007/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0222 - val_loss: 0.6135\n",
      "Epoch 5008/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0293 - val_loss: 0.6181\n",
      "Epoch 5009/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0319 - val_loss: 0.6059\n",
      "Epoch 5010/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0366 - val_loss: 0.6203\n",
      "Epoch 5011/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0187 - val_loss: 0.6274\n",
      "Epoch 5012/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0210 - val_loss: 0.6238\n",
      "Epoch 5013/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0214 - val_loss: 0.6139\n",
      "Epoch 5014/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0166 - val_loss: 0.6205\n",
      "Epoch 5015/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0196 - val_loss: 0.6321\n",
      "Epoch 5016/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0185 - val_loss: 0.6261\n",
      "Epoch 5017/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0165 - val_loss: 0.6034\n",
      "Epoch 5018/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0256 - val_loss: 0.6310\n",
      "Epoch 5019/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 714us/step - loss: 0.0327 - val_loss: 0.6514\n",
      "Epoch 5020/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0264 - val_loss: 0.6227\n",
      "Epoch 5021/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0185 - val_loss: 0.6591\n",
      "Epoch 5022/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0181 - val_loss: 0.6209\n",
      "Epoch 5023/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0311 - val_loss: 0.6274\n",
      "Epoch 5024/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0645 - val_loss: 0.6451\n",
      "Epoch 5025/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0299 - val_loss: 0.6060\n",
      "Epoch 5026/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0180 - val_loss: 0.5962\n",
      "Epoch 5027/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0152 - val_loss: 0.6079\n",
      "Epoch 5028/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0147 - val_loss: 0.6080\n",
      "Epoch 5029/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0143 - val_loss: 0.6086\n",
      "Epoch 5030/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0269 - val_loss: 0.6191\n",
      "Epoch 5031/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0351 - val_loss: 0.6245\n",
      "Epoch 5032/10000\n",
      "130/130 [==============================] - 0s 899us/step - loss: 0.0360 - val_loss: 0.6405\n",
      "Epoch 5033/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0306 - val_loss: 0.6056\n",
      "Epoch 5034/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0174 - val_loss: 0.6068\n",
      "Epoch 5035/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0177 - val_loss: 0.6240\n",
      "Epoch 5036/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0196 - val_loss: 0.6400\n",
      "Epoch 5037/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0151 - val_loss: 0.6170\n",
      "Epoch 5038/10000\n",
      "130/130 [==============================] - 0s 867us/step - loss: 0.0158 - val_loss: 0.6267\n",
      "Epoch 5039/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0239 - val_loss: 0.6350\n",
      "Epoch 5040/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0217 - val_loss: 0.6413\n",
      "Epoch 5041/10000\n",
      "130/130 [==============================] - 0s 862us/step - loss: 0.0227 - val_loss: 0.6391\n",
      "Epoch 5042/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0248 - val_loss: 0.6234\n",
      "Epoch 5043/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0211 - val_loss: 0.6144\n",
      "Epoch 5044/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0222 - val_loss: 0.6307\n",
      "Epoch 5045/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0228 - val_loss: 0.6245\n",
      "Epoch 5046/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0278 - val_loss: 0.6265\n",
      "Epoch 5047/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0864 - val_loss: 0.6100\n",
      "Epoch 5048/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0553 - val_loss: 0.6266\n",
      "Epoch 5049/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0172 - val_loss: 0.6264\n",
      "Epoch 5050/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0140 - val_loss: 0.6175\n",
      "Epoch 5051/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0126 - val_loss: 0.6166\n",
      "Epoch 5052/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0157 - val_loss: 0.6179\n",
      "Epoch 5053/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0121 - val_loss: 0.6188\n",
      "Epoch 5054/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0158 - val_loss: 0.6199\n",
      "Epoch 5055/10000\n",
      "130/130 [==============================] - 0s 820us/step - loss: 0.0146 - val_loss: 0.6250\n",
      "Epoch 5056/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0179 - val_loss: 0.6237\n",
      "Epoch 5057/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0211 - val_loss: 0.6295\n",
      "Epoch 5058/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0260 - val_loss: 0.6368\n",
      "Epoch 5059/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0340 - val_loss: 0.6517\n",
      "Epoch 5060/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0395 - val_loss: 0.6220\n",
      "Epoch 5061/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0466 - val_loss: 0.6491\n",
      "Epoch 5062/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0331 - val_loss: 0.6242\n",
      "Epoch 5063/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0182 - val_loss: 0.6255\n",
      "Epoch 5064/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0197 - val_loss: 0.6278\n",
      "Epoch 5065/10000\n",
      "130/130 [==============================] - 0s 868us/step - loss: 0.0173 - val_loss: 0.6319\n",
      "Epoch 5066/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.6172\n",
      "Epoch 5067/10000\n",
      "130/130 [==============================] - 0s 839us/step - loss: 0.0162 - val_loss: 0.6207\n",
      "Epoch 5068/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0163 - val_loss: 0.6170\n",
      "Epoch 5069/10000\n",
      "130/130 [==============================] - 0s 981us/step - loss: 0.0154 - val_loss: 0.6107\n",
      "Epoch 5070/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.6303\n",
      "Epoch 5071/10000\n",
      "130/130 [==============================] - 0s 843us/step - loss: 0.0316 - val_loss: 0.6068\n",
      "Epoch 5072/10000\n",
      "130/130 [==============================] - 0s 846us/step - loss: 0.0364 - val_loss: 0.6286\n",
      "Epoch 5073/10000\n",
      "130/130 [==============================] - 0s 853us/step - loss: 0.0249 - val_loss: 0.6350\n",
      "Epoch 5074/10000\n",
      "130/130 [==============================] - 0s 890us/step - loss: 0.0219 - val_loss: 0.6264\n",
      "Epoch 5075/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.6148\n",
      "Epoch 5076/10000\n",
      "130/130 [==============================] - 0s 975us/step - loss: 0.0212 - val_loss: 0.6420\n",
      "Epoch 5077/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0248 - val_loss: 0.6318\n",
      "Epoch 5078/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.0186 - val_loss: 0.6214\n",
      "Epoch 5079/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0174 - val_loss: 0.6134\n",
      "Epoch 5080/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0171 - val_loss: 0.6247\n",
      "Epoch 5081/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0226 - val_loss: 0.6441\n",
      "Epoch 5082/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0274 - val_loss: 0.6384\n",
      "Epoch 5083/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0285 - val_loss: 0.6507\n",
      "Epoch 5084/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0369 - val_loss: 0.6444\n",
      "Epoch 5085/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0359 - val_loss: 0.6443\n",
      "Epoch 5086/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0238 - val_loss: 0.6145\n",
      "Epoch 5087/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0226 - val_loss: 0.6158\n",
      "Epoch 5088/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0143 - val_loss: 0.6155\n",
      "Epoch 5089/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0143 - val_loss: 0.6266\n",
      "Epoch 5090/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0167 - val_loss: 0.6211\n",
      "Epoch 5091/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0231 - val_loss: 0.6371\n",
      "Epoch 5092/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0396 - val_loss: 0.6378\n",
      "Epoch 5093/10000\n",
      "130/130 [==============================] - 0s 792us/step - loss: 0.0267 - val_loss: 0.6306\n",
      "Epoch 5094/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0181 - val_loss: 0.6172\n",
      "Epoch 5095/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 860us/step - loss: 0.0162 - val_loss: 0.6398\n",
      "Epoch 5096/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.6326\n",
      "Epoch 5097/10000\n",
      "130/130 [==============================] - 0s 885us/step - loss: 0.0162 - val_loss: 0.6229\n",
      "Epoch 5098/10000\n",
      "130/130 [==============================] - 0s 936us/step - loss: 0.0177 - val_loss: 0.6303\n",
      "Epoch 5099/10000\n",
      "130/130 [==============================] - 0s 909us/step - loss: 0.0198 - val_loss: 0.6567\n",
      "Epoch 5100/10000\n",
      "130/130 [==============================] - 0s 819us/step - loss: 0.0364 - val_loss: 0.6096\n",
      "Epoch 5101/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0391 - val_loss: 0.6599\n",
      "Epoch 5102/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0521 - val_loss: 0.6310\n",
      "Epoch 5103/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0258 - val_loss: 0.6342\n",
      "Epoch 5104/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0162 - val_loss: 0.6258\n",
      "Epoch 5105/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0167 - val_loss: 0.6131\n",
      "Epoch 5106/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0191 - val_loss: 0.6221\n",
      "Epoch 5107/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0194 - val_loss: 0.6241\n",
      "Epoch 5108/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0151 - val_loss: 0.6305\n",
      "Epoch 5109/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0185 - val_loss: 0.6240\n",
      "Epoch 5110/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0204 - val_loss: 0.6235\n",
      "Epoch 5111/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0231 - val_loss: 0.6396\n",
      "Epoch 5112/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0190 - val_loss: 0.6084\n",
      "Epoch 5113/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0162 - val_loss: 0.6480\n",
      "Epoch 5114/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0238 - val_loss: 0.6161\n",
      "Epoch 5115/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0331 - val_loss: 0.6336\n",
      "Epoch 5116/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0409 - val_loss: 0.6182\n",
      "Epoch 5117/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0512 - val_loss: 0.6050\n",
      "Epoch 5118/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0247 - val_loss: 0.6154\n",
      "Epoch 5119/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0139 - val_loss: 0.6158\n",
      "Epoch 5120/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0167 - val_loss: 0.6302\n",
      "Epoch 5121/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0128 - val_loss: 0.6223\n",
      "Epoch 5122/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0131 - val_loss: 0.6298\n",
      "Epoch 5123/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0246 - val_loss: 0.6322\n",
      "Epoch 5124/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0373 - val_loss: 0.6207\n",
      "Epoch 5125/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0240 - val_loss: 0.6275\n",
      "Epoch 5126/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0259 - val_loss: 0.6124\n",
      "Epoch 5127/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0249 - val_loss: 0.6260\n",
      "Epoch 5128/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0198 - val_loss: 0.6193\n",
      "Epoch 5129/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0182 - val_loss: 0.5939\n",
      "Epoch 5130/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0149 - val_loss: 0.6245\n",
      "Epoch 5131/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0205 - val_loss: 0.6225\n",
      "Epoch 5132/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0249 - val_loss: 0.6455\n",
      "Epoch 5133/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0218 - val_loss: 0.6169\n",
      "Epoch 5134/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0250 - val_loss: 0.6152\n",
      "Epoch 5135/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0228 - val_loss: 0.6059\n",
      "Epoch 5136/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0172 - val_loss: 0.6266\n",
      "Epoch 5137/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0198 - val_loss: 0.6332\n",
      "Epoch 5138/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0188 - val_loss: 0.6064\n",
      "Epoch 5139/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0188 - val_loss: 0.6087\n",
      "Epoch 5140/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0302 - val_loss: 0.6208\n",
      "Epoch 5141/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0268 - val_loss: 0.6282\n",
      "Epoch 5142/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0202 - val_loss: 0.6220\n",
      "Epoch 5143/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0206 - val_loss: 0.6206\n",
      "Epoch 5144/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0226 - val_loss: 0.6088\n",
      "Epoch 5145/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0291 - val_loss: 0.6362\n",
      "Epoch 5146/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0210 - val_loss: 0.6138\n",
      "Epoch 5147/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0174 - val_loss: 0.6227\n",
      "Epoch 5148/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0162 - val_loss: 0.6119\n",
      "Epoch 5149/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0351 - val_loss: 0.6355\n",
      "Epoch 5150/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0863 - val_loss: 0.6269\n",
      "Epoch 5151/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0312 - val_loss: 0.6275\n",
      "Epoch 5152/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0157 - val_loss: 0.6129\n",
      "Epoch 5153/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0144 - val_loss: 0.6199\n",
      "Epoch 5154/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0178 - val_loss: 0.6263\n",
      "Epoch 5155/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0167 - val_loss: 0.6247\n",
      "Epoch 5156/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0139 - val_loss: 0.6255\n",
      "Epoch 5157/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0153 - val_loss: 0.6284\n",
      "Epoch 5158/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0166 - val_loss: 0.6327\n",
      "Epoch 5159/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0208 - val_loss: 0.6310\n",
      "Epoch 5160/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0226 - val_loss: 0.6077\n",
      "Epoch 5161/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0264 - val_loss: 0.6123\n",
      "Epoch 5162/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0242 - val_loss: 0.6317\n",
      "Epoch 5163/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0313 - val_loss: 0.6291\n",
      "Epoch 5164/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0274 - val_loss: 0.6214\n",
      "Epoch 5165/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0222 - val_loss: 0.6343\n",
      "Epoch 5166/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0210 - val_loss: 0.6152\n",
      "Epoch 5167/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0163 - val_loss: 0.6440\n",
      "Epoch 5168/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0151 - val_loss: 0.6240\n",
      "Epoch 5169/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.6256\n",
      "Epoch 5170/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0222 - val_loss: 0.6273\n",
      "Epoch 5171/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 721us/step - loss: 0.0174 - val_loss: 0.6265\n",
      "Epoch 5172/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0165 - val_loss: 0.6071\n",
      "Epoch 5173/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0150 - val_loss: 0.6261\n",
      "Epoch 5174/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0158 - val_loss: 0.6255\n",
      "Epoch 5175/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0295 - val_loss: 0.6735\n",
      "Epoch 5176/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0495 - val_loss: 0.6446\n",
      "Epoch 5177/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0296 - val_loss: 0.6382\n",
      "Epoch 5178/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0207 - val_loss: 0.6139\n",
      "Epoch 5179/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0204 - val_loss: 0.6254\n",
      "Epoch 5180/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0212 - val_loss: 0.6106\n",
      "Epoch 5181/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0165 - val_loss: 0.6214\n",
      "Epoch 5182/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0257 - val_loss: 0.6418\n",
      "Epoch 5183/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0233 - val_loss: 0.6031\n",
      "Epoch 5184/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0245 - val_loss: 0.6406\n",
      "Epoch 5185/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0295 - val_loss: 0.6206\n",
      "Epoch 5186/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0364 - val_loss: 0.6289\n",
      "Epoch 5187/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0252 - val_loss: 0.6363\n",
      "Epoch 5188/10000\n",
      "130/130 [==============================] - 0s 804us/step - loss: 0.0158 - val_loss: 0.6217\n",
      "Epoch 5189/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0188 - val_loss: 0.6478\n",
      "Epoch 5190/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0166 - val_loss: 0.6310\n",
      "Epoch 5191/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0213 - val_loss: 0.6258\n",
      "Epoch 5192/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0206 - val_loss: 0.6357\n",
      "Epoch 5193/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0184 - val_loss: 0.6338\n",
      "Epoch 5194/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0206 - val_loss: 0.6437\n",
      "Epoch 5195/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0277 - val_loss: 0.6288\n",
      "Epoch 5196/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0228 - val_loss: 0.6095\n",
      "Epoch 5197/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0353 - val_loss: 0.6384\n",
      "Epoch 5198/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0222 - val_loss: 0.6143\n",
      "Epoch 5199/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0151 - val_loss: 0.6167\n",
      "Epoch 5200/10000\n",
      "130/130 [==============================] - 0s 809us/step - loss: 0.0184 - val_loss: 0.6204\n",
      "Epoch 5201/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0259 - val_loss: 0.6246\n",
      "Epoch 5202/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0267 - val_loss: 0.6559\n",
      "Epoch 5203/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0333 - val_loss: 0.6170\n",
      "Epoch 5204/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0560 - val_loss: 0.6439\n",
      "Epoch 5205/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0447 - val_loss: 0.5914\n",
      "Epoch 5206/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0217 - val_loss: 0.6112\n",
      "Epoch 5207/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0160 - val_loss: 0.6321\n",
      "Epoch 5208/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0132 - val_loss: 0.6222\n",
      "Epoch 5209/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0143 - val_loss: 0.6384\n",
      "Epoch 5210/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0195 - val_loss: 0.6425\n",
      "Epoch 5211/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0181 - val_loss: 0.6302\n",
      "Epoch 5212/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0239 - val_loss: 0.6148\n",
      "Epoch 5213/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0240 - val_loss: 0.6213\n",
      "Epoch 5214/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0184 - val_loss: 0.6138\n",
      "Epoch 5215/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0177 - val_loss: 0.6357\n",
      "Epoch 5216/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0286 - val_loss: 0.6480\n",
      "Epoch 5217/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0231 - val_loss: 0.6328\n",
      "Epoch 5218/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0184 - val_loss: 0.6060\n",
      "Epoch 5219/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0230 - val_loss: 0.6152\n",
      "Epoch 5220/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0203 - val_loss: 0.6312\n",
      "Epoch 5221/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0201 - val_loss: 0.6165\n",
      "Epoch 5222/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0210 - val_loss: 0.6238\n",
      "Epoch 5223/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0156 - val_loss: 0.6063\n",
      "Epoch 5224/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0155 - val_loss: 0.6077\n",
      "Epoch 5225/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0161 - val_loss: 0.6231\n",
      "Epoch 5226/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0188 - val_loss: 0.6080\n",
      "Epoch 5227/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0322 - val_loss: 0.6734\n",
      "Epoch 5228/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0375 - val_loss: 0.6267\n",
      "Epoch 5229/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0274 - val_loss: 0.6246\n",
      "Epoch 5230/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0231 - val_loss: 0.6276\n",
      "Epoch 5231/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0346 - val_loss: 0.6382\n",
      "Epoch 5232/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0371 - val_loss: 0.6359\n",
      "Epoch 5233/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0269 - val_loss: 0.6333\n",
      "Epoch 5234/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0233 - val_loss: 0.6151\n",
      "Epoch 5235/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0142 - val_loss: 0.6056\n",
      "Epoch 5236/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0168 - val_loss: 0.6382\n",
      "Epoch 5237/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0232 - val_loss: 0.6185\n",
      "Epoch 5238/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0344 - val_loss: 0.6135\n",
      "Epoch 5239/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0290 - val_loss: 0.6078\n",
      "Epoch 5240/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0190 - val_loss: 0.6262\n",
      "Epoch 5241/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0149 - val_loss: 0.6119\n",
      "Epoch 5242/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0143 - val_loss: 0.6376\n",
      "Epoch 5243/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0149 - val_loss: 0.6225\n",
      "Epoch 5244/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0180 - val_loss: 0.6389\n",
      "Epoch 5245/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0170 - val_loss: 0.6021\n",
      "Epoch 5246/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0241 - val_loss: 0.6280\n",
      "Epoch 5247/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 764us/step - loss: 0.0253 - val_loss: 0.6267\n",
      "Epoch 5248/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0157 - val_loss: 0.6110\n",
      "Epoch 5249/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0210 - val_loss: 0.6183\n",
      "Epoch 5250/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0259 - val_loss: 0.6517\n",
      "Epoch 5251/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0340 - val_loss: 0.5964\n",
      "Epoch 5252/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0429 - val_loss: 0.6048\n",
      "Epoch 5253/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0958 - val_loss: 0.6346\n",
      "Epoch 5254/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0322 - val_loss: 0.6263\n",
      "Epoch 5255/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0144 - val_loss: 0.6074\n",
      "Epoch 5256/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0116 - val_loss: 0.6021\n",
      "Epoch 5257/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0118 - val_loss: 0.6216\n",
      "Epoch 5258/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0112 - val_loss: 0.6043\n",
      "Epoch 5259/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0128 - val_loss: 0.6077\n",
      "Epoch 5260/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0136 - val_loss: 0.6452\n",
      "Epoch 5261/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0157 - val_loss: 0.6128\n",
      "Epoch 5262/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0178 - val_loss: 0.6326\n",
      "Epoch 5263/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0219 - val_loss: 0.6578\n",
      "Epoch 5264/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0359 - val_loss: 0.6112\n",
      "Epoch 5265/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0443 - val_loss: 0.6189\n",
      "Epoch 5266/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0231 - val_loss: 0.6128\n",
      "Epoch 5267/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0173 - val_loss: 0.6148\n",
      "Epoch 5268/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0150 - val_loss: 0.6024\n",
      "Epoch 5269/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0159 - val_loss: 0.6186\n",
      "Epoch 5270/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0154 - val_loss: 0.5979\n",
      "Epoch 5271/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0232 - val_loss: 0.6083\n",
      "Epoch 5272/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0252 - val_loss: 0.6007\n",
      "Epoch 5273/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0410 - val_loss: 0.6245\n",
      "Epoch 5274/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0525 - val_loss: 0.6204\n",
      "Epoch 5275/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0339 - val_loss: 0.6243\n",
      "Epoch 5276/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0195 - val_loss: 0.6114\n",
      "Epoch 5277/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0133 - val_loss: 0.6136\n",
      "Epoch 5278/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0127 - val_loss: 0.6092\n",
      "Epoch 5279/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0118 - val_loss: 0.6126\n",
      "Epoch 5280/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0129 - val_loss: 0.6196\n",
      "Epoch 5281/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0134 - val_loss: 0.6097\n",
      "Epoch 5282/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0161 - val_loss: 0.5971\n",
      "Epoch 5283/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0226 - val_loss: 0.6059\n",
      "Epoch 5284/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0427 - val_loss: 0.6145\n",
      "Epoch 5285/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0286 - val_loss: 0.6116\n",
      "Epoch 5286/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0223 - val_loss: 0.6183\n",
      "Epoch 5287/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0217 - val_loss: 0.6176\n",
      "Epoch 5288/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0203 - val_loss: 0.6108\n",
      "Epoch 5289/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0199 - val_loss: 0.6293\n",
      "Epoch 5290/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0188 - val_loss: 0.6147\n",
      "Epoch 5291/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0288 - val_loss: 0.5905\n",
      "Epoch 5292/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0245 - val_loss: 0.6306\n",
      "Epoch 5293/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0247 - val_loss: 0.6100\n",
      "Epoch 5294/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0281 - val_loss: 0.6332\n",
      "Epoch 5295/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0168 - val_loss: 0.6260\n",
      "Epoch 5296/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0223 - val_loss: 0.6348\n",
      "Epoch 5297/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0212 - val_loss: 0.6363\n",
      "Epoch 5298/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0138 - val_loss: 0.6233\n",
      "Epoch 5299/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0180 - val_loss: 0.5927\n",
      "Epoch 5300/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0162 - val_loss: 0.6189\n",
      "Epoch 5301/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0143 - val_loss: 0.6290\n",
      "Epoch 5302/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0174 - val_loss: 0.6149\n",
      "Epoch 5303/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0295 - val_loss: 0.6334\n",
      "Epoch 5304/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0309 - val_loss: 0.6103\n",
      "Epoch 5305/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0388 - val_loss: 0.6192\n",
      "Epoch 5306/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0412 - val_loss: 0.6248\n",
      "Epoch 5307/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0336 - val_loss: 0.6308\n",
      "Epoch 5308/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0160 - val_loss: 0.6198\n",
      "Epoch 5309/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0128 - val_loss: 0.6323\n",
      "Epoch 5310/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0187 - val_loss: 0.6159\n",
      "Epoch 5311/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0241 - val_loss: 0.6271\n",
      "Epoch 5312/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0245 - val_loss: 0.6209\n",
      "Epoch 5313/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0223 - val_loss: 0.6178\n",
      "Epoch 5314/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0251 - val_loss: 0.6225\n",
      "Epoch 5315/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0157 - val_loss: 0.6068\n",
      "Epoch 5316/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0167 - val_loss: 0.6256\n",
      "Epoch 5317/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0199 - val_loss: 0.6331\n",
      "Epoch 5318/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0156 - val_loss: 0.6524\n",
      "Epoch 5319/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0176 - val_loss: 0.6160\n",
      "Epoch 5320/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0220 - val_loss: 0.6386\n",
      "Epoch 5321/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0244 - val_loss: 0.6279\n",
      "Epoch 5322/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0272 - val_loss: 0.6438\n",
      "Epoch 5323/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 735us/step - loss: 0.1126 - val_loss: 0.6108\n",
      "Epoch 5324/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0473 - val_loss: 0.5948\n",
      "Epoch 5325/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0799 - val_loss: 0.6388\n",
      "Epoch 5326/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0212 - val_loss: 0.6270\n",
      "Epoch 5327/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0145 - val_loss: 0.6154\n",
      "Epoch 5328/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0123 - val_loss: 0.6200\n",
      "Epoch 5329/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0126 - val_loss: 0.6320\n",
      "Epoch 5330/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0157 - val_loss: 0.6209\n",
      "Epoch 5331/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0122 - val_loss: 0.6096\n",
      "Epoch 5332/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0123 - val_loss: 0.6140\n",
      "Epoch 5333/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0116 - val_loss: 0.6172\n",
      "Epoch 5334/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0179 - val_loss: 0.6433\n",
      "Epoch 5335/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0260 - val_loss: 0.6213\n",
      "Epoch 5336/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0255 - val_loss: 0.6101\n",
      "Epoch 5337/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0230 - val_loss: 0.6049\n",
      "Epoch 5338/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0365 - val_loss: 0.6215\n",
      "Epoch 5339/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0351 - val_loss: 0.5984\n",
      "Epoch 5340/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0233 - val_loss: 0.6279\n",
      "Epoch 5341/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0243 - val_loss: 0.6170\n",
      "Epoch 5342/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0125 - val_loss: 0.6198\n",
      "Epoch 5343/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0141 - val_loss: 0.6061\n",
      "Epoch 5344/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0121 - val_loss: 0.6203\n",
      "Epoch 5345/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0304 - val_loss: 0.6301\n",
      "Epoch 5346/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0342 - val_loss: 0.6246\n",
      "Epoch 5347/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0230 - val_loss: 0.6223\n",
      "Epoch 5348/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0308 - val_loss: 0.6173\n",
      "Epoch 5349/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0284 - val_loss: 0.6327\n",
      "Epoch 5350/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0231 - val_loss: 0.6122\n",
      "Epoch 5351/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0150 - val_loss: 0.6165\n",
      "Epoch 5352/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0130 - val_loss: 0.6304\n",
      "Epoch 5353/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0152 - val_loss: 0.6258\n",
      "Epoch 5354/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0155 - val_loss: 0.6106\n",
      "Epoch 5355/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0144 - val_loss: 0.6117\n",
      "Epoch 5356/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0241 - val_loss: 0.6354\n",
      "Epoch 5357/10000\n",
      "130/130 [==============================] - 0s 842us/step - loss: 0.0369 - val_loss: 0.6132\n",
      "Epoch 5358/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0692 - val_loss: 0.5877\n",
      "Epoch 5359/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0786 - val_loss: 0.6114\n",
      "Epoch 5360/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0374 - val_loss: 0.5917\n",
      "Epoch 5361/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0179 - val_loss: 0.6016\n",
      "Epoch 5362/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0112 - val_loss: 0.6026\n",
      "Epoch 5363/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0118 - val_loss: 0.6108\n",
      "Epoch 5364/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0135 - val_loss: 0.6009\n",
      "Epoch 5365/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0159 - val_loss: 0.6199\n",
      "Epoch 5366/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0154 - val_loss: 0.6036\n",
      "Epoch 5367/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0159 - val_loss: 0.6062\n",
      "Epoch 5368/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0182 - val_loss: 0.6025\n",
      "Epoch 5369/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0330 - val_loss: 0.6165\n",
      "Epoch 5370/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0452 - val_loss: 0.6215\n",
      "Epoch 5371/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0336 - val_loss: 0.6145\n",
      "Epoch 5372/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0189 - val_loss: 0.6009\n",
      "Epoch 5373/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0163 - val_loss: 0.6427\n",
      "Epoch 5374/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0155 - val_loss: 0.6016\n",
      "Epoch 5375/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0142 - val_loss: 0.6134\n",
      "Epoch 5376/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0144 - val_loss: 0.6216\n",
      "Epoch 5377/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0277 - val_loss: 0.6216\n",
      "Epoch 5378/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0285 - val_loss: 0.6170\n",
      "Epoch 5379/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0247 - val_loss: 0.6444\n",
      "Epoch 5380/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0268 - val_loss: 0.6218\n",
      "Epoch 5381/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0182 - val_loss: 0.6135\n",
      "Epoch 5382/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0163 - val_loss: 0.6163\n",
      "Epoch 5383/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0382 - val_loss: 0.6455\n",
      "Epoch 5384/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0364 - val_loss: 0.6111\n",
      "Epoch 5385/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0224 - val_loss: 0.6051\n",
      "Epoch 5386/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0153 - val_loss: 0.5955\n",
      "Epoch 5387/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0183 - val_loss: 0.6120\n",
      "Epoch 5388/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0158 - val_loss: 0.6252\n",
      "Epoch 5389/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0125 - val_loss: 0.6243\n",
      "Epoch 5390/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0182 - val_loss: 0.6182\n",
      "Epoch 5391/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0259 - val_loss: 0.6325\n",
      "Epoch 5392/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.6373\n",
      "Epoch 5393/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0274 - val_loss: 0.6204\n",
      "Epoch 5394/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0313 - val_loss: 0.6105\n",
      "Epoch 5395/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0262 - val_loss: 0.6245\n",
      "Epoch 5396/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0235 - val_loss: 0.6313\n",
      "Epoch 5397/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0340 - val_loss: 0.6052\n",
      "Epoch 5398/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0403 - val_loss: 0.6257\n",
      "Epoch 5399/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 742us/step - loss: 0.0206 - val_loss: 0.5993\n",
      "Epoch 5400/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0151 - val_loss: 0.6193\n",
      "Epoch 5401/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0151 - val_loss: 0.6032\n",
      "Epoch 5402/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0210 - val_loss: 0.6205\n",
      "Epoch 5403/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0144 - val_loss: 0.6155\n",
      "Epoch 5404/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0137 - val_loss: 0.6254\n",
      "Epoch 5405/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0189 - val_loss: 0.6056\n",
      "Epoch 5406/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0227 - val_loss: 0.6277\n",
      "Epoch 5407/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0201 - val_loss: 0.6199\n",
      "Epoch 5408/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0323 - val_loss: 0.6478\n",
      "Epoch 5409/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0445 - val_loss: 0.6389\n",
      "Epoch 5410/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0239 - val_loss: 0.6263\n",
      "Epoch 5411/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0146 - val_loss: 0.5960\n",
      "Epoch 5412/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0179 - val_loss: 0.6109\n",
      "Epoch 5413/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0160 - val_loss: 0.6113\n",
      "Epoch 5414/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0179 - val_loss: 0.6524\n",
      "Epoch 5415/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0272 - val_loss: 0.5991\n",
      "Epoch 5416/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0186 - val_loss: 0.6143\n",
      "Epoch 5417/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0276 - val_loss: 0.6114\n",
      "Epoch 5418/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0381 - val_loss: 0.6055\n",
      "Epoch 5419/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0299 - val_loss: 0.6101\n",
      "Epoch 5420/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0164 - val_loss: 0.6153\n",
      "Epoch 5421/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0113 - val_loss: 0.6236\n",
      "Epoch 5422/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0113 - val_loss: 0.6174\n",
      "Epoch 5423/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0201 - val_loss: 0.6075\n",
      "Epoch 5424/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0186 - val_loss: 0.6421\n",
      "Epoch 5425/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0205 - val_loss: 0.6613\n",
      "Epoch 5426/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0277 - val_loss: 0.6157\n",
      "Epoch 5427/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0215 - val_loss: 0.6188\n",
      "Epoch 5428/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0762 - val_loss: 0.6272\n",
      "Epoch 5429/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0383 - val_loss: 0.6139\n",
      "Epoch 5430/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0180 - val_loss: 0.6258\n",
      "Epoch 5431/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0143 - val_loss: 0.6022\n",
      "Epoch 5432/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0124 - val_loss: 0.6224\n",
      "Epoch 5433/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0145 - val_loss: 0.6173\n",
      "Epoch 5434/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0130 - val_loss: 0.6369\n",
      "Epoch 5435/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0413 - val_loss: 0.6729\n",
      "Epoch 5436/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0544 - val_loss: 0.5856\n",
      "Epoch 5437/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0291 - val_loss: 0.6222\n",
      "Epoch 5438/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0192 - val_loss: 0.6179\n",
      "Epoch 5439/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0159 - val_loss: 0.6383\n",
      "Epoch 5440/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0116 - val_loss: 0.6169\n",
      "Epoch 5441/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0160 - val_loss: 0.6191\n",
      "Epoch 5442/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0172 - val_loss: 0.6357\n",
      "Epoch 5443/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0174 - val_loss: 0.6147\n",
      "Epoch 5444/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0176 - val_loss: 0.6356\n",
      "Epoch 5445/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0267 - val_loss: 0.6136\n",
      "Epoch 5446/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0425 - val_loss: 0.6496\n",
      "Epoch 5447/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0354 - val_loss: 0.6525\n",
      "Epoch 5448/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0185 - val_loss: 0.6319\n",
      "Epoch 5449/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0200 - val_loss: 0.6511\n",
      "Epoch 5450/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0143 - val_loss: 0.6115\n",
      "Epoch 5451/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0108 - val_loss: 0.6428\n",
      "Epoch 5452/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0144 - val_loss: 0.6234\n",
      "Epoch 5453/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0344 - val_loss: 0.6240\n",
      "Epoch 5454/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0273 - val_loss: 0.6113\n",
      "Epoch 5455/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0156 - val_loss: 0.6215\n",
      "Epoch 5456/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0174 - val_loss: 0.6298\n",
      "Epoch 5457/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0321 - val_loss: 0.6334\n",
      "Epoch 5458/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0355 - val_loss: 0.6240\n",
      "Epoch 5459/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0240 - val_loss: 0.6304\n",
      "Epoch 5460/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0274 - val_loss: 0.6009\n",
      "Epoch 5461/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0260 - val_loss: 0.6246\n",
      "Epoch 5462/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0389 - val_loss: 0.6194\n",
      "Epoch 5463/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0208 - val_loss: 0.6266\n",
      "Epoch 5464/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0170 - val_loss: 0.6286\n",
      "Epoch 5465/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0133 - val_loss: 0.6234\n",
      "Epoch 5466/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0107 - val_loss: 0.6216\n",
      "Epoch 5467/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0125 - val_loss: 0.6352\n",
      "Epoch 5468/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0121 - val_loss: 0.6300\n",
      "Epoch 5469/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0142 - val_loss: 0.6211\n",
      "Epoch 5470/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0237 - val_loss: 0.6182\n",
      "Epoch 5471/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0385 - val_loss: 0.6256\n",
      "Epoch 5472/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0378 - val_loss: 0.5933\n",
      "Epoch 5473/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0473 - val_loss: 0.6190\n",
      "Epoch 5474/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0414 - val_loss: 0.6125\n",
      "Epoch 5475/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 750us/step - loss: 0.0210 - val_loss: 0.6061\n",
      "Epoch 5476/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0168 - val_loss: 0.6071\n",
      "Epoch 5477/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0148 - val_loss: 0.6231\n",
      "Epoch 5478/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0183 - val_loss: 0.6267\n",
      "Epoch 5479/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0131 - val_loss: 0.5972\n",
      "Epoch 5480/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0127 - val_loss: 0.6065\n",
      "Epoch 5481/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0124 - val_loss: 0.6292\n",
      "Epoch 5482/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0185 - val_loss: 0.6369\n",
      "Epoch 5483/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0261 - val_loss: 0.6365\n",
      "Epoch 5484/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0504 - val_loss: 0.6497\n",
      "Epoch 5485/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0302 - val_loss: 0.6404\n",
      "Epoch 5486/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0255 - val_loss: 0.6246\n",
      "Epoch 5487/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0203 - val_loss: 0.6248\n",
      "Epoch 5488/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0142 - val_loss: 0.6321\n",
      "Epoch 5489/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0127 - val_loss: 0.5870\n",
      "Epoch 5490/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0209 - val_loss: 0.6305\n",
      "Epoch 5491/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0214 - val_loss: 0.6390\n",
      "Epoch 5492/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0429 - val_loss: 0.6337\n",
      "Epoch 5493/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0299 - val_loss: 0.6523\n",
      "Epoch 5494/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0263 - val_loss: 0.6219\n",
      "Epoch 5495/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0195 - val_loss: 0.6026\n",
      "Epoch 5496/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0143 - val_loss: 0.6217\n",
      "Epoch 5497/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0135 - val_loss: 0.6152\n",
      "Epoch 5498/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0108 - val_loss: 0.6061\n",
      "Epoch 5499/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0136 - val_loss: 0.5999\n",
      "Epoch 5500/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0192 - val_loss: 0.6028\n",
      "Epoch 5501/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0257 - val_loss: 0.6656\n",
      "Epoch 5502/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0276 - val_loss: 0.6321\n",
      "Epoch 5503/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0290 - val_loss: 0.6346\n",
      "Epoch 5504/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0661 - val_loss: 0.5907\n",
      "Epoch 5505/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0375 - val_loss: 0.5894\n",
      "Epoch 5506/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0202 - val_loss: 0.6130\n",
      "Epoch 5507/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0122 - val_loss: 0.6115\n",
      "Epoch 5508/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0111 - val_loss: 0.6069\n",
      "Epoch 5509/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0114 - val_loss: 0.6185\n",
      "Epoch 5510/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0216 - val_loss: 0.6552\n",
      "Epoch 5511/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0261 - val_loss: 0.6595\n",
      "Epoch 5512/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0236 - val_loss: 0.6061\n",
      "Epoch 5513/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0243 - val_loss: 0.6248\n",
      "Epoch 5514/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0184 - val_loss: 0.6031\n",
      "Epoch 5515/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0209 - val_loss: 0.6290\n",
      "Epoch 5516/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0383 - val_loss: 0.6429\n",
      "Epoch 5517/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0306 - val_loss: 0.6090\n",
      "Epoch 5518/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0246 - val_loss: 0.6546\n",
      "Epoch 5519/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0343 - val_loss: 0.6303\n",
      "Epoch 5520/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0474 - val_loss: 0.6464\n",
      "Epoch 5521/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0309 - val_loss: 0.6320\n",
      "Epoch 5522/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0138 - val_loss: 0.6226\n",
      "Epoch 5523/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0103 - val_loss: 0.6060\n",
      "Epoch 5524/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0094 - val_loss: 0.6178\n",
      "Epoch 5525/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0106 - val_loss: 0.6094\n",
      "Epoch 5526/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0129 - val_loss: 0.6253\n",
      "Epoch 5527/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0175 - val_loss: 0.6167\n",
      "Epoch 5528/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0155 - val_loss: 0.6256\n",
      "Epoch 5529/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0291 - val_loss: 0.6354\n",
      "Epoch 5530/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0500 - val_loss: 0.6511\n",
      "Epoch 5531/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0670 - val_loss: 0.6160\n",
      "Epoch 5532/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0390 - val_loss: 0.5972\n",
      "Epoch 5533/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0116 - val_loss: 0.6257\n",
      "Epoch 5534/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0101 - val_loss: 0.6018\n",
      "Epoch 5535/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0113 - val_loss: 0.6093\n",
      "Epoch 5536/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0107 - val_loss: 0.6209\n",
      "Epoch 5537/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0160 - val_loss: 0.6178\n",
      "Epoch 5538/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0293 - val_loss: 0.6359\n",
      "Epoch 5539/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0272 - val_loss: 0.6288\n",
      "Epoch 5540/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0420 - val_loss: 0.6130\n",
      "Epoch 5541/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0426 - val_loss: 0.6274\n",
      "Epoch 5542/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0226 - val_loss: 0.6010\n",
      "Epoch 5543/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0226 - val_loss: 0.6127\n",
      "Epoch 5544/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0254 - val_loss: 0.5970\n",
      "Epoch 5545/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0156 - val_loss: 0.5918\n",
      "Epoch 5546/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0141 - val_loss: 0.6144\n",
      "Epoch 5547/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0155 - val_loss: 0.6239\n",
      "Epoch 5548/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0167 - val_loss: 0.6236\n",
      "Epoch 5549/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0166 - val_loss: 0.6180\n",
      "Epoch 5550/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0195 - val_loss: 0.6306\n",
      "Epoch 5551/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 744us/step - loss: 0.0281 - val_loss: 0.5994\n",
      "Epoch 5552/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0267 - val_loss: 0.6200\n",
      "Epoch 5553/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0268 - val_loss: 0.6358\n",
      "Epoch 5554/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0237 - val_loss: 0.6070\n",
      "Epoch 5555/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0217 - val_loss: 0.6117\n",
      "Epoch 5556/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0270 - val_loss: 0.5985\n",
      "Epoch 5557/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0230 - val_loss: 0.6175\n",
      "Epoch 5558/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0199 - val_loss: 0.6466\n",
      "Epoch 5559/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0152 - val_loss: 0.5924\n",
      "Epoch 5560/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0160 - val_loss: 0.6106\n",
      "Epoch 5561/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0246 - val_loss: 0.6215\n",
      "Epoch 5562/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0398 - val_loss: 0.6127\n",
      "Epoch 5563/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0372 - val_loss: 0.6261\n",
      "Epoch 5564/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0525 - val_loss: 0.6352\n",
      "Epoch 5565/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0588 - val_loss: 0.6355\n",
      "Epoch 5566/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0289 - val_loss: 0.6163\n",
      "Epoch 5567/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0155 - val_loss: 0.6144\n",
      "Epoch 5568/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0151 - val_loss: 0.6040\n",
      "Epoch 5569/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0108 - val_loss: 0.6103\n",
      "Epoch 5570/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0089 - val_loss: 0.6002\n",
      "Epoch 5571/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0098 - val_loss: 0.5827\n",
      "Epoch 5572/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0139 - val_loss: 0.6303\n",
      "Epoch 5573/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0224 - val_loss: 0.5962\n",
      "Epoch 5574/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0636 - val_loss: 0.6130\n",
      "Epoch 5575/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0644 - val_loss: 0.5866\n",
      "Epoch 5576/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0268 - val_loss: 0.5956\n",
      "Epoch 5577/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0148 - val_loss: 0.6217\n",
      "Epoch 5578/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0177 - val_loss: 0.6230\n",
      "Epoch 5579/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0169 - val_loss: 0.6269\n",
      "Epoch 5580/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0119 - val_loss: 0.6190\n",
      "Epoch 5581/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0124 - val_loss: 0.6015\n",
      "Epoch 5582/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0142 - val_loss: 0.5881\n",
      "Epoch 5583/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0197 - val_loss: 0.6139\n",
      "Epoch 5584/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0343 - val_loss: 0.6074\n",
      "Epoch 5585/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0390 - val_loss: 0.6141\n",
      "Epoch 5586/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0298 - val_loss: 0.6129\n",
      "Epoch 5587/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0222 - val_loss: 0.6328\n",
      "Epoch 5588/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0132 - val_loss: 0.6059\n",
      "Epoch 5589/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0235 - val_loss: 0.6223\n",
      "Epoch 5590/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0221 - val_loss: 0.5819\n",
      "Epoch 5591/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0280 - val_loss: 0.6218\n",
      "Epoch 5592/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0304 - val_loss: 0.6049\n",
      "Epoch 5593/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0236 - val_loss: 0.6263\n",
      "Epoch 5594/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0268 - val_loss: 0.6119\n",
      "Epoch 5595/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0159 - val_loss: 0.6124\n",
      "Epoch 5596/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0180 - val_loss: 0.6152\n",
      "Epoch 5597/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0159 - val_loss: 0.6175\n",
      "Epoch 5598/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0173 - val_loss: 0.5949\n",
      "Epoch 5599/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0148 - val_loss: 0.6128\n",
      "Epoch 5600/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0204 - val_loss: 0.6142\n",
      "Epoch 5601/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0260 - val_loss: 0.6188\n",
      "Epoch 5602/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1066 - val_loss: 0.6262\n",
      "Epoch 5603/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1354 - val_loss: 0.6102\n",
      "Epoch 5604/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0469 - val_loss: 0.6249\n",
      "Epoch 5605/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0223 - val_loss: 0.6255\n",
      "Epoch 5606/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0156 - val_loss: 0.6107\n",
      "Epoch 5607/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0119 - val_loss: 0.6209\n",
      "Epoch 5608/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0095 - val_loss: 0.6299\n",
      "Epoch 5609/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0092 - val_loss: 0.6144\n",
      "Epoch 5610/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0110 - val_loss: 0.6137\n",
      "Epoch 5611/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0146 - val_loss: 0.6233\n",
      "Epoch 5612/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0202 - val_loss: 0.6103\n",
      "Epoch 5613/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0229 - val_loss: 0.6231\n",
      "Epoch 5614/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0393 - val_loss: 0.6472\n",
      "Epoch 5615/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0279 - val_loss: 0.6286\n",
      "Epoch 5616/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0189 - val_loss: 0.6136\n",
      "Epoch 5617/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0214 - val_loss: 0.6029\n",
      "Epoch 5618/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0450 - val_loss: 0.6335\n",
      "Epoch 5619/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0216 - val_loss: 0.6183\n",
      "Epoch 5620/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0180 - val_loss: 0.6193\n",
      "Epoch 5621/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0131 - val_loss: 0.6278\n",
      "Epoch 5622/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0109 - val_loss: 0.6261\n",
      "Epoch 5623/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0113 - val_loss: 0.6165\n",
      "Epoch 5624/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0124 - val_loss: 0.6292\n",
      "Epoch 5625/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0195 - val_loss: 0.6353\n",
      "Epoch 5626/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0409 - val_loss: 0.6106\n",
      "Epoch 5627/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 743us/step - loss: 0.0531 - val_loss: 0.6605\n",
      "Epoch 5628/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0398 - val_loss: 0.6002\n",
      "Epoch 5629/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0305 - val_loss: 0.6309\n",
      "Epoch 5630/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0235 - val_loss: 0.6077\n",
      "Epoch 5631/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0115 - val_loss: 0.6050\n",
      "Epoch 5632/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0117 - val_loss: 0.6210\n",
      "Epoch 5633/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0178 - val_loss: 0.6161\n",
      "Epoch 5634/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0237 - val_loss: 0.6200\n",
      "Epoch 5635/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0161 - val_loss: 0.6231\n",
      "Epoch 5636/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0162 - val_loss: 0.6000\n",
      "Epoch 5637/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0390 - val_loss: 0.6144\n",
      "Epoch 5638/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0227 - val_loss: 0.6288\n",
      "Epoch 5639/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0149 - val_loss: 0.6351\n",
      "Epoch 5640/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0285 - val_loss: 0.5917\n",
      "Epoch 5641/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0217 - val_loss: 0.6111\n",
      "Epoch 5642/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0356 - val_loss: 0.6634\n",
      "Epoch 5643/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0277 - val_loss: 0.6137\n",
      "Epoch 5644/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0195 - val_loss: 0.6203\n",
      "Epoch 5645/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0289 - val_loss: 0.6045\n",
      "Epoch 5646/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0430 - val_loss: 0.6441\n",
      "Epoch 5647/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0519 - val_loss: 0.6247\n",
      "Epoch 5648/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0262 - val_loss: 0.6179\n",
      "Epoch 5649/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0163 - val_loss: 0.6306\n",
      "Epoch 5650/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0140 - val_loss: 0.6288\n",
      "Epoch 5651/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0130 - val_loss: 0.6353\n",
      "Epoch 5652/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0138 - val_loss: 0.6254\n",
      "Epoch 5653/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0320 - val_loss: 0.6269\n",
      "Epoch 5654/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0407 - val_loss: 0.6388\n",
      "Epoch 5655/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0523 - val_loss: 0.6263\n",
      "Epoch 5656/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0227 - val_loss: 0.6170\n",
      "Epoch 5657/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0193 - val_loss: 0.5941\n",
      "Epoch 5658/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0138 - val_loss: 0.6180\n",
      "Epoch 5659/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0145 - val_loss: 0.6047\n",
      "Epoch 5660/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0220 - val_loss: 0.5780\n",
      "Epoch 5661/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0137 - val_loss: 0.6304\n",
      "Epoch 5662/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0250 - val_loss: 0.6234\n",
      "Epoch 5663/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0369 - val_loss: 0.6499\n",
      "Epoch 5664/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0231 - val_loss: 0.6271\n",
      "Epoch 5665/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0215 - val_loss: 0.6325\n",
      "Epoch 5666/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0333 - val_loss: 0.6248\n",
      "Epoch 5667/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0358 - val_loss: 0.6067\n",
      "Epoch 5668/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0251 - val_loss: 0.6246\n",
      "Epoch 5669/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0187 - val_loss: 0.6230\n",
      "Epoch 5670/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0143 - val_loss: 0.6303\n",
      "Epoch 5671/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0160 - val_loss: 0.6329\n",
      "Epoch 5672/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0148 - val_loss: 0.6241\n",
      "Epoch 5673/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0256 - val_loss: 0.6220\n",
      "Epoch 5674/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0169 - val_loss: 0.6087\n",
      "Epoch 5675/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0250 - val_loss: 0.6152\n",
      "Epoch 5676/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0441 - val_loss: 0.6465\n",
      "Epoch 5677/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0401 - val_loss: 0.6470\n",
      "Epoch 5678/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0229 - val_loss: 0.5909\n",
      "Epoch 5679/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0146 - val_loss: 0.6056\n",
      "Epoch 5680/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0114 - val_loss: 0.5960\n",
      "Epoch 5681/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0175 - val_loss: 0.6249\n",
      "Epoch 5682/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0289 - val_loss: 0.6265\n",
      "Epoch 5683/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0157 - val_loss: 0.6306\n",
      "Epoch 5684/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0227 - val_loss: 0.6222\n",
      "Epoch 5685/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0339 - val_loss: 0.6005\n",
      "Epoch 5686/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0160 - val_loss: 0.6032\n",
      "Epoch 5687/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0195 - val_loss: 0.6288\n",
      "Epoch 5688/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0296 - val_loss: 0.6233\n",
      "Epoch 5689/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0306 - val_loss: 0.6459\n",
      "Epoch 5690/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0385 - val_loss: 0.6072\n",
      "Epoch 5691/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0194 - val_loss: 0.6068\n",
      "Epoch 5692/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0146 - val_loss: 0.6330\n",
      "Epoch 5693/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0194 - val_loss: 0.6364\n",
      "Epoch 5694/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0233 - val_loss: 0.6051\n",
      "Epoch 5695/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0248 - val_loss: 0.6154\n",
      "Epoch 5696/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0141 - val_loss: 0.6215\n",
      "Epoch 5697/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0153 - val_loss: 0.6327\n",
      "Epoch 5698/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0235 - val_loss: 0.6063\n",
      "Epoch 5699/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0655 - val_loss: 0.6295\n",
      "Epoch 5700/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0553 - val_loss: 0.6144\n",
      "Epoch 5701/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0199 - val_loss: 0.6410\n",
      "Epoch 5702/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0153 - val_loss: 0.6312\n",
      "Epoch 5703/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 727us/step - loss: 0.0168 - val_loss: 0.6212\n",
      "Epoch 5704/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0138 - val_loss: 0.6383\n",
      "Epoch 5705/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0211 - val_loss: 0.6577\n",
      "Epoch 5706/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0287 - val_loss: 0.6102\n",
      "Epoch 5707/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0342 - val_loss: 0.6418\n",
      "Epoch 5708/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0454 - val_loss: 0.6074\n",
      "Epoch 5709/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0318 - val_loss: 0.6088\n",
      "Epoch 5710/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0220 - val_loss: 0.6217\n",
      "Epoch 5711/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0144 - val_loss: 0.6067\n",
      "Epoch 5712/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0096 - val_loss: 0.6118\n",
      "Epoch 5713/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0148 - val_loss: 0.6042\n",
      "Epoch 5714/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0191 - val_loss: 0.6195\n",
      "Epoch 5715/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0219 - val_loss: 0.6094\n",
      "Epoch 5716/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0268 - val_loss: 0.6425\n",
      "Epoch 5717/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0251 - val_loss: 0.6258\n",
      "Epoch 5718/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0310 - val_loss: 0.6141\n",
      "Epoch 5719/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0428 - val_loss: 0.5963\n",
      "Epoch 5720/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0429 - val_loss: 0.6352\n",
      "Epoch 5721/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0258 - val_loss: 0.6259\n",
      "Epoch 5722/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0208 - val_loss: 0.6037\n",
      "Epoch 5723/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0144 - val_loss: 0.6223\n",
      "Epoch 5724/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0140 - val_loss: 0.6279\n",
      "Epoch 5725/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0108 - val_loss: 0.6038\n",
      "Epoch 5726/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0116 - val_loss: 0.6291\n",
      "Epoch 5727/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0106 - val_loss: 0.5958\n",
      "Epoch 5728/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0130 - val_loss: 0.6229\n",
      "Epoch 5729/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0227 - val_loss: 0.6026\n",
      "Epoch 5730/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0428 - val_loss: 0.6220\n",
      "Epoch 5731/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0575 - val_loss: 0.6195\n",
      "Epoch 5732/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0395 - val_loss: 0.6366\n",
      "Epoch 5733/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0355 - val_loss: 0.6228\n",
      "Epoch 5734/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0280 - val_loss: 0.6378\n",
      "Epoch 5735/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0279 - val_loss: 0.6359\n",
      "Epoch 5736/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0161 - val_loss: 0.6277\n",
      "Epoch 5737/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0178 - val_loss: 0.6353\n",
      "Epoch 5738/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0227 - val_loss: 0.6362\n",
      "Epoch 5739/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0225 - val_loss: 0.5964\n",
      "Epoch 5740/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0124 - val_loss: 0.6187\n",
      "Epoch 5741/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0138 - val_loss: 0.6169\n",
      "Epoch 5742/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0147 - val_loss: 0.6200\n",
      "Epoch 5743/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0146 - val_loss: 0.6258\n",
      "Epoch 5744/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0227 - val_loss: 0.6248\n",
      "Epoch 5745/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0270 - val_loss: 0.6081\n",
      "Epoch 5746/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0304 - val_loss: 0.6351\n",
      "Epoch 5747/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0332 - val_loss: 0.6115\n",
      "Epoch 5748/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0254 - val_loss: 0.6367\n",
      "Epoch 5749/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0174 - val_loss: 0.6064\n",
      "Epoch 5750/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0184 - val_loss: 0.6461\n",
      "Epoch 5751/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0244 - val_loss: 0.6117\n",
      "Epoch 5752/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0243 - val_loss: 0.6425\n",
      "Epoch 5753/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0208 - val_loss: 0.6453\n",
      "Epoch 5754/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0294 - val_loss: 0.6494\n",
      "Epoch 5755/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0381 - val_loss: 0.6235\n",
      "Epoch 5756/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0470 - val_loss: 0.6233\n",
      "Epoch 5757/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0473 - val_loss: 0.6045\n",
      "Epoch 5758/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0304 - val_loss: 0.6173\n",
      "Epoch 5759/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0259 - val_loss: 0.6088\n",
      "Epoch 5760/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0136 - val_loss: 0.6176\n",
      "Epoch 5761/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0113 - val_loss: 0.6221\n",
      "Epoch 5762/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0079 - val_loss: 0.6232\n",
      "Epoch 5763/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0142 - val_loss: 0.6095\n",
      "Epoch 5764/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0340 - val_loss: 0.6507\n",
      "Epoch 5765/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0409 - val_loss: 0.6229\n",
      "Epoch 5766/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0201 - val_loss: 0.6196\n",
      "Epoch 5767/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0158 - val_loss: 0.5997\n",
      "Epoch 5768/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0205 - val_loss: 0.6274\n",
      "Epoch 5769/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0314 - val_loss: 0.6191\n",
      "Epoch 5770/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0353 - val_loss: 0.6286\n",
      "Epoch 5771/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0235 - val_loss: 0.6115\n",
      "Epoch 5772/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0167 - val_loss: 0.6022\n",
      "Epoch 5773/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0227 - val_loss: 0.6275\n",
      "Epoch 5774/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0258 - val_loss: 0.6072\n",
      "Epoch 5775/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0342 - val_loss: 0.5986\n",
      "Epoch 5776/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0266 - val_loss: 0.6002\n",
      "Epoch 5777/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0302 - val_loss: 0.6142\n",
      "Epoch 5778/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0284 - val_loss: 0.6197\n",
      "Epoch 5779/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 734us/step - loss: 0.0221 - val_loss: 0.6101\n",
      "Epoch 5780/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0237 - val_loss: 0.6222\n",
      "Epoch 5781/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0181 - val_loss: 0.6169\n",
      "Epoch 5782/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0167 - val_loss: 0.6210\n",
      "Epoch 5783/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0212 - val_loss: 0.6092\n",
      "Epoch 5784/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0216 - val_loss: 0.6046\n",
      "Epoch 5785/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0151 - val_loss: 0.6046\n",
      "Epoch 5786/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0144 - val_loss: 0.6085\n",
      "Epoch 5787/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0137 - val_loss: 0.6168\n",
      "Epoch 5788/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0202 - val_loss: 0.6263\n",
      "Epoch 5789/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0263 - val_loss: 0.6188\n",
      "Epoch 5790/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0288 - val_loss: 0.6242\n",
      "Epoch 5791/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0358 - val_loss: 0.6216\n",
      "Epoch 5792/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0474 - val_loss: 0.6047\n",
      "Epoch 5793/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0341 - val_loss: 0.6103\n",
      "Epoch 5794/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0278 - val_loss: 0.6144\n",
      "Epoch 5795/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0203 - val_loss: 0.6158\n",
      "Epoch 5796/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0191 - val_loss: 0.6162\n",
      "Epoch 5797/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0140 - val_loss: 0.6191\n",
      "Epoch 5798/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0136 - val_loss: 0.6108\n",
      "Epoch 5799/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0192 - val_loss: 0.5975\n",
      "Epoch 5800/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0295 - val_loss: 0.6132\n",
      "Epoch 5801/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0379 - val_loss: 0.6133\n",
      "Epoch 5802/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0269 - val_loss: 0.6355\n",
      "Epoch 5803/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0143 - val_loss: 0.6143\n",
      "Epoch 5804/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0311 - val_loss: 0.5726\n",
      "Epoch 5805/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0359 - val_loss: 0.6232\n",
      "Epoch 5806/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0355 - val_loss: 0.6436\n",
      "Epoch 5807/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0355 - val_loss: 0.6051\n",
      "Epoch 5808/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0283 - val_loss: 0.6037\n",
      "Epoch 5809/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0202 - val_loss: 0.6174\n",
      "Epoch 5810/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0166 - val_loss: 0.6166\n",
      "Epoch 5811/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0177 - val_loss: 0.6233\n",
      "Epoch 5812/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0162 - val_loss: 0.6165\n",
      "Epoch 5813/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0116 - val_loss: 0.6112\n",
      "Epoch 5814/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0121 - val_loss: 0.6025\n",
      "Epoch 5815/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0155 - val_loss: 0.6068\n",
      "Epoch 5816/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0325 - val_loss: 0.6299\n",
      "Epoch 5817/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0526 - val_loss: 0.6010\n",
      "Epoch 5818/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0438 - val_loss: 0.6493\n",
      "Epoch 5819/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0303 - val_loss: 0.6142\n",
      "Epoch 5820/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0216 - val_loss: 0.6254\n",
      "Epoch 5821/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0169 - val_loss: 0.6119\n",
      "Epoch 5822/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0201 - val_loss: 0.6197\n",
      "Epoch 5823/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0199 - val_loss: 0.6186\n",
      "Epoch 5824/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0179 - val_loss: 0.6097\n",
      "Epoch 5825/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0133 - val_loss: 0.6289\n",
      "Epoch 5826/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0203 - val_loss: 0.6090\n",
      "Epoch 5827/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0242 - val_loss: 0.6146\n",
      "Epoch 5828/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0189 - val_loss: 0.6011\n",
      "Epoch 5829/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0228 - val_loss: 0.6522\n",
      "Epoch 5830/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0248 - val_loss: 0.6570\n",
      "Epoch 5831/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0248 - val_loss: 0.6251\n",
      "Epoch 5832/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0496 - val_loss: 0.6508\n",
      "Epoch 5833/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0348 - val_loss: 0.6273\n",
      "Epoch 5834/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0151 - val_loss: 0.6251\n",
      "Epoch 5835/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0182 - val_loss: 0.5984\n",
      "Epoch 5836/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0174 - val_loss: 0.6053\n",
      "Epoch 5837/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0165 - val_loss: 0.6047\n",
      "Epoch 5838/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0591 - val_loss: 0.6435\n",
      "Epoch 5839/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0464 - val_loss: 0.6074\n",
      "Epoch 5840/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0257 - val_loss: 0.6350\n",
      "Epoch 5841/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0269 - val_loss: 0.5723\n",
      "Epoch 5842/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0183 - val_loss: 0.6270\n",
      "Epoch 5843/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0135 - val_loss: 0.6224\n",
      "Epoch 5844/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0133 - val_loss: 0.6258\n",
      "Epoch 5845/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0097 - val_loss: 0.6515\n",
      "Epoch 5846/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0136 - val_loss: 0.6275\n",
      "Epoch 5847/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0182 - val_loss: 0.5882\n",
      "Epoch 5848/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0148 - val_loss: 0.6276\n",
      "Epoch 5849/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0254 - val_loss: 0.6396\n",
      "Epoch 5850/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0368 - val_loss: 0.6048\n",
      "Epoch 5851/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0435 - val_loss: 0.6222\n",
      "Epoch 5852/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0380 - val_loss: 0.5780\n",
      "Epoch 5853/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0266 - val_loss: 0.6292\n",
      "Epoch 5854/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0452 - val_loss: 0.6213\n",
      "Epoch 5855/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 744us/step - loss: 0.0263 - val_loss: 0.6202\n",
      "Epoch 5856/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0241 - val_loss: 0.6067\n",
      "Epoch 5857/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0175 - val_loss: 0.5876\n",
      "Epoch 5858/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0205 - val_loss: 0.6079\n",
      "Epoch 5859/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0172 - val_loss: 0.6108\n",
      "Epoch 5860/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0158 - val_loss: 0.6314\n",
      "Epoch 5861/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0111 - val_loss: 0.6271\n",
      "Epoch 5862/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0131 - val_loss: 0.6157\n",
      "Epoch 5863/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0105 - val_loss: 0.6228\n",
      "Epoch 5864/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0095 - val_loss: 0.6175\n",
      "Epoch 5865/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0127 - val_loss: 0.6195\n",
      "Epoch 5866/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0348 - val_loss: 0.6127\n",
      "Epoch 5867/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0833 - val_loss: 0.6297\n",
      "Epoch 5868/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0390 - val_loss: 0.6294\n",
      "Epoch 5869/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0234 - val_loss: 0.6024\n",
      "Epoch 5870/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0263 - val_loss: 0.6498\n",
      "Epoch 5871/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0209 - val_loss: 0.6057\n",
      "Epoch 5872/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0202 - val_loss: 0.6544\n",
      "Epoch 5873/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0161 - val_loss: 0.6103\n",
      "Epoch 5874/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0139 - val_loss: 0.6441\n",
      "Epoch 5875/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0150 - val_loss: 0.6388\n",
      "Epoch 5876/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0347 - val_loss: 0.6396\n",
      "Epoch 5877/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0633 - val_loss: 0.6341\n",
      "Epoch 5878/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0442 - val_loss: 0.6352\n",
      "Epoch 5879/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0189 - val_loss: 0.6131\n",
      "Epoch 5880/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0233 - val_loss: 0.6454\n",
      "Epoch 5881/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0170 - val_loss: 0.6293\n",
      "Epoch 5882/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0230 - val_loss: 0.6639\n",
      "Epoch 5883/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0347 - val_loss: 0.6440\n",
      "Epoch 5884/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0160 - val_loss: 0.6294\n",
      "Epoch 5885/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0147 - val_loss: 0.6214\n",
      "Epoch 5886/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0130 - val_loss: 0.6380\n",
      "Epoch 5887/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0152 - val_loss: 0.5979\n",
      "Epoch 5888/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0204 - val_loss: 0.6323\n",
      "Epoch 5889/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0209 - val_loss: 0.6375\n",
      "Epoch 5890/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0171 - val_loss: 0.6390\n",
      "Epoch 5891/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0137 - val_loss: 0.6370\n",
      "Epoch 5892/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0291 - val_loss: 0.6083\n",
      "Epoch 5893/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0759 - val_loss: 0.6512\n",
      "Epoch 5894/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0533 - val_loss: 0.5898\n",
      "Epoch 5895/10000\n",
      "130/130 [==============================] - 0s 835us/step - loss: 0.0250 - val_loss: 0.6342\n",
      "Epoch 5896/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0168 - val_loss: 0.5948\n",
      "Epoch 5897/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0143 - val_loss: 0.6147\n",
      "Epoch 5898/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0147 - val_loss: 0.6127\n",
      "Epoch 5899/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0115 - val_loss: 0.5970\n",
      "Epoch 5900/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0216 - val_loss: 0.6294\n",
      "Epoch 5901/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0293 - val_loss: 0.6049\n",
      "Epoch 5902/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0409 - val_loss: 0.6250\n",
      "Epoch 5903/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0414 - val_loss: 0.6401\n",
      "Epoch 5904/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0240 - val_loss: 0.5988\n",
      "Epoch 5905/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0206 - val_loss: 0.6220\n",
      "Epoch 5906/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0154 - val_loss: 0.6139\n",
      "Epoch 5907/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0146 - val_loss: 0.6167\n",
      "Epoch 5908/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0105 - val_loss: 0.6031\n",
      "Epoch 5909/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0133 - val_loss: 0.6102\n",
      "Epoch 5910/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0209 - val_loss: 0.6182\n",
      "Epoch 5911/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0334 - val_loss: 0.5923\n",
      "Epoch 5912/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0264 - val_loss: 0.6291\n",
      "Epoch 5913/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0274 - val_loss: 0.6029\n",
      "Epoch 5914/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0149 - val_loss: 0.5925\n",
      "Epoch 5915/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0136 - val_loss: 0.6115\n",
      "Epoch 5916/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0251 - val_loss: 0.5885\n",
      "Epoch 5917/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0259 - val_loss: 0.6312\n",
      "Epoch 5918/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0298 - val_loss: 0.6500\n",
      "Epoch 5919/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0301 - val_loss: 0.6212\n",
      "Epoch 5920/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0275 - val_loss: 0.6152\n",
      "Epoch 5921/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0249 - val_loss: 0.5875\n",
      "Epoch 5922/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0266 - val_loss: 0.6025\n",
      "Epoch 5923/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0301 - val_loss: 0.5987\n",
      "Epoch 5924/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0146 - val_loss: 0.6154\n",
      "Epoch 5925/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0145 - val_loss: 0.6282\n",
      "Epoch 5926/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0271 - val_loss: 0.5900\n",
      "Epoch 5927/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0255 - val_loss: 0.5907\n",
      "Epoch 5928/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0214 - val_loss: 0.6030\n",
      "Epoch 5929/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0529 - val_loss: 0.6320\n",
      "Epoch 5930/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0313 - val_loss: 0.6083\n",
      "Epoch 5931/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 754us/step - loss: 0.0177 - val_loss: 0.5951\n",
      "Epoch 5932/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0288 - val_loss: 0.6134\n",
      "Epoch 5933/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0175 - val_loss: 0.6141\n",
      "Epoch 5934/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0202 - val_loss: 0.6286\n",
      "Epoch 5935/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0190 - val_loss: 0.6184\n",
      "Epoch 5936/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0240 - val_loss: 0.6303\n",
      "Epoch 5937/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0305 - val_loss: 0.6120\n",
      "Epoch 5938/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0500 - val_loss: 0.5984\n",
      "Epoch 5939/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0412 - val_loss: 0.6188\n",
      "Epoch 5940/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0170 - val_loss: 0.6050\n",
      "Epoch 5941/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0113 - val_loss: 0.6112\n",
      "Epoch 5942/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0121 - val_loss: 0.6079\n",
      "Epoch 5943/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0245 - val_loss: 0.6401\n",
      "Epoch 5944/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0368 - val_loss: 0.6069\n",
      "Epoch 5945/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0328 - val_loss: 0.6141\n",
      "Epoch 5946/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0247 - val_loss: 0.6064\n",
      "Epoch 5947/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0289 - val_loss: 0.6135\n",
      "Epoch 5948/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0345 - val_loss: 0.5980\n",
      "Epoch 5949/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0208 - val_loss: 0.6193\n",
      "Epoch 5950/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0165 - val_loss: 0.6093\n",
      "Epoch 5951/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0147 - val_loss: 0.5953\n",
      "Epoch 5952/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0108 - val_loss: 0.5954\n",
      "Epoch 5953/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0098 - val_loss: 0.6097\n",
      "Epoch 5954/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0148 - val_loss: 0.5985\n",
      "Epoch 5955/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0358 - val_loss: 0.6396\n",
      "Epoch 5956/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0461 - val_loss: 0.6063\n",
      "Epoch 5957/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0634 - val_loss: 0.6350\n",
      "Epoch 5958/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0238 - val_loss: 0.6270\n",
      "Epoch 5959/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0235 - val_loss: 0.6233\n",
      "Epoch 5960/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0229 - val_loss: 0.6226\n",
      "Epoch 5961/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0169 - val_loss: 0.6021\n",
      "Epoch 5962/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0120 - val_loss: 0.5949\n",
      "Epoch 5963/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0089 - val_loss: 0.5991\n",
      "Epoch 5964/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0092 - val_loss: 0.6133\n",
      "Epoch 5965/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0103 - val_loss: 0.6097\n",
      "Epoch 5966/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0211 - val_loss: 0.6198\n",
      "Epoch 5967/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0410 - val_loss: 0.6353\n",
      "Epoch 5968/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1081 - val_loss: 0.6130\n",
      "Epoch 5969/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0870 - val_loss: 0.5804\n",
      "Epoch 5970/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0466 - val_loss: 0.6160\n",
      "Epoch 5971/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0192 - val_loss: 0.5976\n",
      "Epoch 5972/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0133 - val_loss: 0.6059\n",
      "Epoch 5973/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0108 - val_loss: 0.6070\n",
      "Epoch 5974/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0176 - val_loss: 0.6165\n",
      "Epoch 5975/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0135 - val_loss: 0.5904\n",
      "Epoch 5976/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0111 - val_loss: 0.6004\n",
      "Epoch 5977/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0179 - val_loss: 0.6046\n",
      "Epoch 5978/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0290 - val_loss: 0.6112\n",
      "Epoch 5979/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0273 - val_loss: 0.6012\n",
      "Epoch 5980/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0136 - val_loss: 0.6167\n",
      "Epoch 5981/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0152 - val_loss: 0.6246\n",
      "Epoch 5982/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0490 - val_loss: 0.6232\n",
      "Epoch 5983/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0304 - val_loss: 0.6060\n",
      "Epoch 5984/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0159 - val_loss: 0.6205\n",
      "Epoch 5985/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0126 - val_loss: 0.6193\n",
      "Epoch 5986/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0111 - val_loss: 0.6207\n",
      "Epoch 5987/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0106 - val_loss: 0.6201\n",
      "Epoch 5988/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0222 - val_loss: 0.5986\n",
      "Epoch 5989/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0327 - val_loss: 0.6255\n",
      "Epoch 5990/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0363 - val_loss: 0.6263\n",
      "Epoch 5991/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0524 - val_loss: 0.6216\n",
      "Epoch 5992/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0444 - val_loss: 0.6276\n",
      "Epoch 5993/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0310 - val_loss: 0.6152\n",
      "Epoch 5994/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0158 - val_loss: 0.6047\n",
      "Epoch 5995/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0146 - val_loss: 0.6177\n",
      "Epoch 5996/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0117 - val_loss: 0.6057\n",
      "Epoch 5997/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0134 - val_loss: 0.6060\n",
      "Epoch 5998/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0191 - val_loss: 0.6242\n",
      "Epoch 5999/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0362 - val_loss: 0.6022\n",
      "Epoch 6000/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0356 - val_loss: 0.6159\n",
      "Epoch 6001/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0269 - val_loss: 0.6151\n",
      "Epoch 6002/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0209 - val_loss: 0.5812\n",
      "Epoch 6003/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0234 - val_loss: 0.6058\n",
      "Epoch 6004/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0333 - val_loss: 0.6506\n",
      "Epoch 6005/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0177 - val_loss: 0.6261\n",
      "Epoch 6006/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0231 - val_loss: 0.6118\n",
      "Epoch 6007/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 755us/step - loss: 0.0219 - val_loss: 0.6166\n",
      "Epoch 6008/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0229 - val_loss: 0.6176\n",
      "Epoch 6009/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0266 - val_loss: 0.6100\n",
      "Epoch 6010/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0229 - val_loss: 0.6266\n",
      "Epoch 6011/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0218 - val_loss: 0.6490\n",
      "Epoch 6012/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0255 - val_loss: 0.6080\n",
      "Epoch 6013/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0243 - val_loss: 0.6159\n",
      "Epoch 6014/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0256 - val_loss: 0.6184\n",
      "Epoch 6015/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0386 - val_loss: 0.6337\n",
      "Epoch 6016/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0402 - val_loss: 0.6284\n",
      "Epoch 6017/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0308 - val_loss: 0.6227\n",
      "Epoch 6018/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0311 - val_loss: 0.6102\n",
      "Epoch 6019/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0257 - val_loss: 0.6413\n",
      "Epoch 6020/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0261 - val_loss: 0.6097\n",
      "Epoch 6021/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0140 - val_loss: 0.6083\n",
      "Epoch 6022/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0093 - val_loss: 0.6015\n",
      "Epoch 6023/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0132 - val_loss: 0.5950\n",
      "Epoch 6024/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0161 - val_loss: 0.6126\n",
      "Epoch 6025/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0183 - val_loss: 0.5863\n",
      "Epoch 6026/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0332 - val_loss: 0.6125\n",
      "Epoch 6027/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0326 - val_loss: 0.6031\n",
      "Epoch 6028/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0345 - val_loss: 0.6261\n",
      "Epoch 6029/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0354 - val_loss: 0.6315\n",
      "Epoch 6030/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0195 - val_loss: 0.6279\n",
      "Epoch 6031/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0195 - val_loss: 0.6173\n",
      "Epoch 6032/10000\n",
      "130/130 [==============================] - 0s 796us/step - loss: 0.0177 - val_loss: 0.6187\n",
      "Epoch 6033/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0132 - val_loss: 0.6304\n",
      "Epoch 6034/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0208 - val_loss: 0.6261\n",
      "Epoch 6035/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0247 - val_loss: 0.6179\n",
      "Epoch 6036/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0540 - val_loss: 0.6505\n",
      "Epoch 6037/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0513 - val_loss: 0.6218\n",
      "Epoch 6038/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0240 - val_loss: 0.6133\n",
      "Epoch 6039/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0205 - val_loss: 0.6007\n",
      "Epoch 6040/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0232 - val_loss: 0.6143\n",
      "Epoch 6041/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0339 - val_loss: 0.6248\n",
      "Epoch 6042/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0334 - val_loss: 0.6187\n",
      "Epoch 6043/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0130 - val_loss: 0.6128\n",
      "Epoch 6044/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0169 - val_loss: 0.6197\n",
      "Epoch 6045/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0168 - val_loss: 0.6176\n",
      "Epoch 6046/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0142 - val_loss: 0.6020\n",
      "Epoch 6047/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0361 - val_loss: 0.6169\n",
      "Epoch 6048/10000\n",
      "130/130 [==============================] - 0s 819us/step - loss: 0.0235 - val_loss: 0.5977\n",
      "Epoch 6049/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0184 - val_loss: 0.6234\n",
      "Epoch 6050/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0203 - val_loss: 0.5994\n",
      "Epoch 6051/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0304 - val_loss: 0.6323\n",
      "Epoch 6052/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0241 - val_loss: 0.6275\n",
      "Epoch 6053/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0452 - val_loss: 0.6289\n",
      "Epoch 6054/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0287 - val_loss: 0.6355\n",
      "Epoch 6055/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0400 - val_loss: 0.6508\n",
      "Epoch 6056/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0263 - val_loss: 0.6116\n",
      "Epoch 6057/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0178 - val_loss: 0.5978\n",
      "Epoch 6058/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0146 - val_loss: 0.6495\n",
      "Epoch 6059/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0138 - val_loss: 0.6185\n",
      "Epoch 6060/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0118 - val_loss: 0.6075\n",
      "Epoch 6061/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0090 - val_loss: 0.5923\n",
      "Epoch 6062/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0135 - val_loss: 0.5931\n",
      "Epoch 6063/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0141 - val_loss: 0.6118\n",
      "Epoch 6064/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0209 - val_loss: 0.6350\n",
      "Epoch 6065/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0728 - val_loss: 0.6204\n",
      "Epoch 6066/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0418 - val_loss: 0.6069\n",
      "Epoch 6067/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0223 - val_loss: 0.6145\n",
      "Epoch 6068/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0189 - val_loss: 0.6350\n",
      "Epoch 6069/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0147 - val_loss: 0.6465\n",
      "Epoch 6070/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0282 - val_loss: 0.5971\n",
      "Epoch 6071/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0340 - val_loss: 0.6096\n",
      "Epoch 6072/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0295 - val_loss: 0.6019\n",
      "Epoch 6073/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0216 - val_loss: 0.5919\n",
      "Epoch 6074/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0130 - val_loss: 0.6044\n",
      "Epoch 6075/10000\n",
      "130/130 [==============================] - 0s 853us/step - loss: 0.0104 - val_loss: 0.5984\n",
      "Epoch 6076/10000\n",
      "130/130 [==============================] - 0s 805us/step - loss: 0.0104 - val_loss: 0.5913\n",
      "Epoch 6077/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0294 - val_loss: 0.6123\n",
      "Epoch 6078/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0480 - val_loss: 0.6313\n",
      "Epoch 6079/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0299 - val_loss: 0.5972\n",
      "Epoch 6080/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0192 - val_loss: 0.6051\n",
      "Epoch 6081/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0164 - val_loss: 0.6077\n",
      "Epoch 6082/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0177 - val_loss: 0.6042\n",
      "Epoch 6083/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 749us/step - loss: 0.0309 - val_loss: 0.6150\n",
      "Epoch 6084/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0213 - val_loss: 0.6012\n",
      "Epoch 6085/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0151 - val_loss: 0.6174\n",
      "Epoch 6086/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0175 - val_loss: 0.6095\n",
      "Epoch 6087/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0157 - val_loss: 0.6191\n",
      "Epoch 6088/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0263 - val_loss: 0.6029\n",
      "Epoch 6089/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0221 - val_loss: 0.6324\n",
      "Epoch 6090/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0423 - val_loss: 0.6157\n",
      "Epoch 6091/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0453 - val_loss: 0.6423\n",
      "Epoch 6092/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0622 - val_loss: 0.5978\n",
      "Epoch 6093/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0235 - val_loss: 0.6118\n",
      "Epoch 6094/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0146 - val_loss: 0.6129\n",
      "Epoch 6095/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0159 - val_loss: 0.6250\n",
      "Epoch 6096/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0150 - val_loss: 0.5936\n",
      "Epoch 6097/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0156 - val_loss: 0.5932\n",
      "Epoch 6098/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0225 - val_loss: 0.6201\n",
      "Epoch 6099/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0286 - val_loss: 0.5984\n",
      "Epoch 6100/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0231 - val_loss: 0.5952\n",
      "Epoch 6101/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0134 - val_loss: 0.6024\n",
      "Epoch 6102/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0213 - val_loss: 0.6265\n",
      "Epoch 6103/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0410 - val_loss: 0.6104\n",
      "Epoch 6104/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0297 - val_loss: 0.6123\n",
      "Epoch 6105/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0258 - val_loss: 0.6034\n",
      "Epoch 6106/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0158 - val_loss: 0.6268\n",
      "Epoch 6107/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0168 - val_loss: 0.6365\n",
      "Epoch 6108/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0209 - val_loss: 0.6081\n",
      "Epoch 6109/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0328 - val_loss: 0.6174\n",
      "Epoch 6110/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0365 - val_loss: 0.6016\n",
      "Epoch 6111/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0230 - val_loss: 0.6131\n",
      "Epoch 6112/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0195 - val_loss: 0.6136\n",
      "Epoch 6113/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0293 - val_loss: 0.5914\n",
      "Epoch 6114/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0306 - val_loss: 0.6263\n",
      "Epoch 6115/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0201 - val_loss: 0.6130\n",
      "Epoch 6116/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0178 - val_loss: 0.6472\n",
      "Epoch 6117/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0116 - val_loss: 0.6454\n",
      "Epoch 6118/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0176 - val_loss: 0.6072\n",
      "Epoch 6119/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0229 - val_loss: 0.6080\n",
      "Epoch 6120/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0277 - val_loss: 0.6301\n",
      "Epoch 6121/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0277 - val_loss: 0.6078\n",
      "Epoch 6122/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0190 - val_loss: 0.6269\n",
      "Epoch 6123/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0250 - val_loss: 0.6199\n",
      "Epoch 6124/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0295 - val_loss: 0.6216\n",
      "Epoch 6125/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0354 - val_loss: 0.6205\n",
      "Epoch 6126/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0335 - val_loss: 0.6123\n",
      "Epoch 6127/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0177 - val_loss: 0.6370\n",
      "Epoch 6128/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0223 - val_loss: 0.5954\n",
      "Epoch 6129/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0261 - val_loss: 0.6395\n",
      "Epoch 6130/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0284 - val_loss: 0.6215\n",
      "Epoch 6131/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0274 - val_loss: 0.6171\n",
      "Epoch 6132/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0237 - val_loss: 0.6155\n",
      "Epoch 6133/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0163 - val_loss: 0.6202\n",
      "Epoch 6134/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0118 - val_loss: 0.6469\n",
      "Epoch 6135/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0107 - val_loss: 0.6066\n",
      "Epoch 6136/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0149 - val_loss: 0.6367\n",
      "Epoch 6137/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0256 - val_loss: 0.6337\n",
      "Epoch 6138/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0567 - val_loss: 0.6410\n",
      "Epoch 6139/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0727 - val_loss: 0.6681\n",
      "Epoch 6140/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0652 - val_loss: 0.6416\n",
      "Epoch 6141/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0411 - val_loss: 0.6103\n",
      "Epoch 6142/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0273 - val_loss: 0.6207\n",
      "Epoch 6143/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0164 - val_loss: 0.6045\n",
      "Epoch 6144/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0157 - val_loss: 0.5908\n",
      "Epoch 6145/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0184 - val_loss: 0.6109\n",
      "Epoch 6146/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0121 - val_loss: 0.6011\n",
      "Epoch 6147/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0118 - val_loss: 0.6042\n",
      "Epoch 6148/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0117 - val_loss: 0.5959\n",
      "Epoch 6149/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0185 - val_loss: 0.6111\n",
      "Epoch 6150/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0217 - val_loss: 0.6042\n",
      "Epoch 6151/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0278 - val_loss: 0.6196\n",
      "Epoch 6152/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0437 - val_loss: 0.6450\n",
      "Epoch 6153/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0312 - val_loss: 0.6119\n",
      "Epoch 6154/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0279 - val_loss: 0.6103\n",
      "Epoch 6155/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0189 - val_loss: 0.6126\n",
      "Epoch 6156/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0163 - val_loss: 0.6123\n",
      "Epoch 6157/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0218 - val_loss: 0.6172\n",
      "Epoch 6158/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0182 - val_loss: 0.6079\n",
      "Epoch 6159/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 759us/step - loss: 0.0224 - val_loss: 0.6388\n",
      "Epoch 6160/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0286 - val_loss: 0.6237\n",
      "Epoch 6161/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0320 - val_loss: 0.5791\n",
      "Epoch 6162/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0168 - val_loss: 0.6139\n",
      "Epoch 6163/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0093 - val_loss: 0.5990\n",
      "Epoch 6164/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0104 - val_loss: 0.6176\n",
      "Epoch 6165/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0126 - val_loss: 0.6522\n",
      "Epoch 6166/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0240 - val_loss: 0.5924\n",
      "Epoch 6167/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0618 - val_loss: 0.6897\n",
      "Epoch 6168/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0798 - val_loss: 0.6277\n",
      "Epoch 6169/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0332 - val_loss: 0.5950\n",
      "Epoch 6170/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0210 - val_loss: 0.6156\n",
      "Epoch 6171/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0198 - val_loss: 0.6203\n",
      "Epoch 6172/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0209 - val_loss: 0.6185\n",
      "Epoch 6173/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0155 - val_loss: 0.6175\n",
      "Epoch 6174/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0162 - val_loss: 0.5978\n",
      "Epoch 6175/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0202 - val_loss: 0.6044\n",
      "Epoch 6176/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0201 - val_loss: 0.5908\n",
      "Epoch 6177/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0235 - val_loss: 0.6095\n",
      "Epoch 6178/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0175 - val_loss: 0.6063\n",
      "Epoch 6179/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0148 - val_loss: 0.6071\n",
      "Epoch 6180/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0187 - val_loss: 0.6506\n",
      "Epoch 6181/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0163 - val_loss: 0.6102\n",
      "Epoch 6182/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0146 - val_loss: 0.6117\n",
      "Epoch 6183/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0340 - val_loss: 0.5858\n",
      "Epoch 6184/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0444 - val_loss: 0.6070\n",
      "Epoch 6185/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0495 - val_loss: 0.6348\n",
      "Epoch 6186/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0586 - val_loss: 0.6098\n",
      "Epoch 6187/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0360 - val_loss: 0.5951\n",
      "Epoch 6188/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0267 - val_loss: 0.5866\n",
      "Epoch 6189/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0307 - val_loss: 0.6140\n",
      "Epoch 6190/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0239 - val_loss: 0.6182\n",
      "Epoch 6191/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0154 - val_loss: 0.6358\n",
      "Epoch 6192/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0214 - val_loss: 0.6056\n",
      "Epoch 6193/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0292 - val_loss: 0.6489\n",
      "Epoch 6194/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0235 - val_loss: 0.6155\n",
      "Epoch 6195/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0300 - val_loss: 0.5948\n",
      "Epoch 6196/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0247 - val_loss: 0.6067\n",
      "Epoch 6197/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0277 - val_loss: 0.5914\n",
      "Epoch 6198/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0205 - val_loss: 0.6196\n",
      "Epoch 6199/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0187 - val_loss: 0.6088\n",
      "Epoch 6200/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0222 - val_loss: 0.6164\n",
      "Epoch 6201/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0155 - val_loss: 0.6065\n",
      "Epoch 6202/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0142 - val_loss: 0.6171\n",
      "Epoch 6203/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0147 - val_loss: 0.6188\n",
      "Epoch 6204/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0354 - val_loss: 0.6245\n",
      "Epoch 6205/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0190 - val_loss: 0.6224\n",
      "Epoch 6206/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0155 - val_loss: 0.5937\n",
      "Epoch 6207/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0293 - val_loss: 0.6314\n",
      "Epoch 6208/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0391 - val_loss: 0.6153\n",
      "Epoch 6209/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0412 - val_loss: 0.6268\n",
      "Epoch 6210/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0277 - val_loss: 0.6053\n",
      "Epoch 6211/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0294 - val_loss: 0.6267\n",
      "Epoch 6212/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0231 - val_loss: 0.5981\n",
      "Epoch 6213/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0294 - val_loss: 0.5881\n",
      "Epoch 6214/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0203 - val_loss: 0.5989\n",
      "Epoch 6215/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0159 - val_loss: 0.6100\n",
      "Epoch 6216/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0227 - val_loss: 0.6213\n",
      "Epoch 6217/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0141 - val_loss: 0.6092\n",
      "Epoch 6218/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0112 - val_loss: 0.6181\n",
      "Epoch 6219/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0154 - val_loss: 0.5942\n",
      "Epoch 6220/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0233 - val_loss: 0.6279\n",
      "Epoch 6221/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0424 - val_loss: 0.6211\n",
      "Epoch 6222/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0234 - val_loss: 0.6418\n",
      "Epoch 6223/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0244 - val_loss: 0.6127\n",
      "Epoch 6224/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0285 - val_loss: 0.6066\n",
      "Epoch 6225/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0210 - val_loss: 0.6237\n",
      "Epoch 6226/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0156 - val_loss: 0.6137\n",
      "Epoch 6227/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0224 - val_loss: 0.6214\n",
      "Epoch 6228/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0293 - val_loss: 0.6124\n",
      "Epoch 6229/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0319 - val_loss: 0.5899\n",
      "Epoch 6230/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0623 - val_loss: 0.6482\n",
      "Epoch 6231/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0211 - val_loss: 0.5924\n",
      "Epoch 6232/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0191 - val_loss: 0.6245\n",
      "Epoch 6233/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0211 - val_loss: 0.6128\n",
      "Epoch 6234/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0201 - val_loss: 0.6395\n",
      "Epoch 6235/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 749us/step - loss: 0.0174 - val_loss: 0.6177\n",
      "Epoch 6236/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0260 - val_loss: 0.6250\n",
      "Epoch 6237/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0360 - val_loss: 0.6238\n",
      "Epoch 6238/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0175 - val_loss: 0.6213\n",
      "Epoch 6239/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0139 - val_loss: 0.6293\n",
      "Epoch 6240/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0131 - val_loss: 0.5970\n",
      "Epoch 6241/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0118 - val_loss: 0.6183\n",
      "Epoch 6242/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0138 - val_loss: 0.6159\n",
      "Epoch 6243/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0207 - val_loss: 0.6256\n",
      "Epoch 6244/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0164 - val_loss: 0.6186\n",
      "Epoch 6245/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0379 - val_loss: 0.6076\n",
      "Epoch 6246/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0255 - val_loss: 0.6162\n",
      "Epoch 6247/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0221 - val_loss: 0.6095\n",
      "Epoch 6248/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0440 - val_loss: 0.6264\n",
      "Epoch 6249/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0416 - val_loss: 0.6355\n",
      "Epoch 6250/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0274 - val_loss: 0.6134\n",
      "Epoch 6251/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0318 - val_loss: 0.6591\n",
      "Epoch 6252/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0241 - val_loss: 0.6050\n",
      "Epoch 6253/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0174 - val_loss: 0.6382\n",
      "Epoch 6254/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0250 - val_loss: 0.6082\n",
      "Epoch 6255/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0344 - val_loss: 0.6335\n",
      "Epoch 6256/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0265 - val_loss: 0.6248\n",
      "Epoch 6257/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0379 - val_loss: 0.5781\n",
      "Epoch 6258/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0205 - val_loss: 0.6089\n",
      "Epoch 6259/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0194 - val_loss: 0.5870\n",
      "Epoch 6260/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0221 - val_loss: 0.6489\n",
      "Epoch 6261/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0231 - val_loss: 0.6278\n",
      "Epoch 6262/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0268 - val_loss: 0.6339\n",
      "Epoch 6263/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0183 - val_loss: 0.6241\n",
      "Epoch 6264/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0122 - val_loss: 0.6115\n",
      "Epoch 6265/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0163 - val_loss: 0.6237\n",
      "Epoch 6266/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0252 - val_loss: 0.6207\n",
      "Epoch 6267/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0274 - val_loss: 0.6306\n",
      "Epoch 6268/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0219 - val_loss: 0.6239\n",
      "Epoch 6269/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0223 - val_loss: 0.6265\n",
      "Epoch 6270/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0439 - val_loss: 0.5979\n",
      "Epoch 6271/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0354 - val_loss: 0.6782\n",
      "Epoch 6272/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0604 - val_loss: 0.6406\n",
      "Epoch 6273/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0176 - val_loss: 0.5998\n",
      "Epoch 6274/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0151 - val_loss: 0.5988\n",
      "Epoch 6275/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0182 - val_loss: 0.6073\n",
      "Epoch 6276/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0148 - val_loss: 0.6097\n",
      "Epoch 6277/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0273 - val_loss: 0.6157\n",
      "Epoch 6278/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0275 - val_loss: 0.6052\n",
      "Epoch 6279/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0305 - val_loss: 0.6221\n",
      "Epoch 6280/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0225 - val_loss: 0.6373\n",
      "Epoch 6281/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0228 - val_loss: 0.6268\n",
      "Epoch 6282/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0214 - val_loss: 0.6117\n",
      "Epoch 6283/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0249 - val_loss: 0.6312\n",
      "Epoch 6284/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0260 - val_loss: 0.6044\n",
      "Epoch 6285/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0179 - val_loss: 0.6152\n",
      "Epoch 6286/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0192 - val_loss: 0.6116\n",
      "Epoch 6287/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0150 - val_loss: 0.6093\n",
      "Epoch 6288/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0149 - val_loss: 0.6178\n",
      "Epoch 6289/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0173 - val_loss: 0.6124\n",
      "Epoch 6290/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0371 - val_loss: 0.6018\n",
      "Epoch 6291/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0324 - val_loss: 0.6109\n",
      "Epoch 6292/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0216 - val_loss: 0.6200\n",
      "Epoch 6293/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0205 - val_loss: 0.6218\n",
      "Epoch 6294/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0124 - val_loss: 0.6102\n",
      "Epoch 6295/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0150 - val_loss: 0.6057\n",
      "Epoch 6296/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0252 - val_loss: 0.5998\n",
      "Epoch 6297/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0287 - val_loss: 0.6371\n",
      "Epoch 6298/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0321 - val_loss: 0.6427\n",
      "Epoch 6299/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0329 - val_loss: 0.6102\n",
      "Epoch 6300/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0160 - val_loss: 0.6097\n",
      "Epoch 6301/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0173 - val_loss: 0.6348\n",
      "Epoch 6302/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0272 - val_loss: 0.6216\n",
      "Epoch 6303/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0643 - val_loss: 0.6046\n",
      "Epoch 6304/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0298 - val_loss: 0.5864\n",
      "Epoch 6305/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0258 - val_loss: 0.6175\n",
      "Epoch 6306/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0153 - val_loss: 0.5942\n",
      "Epoch 6307/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0248 - val_loss: 0.5494\n",
      "Epoch 6308/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0270 - val_loss: 0.5865\n",
      "Epoch 6309/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0372 - val_loss: 0.6385\n",
      "Epoch 6310/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0268 - val_loss: 0.6078\n",
      "Epoch 6311/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 747us/step - loss: 0.0165 - val_loss: 0.6043\n",
      "Epoch 6312/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0111 - val_loss: 0.6027\n",
      "Epoch 6313/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0118 - val_loss: 0.6254\n",
      "Epoch 6314/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0150 - val_loss: 0.6326\n",
      "Epoch 6315/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0310 - val_loss: 0.5957\n",
      "Epoch 6316/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0234 - val_loss: 0.6571\n",
      "Epoch 6317/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0327 - val_loss: 0.6016\n",
      "Epoch 6318/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0211 - val_loss: 0.5856\n",
      "Epoch 6319/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0295 - val_loss: 0.6300\n",
      "Epoch 6320/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0440 - val_loss: 0.6346\n",
      "Epoch 6321/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0327 - val_loss: 0.6364\n",
      "Epoch 6322/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0167 - val_loss: 0.6245\n",
      "Epoch 6323/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0125 - val_loss: 0.6250\n",
      "Epoch 6324/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0216 - val_loss: 0.6454\n",
      "Epoch 6325/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0225 - val_loss: 0.6255\n",
      "Epoch 6326/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0232 - val_loss: 0.6231\n",
      "Epoch 6327/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0178 - val_loss: 0.6469\n",
      "Epoch 6328/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0352 - val_loss: 0.6470\n",
      "Epoch 6329/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0628 - val_loss: 0.6066\n",
      "Epoch 6330/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0484 - val_loss: 0.6279\n",
      "Epoch 6331/10000\n",
      "130/130 [==============================] - 0s 819us/step - loss: 0.0198 - val_loss: 0.6090\n",
      "Epoch 6332/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0135 - val_loss: 0.6126\n",
      "Epoch 6333/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0164 - val_loss: 0.6130\n",
      "Epoch 6334/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0209 - val_loss: 0.6206\n",
      "Epoch 6335/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0275 - val_loss: 0.6194\n",
      "Epoch 6336/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0232 - val_loss: 0.6054\n",
      "Epoch 6337/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0129 - val_loss: 0.6142\n",
      "Epoch 6338/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0103 - val_loss: 0.6365\n",
      "Epoch 6339/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0099 - val_loss: 0.6330\n",
      "Epoch 6340/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0225 - val_loss: 0.6026\n",
      "Epoch 6341/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0351 - val_loss: 0.6340\n",
      "Epoch 6342/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0309 - val_loss: 0.6121\n",
      "Epoch 6343/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0493 - val_loss: 0.6273\n",
      "Epoch 6344/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0316 - val_loss: 0.6169\n",
      "Epoch 6345/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0215 - val_loss: 0.6088\n",
      "Epoch 6346/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0159 - val_loss: 0.6221\n",
      "Epoch 6347/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0131 - val_loss: 0.6068\n",
      "Epoch 6348/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0122 - val_loss: 0.6143\n",
      "Epoch 6349/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0122 - val_loss: 0.6002\n",
      "Epoch 6350/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0229 - val_loss: 0.6108\n",
      "Epoch 6351/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0289 - val_loss: 0.6216\n",
      "Epoch 6352/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0287 - val_loss: 0.6167\n",
      "Epoch 6353/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0288 - val_loss: 0.6335\n",
      "Epoch 6354/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0289 - val_loss: 0.6168\n",
      "Epoch 6355/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0250 - val_loss: 0.6365\n",
      "Epoch 6356/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0315 - val_loss: 0.6188\n",
      "Epoch 6357/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0333 - val_loss: 0.6300\n",
      "Epoch 6358/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0238 - val_loss: 0.6260\n",
      "Epoch 6359/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0218 - val_loss: 0.5959\n",
      "Epoch 6360/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0125 - val_loss: 0.6199\n",
      "Epoch 6361/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0132 - val_loss: 0.6357\n",
      "Epoch 6362/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0308 - val_loss: 0.6267\n",
      "Epoch 6363/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0337 - val_loss: 0.6216\n",
      "Epoch 6364/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0356 - val_loss: 0.6538\n",
      "Epoch 6365/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0421 - val_loss: 0.5957\n",
      "Epoch 6366/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0227 - val_loss: 0.6316\n",
      "Epoch 6367/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0170 - val_loss: 0.6156\n",
      "Epoch 6368/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0130 - val_loss: 0.5987\n",
      "Epoch 6369/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0391 - val_loss: 0.6271\n",
      "Epoch 6370/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0564 - val_loss: 0.6251\n",
      "Epoch 6371/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0323 - val_loss: 0.6174\n",
      "Epoch 6372/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0176 - val_loss: 0.6319\n",
      "Epoch 6373/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0265 - val_loss: 0.6021\n",
      "Epoch 6374/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0226 - val_loss: 0.6178\n",
      "Epoch 6375/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0148 - val_loss: 0.6137\n",
      "Epoch 6376/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0175 - val_loss: 0.6172\n",
      "Epoch 6377/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0134 - val_loss: 0.5915\n",
      "Epoch 6378/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0156 - val_loss: 0.5945\n",
      "Epoch 6379/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0204 - val_loss: 0.6339\n",
      "Epoch 6380/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0352 - val_loss: 0.6333\n",
      "Epoch 6381/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0350 - val_loss: 0.6297\n",
      "Epoch 6382/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0259 - val_loss: 0.6089\n",
      "Epoch 6383/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0158 - val_loss: 0.6018\n",
      "Epoch 6384/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0101 - val_loss: 0.6030\n",
      "Epoch 6385/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0099 - val_loss: 0.6161\n",
      "Epoch 6386/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0126 - val_loss: 0.5917\n",
      "Epoch 6387/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 752us/step - loss: 0.0210 - val_loss: 0.6501\n",
      "Epoch 6388/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0432 - val_loss: 0.6023\n",
      "Epoch 6389/10000\n",
      "130/130 [==============================] - 0s 804us/step - loss: 0.0266 - val_loss: 0.6339\n",
      "Epoch 6390/10000\n",
      "130/130 [==============================] - 0s 837us/step - loss: 0.0221 - val_loss: 0.6004\n",
      "Epoch 6391/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0316 - val_loss: 0.6082\n",
      "Epoch 6392/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.0237 - val_loss: 0.6066\n",
      "Epoch 6393/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0196 - val_loss: 0.6030\n",
      "Epoch 6394/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0159 - val_loss: 0.6157\n",
      "Epoch 6395/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0233 - val_loss: 0.6112\n",
      "Epoch 6396/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0732 - val_loss: 0.6053\n",
      "Epoch 6397/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0397 - val_loss: 0.5945\n",
      "Epoch 6398/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0325 - val_loss: 0.6119\n",
      "Epoch 6399/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0257 - val_loss: 0.6505\n",
      "Epoch 6400/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0211 - val_loss: 0.6350\n",
      "Epoch 6401/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0156 - val_loss: 0.6142\n",
      "Epoch 6402/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0189 - val_loss: 0.6574\n",
      "Epoch 6403/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0202 - val_loss: 0.6236\n",
      "Epoch 6404/10000\n",
      "130/130 [==============================] - 0s 857us/step - loss: 0.0094 - val_loss: 0.6075\n",
      "Epoch 6405/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.6342\n",
      "Epoch 6406/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.6050\n",
      "Epoch 6407/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0270 - val_loss: 0.6119\n",
      "Epoch 6408/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0307 - val_loss: 0.6013\n",
      "Epoch 6409/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0253 - val_loss: 0.6362\n",
      "Epoch 6410/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0484 - val_loss: 0.6033\n",
      "Epoch 6411/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0579 - val_loss: 0.6166\n",
      "Epoch 6412/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0331 - val_loss: 0.6285\n",
      "Epoch 6413/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0247 - val_loss: 0.6431\n",
      "Epoch 6414/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0193 - val_loss: 0.6284\n",
      "Epoch 6415/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0163 - val_loss: 0.6016\n",
      "Epoch 6416/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0126 - val_loss: 0.6270\n",
      "Epoch 6417/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0114 - val_loss: 0.6155\n",
      "Epoch 6418/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0108 - val_loss: 0.6262\n",
      "Epoch 6419/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0130 - val_loss: 0.6359\n",
      "Epoch 6420/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0267 - val_loss: 0.6255\n",
      "Epoch 6421/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0318 - val_loss: 0.6179\n",
      "Epoch 6422/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0403 - val_loss: 0.6203\n",
      "Epoch 6423/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0338 - val_loss: 0.5959\n",
      "Epoch 6424/10000\n",
      "130/130 [==============================] - 0s 843us/step - loss: 0.0317 - val_loss: 0.6374\n",
      "Epoch 6425/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0184 - val_loss: 0.5977\n",
      "Epoch 6426/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0139 - val_loss: 0.6124\n",
      "Epoch 6427/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0110 - val_loss: 0.6314\n",
      "Epoch 6428/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0162 - val_loss: 0.6198\n",
      "Epoch 6429/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0323 - val_loss: 0.6067\n",
      "Epoch 6430/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0233 - val_loss: 0.6228\n",
      "Epoch 6431/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0393 - val_loss: 0.6645\n",
      "Epoch 6432/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0427 - val_loss: 0.6100\n",
      "Epoch 6433/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0204 - val_loss: 0.6282\n",
      "Epoch 6434/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0228 - val_loss: 0.6002\n",
      "Epoch 6435/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0206 - val_loss: 0.6123\n",
      "Epoch 6436/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0145 - val_loss: 0.6340\n",
      "Epoch 6437/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0171 - val_loss: 0.6558\n",
      "Epoch 6438/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0188 - val_loss: 0.6543\n",
      "Epoch 6439/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0257 - val_loss: 0.5916\n",
      "Epoch 6440/10000\n",
      "130/130 [==============================] - 0s 940us/step - loss: 0.0298 - val_loss: 0.6779\n",
      "Epoch 6441/10000\n",
      "130/130 [==============================] - 0s 932us/step - loss: 0.0348 - val_loss: 0.6223\n",
      "Epoch 6442/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0154 - val_loss: 0.6125\n",
      "Epoch 6443/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0211 - val_loss: 0.6145\n",
      "Epoch 6444/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0365 - val_loss: 0.6077\n",
      "Epoch 6445/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0337 - val_loss: 0.5983\n",
      "Epoch 6446/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0170 - val_loss: 0.6038\n",
      "Epoch 6447/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0136 - val_loss: 0.6231\n",
      "Epoch 6448/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0128 - val_loss: 0.6182\n",
      "Epoch 6449/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0204 - val_loss: 0.6470\n",
      "Epoch 6450/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0297 - val_loss: 0.5927\n",
      "Epoch 6451/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0369 - val_loss: 0.6240\n",
      "Epoch 6452/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0347 - val_loss: 0.6135\n",
      "Epoch 6453/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0317 - val_loss: 0.6200\n",
      "Epoch 6454/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0198 - val_loss: 0.6120\n",
      "Epoch 6455/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0146 - val_loss: 0.6009\n",
      "Epoch 6456/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0176 - val_loss: 0.6409\n",
      "Epoch 6457/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0171 - val_loss: 0.6282\n",
      "Epoch 6458/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0134 - val_loss: 0.6222\n",
      "Epoch 6459/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0095 - val_loss: 0.6228\n",
      "Epoch 6460/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0187 - val_loss: 0.6344\n",
      "Epoch 6461/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0314 - val_loss: 0.6410\n",
      "Epoch 6462/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0497 - val_loss: 0.6150\n",
      "Epoch 6463/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 741us/step - loss: 0.0376 - val_loss: 0.6092\n",
      "Epoch 6464/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0277 - val_loss: 0.6406\n",
      "Epoch 6465/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0257 - val_loss: 0.6087\n",
      "Epoch 6466/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0275 - val_loss: 0.6229\n",
      "Epoch 6467/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0202 - val_loss: 0.6411\n",
      "Epoch 6468/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0198 - val_loss: 0.6485\n",
      "Epoch 6469/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0101 - val_loss: 0.6233\n",
      "Epoch 6470/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0121 - val_loss: 0.6278\n",
      "Epoch 6471/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0121 - val_loss: 0.6201\n",
      "Epoch 6472/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0093 - val_loss: 0.6315\n",
      "Epoch 6473/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0214 - val_loss: 0.6151\n",
      "Epoch 6474/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0319 - val_loss: 0.6675\n",
      "Epoch 6475/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0622 - val_loss: 0.6445\n",
      "Epoch 6476/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0418 - val_loss: 0.6468\n",
      "Epoch 6477/10000\n",
      "130/130 [==============================] - 0s 891us/step - loss: 0.0567 - val_loss: 0.5911\n",
      "Epoch 6478/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0221 - val_loss: 0.6069\n",
      "Epoch 6479/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0209 - val_loss: 0.6291\n",
      "Epoch 6480/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0244 - val_loss: 0.6238\n",
      "Epoch 6481/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0351 - val_loss: 0.6202\n",
      "Epoch 6482/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0327 - val_loss: 0.6368\n",
      "Epoch 6483/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0292 - val_loss: 0.6226\n",
      "Epoch 6484/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0202 - val_loss: 0.6260\n",
      "Epoch 6485/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0135 - val_loss: 0.6045\n",
      "Epoch 6486/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0123 - val_loss: 0.6052\n",
      "Epoch 6487/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0129 - val_loss: 0.6240\n",
      "Epoch 6488/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0120 - val_loss: 0.6193\n",
      "Epoch 6489/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0354 - val_loss: 0.5991\n",
      "Epoch 6490/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0356 - val_loss: 0.6472\n",
      "Epoch 6491/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0492 - val_loss: 0.6303\n",
      "Epoch 6492/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0353 - val_loss: 0.6004\n",
      "Epoch 6493/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0191 - val_loss: 0.6245\n",
      "Epoch 6494/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0161 - val_loss: 0.5937\n",
      "Epoch 6495/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0116 - val_loss: 0.6325\n",
      "Epoch 6496/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0209 - val_loss: 0.6014\n",
      "Epoch 6497/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0206 - val_loss: 0.6321\n",
      "Epoch 6498/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0391 - val_loss: 0.6217\n",
      "Epoch 6499/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0323 - val_loss: 0.6134\n",
      "Epoch 6500/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0126 - val_loss: 0.5966\n",
      "Epoch 6501/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0095 - val_loss: 0.6038\n",
      "Epoch 6502/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0159 - val_loss: 0.6072\n",
      "Epoch 6503/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0149 - val_loss: 0.6117\n",
      "Epoch 6504/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0293 - val_loss: 0.6145\n",
      "Epoch 6505/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0351 - val_loss: 0.6207\n",
      "Epoch 6506/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0185 - val_loss: 0.6157\n",
      "Epoch 6507/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0227 - val_loss: 0.6416\n",
      "Epoch 6508/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0414 - val_loss: 0.6283\n",
      "Epoch 6509/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0324 - val_loss: 0.6063\n",
      "Epoch 6510/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0305 - val_loss: 0.6374\n",
      "Epoch 6511/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0251 - val_loss: 0.6440\n",
      "Epoch 6512/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0226 - val_loss: 0.6070\n",
      "Epoch 6513/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0201 - val_loss: 0.6090\n",
      "Epoch 6514/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0249 - val_loss: 0.6311\n",
      "Epoch 6515/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0161 - val_loss: 0.6230\n",
      "Epoch 6516/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0254 - val_loss: 0.5843\n",
      "Epoch 6517/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0191 - val_loss: 0.6245\n",
      "Epoch 6518/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0228 - val_loss: 0.6263\n",
      "Epoch 6519/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0162 - val_loss: 0.6248\n",
      "Epoch 6520/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0113 - val_loss: 0.6175\n",
      "Epoch 6521/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0246 - val_loss: 0.6317\n",
      "Epoch 6522/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0356 - val_loss: 0.5705\n",
      "Epoch 6523/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0258 - val_loss: 0.6196\n",
      "Epoch 6524/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0362 - val_loss: 0.6138\n",
      "Epoch 6525/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0307 - val_loss: 0.5805\n",
      "Epoch 6526/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0293 - val_loss: 0.6221\n",
      "Epoch 6527/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0349 - val_loss: 0.6186\n",
      "Epoch 6528/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.6147\n",
      "Epoch 6529/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0409 - val_loss: 0.6562\n",
      "Epoch 6530/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0392 - val_loss: 0.6121\n",
      "Epoch 6531/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0263 - val_loss: 0.6211\n",
      "Epoch 6532/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0192 - val_loss: 0.6189\n",
      "Epoch 6533/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0185 - val_loss: 0.6356\n",
      "Epoch 6534/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0150 - val_loss: 0.6014\n",
      "Epoch 6535/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0142 - val_loss: 0.6291\n",
      "Epoch 6536/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0164 - val_loss: 0.6300\n",
      "Epoch 6537/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0151 - val_loss: 0.6407\n",
      "Epoch 6538/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0242 - val_loss: 0.6300\n",
      "Epoch 6539/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 772us/step - loss: 0.0577 - val_loss: 0.5994\n",
      "Epoch 6540/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0316 - val_loss: 0.5942\n",
      "Epoch 6541/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0173 - val_loss: 0.5842\n",
      "Epoch 6542/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0160 - val_loss: 0.6269\n",
      "Epoch 6543/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0167 - val_loss: 0.6130\n",
      "Epoch 6544/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0190 - val_loss: 0.6250\n",
      "Epoch 6545/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0213 - val_loss: 0.6095\n",
      "Epoch 6546/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0199 - val_loss: 0.6156\n",
      "Epoch 6547/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0194 - val_loss: 0.6280\n",
      "Epoch 6548/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0210 - val_loss: 0.6226\n",
      "Epoch 6549/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0161 - val_loss: 0.6222\n",
      "Epoch 6550/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0176 - val_loss: 0.6134\n",
      "Epoch 6551/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0196 - val_loss: 0.6325\n",
      "Epoch 6552/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0368 - val_loss: 0.6272\n",
      "Epoch 6553/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0348 - val_loss: 0.5811\n",
      "Epoch 6554/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0400 - val_loss: 0.5998\n",
      "Epoch 6555/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0285 - val_loss: 0.5807\n",
      "Epoch 6556/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0207 - val_loss: 0.6152\n",
      "Epoch 6557/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0198 - val_loss: 0.5988\n",
      "Epoch 6558/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0168 - val_loss: 0.5882\n",
      "Epoch 6559/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0169 - val_loss: 0.6034\n",
      "Epoch 6560/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0235 - val_loss: 0.5890\n",
      "Epoch 6561/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0207 - val_loss: 0.6018\n",
      "Epoch 6562/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0184 - val_loss: 0.5968\n",
      "Epoch 6563/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0240 - val_loss: 0.6051\n",
      "Epoch 6564/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0442 - val_loss: 0.6386\n",
      "Epoch 6565/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0496 - val_loss: 0.6063\n",
      "Epoch 6566/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0290 - val_loss: 0.6052\n",
      "Epoch 6567/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0190 - val_loss: 0.5997\n",
      "Epoch 6568/10000\n",
      "130/130 [==============================] - 0s 966us/step - loss: 0.0207 - val_loss: 0.6396\n",
      "Epoch 6569/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0214 - val_loss: 0.6270\n",
      "Epoch 6570/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0170 - val_loss: 0.6233\n",
      "Epoch 6571/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0156 - val_loss: 0.6224\n",
      "Epoch 6572/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0249 - val_loss: 0.6485\n",
      "Epoch 6573/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0588 - val_loss: 0.6402\n",
      "Epoch 6574/10000\n",
      "130/130 [==============================] - 0s 825us/step - loss: 0.0225 - val_loss: 0.6329\n",
      "Epoch 6575/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0292 - val_loss: 0.6206\n",
      "Epoch 6576/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0220 - val_loss: 0.6194\n",
      "Epoch 6577/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0221 - val_loss: 0.6238\n",
      "Epoch 6578/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0180 - val_loss: 0.6038\n",
      "Epoch 6579/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0193 - val_loss: 0.6341\n",
      "Epoch 6580/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0237 - val_loss: 0.6093\n",
      "Epoch 6581/10000\n",
      "130/130 [==============================] - 0s 899us/step - loss: 0.0248 - val_loss: 0.5824\n",
      "Epoch 6582/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.5917\n",
      "Epoch 6583/10000\n",
      "130/130 [==============================] - 0s 922us/step - loss: 0.0226 - val_loss: 0.6040\n",
      "Epoch 6584/10000\n",
      "130/130 [==============================] - 0s 831us/step - loss: 0.0231 - val_loss: 0.6062\n",
      "Epoch 6585/10000\n",
      "130/130 [==============================] - 0s 860us/step - loss: 0.0245 - val_loss: 0.6330\n",
      "Epoch 6586/10000\n",
      "130/130 [==============================] - 0s 814us/step - loss: 0.0209 - val_loss: 0.6257\n",
      "Epoch 6587/10000\n",
      "130/130 [==============================] - 0s 830us/step - loss: 0.0245 - val_loss: 0.6159\n",
      "Epoch 6588/10000\n",
      "130/130 [==============================] - 0s 873us/step - loss: 0.0353 - val_loss: 0.6244\n",
      "Epoch 6589/10000\n",
      "130/130 [==============================] - 0s 844us/step - loss: 0.0263 - val_loss: 0.6250\n",
      "Epoch 6590/10000\n",
      "130/130 [==============================] - 0s 871us/step - loss: 0.0223 - val_loss: 0.6038\n",
      "Epoch 6591/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0295 - val_loss: 0.6421\n",
      "Epoch 6592/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0221 - val_loss: 0.5921\n",
      "Epoch 6593/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0546 - val_loss: 0.6295\n",
      "Epoch 6594/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0266 - val_loss: 0.6153\n",
      "Epoch 6595/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0200 - val_loss: 0.6248\n",
      "Epoch 6596/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0163 - val_loss: 0.6140\n",
      "Epoch 6597/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0104 - val_loss: 0.6078\n",
      "Epoch 6598/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0067 - val_loss: 0.6033\n",
      "Epoch 6599/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0105 - val_loss: 0.6106\n",
      "Epoch 6600/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0177 - val_loss: 0.5977\n",
      "Epoch 6601/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0356 - val_loss: 0.6383\n",
      "Epoch 6602/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0439 - val_loss: 0.6520\n",
      "Epoch 6603/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0439 - val_loss: 0.6493\n",
      "Epoch 6604/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.6245\n",
      "Epoch 6605/10000\n",
      "130/130 [==============================] - 0s 851us/step - loss: 0.0224 - val_loss: 0.6348\n",
      "Epoch 6606/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0240 - val_loss: 0.6355\n",
      "Epoch 6607/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0133 - val_loss: 0.6071\n",
      "Epoch 6608/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0169 - val_loss: 0.6203\n",
      "Epoch 6609/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0239 - val_loss: 0.6142\n",
      "Epoch 6610/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0233 - val_loss: 0.6267\n",
      "Epoch 6611/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0213 - val_loss: 0.6166\n",
      "Epoch 6612/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0241 - val_loss: 0.6177\n",
      "Epoch 6613/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0167 - val_loss: 0.6197\n",
      "Epoch 6614/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0163 - val_loss: 0.6450\n",
      "Epoch 6615/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 801us/step - loss: 0.0209 - val_loss: 0.6047\n",
      "Epoch 6616/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0274 - val_loss: 0.6188\n",
      "Epoch 6617/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0370 - val_loss: 0.6122\n",
      "Epoch 6618/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0185 - val_loss: 0.5891\n",
      "Epoch 6619/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0206 - val_loss: 0.6326\n",
      "Epoch 6620/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0297 - val_loss: 0.5942\n",
      "Epoch 6621/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0457 - val_loss: 0.5969\n",
      "Epoch 6622/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0269 - val_loss: 0.5845\n",
      "Epoch 6623/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0158 - val_loss: 0.6170\n",
      "Epoch 6624/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0091 - val_loss: 0.6160\n",
      "Epoch 6625/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0087 - val_loss: 0.6132\n",
      "Epoch 6626/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0093 - val_loss: 0.6151\n",
      "Epoch 6627/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0191 - val_loss: 0.6444\n",
      "Epoch 6628/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0252 - val_loss: 0.6381\n",
      "Epoch 6629/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0378 - val_loss: 0.6161\n",
      "Epoch 6630/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0490 - val_loss: 0.5873\n",
      "Epoch 6631/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0333 - val_loss: 0.6084\n",
      "Epoch 6632/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0397 - val_loss: 0.6273\n",
      "Epoch 6633/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0395 - val_loss: 0.6125\n",
      "Epoch 6634/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0136 - val_loss: 0.6258\n",
      "Epoch 6635/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0090 - val_loss: 0.6124\n",
      "Epoch 6636/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0112 - val_loss: 0.6336\n",
      "Epoch 6637/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0146 - val_loss: 0.6306\n",
      "Epoch 6638/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0160 - val_loss: 0.6373\n",
      "Epoch 6639/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0456 - val_loss: 0.6398\n",
      "Epoch 6640/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0346 - val_loss: 0.6131\n",
      "Epoch 6641/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0306 - val_loss: 0.6168\n",
      "Epoch 6642/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0198 - val_loss: 0.5911\n",
      "Epoch 6643/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0134 - val_loss: 0.5844\n",
      "Epoch 6644/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0135 - val_loss: 0.5873\n",
      "Epoch 6645/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0297 - val_loss: 0.6265\n",
      "Epoch 6646/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0421 - val_loss: 0.6141\n",
      "Epoch 6647/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0309 - val_loss: 0.6401\n",
      "Epoch 6648/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0187 - val_loss: 0.6324\n",
      "Epoch 6649/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0201 - val_loss: 0.6041\n",
      "Epoch 6650/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0204 - val_loss: 0.6561\n",
      "Epoch 6651/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0244 - val_loss: 0.5608\n",
      "Epoch 6652/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0336 - val_loss: 0.5975\n",
      "Epoch 6653/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0243 - val_loss: 0.5924\n",
      "Epoch 6654/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0326 - val_loss: 0.6065\n",
      "Epoch 6655/10000\n",
      "130/130 [==============================] - 0s 831us/step - loss: 0.0343 - val_loss: 0.6333\n",
      "Epoch 6656/10000\n",
      "130/130 [==============================] - 0s 924us/step - loss: 0.0181 - val_loss: 0.6380\n",
      "Epoch 6657/10000\n",
      "130/130 [==============================] - 0s 983us/step - loss: 0.0188 - val_loss: 0.6021\n",
      "Epoch 6658/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0144 - val_loss: 0.6331\n",
      "Epoch 6659/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0131 - val_loss: 0.5914\n",
      "Epoch 6660/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0157 - val_loss: 0.6237\n",
      "Epoch 6661/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0237 - val_loss: 0.6212\n",
      "Epoch 6662/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0153 - val_loss: 0.6170\n",
      "Epoch 6663/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0124 - val_loss: 0.6036\n",
      "Epoch 6664/10000\n",
      "130/130 [==============================] - 0s 878us/step - loss: 0.0157 - val_loss: 0.6129\n",
      "Epoch 6665/10000\n",
      "130/130 [==============================] - 0s 825us/step - loss: 0.0273 - val_loss: 0.6184\n",
      "Epoch 6666/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0429 - val_loss: 0.6193\n",
      "Epoch 6667/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0392 - val_loss: 0.6258\n",
      "Epoch 6668/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0413 - val_loss: 0.5761\n",
      "Epoch 6669/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0423 - val_loss: 0.5991\n",
      "Epoch 6670/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0319 - val_loss: 0.6017\n",
      "Epoch 6671/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0142 - val_loss: 0.6000\n",
      "Epoch 6672/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0188 - val_loss: 0.5927\n",
      "Epoch 6673/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0143 - val_loss: 0.6018\n",
      "Epoch 6674/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0154 - val_loss: 0.6048\n",
      "Epoch 6675/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0192 - val_loss: 0.6144\n",
      "Epoch 6676/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0225 - val_loss: 0.6144\n",
      "Epoch 6677/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0133 - val_loss: 0.6000\n",
      "Epoch 6678/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0217 - val_loss: 0.6053\n",
      "Epoch 6679/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0584 - val_loss: 0.6276\n",
      "Epoch 6680/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0403 - val_loss: 0.5930\n",
      "Epoch 6681/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0228 - val_loss: 0.6164\n",
      "Epoch 6682/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0249 - val_loss: 0.6415\n",
      "Epoch 6683/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0205 - val_loss: 0.6382\n",
      "Epoch 6684/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0231 - val_loss: 0.6185\n",
      "Epoch 6685/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0181 - val_loss: 0.6209\n",
      "Epoch 6686/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0227 - val_loss: 0.6108\n",
      "Epoch 6687/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0252 - val_loss: 0.6121\n",
      "Epoch 6688/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0171 - val_loss: 0.6367\n",
      "Epoch 6689/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0237 - val_loss: 0.6232\n",
      "Epoch 6690/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0180 - val_loss: 0.6356\n",
      "Epoch 6691/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 737us/step - loss: 0.0567 - val_loss: 0.6082\n",
      "Epoch 6692/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0360 - val_loss: 0.6207\n",
      "Epoch 6693/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0179 - val_loss: 0.6272\n",
      "Epoch 6694/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0155 - val_loss: 0.6261\n",
      "Epoch 6695/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0109 - val_loss: 0.6315\n",
      "Epoch 6696/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0070 - val_loss: 0.6295\n",
      "Epoch 6697/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0210 - val_loss: 0.6228\n",
      "Epoch 6698/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0886 - val_loss: 0.5930\n",
      "Epoch 6699/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0667 - val_loss: 0.5927\n",
      "Epoch 6700/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0288 - val_loss: 0.6026\n",
      "Epoch 6701/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0164 - val_loss: 0.5813\n",
      "Epoch 6702/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0092 - val_loss: 0.5992\n",
      "Epoch 6703/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0077 - val_loss: 0.6106\n",
      "Epoch 6704/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0145 - val_loss: 0.5952\n",
      "Epoch 6705/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0126 - val_loss: 0.6214\n",
      "Epoch 6706/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0334 - val_loss: 0.5979\n",
      "Epoch 6707/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0482 - val_loss: 0.6139\n",
      "Epoch 6708/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0791 - val_loss: 0.6315\n",
      "Epoch 6709/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0354 - val_loss: 0.6071\n",
      "Epoch 6710/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0266 - val_loss: 0.6023\n",
      "Epoch 6711/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0136 - val_loss: 0.5942\n",
      "Epoch 6712/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0102 - val_loss: 0.6056\n",
      "Epoch 6713/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0161 - val_loss: 0.6064\n",
      "Epoch 6714/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0223 - val_loss: 0.6186\n",
      "Epoch 6715/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0218 - val_loss: 0.5896\n",
      "Epoch 6716/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0218 - val_loss: 0.6035\n",
      "Epoch 6717/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0253 - val_loss: 0.6148\n",
      "Epoch 6718/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0392 - val_loss: 0.6069\n",
      "Epoch 6719/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0363 - val_loss: 0.6096\n",
      "Epoch 6720/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0136 - val_loss: 0.5839\n",
      "Epoch 6721/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0140 - val_loss: 0.6000\n",
      "Epoch 6722/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0212 - val_loss: 0.6473\n",
      "Epoch 6723/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0262 - val_loss: 0.6426\n",
      "Epoch 6724/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0261 - val_loss: 0.6353\n",
      "Epoch 6725/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0197 - val_loss: 0.5891\n",
      "Epoch 6726/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0143 - val_loss: 0.6144\n",
      "Epoch 6727/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0154 - val_loss: 0.6011\n",
      "Epoch 6728/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0165 - val_loss: 0.6208\n",
      "Epoch 6729/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.5935\n",
      "Epoch 6730/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0236 - val_loss: 0.6464\n",
      "Epoch 6731/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0206 - val_loss: 0.6174\n",
      "Epoch 6732/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0246 - val_loss: 0.6166\n",
      "Epoch 6733/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0194 - val_loss: 0.5974\n",
      "Epoch 6734/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0178 - val_loss: 0.6127\n",
      "Epoch 6735/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0161 - val_loss: 0.6293\n",
      "Epoch 6736/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0220 - val_loss: 0.6056\n",
      "Epoch 6737/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0165 - val_loss: 0.6202\n",
      "Epoch 6738/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0253 - val_loss: 0.6416\n",
      "Epoch 6739/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0300 - val_loss: 0.6317\n",
      "Epoch 6740/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0292 - val_loss: 0.6181\n",
      "Epoch 6741/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0168 - val_loss: 0.6230\n",
      "Epoch 6742/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0142 - val_loss: 0.6248\n",
      "Epoch 6743/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0146 - val_loss: 0.5999\n",
      "Epoch 6744/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0200 - val_loss: 0.6513\n",
      "Epoch 6745/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0520 - val_loss: 0.6119\n",
      "Epoch 6746/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0420 - val_loss: 0.6303\n",
      "Epoch 6747/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0386 - val_loss: 0.6372\n",
      "Epoch 6748/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0275 - val_loss: 0.6284\n",
      "Epoch 6749/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0159 - val_loss: 0.5999\n",
      "Epoch 6750/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0217 - val_loss: 0.6014\n",
      "Epoch 6751/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0131 - val_loss: 0.6370\n",
      "Epoch 6752/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0163 - val_loss: 0.6046\n",
      "Epoch 6753/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0191 - val_loss: 0.6246\n",
      "Epoch 6754/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0799 - val_loss: 0.6183\n",
      "Epoch 6755/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0570 - val_loss: 0.6353\n",
      "Epoch 6756/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0176 - val_loss: 0.5956\n",
      "Epoch 6757/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0138 - val_loss: 0.6332\n",
      "Epoch 6758/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0110 - val_loss: 0.6228\n",
      "Epoch 6759/10000\n",
      "130/130 [==============================] - 0s 841us/step - loss: 0.0262 - val_loss: 0.6184\n",
      "Epoch 6760/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0209 - val_loss: 0.6199\n",
      "Epoch 6761/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0187 - val_loss: 0.6038\n",
      "Epoch 6762/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0152 - val_loss: 0.6028\n",
      "Epoch 6763/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0095 - val_loss: 0.6155\n",
      "Epoch 6764/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0210 - val_loss: 0.6514\n",
      "Epoch 6765/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0558 - val_loss: 0.6300\n",
      "Epoch 6766/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0337 - val_loss: 0.6187\n",
      "Epoch 6767/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 757us/step - loss: 0.0271 - val_loss: 0.5889\n",
      "Epoch 6768/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0295 - val_loss: 0.6085\n",
      "Epoch 6769/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0225 - val_loss: 0.6332\n",
      "Epoch 6770/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0162 - val_loss: 0.6143\n",
      "Epoch 6771/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0144 - val_loss: 0.6338\n",
      "Epoch 6772/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0184 - val_loss: 0.6003\n",
      "Epoch 6773/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0160 - val_loss: 0.5963\n",
      "Epoch 6774/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0168 - val_loss: 0.6373\n",
      "Epoch 6775/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0470 - val_loss: 0.6279\n",
      "Epoch 6776/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0284 - val_loss: 0.6065\n",
      "Epoch 6777/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0205 - val_loss: 0.6141\n",
      "Epoch 6778/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0201 - val_loss: 0.5935\n",
      "Epoch 6779/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0163 - val_loss: 0.6018\n",
      "Epoch 6780/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0328 - val_loss: 0.5900\n",
      "Epoch 6781/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0308 - val_loss: 0.6140\n",
      "Epoch 6782/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0253 - val_loss: 0.6204\n",
      "Epoch 6783/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0261 - val_loss: 0.6214\n",
      "Epoch 6784/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0234 - val_loss: 0.6109\n",
      "Epoch 6785/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0182 - val_loss: 0.5950\n",
      "Epoch 6786/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0166 - val_loss: 0.6161\n",
      "Epoch 6787/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0317 - val_loss: 0.5976\n",
      "Epoch 6788/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0412 - val_loss: 0.6309\n",
      "Epoch 6789/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0416 - val_loss: 0.6348\n",
      "Epoch 6790/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0244 - val_loss: 0.6044\n",
      "Epoch 6791/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0203 - val_loss: 0.6214\n",
      "Epoch 6792/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0188 - val_loss: 0.6241\n",
      "Epoch 6793/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0130 - val_loss: 0.6145\n",
      "Epoch 6794/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0230 - val_loss: 0.6123\n",
      "Epoch 6795/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0240 - val_loss: 0.6072\n",
      "Epoch 6796/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0161 - val_loss: 0.6036\n",
      "Epoch 6797/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0257 - val_loss: 0.5876\n",
      "Epoch 6798/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0220 - val_loss: 0.6365\n",
      "Epoch 6799/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0265 - val_loss: 0.5948\n",
      "Epoch 6800/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0308 - val_loss: 0.6293\n",
      "Epoch 6801/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0293 - val_loss: 0.6022\n",
      "Epoch 6802/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0191 - val_loss: 0.5928\n",
      "Epoch 6803/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0169 - val_loss: 0.5915\n",
      "Epoch 6804/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0286 - val_loss: 0.6461\n",
      "Epoch 6805/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0220 - val_loss: 0.6230\n",
      "Epoch 6806/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0165 - val_loss: 0.5931\n",
      "Epoch 6807/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0128 - val_loss: 0.5772\n",
      "Epoch 6808/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0263 - val_loss: 0.5947\n",
      "Epoch 6809/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0279 - val_loss: 0.5919\n",
      "Epoch 6810/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0245 - val_loss: 0.6463\n",
      "Epoch 6811/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0237 - val_loss: 0.5894\n",
      "Epoch 6812/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0362 - val_loss: 0.6097\n",
      "Epoch 6813/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0351 - val_loss: 0.6178\n",
      "Epoch 6814/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0153 - val_loss: 0.6182\n",
      "Epoch 6815/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0251 - val_loss: 0.6325\n",
      "Epoch 6816/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0222 - val_loss: 0.6149\n",
      "Epoch 6817/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0195 - val_loss: 0.5943\n",
      "Epoch 6818/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0187 - val_loss: 0.6228\n",
      "Epoch 6819/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0123 - val_loss: 0.5956\n",
      "Epoch 6820/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0245 - val_loss: 0.6125\n",
      "Epoch 6821/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0298 - val_loss: 0.6246\n",
      "Epoch 6822/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0456 - val_loss: 0.6344\n",
      "Epoch 6823/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0469 - val_loss: 0.5696\n",
      "Epoch 6824/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0310 - val_loss: 0.6050\n",
      "Epoch 6825/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0234 - val_loss: 0.5960\n",
      "Epoch 6826/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0161 - val_loss: 0.6159\n",
      "Epoch 6827/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0115 - val_loss: 0.6173\n",
      "Epoch 6828/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0197 - val_loss: 0.6238\n",
      "Epoch 6829/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0273 - val_loss: 0.6183\n",
      "Epoch 6830/10000\n",
      "130/130 [==============================] - 0s 805us/step - loss: 0.0316 - val_loss: 0.6169\n",
      "Epoch 6831/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0278 - val_loss: 0.6118\n",
      "Epoch 6832/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0440 - val_loss: 0.6470\n",
      "Epoch 6833/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0212 - val_loss: 0.6133\n",
      "Epoch 6834/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0174 - val_loss: 0.6118\n",
      "Epoch 6835/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0232 - val_loss: 0.6122\n",
      "Epoch 6836/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0200 - val_loss: 0.6020\n",
      "Epoch 6837/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0155 - val_loss: 0.6051\n",
      "Epoch 6838/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0161 - val_loss: 0.6051\n",
      "Epoch 6839/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0231 - val_loss: 0.5943\n",
      "Epoch 6840/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0216 - val_loss: 0.6148\n",
      "Epoch 6841/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0188 - val_loss: 0.6124\n",
      "Epoch 6842/10000\n",
      "130/130 [==============================] - 0s 867us/step - loss: 0.0159 - val_loss: 0.6002\n",
      "Epoch 6843/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 786us/step - loss: 0.0177 - val_loss: 0.6017\n",
      "Epoch 6844/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0141 - val_loss: 0.6301\n",
      "Epoch 6845/10000\n",
      "130/130 [==============================] - 0s 987us/step - loss: 0.0372 - val_loss: 0.6183\n",
      "Epoch 6846/10000\n",
      "130/130 [==============================] - 0s 995us/step - loss: 0.0294 - val_loss: 0.5988\n",
      "Epoch 6847/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0298 - val_loss: 0.6247\n",
      "Epoch 6848/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0681 - val_loss: 0.6069\n",
      "Epoch 6849/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0453 - val_loss: 0.5909\n",
      "Epoch 6850/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0119 - val_loss: 0.5890\n",
      "Epoch 6851/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0087 - val_loss: 0.6147\n",
      "Epoch 6852/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0083 - val_loss: 0.6033\n",
      "Epoch 6853/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0106 - val_loss: 0.5949\n",
      "Epoch 6854/10000\n",
      "130/130 [==============================] - 0s 833us/step - loss: 0.0126 - val_loss: 0.6203\n",
      "Epoch 6855/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0339 - val_loss: 0.6242\n",
      "Epoch 6856/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0951 - val_loss: 0.6447\n",
      "Epoch 6857/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0542 - val_loss: 0.6253\n",
      "Epoch 6858/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0162 - val_loss: 0.6158\n",
      "Epoch 6859/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0145 - val_loss: 0.5988\n",
      "Epoch 6860/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0097 - val_loss: 0.6099\n",
      "Epoch 6861/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0075 - val_loss: 0.5916\n",
      "Epoch 6862/10000\n",
      "130/130 [==============================] - 0s 840us/step - loss: 0.0127 - val_loss: 0.6059\n",
      "Epoch 6863/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0250 - val_loss: 0.5990\n",
      "Epoch 6864/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0280 - val_loss: 0.6142\n",
      "Epoch 6865/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0190 - val_loss: 0.6110\n",
      "Epoch 6866/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0168 - val_loss: 0.6341\n",
      "Epoch 6867/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0227 - val_loss: 0.6160\n",
      "Epoch 6868/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0251 - val_loss: 0.6271\n",
      "Epoch 6869/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0215 - val_loss: 0.6263\n",
      "Epoch 6870/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0186 - val_loss: 0.6088\n",
      "Epoch 6871/10000\n",
      "130/130 [==============================] - 0s 844us/step - loss: 0.0157 - val_loss: 0.6260\n",
      "Epoch 6872/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0226 - val_loss: 0.6117\n",
      "Epoch 6873/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0202 - val_loss: 0.5879\n",
      "Epoch 6874/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0244 - val_loss: 0.6354\n",
      "Epoch 6875/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0467 - val_loss: 0.6235\n",
      "Epoch 6876/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0308 - val_loss: 0.6071\n",
      "Epoch 6877/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0340 - val_loss: 0.6308\n",
      "Epoch 6878/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0229 - val_loss: 0.6192\n",
      "Epoch 6879/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0148 - val_loss: 0.6225\n",
      "Epoch 6880/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0161 - val_loss: 0.6245\n",
      "Epoch 6881/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0134 - val_loss: 0.6208\n",
      "Epoch 6882/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0088 - val_loss: 0.6109\n",
      "Epoch 6883/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0177 - val_loss: 0.6435\n",
      "Epoch 6884/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0293 - val_loss: 0.6065\n",
      "Epoch 6885/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0224 - val_loss: 0.5916\n",
      "Epoch 6886/10000\n",
      "130/130 [==============================] - 0s 847us/step - loss: 0.0346 - val_loss: 0.6457\n",
      "Epoch 6887/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0454 - val_loss: 0.6098\n",
      "Epoch 6888/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0307 - val_loss: 0.6148\n",
      "Epoch 6889/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0391 - val_loss: 0.5905\n",
      "Epoch 6890/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0210 - val_loss: 0.6284\n",
      "Epoch 6891/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0213 - val_loss: 0.5854\n",
      "Epoch 6892/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0148 - val_loss: 0.6133\n",
      "Epoch 6893/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0168 - val_loss: 0.6064\n",
      "Epoch 6894/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0181 - val_loss: 0.6452\n",
      "Epoch 6895/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0371 - val_loss: 0.6071\n",
      "Epoch 6896/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0257 - val_loss: 0.6027\n",
      "Epoch 6897/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0238 - val_loss: 0.6197\n",
      "Epoch 6898/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0241 - val_loss: 0.5711\n",
      "Epoch 6899/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0551 - val_loss: 0.5662\n",
      "Epoch 6900/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0330 - val_loss: 0.5851\n",
      "Epoch 6901/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0202 - val_loss: 0.6169\n",
      "Epoch 6902/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0169 - val_loss: 0.6177\n",
      "Epoch 6903/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0121 - val_loss: 0.5959\n",
      "Epoch 6904/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0149 - val_loss: 0.6199\n",
      "Epoch 6905/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0139 - val_loss: 0.6110\n",
      "Epoch 6906/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0142 - val_loss: 0.5978\n",
      "Epoch 6907/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0145 - val_loss: 0.6229\n",
      "Epoch 6908/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0302 - val_loss: 0.6498\n",
      "Epoch 6909/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0554 - val_loss: 0.6065\n",
      "Epoch 6910/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0346 - val_loss: 0.6170\n",
      "Epoch 6911/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0235 - val_loss: 0.5919\n",
      "Epoch 6912/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0117 - val_loss: 0.6223\n",
      "Epoch 6913/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0099 - val_loss: 0.6236\n",
      "Epoch 6914/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0168 - val_loss: 0.6396\n",
      "Epoch 6915/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0321 - val_loss: 0.6098\n",
      "Epoch 6916/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0274 - val_loss: 0.6118\n",
      "Epoch 6917/10000\n",
      "130/130 [==============================] - 0s 859us/step - loss: 0.0228 - val_loss: 0.6273\n",
      "Epoch 6918/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0311 - val_loss: 0.5888\n",
      "Epoch 6919/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 755us/step - loss: 0.0430 - val_loss: 0.6346\n",
      "Epoch 6920/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0293 - val_loss: 0.6073\n",
      "Epoch 6921/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0255 - val_loss: 0.6398\n",
      "Epoch 6922/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0128 - val_loss: 0.6334\n",
      "Epoch 6923/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0121 - val_loss: 0.6241\n",
      "Epoch 6924/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0181 - val_loss: 0.5996\n",
      "Epoch 6925/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0137 - val_loss: 0.6180\n",
      "Epoch 6926/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0230 - val_loss: 0.5925\n",
      "Epoch 6927/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0201 - val_loss: 0.6087\n",
      "Epoch 6928/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0541 - val_loss: 0.6000\n",
      "Epoch 6929/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0574 - val_loss: 0.6253\n",
      "Epoch 6930/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0273 - val_loss: 0.6045\n",
      "Epoch 6931/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0186 - val_loss: 0.6190\n",
      "Epoch 6932/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0218 - val_loss: 0.6402\n",
      "Epoch 6933/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0203 - val_loss: 0.6135\n",
      "Epoch 6934/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0304 - val_loss: 0.6137\n",
      "Epoch 6935/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0300 - val_loss: 0.6337\n",
      "Epoch 6936/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0260 - val_loss: 0.5953\n",
      "Epoch 6937/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0134 - val_loss: 0.6289\n",
      "Epoch 6938/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0303 - val_loss: 0.5936\n",
      "Epoch 6939/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0208 - val_loss: 0.6164\n",
      "Epoch 6940/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0118 - val_loss: 0.6026\n",
      "Epoch 6941/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0259 - val_loss: 0.6175\n",
      "Epoch 6942/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0307 - val_loss: 0.6140\n",
      "Epoch 6943/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0276 - val_loss: 0.6180\n",
      "Epoch 6944/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0203 - val_loss: 0.6291\n",
      "Epoch 6945/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0169 - val_loss: 0.5932\n",
      "Epoch 6946/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0133 - val_loss: 0.6129\n",
      "Epoch 6947/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0074 - val_loss: 0.6064\n",
      "Epoch 6948/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0143 - val_loss: 0.6157\n",
      "Epoch 6949/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0133 - val_loss: 0.6063\n",
      "Epoch 6950/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0167 - val_loss: 0.6040\n",
      "Epoch 6951/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0383 - val_loss: 0.6163\n",
      "Epoch 6952/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0508 - val_loss: 0.6118\n",
      "Epoch 6953/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0738 - val_loss: 0.6061\n",
      "Epoch 6954/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0586 - val_loss: 0.6288\n",
      "Epoch 6955/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0307 - val_loss: 0.6234\n",
      "Epoch 6956/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0153 - val_loss: 0.6114\n",
      "Epoch 6957/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0143 - val_loss: 0.6123\n",
      "Epoch 6958/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0149 - val_loss: 0.6011\n",
      "Epoch 6959/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0110 - val_loss: 0.6170\n",
      "Epoch 6960/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0161 - val_loss: 0.5962\n",
      "Epoch 6961/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0311 - val_loss: 0.6057\n",
      "Epoch 6962/10000\n",
      "130/130 [==============================] - 0s 829us/step - loss: 0.0396 - val_loss: 0.6385\n",
      "Epoch 6963/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0335 - val_loss: 0.5930\n",
      "Epoch 6964/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0209 - val_loss: 0.5993\n",
      "Epoch 6965/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0149 - val_loss: 0.5968\n",
      "Epoch 6966/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0108 - val_loss: 0.6164\n",
      "Epoch 6967/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0147 - val_loss: 0.6123\n",
      "Epoch 6968/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0127 - val_loss: 0.5904\n",
      "Epoch 6969/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0147 - val_loss: 0.6202\n",
      "Epoch 6970/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0261 - val_loss: 0.6406\n",
      "Epoch 6971/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0356 - val_loss: 0.6127\n",
      "Epoch 6972/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0300 - val_loss: 0.6024\n",
      "Epoch 6973/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0281 - val_loss: 0.6106\n",
      "Epoch 6974/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0259 - val_loss: 0.6211\n",
      "Epoch 6975/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0285 - val_loss: 0.6391\n",
      "Epoch 6976/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0292 - val_loss: 0.6024\n",
      "Epoch 6977/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0325 - val_loss: 0.6040\n",
      "Epoch 6978/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0224 - val_loss: 0.6066\n",
      "Epoch 6979/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0205 - val_loss: 0.6098\n",
      "Epoch 6980/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0143 - val_loss: 0.6182\n",
      "Epoch 6981/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0204 - val_loss: 0.6078\n",
      "Epoch 6982/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0157 - val_loss: 0.5871\n",
      "Epoch 6983/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0111 - val_loss: 0.5971\n",
      "Epoch 6984/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0211 - val_loss: 0.6701\n",
      "Epoch 6985/10000\n",
      "130/130 [==============================] - 0s 824us/step - loss: 0.0310 - val_loss: 0.6589\n",
      "Epoch 6986/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0468 - val_loss: 0.6148\n",
      "Epoch 6987/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0379 - val_loss: 0.6069\n",
      "Epoch 6988/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0177 - val_loss: 0.6446\n",
      "Epoch 6989/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0180 - val_loss: 0.5771\n",
      "Epoch 6990/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0144 - val_loss: 0.5925\n",
      "Epoch 6991/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0156 - val_loss: 0.6015\n",
      "Epoch 6992/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0163 - val_loss: 0.5888\n",
      "Epoch 6993/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0300 - val_loss: 0.5749\n",
      "Epoch 6994/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0309 - val_loss: 0.6165\n",
      "Epoch 6995/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 749us/step - loss: 0.0336 - val_loss: 0.6093\n",
      "Epoch 6996/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0208 - val_loss: 0.6142\n",
      "Epoch 6997/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0226 - val_loss: 0.5876\n",
      "Epoch 6998/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0134 - val_loss: 0.5984\n",
      "Epoch 6999/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0187 - val_loss: 0.6269\n",
      "Epoch 7000/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0355 - val_loss: 0.6094\n",
      "Epoch 7001/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0406 - val_loss: 0.6477\n",
      "Epoch 7002/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0225 - val_loss: 0.6354\n",
      "Epoch 7003/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0165 - val_loss: 0.5903\n",
      "Epoch 7004/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0253 - val_loss: 0.6075\n",
      "Epoch 7005/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0613 - val_loss: 0.5851\n",
      "Epoch 7006/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0329 - val_loss: 0.6256\n",
      "Epoch 7007/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0160 - val_loss: 0.6103\n",
      "Epoch 7008/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0124 - val_loss: 0.6114\n",
      "Epoch 7009/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0091 - val_loss: 0.6136\n",
      "Epoch 7010/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0089 - val_loss: 0.6064\n",
      "Epoch 7011/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0214 - val_loss: 0.5933\n",
      "Epoch 7012/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0253 - val_loss: 0.5984\n",
      "Epoch 7013/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0362 - val_loss: 0.5875\n",
      "Epoch 7014/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0349 - val_loss: 0.6245\n",
      "Epoch 7015/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0336 - val_loss: 0.6184\n",
      "Epoch 7016/10000\n",
      "130/130 [==============================] - 0s 850us/step - loss: 0.0202 - val_loss: 0.6176\n",
      "Epoch 7017/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0154 - val_loss: 0.6212\n",
      "Epoch 7018/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0218 - val_loss: 0.6141\n",
      "Epoch 7019/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0218 - val_loss: 0.6298\n",
      "Epoch 7020/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0136 - val_loss: 0.6211\n",
      "Epoch 7021/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0137 - val_loss: 0.6086\n",
      "Epoch 7022/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0242 - val_loss: 0.6332\n",
      "Epoch 7023/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0282 - val_loss: 0.6336\n",
      "Epoch 7024/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0344 - val_loss: 0.6435\n",
      "Epoch 7025/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0429 - val_loss: 0.6255\n",
      "Epoch 7026/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0290 - val_loss: 0.5924\n",
      "Epoch 7027/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0222 - val_loss: 0.6067\n",
      "Epoch 7028/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0314 - val_loss: 0.6297\n",
      "Epoch 7029/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0246 - val_loss: 0.5978\n",
      "Epoch 7030/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0162 - val_loss: 0.6178\n",
      "Epoch 7031/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0148 - val_loss: 0.6229\n",
      "Epoch 7032/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0209 - val_loss: 0.6381\n",
      "Epoch 7033/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0224 - val_loss: 0.6442\n",
      "Epoch 7034/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0150 - val_loss: 0.6067\n",
      "Epoch 7035/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0156 - val_loss: 0.6078\n",
      "Epoch 7036/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0166 - val_loss: 0.6171\n",
      "Epoch 7037/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0174 - val_loss: 0.6130\n",
      "Epoch 7038/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0153 - val_loss: 0.6138\n",
      "Epoch 7039/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0150 - val_loss: 0.6217\n",
      "Epoch 7040/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0286 - val_loss: 0.6016\n",
      "Epoch 7041/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0303 - val_loss: 0.6638\n",
      "Epoch 7042/10000\n",
      "130/130 [==============================] - 0s 803us/step - loss: 0.0424 - val_loss: 0.6518\n",
      "Epoch 7043/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0357 - val_loss: 0.6498\n",
      "Epoch 7044/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0195 - val_loss: 0.6491\n",
      "Epoch 7045/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0228 - val_loss: 0.6131\n",
      "Epoch 7046/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0222 - val_loss: 0.6368\n",
      "Epoch 7047/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0257 - val_loss: 0.6129\n",
      "Epoch 7048/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0189 - val_loss: 0.6364\n",
      "Epoch 7049/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0127 - val_loss: 0.6185\n",
      "Epoch 7050/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0119 - val_loss: 0.6119\n",
      "Epoch 7051/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0116 - val_loss: 0.6206\n",
      "Epoch 7052/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0299 - val_loss: 0.6042\n",
      "Epoch 7053/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0227 - val_loss: 0.6243\n",
      "Epoch 7054/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0191 - val_loss: 0.6352\n",
      "Epoch 7055/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0399 - val_loss: 0.6361\n",
      "Epoch 7056/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0406 - val_loss: 0.6082\n",
      "Epoch 7057/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0286 - val_loss: 0.6096\n",
      "Epoch 7058/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0221 - val_loss: 0.5748\n",
      "Epoch 7059/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0174 - val_loss: 0.5906\n",
      "Epoch 7060/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0164 - val_loss: 0.6089\n",
      "Epoch 7061/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0262 - val_loss: 0.6086\n",
      "Epoch 7062/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0349 - val_loss: 0.5977\n",
      "Epoch 7063/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0213 - val_loss: 0.6123\n",
      "Epoch 7064/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0122 - val_loss: 0.6059\n",
      "Epoch 7065/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0117 - val_loss: 0.6027\n",
      "Epoch 7066/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0173 - val_loss: 0.6198\n",
      "Epoch 7067/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0296 - val_loss: 0.6088\n",
      "Epoch 7068/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0497 - val_loss: 0.5947\n",
      "Epoch 7069/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0326 - val_loss: 0.5889\n",
      "Epoch 7070/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0195 - val_loss: 0.6041\n",
      "Epoch 7071/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 739us/step - loss: 0.0222 - val_loss: 0.6211\n",
      "Epoch 7072/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0308 - val_loss: 0.6227\n",
      "Epoch 7073/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0222 - val_loss: 0.6196\n",
      "Epoch 7074/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0163 - val_loss: 0.5982\n",
      "Epoch 7075/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0126 - val_loss: 0.6127\n",
      "Epoch 7076/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0178 - val_loss: 0.6260\n",
      "Epoch 7077/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0129 - val_loss: 0.6024\n",
      "Epoch 7078/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0162 - val_loss: 0.5925\n",
      "Epoch 7079/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0196 - val_loss: 0.6197\n",
      "Epoch 7080/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0303 - val_loss: 0.6224\n",
      "Epoch 7081/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0316 - val_loss: 0.5909\n",
      "Epoch 7082/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0510 - val_loss: 0.6065\n",
      "Epoch 7083/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0440 - val_loss: 0.6120\n",
      "Epoch 7084/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0564 - val_loss: 0.6209\n",
      "Epoch 7085/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0223 - val_loss: 0.6126\n",
      "Epoch 7086/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0352 - val_loss: 0.6073\n",
      "Epoch 7087/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0291 - val_loss: 0.6086\n",
      "Epoch 7088/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0142 - val_loss: 0.6085\n",
      "Epoch 7089/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0097 - val_loss: 0.6064\n",
      "Epoch 7090/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0197 - val_loss: 0.6085\n",
      "Epoch 7091/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0279 - val_loss: 0.6192\n",
      "Epoch 7092/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0224 - val_loss: 0.6127\n",
      "Epoch 7093/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0159 - val_loss: 0.6133\n",
      "Epoch 7094/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0142 - val_loss: 0.6471\n",
      "Epoch 7095/10000\n",
      "130/130 [==============================] - 0s 804us/step - loss: 0.0188 - val_loss: 0.5920\n",
      "Epoch 7096/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0265 - val_loss: 0.6008\n",
      "Epoch 7097/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0303 - val_loss: 0.5830\n",
      "Epoch 7098/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0265 - val_loss: 0.5995\n",
      "Epoch 7099/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0159 - val_loss: 0.6175\n",
      "Epoch 7100/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0234 - val_loss: 0.6022\n",
      "Epoch 7101/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0174 - val_loss: 0.6022\n",
      "Epoch 7102/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0192 - val_loss: 0.6328\n",
      "Epoch 7103/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0239 - val_loss: 0.6212\n",
      "Epoch 7104/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1192 - val_loss: 0.6003\n",
      "Epoch 7105/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0738 - val_loss: 0.5837\n",
      "Epoch 7106/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0162 - val_loss: 0.6259\n",
      "Epoch 7107/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0092 - val_loss: 0.6149\n",
      "Epoch 7108/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0114 - val_loss: 0.6012\n",
      "Epoch 7109/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0110 - val_loss: 0.6106\n",
      "Epoch 7110/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0081 - val_loss: 0.6032\n",
      "Epoch 7111/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0096 - val_loss: 0.6185\n",
      "Epoch 7112/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0177 - val_loss: 0.6147\n",
      "Epoch 7113/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0175 - val_loss: 0.5943\n",
      "Epoch 7114/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0360 - val_loss: 0.6125\n",
      "Epoch 7115/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0554 - val_loss: 0.6277\n",
      "Epoch 7116/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0430 - val_loss: 0.6015\n",
      "Epoch 7117/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0241 - val_loss: 0.5848\n",
      "Epoch 7118/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0211 - val_loss: 0.6164\n",
      "Epoch 7119/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0115 - val_loss: 0.5940\n",
      "Epoch 7120/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0070 - val_loss: 0.5895\n",
      "Epoch 7121/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0130 - val_loss: 0.6112\n",
      "Epoch 7122/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0211 - val_loss: 0.6044\n",
      "Epoch 7123/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0260 - val_loss: 0.5965\n",
      "Epoch 7124/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0256 - val_loss: 0.6158\n",
      "Epoch 7125/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0198 - val_loss: 0.5990\n",
      "Epoch 7126/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0243 - val_loss: 0.6159\n",
      "Epoch 7127/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0416 - val_loss: 0.6225\n",
      "Epoch 7128/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0492 - val_loss: 0.6011\n",
      "Epoch 7129/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0297 - val_loss: 0.5954\n",
      "Epoch 7130/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0386 - val_loss: 0.6203\n",
      "Epoch 7131/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0222 - val_loss: 0.6009\n",
      "Epoch 7132/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0211 - val_loss: 0.6052\n",
      "Epoch 7133/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0224 - val_loss: 0.5935\n",
      "Epoch 7134/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0118 - val_loss: 0.6255\n",
      "Epoch 7135/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0115 - val_loss: 0.5955\n",
      "Epoch 7136/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0247 - val_loss: 0.5754\n",
      "Epoch 7137/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0208 - val_loss: 0.5980\n",
      "Epoch 7138/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0143 - val_loss: 0.5967\n",
      "Epoch 7139/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0211 - val_loss: 0.5985\n",
      "Epoch 7140/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0263 - val_loss: 0.5982\n",
      "Epoch 7141/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0282 - val_loss: 0.5874\n",
      "Epoch 7142/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0316 - val_loss: 0.6199\n",
      "Epoch 7143/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0253 - val_loss: 0.6162\n",
      "Epoch 7144/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0200 - val_loss: 0.6089\n",
      "Epoch 7145/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0215 - val_loss: 0.6170\n",
      "Epoch 7146/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0232 - val_loss: 0.6139\n",
      "Epoch 7147/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 730us/step - loss: 0.0110 - val_loss: 0.5956\n",
      "Epoch 7148/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0097 - val_loss: 0.5989\n",
      "Epoch 7149/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0112 - val_loss: 0.5985\n",
      "Epoch 7150/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0136 - val_loss: 0.6150\n",
      "Epoch 7151/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0357 - val_loss: 0.6175\n",
      "Epoch 7152/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0519 - val_loss: 0.5807\n",
      "Epoch 7153/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0378 - val_loss: 0.5792\n",
      "Epoch 7154/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0210 - val_loss: 0.5938\n",
      "Epoch 7155/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0106 - val_loss: 0.5843\n",
      "Epoch 7156/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0156 - val_loss: 0.6142\n",
      "Epoch 7157/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0144 - val_loss: 0.6079\n",
      "Epoch 7158/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0166 - val_loss: 0.6276\n",
      "Epoch 7159/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0247 - val_loss: 0.6112\n",
      "Epoch 7160/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0244 - val_loss: 0.6015\n",
      "Epoch 7161/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0421 - val_loss: 0.6103\n",
      "Epoch 7162/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0358 - val_loss: 0.5898\n",
      "Epoch 7163/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0201 - val_loss: 0.6100\n",
      "Epoch 7164/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0192 - val_loss: 0.5987\n",
      "Epoch 7165/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0331 - val_loss: 0.6327\n",
      "Epoch 7166/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0347 - val_loss: 0.6190\n",
      "Epoch 7167/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0314 - val_loss: 0.6185\n",
      "Epoch 7168/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0490 - val_loss: 0.6244\n",
      "Epoch 7169/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0263 - val_loss: 0.6060\n",
      "Epoch 7170/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0127 - val_loss: 0.5949\n",
      "Epoch 7171/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0239 - val_loss: 0.5908\n",
      "Epoch 7172/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0303 - val_loss: 0.6324\n",
      "Epoch 7173/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0220 - val_loss: 0.6181\n",
      "Epoch 7174/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0150 - val_loss: 0.6007\n",
      "Epoch 7175/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0183 - val_loss: 0.5806\n",
      "Epoch 7176/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0141 - val_loss: 0.6209\n",
      "Epoch 7177/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0182 - val_loss: 0.6462\n",
      "Epoch 7178/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0242 - val_loss: 0.6066\n",
      "Epoch 7179/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0326 - val_loss: 0.6259\n",
      "Epoch 7180/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0341 - val_loss: 0.6588\n",
      "Epoch 7181/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0335 - val_loss: 0.6362\n",
      "Epoch 7182/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0297 - val_loss: 0.6047\n",
      "Epoch 7183/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0160 - val_loss: 0.6149\n",
      "Epoch 7184/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0114 - val_loss: 0.5981\n",
      "Epoch 7185/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0144 - val_loss: 0.6161\n",
      "Epoch 7186/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0200 - val_loss: 0.6121\n",
      "Epoch 7187/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0194 - val_loss: 0.6333\n",
      "Epoch 7188/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0217 - val_loss: 0.5943\n",
      "Epoch 7189/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0300 - val_loss: 0.6069\n",
      "Epoch 7190/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0215 - val_loss: 0.6041\n",
      "Epoch 7191/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0285 - val_loss: 0.5969\n",
      "Epoch 7192/10000\n",
      "130/130 [==============================] - 0s 851us/step - loss: 0.0367 - val_loss: 0.5949\n",
      "Epoch 7193/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0250 - val_loss: 0.5889\n",
      "Epoch 7194/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0156 - val_loss: 0.5986\n",
      "Epoch 7195/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0202 - val_loss: 0.5976\n",
      "Epoch 7196/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0179 - val_loss: 0.5877\n",
      "Epoch 7197/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0120 - val_loss: 0.5854\n",
      "Epoch 7198/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0121 - val_loss: 0.6064\n",
      "Epoch 7199/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0272 - val_loss: 0.6271\n",
      "Epoch 7200/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0494 - val_loss: 0.6219\n",
      "Epoch 7201/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0529 - val_loss: 0.6338\n",
      "Epoch 7202/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0271 - val_loss: 0.6214\n",
      "Epoch 7203/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0179 - val_loss: 0.6061\n",
      "Epoch 7204/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0135 - val_loss: 0.5849\n",
      "Epoch 7205/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0197 - val_loss: 0.6117\n",
      "Epoch 7206/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0136 - val_loss: 0.6081\n",
      "Epoch 7207/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0272 - val_loss: 0.6308\n",
      "Epoch 7208/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0476 - val_loss: 0.6126\n",
      "Epoch 7209/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0260 - val_loss: 0.6243\n",
      "Epoch 7210/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0168 - val_loss: 0.6003\n",
      "Epoch 7211/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0119 - val_loss: 0.5894\n",
      "Epoch 7212/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0314 - val_loss: 0.5816\n",
      "Epoch 7213/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0459 - val_loss: 0.6100\n",
      "Epoch 7214/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0314 - val_loss: 0.5889\n",
      "Epoch 7215/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0146 - val_loss: 0.6297\n",
      "Epoch 7216/10000\n",
      "130/130 [==============================] - 0s 820us/step - loss: 0.0116 - val_loss: 0.6169\n",
      "Epoch 7217/10000\n",
      "130/130 [==============================] - 0s 894us/step - loss: 0.0150 - val_loss: 0.5962\n",
      "Epoch 7218/10000\n",
      "130/130 [==============================] - 0s 825us/step - loss: 0.0181 - val_loss: 0.5959\n",
      "Epoch 7219/10000\n",
      "130/130 [==============================] - 0s 846us/step - loss: 0.0195 - val_loss: 0.6057\n",
      "Epoch 7220/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0139 - val_loss: 0.5945\n",
      "Epoch 7221/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0171 - val_loss: 0.6308\n",
      "Epoch 7222/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0215 - val_loss: 0.6050\n",
      "Epoch 7223/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 769us/step - loss: 0.0937 - val_loss: 0.6212\n",
      "Epoch 7224/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0797 - val_loss: 0.5955\n",
      "Epoch 7225/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0313 - val_loss: 0.6068\n",
      "Epoch 7226/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0195 - val_loss: 0.6046\n",
      "Epoch 7227/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0203 - val_loss: 0.5790\n",
      "Epoch 7228/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0123 - val_loss: 0.6035\n",
      "Epoch 7229/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0102 - val_loss: 0.5960\n",
      "Epoch 7230/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0105 - val_loss: 0.6080\n",
      "Epoch 7231/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0141 - val_loss: 0.6116\n",
      "Epoch 7232/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0456 - val_loss: 0.6005\n",
      "Epoch 7233/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0324 - val_loss: 0.6035\n",
      "Epoch 7234/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0127 - val_loss: 0.5969\n",
      "Epoch 7235/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0203 - val_loss: 0.6126\n",
      "Epoch 7236/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.5998\n",
      "Epoch 7237/10000\n",
      "130/130 [==============================] - 0s 950us/step - loss: 0.0272 - val_loss: 0.6198\n",
      "Epoch 7238/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0211 - val_loss: 0.5953\n",
      "Epoch 7239/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0182 - val_loss: 0.5993\n",
      "Epoch 7240/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0307 - val_loss: 0.6034\n",
      "Epoch 7241/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0255 - val_loss: 0.6121\n",
      "Epoch 7242/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0147 - val_loss: 0.6147\n",
      "Epoch 7243/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0228 - val_loss: 0.6145\n",
      "Epoch 7244/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0227 - val_loss: 0.6224\n",
      "Epoch 7245/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0255 - val_loss: 0.6394\n",
      "Epoch 7246/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0262 - val_loss: 0.5959\n",
      "Epoch 7247/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0224 - val_loss: 0.6013\n",
      "Epoch 7248/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0123 - val_loss: 0.5927\n",
      "Epoch 7249/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0166 - val_loss: 0.5900\n",
      "Epoch 7250/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0185 - val_loss: 0.6103\n",
      "Epoch 7251/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0403 - val_loss: 0.5985\n",
      "Epoch 7252/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0265 - val_loss: 0.6134\n",
      "Epoch 7253/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0215 - val_loss: 0.5925\n",
      "Epoch 7254/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0216 - val_loss: 0.5923\n",
      "Epoch 7255/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0221 - val_loss: 0.6101\n",
      "Epoch 7256/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0155 - val_loss: 0.5819\n",
      "Epoch 7257/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0194 - val_loss: 0.6067\n",
      "Epoch 7258/10000\n",
      "130/130 [==============================] - 0s 936us/step - loss: 0.0267 - val_loss: 0.6332\n",
      "Epoch 7259/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0237 - val_loss: 0.5945\n",
      "Epoch 7260/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0213 - val_loss: 0.6242\n",
      "Epoch 7261/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0507 - val_loss: 0.6158\n",
      "Epoch 7262/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0555 - val_loss: 0.6269\n",
      "Epoch 7263/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0225 - val_loss: 0.6029\n",
      "Epoch 7264/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0119 - val_loss: 0.6001\n",
      "Epoch 7265/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0132 - val_loss: 0.5970\n",
      "Epoch 7266/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0088 - val_loss: 0.6030\n",
      "Epoch 7267/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0121 - val_loss: 0.6256\n",
      "Epoch 7268/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0140 - val_loss: 0.6211\n",
      "Epoch 7269/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0110 - val_loss: 0.5975\n",
      "Epoch 7270/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0289 - val_loss: 0.6252\n",
      "Epoch 7271/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0510 - val_loss: 0.6077\n",
      "Epoch 7272/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0314 - val_loss: 0.5799\n",
      "Epoch 7273/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0350 - val_loss: 0.5898\n",
      "Epoch 7274/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0281 - val_loss: 0.5756\n",
      "Epoch 7275/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0169 - val_loss: 0.6073\n",
      "Epoch 7276/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0102 - val_loss: 0.6005\n",
      "Epoch 7277/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0258 - val_loss: 0.6053\n",
      "Epoch 7278/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0795 - val_loss: 0.6291\n",
      "Epoch 7279/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0777 - val_loss: 0.6255\n",
      "Epoch 7280/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0216 - val_loss: 0.6029\n",
      "Epoch 7281/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0141 - val_loss: 0.6448\n",
      "Epoch 7282/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0100 - val_loss: 0.6044\n",
      "Epoch 7283/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0085 - val_loss: 0.6161\n",
      "Epoch 7284/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0126 - val_loss: 0.6071\n",
      "Epoch 7285/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0147 - val_loss: 0.6295\n",
      "Epoch 7286/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0191 - val_loss: 0.6150\n",
      "Epoch 7287/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0151 - val_loss: 0.6324\n",
      "Epoch 7288/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0208 - val_loss: 0.6125\n",
      "Epoch 7289/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0168 - val_loss: 0.5796\n",
      "Epoch 7290/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0285 - val_loss: 0.6524\n",
      "Epoch 7291/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0302 - val_loss: 0.6325\n",
      "Epoch 7292/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0397 - val_loss: 0.6134\n",
      "Epoch 7293/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0381 - val_loss: 0.6215\n",
      "Epoch 7294/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0246 - val_loss: 0.6358\n",
      "Epoch 7295/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0220 - val_loss: 0.6057\n",
      "Epoch 7296/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0254 - val_loss: 0.6125\n",
      "Epoch 7297/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0207 - val_loss: 0.6074\n",
      "Epoch 7298/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0135 - val_loss: 0.5986\n",
      "Epoch 7299/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 732us/step - loss: 0.0146 - val_loss: 0.6063\n",
      "Epoch 7300/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0093 - val_loss: 0.6225\n",
      "Epoch 7301/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0094 - val_loss: 0.6074\n",
      "Epoch 7302/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0190 - val_loss: 0.6053\n",
      "Epoch 7303/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0547 - val_loss: 0.6368\n",
      "Epoch 7304/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0821 - val_loss: 0.6119\n",
      "Epoch 7305/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0403 - val_loss: 0.6198\n",
      "Epoch 7306/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0227 - val_loss: 0.6402\n",
      "Epoch 7307/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0183 - val_loss: 0.6130\n",
      "Epoch 7308/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0148 - val_loss: 0.5977\n",
      "Epoch 7309/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0187 - val_loss: 0.5916\n",
      "Epoch 7310/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0180 - val_loss: 0.6127\n",
      "Epoch 7311/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0193 - val_loss: 0.6062\n",
      "Epoch 7312/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0167 - val_loss: 0.5929\n",
      "Epoch 7313/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0189 - val_loss: 0.6029\n",
      "Epoch 7314/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0221 - val_loss: 0.6075\n",
      "Epoch 7315/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0231 - val_loss: 0.6058\n",
      "Epoch 7316/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0304 - val_loss: 0.6016\n",
      "Epoch 7317/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0212 - val_loss: 0.6118\n",
      "Epoch 7318/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0183 - val_loss: 0.6106\n",
      "Epoch 7319/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0207 - val_loss: 0.5918\n",
      "Epoch 7320/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0180 - val_loss: 0.6365\n",
      "Epoch 7321/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0168 - val_loss: 0.6012\n",
      "Epoch 7322/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0182 - val_loss: 0.6331\n",
      "Epoch 7323/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0174 - val_loss: 0.5938\n",
      "Epoch 7324/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0298 - val_loss: 0.5713\n",
      "Epoch 7325/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0247 - val_loss: 0.6092\n",
      "Epoch 7326/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0331 - val_loss: 0.5980\n",
      "Epoch 7327/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0307 - val_loss: 0.6015\n",
      "Epoch 7328/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0215 - val_loss: 0.6170\n",
      "Epoch 7329/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0124 - val_loss: 0.5888\n",
      "Epoch 7330/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0226 - val_loss: 0.6151\n",
      "Epoch 7331/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0175 - val_loss: 0.5849\n",
      "Epoch 7332/10000\n",
      "130/130 [==============================] - 0s 880us/step - loss: 0.0452 - val_loss: 0.6307\n",
      "Epoch 7333/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0364 - val_loss: 0.6201\n",
      "Epoch 7334/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0238 - val_loss: 0.6296\n",
      "Epoch 7335/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0183 - val_loss: 0.6397\n",
      "Epoch 7336/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0320 - val_loss: 0.5957\n",
      "Epoch 7337/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0405 - val_loss: 0.5824\n",
      "Epoch 7338/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0341 - val_loss: 0.5816\n",
      "Epoch 7339/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0241 - val_loss: 0.6290\n",
      "Epoch 7340/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0235 - val_loss: 0.6116\n",
      "Epoch 7341/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0193 - val_loss: 0.6039\n",
      "Epoch 7342/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0140 - val_loss: 0.6051\n",
      "Epoch 7343/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0073 - val_loss: 0.6192\n",
      "Epoch 7344/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0072 - val_loss: 0.6018\n",
      "Epoch 7345/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0068 - val_loss: 0.6171\n",
      "Epoch 7346/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0125 - val_loss: 0.5883\n",
      "Epoch 7347/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0359 - val_loss: 0.5861\n",
      "Epoch 7348/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0489 - val_loss: 0.6206\n",
      "Epoch 7349/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0498 - val_loss: 0.6129\n",
      "Epoch 7350/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0187 - val_loss: 0.6130\n",
      "Epoch 7351/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0146 - val_loss: 0.5900\n",
      "Epoch 7352/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0189 - val_loss: 0.6223\n",
      "Epoch 7353/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0193 - val_loss: 0.6129\n",
      "Epoch 7354/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0156 - val_loss: 0.6108\n",
      "Epoch 7355/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0198 - val_loss: 0.6196\n",
      "Epoch 7356/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0232 - val_loss: 0.5823\n",
      "Epoch 7357/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0310 - val_loss: 0.6261\n",
      "Epoch 7358/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0336 - val_loss: 0.6372\n",
      "Epoch 7359/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0279 - val_loss: 0.5847\n",
      "Epoch 7360/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0206 - val_loss: 0.6076\n",
      "Epoch 7361/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0176 - val_loss: 0.6328\n",
      "Epoch 7362/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0242 - val_loss: 0.6109\n",
      "Epoch 7363/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0247 - val_loss: 0.6023\n",
      "Epoch 7364/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0273 - val_loss: 0.6441\n",
      "Epoch 7365/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0272 - val_loss: 0.6168\n",
      "Epoch 7366/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0259 - val_loss: 0.6276\n",
      "Epoch 7367/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0191 - val_loss: 0.6137\n",
      "Epoch 7368/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0100 - val_loss: 0.6230\n",
      "Epoch 7369/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0131 - val_loss: 0.5934\n",
      "Epoch 7370/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0252 - val_loss: 0.6088\n",
      "Epoch 7371/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0252 - val_loss: 0.6224\n",
      "Epoch 7372/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0219 - val_loss: 0.6197\n",
      "Epoch 7373/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0280 - val_loss: 0.5962\n",
      "Epoch 7374/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0379 - val_loss: 0.6166\n",
      "Epoch 7375/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 765us/step - loss: 0.0294 - val_loss: 0.6111\n",
      "Epoch 7376/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0249 - val_loss: 0.6089\n",
      "Epoch 7377/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0291 - val_loss: 0.5824\n",
      "Epoch 7378/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0261 - val_loss: 0.6015\n",
      "Epoch 7379/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0191 - val_loss: 0.6089\n",
      "Epoch 7380/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0125 - val_loss: 0.6108\n",
      "Epoch 7381/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0102 - val_loss: 0.6243\n",
      "Epoch 7382/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0171 - val_loss: 0.6294\n",
      "Epoch 7383/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0361 - val_loss: 0.6086\n",
      "Epoch 7384/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0322 - val_loss: 0.5963\n",
      "Epoch 7385/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0348 - val_loss: 0.5941\n",
      "Epoch 7386/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0236 - val_loss: 0.5917\n",
      "Epoch 7387/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0168 - val_loss: 0.6113\n",
      "Epoch 7388/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0249 - val_loss: 0.6315\n",
      "Epoch 7389/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0391 - val_loss: 0.6158\n",
      "Epoch 7390/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0468 - val_loss: 0.6375\n",
      "Epoch 7391/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0288 - val_loss: 0.5909\n",
      "Epoch 7392/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0271 - val_loss: 0.5858\n",
      "Epoch 7393/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0127 - val_loss: 0.6009\n",
      "Epoch 7394/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0152 - val_loss: 0.5861\n",
      "Epoch 7395/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0169 - val_loss: 0.5982\n",
      "Epoch 7396/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0115 - val_loss: 0.6169\n",
      "Epoch 7397/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0118 - val_loss: 0.6046\n",
      "Epoch 7398/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0122 - val_loss: 0.6135\n",
      "Epoch 7399/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0135 - val_loss: 0.6026\n",
      "Epoch 7400/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0218 - val_loss: 0.6107\n",
      "Epoch 7401/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0390 - val_loss: 0.6359\n",
      "Epoch 7402/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0342 - val_loss: 0.5792\n",
      "Epoch 7403/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0393 - val_loss: 0.5899\n",
      "Epoch 7404/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0263 - val_loss: 0.6174\n",
      "Epoch 7405/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0435 - val_loss: 0.6244\n",
      "Epoch 7406/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0239 - val_loss: 0.6075\n",
      "Epoch 7407/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0161 - val_loss: 0.6448\n",
      "Epoch 7408/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0338 - val_loss: 0.6076\n",
      "Epoch 7409/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0202 - val_loss: 0.6152\n",
      "Epoch 7410/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0278 - val_loss: 0.5990\n",
      "Epoch 7411/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0352 - val_loss: 0.5937\n",
      "Epoch 7412/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0457 - val_loss: 0.6017\n",
      "Epoch 7413/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0220 - val_loss: 0.6038\n",
      "Epoch 7414/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0171 - val_loss: 0.5863\n",
      "Epoch 7415/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0158 - val_loss: 0.5860\n",
      "Epoch 7416/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0169 - val_loss: 0.6051\n",
      "Epoch 7417/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0172 - val_loss: 0.6090\n",
      "Epoch 7418/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0140 - val_loss: 0.6115\n",
      "Epoch 7419/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0132 - val_loss: 0.6155\n",
      "Epoch 7420/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0303 - val_loss: 0.6285\n",
      "Epoch 7421/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0664 - val_loss: 0.6198\n",
      "Epoch 7422/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0358 - val_loss: 0.5792\n",
      "Epoch 7423/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0186 - val_loss: 0.5957\n",
      "Epoch 7424/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0147 - val_loss: 0.6080\n",
      "Epoch 7425/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0137 - val_loss: 0.6155\n",
      "Epoch 7426/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0137 - val_loss: 0.5831\n",
      "Epoch 7427/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0177 - val_loss: 0.6019\n",
      "Epoch 7428/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0365 - val_loss: 0.6004\n",
      "Epoch 7429/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0167 - val_loss: 0.5891\n",
      "Epoch 7430/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0182 - val_loss: 0.5930\n",
      "Epoch 7431/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0138 - val_loss: 0.6157\n",
      "Epoch 7432/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0211 - val_loss: 0.6311\n",
      "Epoch 7433/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0123 - val_loss: 0.6032\n",
      "Epoch 7434/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0233 - val_loss: 0.6108\n",
      "Epoch 7435/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0361 - val_loss: 0.6229\n",
      "Epoch 7436/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0496 - val_loss: 0.6188\n",
      "Epoch 7437/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0403 - val_loss: 0.6029\n",
      "Epoch 7438/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0227 - val_loss: 0.6386\n",
      "Epoch 7439/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0256 - val_loss: 0.6112\n",
      "Epoch 7440/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0169 - val_loss: 0.6204\n",
      "Epoch 7441/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0122 - val_loss: 0.6197\n",
      "Epoch 7442/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0137 - val_loss: 0.6043\n",
      "Epoch 7443/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0350 - val_loss: 0.6163\n",
      "Epoch 7444/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0316 - val_loss: 0.6062\n",
      "Epoch 7445/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0261 - val_loss: 0.6209\n",
      "Epoch 7446/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0182 - val_loss: 0.6121\n",
      "Epoch 7447/10000\n",
      "130/130 [==============================] - 0s 810us/step - loss: 0.0262 - val_loss: 0.6302\n",
      "Epoch 7448/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0163 - val_loss: 0.6203\n",
      "Epoch 7449/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0250 - val_loss: 0.6171\n",
      "Epoch 7450/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0293 - val_loss: 0.6127\n",
      "Epoch 7451/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 781us/step - loss: 0.0343 - val_loss: 0.5800\n",
      "Epoch 7452/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0190 - val_loss: 0.5940\n",
      "Epoch 7453/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0272 - val_loss: 0.6161\n",
      "Epoch 7454/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0223 - val_loss: 0.6195\n",
      "Epoch 7455/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0304 - val_loss: 0.6095\n",
      "Epoch 7456/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0495 - val_loss: 0.6215\n",
      "Epoch 7457/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0215 - val_loss: 0.6064\n",
      "Epoch 7458/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0263 - val_loss: 0.5845\n",
      "Epoch 7459/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0174 - val_loss: 0.5970\n",
      "Epoch 7460/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0149 - val_loss: 0.5882\n",
      "Epoch 7461/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0096 - val_loss: 0.5914\n",
      "Epoch 7462/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0109 - val_loss: 0.6052\n",
      "Epoch 7463/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0089 - val_loss: 0.6044\n",
      "Epoch 7464/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0259 - val_loss: 0.6121\n",
      "Epoch 7465/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0505 - val_loss: 0.6024\n",
      "Epoch 7466/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0294 - val_loss: 0.6152\n",
      "Epoch 7467/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0124 - val_loss: 0.6003\n",
      "Epoch 7468/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0173 - val_loss: 0.5999\n",
      "Epoch 7469/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0312 - val_loss: 0.5983\n",
      "Epoch 7470/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0284 - val_loss: 0.5992\n",
      "Epoch 7471/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0274 - val_loss: 0.6068\n",
      "Epoch 7472/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0350 - val_loss: 0.6094\n",
      "Epoch 7473/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0160 - val_loss: 0.6101\n",
      "Epoch 7474/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0192 - val_loss: 0.6195\n",
      "Epoch 7475/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0251 - val_loss: 0.5998\n",
      "Epoch 7476/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0157 - val_loss: 0.5998\n",
      "Epoch 7477/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0262 - val_loss: 0.6181\n",
      "Epoch 7478/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0379 - val_loss: 0.5993\n",
      "Epoch 7479/10000\n",
      "130/130 [==============================] - 0s 896us/step - loss: 0.0236 - val_loss: 0.6257\n",
      "Epoch 7480/10000\n",
      "130/130 [==============================] - 0s 857us/step - loss: 0.0192 - val_loss: 0.5858\n",
      "Epoch 7481/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0252 - val_loss: 0.6162\n",
      "Epoch 7482/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0260 - val_loss: 0.5999\n",
      "Epoch 7483/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0134 - val_loss: 0.6148\n",
      "Epoch 7484/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0154 - val_loss: 0.6174\n",
      "Epoch 7485/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0150 - val_loss: 0.5965\n",
      "Epoch 7486/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0149 - val_loss: 0.5836\n",
      "Epoch 7487/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0215 - val_loss: 0.6530\n",
      "Epoch 7488/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0224 - val_loss: 0.6064\n",
      "Epoch 7489/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0195 - val_loss: 0.6137\n",
      "Epoch 7490/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0202 - val_loss: 0.5938\n",
      "Epoch 7491/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0188 - val_loss: 0.5960\n",
      "Epoch 7492/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0312 - val_loss: 0.6035\n",
      "Epoch 7493/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0332 - val_loss: 0.6206\n",
      "Epoch 7494/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0339 - val_loss: 0.6349\n",
      "Epoch 7495/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0137 - val_loss: 0.6211\n",
      "Epoch 7496/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0135 - val_loss: 0.6162\n",
      "Epoch 7497/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0110 - val_loss: 0.6155\n",
      "Epoch 7498/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0145 - val_loss: 0.6038\n",
      "Epoch 7499/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0229 - val_loss: 0.6230\n",
      "Epoch 7500/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0321 - val_loss: 0.6258\n",
      "Epoch 7501/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0362 - val_loss: 0.6327\n",
      "Epoch 7502/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0390 - val_loss: 0.6029\n",
      "Epoch 7503/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0385 - val_loss: 0.6278\n",
      "Epoch 7504/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0555 - val_loss: 0.6199\n",
      "Epoch 7505/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0377 - val_loss: 0.6160\n",
      "Epoch 7506/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0213 - val_loss: 0.5936\n",
      "Epoch 7507/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0132 - val_loss: 0.5963\n",
      "Epoch 7508/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0168 - val_loss: 0.6071\n",
      "Epoch 7509/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0168 - val_loss: 0.5995\n",
      "Epoch 7510/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0187 - val_loss: 0.6330\n",
      "Epoch 7511/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0152 - val_loss: 0.6198\n",
      "Epoch 7512/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0143 - val_loss: 0.6360\n",
      "Epoch 7513/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0259 - val_loss: 0.6158\n",
      "Epoch 7514/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0385 - val_loss: 0.6334\n",
      "Epoch 7515/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0274 - val_loss: 0.5947\n",
      "Epoch 7516/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0177 - val_loss: 0.6052\n",
      "Epoch 7517/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0175 - val_loss: 0.6190\n",
      "Epoch 7518/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0223 - val_loss: 0.5906\n",
      "Epoch 7519/10000\n",
      "130/130 [==============================] - 0s 873us/step - loss: 0.0261 - val_loss: 0.6132\n",
      "Epoch 7520/10000\n",
      "130/130 [==============================] - 0s 868us/step - loss: 0.0168 - val_loss: 0.6017\n",
      "Epoch 7521/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0147 - val_loss: 0.6023\n",
      "Epoch 7522/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0217 - val_loss: 0.6343\n",
      "Epoch 7523/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0355 - val_loss: 0.6169\n",
      "Epoch 7524/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0338 - val_loss: 0.6115\n",
      "Epoch 7525/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0224 - val_loss: 0.6650\n",
      "Epoch 7526/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0193 - val_loss: 0.5921\n",
      "Epoch 7527/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 766us/step - loss: 0.0149 - val_loss: 0.6220\n",
      "Epoch 7528/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0134 - val_loss: 0.6256\n",
      "Epoch 7529/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0167 - val_loss: 0.6290\n",
      "Epoch 7530/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0309 - val_loss: 0.6030\n",
      "Epoch 7531/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0191 - val_loss: 0.6191\n",
      "Epoch 7532/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0123 - val_loss: 0.5957\n",
      "Epoch 7533/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0279 - val_loss: 0.6133\n",
      "Epoch 7534/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0255 - val_loss: 0.6279\n",
      "Epoch 7535/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0254 - val_loss: 0.6326\n",
      "Epoch 7536/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0244 - val_loss: 0.6205\n",
      "Epoch 7537/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0218 - val_loss: 0.6002\n",
      "Epoch 7538/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0202 - val_loss: 0.6069\n",
      "Epoch 7539/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0279 - val_loss: 0.6020\n",
      "Epoch 7540/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0279 - val_loss: 0.6120\n",
      "Epoch 7541/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0285 - val_loss: 0.6105\n",
      "Epoch 7542/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0228 - val_loss: 0.6217\n",
      "Epoch 7543/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0176 - val_loss: 0.5795\n",
      "Epoch 7544/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0164 - val_loss: 0.6097\n",
      "Epoch 7545/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0253 - val_loss: 0.6156\n",
      "Epoch 7546/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0299 - val_loss: 0.5792\n",
      "Epoch 7547/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0312 - val_loss: 0.5941\n",
      "Epoch 7548/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0193 - val_loss: 0.6104\n",
      "Epoch 7549/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0141 - val_loss: 0.6136\n",
      "Epoch 7550/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0139 - val_loss: 0.6095\n",
      "Epoch 7551/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0252 - val_loss: 0.6185\n",
      "Epoch 7552/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0456 - val_loss: 0.6248\n",
      "Epoch 7553/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0495 - val_loss: 0.6100\n",
      "Epoch 7554/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0221 - val_loss: 0.5994\n",
      "Epoch 7555/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0137 - val_loss: 0.6074\n",
      "Epoch 7556/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0157 - val_loss: 0.6178\n",
      "Epoch 7557/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0268 - val_loss: 0.5806\n",
      "Epoch 7558/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0389 - val_loss: 0.6300\n",
      "Epoch 7559/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0237 - val_loss: 0.6274\n",
      "Epoch 7560/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0247 - val_loss: 0.6144\n",
      "Epoch 7561/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0330 - val_loss: 0.6062\n",
      "Epoch 7562/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0303 - val_loss: 0.6150\n",
      "Epoch 7563/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0194 - val_loss: 0.6042\n",
      "Epoch 7564/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0097 - val_loss: 0.6057\n",
      "Epoch 7565/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0103 - val_loss: 0.6164\n",
      "Epoch 7566/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0110 - val_loss: 0.6061\n",
      "Epoch 7567/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0092 - val_loss: 0.6102\n",
      "Epoch 7568/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0174 - val_loss: 0.6234\n",
      "Epoch 7569/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0400 - val_loss: 0.5801\n",
      "Epoch 7570/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0526 - val_loss: 0.6416\n",
      "Epoch 7571/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0367 - val_loss: 0.5893\n",
      "Epoch 7572/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0202 - val_loss: 0.6182\n",
      "Epoch 7573/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0241 - val_loss: 0.6023\n",
      "Epoch 7574/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0227 - val_loss: 0.6003\n",
      "Epoch 7575/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0194 - val_loss: 0.6002\n",
      "Epoch 7576/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0113 - val_loss: 0.5876\n",
      "Epoch 7577/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0153 - val_loss: 0.5851\n",
      "Epoch 7578/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0290 - val_loss: 0.6072\n",
      "Epoch 7579/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0238 - val_loss: 0.6051\n",
      "Epoch 7580/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0205 - val_loss: 0.5843\n",
      "Epoch 7581/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0176 - val_loss: 0.6239\n",
      "Epoch 7582/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0207 - val_loss: 0.6031\n",
      "Epoch 7583/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0407 - val_loss: 0.6330\n",
      "Epoch 7584/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0265 - val_loss: 0.6185\n",
      "Epoch 7585/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0145 - val_loss: 0.6080\n",
      "Epoch 7586/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0241 - val_loss: 0.6173\n",
      "Epoch 7587/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0201 - val_loss: 0.5921\n",
      "Epoch 7588/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0204 - val_loss: 0.6026\n",
      "Epoch 7589/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0160 - val_loss: 0.5819\n",
      "Epoch 7590/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0241 - val_loss: 0.5974\n",
      "Epoch 7591/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0305 - val_loss: 0.6063\n",
      "Epoch 7592/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0399 - val_loss: 0.6094\n",
      "Epoch 7593/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0307 - val_loss: 0.6025\n",
      "Epoch 7594/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0206 - val_loss: 0.5871\n",
      "Epoch 7595/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0217 - val_loss: 0.5924\n",
      "Epoch 7596/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0211 - val_loss: 0.6063\n",
      "Epoch 7597/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0257 - val_loss: 0.6082\n",
      "Epoch 7598/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0506 - val_loss: 0.6046\n",
      "Epoch 7599/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0460 - val_loss: 0.6215\n",
      "Epoch 7600/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0337 - val_loss: 0.5877\n",
      "Epoch 7601/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0110 - val_loss: 0.5991\n",
      "Epoch 7602/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0070 - val_loss: 0.6179\n",
      "Epoch 7603/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 760us/step - loss: 0.0108 - val_loss: 0.6030\n",
      "Epoch 7604/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0131 - val_loss: 0.5819\n",
      "Epoch 7605/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0182 - val_loss: 0.5877\n",
      "Epoch 7606/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0222 - val_loss: 0.6193\n",
      "Epoch 7607/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0220 - val_loss: 0.6001\n",
      "Epoch 7608/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0257 - val_loss: 0.6038\n",
      "Epoch 7609/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0327 - val_loss: 0.6003\n",
      "Epoch 7610/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0267 - val_loss: 0.6113\n",
      "Epoch 7611/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0390 - val_loss: 0.6205\n",
      "Epoch 7612/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0223 - val_loss: 0.5844\n",
      "Epoch 7613/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0126 - val_loss: 0.6183\n",
      "Epoch 7614/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0173 - val_loss: 0.6077\n",
      "Epoch 7615/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0610 - val_loss: 0.6736\n",
      "Epoch 7616/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0438 - val_loss: 0.6040\n",
      "Epoch 7617/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0243 - val_loss: 0.6001\n",
      "Epoch 7618/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0104 - val_loss: 0.6127\n",
      "Epoch 7619/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0099 - val_loss: 0.6045\n",
      "Epoch 7620/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0140 - val_loss: 0.6061\n",
      "Epoch 7621/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0197 - val_loss: 0.6166\n",
      "Epoch 7622/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0594 - val_loss: 0.6122\n",
      "Epoch 7623/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0654 - val_loss: 0.6018\n",
      "Epoch 7624/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0358 - val_loss: 0.6341\n",
      "Epoch 7625/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0210 - val_loss: 0.6162\n",
      "Epoch 7626/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0118 - val_loss: 0.6140\n",
      "Epoch 7627/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0117 - val_loss: 0.6233\n",
      "Epoch 7628/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0135 - val_loss: 0.5891\n",
      "Epoch 7629/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0138 - val_loss: 0.5768\n",
      "Epoch 7630/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0142 - val_loss: 0.6103\n",
      "Epoch 7631/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0178 - val_loss: 0.6260\n",
      "Epoch 7632/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0250 - val_loss: 0.6329\n",
      "Epoch 7633/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0233 - val_loss: 0.5927\n",
      "Epoch 7634/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0158 - val_loss: 0.6158\n",
      "Epoch 7635/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0202 - val_loss: 0.6044\n",
      "Epoch 7636/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0135 - val_loss: 0.6048\n",
      "Epoch 7637/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0120 - val_loss: 0.5967\n",
      "Epoch 7638/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0092 - val_loss: 0.6030\n",
      "Epoch 7639/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0622 - val_loss: 0.6081\n",
      "Epoch 7640/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0974 - val_loss: 0.6155\n",
      "Epoch 7641/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0440 - val_loss: 0.6234\n",
      "Epoch 7642/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0208 - val_loss: 0.5881\n",
      "Epoch 7643/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0178 - val_loss: 0.6203\n",
      "Epoch 7644/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0145 - val_loss: 0.6125\n",
      "Epoch 7645/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0133 - val_loss: 0.6215\n",
      "Epoch 7646/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0270 - val_loss: 0.6086\n",
      "Epoch 7647/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0212 - val_loss: 0.5995\n",
      "Epoch 7648/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0234 - val_loss: 0.6042\n",
      "Epoch 7649/10000\n",
      "130/130 [==============================] - 0s 826us/step - loss: 0.0158 - val_loss: 0.6142\n",
      "Epoch 7650/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0274 - val_loss: 0.5983\n",
      "Epoch 7651/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0204 - val_loss: 0.6251\n",
      "Epoch 7652/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0398 - val_loss: 0.6205\n",
      "Epoch 7653/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0381 - val_loss: 0.5796\n",
      "Epoch 7654/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0442 - val_loss: 0.6138\n",
      "Epoch 7655/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0308 - val_loss: 0.6039\n",
      "Epoch 7656/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0137 - val_loss: 0.5689\n",
      "Epoch 7657/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0080 - val_loss: 0.5994\n",
      "Epoch 7658/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0128 - val_loss: 0.5951\n",
      "Epoch 7659/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0219 - val_loss: 0.6141\n",
      "Epoch 7660/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0277 - val_loss: 0.6143\n",
      "Epoch 7661/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0313 - val_loss: 0.6390\n",
      "Epoch 7662/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0642 - val_loss: 0.5933\n",
      "Epoch 7663/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0294 - val_loss: 0.6048\n",
      "Epoch 7664/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0129 - val_loss: 0.5819\n",
      "Epoch 7665/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0132 - val_loss: 0.5893\n",
      "Epoch 7666/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0136 - val_loss: 0.6167\n",
      "Epoch 7667/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0183 - val_loss: 0.6482\n",
      "Epoch 7668/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0220 - val_loss: 0.5990\n",
      "Epoch 7669/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0193 - val_loss: 0.5965\n",
      "Epoch 7670/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0178 - val_loss: 0.6260\n",
      "Epoch 7671/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0129 - val_loss: 0.6162\n",
      "Epoch 7672/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0115 - val_loss: 0.6206\n",
      "Epoch 7673/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0150 - val_loss: 0.6145\n",
      "Epoch 7674/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0226 - val_loss: 0.6254\n",
      "Epoch 7675/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0386 - val_loss: 0.6089\n",
      "Epoch 7676/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0605 - val_loss: 0.6149\n",
      "Epoch 7677/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0455 - val_loss: 0.5911\n",
      "Epoch 7678/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0270 - val_loss: 0.6093\n",
      "Epoch 7679/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 751us/step - loss: 0.0175 - val_loss: 0.5807\n",
      "Epoch 7680/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0180 - val_loss: 0.6078\n",
      "Epoch 7681/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0153 - val_loss: 0.6188\n",
      "Epoch 7682/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0097 - val_loss: 0.5946\n",
      "Epoch 7683/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0091 - val_loss: 0.6255\n",
      "Epoch 7684/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0156 - val_loss: 0.5747\n",
      "Epoch 7685/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0426 - val_loss: 0.6228\n",
      "Epoch 7686/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0381 - val_loss: 0.6041\n",
      "Epoch 7687/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0149 - val_loss: 0.6087\n",
      "Epoch 7688/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0226 - val_loss: 0.6324\n",
      "Epoch 7689/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0181 - val_loss: 0.6059\n",
      "Epoch 7690/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0297 - val_loss: 0.6112\n",
      "Epoch 7691/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0419 - val_loss: 0.6214\n",
      "Epoch 7692/10000\n",
      "130/130 [==============================] - 0s 803us/step - loss: 0.0303 - val_loss: 0.5861\n",
      "Epoch 7693/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0247 - val_loss: 0.6052\n",
      "Epoch 7694/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0245 - val_loss: 0.6122\n",
      "Epoch 7695/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0151 - val_loss: 0.6112\n",
      "Epoch 7696/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0174 - val_loss: 0.5996\n",
      "Epoch 7697/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0162 - val_loss: 0.6175\n",
      "Epoch 7698/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0181 - val_loss: 0.5945\n",
      "Epoch 7699/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0249 - val_loss: 0.6049\n",
      "Epoch 7700/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0227 - val_loss: 0.6079\n",
      "Epoch 7701/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0200 - val_loss: 0.6285\n",
      "Epoch 7702/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0209 - val_loss: 0.5910\n",
      "Epoch 7703/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0340 - val_loss: 0.5810\n",
      "Epoch 7704/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0254 - val_loss: 0.6099\n",
      "Epoch 7705/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0144 - val_loss: 0.5961\n",
      "Epoch 7706/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0135 - val_loss: 0.6157\n",
      "Epoch 7707/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0213 - val_loss: 0.6028\n",
      "Epoch 7708/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0177 - val_loss: 0.6028\n",
      "Epoch 7709/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0272 - val_loss: 0.5798\n",
      "Epoch 7710/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0142 - val_loss: 0.6027\n",
      "Epoch 7711/10000\n",
      "130/130 [==============================] - 0s 829us/step - loss: 0.0140 - val_loss: 0.5975\n",
      "Epoch 7712/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0152 - val_loss: 0.6160\n",
      "Epoch 7713/10000\n",
      "130/130 [==============================] - 0s 809us/step - loss: 0.0744 - val_loss: 0.5866\n",
      "Epoch 7714/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0550 - val_loss: 0.5936\n",
      "Epoch 7715/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0359 - val_loss: 0.5951\n",
      "Epoch 7716/10000\n",
      "130/130 [==============================] - 0s 796us/step - loss: 0.0202 - val_loss: 0.6116\n",
      "Epoch 7717/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0128 - val_loss: 0.5996\n",
      "Epoch 7718/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0109 - val_loss: 0.5965\n",
      "Epoch 7719/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0132 - val_loss: 0.6051\n",
      "Epoch 7720/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0143 - val_loss: 0.6087\n",
      "Epoch 7721/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0154 - val_loss: 0.6220\n",
      "Epoch 7722/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0104 - val_loss: 0.6163\n",
      "Epoch 7723/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0139 - val_loss: 0.6280\n",
      "Epoch 7724/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0652 - val_loss: 0.6148\n",
      "Epoch 7725/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0497 - val_loss: 0.6334\n",
      "Epoch 7726/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0261 - val_loss: 0.6211\n",
      "Epoch 7727/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0139 - val_loss: 0.5979\n",
      "Epoch 7728/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0114 - val_loss: 0.6211\n",
      "Epoch 7729/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0078 - val_loss: 0.6174\n",
      "Epoch 7730/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0074 - val_loss: 0.6065\n",
      "Epoch 7731/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0133 - val_loss: 0.6404\n",
      "Epoch 7732/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0248 - val_loss: 0.5942\n",
      "Epoch 7733/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0376 - val_loss: 0.5976\n",
      "Epoch 7734/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0383 - val_loss: 0.6252\n",
      "Epoch 7735/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0502 - val_loss: 0.5848\n",
      "Epoch 7736/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0249 - val_loss: 0.5970\n",
      "Epoch 7737/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0220 - val_loss: 0.6055\n",
      "Epoch 7738/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0241 - val_loss: 0.6027\n",
      "Epoch 7739/10000\n",
      "130/130 [==============================] - 0s 833us/step - loss: 0.0156 - val_loss: 0.5934\n",
      "Epoch 7740/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0229 - val_loss: 0.6212\n",
      "Epoch 7741/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0242 - val_loss: 0.6181\n",
      "Epoch 7742/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0387 - val_loss: 0.5933\n",
      "Epoch 7743/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0184 - val_loss: 0.6491\n",
      "Epoch 7744/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0153 - val_loss: 0.6004\n",
      "Epoch 7745/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0102 - val_loss: 0.6035\n",
      "Epoch 7746/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0153 - val_loss: 0.6059\n",
      "Epoch 7747/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0587 - val_loss: 0.6052\n",
      "Epoch 7748/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0898 - val_loss: 0.5977\n",
      "Epoch 7749/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0541 - val_loss: 0.6082\n",
      "Epoch 7750/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0172 - val_loss: 0.6070\n",
      "Epoch 7751/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0133 - val_loss: 0.6152\n",
      "Epoch 7752/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0166 - val_loss: 0.5950\n",
      "Epoch 7753/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0121 - val_loss: 0.6142\n",
      "Epoch 7754/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0173 - val_loss: 0.6034\n",
      "Epoch 7755/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 746us/step - loss: 0.0240 - val_loss: 0.6206\n",
      "Epoch 7756/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0183 - val_loss: 0.6254\n",
      "Epoch 7757/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0143 - val_loss: 0.6084\n",
      "Epoch 7758/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0117 - val_loss: 0.6183\n",
      "Epoch 7759/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0100 - val_loss: 0.6222\n",
      "Epoch 7760/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0078 - val_loss: 0.6339\n",
      "Epoch 7761/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0111 - val_loss: 0.6016\n",
      "Epoch 7762/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0211 - val_loss: 0.6114\n",
      "Epoch 7763/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0547 - val_loss: 0.6027\n",
      "Epoch 7764/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0386 - val_loss: 0.5770\n",
      "Epoch 7765/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0312 - val_loss: 0.6377\n",
      "Epoch 7766/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0281 - val_loss: 0.5968\n",
      "Epoch 7767/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0212 - val_loss: 0.5990\n",
      "Epoch 7768/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0177 - val_loss: 0.5760\n",
      "Epoch 7769/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0162 - val_loss: 0.5955\n",
      "Epoch 7770/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0163 - val_loss: 0.5664\n",
      "Epoch 7771/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0168 - val_loss: 0.6056\n",
      "Epoch 7772/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0166 - val_loss: 0.6074\n",
      "Epoch 7773/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0461 - val_loss: 0.6401\n",
      "Epoch 7774/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0574 - val_loss: 0.6001\n",
      "Epoch 7775/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0304 - val_loss: 0.5924\n",
      "Epoch 7776/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0213 - val_loss: 0.5900\n",
      "Epoch 7777/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0129 - val_loss: 0.6132\n",
      "Epoch 7778/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0164 - val_loss: 0.6439\n",
      "Epoch 7779/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0180 - val_loss: 0.5989\n",
      "Epoch 7780/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0137 - val_loss: 0.5998\n",
      "Epoch 7781/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0183 - val_loss: 0.6043\n",
      "Epoch 7782/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0221 - val_loss: 0.5942\n",
      "Epoch 7783/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0296 - val_loss: 0.5931\n",
      "Epoch 7784/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0209 - val_loss: 0.6002\n",
      "Epoch 7785/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0174 - val_loss: 0.5795\n",
      "Epoch 7786/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0139 - val_loss: 0.6008\n",
      "Epoch 7787/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0113 - val_loss: 0.6220\n",
      "Epoch 7788/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0157 - val_loss: 0.6039\n",
      "Epoch 7789/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0422 - val_loss: 0.5931\n",
      "Epoch 7790/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0456 - val_loss: 0.5985\n",
      "Epoch 7791/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0296 - val_loss: 0.5845\n",
      "Epoch 7792/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0162 - val_loss: 0.6141\n",
      "Epoch 7793/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0229 - val_loss: 0.6363\n",
      "Epoch 7794/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0181 - val_loss: 0.6068\n",
      "Epoch 7795/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0280 - val_loss: 0.6180\n",
      "Epoch 7796/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0231 - val_loss: 0.6093\n",
      "Epoch 7797/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0184 - val_loss: 0.6083\n",
      "Epoch 7798/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0283 - val_loss: 0.6008\n",
      "Epoch 7799/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0303 - val_loss: 0.5934\n",
      "Epoch 7800/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0143 - val_loss: 0.6195\n",
      "Epoch 7801/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0165 - val_loss: 0.6478\n",
      "Epoch 7802/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0310 - val_loss: 0.5959\n",
      "Epoch 7803/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0291 - val_loss: 0.6078\n",
      "Epoch 7804/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0415 - val_loss: 0.6073\n",
      "Epoch 7805/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0283 - val_loss: 0.6129\n",
      "Epoch 7806/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0160 - val_loss: 0.6205\n",
      "Epoch 7807/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0153 - val_loss: 0.6320\n",
      "Epoch 7808/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0196 - val_loss: 0.6167\n",
      "Epoch 7809/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0088 - val_loss: 0.6206\n",
      "Epoch 7810/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0155 - val_loss: 0.6083\n",
      "Epoch 7811/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0229 - val_loss: 0.6180\n",
      "Epoch 7812/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0245 - val_loss: 0.6387\n",
      "Epoch 7813/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0434 - val_loss: 0.6230\n",
      "Epoch 7814/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0592 - val_loss: 0.5963\n",
      "Epoch 7815/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0274 - val_loss: 0.6120\n",
      "Epoch 7816/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0174 - val_loss: 0.6047\n",
      "Epoch 7817/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0145 - val_loss: 0.5743\n",
      "Epoch 7818/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0113 - val_loss: 0.6205\n",
      "Epoch 7819/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0083 - val_loss: 0.6026\n",
      "Epoch 7820/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0077 - val_loss: 0.6030\n",
      "Epoch 7821/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0078 - val_loss: 0.6046\n",
      "Epoch 7822/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0074 - val_loss: 0.5939\n",
      "Epoch 7823/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0060 - val_loss: 0.6007\n",
      "Epoch 7824/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0405 - val_loss: 0.6258\n",
      "Epoch 7825/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0855 - val_loss: 0.6216\n",
      "Epoch 7826/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0601 - val_loss: 0.5935\n",
      "Epoch 7827/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0487 - val_loss: 0.6257\n",
      "Epoch 7828/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0315 - val_loss: 0.5806\n",
      "Epoch 7829/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0265 - val_loss: 0.6158\n",
      "Epoch 7830/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0159 - val_loss: 0.5904\n",
      "Epoch 7831/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 759us/step - loss: 0.0120 - val_loss: 0.6001\n",
      "Epoch 7832/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0174 - val_loss: 0.5660\n",
      "Epoch 7833/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0134 - val_loss: 0.5791\n",
      "Epoch 7834/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0089 - val_loss: 0.5882\n",
      "Epoch 7835/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0133 - val_loss: 0.5795\n",
      "Epoch 7836/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0110 - val_loss: 0.6020\n",
      "Epoch 7837/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0113 - val_loss: 0.6127\n",
      "Epoch 7838/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0637 - val_loss: 0.6058\n",
      "Epoch 7839/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1313 - val_loss: 0.6121\n",
      "Epoch 7840/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0566 - val_loss: 0.6241\n",
      "Epoch 7841/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0195 - val_loss: 0.6122\n",
      "Epoch 7842/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0141 - val_loss: 0.6269\n",
      "Epoch 7843/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0175 - val_loss: 0.5927\n",
      "Epoch 7844/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0132 - val_loss: 0.5930\n",
      "Epoch 7845/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0117 - val_loss: 0.6099\n",
      "Epoch 7846/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0148 - val_loss: 0.5914\n",
      "Epoch 7847/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0189 - val_loss: 0.6031\n",
      "Epoch 7848/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0144 - val_loss: 0.6117\n",
      "Epoch 7849/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0122 - val_loss: 0.5964\n",
      "Epoch 7850/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0506 - val_loss: 0.5698\n",
      "Epoch 7851/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0424 - val_loss: 0.5887\n",
      "Epoch 7852/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0324 - val_loss: 0.6138\n",
      "Epoch 7853/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0261 - val_loss: 0.6249\n",
      "Epoch 7854/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0175 - val_loss: 0.6230\n",
      "Epoch 7855/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0177 - val_loss: 0.6213\n",
      "Epoch 7856/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0146 - val_loss: 0.6168\n",
      "Epoch 7857/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0096 - val_loss: 0.6099\n",
      "Epoch 7858/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0099 - val_loss: 0.5958\n",
      "Epoch 7859/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0145 - val_loss: 0.6703\n",
      "Epoch 7860/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0417 - val_loss: 0.6136\n",
      "Epoch 7861/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0491 - val_loss: 0.5809\n",
      "Epoch 7862/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0528 - val_loss: 0.6179\n",
      "Epoch 7863/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0374 - val_loss: 0.6294\n",
      "Epoch 7864/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0183 - val_loss: 0.5976\n",
      "Epoch 7865/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0101 - val_loss: 0.5929\n",
      "Epoch 7866/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0071 - val_loss: 0.6065\n",
      "Epoch 7867/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0074 - val_loss: 0.6163\n",
      "Epoch 7868/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0107 - val_loss: 0.6122\n",
      "Epoch 7869/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0212 - val_loss: 0.6051\n",
      "Epoch 7870/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0269 - val_loss: 0.5734\n",
      "Epoch 7871/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0332 - val_loss: 0.6017\n",
      "Epoch 7872/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0601 - val_loss: 0.5677\n",
      "Epoch 7873/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0340 - val_loss: 0.5874\n",
      "Epoch 7874/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0133 - val_loss: 0.5994\n",
      "Epoch 7875/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0117 - val_loss: 0.5929\n",
      "Epoch 7876/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0307 - val_loss: 0.6080\n",
      "Epoch 7877/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0517 - val_loss: 0.6078\n",
      "Epoch 7878/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0242 - val_loss: 0.5962\n",
      "Epoch 7879/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0170 - val_loss: 0.6168\n",
      "Epoch 7880/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0192 - val_loss: 0.5981\n",
      "Epoch 7881/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0186 - val_loss: 0.6119\n",
      "Epoch 7882/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0140 - val_loss: 0.6074\n",
      "Epoch 7883/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0117 - val_loss: 0.6043\n",
      "Epoch 7884/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0099 - val_loss: 0.6002\n",
      "Epoch 7885/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0125 - val_loss: 0.6262\n",
      "Epoch 7886/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0271 - val_loss: 0.5822\n",
      "Epoch 7887/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0655 - val_loss: 0.6243\n",
      "Epoch 7888/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0655 - val_loss: 0.5997\n",
      "Epoch 7889/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0524 - val_loss: 0.6148\n",
      "Epoch 7890/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0283 - val_loss: 0.6163\n",
      "Epoch 7891/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0129 - val_loss: 0.6218\n",
      "Epoch 7892/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0122 - val_loss: 0.5929\n",
      "Epoch 7893/10000\n",
      "130/130 [==============================] - 0s 813us/step - loss: 0.0071 - val_loss: 0.5970\n",
      "Epoch 7894/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0057 - val_loss: 0.6110\n",
      "Epoch 7895/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0053 - val_loss: 0.5981\n",
      "Epoch 7896/10000\n",
      "130/130 [==============================] - 0s 833us/step - loss: 0.0065 - val_loss: 0.5995\n",
      "Epoch 7897/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0131 - val_loss: 0.6209\n",
      "Epoch 7898/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0252 - val_loss: 0.6107\n",
      "Epoch 7899/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0527 - val_loss: 0.6416\n",
      "Epoch 7900/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0566 - val_loss: 0.6312\n",
      "Epoch 7901/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0374 - val_loss: 0.6229\n",
      "Epoch 7902/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0175 - val_loss: 0.6007\n",
      "Epoch 7903/10000\n",
      "130/130 [==============================] - 0s 805us/step - loss: 0.0108 - val_loss: 0.6097\n",
      "Epoch 7904/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0118 - val_loss: 0.6147\n",
      "Epoch 7905/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0243 - val_loss: 0.6032\n",
      "Epoch 7906/10000\n",
      "130/130 [==============================] - 0s 893us/step - loss: 0.0392 - val_loss: 0.6170\n",
      "Epoch 7907/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 745us/step - loss: 0.0243 - val_loss: 0.6272\n",
      "Epoch 7908/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0166 - val_loss: 0.6252\n",
      "Epoch 7909/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0183 - val_loss: 0.5900\n",
      "Epoch 7910/10000\n",
      "130/130 [==============================] - 0s 792us/step - loss: 0.0355 - val_loss: 0.6040\n",
      "Epoch 7911/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0231 - val_loss: 0.6159\n",
      "Epoch 7912/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0228 - val_loss: 0.6011\n",
      "Epoch 7913/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0310 - val_loss: 0.6254\n",
      "Epoch 7914/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0131 - val_loss: 0.6220\n",
      "Epoch 7915/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0148 - val_loss: 0.6244\n",
      "Epoch 7916/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0183 - val_loss: 0.5953\n",
      "Epoch 7917/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0252 - val_loss: 0.6318\n",
      "Epoch 7918/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0437 - val_loss: 0.5957\n",
      "Epoch 7919/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0226 - val_loss: 0.6050\n",
      "Epoch 7920/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0299 - val_loss: 0.5868\n",
      "Epoch 7921/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0245 - val_loss: 0.5995\n",
      "Epoch 7922/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0248 - val_loss: 0.6003\n",
      "Epoch 7923/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0276 - val_loss: 0.6201\n",
      "Epoch 7924/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0261 - val_loss: 0.5939\n",
      "Epoch 7925/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0278 - val_loss: 0.6146\n",
      "Epoch 7926/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0217 - val_loss: 0.5962\n",
      "Epoch 7927/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0113 - val_loss: 0.5873\n",
      "Epoch 7928/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0119 - val_loss: 0.6020\n",
      "Epoch 7929/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0168 - val_loss: 0.6021\n",
      "Epoch 7930/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0274 - val_loss: 0.5937\n",
      "Epoch 7931/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0300 - val_loss: 0.6215\n",
      "Epoch 7932/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0467 - val_loss: 0.6691\n",
      "Epoch 7933/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0336 - val_loss: 0.6407\n",
      "Epoch 7934/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0232 - val_loss: 0.6227\n",
      "Epoch 7935/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0165 - val_loss: 0.6268\n",
      "Epoch 7936/10000\n",
      "130/130 [==============================] - 0s 810us/step - loss: 0.0150 - val_loss: 0.6113\n",
      "Epoch 7937/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0168 - val_loss: 0.6211\n",
      "Epoch 7938/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0247 - val_loss: 0.5879\n",
      "Epoch 7939/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0212 - val_loss: 0.6295\n",
      "Epoch 7940/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0251 - val_loss: 0.5941\n",
      "Epoch 7941/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0245 - val_loss: 0.5967\n",
      "Epoch 7942/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0176 - val_loss: 0.6069\n",
      "Epoch 7943/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0209 - val_loss: 0.6119\n",
      "Epoch 7944/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0183 - val_loss: 0.5850\n",
      "Epoch 7945/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0118 - val_loss: 0.5786\n",
      "Epoch 7946/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0239 - val_loss: 0.6008\n",
      "Epoch 7947/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0245 - val_loss: 0.6357\n",
      "Epoch 7948/10000\n",
      "130/130 [==============================] - 0s 822us/step - loss: 0.0367 - val_loss: 0.6067\n",
      "Epoch 7949/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0568 - val_loss: 0.6171\n",
      "Epoch 7950/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0212 - val_loss: 0.6005\n",
      "Epoch 7951/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0200 - val_loss: 0.5894\n",
      "Epoch 7952/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0220 - val_loss: 0.5996\n",
      "Epoch 7953/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0281 - val_loss: 0.6036\n",
      "Epoch 7954/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0318 - val_loss: 0.5928\n",
      "Epoch 7955/10000\n",
      "130/130 [==============================] - 0s 803us/step - loss: 0.0222 - val_loss: 0.6089\n",
      "Epoch 7956/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0194 - val_loss: 0.6209\n",
      "Epoch 7957/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0207 - val_loss: 0.6183\n",
      "Epoch 7958/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0310 - val_loss: 0.6100\n",
      "Epoch 7959/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0144 - val_loss: 0.6043\n",
      "Epoch 7960/10000\n",
      "130/130 [==============================] - 0s 804us/step - loss: 0.0136 - val_loss: 0.6107\n",
      "Epoch 7961/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0211 - val_loss: 0.6062\n",
      "Epoch 7962/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0346 - val_loss: 0.6152\n",
      "Epoch 7963/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0343 - val_loss: 0.6016\n",
      "Epoch 7964/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0204 - val_loss: 0.5951\n",
      "Epoch 7965/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0121 - val_loss: 0.5984\n",
      "Epoch 7966/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0158 - val_loss: 0.5944\n",
      "Epoch 7967/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0130 - val_loss: 0.6105\n",
      "Epoch 7968/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0092 - val_loss: 0.6048\n",
      "Epoch 7969/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0184 - val_loss: 0.6108\n",
      "Epoch 7970/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0487 - val_loss: 0.6228\n",
      "Epoch 7971/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0301 - val_loss: 0.5995\n",
      "Epoch 7972/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0311 - val_loss: 0.6047\n",
      "Epoch 7973/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0178 - val_loss: 0.5981\n",
      "Epoch 7974/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0125 - val_loss: 0.5948\n",
      "Epoch 7975/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0142 - val_loss: 0.5930\n",
      "Epoch 7976/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0087 - val_loss: 0.5993\n",
      "Epoch 7977/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0092 - val_loss: 0.6007\n",
      "Epoch 7978/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0160 - val_loss: 0.6225\n",
      "Epoch 7979/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0362 - val_loss: 0.5951\n",
      "Epoch 7980/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0438 - val_loss: 0.5988\n",
      "Epoch 7981/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0308 - val_loss: 0.6101\n",
      "Epoch 7982/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0330 - val_loss: 0.6311\n",
      "Epoch 7983/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 752us/step - loss: 0.0295 - val_loss: 0.5945\n",
      "Epoch 7984/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0280 - val_loss: 0.6124\n",
      "Epoch 7985/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0178 - val_loss: 0.5975\n",
      "Epoch 7986/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0107 - val_loss: 0.6098\n",
      "Epoch 7987/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0100 - val_loss: 0.6206\n",
      "Epoch 7988/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0205 - val_loss: 0.6278\n",
      "Epoch 7989/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0537 - val_loss: 0.6341\n",
      "Epoch 7990/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0323 - val_loss: 0.6345\n",
      "Epoch 7991/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0236 - val_loss: 0.6117\n",
      "Epoch 7992/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0185 - val_loss: 0.5999\n",
      "Epoch 7993/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0188 - val_loss: 0.6243\n",
      "Epoch 7994/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0193 - val_loss: 0.5904\n",
      "Epoch 7995/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0129 - val_loss: 0.5921\n",
      "Epoch 7996/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0088 - val_loss: 0.5721\n",
      "Epoch 7997/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0124 - val_loss: 0.6019\n",
      "Epoch 7998/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0212 - val_loss: 0.5982\n",
      "Epoch 7999/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0271 - val_loss: 0.6026\n",
      "Epoch 8000/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0250 - val_loss: 0.6447\n",
      "Epoch 8001/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0313 - val_loss: 0.6189\n",
      "Epoch 8002/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0563 - val_loss: 0.5987\n",
      "Epoch 8003/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0320 - val_loss: 0.6127\n",
      "Epoch 8004/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0307 - val_loss: 0.6010\n",
      "Epoch 8005/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0144 - val_loss: 0.6035\n",
      "Epoch 8006/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0121 - val_loss: 0.6132\n",
      "Epoch 8007/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0153 - val_loss: 0.6093\n",
      "Epoch 8008/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0231 - val_loss: 0.6414\n",
      "Epoch 8009/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0252 - val_loss: 0.6288\n",
      "Epoch 8010/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0201 - val_loss: 0.6237\n",
      "Epoch 8011/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0253 - val_loss: 0.6046\n",
      "Epoch 8012/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0212 - val_loss: 0.5965\n",
      "Epoch 8013/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0190 - val_loss: 0.6050\n",
      "Epoch 8014/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0113 - val_loss: 0.5831\n",
      "Epoch 8015/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0151 - val_loss: 0.6136\n",
      "Epoch 8016/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0148 - val_loss: 0.6226\n",
      "Epoch 8017/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0358 - val_loss: 0.5929\n",
      "Epoch 8018/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0442 - val_loss: 0.6280\n",
      "Epoch 8019/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0350 - val_loss: 0.6164\n",
      "Epoch 8020/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0258 - val_loss: 0.5941\n",
      "Epoch 8021/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0263 - val_loss: 0.5865\n",
      "Epoch 8022/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0219 - val_loss: 0.6151\n",
      "Epoch 8023/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0246 - val_loss: 0.6292\n",
      "Epoch 8024/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0364 - val_loss: 0.6209\n",
      "Epoch 8025/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0137 - val_loss: 0.6239\n",
      "Epoch 8026/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0124 - val_loss: 0.6137\n",
      "Epoch 8027/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0098 - val_loss: 0.6198\n",
      "Epoch 8028/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0083 - val_loss: 0.6200\n",
      "Epoch 8029/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0177 - val_loss: 0.6120\n",
      "Epoch 8030/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0287 - val_loss: 0.6344\n",
      "Epoch 8031/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0555 - val_loss: 0.5934\n",
      "Epoch 8032/10000\n",
      "130/130 [==============================] - 0s 816us/step - loss: 0.0516 - val_loss: 0.6266\n",
      "Epoch 8033/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0215 - val_loss: 0.6288\n",
      "Epoch 8034/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0161 - val_loss: 0.5831\n",
      "Epoch 8035/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0135 - val_loss: 0.6352\n",
      "Epoch 8036/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0129 - val_loss: 0.6060\n",
      "Epoch 8037/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0204 - val_loss: 0.5968\n",
      "Epoch 8038/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0278 - val_loss: 0.6170\n",
      "Epoch 8039/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0167 - val_loss: 0.6098\n",
      "Epoch 8040/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0174 - val_loss: 0.5971\n",
      "Epoch 8041/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0176 - val_loss: 0.6194\n",
      "Epoch 8042/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0223 - val_loss: 0.5880\n",
      "Epoch 8043/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0225 - val_loss: 0.6412\n",
      "Epoch 8044/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0276 - val_loss: 0.6144\n",
      "Epoch 8045/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0180 - val_loss: 0.6054\n",
      "Epoch 8046/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0290 - val_loss: 0.6494\n",
      "Epoch 8047/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0231 - val_loss: 0.5998\n",
      "Epoch 8048/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0233 - val_loss: 0.6128\n",
      "Epoch 8049/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0275 - val_loss: 0.5968\n",
      "Epoch 8050/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0247 - val_loss: 0.6143\n",
      "Epoch 8051/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0183 - val_loss: 0.6085\n",
      "Epoch 8052/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0214 - val_loss: 0.5849\n",
      "Epoch 8053/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0148 - val_loss: 0.6314\n",
      "Epoch 8054/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0180 - val_loss: 0.6322\n",
      "Epoch 8055/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0143 - val_loss: 0.6110\n",
      "Epoch 8056/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0203 - val_loss: 0.5952\n",
      "Epoch 8057/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0188 - val_loss: 0.6240\n",
      "Epoch 8058/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0200 - val_loss: 0.6074\n",
      "Epoch 8059/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 731us/step - loss: 0.0202 - val_loss: 0.5877\n",
      "Epoch 8060/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0300 - val_loss: 0.6439\n",
      "Epoch 8061/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0366 - val_loss: 0.5976\n",
      "Epoch 8062/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0520 - val_loss: 0.6194\n",
      "Epoch 8063/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0213 - val_loss: 0.5985\n",
      "Epoch 8064/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0195 - val_loss: 0.6276\n",
      "Epoch 8065/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0151 - val_loss: 0.6226\n",
      "Epoch 8066/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0100 - val_loss: 0.6369\n",
      "Epoch 8067/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0226 - val_loss: 0.6227\n",
      "Epoch 8068/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0201 - val_loss: 0.6018\n",
      "Epoch 8069/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0220 - val_loss: 0.6150\n",
      "Epoch 8070/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0213 - val_loss: 0.5966\n",
      "Epoch 8071/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0250 - val_loss: 0.6225\n",
      "Epoch 8072/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0158 - val_loss: 0.6108\n",
      "Epoch 8073/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0160 - val_loss: 0.5970\n",
      "Epoch 8074/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0141 - val_loss: 0.6035\n",
      "Epoch 8075/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0203 - val_loss: 0.5968\n",
      "Epoch 8076/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0212 - val_loss: 0.5965\n",
      "Epoch 8077/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0190 - val_loss: 0.6056\n",
      "Epoch 8078/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0154 - val_loss: 0.5912\n",
      "Epoch 8079/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0270 - val_loss: 0.6299\n",
      "Epoch 8080/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0354 - val_loss: 0.6019\n",
      "Epoch 8081/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0345 - val_loss: 0.5977\n",
      "Epoch 8082/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0185 - val_loss: 0.6055\n",
      "Epoch 8083/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0092 - val_loss: 0.6015\n",
      "Epoch 8084/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0085 - val_loss: 0.5942\n",
      "Epoch 8085/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0164 - val_loss: 0.6213\n",
      "Epoch 8086/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0492 - val_loss: 0.6190\n",
      "Epoch 8087/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0496 - val_loss: 0.6038\n",
      "Epoch 8088/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0412 - val_loss: 0.6486\n",
      "Epoch 8089/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0198 - val_loss: 0.5800\n",
      "Epoch 8090/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0157 - val_loss: 0.6293\n",
      "Epoch 8091/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0248 - val_loss: 0.6092\n",
      "Epoch 8092/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0220 - val_loss: 0.6120\n",
      "Epoch 8093/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0261 - val_loss: 0.6199\n",
      "Epoch 8094/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0243 - val_loss: 0.6052\n",
      "Epoch 8095/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0254 - val_loss: 0.6207\n",
      "Epoch 8096/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0165 - val_loss: 0.6154\n",
      "Epoch 8097/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0185 - val_loss: 0.6250\n",
      "Epoch 8098/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0252 - val_loss: 0.5992\n",
      "Epoch 8099/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0171 - val_loss: 0.5811\n",
      "Epoch 8100/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0128 - val_loss: 0.5921\n",
      "Epoch 8101/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0103 - val_loss: 0.6200\n",
      "Epoch 8102/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0145 - val_loss: 0.6232\n",
      "Epoch 8103/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0213 - val_loss: 0.5889\n",
      "Epoch 8104/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0243 - val_loss: 0.5976\n",
      "Epoch 8105/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0647 - val_loss: 0.5966\n",
      "Epoch 8106/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0531 - val_loss: 0.5726\n",
      "Epoch 8107/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0267 - val_loss: 0.5808\n",
      "Epoch 8108/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0143 - val_loss: 0.5809\n",
      "Epoch 8109/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0196 - val_loss: 0.6098\n",
      "Epoch 8110/10000\n",
      "130/130 [==============================] - 0s 826us/step - loss: 0.0239 - val_loss: 0.6300\n",
      "Epoch 8111/10000\n",
      "130/130 [==============================] - 0s 816us/step - loss: 0.0240 - val_loss: 0.6002\n",
      "Epoch 8112/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0174 - val_loss: 0.6388\n",
      "Epoch 8113/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0331 - val_loss: 0.6059\n",
      "Epoch 8114/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0364 - val_loss: 0.6271\n",
      "Epoch 8115/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0141 - val_loss: 0.6031\n",
      "Epoch 8116/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0098 - val_loss: 0.6072\n",
      "Epoch 8117/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0182 - val_loss: 0.5816\n",
      "Epoch 8118/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0238 - val_loss: 0.5811\n",
      "Epoch 8119/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0215 - val_loss: 0.6273\n",
      "Epoch 8120/10000\n",
      "130/130 [==============================] - 0s 846us/step - loss: 0.0198 - val_loss: 0.6314\n",
      "Epoch 8121/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0150 - val_loss: 0.5883\n",
      "Epoch 8122/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0161 - val_loss: 0.6207\n",
      "Epoch 8123/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0178 - val_loss: 0.6060\n",
      "Epoch 8124/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0202 - val_loss: 0.6255\n",
      "Epoch 8125/10000\n",
      "130/130 [==============================] - 0s 816us/step - loss: 0.0387 - val_loss: 0.5910\n",
      "Epoch 8126/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0250 - val_loss: 0.6042\n",
      "Epoch 8127/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0242 - val_loss: 0.6094\n",
      "Epoch 8128/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0304 - val_loss: 0.6432\n",
      "Epoch 8129/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0198 - val_loss: 0.6326\n",
      "Epoch 8130/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0232 - val_loss: 0.6052\n",
      "Epoch 8131/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0269 - val_loss: 0.6301\n",
      "Epoch 8132/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0224 - val_loss: 0.5963\n",
      "Epoch 8133/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0234 - val_loss: 0.6195\n",
      "Epoch 8134/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0219 - val_loss: 0.6083\n",
      "Epoch 8135/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 740us/step - loss: 0.0333 - val_loss: 0.5851\n",
      "Epoch 8136/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0200 - val_loss: 0.6118\n",
      "Epoch 8137/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0130 - val_loss: 0.5958\n",
      "Epoch 8138/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0094 - val_loss: 0.5984\n",
      "Epoch 8139/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0101 - val_loss: 0.5967\n",
      "Epoch 8140/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0136 - val_loss: 0.5681\n",
      "Epoch 8141/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0434 - val_loss: 0.6276\n",
      "Epoch 8142/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0321 - val_loss: 0.6061\n",
      "Epoch 8143/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0197 - val_loss: 0.6147\n",
      "Epoch 8144/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0231 - val_loss: 0.5974\n",
      "Epoch 8145/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0263 - val_loss: 0.6322\n",
      "Epoch 8146/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0266 - val_loss: 0.6167\n",
      "Epoch 8147/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0217 - val_loss: 0.6051\n",
      "Epoch 8148/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0118 - val_loss: 0.6066\n",
      "Epoch 8149/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0201 - val_loss: 0.6100\n",
      "Epoch 8150/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0194 - val_loss: 0.6219\n",
      "Epoch 8151/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0207 - val_loss: 0.6345\n",
      "Epoch 8152/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0189 - val_loss: 0.6060\n",
      "Epoch 8153/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0130 - val_loss: 0.6149\n",
      "Epoch 8154/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0145 - val_loss: 0.6404\n",
      "Epoch 8155/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0182 - val_loss: 0.6281\n",
      "Epoch 8156/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0328 - val_loss: 0.6484\n",
      "Epoch 8157/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0477 - val_loss: 0.6367\n",
      "Epoch 8158/10000\n",
      "130/130 [==============================] - 0s 810us/step - loss: 0.0229 - val_loss: 0.6362\n",
      "Epoch 8159/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0155 - val_loss: 0.6017\n",
      "Epoch 8160/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0234 - val_loss: 0.6152\n",
      "Epoch 8161/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0180 - val_loss: 0.5982\n",
      "Epoch 8162/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0163 - val_loss: 0.6041\n",
      "Epoch 8163/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0153 - val_loss: 0.6039\n",
      "Epoch 8164/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0075 - val_loss: 0.6090\n",
      "Epoch 8165/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0122 - val_loss: 0.5991\n",
      "Epoch 8166/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0197 - val_loss: 0.6042\n",
      "Epoch 8167/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0276 - val_loss: 0.6167\n",
      "Epoch 8168/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0397 - val_loss: 0.6485\n",
      "Epoch 8169/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0492 - val_loss: 0.6194\n",
      "Epoch 8170/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0379 - val_loss: 0.6168\n",
      "Epoch 8171/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0203 - val_loss: 0.6027\n",
      "Epoch 8172/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0162 - val_loss: 0.5888\n",
      "Epoch 8173/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0156 - val_loss: 0.6057\n",
      "Epoch 8174/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0110 - val_loss: 0.6167\n",
      "Epoch 8175/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0150 - val_loss: 0.6200\n",
      "Epoch 8176/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0130 - val_loss: 0.6356\n",
      "Epoch 8177/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0166 - val_loss: 0.6207\n",
      "Epoch 8178/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0152 - val_loss: 0.6090\n",
      "Epoch 8179/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0230 - val_loss: 0.6189\n",
      "Epoch 8180/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0304 - val_loss: 0.6020\n",
      "Epoch 8181/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0292 - val_loss: 0.6001\n",
      "Epoch 8182/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0215 - val_loss: 0.6380\n",
      "Epoch 8183/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0631 - val_loss: 0.6631\n",
      "Epoch 8184/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0718 - val_loss: 0.6232\n",
      "Epoch 8185/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0322 - val_loss: 0.6005\n",
      "Epoch 8186/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.0183 - val_loss: 0.6089\n",
      "Epoch 8187/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0160 - val_loss: 0.6062\n",
      "Epoch 8188/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0123 - val_loss: 0.6125\n",
      "Epoch 8189/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0129 - val_loss: 0.6064\n",
      "Epoch 8190/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0105 - val_loss: 0.6164\n",
      "Epoch 8191/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.0197 - val_loss: 0.6053\n",
      "Epoch 8192/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0193 - val_loss: 0.6007\n",
      "Epoch 8193/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0151 - val_loss: 0.6117\n",
      "Epoch 8194/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0235 - val_loss: 0.6052\n",
      "Epoch 8195/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0338 - val_loss: 0.6274\n",
      "Epoch 8196/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0367 - val_loss: 0.6369\n",
      "Epoch 8197/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0262 - val_loss: 0.5977\n",
      "Epoch 8198/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0171 - val_loss: 0.6315\n",
      "Epoch 8199/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0165 - val_loss: 0.6430\n",
      "Epoch 8200/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0173 - val_loss: 0.6140\n",
      "Epoch 8201/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0232 - val_loss: 0.6149\n",
      "Epoch 8202/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0272 - val_loss: 0.6222\n",
      "Epoch 8203/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0127 - val_loss: 0.6178\n",
      "Epoch 8204/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0124 - val_loss: 0.6115\n",
      "Epoch 8205/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0399 - val_loss: 0.6322\n",
      "Epoch 8206/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0413 - val_loss: 0.6335\n",
      "Epoch 8207/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0141 - val_loss: 0.6232\n",
      "Epoch 8208/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0113 - val_loss: 0.6296\n",
      "Epoch 8209/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0124 - val_loss: 0.6302\n",
      "Epoch 8210/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0180 - val_loss: 0.6403\n",
      "Epoch 8211/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 729us/step - loss: 0.0239 - val_loss: 0.6272\n",
      "Epoch 8212/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0262 - val_loss: 0.6216\n",
      "Epoch 8213/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0389 - val_loss: 0.6034\n",
      "Epoch 8214/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0276 - val_loss: 0.6333\n",
      "Epoch 8215/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0418 - val_loss: 0.6002\n",
      "Epoch 8216/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0222 - val_loss: 0.6265\n",
      "Epoch 8217/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0204 - val_loss: 0.6029\n",
      "Epoch 8218/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0268 - val_loss: 0.6221\n",
      "Epoch 8219/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0207 - val_loss: 0.6103\n",
      "Epoch 8220/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0273 - val_loss: 0.6258\n",
      "Epoch 8221/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0192 - val_loss: 0.5966\n",
      "Epoch 8222/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0242 - val_loss: 0.6481\n",
      "Epoch 8223/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0176 - val_loss: 0.6350\n",
      "Epoch 8224/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0099 - val_loss: 0.6309\n",
      "Epoch 8225/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0081 - val_loss: 0.6273\n",
      "Epoch 8226/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0090 - val_loss: 0.6345\n",
      "Epoch 8227/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0179 - val_loss: 0.6351\n",
      "Epoch 8228/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0412 - val_loss: 0.6470\n",
      "Epoch 8229/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0468 - val_loss: 0.6105\n",
      "Epoch 8230/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0425 - val_loss: 0.6088\n",
      "Epoch 8231/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0298 - val_loss: 0.6146\n",
      "Epoch 8232/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0176 - val_loss: 0.5872\n",
      "Epoch 8233/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0182 - val_loss: 0.6533\n",
      "Epoch 8234/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0145 - val_loss: 0.5958\n",
      "Epoch 8235/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0170 - val_loss: 0.6208\n",
      "Epoch 8236/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0267 - val_loss: 0.6306\n",
      "Epoch 8237/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0212 - val_loss: 0.6171\n",
      "Epoch 8238/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0176 - val_loss: 0.6313\n",
      "Epoch 8239/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0193 - val_loss: 0.6394\n",
      "Epoch 8240/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0185 - val_loss: 0.5892\n",
      "Epoch 8241/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0227 - val_loss: 0.5793\n",
      "Epoch 8242/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0294 - val_loss: 0.6124\n",
      "Epoch 8243/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0108 - val_loss: 0.6177\n",
      "Epoch 8244/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0184 - val_loss: 0.6373\n",
      "Epoch 8245/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0182 - val_loss: 0.6166\n",
      "Epoch 8246/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0274 - val_loss: 0.6260\n",
      "Epoch 8247/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0595 - val_loss: 0.5940\n",
      "Epoch 8248/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0504 - val_loss: 0.6048\n",
      "Epoch 8249/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0289 - val_loss: 0.5833\n",
      "Epoch 8250/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0252 - val_loss: 0.6207\n",
      "Epoch 8251/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0119 - val_loss: 0.6134\n",
      "Epoch 8252/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0082 - val_loss: 0.6104\n",
      "Epoch 8253/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0071 - val_loss: 0.6318\n",
      "Epoch 8254/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0088 - val_loss: 0.6120\n",
      "Epoch 8255/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0091 - val_loss: 0.6430\n",
      "Epoch 8256/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0103 - val_loss: 0.6129\n",
      "Epoch 8257/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0210 - val_loss: 0.5988\n",
      "Epoch 8258/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0404 - val_loss: 0.6541\n",
      "Epoch 8259/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0513 - val_loss: 0.5765\n",
      "Epoch 8260/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0420 - val_loss: 0.6442\n",
      "Epoch 8261/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0350 - val_loss: 0.6022\n",
      "Epoch 8262/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0206 - val_loss: 0.6043\n",
      "Epoch 8263/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0153 - val_loss: 0.6005\n",
      "Epoch 8264/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0125 - val_loss: 0.6133\n",
      "Epoch 8265/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0110 - val_loss: 0.6099\n",
      "Epoch 8266/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0078 - val_loss: 0.6056\n",
      "Epoch 8267/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0104 - val_loss: 0.5928\n",
      "Epoch 8268/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0071 - val_loss: 0.6176\n",
      "Epoch 8269/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0124 - val_loss: 0.6187\n",
      "Epoch 8270/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0418 - val_loss: 0.6643\n",
      "Epoch 8271/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0602 - val_loss: 0.6309\n",
      "Epoch 8272/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0535 - val_loss: 0.6326\n",
      "Epoch 8273/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0303 - val_loss: 0.6059\n",
      "Epoch 8274/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0125 - val_loss: 0.6360\n",
      "Epoch 8275/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0113 - val_loss: 0.5912\n",
      "Epoch 8276/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0149 - val_loss: 0.6106\n",
      "Epoch 8277/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0138 - val_loss: 0.6246\n",
      "Epoch 8278/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0317 - val_loss: 0.6289\n",
      "Epoch 8279/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0839 - val_loss: 0.6218\n",
      "Epoch 8280/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0636 - val_loss: 0.5972\n",
      "Epoch 8281/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0235 - val_loss: 0.6212\n",
      "Epoch 8282/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0188 - val_loss: 0.6213\n",
      "Epoch 8283/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0163 - val_loss: 0.6261\n",
      "Epoch 8284/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0210 - val_loss: 0.6250\n",
      "Epoch 8285/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0089 - val_loss: 0.6076\n",
      "Epoch 8286/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0111 - val_loss: 0.5968\n",
      "Epoch 8287/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 741us/step - loss: 0.0255 - val_loss: 0.6093\n",
      "Epoch 8288/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0191 - val_loss: 0.5960\n",
      "Epoch 8289/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0133 - val_loss: 0.6237\n",
      "Epoch 8290/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0117 - val_loss: 0.6352\n",
      "Epoch 8291/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0101 - val_loss: 0.6255\n",
      "Epoch 8292/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0154 - val_loss: 0.6370\n",
      "Epoch 8293/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0308 - val_loss: 0.6343\n",
      "Epoch 8294/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0278 - val_loss: 0.5896\n",
      "Epoch 8295/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0160 - val_loss: 0.5976\n",
      "Epoch 8296/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0230 - val_loss: 0.6105\n",
      "Epoch 8297/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0395 - val_loss: 0.6315\n",
      "Epoch 8298/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0261 - val_loss: 0.6014\n",
      "Epoch 8299/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0140 - val_loss: 0.6234\n",
      "Epoch 8300/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0101 - val_loss: 0.6346\n",
      "Epoch 8301/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0092 - val_loss: 0.6220\n",
      "Epoch 8302/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0154 - val_loss: 0.6192\n",
      "Epoch 8303/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0414 - val_loss: 0.6343\n",
      "Epoch 8304/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0298 - val_loss: 0.6109\n",
      "Epoch 8305/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0171 - val_loss: 0.6116\n",
      "Epoch 8306/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0218 - val_loss: 0.6344\n",
      "Epoch 8307/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0149 - val_loss: 0.6176\n",
      "Epoch 8308/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0146 - val_loss: 0.6050\n",
      "Epoch 8309/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0098 - val_loss: 0.6275\n",
      "Epoch 8310/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0188 - val_loss: 0.6261\n",
      "Epoch 8311/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0274 - val_loss: 0.6098\n",
      "Epoch 8312/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0497 - val_loss: 0.6157\n",
      "Epoch 8313/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0298 - val_loss: 0.6240\n",
      "Epoch 8314/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0158 - val_loss: 0.6091\n",
      "Epoch 8315/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0246 - val_loss: 0.6117\n",
      "Epoch 8316/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0417 - val_loss: 0.6561\n",
      "Epoch 8317/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0393 - val_loss: 0.6023\n",
      "Epoch 8318/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0130 - val_loss: 0.6058\n",
      "Epoch 8319/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0066 - val_loss: 0.6132\n",
      "Epoch 8320/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0099 - val_loss: 0.6234\n",
      "Epoch 8321/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0246 - val_loss: 0.5919\n",
      "Epoch 8322/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0220 - val_loss: 0.5891\n",
      "Epoch 8323/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0207 - val_loss: 0.6001\n",
      "Epoch 8324/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0299 - val_loss: 0.5893\n",
      "Epoch 8325/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0189 - val_loss: 0.5912\n",
      "Epoch 8326/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0127 - val_loss: 0.6017\n",
      "Epoch 8327/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0143 - val_loss: 0.5757\n",
      "Epoch 8328/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0405 - val_loss: 0.5973\n",
      "Epoch 8329/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0437 - val_loss: 0.5880\n",
      "Epoch 8330/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0331 - val_loss: 0.5838\n",
      "Epoch 8331/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0180 - val_loss: 0.6025\n",
      "Epoch 8332/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0216 - val_loss: 0.6263\n",
      "Epoch 8333/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0191 - val_loss: 0.6150\n",
      "Epoch 8334/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0163 - val_loss: 0.5815\n",
      "Epoch 8335/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0187 - val_loss: 0.5905\n",
      "Epoch 8336/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0203 - val_loss: 0.6142\n",
      "Epoch 8337/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0159 - val_loss: 0.6223\n",
      "Epoch 8338/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0306 - val_loss: 0.5789\n",
      "Epoch 8339/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0312 - val_loss: 0.6463\n",
      "Epoch 8340/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0160 - val_loss: 0.6341\n",
      "Epoch 8341/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0152 - val_loss: 0.5944\n",
      "Epoch 8342/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0218 - val_loss: 0.6180\n",
      "Epoch 8343/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0186 - val_loss: 0.5815\n",
      "Epoch 8344/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0090 - val_loss: 0.6285\n",
      "Epoch 8345/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0072 - val_loss: 0.6324\n",
      "Epoch 8346/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0127 - val_loss: 0.6020\n",
      "Epoch 8347/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0219 - val_loss: 0.5949\n",
      "Epoch 8348/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0226 - val_loss: 0.6139\n",
      "Epoch 8349/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0386 - val_loss: 0.6342\n",
      "Epoch 8350/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0616 - val_loss: 0.6769\n",
      "Epoch 8351/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0407 - val_loss: 0.6196\n",
      "Epoch 8352/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.6105\n",
      "Epoch 8353/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0229 - val_loss: 0.6074\n",
      "Epoch 8354/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0162 - val_loss: 0.6204\n",
      "Epoch 8355/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0090 - val_loss: 0.5737\n",
      "Epoch 8356/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0082 - val_loss: 0.5847\n",
      "Epoch 8357/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0087 - val_loss: 0.5987\n",
      "Epoch 8358/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0068 - val_loss: 0.5978\n",
      "Epoch 8359/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0087 - val_loss: 0.5959\n",
      "Epoch 8360/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0137 - val_loss: 0.5792\n",
      "Epoch 8361/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0362 - val_loss: 0.5990\n",
      "Epoch 8362/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0709 - val_loss: 0.6208\n",
      "Epoch 8363/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 724us/step - loss: 0.0386 - val_loss: 0.6005\n",
      "Epoch 8364/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0270 - val_loss: 0.6033\n",
      "Epoch 8365/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0252 - val_loss: 0.5951\n",
      "Epoch 8366/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0206 - val_loss: 0.6091\n",
      "Epoch 8367/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0156 - val_loss: 0.6214\n",
      "Epoch 8368/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0110 - val_loss: 0.6087\n",
      "Epoch 8369/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0122 - val_loss: 0.6099\n",
      "Epoch 8370/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0236 - val_loss: 0.6143\n",
      "Epoch 8371/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0286 - val_loss: 0.5993\n",
      "Epoch 8372/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0312 - val_loss: 0.6182\n",
      "Epoch 8373/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0250 - val_loss: 0.5856\n",
      "Epoch 8374/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0459 - val_loss: 0.5837\n",
      "Epoch 8375/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0164 - val_loss: 0.5970\n",
      "Epoch 8376/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0122 - val_loss: 0.5904\n",
      "Epoch 8377/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0130 - val_loss: 0.6178\n",
      "Epoch 8378/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0173 - val_loss: 0.6059\n",
      "Epoch 8379/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0151 - val_loss: 0.6146\n",
      "Epoch 8380/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0151 - val_loss: 0.5805\n",
      "Epoch 8381/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0124 - val_loss: 0.6062\n",
      "Epoch 8382/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0146 - val_loss: 0.5860\n",
      "Epoch 8383/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0127 - val_loss: 0.5959\n",
      "Epoch 8384/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0230 - val_loss: 0.6129\n",
      "Epoch 8385/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0696 - val_loss: 0.6393\n",
      "Epoch 8386/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0620 - val_loss: 0.5518\n",
      "Epoch 8387/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0220 - val_loss: 0.5899\n",
      "Epoch 8388/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0250 - val_loss: 0.5712\n",
      "Epoch 8389/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0177 - val_loss: 0.6210\n",
      "Epoch 8390/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0102 - val_loss: 0.6068\n",
      "Epoch 8391/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0129 - val_loss: 0.6016\n",
      "Epoch 8392/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0164 - val_loss: 0.5859\n",
      "Epoch 8393/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0138 - val_loss: 0.5736\n",
      "Epoch 8394/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0150 - val_loss: 0.5886\n",
      "Epoch 8395/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0138 - val_loss: 0.5956\n",
      "Epoch 8396/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0133 - val_loss: 0.6008\n",
      "Epoch 8397/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0120 - val_loss: 0.5928\n",
      "Epoch 8398/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0143 - val_loss: 0.6211\n",
      "Epoch 8399/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0242 - val_loss: 0.6242\n",
      "Epoch 8400/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0337 - val_loss: 0.5836\n",
      "Epoch 8401/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0432 - val_loss: 0.5833\n",
      "Epoch 8402/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0382 - val_loss: 0.5868\n",
      "Epoch 8403/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0301 - val_loss: 0.6083\n",
      "Epoch 8404/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0154 - val_loss: 0.6130\n",
      "Epoch 8405/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0129 - val_loss: 0.6364\n",
      "Epoch 8406/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0248 - val_loss: 0.6183\n",
      "Epoch 8407/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0197 - val_loss: 0.6074\n",
      "Epoch 8408/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0160 - val_loss: 0.6258\n",
      "Epoch 8409/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0222 - val_loss: 0.6014\n",
      "Epoch 8410/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0300 - val_loss: 0.5889\n",
      "Epoch 8411/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0190 - val_loss: 0.6010\n",
      "Epoch 8412/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0379 - val_loss: 0.6267\n",
      "Epoch 8413/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0465 - val_loss: 0.6226\n",
      "Epoch 8414/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0282 - val_loss: 0.6014\n",
      "Epoch 8415/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0211 - val_loss: 0.6052\n",
      "Epoch 8416/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0147 - val_loss: 0.5983\n",
      "Epoch 8417/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0226 - val_loss: 0.6013\n",
      "Epoch 8418/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0214 - val_loss: 0.6077\n",
      "Epoch 8419/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0197 - val_loss: 0.6110\n",
      "Epoch 8420/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0099 - val_loss: 0.5882\n",
      "Epoch 8421/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0064 - val_loss: 0.6046\n",
      "Epoch 8422/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0054 - val_loss: 0.6133\n",
      "Epoch 8423/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0081 - val_loss: 0.6198\n",
      "Epoch 8424/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0069 - val_loss: 0.6301\n",
      "Epoch 8425/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0219 - val_loss: 0.6158\n",
      "Epoch 8426/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0421 - val_loss: 0.6053\n",
      "Epoch 8427/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0825 - val_loss: 0.6328\n",
      "Epoch 8428/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0547 - val_loss: 0.6375\n",
      "Epoch 8429/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0303 - val_loss: 0.6115\n",
      "Epoch 8430/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0177 - val_loss: 0.5974\n",
      "Epoch 8431/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0111 - val_loss: 0.6144\n",
      "Epoch 8432/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0130 - val_loss: 0.6220\n",
      "Epoch 8433/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0157 - val_loss: 0.6043\n",
      "Epoch 8434/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0355 - val_loss: 0.6264\n",
      "Epoch 8435/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0261 - val_loss: 0.5858\n",
      "Epoch 8436/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0296 - val_loss: 0.5854\n",
      "Epoch 8437/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0208 - val_loss: 0.5811\n",
      "Epoch 8438/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0115 - val_loss: 0.6050\n",
      "Epoch 8439/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 759us/step - loss: 0.0111 - val_loss: 0.5987\n",
      "Epoch 8440/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0110 - val_loss: 0.6025\n",
      "Epoch 8441/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0331 - val_loss: 0.6014\n",
      "Epoch 8442/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0636 - val_loss: 0.5993\n",
      "Epoch 8443/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0251 - val_loss: 0.6182\n",
      "Epoch 8444/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0163 - val_loss: 0.5958\n",
      "Epoch 8445/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0132 - val_loss: 0.6030\n",
      "Epoch 8446/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0131 - val_loss: 0.6203\n",
      "Epoch 8447/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0161 - val_loss: 0.6263\n",
      "Epoch 8448/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0144 - val_loss: 0.6230\n",
      "Epoch 8449/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0397 - val_loss: 0.6564\n",
      "Epoch 8450/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0462 - val_loss: 0.6019\n",
      "Epoch 8451/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0308 - val_loss: 0.6374\n",
      "Epoch 8452/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0263 - val_loss: 0.6476\n",
      "Epoch 8453/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0200 - val_loss: 0.6072\n",
      "Epoch 8454/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0208 - val_loss: 0.6278\n",
      "Epoch 8455/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0122 - val_loss: 0.5940\n",
      "Epoch 8456/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0094 - val_loss: 0.6241\n",
      "Epoch 8457/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0193 - val_loss: 0.6252\n",
      "Epoch 8458/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0142 - val_loss: 0.6051\n",
      "Epoch 8459/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0162 - val_loss: 0.5967\n",
      "Epoch 8460/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0188 - val_loss: 0.6063\n",
      "Epoch 8461/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0213 - val_loss: 0.6186\n",
      "Epoch 8462/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0179 - val_loss: 0.5995\n",
      "Epoch 8463/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0369 - val_loss: 0.6397\n",
      "Epoch 8464/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0598 - val_loss: 0.5981\n",
      "Epoch 8465/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0226 - val_loss: 0.6208\n",
      "Epoch 8466/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0139 - val_loss: 0.6424\n",
      "Epoch 8467/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0146 - val_loss: 0.6053\n",
      "Epoch 8468/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0123 - val_loss: 0.6161\n",
      "Epoch 8469/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0149 - val_loss: 0.6164\n",
      "Epoch 8470/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0244 - val_loss: 0.6277\n",
      "Epoch 8471/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0292 - val_loss: 0.6248\n",
      "Epoch 8472/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0262 - val_loss: 0.5749\n",
      "Epoch 8473/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0185 - val_loss: 0.5901\n",
      "Epoch 8474/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0126 - val_loss: 0.6105\n",
      "Epoch 8475/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0152 - val_loss: 0.6137\n",
      "Epoch 8476/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0136 - val_loss: 0.6089\n",
      "Epoch 8477/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0308 - val_loss: 0.6147\n",
      "Epoch 8478/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0456 - val_loss: 0.6441\n",
      "Epoch 8479/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0285 - val_loss: 0.6129\n",
      "Epoch 8480/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0351 - val_loss: 0.6296\n",
      "Epoch 8481/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0261 - val_loss: 0.6153\n",
      "Epoch 8482/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0133 - val_loss: 0.6301\n",
      "Epoch 8483/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0203 - val_loss: 0.6026\n",
      "Epoch 8484/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0301 - val_loss: 0.5870\n",
      "Epoch 8485/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0243 - val_loss: 0.6044\n",
      "Epoch 8486/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0394 - val_loss: 0.6107\n",
      "Epoch 8487/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0339 - val_loss: 0.6164\n",
      "Epoch 8488/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0159 - val_loss: 0.6006\n",
      "Epoch 8489/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0079 - val_loss: 0.6094\n",
      "Epoch 8490/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0087 - val_loss: 0.5840\n",
      "Epoch 8491/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0089 - val_loss: 0.6061\n",
      "Epoch 8492/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0098 - val_loss: 0.6056\n",
      "Epoch 8493/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0135 - val_loss: 0.6260\n",
      "Epoch 8494/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0177 - val_loss: 0.6143\n",
      "Epoch 8495/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0441 - val_loss: 0.5969\n",
      "Epoch 8496/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0535 - val_loss: 0.6394\n",
      "Epoch 8497/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0282 - val_loss: 0.5880\n",
      "Epoch 8498/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0159 - val_loss: 0.5860\n",
      "Epoch 8499/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0144 - val_loss: 0.5807\n",
      "Epoch 8500/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0163 - val_loss: 0.5973\n",
      "Epoch 8501/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0135 - val_loss: 0.6005\n",
      "Epoch 8502/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0125 - val_loss: 0.6199\n",
      "Epoch 8503/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0243 - val_loss: 0.6115\n",
      "Epoch 8504/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0107 - val_loss: 0.5964\n",
      "Epoch 8505/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0148 - val_loss: 0.6105\n",
      "Epoch 8506/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0182 - val_loss: 0.6041\n",
      "Epoch 8507/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0225 - val_loss: 0.5953\n",
      "Epoch 8508/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0264 - val_loss: 0.6071\n",
      "Epoch 8509/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0264 - val_loss: 0.6099\n",
      "Epoch 8510/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0252 - val_loss: 0.6125\n",
      "Epoch 8511/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0241 - val_loss: 0.6178\n",
      "Epoch 8512/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0207 - val_loss: 0.5823\n",
      "Epoch 8513/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0171 - val_loss: 0.6108\n",
      "Epoch 8514/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0246 - val_loss: 0.6184\n",
      "Epoch 8515/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 735us/step - loss: 0.0232 - val_loss: 0.6093\n",
      "Epoch 8516/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0151 - val_loss: 0.6116\n",
      "Epoch 8517/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0163 - val_loss: 0.6041\n",
      "Epoch 8518/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0532 - val_loss: 0.6174\n",
      "Epoch 8519/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0296 - val_loss: 0.6366\n",
      "Epoch 8520/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0411 - val_loss: 0.6014\n",
      "Epoch 8521/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0336 - val_loss: 0.5991\n",
      "Epoch 8522/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0140 - val_loss: 0.6030\n",
      "Epoch 8523/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0243 - val_loss: 0.6275\n",
      "Epoch 8524/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0144 - val_loss: 0.5957\n",
      "Epoch 8525/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0135 - val_loss: 0.6155\n",
      "Epoch 8526/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0111 - val_loss: 0.5771\n",
      "Epoch 8527/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0178 - val_loss: 0.6468\n",
      "Epoch 8528/10000\n",
      "130/130 [==============================] - 0s 985us/step - loss: 0.0315 - val_loss: 0.6252\n",
      "Epoch 8529/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0287 - val_loss: 0.5786\n",
      "Epoch 8530/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0254 - val_loss: 0.6261\n",
      "Epoch 8531/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0204 - val_loss: 0.6012\n",
      "Epoch 8532/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0204 - val_loss: 0.5897\n",
      "Epoch 8533/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0205 - val_loss: 0.6090\n",
      "Epoch 8534/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0227 - val_loss: 0.5943\n",
      "Epoch 8535/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0432 - val_loss: 0.6315\n",
      "Epoch 8536/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0240 - val_loss: 0.5967\n",
      "Epoch 8537/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0250 - val_loss: 0.5849\n",
      "Epoch 8538/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0128 - val_loss: 0.6112\n",
      "Epoch 8539/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0211 - val_loss: 0.6065\n",
      "Epoch 8540/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0123 - val_loss: 0.6027\n",
      "Epoch 8541/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0143 - val_loss: 0.6251\n",
      "Epoch 8542/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0137 - val_loss: 0.5873\n",
      "Epoch 8543/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0236 - val_loss: 0.6256\n",
      "Epoch 8544/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0438 - val_loss: 0.5960\n",
      "Epoch 8545/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0385 - val_loss: 0.5877\n",
      "Epoch 8546/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0326 - val_loss: 0.6002\n",
      "Epoch 8547/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0155 - val_loss: 0.6200\n",
      "Epoch 8548/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0094 - val_loss: 0.6137\n",
      "Epoch 8549/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0166 - val_loss: 0.6456\n",
      "Epoch 8550/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0294 - val_loss: 0.5857\n",
      "Epoch 8551/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0397 - val_loss: 0.6153\n",
      "Epoch 8552/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0337 - val_loss: 0.6242\n",
      "Epoch 8553/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0214 - val_loss: 0.5764\n",
      "Epoch 8554/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0134 - val_loss: 0.5899\n",
      "Epoch 8555/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0197 - val_loss: 0.5931\n",
      "Epoch 8556/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0120 - val_loss: 0.6063\n",
      "Epoch 8557/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0119 - val_loss: 0.6194\n",
      "Epoch 8558/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0244 - val_loss: 0.6129\n",
      "Epoch 8559/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0247 - val_loss: 0.6081\n",
      "Epoch 8560/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0246 - val_loss: 0.5960\n",
      "Epoch 8561/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0274 - val_loss: 0.5782\n",
      "Epoch 8562/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0321 - val_loss: 0.6095\n",
      "Epoch 8563/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0339 - val_loss: 0.5940\n",
      "Epoch 8564/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0259 - val_loss: 0.6176\n",
      "Epoch 8565/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0219 - val_loss: 0.6100\n",
      "Epoch 8566/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0095 - val_loss: 0.5698\n",
      "Epoch 8567/10000\n",
      "130/130 [==============================] - 0s 927us/step - loss: 0.0074 - val_loss: 0.6043\n",
      "Epoch 8568/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0110 - val_loss: 0.6045\n",
      "Epoch 8569/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0135 - val_loss: 0.6119\n",
      "Epoch 8570/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0095 - val_loss: 0.5847\n",
      "Epoch 8571/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0347 - val_loss: 0.6064\n",
      "Epoch 8572/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0397 - val_loss: 0.6028\n",
      "Epoch 8573/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0481 - val_loss: 0.6087\n",
      "Epoch 8574/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0331 - val_loss: 0.6056\n",
      "Epoch 8575/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0281 - val_loss: 0.5880\n",
      "Epoch 8576/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0208 - val_loss: 0.6082\n",
      "Epoch 8577/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0186 - val_loss: 0.6337\n",
      "Epoch 8578/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0121 - val_loss: 0.6186\n",
      "Epoch 8579/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0111 - val_loss: 0.6026\n",
      "Epoch 8580/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0140 - val_loss: 0.6117\n",
      "Epoch 8581/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0331 - val_loss: 0.5886\n",
      "Epoch 8582/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0266 - val_loss: 0.5976\n",
      "Epoch 8583/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0181 - val_loss: 0.6404\n",
      "Epoch 8584/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0243 - val_loss: 0.5859\n",
      "Epoch 8585/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0117 - val_loss: 0.6003\n",
      "Epoch 8586/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0217 - val_loss: 0.6279\n",
      "Epoch 8587/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0221 - val_loss: 0.6051\n",
      "Epoch 8588/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0210 - val_loss: 0.5940\n",
      "Epoch 8589/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0254 - val_loss: 0.5831\n",
      "Epoch 8590/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0243 - val_loss: 0.6172\n",
      "Epoch 8591/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 739us/step - loss: 0.0347 - val_loss: 0.6006\n",
      "Epoch 8592/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0168 - val_loss: 0.5789\n",
      "Epoch 8593/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0158 - val_loss: 0.5983\n",
      "Epoch 8594/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0211 - val_loss: 0.6159\n",
      "Epoch 8595/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0201 - val_loss: 0.5843\n",
      "Epoch 8596/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0138 - val_loss: 0.6068\n",
      "Epoch 8597/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0101 - val_loss: 0.5902\n",
      "Epoch 8598/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0113 - val_loss: 0.5927\n",
      "Epoch 8599/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0176 - val_loss: 0.5937\n",
      "Epoch 8600/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0353 - val_loss: 0.6204\n",
      "Epoch 8601/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0303 - val_loss: 0.5938\n",
      "Epoch 8602/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0329 - val_loss: 0.5853\n",
      "Epoch 8603/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0273 - val_loss: 0.6141\n",
      "Epoch 8604/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0112 - val_loss: 0.6062\n",
      "Epoch 8605/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0155 - val_loss: 0.5886\n",
      "Epoch 8606/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0178 - val_loss: 0.5942\n",
      "Epoch 8607/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0159 - val_loss: 0.6022\n",
      "Epoch 8608/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0141 - val_loss: 0.5920\n",
      "Epoch 8609/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0559 - val_loss: 0.6206\n",
      "Epoch 8610/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0547 - val_loss: 0.5971\n",
      "Epoch 8611/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0271 - val_loss: 0.5901\n",
      "Epoch 8612/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0235 - val_loss: 0.6264\n",
      "Epoch 8613/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0256 - val_loss: 0.6201\n",
      "Epoch 8614/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0131 - val_loss: 0.5879\n",
      "Epoch 8615/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0111 - val_loss: 0.5856\n",
      "Epoch 8616/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0104 - val_loss: 0.5870\n",
      "Epoch 8617/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0073 - val_loss: 0.5804\n",
      "Epoch 8618/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0163 - val_loss: 0.5833\n",
      "Epoch 8619/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0230 - val_loss: 0.6112\n",
      "Epoch 8620/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0271 - val_loss: 0.5944\n",
      "Epoch 8621/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0273 - val_loss: 0.6089\n",
      "Epoch 8622/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0467 - val_loss: 0.6436\n",
      "Epoch 8623/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0308 - val_loss: 0.6048\n",
      "Epoch 8624/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0232 - val_loss: 0.6268\n",
      "Epoch 8625/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0224 - val_loss: 0.6021\n",
      "Epoch 8626/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0232 - val_loss: 0.6086\n",
      "Epoch 8627/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0181 - val_loss: 0.6099\n",
      "Epoch 8628/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0155 - val_loss: 0.6038\n",
      "Epoch 8629/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0094 - val_loss: 0.6126\n",
      "Epoch 8630/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0125 - val_loss: 0.6020\n",
      "Epoch 8631/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0389 - val_loss: 0.6357\n",
      "Epoch 8632/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0413 - val_loss: 0.6207\n",
      "Epoch 8633/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0268 - val_loss: 0.6039\n",
      "Epoch 8634/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0208 - val_loss: 0.6256\n",
      "Epoch 8635/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0304 - val_loss: 0.6372\n",
      "Epoch 8636/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0324 - val_loss: 0.6288\n",
      "Epoch 8637/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0177 - val_loss: 0.6029\n",
      "Epoch 8638/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0250 - val_loss: 0.5881\n",
      "Epoch 8639/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0227 - val_loss: 0.6177\n",
      "Epoch 8640/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0213 - val_loss: 0.5874\n",
      "Epoch 8641/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0163 - val_loss: 0.6085\n",
      "Epoch 8642/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0248 - val_loss: 0.6043\n",
      "Epoch 8643/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0243 - val_loss: 0.6201\n",
      "Epoch 8644/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0151 - val_loss: 0.6067\n",
      "Epoch 8645/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0137 - val_loss: 0.6206\n",
      "Epoch 8646/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0161 - val_loss: 0.6322\n",
      "Epoch 8647/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0213 - val_loss: 0.6154\n",
      "Epoch 8648/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0196 - val_loss: 0.6138\n",
      "Epoch 8649/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0157 - val_loss: 0.6122\n",
      "Epoch 8650/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0132 - val_loss: 0.6088\n",
      "Epoch 8651/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0241 - val_loss: 0.5866\n",
      "Epoch 8652/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0267 - val_loss: 0.5719\n",
      "Epoch 8653/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0227 - val_loss: 0.5883\n",
      "Epoch 8654/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0243 - val_loss: 0.6141\n",
      "Epoch 8655/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0215 - val_loss: 0.6120\n",
      "Epoch 8656/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0192 - val_loss: 0.5966\n",
      "Epoch 8657/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0303 - val_loss: 0.6045\n",
      "Epoch 8658/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0284 - val_loss: 0.5872\n",
      "Epoch 8659/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0185 - val_loss: 0.6000\n",
      "Epoch 8660/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0118 - val_loss: 0.5931\n",
      "Epoch 8661/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0081 - val_loss: 0.5998\n",
      "Epoch 8662/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0061 - val_loss: 0.6104\n",
      "Epoch 8663/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0064 - val_loss: 0.6102\n",
      "Epoch 8664/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0497 - val_loss: 0.6491\n",
      "Epoch 8665/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0564 - val_loss: 0.6391\n",
      "Epoch 8666/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0436 - val_loss: 0.6055\n",
      "Epoch 8667/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 730us/step - loss: 0.0256 - val_loss: 0.6128\n",
      "Epoch 8668/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0213 - val_loss: 0.6309\n",
      "Epoch 8669/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0180 - val_loss: 0.5889\n",
      "Epoch 8670/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0124 - val_loss: 0.6084\n",
      "Epoch 8671/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0116 - val_loss: 0.6224\n",
      "Epoch 8672/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0119 - val_loss: 0.6183\n",
      "Epoch 8673/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0121 - val_loss: 0.5962\n",
      "Epoch 8674/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0099 - val_loss: 0.6334\n",
      "Epoch 8675/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0139 - val_loss: 0.6204\n",
      "Epoch 8676/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0192 - val_loss: 0.6265\n",
      "Epoch 8677/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0276 - val_loss: 0.6261\n",
      "Epoch 8678/10000\n",
      "130/130 [==============================] - 0s 960us/step - loss: 0.0480 - val_loss: 0.6203\n",
      "Epoch 8679/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.1032 - val_loss: 0.5976\n",
      "Epoch 8680/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0525 - val_loss: 0.6163\n",
      "Epoch 8681/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0217 - val_loss: 0.6318\n",
      "Epoch 8682/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0162 - val_loss: 0.6060\n",
      "Epoch 8683/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0143 - val_loss: 0.6112\n",
      "Epoch 8684/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0099 - val_loss: 0.6039\n",
      "Epoch 8685/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0122 - val_loss: 0.6126\n",
      "Epoch 8686/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0098 - val_loss: 0.5991\n",
      "Epoch 8687/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0140 - val_loss: 0.6113\n",
      "Epoch 8688/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0087 - val_loss: 0.6082\n",
      "Epoch 8689/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0114 - val_loss: 0.6332\n",
      "Epoch 8690/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0152 - val_loss: 0.6327\n",
      "Epoch 8691/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0281 - val_loss: 0.6219\n",
      "Epoch 8692/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0324 - val_loss: 0.6438\n",
      "Epoch 8693/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0644 - val_loss: 0.6227\n",
      "Epoch 8694/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0417 - val_loss: 0.5990\n",
      "Epoch 8695/10000\n",
      "130/130 [==============================] - 0s 813us/step - loss: 0.0278 - val_loss: 0.6005\n",
      "Epoch 8696/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0327 - val_loss: 0.5991\n",
      "Epoch 8697/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0173 - val_loss: 0.5977\n",
      "Epoch 8698/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0089 - val_loss: 0.5953\n",
      "Epoch 8699/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0131 - val_loss: 0.6076\n",
      "Epoch 8700/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0118 - val_loss: 0.6273\n",
      "Epoch 8701/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0248 - val_loss: 0.6019\n",
      "Epoch 8702/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0334 - val_loss: 0.6407\n",
      "Epoch 8703/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0194 - val_loss: 0.6153\n",
      "Epoch 8704/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0151 - val_loss: 0.6087\n",
      "Epoch 8705/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0103 - val_loss: 0.5911\n",
      "Epoch 8706/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0090 - val_loss: 0.6004\n",
      "Epoch 8707/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0134 - val_loss: 0.6061\n",
      "Epoch 8708/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0227 - val_loss: 0.6101\n",
      "Epoch 8709/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0250 - val_loss: 0.6309\n",
      "Epoch 8710/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0302 - val_loss: 0.6098\n",
      "Epoch 8711/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0575 - val_loss: 0.5738\n",
      "Epoch 8712/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0411 - val_loss: 0.5955\n",
      "Epoch 8713/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0205 - val_loss: 0.6054\n",
      "Epoch 8714/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0090 - val_loss: 0.6094\n",
      "Epoch 8715/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0076 - val_loss: 0.6092\n",
      "Epoch 8716/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0310 - val_loss: 0.6005\n",
      "Epoch 8717/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0382 - val_loss: 0.6440\n",
      "Epoch 8718/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0178 - val_loss: 0.6143\n",
      "Epoch 8719/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0110 - val_loss: 0.6010\n",
      "Epoch 8720/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0091 - val_loss: 0.5986\n",
      "Epoch 8721/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0101 - val_loss: 0.6119\n",
      "Epoch 8722/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0096 - val_loss: 0.6069\n",
      "Epoch 8723/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0280 - val_loss: 0.6194\n",
      "Epoch 8724/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0306 - val_loss: 0.5964\n",
      "Epoch 8725/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0292 - val_loss: 0.5910\n",
      "Epoch 8726/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0218 - val_loss: 0.6022\n",
      "Epoch 8727/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0171 - val_loss: 0.6172\n",
      "Epoch 8728/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0206 - val_loss: 0.6030\n",
      "Epoch 8729/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0303 - val_loss: 0.6300\n",
      "Epoch 8730/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0236 - val_loss: 0.6021\n",
      "Epoch 8731/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0189 - val_loss: 0.6351\n",
      "Epoch 8732/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0288 - val_loss: 0.5751\n",
      "Epoch 8733/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0187 - val_loss: 0.5795\n",
      "Epoch 8734/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0184 - val_loss: 0.6158\n",
      "Epoch 8735/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0305 - val_loss: 0.5831\n",
      "Epoch 8736/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0413 - val_loss: 0.6085\n",
      "Epoch 8737/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0484 - val_loss: 0.5912\n",
      "Epoch 8738/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0245 - val_loss: 0.5911\n",
      "Epoch 8739/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0144 - val_loss: 0.5892\n",
      "Epoch 8740/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0090 - val_loss: 0.5813\n",
      "Epoch 8741/10000\n",
      "130/130 [==============================] - 0s 819us/step - loss: 0.0139 - val_loss: 0.6011\n",
      "Epoch 8742/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0171 - val_loss: 0.5976\n",
      "Epoch 8743/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 798us/step - loss: 0.0105 - val_loss: 0.5964\n",
      "Epoch 8744/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0120 - val_loss: 0.5979\n",
      "Epoch 8745/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0150 - val_loss: 0.6093\n",
      "Epoch 8746/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0322 - val_loss: 0.6055\n",
      "Epoch 8747/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0195 - val_loss: 0.6156\n",
      "Epoch 8748/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0228 - val_loss: 0.5906\n",
      "Epoch 8749/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0336 - val_loss: 0.6097\n",
      "Epoch 8750/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0571 - val_loss: 0.6076\n",
      "Epoch 8751/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0204 - val_loss: 0.6062\n",
      "Epoch 8752/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0154 - val_loss: 0.6164\n",
      "Epoch 8753/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0150 - val_loss: 0.6158\n",
      "Epoch 8754/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0176 - val_loss: 0.6209\n",
      "Epoch 8755/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0121 - val_loss: 0.6319\n",
      "Epoch 8756/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0224 - val_loss: 0.6123\n",
      "Epoch 8757/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0381 - val_loss: 0.6649\n",
      "Epoch 8758/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0284 - val_loss: 0.6151\n",
      "Epoch 8759/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0317 - val_loss: 0.6144\n",
      "Epoch 8760/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0196 - val_loss: 0.6283\n",
      "Epoch 8761/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0120 - val_loss: 0.6181\n",
      "Epoch 8762/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0109 - val_loss: 0.6142\n",
      "Epoch 8763/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0201 - val_loss: 0.6077\n",
      "Epoch 8764/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0209 - val_loss: 0.6205\n",
      "Epoch 8765/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0218 - val_loss: 0.6025\n",
      "Epoch 8766/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0185 - val_loss: 0.6146\n",
      "Epoch 8767/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0178 - val_loss: 0.6081\n",
      "Epoch 8768/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0350 - val_loss: 0.6071\n",
      "Epoch 8769/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0356 - val_loss: 0.6041\n",
      "Epoch 8770/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0158 - val_loss: 0.5818\n",
      "Epoch 8771/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0171 - val_loss: 0.6183\n",
      "Epoch 8772/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0196 - val_loss: 0.6084\n",
      "Epoch 8773/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0214 - val_loss: 0.6056\n",
      "Epoch 8774/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0233 - val_loss: 0.6302\n",
      "Epoch 8775/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0231 - val_loss: 0.6127\n",
      "Epoch 8776/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0294 - val_loss: 0.6276\n",
      "Epoch 8777/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0197 - val_loss: 0.6299\n",
      "Epoch 8778/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0103 - val_loss: 0.6182\n",
      "Epoch 8779/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0154 - val_loss: 0.6061\n",
      "Epoch 8780/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0535 - val_loss: 0.5815\n",
      "Epoch 8781/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0362 - val_loss: 0.6330\n",
      "Epoch 8782/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0181 - val_loss: 0.6178\n",
      "Epoch 8783/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0166 - val_loss: 0.6075\n",
      "Epoch 8784/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0219 - val_loss: 0.6013\n",
      "Epoch 8785/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0220 - val_loss: 0.5956\n",
      "Epoch 8786/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0181 - val_loss: 0.5881\n",
      "Epoch 8787/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0199 - val_loss: 0.5971\n",
      "Epoch 8788/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0104 - val_loss: 0.6028\n",
      "Epoch 8789/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0168 - val_loss: 0.6070\n",
      "Epoch 8790/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0232 - val_loss: 0.6280\n",
      "Epoch 8791/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0208 - val_loss: 0.6082\n",
      "Epoch 8792/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0230 - val_loss: 0.5830\n",
      "Epoch 8793/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0158 - val_loss: 0.5949\n",
      "Epoch 8794/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0144 - val_loss: 0.6190\n",
      "Epoch 8795/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0187 - val_loss: 0.5674\n",
      "Epoch 8796/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0213 - val_loss: 0.6204\n",
      "Epoch 8797/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0281 - val_loss: 0.6105\n",
      "Epoch 8798/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0469 - val_loss: 0.6144\n",
      "Epoch 8799/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0412 - val_loss: 0.6170\n",
      "Epoch 8800/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0369 - val_loss: 0.6156\n",
      "Epoch 8801/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0228 - val_loss: 0.6269\n",
      "Epoch 8802/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0108 - val_loss: 0.6250\n",
      "Epoch 8803/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0086 - val_loss: 0.6168\n",
      "Epoch 8804/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0181 - val_loss: 0.5960\n",
      "Epoch 8805/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0356 - val_loss: 0.5756\n",
      "Epoch 8806/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0410 - val_loss: 0.6084\n",
      "Epoch 8807/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0205 - val_loss: 0.6099\n",
      "Epoch 8808/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0213 - val_loss: 0.6229\n",
      "Epoch 8809/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0600 - val_loss: 0.5632\n",
      "Epoch 8810/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0252 - val_loss: 0.5956\n",
      "Epoch 8811/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0115 - val_loss: 0.5899\n",
      "Epoch 8812/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0080 - val_loss: 0.5787\n",
      "Epoch 8813/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0077 - val_loss: 0.6007\n",
      "Epoch 8814/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0067 - val_loss: 0.6017\n",
      "Epoch 8815/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0154 - val_loss: 0.5861\n",
      "Epoch 8816/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0240 - val_loss: 0.5925\n",
      "Epoch 8817/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0163 - val_loss: 0.5905\n",
      "Epoch 8818/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0125 - val_loss: 0.6166\n",
      "Epoch 8819/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 740us/step - loss: 0.0103 - val_loss: 0.6189\n",
      "Epoch 8820/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0241 - val_loss: 0.6081\n",
      "Epoch 8821/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0572 - val_loss: 0.5886\n",
      "Epoch 8822/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0678 - val_loss: 0.6423\n",
      "Epoch 8823/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0618 - val_loss: 0.6172\n",
      "Epoch 8824/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0288 - val_loss: 0.5996\n",
      "Epoch 8825/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0134 - val_loss: 0.6193\n",
      "Epoch 8826/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0108 - val_loss: 0.6002\n",
      "Epoch 8827/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0099 - val_loss: 0.6107\n",
      "Epoch 8828/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0095 - val_loss: 0.6437\n",
      "Epoch 8829/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0119 - val_loss: 0.6315\n",
      "Epoch 8830/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0188 - val_loss: 0.6389\n",
      "Epoch 8831/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0236 - val_loss: 0.6022\n",
      "Epoch 8832/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0193 - val_loss: 0.6388\n",
      "Epoch 8833/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0175 - val_loss: 0.6029\n",
      "Epoch 8834/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0147 - val_loss: 0.6108\n",
      "Epoch 8835/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0215 - val_loss: 0.5939\n",
      "Epoch 8836/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0182 - val_loss: 0.5675\n",
      "Epoch 8837/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0117 - val_loss: 0.6285\n",
      "Epoch 8838/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0204 - val_loss: 0.6091\n",
      "Epoch 8839/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0262 - val_loss: 0.6396\n",
      "Epoch 8840/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0250 - val_loss: 0.6021\n",
      "Epoch 8841/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0327 - val_loss: 0.5929\n",
      "Epoch 8842/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0160 - val_loss: 0.6054\n",
      "Epoch 8843/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0122 - val_loss: 0.5918\n",
      "Epoch 8844/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0143 - val_loss: 0.5967\n",
      "Epoch 8845/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0266 - val_loss: 0.5733\n",
      "Epoch 8846/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0314 - val_loss: 0.6119\n",
      "Epoch 8847/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0391 - val_loss: 0.5923\n",
      "Epoch 8848/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0529 - val_loss: 0.6176\n",
      "Epoch 8849/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0405 - val_loss: 0.5831\n",
      "Epoch 8850/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0187 - val_loss: 0.5927\n",
      "Epoch 8851/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0196 - val_loss: 0.6023\n",
      "Epoch 8852/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0154 - val_loss: 0.5974\n",
      "Epoch 8853/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0165 - val_loss: 0.6127\n",
      "Epoch 8854/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0338 - val_loss: 0.5950\n",
      "Epoch 8855/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0246 - val_loss: 0.5977\n",
      "Epoch 8856/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0269 - val_loss: 0.6368\n",
      "Epoch 8857/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0183 - val_loss: 0.6062\n",
      "Epoch 8858/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0110 - val_loss: 0.6093\n",
      "Epoch 8859/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0181 - val_loss: 0.6245\n",
      "Epoch 8860/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0201 - val_loss: 0.6021\n",
      "Epoch 8861/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0199 - val_loss: 0.6239\n",
      "Epoch 8862/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0118 - val_loss: 0.6286\n",
      "Epoch 8863/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0108 - val_loss: 0.6219\n",
      "Epoch 8864/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0148 - val_loss: 0.6227\n",
      "Epoch 8865/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0191 - val_loss: 0.6376\n",
      "Epoch 8866/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0312 - val_loss: 0.5968\n",
      "Epoch 8867/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0335 - val_loss: 0.5796\n",
      "Epoch 8868/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0324 - val_loss: 0.6285\n",
      "Epoch 8869/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0343 - val_loss: 0.6231\n",
      "Epoch 8870/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0475 - val_loss: 0.6305\n",
      "Epoch 8871/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0310 - val_loss: 0.6018\n",
      "Epoch 8872/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0282 - val_loss: 0.6043\n",
      "Epoch 8873/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0132 - val_loss: 0.6292\n",
      "Epoch 8874/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0107 - val_loss: 0.6158\n",
      "Epoch 8875/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0108 - val_loss: 0.6179\n",
      "Epoch 8876/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0084 - val_loss: 0.5966\n",
      "Epoch 8877/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0105 - val_loss: 0.5930\n",
      "Epoch 8878/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0119 - val_loss: 0.5999\n",
      "Epoch 8879/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0165 - val_loss: 0.6154\n",
      "Epoch 8880/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0321 - val_loss: 0.5911\n",
      "Epoch 8881/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0279 - val_loss: 0.6000\n",
      "Epoch 8882/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0211 - val_loss: 0.6002\n",
      "Epoch 8883/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0185 - val_loss: 0.6235\n",
      "Epoch 8884/10000\n",
      "130/130 [==============================] - 0s 850us/step - loss: 0.0284 - val_loss: 0.6129\n",
      "Epoch 8885/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0493 - val_loss: 0.6402\n",
      "Epoch 8886/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0305 - val_loss: 0.5922\n",
      "Epoch 8887/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0168 - val_loss: 0.6068\n",
      "Epoch 8888/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0107 - val_loss: 0.6242\n",
      "Epoch 8889/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0201 - val_loss: 0.6387\n",
      "Epoch 8890/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0347 - val_loss: 0.6401\n",
      "Epoch 8891/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0194 - val_loss: 0.6026\n",
      "Epoch 8892/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0179 - val_loss: 0.6094\n",
      "Epoch 8893/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0210 - val_loss: 0.6085\n",
      "Epoch 8894/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0152 - val_loss: 0.5806\n",
      "Epoch 8895/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 747us/step - loss: 0.0148 - val_loss: 0.6116\n",
      "Epoch 8896/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0160 - val_loss: 0.6070\n",
      "Epoch 8897/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0233 - val_loss: 0.5926\n",
      "Epoch 8898/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0184 - val_loss: 0.5957\n",
      "Epoch 8899/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0139 - val_loss: 0.6072\n",
      "Epoch 8900/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0136 - val_loss: 0.6027\n",
      "Epoch 8901/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0302 - val_loss: 0.6063\n",
      "Epoch 8902/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0281 - val_loss: 0.5860\n",
      "Epoch 8903/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0251 - val_loss: 0.6059\n",
      "Epoch 8904/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0422 - val_loss: 0.6292\n",
      "Epoch 8905/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0293 - val_loss: 0.6155\n",
      "Epoch 8906/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0225 - val_loss: 0.6205\n",
      "Epoch 8907/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0137 - val_loss: 0.6065\n",
      "Epoch 8908/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0181 - val_loss: 0.5991\n",
      "Epoch 8909/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0265 - val_loss: 0.6112\n",
      "Epoch 8910/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0375 - val_loss: 0.6042\n",
      "Epoch 8911/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0266 - val_loss: 0.6013\n",
      "Epoch 8912/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0215 - val_loss: 0.5770\n",
      "Epoch 8913/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0122 - val_loss: 0.5865\n",
      "Epoch 8914/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0103 - val_loss: 0.6032\n",
      "Epoch 8915/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0076 - val_loss: 0.5937\n",
      "Epoch 8916/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0064 - val_loss: 0.5784\n",
      "Epoch 8917/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0092 - val_loss: 0.6062\n",
      "Epoch 8918/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0243 - val_loss: 0.6127\n",
      "Epoch 8919/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0434 - val_loss: 0.6315\n",
      "Epoch 8920/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0370 - val_loss: 0.6511\n",
      "Epoch 8921/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0314 - val_loss: 0.6269\n",
      "Epoch 8922/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0260 - val_loss: 0.5891\n",
      "Epoch 8923/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0175 - val_loss: 0.5952\n",
      "Epoch 8924/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0103 - val_loss: 0.6148\n",
      "Epoch 8925/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0159 - val_loss: 0.6198\n",
      "Epoch 8926/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.5952\n",
      "Epoch 8927/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0215 - val_loss: 0.6008\n",
      "Epoch 8928/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0172 - val_loss: 0.5967\n",
      "Epoch 8929/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0111 - val_loss: 0.6141\n",
      "Epoch 8930/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0215 - val_loss: 0.6241\n",
      "Epoch 8931/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0359 - val_loss: 0.6117\n",
      "Epoch 8932/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0258 - val_loss: 0.6029\n",
      "Epoch 8933/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0316 - val_loss: 0.6132\n",
      "Epoch 8934/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0523 - val_loss: 0.6073\n",
      "Epoch 8935/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0236 - val_loss: 0.5833\n",
      "Epoch 8936/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0092 - val_loss: 0.6045\n",
      "Epoch 8937/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0089 - val_loss: 0.5970\n",
      "Epoch 8938/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0086 - val_loss: 0.5972\n",
      "Epoch 8939/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0066 - val_loss: 0.5682\n",
      "Epoch 8940/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0065 - val_loss: 0.6015\n",
      "Epoch 8941/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0117 - val_loss: 0.6118\n",
      "Epoch 8942/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0149 - val_loss: 0.6132\n",
      "Epoch 8943/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0202 - val_loss: 0.6125\n",
      "Epoch 8944/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0418 - val_loss: 0.6192\n",
      "Epoch 8945/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0758 - val_loss: 0.6011\n",
      "Epoch 8946/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0510 - val_loss: 0.6024\n",
      "Epoch 8947/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0244 - val_loss: 0.5835\n",
      "Epoch 8948/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0195 - val_loss: 0.6039\n",
      "Epoch 8949/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0133 - val_loss: 0.6074\n",
      "Epoch 8950/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0098 - val_loss: 0.5932\n",
      "Epoch 8951/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0130 - val_loss: 0.5943\n",
      "Epoch 8952/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0300 - val_loss: 0.6110\n",
      "Epoch 8953/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0420 - val_loss: 0.6071\n",
      "Epoch 8954/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0309 - val_loss: 0.6298\n",
      "Epoch 8955/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0252 - val_loss: 0.6016\n",
      "Epoch 8956/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0288 - val_loss: 0.6356\n",
      "Epoch 8957/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0229 - val_loss: 0.5818\n",
      "Epoch 8958/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0206 - val_loss: 0.6071\n",
      "Epoch 8959/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0129 - val_loss: 0.5975\n",
      "Epoch 8960/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0100 - val_loss: 0.5834\n",
      "Epoch 8961/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0110 - val_loss: 0.5808\n",
      "Epoch 8962/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0087 - val_loss: 0.5897\n",
      "Epoch 8963/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0096 - val_loss: 0.5989\n",
      "Epoch 8964/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0155 - val_loss: 0.5946\n",
      "Epoch 8965/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0424 - val_loss: 0.6179\n",
      "Epoch 8966/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0444 - val_loss: 0.5712\n",
      "Epoch 8967/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0165 - val_loss: 0.5903\n",
      "Epoch 8968/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0196 - val_loss: 0.6028\n",
      "Epoch 8969/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0279 - val_loss: 0.5896\n",
      "Epoch 8970/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0147 - val_loss: 0.6179\n",
      "Epoch 8971/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 742us/step - loss: 0.0111 - val_loss: 0.6129\n",
      "Epoch 8972/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0106 - val_loss: 0.5978\n",
      "Epoch 8973/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0127 - val_loss: 0.5870\n",
      "Epoch 8974/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0186 - val_loss: 0.6041\n",
      "Epoch 8975/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0416 - val_loss: 0.6161\n",
      "Epoch 8976/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0776 - val_loss: 0.5944\n",
      "Epoch 8977/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0513 - val_loss: 0.6397\n",
      "Epoch 8978/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0174 - val_loss: 0.5958\n",
      "Epoch 8979/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0149 - val_loss: 0.5934\n",
      "Epoch 8980/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0116 - val_loss: 0.5882\n",
      "Epoch 8981/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0091 - val_loss: 0.6318\n",
      "Epoch 8982/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0157 - val_loss: 0.6180\n",
      "Epoch 8983/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0225 - val_loss: 0.6192\n",
      "Epoch 8984/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0130 - val_loss: 0.6068\n",
      "Epoch 8985/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0144 - val_loss: 0.6197\n",
      "Epoch 8986/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0156 - val_loss: 0.6136\n",
      "Epoch 8987/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0213 - val_loss: 0.6083\n",
      "Epoch 8988/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0187 - val_loss: 0.5973\n",
      "Epoch 8989/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0235 - val_loss: 0.6064\n",
      "Epoch 8990/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0251 - val_loss: 0.5831\n",
      "Epoch 8991/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0201 - val_loss: 0.5908\n",
      "Epoch 8992/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0357 - val_loss: 0.6186\n",
      "Epoch 8993/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0274 - val_loss: 0.5787\n",
      "Epoch 8994/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0215 - val_loss: 0.6126\n",
      "Epoch 8995/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0232 - val_loss: 0.5886\n",
      "Epoch 8996/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0188 - val_loss: 0.5847\n",
      "Epoch 8997/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0230 - val_loss: 0.6034\n",
      "Epoch 8998/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0124 - val_loss: 0.6108\n",
      "Epoch 8999/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0102 - val_loss: 0.5899\n",
      "Epoch 9000/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0107 - val_loss: 0.6069\n",
      "Epoch 9001/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0233 - val_loss: 0.5904\n",
      "Epoch 9002/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0535 - val_loss: 0.6092\n",
      "Epoch 9003/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0776 - val_loss: 0.6259\n",
      "Epoch 9004/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0869 - val_loss: 0.6006\n",
      "Epoch 9005/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0278 - val_loss: 0.6117\n",
      "Epoch 9006/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0192 - val_loss: 0.6075\n",
      "Epoch 9007/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0104 - val_loss: 0.6043\n",
      "Epoch 9008/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0114 - val_loss: 0.5907\n",
      "Epoch 9009/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0205 - val_loss: 0.6080\n",
      "Epoch 9010/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0138 - val_loss: 0.5782\n",
      "Epoch 9011/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0117 - val_loss: 0.5764\n",
      "Epoch 9012/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0107 - val_loss: 0.6134\n",
      "Epoch 9013/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0130 - val_loss: 0.5921\n",
      "Epoch 9014/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0128 - val_loss: 0.5783\n",
      "Epoch 9015/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0141 - val_loss: 0.5971\n",
      "Epoch 9016/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0144 - val_loss: 0.6345\n",
      "Epoch 9017/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0224 - val_loss: 0.6215\n",
      "Epoch 9018/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0812 - val_loss: 0.5940\n",
      "Epoch 9019/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0446 - val_loss: 0.6204\n",
      "Epoch 9020/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0151 - val_loss: 0.6034\n",
      "Epoch 9021/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0178 - val_loss: 0.6126\n",
      "Epoch 9022/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0177 - val_loss: 0.6091\n",
      "Epoch 9023/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0121 - val_loss: 0.5970\n",
      "Epoch 9024/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0102 - val_loss: 0.5812\n",
      "Epoch 9025/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0085 - val_loss: 0.6015\n",
      "Epoch 9026/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0320 - val_loss: 0.6252\n",
      "Epoch 9027/10000\n",
      "130/130 [==============================] - 0s 821us/step - loss: 0.0228 - val_loss: 0.5995\n",
      "Epoch 9028/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0160 - val_loss: 0.6195\n",
      "Epoch 9029/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0113 - val_loss: 0.6277\n",
      "Epoch 9030/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0138 - val_loss: 0.6105\n",
      "Epoch 9031/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0220 - val_loss: 0.5880\n",
      "Epoch 9032/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0311 - val_loss: 0.5857\n",
      "Epoch 9033/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0326 - val_loss: 0.6307\n",
      "Epoch 9034/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0258 - val_loss: 0.5665\n",
      "Epoch 9035/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0187 - val_loss: 0.6116\n",
      "Epoch 9036/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0198 - val_loss: 0.6082\n",
      "Epoch 9037/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0246 - val_loss: 0.6288\n",
      "Epoch 9038/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0292 - val_loss: 0.6420\n",
      "Epoch 9039/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0190 - val_loss: 0.6157\n",
      "Epoch 9040/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0234 - val_loss: 0.5963\n",
      "Epoch 9041/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0623 - val_loss: 0.5989\n",
      "Epoch 9042/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0396 - val_loss: 0.6362\n",
      "Epoch 9043/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0280 - val_loss: 0.5961\n",
      "Epoch 9044/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0125 - val_loss: 0.6029\n",
      "Epoch 9045/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0109 - val_loss: 0.6008\n",
      "Epoch 9046/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0081 - val_loss: 0.5898\n",
      "Epoch 9047/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 740us/step - loss: 0.0082 - val_loss: 0.6004\n",
      "Epoch 9048/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0067 - val_loss: 0.6137\n",
      "Epoch 9049/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0068 - val_loss: 0.5962\n",
      "Epoch 9050/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0118 - val_loss: 0.6284\n",
      "Epoch 9051/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0398 - val_loss: 0.6044\n",
      "Epoch 9052/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0733 - val_loss: 0.6067\n",
      "Epoch 9053/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0285 - val_loss: 0.5911\n",
      "Epoch 9054/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0216 - val_loss: 0.6081\n",
      "Epoch 9055/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0172 - val_loss: 0.5998\n",
      "Epoch 9056/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0114 - val_loss: 0.6240\n",
      "Epoch 9057/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0097 - val_loss: 0.5953\n",
      "Epoch 9058/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0247 - val_loss: 0.6406\n",
      "Epoch 9059/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0281 - val_loss: 0.5899\n",
      "Epoch 9060/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0378 - val_loss: 0.6104\n",
      "Epoch 9061/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0345 - val_loss: 0.6084\n",
      "Epoch 9062/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0218 - val_loss: 0.6093\n",
      "Epoch 9063/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0162 - val_loss: 0.6150\n",
      "Epoch 9064/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0158 - val_loss: 0.5852\n",
      "Epoch 9065/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0144 - val_loss: 0.5961\n",
      "Epoch 9066/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0147 - val_loss: 0.5853\n",
      "Epoch 9067/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0191 - val_loss: 0.6048\n",
      "Epoch 9068/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0230 - val_loss: 0.6082\n",
      "Epoch 9069/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0198 - val_loss: 0.5968\n",
      "Epoch 9070/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0216 - val_loss: 0.6227\n",
      "Epoch 9071/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0344 - val_loss: 0.6086\n",
      "Epoch 9072/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0390 - val_loss: 0.6350\n",
      "Epoch 9073/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0366 - val_loss: 0.6098\n",
      "Epoch 9074/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0158 - val_loss: 0.6148\n",
      "Epoch 9075/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0142 - val_loss: 0.5876\n",
      "Epoch 9076/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0145 - val_loss: 0.5736\n",
      "Epoch 9077/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0225 - val_loss: 0.5709\n",
      "Epoch 9078/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0345 - val_loss: 0.6278\n",
      "Epoch 9079/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0141 - val_loss: 0.6082\n",
      "Epoch 9080/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0083 - val_loss: 0.5931\n",
      "Epoch 9081/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0107 - val_loss: 0.5895\n",
      "Epoch 9082/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0073 - val_loss: 0.6182\n",
      "Epoch 9083/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0072 - val_loss: 0.6034\n",
      "Epoch 9084/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0091 - val_loss: 0.5992\n",
      "Epoch 9085/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0196 - val_loss: 0.6300\n",
      "Epoch 9086/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0386 - val_loss: 0.6121\n",
      "Epoch 9087/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0592 - val_loss: 0.6039\n",
      "Epoch 9088/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0343 - val_loss: 0.5988\n",
      "Epoch 9089/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0169 - val_loss: 0.6041\n",
      "Epoch 9090/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0134 - val_loss: 0.5826\n",
      "Epoch 9091/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0169 - val_loss: 0.6128\n",
      "Epoch 9092/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0297 - val_loss: 0.6039\n",
      "Epoch 9093/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0351 - val_loss: 0.6197\n",
      "Epoch 9094/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0574 - val_loss: 0.6025\n",
      "Epoch 9095/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0292 - val_loss: 0.5987\n",
      "Epoch 9096/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0177 - val_loss: 0.6042\n",
      "Epoch 9097/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0170 - val_loss: 0.5974\n",
      "Epoch 9098/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0117 - val_loss: 0.6040\n",
      "Epoch 9099/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0122 - val_loss: 0.5919\n",
      "Epoch 9100/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0220 - val_loss: 0.5774\n",
      "Epoch 9101/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0225 - val_loss: 0.6140\n",
      "Epoch 9102/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0266 - val_loss: 0.5759\n",
      "Epoch 9103/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0209 - val_loss: 0.6451\n",
      "Epoch 9104/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0267 - val_loss: 0.5812\n",
      "Epoch 9105/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0260 - val_loss: 0.5950\n",
      "Epoch 9106/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0334 - val_loss: 0.6330\n",
      "Epoch 9107/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0214 - val_loss: 0.5952\n",
      "Epoch 9108/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0302 - val_loss: 0.5583\n",
      "Epoch 9109/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0302 - val_loss: 0.6235\n",
      "Epoch 9110/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0342 - val_loss: 0.6107\n",
      "Epoch 9111/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0152 - val_loss: 0.5770\n",
      "Epoch 9112/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0174 - val_loss: 0.6033\n",
      "Epoch 9113/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0182 - val_loss: 0.6037\n",
      "Epoch 9114/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0206 - val_loss: 0.6182\n",
      "Epoch 9115/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0306 - val_loss: 0.5757\n",
      "Epoch 9116/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0112 - val_loss: 0.5874\n",
      "Epoch 9117/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0131 - val_loss: 0.5922\n",
      "Epoch 9118/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0108 - val_loss: 0.5741\n",
      "Epoch 9119/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0081 - val_loss: 0.5945\n",
      "Epoch 9120/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0062 - val_loss: 0.5852\n",
      "Epoch 9121/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0073 - val_loss: 0.5892\n",
      "Epoch 9122/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0184 - val_loss: 0.5843\n",
      "Epoch 9123/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 830us/step - loss: 0.0358 - val_loss: 0.6009\n",
      "Epoch 9124/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0475 - val_loss: 0.5862\n",
      "Epoch 9125/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0488 - val_loss: 0.6118\n",
      "Epoch 9126/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0232 - val_loss: 0.6130\n",
      "Epoch 9127/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0200 - val_loss: 0.5703\n",
      "Epoch 9128/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0211 - val_loss: 0.5916\n",
      "Epoch 9129/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0143 - val_loss: 0.5721\n",
      "Epoch 9130/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0207 - val_loss: 0.6117\n",
      "Epoch 9131/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0153 - val_loss: 0.6030\n",
      "Epoch 9132/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0111 - val_loss: 0.6022\n",
      "Epoch 9133/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0105 - val_loss: 0.5795\n",
      "Epoch 9134/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0096 - val_loss: 0.5904\n",
      "Epoch 9135/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0079 - val_loss: 0.5942\n",
      "Epoch 9136/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0202 - val_loss: 0.6188\n",
      "Epoch 9137/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0609 - val_loss: 0.6210\n",
      "Epoch 9138/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0361 - val_loss: 0.6254\n",
      "Epoch 9139/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0323 - val_loss: 0.6147\n",
      "Epoch 9140/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0271 - val_loss: 0.6008\n",
      "Epoch 9141/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0372 - val_loss: 0.5907\n",
      "Epoch 9142/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0245 - val_loss: 0.5720\n",
      "Epoch 9143/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0198 - val_loss: 0.6027\n",
      "Epoch 9144/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0148 - val_loss: 0.6237\n",
      "Epoch 9145/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0087 - val_loss: 0.6108\n",
      "Epoch 9146/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0191 - val_loss: 0.6113\n",
      "Epoch 9147/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0255 - val_loss: 0.6047\n",
      "Epoch 9148/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0178 - val_loss: 0.5923\n",
      "Epoch 9149/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0178 - val_loss: 0.6048\n",
      "Epoch 9150/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0198 - val_loss: 0.6141\n",
      "Epoch 9151/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0233 - val_loss: 0.6078\n",
      "Epoch 9152/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0208 - val_loss: 0.6162\n",
      "Epoch 9153/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0232 - val_loss: 0.5592\n",
      "Epoch 9154/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0297 - val_loss: 0.5928\n",
      "Epoch 9155/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0336 - val_loss: 0.5637\n",
      "Epoch 9156/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0199 - val_loss: 0.6149\n",
      "Epoch 9157/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0193 - val_loss: 0.5936\n",
      "Epoch 9158/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0195 - val_loss: 0.6061\n",
      "Epoch 9159/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0130 - val_loss: 0.6321\n",
      "Epoch 9160/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0114 - val_loss: 0.6050\n",
      "Epoch 9161/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0109 - val_loss: 0.5998\n",
      "Epoch 9162/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0129 - val_loss: 0.6281\n",
      "Epoch 9163/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0175 - val_loss: 0.5890\n",
      "Epoch 9164/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0519 - val_loss: 0.6069\n",
      "Epoch 9165/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0625 - val_loss: 0.6258\n",
      "Epoch 9166/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0299 - val_loss: 0.6072\n",
      "Epoch 9167/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0117 - val_loss: 0.5712\n",
      "Epoch 9168/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0118 - val_loss: 0.6080\n",
      "Epoch 9169/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0122 - val_loss: 0.5929\n",
      "Epoch 9170/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0208 - val_loss: 0.5570\n",
      "Epoch 9171/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0233 - val_loss: 0.6175\n",
      "Epoch 9172/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0288 - val_loss: 0.6181\n",
      "Epoch 9173/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0251 - val_loss: 0.5938\n",
      "Epoch 9174/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0224 - val_loss: 0.5952\n",
      "Epoch 9175/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0189 - val_loss: 0.6037\n",
      "Epoch 9176/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0204 - val_loss: 0.6160\n",
      "Epoch 9177/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0152 - val_loss: 0.6010\n",
      "Epoch 9178/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0178 - val_loss: 0.6001\n",
      "Epoch 9179/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0153 - val_loss: 0.5908\n",
      "Epoch 9180/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0118 - val_loss: 0.6031\n",
      "Epoch 9181/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0271 - val_loss: 0.5976\n",
      "Epoch 9182/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0247 - val_loss: 0.5732\n",
      "Epoch 9183/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0279 - val_loss: 0.5850\n",
      "Epoch 9184/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0324 - val_loss: 0.5847\n",
      "Epoch 9185/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0193 - val_loss: 0.5772\n",
      "Epoch 9186/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0219 - val_loss: 0.5897\n",
      "Epoch 9187/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0164 - val_loss: 0.6125\n",
      "Epoch 9188/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0252 - val_loss: 0.5617\n",
      "Epoch 9189/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0587 - val_loss: 0.6196\n",
      "Epoch 9190/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0281 - val_loss: 0.5816\n",
      "Epoch 9191/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0115 - val_loss: 0.6012\n",
      "Epoch 9192/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0153 - val_loss: 0.5769\n",
      "Epoch 9193/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0100 - val_loss: 0.5925\n",
      "Epoch 9194/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0087 - val_loss: 0.5925\n",
      "Epoch 9195/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0084 - val_loss: 0.6160\n",
      "Epoch 9196/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0144 - val_loss: 0.6152\n",
      "Epoch 9197/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0167 - val_loss: 0.6204\n",
      "Epoch 9198/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0383 - val_loss: 0.6264\n",
      "Epoch 9199/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 730us/step - loss: 0.0396 - val_loss: 0.6209\n",
      "Epoch 9200/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0316 - val_loss: 0.5835\n",
      "Epoch 9201/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0241 - val_loss: 0.6214\n",
      "Epoch 9202/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0247 - val_loss: 0.5817\n",
      "Epoch 9203/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0166 - val_loss: 0.5861\n",
      "Epoch 9204/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0208 - val_loss: 0.6100\n",
      "Epoch 9205/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0151 - val_loss: 0.6062\n",
      "Epoch 9206/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0147 - val_loss: 0.5860\n",
      "Epoch 9207/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0161 - val_loss: 0.6007\n",
      "Epoch 9208/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0223 - val_loss: 0.6012\n",
      "Epoch 9209/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0225 - val_loss: 0.6183\n",
      "Epoch 9210/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0362 - val_loss: 0.6369\n",
      "Epoch 9211/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0230 - val_loss: 0.5867\n",
      "Epoch 9212/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0192 - val_loss: 0.6175\n",
      "Epoch 9213/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0118 - val_loss: 0.5932\n",
      "Epoch 9214/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0161 - val_loss: 0.6129\n",
      "Epoch 9215/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0209 - val_loss: 0.6103\n",
      "Epoch 9216/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0242 - val_loss: 0.6252\n",
      "Epoch 9217/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0165 - val_loss: 0.5973\n",
      "Epoch 9218/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0177 - val_loss: 0.6091\n",
      "Epoch 9219/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0217 - val_loss: 0.6036\n",
      "Epoch 9220/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0171 - val_loss: 0.6018\n",
      "Epoch 9221/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0208 - val_loss: 0.6081\n",
      "Epoch 9222/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0587 - val_loss: 0.6023\n",
      "Epoch 9223/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0412 - val_loss: 0.6066\n",
      "Epoch 9224/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0159 - val_loss: 0.5789\n",
      "Epoch 9225/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0098 - val_loss: 0.5885\n",
      "Epoch 9226/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0087 - val_loss: 0.5983\n",
      "Epoch 9227/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0092 - val_loss: 0.5779\n",
      "Epoch 9228/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0217 - val_loss: 0.6291\n",
      "Epoch 9229/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0583 - val_loss: 0.5963\n",
      "Epoch 9230/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0536 - val_loss: 0.6334\n",
      "Epoch 9231/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0300 - val_loss: 0.6095\n",
      "Epoch 9232/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0116 - val_loss: 0.6037\n",
      "Epoch 9233/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0155 - val_loss: 0.5816\n",
      "Epoch 9234/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0206 - val_loss: 0.5936\n",
      "Epoch 9235/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0257 - val_loss: 0.5984\n",
      "Epoch 9236/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0176 - val_loss: 0.5826\n",
      "Epoch 9237/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0149 - val_loss: 0.5800\n",
      "Epoch 9238/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0089 - val_loss: 0.6017\n",
      "Epoch 9239/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0091 - val_loss: 0.6003\n",
      "Epoch 9240/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0081 - val_loss: 0.5983\n",
      "Epoch 9241/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0084 - val_loss: 0.6181\n",
      "Epoch 9242/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0139 - val_loss: 0.6166\n",
      "Epoch 9243/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0311 - val_loss: 0.5798\n",
      "Epoch 9244/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0667 - val_loss: 0.6021\n",
      "Epoch 9245/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0528 - val_loss: 0.5805\n",
      "Epoch 9246/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0382 - val_loss: 0.5893\n",
      "Epoch 9247/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0202 - val_loss: 0.6006\n",
      "Epoch 9248/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0180 - val_loss: 0.5830\n",
      "Epoch 9249/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0132 - val_loss: 0.6249\n",
      "Epoch 9250/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0161 - val_loss: 0.5934\n",
      "Epoch 9251/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0141 - val_loss: 0.6047\n",
      "Epoch 9252/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0189 - val_loss: 0.6026\n",
      "Epoch 9253/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0154 - val_loss: 0.6177\n",
      "Epoch 9254/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0236 - val_loss: 0.5988\n",
      "Epoch 9255/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0202 - val_loss: 0.6028\n",
      "Epoch 9256/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0178 - val_loss: 0.6025\n",
      "Epoch 9257/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0138 - val_loss: 0.6325\n",
      "Epoch 9258/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0204 - val_loss: 0.6233\n",
      "Epoch 9259/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0260 - val_loss: 0.6219\n",
      "Epoch 9260/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0230 - val_loss: 0.6136\n",
      "Epoch 9261/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0282 - val_loss: 0.6026\n",
      "Epoch 9262/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0258 - val_loss: 0.5778\n",
      "Epoch 9263/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0175 - val_loss: 0.5980\n",
      "Epoch 9264/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0114 - val_loss: 0.5994\n",
      "Epoch 9265/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0128 - val_loss: 0.6088\n",
      "Epoch 9266/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0314 - val_loss: 0.5934\n",
      "Epoch 9267/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0235 - val_loss: 0.5867\n",
      "Epoch 9268/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0212 - val_loss: 0.6035\n",
      "Epoch 9269/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0220 - val_loss: 0.5682\n",
      "Epoch 9270/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0147 - val_loss: 0.6050\n",
      "Epoch 9271/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0128 - val_loss: 0.6184\n",
      "Epoch 9272/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0100 - val_loss: 0.6337\n",
      "Epoch 9273/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0114 - val_loss: 0.5870\n",
      "Epoch 9274/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0117 - val_loss: 0.6023\n",
      "Epoch 9275/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 732us/step - loss: 0.0237 - val_loss: 0.6061\n",
      "Epoch 9276/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0355 - val_loss: 0.6313\n",
      "Epoch 9277/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0328 - val_loss: 0.5996\n",
      "Epoch 9278/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0329 - val_loss: 0.5771\n",
      "Epoch 9279/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0198 - val_loss: 0.5744\n",
      "Epoch 9280/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0223 - val_loss: 0.6026\n",
      "Epoch 9281/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0226 - val_loss: 0.5682\n",
      "Epoch 9282/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0324 - val_loss: 0.6274\n",
      "Epoch 9283/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0315 - val_loss: 0.6347\n",
      "Epoch 9284/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0317 - val_loss: 0.6262\n",
      "Epoch 9285/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0431 - val_loss: 0.6139\n",
      "Epoch 9286/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0269 - val_loss: 0.5939\n",
      "Epoch 9287/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0159 - val_loss: 0.6003\n",
      "Epoch 9288/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0110 - val_loss: 0.6181\n",
      "Epoch 9289/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0142 - val_loss: 0.6123\n",
      "Epoch 9290/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0179 - val_loss: 0.6204\n",
      "Epoch 9291/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0244 - val_loss: 0.6041\n",
      "Epoch 9292/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0209 - val_loss: 0.5803\n",
      "Epoch 9293/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0288 - val_loss: 0.6041\n",
      "Epoch 9294/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0105 - val_loss: 0.5929\n",
      "Epoch 9295/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0097 - val_loss: 0.5836\n",
      "Epoch 9296/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0120 - val_loss: 0.5726\n",
      "Epoch 9297/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0216 - val_loss: 0.5704\n",
      "Epoch 9298/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0366 - val_loss: 0.6087\n",
      "Epoch 9299/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0402 - val_loss: 0.5957\n",
      "Epoch 9300/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0241 - val_loss: 0.5826\n",
      "Epoch 9301/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0175 - val_loss: 0.6015\n",
      "Epoch 9302/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0153 - val_loss: 0.6211\n",
      "Epoch 9303/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0122 - val_loss: 0.5983\n",
      "Epoch 9304/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0098 - val_loss: 0.5860\n",
      "Epoch 9305/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0238 - val_loss: 0.6181\n",
      "Epoch 9306/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0246 - val_loss: 0.6152\n",
      "Epoch 9307/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0277 - val_loss: 0.5888\n",
      "Epoch 9308/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0507 - val_loss: 0.6066\n",
      "Epoch 9309/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0291 - val_loss: 0.5998\n",
      "Epoch 9310/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0152 - val_loss: 0.6058\n",
      "Epoch 9311/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0180 - val_loss: 0.6106\n",
      "Epoch 9312/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0133 - val_loss: 0.5948\n",
      "Epoch 9313/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0167 - val_loss: 0.5613\n",
      "Epoch 9314/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0182 - val_loss: 0.5922\n",
      "Epoch 9315/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0254 - val_loss: 0.5825\n",
      "Epoch 9316/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0170 - val_loss: 0.5936\n",
      "Epoch 9317/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0181 - val_loss: 0.5939\n",
      "Epoch 9318/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0231 - val_loss: 0.5962\n",
      "Epoch 9319/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0662 - val_loss: 0.6145\n",
      "Epoch 9320/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0490 - val_loss: 0.5972\n",
      "Epoch 9321/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0184 - val_loss: 0.6027\n",
      "Epoch 9322/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0144 - val_loss: 0.6008\n",
      "Epoch 9323/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0238 - val_loss: 0.5944\n",
      "Epoch 9324/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0159 - val_loss: 0.6042\n",
      "Epoch 9325/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0145 - val_loss: 0.5900\n",
      "Epoch 9326/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0164 - val_loss: 0.5786\n",
      "Epoch 9327/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0185 - val_loss: 0.5737\n",
      "Epoch 9328/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0131 - val_loss: 0.5916\n",
      "Epoch 9329/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0133 - val_loss: 0.5994\n",
      "Epoch 9330/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0163 - val_loss: 0.5899\n",
      "Epoch 9331/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0120 - val_loss: 0.6007\n",
      "Epoch 9332/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0134 - val_loss: 0.6218\n",
      "Epoch 9333/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0243 - val_loss: 0.6017\n",
      "Epoch 9334/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0192 - val_loss: 0.6292\n",
      "Epoch 9335/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0306 - val_loss: 0.6045\n",
      "Epoch 9336/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0256 - val_loss: 0.5933\n",
      "Epoch 9337/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0350 - val_loss: 0.5884\n",
      "Epoch 9338/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0211 - val_loss: 0.6143\n",
      "Epoch 9339/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0150 - val_loss: 0.5905\n",
      "Epoch 9340/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0097 - val_loss: 0.6074\n",
      "Epoch 9341/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0243 - val_loss: 0.5930\n",
      "Epoch 9342/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0250 - val_loss: 0.5937\n",
      "Epoch 9343/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0246 - val_loss: 0.5789\n",
      "Epoch 9344/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0155 - val_loss: 0.6082\n",
      "Epoch 9345/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0211 - val_loss: 0.5922\n",
      "Epoch 9346/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0156 - val_loss: 0.5912\n",
      "Epoch 9347/10000\n",
      "130/130 [==============================] - 0s 813us/step - loss: 0.0176 - val_loss: 0.5956\n",
      "Epoch 9348/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0199 - val_loss: 0.6230\n",
      "Epoch 9349/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0318 - val_loss: 0.5546\n",
      "Epoch 9350/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0295 - val_loss: 0.5959\n",
      "Epoch 9351/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 741us/step - loss: 0.0181 - val_loss: 0.5736\n",
      "Epoch 9352/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0128 - val_loss: 0.5783\n",
      "Epoch 9353/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0211 - val_loss: 0.6225\n",
      "Epoch 9354/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0451 - val_loss: 0.6313\n",
      "Epoch 9355/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0404 - val_loss: 0.6185\n",
      "Epoch 9356/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0215 - val_loss: 0.6231\n",
      "Epoch 9357/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0176 - val_loss: 0.5889\n",
      "Epoch 9358/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0185 - val_loss: 0.6153\n",
      "Epoch 9359/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0154 - val_loss: 0.5890\n",
      "Epoch 9360/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0168 - val_loss: 0.6150\n",
      "Epoch 9361/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0145 - val_loss: 0.5971\n",
      "Epoch 9362/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0133 - val_loss: 0.5935\n",
      "Epoch 9363/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0145 - val_loss: 0.5707\n",
      "Epoch 9364/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0228 - val_loss: 0.5893\n",
      "Epoch 9365/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0250 - val_loss: 0.5948\n",
      "Epoch 9366/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0239 - val_loss: 0.6084\n",
      "Epoch 9367/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0177 - val_loss: 0.6112\n",
      "Epoch 9368/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0155 - val_loss: 0.6024\n",
      "Epoch 9369/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0184 - val_loss: 0.6125\n",
      "Epoch 9370/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0312 - val_loss: 0.6230\n",
      "Epoch 9371/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0264 - val_loss: 0.6090\n",
      "Epoch 9372/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0216 - val_loss: 0.6413\n",
      "Epoch 9373/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0377 - val_loss: 0.6151\n",
      "Epoch 9374/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0353 - val_loss: 0.6078\n",
      "Epoch 9375/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0154 - val_loss: 0.5769\n",
      "Epoch 9376/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0161 - val_loss: 0.5846\n",
      "Epoch 9377/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0168 - val_loss: 0.6073\n",
      "Epoch 9378/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0096 - val_loss: 0.6006\n",
      "Epoch 9379/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0075 - val_loss: 0.5959\n",
      "Epoch 9380/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0098 - val_loss: 0.5848\n",
      "Epoch 9381/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0156 - val_loss: 0.6255\n",
      "Epoch 9382/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0145 - val_loss: 0.5917\n",
      "Epoch 9383/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0308 - val_loss: 0.5925\n",
      "Epoch 9384/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0241 - val_loss: 0.5789\n",
      "Epoch 9385/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0279 - val_loss: 0.5937\n",
      "Epoch 9386/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0225 - val_loss: 0.5957\n",
      "Epoch 9387/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0257 - val_loss: 0.6125\n",
      "Epoch 9388/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0343 - val_loss: 0.6104\n",
      "Epoch 9389/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0216 - val_loss: 0.6167\n",
      "Epoch 9390/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0239 - val_loss: 0.6323\n",
      "Epoch 9391/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0211 - val_loss: 0.6241\n",
      "Epoch 9392/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0175 - val_loss: 0.6153\n",
      "Epoch 9393/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0153 - val_loss: 0.5998\n",
      "Epoch 9394/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0149 - val_loss: 0.6016\n",
      "Epoch 9395/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0119 - val_loss: 0.5923\n",
      "Epoch 9396/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0169 - val_loss: 0.6147\n",
      "Epoch 9397/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0394 - val_loss: 0.6119\n",
      "Epoch 9398/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0301 - val_loss: 0.5865\n",
      "Epoch 9399/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0200 - val_loss: 0.5948\n",
      "Epoch 9400/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0200 - val_loss: 0.5947\n",
      "Epoch 9401/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0149 - val_loss: 0.6232\n",
      "Epoch 9402/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0070 - val_loss: 0.5971\n",
      "Epoch 9403/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0067 - val_loss: 0.6045\n",
      "Epoch 9404/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0048 - val_loss: 0.6015\n",
      "Epoch 9405/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0128 - val_loss: 0.6061\n",
      "Epoch 9406/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0314 - val_loss: 0.6259\n",
      "Epoch 9407/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0545 - val_loss: 0.6182\n",
      "Epoch 9408/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0380 - val_loss: 0.6186\n",
      "Epoch 9409/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0226 - val_loss: 0.5933\n",
      "Epoch 9410/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0309 - val_loss: 0.6115\n",
      "Epoch 9411/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0733 - val_loss: 0.5893\n",
      "Epoch 9412/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0286 - val_loss: 0.5960\n",
      "Epoch 9413/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0099 - val_loss: 0.5863\n",
      "Epoch 9414/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0069 - val_loss: 0.5896\n",
      "Epoch 9415/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0061 - val_loss: 0.5789\n",
      "Epoch 9416/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0156 - val_loss: 0.6500\n",
      "Epoch 9417/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0516 - val_loss: 0.6019\n",
      "Epoch 9418/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0331 - val_loss: 0.5870\n",
      "Epoch 9419/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0287 - val_loss: 0.5948\n",
      "Epoch 9420/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0239 - val_loss: 0.6049\n",
      "Epoch 9421/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0234 - val_loss: 0.6010\n",
      "Epoch 9422/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0232 - val_loss: 0.5996\n",
      "Epoch 9423/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0174 - val_loss: 0.5936\n",
      "Epoch 9424/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0122 - val_loss: 0.6143\n",
      "Epoch 9425/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0168 - val_loss: 0.5799\n",
      "Epoch 9426/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0075 - val_loss: 0.5927\n",
      "Epoch 9427/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 740us/step - loss: 0.0061 - val_loss: 0.6001\n",
      "Epoch 9428/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0054 - val_loss: 0.5999\n",
      "Epoch 9429/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0058 - val_loss: 0.5969\n",
      "Epoch 9430/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0149 - val_loss: 0.5844\n",
      "Epoch 9431/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0407 - val_loss: 0.6151\n",
      "Epoch 9432/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0297 - val_loss: 0.5696\n",
      "Epoch 9433/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0257 - val_loss: 0.6121\n",
      "Epoch 9434/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0704 - val_loss: 0.6280\n",
      "Epoch 9435/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0321 - val_loss: 0.5979\n",
      "Epoch 9436/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0138 - val_loss: 0.6179\n",
      "Epoch 9437/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0107 - val_loss: 0.6008\n",
      "Epoch 9438/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0082 - val_loss: 0.6181\n",
      "Epoch 9439/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0082 - val_loss: 0.6147\n",
      "Epoch 9440/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0064 - val_loss: 0.6196\n",
      "Epoch 9441/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0158 - val_loss: 0.6224\n",
      "Epoch 9442/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0299 - val_loss: 0.5830\n",
      "Epoch 9443/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0233 - val_loss: 0.6210\n",
      "Epoch 9444/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0252 - val_loss: 0.6034\n",
      "Epoch 9445/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0203 - val_loss: 0.6016\n",
      "Epoch 9446/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0258 - val_loss: 0.5852\n",
      "Epoch 9447/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0251 - val_loss: 0.6122\n",
      "Epoch 9448/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0269 - val_loss: 0.5842\n",
      "Epoch 9449/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0255 - val_loss: 0.5721\n",
      "Epoch 9450/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0200 - val_loss: 0.6127\n",
      "Epoch 9451/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0133 - val_loss: 0.5928\n",
      "Epoch 9452/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0215 - val_loss: 0.6008\n",
      "Epoch 9453/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0337 - val_loss: 0.5881\n",
      "Epoch 9454/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0180 - val_loss: 0.5934\n",
      "Epoch 9455/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0130 - val_loss: 0.5937\n",
      "Epoch 9456/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0105 - val_loss: 0.5921\n",
      "Epoch 9457/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0120 - val_loss: 0.5859\n",
      "Epoch 9458/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0114 - val_loss: 0.5941\n",
      "Epoch 9459/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0139 - val_loss: 0.6144\n",
      "Epoch 9460/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0604 - val_loss: 0.6221\n",
      "Epoch 9461/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1006 - val_loss: 0.6037\n",
      "Epoch 9462/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0651 - val_loss: 0.6175\n",
      "Epoch 9463/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0186 - val_loss: 0.6147\n",
      "Epoch 9464/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0139 - val_loss: 0.5973\n",
      "Epoch 9465/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0141 - val_loss: 0.5950\n",
      "Epoch 9466/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0121 - val_loss: 0.5883\n",
      "Epoch 9467/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0069 - val_loss: 0.5899\n",
      "Epoch 9468/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0053 - val_loss: 0.6058\n",
      "Epoch 9469/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0047 - val_loss: 0.6040\n",
      "Epoch 9470/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0058 - val_loss: 0.5919\n",
      "Epoch 9471/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0243 - val_loss: 0.6073\n",
      "Epoch 9472/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0545 - val_loss: 0.6424\n",
      "Epoch 9473/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0298 - val_loss: 0.5971\n",
      "Epoch 9474/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0257 - val_loss: 0.6183\n",
      "Epoch 9475/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0242 - val_loss: 0.5941\n",
      "Epoch 9476/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0181 - val_loss: 0.6193\n",
      "Epoch 9477/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0139 - val_loss: 0.5811\n",
      "Epoch 9478/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0142 - val_loss: 0.5808\n",
      "Epoch 9479/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0372 - val_loss: 0.6070\n",
      "Epoch 9480/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0364 - val_loss: 0.6482\n",
      "Epoch 9481/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0360 - val_loss: 0.6138\n",
      "Epoch 9482/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0221 - val_loss: 0.5960\n",
      "Epoch 9483/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0285 - val_loss: 0.6358\n",
      "Epoch 9484/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0160 - val_loss: 0.6132\n",
      "Epoch 9485/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0161 - val_loss: 0.6081\n",
      "Epoch 9486/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0130 - val_loss: 0.6088\n",
      "Epoch 9487/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0098 - val_loss: 0.6203\n",
      "Epoch 9488/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0185 - val_loss: 0.5901\n",
      "Epoch 9489/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0228 - val_loss: 0.6205\n",
      "Epoch 9490/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0335 - val_loss: 0.5945\n",
      "Epoch 9491/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0203 - val_loss: 0.5874\n",
      "Epoch 9492/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0275 - val_loss: 0.6533\n",
      "Epoch 9493/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0187 - val_loss: 0.6052\n",
      "Epoch 9494/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0156 - val_loss: 0.6053\n",
      "Epoch 9495/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0183 - val_loss: 0.5938\n",
      "Epoch 9496/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0125 - val_loss: 0.6065\n",
      "Epoch 9497/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0144 - val_loss: 0.6142\n",
      "Epoch 9498/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0152 - val_loss: 0.6200\n",
      "Epoch 9499/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0196 - val_loss: 0.6328\n",
      "Epoch 9500/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0246 - val_loss: 0.5979\n",
      "Epoch 9501/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0213 - val_loss: 0.6291\n",
      "Epoch 9502/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0367 - val_loss: 0.6254\n",
      "Epoch 9503/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 739us/step - loss: 0.0250 - val_loss: 0.6053\n",
      "Epoch 9504/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0192 - val_loss: 0.5913\n",
      "Epoch 9505/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0097 - val_loss: 0.6034\n",
      "Epoch 9506/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0070 - val_loss: 0.5967\n",
      "Epoch 9507/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0081 - val_loss: 0.6192\n",
      "Epoch 9508/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0193 - val_loss: 0.5927\n",
      "Epoch 9509/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0197 - val_loss: 0.6097\n",
      "Epoch 9510/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0147 - val_loss: 0.6051\n",
      "Epoch 9511/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0145 - val_loss: 0.6228\n",
      "Epoch 9512/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0235 - val_loss: 0.6623\n",
      "Epoch 9513/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0221 - val_loss: 0.6258\n",
      "Epoch 9514/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0414 - val_loss: 0.6593\n",
      "Epoch 9515/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0513 - val_loss: 0.6162\n",
      "Epoch 9516/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0205 - val_loss: 0.6156\n",
      "Epoch 9517/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0182 - val_loss: 0.6169\n",
      "Epoch 9518/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0157 - val_loss: 0.6032\n",
      "Epoch 9519/10000\n",
      "130/130 [==============================] - 0s 901us/step - loss: 0.0121 - val_loss: 0.6193\n",
      "Epoch 9520/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0179 - val_loss: 0.5978\n",
      "Epoch 9521/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0249 - val_loss: 0.6047\n",
      "Epoch 9522/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0171 - val_loss: 0.6202\n",
      "Epoch 9523/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0201 - val_loss: 0.6150\n",
      "Epoch 9524/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0245 - val_loss: 0.6426\n",
      "Epoch 9525/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0334 - val_loss: 0.6332\n",
      "Epoch 9526/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0296 - val_loss: 0.6074\n",
      "Epoch 9527/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0185 - val_loss: 0.5940\n",
      "Epoch 9528/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0404 - val_loss: 0.6291\n",
      "Epoch 9529/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0358 - val_loss: 0.6148\n",
      "Epoch 9530/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0171 - val_loss: 0.5874\n",
      "Epoch 9531/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0113 - val_loss: 0.6135\n",
      "Epoch 9532/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0081 - val_loss: 0.5926\n",
      "Epoch 9533/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0133 - val_loss: 0.5906\n",
      "Epoch 9534/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0148 - val_loss: 0.5851\n",
      "Epoch 9535/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0122 - val_loss: 0.6042\n",
      "Epoch 9536/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0111 - val_loss: 0.6013\n",
      "Epoch 9537/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0201 - val_loss: 0.6051\n",
      "Epoch 9538/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0369 - val_loss: 0.5988\n",
      "Epoch 9539/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0502 - val_loss: 0.6193\n",
      "Epoch 9540/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0297 - val_loss: 0.5933\n",
      "Epoch 9541/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0144 - val_loss: 0.5921\n",
      "Epoch 9542/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0115 - val_loss: 0.5997\n",
      "Epoch 9543/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0132 - val_loss: 0.6205\n",
      "Epoch 9544/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0142 - val_loss: 0.6054\n",
      "Epoch 9545/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0129 - val_loss: 0.6276\n",
      "Epoch 9546/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0128 - val_loss: 0.6164\n",
      "Epoch 9547/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0119 - val_loss: 0.6101\n",
      "Epoch 9548/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0180 - val_loss: 0.6295\n",
      "Epoch 9549/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0504 - val_loss: 0.6168\n",
      "Epoch 9550/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0995 - val_loss: 0.6120\n",
      "Epoch 9551/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0979 - val_loss: 0.6022\n",
      "Epoch 9552/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0349 - val_loss: 0.5826\n",
      "Epoch 9553/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0181 - val_loss: 0.5820\n",
      "Epoch 9554/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0205 - val_loss: 0.5986\n",
      "Epoch 9555/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0109 - val_loss: 0.5920\n",
      "Epoch 9556/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0130 - val_loss: 0.5904\n",
      "Epoch 9557/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0141 - val_loss: 0.5935\n",
      "Epoch 9558/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0152 - val_loss: 0.5918\n",
      "Epoch 9559/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0168 - val_loss: 0.6138\n",
      "Epoch 9560/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0148 - val_loss: 0.6238\n",
      "Epoch 9561/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0103 - val_loss: 0.6190\n",
      "Epoch 9562/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0112 - val_loss: 0.5983\n",
      "Epoch 9563/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0242 - val_loss: 0.6207\n",
      "Epoch 9564/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0304 - val_loss: 0.5940\n",
      "Epoch 9565/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0178 - val_loss: 0.6203\n",
      "Epoch 9566/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0214 - val_loss: 0.6012\n",
      "Epoch 9567/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0259 - val_loss: 0.6038\n",
      "Epoch 9568/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0255 - val_loss: 0.5894\n",
      "Epoch 9569/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0417 - val_loss: 0.6115\n",
      "Epoch 9570/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0271 - val_loss: 0.6015\n",
      "Epoch 9571/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0261 - val_loss: 0.5852\n",
      "Epoch 9572/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0136 - val_loss: 0.6248\n",
      "Epoch 9573/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0154 - val_loss: 0.6174\n",
      "Epoch 9574/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0189 - val_loss: 0.6372\n",
      "Epoch 9575/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0218 - val_loss: 0.6073\n",
      "Epoch 9576/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0195 - val_loss: 0.5928\n",
      "Epoch 9577/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0148 - val_loss: 0.6021\n",
      "Epoch 9578/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0132 - val_loss: 0.6135\n",
      "Epoch 9579/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 743us/step - loss: 0.0197 - val_loss: 0.6040\n",
      "Epoch 9580/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0171 - val_loss: 0.5914\n",
      "Epoch 9581/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0451 - val_loss: 0.6080\n",
      "Epoch 9582/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0349 - val_loss: 0.5968\n",
      "Epoch 9583/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0205 - val_loss: 0.5827\n",
      "Epoch 9584/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0197 - val_loss: 0.5900\n",
      "Epoch 9585/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0134 - val_loss: 0.6107\n",
      "Epoch 9586/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0118 - val_loss: 0.5793\n",
      "Epoch 9587/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0228 - val_loss: 0.5923\n",
      "Epoch 9588/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0172 - val_loss: 0.6012\n",
      "Epoch 9589/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0205 - val_loss: 0.6001\n",
      "Epoch 9590/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0315 - val_loss: 0.6064\n",
      "Epoch 9591/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0245 - val_loss: 0.5817\n",
      "Epoch 9592/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0273 - val_loss: 0.6057\n",
      "Epoch 9593/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0247 - val_loss: 0.5783\n",
      "Epoch 9594/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0189 - val_loss: 0.5836\n",
      "Epoch 9595/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0104 - val_loss: 0.6038\n",
      "Epoch 9596/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0075 - val_loss: 0.5944\n",
      "Epoch 9597/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0200 - val_loss: 0.6105\n",
      "Epoch 9598/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0312 - val_loss: 0.6081\n",
      "Epoch 9599/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0215 - val_loss: 0.6218\n",
      "Epoch 9600/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0246 - val_loss: 0.6017\n",
      "Epoch 9601/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0281 - val_loss: 0.6677\n",
      "Epoch 9602/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0431 - val_loss: 0.6002\n",
      "Epoch 9603/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0373 - val_loss: 0.5830\n",
      "Epoch 9604/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0132 - val_loss: 0.5976\n",
      "Epoch 9605/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0156 - val_loss: 0.5774\n",
      "Epoch 9606/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0215 - val_loss: 0.6012\n",
      "Epoch 9607/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0207 - val_loss: 0.6050\n",
      "Epoch 9608/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0215 - val_loss: 0.5740\n",
      "Epoch 9609/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0212 - val_loss: 0.5821\n",
      "Epoch 9610/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0151 - val_loss: 0.6074\n",
      "Epoch 9611/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0132 - val_loss: 0.5943\n",
      "Epoch 9612/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0122 - val_loss: 0.5749\n",
      "Epoch 9613/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0113 - val_loss: 0.5732\n",
      "Epoch 9614/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0090 - val_loss: 0.5708\n",
      "Epoch 9615/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0152 - val_loss: 0.5952\n",
      "Epoch 9616/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0251 - val_loss: 0.5992\n",
      "Epoch 9617/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0242 - val_loss: 0.6082\n",
      "Epoch 9618/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0259 - val_loss: 0.5935\n",
      "Epoch 9619/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0161 - val_loss: 0.5962\n",
      "Epoch 9620/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0178 - val_loss: 0.5841\n",
      "Epoch 9621/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0277 - val_loss: 0.6049\n",
      "Epoch 9622/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0317 - val_loss: 0.6140\n",
      "Epoch 9623/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0669 - val_loss: 0.5866\n",
      "Epoch 9624/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0294 - val_loss: 0.5853\n",
      "Epoch 9625/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0132 - val_loss: 0.5970\n",
      "Epoch 9626/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0103 - val_loss: 0.5885\n",
      "Epoch 9627/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0091 - val_loss: 0.5916\n",
      "Epoch 9628/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0125 - val_loss: 0.5952\n",
      "Epoch 9629/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0222 - val_loss: 0.5899\n",
      "Epoch 9630/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0236 - val_loss: 0.6051\n",
      "Epoch 9631/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0119 - val_loss: 0.5816\n",
      "Epoch 9632/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0377 - val_loss: 0.5986\n",
      "Epoch 9633/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0327 - val_loss: 0.6026\n",
      "Epoch 9634/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0210 - val_loss: 0.5946\n",
      "Epoch 9635/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0182 - val_loss: 0.5804\n",
      "Epoch 9636/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0124 - val_loss: 0.5983\n",
      "Epoch 9637/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0294 - val_loss: 0.5847\n",
      "Epoch 9638/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0130 - val_loss: 0.6035\n",
      "Epoch 9639/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0134 - val_loss: 0.6125\n",
      "Epoch 9640/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0106 - val_loss: 0.6224\n",
      "Epoch 9641/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0143 - val_loss: 0.5936\n",
      "Epoch 9642/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0114 - val_loss: 0.6132\n",
      "Epoch 9643/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0208 - val_loss: 0.5807\n",
      "Epoch 9644/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0245 - val_loss: 0.6179\n",
      "Epoch 9645/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0612 - val_loss: 0.5866\n",
      "Epoch 9646/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0616 - val_loss: 0.6173\n",
      "Epoch 9647/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0607 - val_loss: 0.6067\n",
      "Epoch 9648/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0251 - val_loss: 0.6104\n",
      "Epoch 9649/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0135 - val_loss: 0.6097\n",
      "Epoch 9650/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0110 - val_loss: 0.6166\n",
      "Epoch 9651/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0147 - val_loss: 0.6120\n",
      "Epoch 9652/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0294 - val_loss: 0.6240\n",
      "Epoch 9653/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0133 - val_loss: 0.6061\n",
      "Epoch 9654/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0076 - val_loss: 0.6151\n",
      "Epoch 9655/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 748us/step - loss: 0.0104 - val_loss: 0.6263\n",
      "Epoch 9656/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0116 - val_loss: 0.6110\n",
      "Epoch 9657/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0115 - val_loss: 0.6045\n",
      "Epoch 9658/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0149 - val_loss: 0.6447\n",
      "Epoch 9659/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0268 - val_loss: 0.6285\n",
      "Epoch 9660/10000\n",
      "130/130 [==============================] - 0s 820us/step - loss: 0.0386 - val_loss: 0.5975\n",
      "Epoch 9661/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0430 - val_loss: 0.6155\n",
      "Epoch 9662/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0333 - val_loss: 0.6244\n",
      "Epoch 9663/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0179 - val_loss: 0.6263\n",
      "Epoch 9664/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0129 - val_loss: 0.6034\n",
      "Epoch 9665/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0127 - val_loss: 0.5916\n",
      "Epoch 9666/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0311 - val_loss: 0.6049\n",
      "Epoch 9667/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0292 - val_loss: 0.5937\n",
      "Epoch 9668/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0271 - val_loss: 0.6040\n",
      "Epoch 9669/10000\n",
      "130/130 [==============================] - 0s 842us/step - loss: 0.0240 - val_loss: 0.6209\n",
      "Epoch 9670/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0118 - val_loss: 0.6138\n",
      "Epoch 9671/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0103 - val_loss: 0.6084\n",
      "Epoch 9672/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0112 - val_loss: 0.6021\n",
      "Epoch 9673/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0073 - val_loss: 0.6004\n",
      "Epoch 9674/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0107 - val_loss: 0.6014\n",
      "Epoch 9675/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0101 - val_loss: 0.5856\n",
      "Epoch 9676/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0223 - val_loss: 0.6085\n",
      "Epoch 9677/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0332 - val_loss: 0.6190\n",
      "Epoch 9678/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0333 - val_loss: 0.5797\n",
      "Epoch 9679/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0436 - val_loss: 0.5980\n",
      "Epoch 9680/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0562 - val_loss: 0.5892\n",
      "Epoch 9681/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0319 - val_loss: 0.5917\n",
      "Epoch 9682/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0128 - val_loss: 0.5911\n",
      "Epoch 9683/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0085 - val_loss: 0.5775\n",
      "Epoch 9684/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0051 - val_loss: 0.5909\n",
      "Epoch 9685/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0050 - val_loss: 0.5919\n",
      "Epoch 9686/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0062 - val_loss: 0.5922\n",
      "Epoch 9687/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0076 - val_loss: 0.5899\n",
      "Epoch 9688/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0153 - val_loss: 0.6289\n",
      "Epoch 9689/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0173 - val_loss: 0.6093\n",
      "Epoch 9690/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0343 - val_loss: 0.5716\n",
      "Epoch 9691/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0535 - val_loss: 0.6052\n",
      "Epoch 9692/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0448 - val_loss: 0.5851\n",
      "Epoch 9693/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0219 - val_loss: 0.5844\n",
      "Epoch 9694/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0333 - val_loss: 0.6196\n",
      "Epoch 9695/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0283 - val_loss: 0.6077\n",
      "Epoch 9696/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0193 - val_loss: 0.6034\n",
      "Epoch 9697/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0165 - val_loss: 0.5788\n",
      "Epoch 9698/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0222 - val_loss: 0.5813\n",
      "Epoch 9699/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0174 - val_loss: 0.6094\n",
      "Epoch 9700/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0181 - val_loss: 0.5999\n",
      "Epoch 9701/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0161 - val_loss: 0.5917\n",
      "Epoch 9702/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0135 - val_loss: 0.5880\n",
      "Epoch 9703/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0294 - val_loss: 0.6220\n",
      "Epoch 9704/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0206 - val_loss: 0.5956\n",
      "Epoch 9705/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0182 - val_loss: 0.5869\n",
      "Epoch 9706/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0138 - val_loss: 0.5914\n",
      "Epoch 9707/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0233 - val_loss: 0.6002\n",
      "Epoch 9708/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0164 - val_loss: 0.6007\n",
      "Epoch 9709/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0148 - val_loss: 0.6076\n",
      "Epoch 9710/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0209 - val_loss: 0.5995\n",
      "Epoch 9711/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0169 - val_loss: 0.6034\n",
      "Epoch 9712/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0344 - val_loss: 0.6387\n",
      "Epoch 9713/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0533 - val_loss: 0.5841\n",
      "Epoch 9714/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0311 - val_loss: 0.5763\n",
      "Epoch 9715/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0240 - val_loss: 0.5950\n",
      "Epoch 9716/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0210 - val_loss: 0.5919\n",
      "Epoch 9717/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0172 - val_loss: 0.6172\n",
      "Epoch 9718/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0233 - val_loss: 0.5651\n",
      "Epoch 9719/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0190 - val_loss: 0.5910\n",
      "Epoch 9720/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0546 - val_loss: 0.6013\n",
      "Epoch 9721/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0347 - val_loss: 0.6045\n",
      "Epoch 9722/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0311 - val_loss: 0.6106\n",
      "Epoch 9723/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0182 - val_loss: 0.5823\n",
      "Epoch 9724/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0153 - val_loss: 0.5992\n",
      "Epoch 9725/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0126 - val_loss: 0.5877\n",
      "Epoch 9726/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0143 - val_loss: 0.6094\n",
      "Epoch 9727/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0144 - val_loss: 0.5944\n",
      "Epoch 9728/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0173 - val_loss: 0.6205\n",
      "Epoch 9729/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0133 - val_loss: 0.6015\n",
      "Epoch 9730/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0066 - val_loss: 0.6026\n",
      "Epoch 9731/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 737us/step - loss: 0.0081 - val_loss: 0.6137\n",
      "Epoch 9732/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0245 - val_loss: 0.6023\n",
      "Epoch 9733/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0275 - val_loss: 0.5741\n",
      "Epoch 9734/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0501 - val_loss: 0.5948\n",
      "Epoch 9735/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0485 - val_loss: 0.6290\n",
      "Epoch 9736/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0303 - val_loss: 0.6033\n",
      "Epoch 9737/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0167 - val_loss: 0.5990\n",
      "Epoch 9738/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0155 - val_loss: 0.5997\n",
      "Epoch 9739/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0146 - val_loss: 0.6021\n",
      "Epoch 9740/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0145 - val_loss: 0.6018\n",
      "Epoch 9741/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0195 - val_loss: 0.6216\n",
      "Epoch 9742/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0156 - val_loss: 0.6113\n",
      "Epoch 9743/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0203 - val_loss: 0.6021\n",
      "Epoch 9744/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0264 - val_loss: 0.6301\n",
      "Epoch 9745/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0277 - val_loss: 0.6114\n",
      "Epoch 9746/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0156 - val_loss: 0.6171\n",
      "Epoch 9747/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0134 - val_loss: 0.6035\n",
      "Epoch 9748/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0112 - val_loss: 0.5967\n",
      "Epoch 9749/10000\n",
      "130/130 [==============================] - 0s 805us/step - loss: 0.0141 - val_loss: 0.6419\n",
      "Epoch 9750/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0174 - val_loss: 0.6288\n",
      "Epoch 9751/10000\n",
      "130/130 [==============================] - 0s 820us/step - loss: 0.0297 - val_loss: 0.6338\n",
      "Epoch 9752/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0308 - val_loss: 0.6314\n",
      "Epoch 9753/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0145 - val_loss: 0.6099\n",
      "Epoch 9754/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0178 - val_loss: 0.6217\n",
      "Epoch 9755/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0097 - val_loss: 0.6268\n",
      "Epoch 9756/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0112 - val_loss: 0.6303\n",
      "Epoch 9757/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0382 - val_loss: 0.6418\n",
      "Epoch 9758/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0293 - val_loss: 0.6214\n",
      "Epoch 9759/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0197 - val_loss: 0.5941\n",
      "Epoch 9760/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0155 - val_loss: 0.6272\n",
      "Epoch 9761/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0267 - val_loss: 0.6276\n",
      "Epoch 9762/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0228 - val_loss: 0.5765\n",
      "Epoch 9763/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0186 - val_loss: 0.5819\n",
      "Epoch 9764/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0196 - val_loss: 0.6336\n",
      "Epoch 9765/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0191 - val_loss: 0.6057\n",
      "Epoch 9766/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0233 - val_loss: 0.6133\n",
      "Epoch 9767/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0091 - val_loss: 0.6072\n",
      "Epoch 9768/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0101 - val_loss: 0.6210\n",
      "Epoch 9769/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0163 - val_loss: 0.6060\n",
      "Epoch 9770/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0297 - val_loss: 0.6285\n",
      "Epoch 9771/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0381 - val_loss: 0.6219\n",
      "Epoch 9772/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0386 - val_loss: 0.6513\n",
      "Epoch 9773/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0337 - val_loss: 0.6046\n",
      "Epoch 9774/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0203 - val_loss: 0.6336\n",
      "Epoch 9775/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0227 - val_loss: 0.6353\n",
      "Epoch 9776/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0106 - val_loss: 0.6087\n",
      "Epoch 9777/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0102 - val_loss: 0.6357\n",
      "Epoch 9778/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0179 - val_loss: 0.6134\n",
      "Epoch 9779/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0284 - val_loss: 0.6386\n",
      "Epoch 9780/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0174 - val_loss: 0.6321\n",
      "Epoch 9781/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0175 - val_loss: 0.5913\n",
      "Epoch 9782/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0206 - val_loss: 0.6221\n",
      "Epoch 9783/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0300 - val_loss: 0.6084\n",
      "Epoch 9784/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0210 - val_loss: 0.5819\n",
      "Epoch 9785/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0166 - val_loss: 0.6139\n",
      "Epoch 9786/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0199 - val_loss: 0.6341\n",
      "Epoch 9787/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0156 - val_loss: 0.5944\n",
      "Epoch 9788/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0147 - val_loss: 0.6079\n",
      "Epoch 9789/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0113 - val_loss: 0.6067\n",
      "Epoch 9790/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0121 - val_loss: 0.6165\n",
      "Epoch 9791/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0122 - val_loss: 0.5859\n",
      "Epoch 9792/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0345 - val_loss: 0.6081\n",
      "Epoch 9793/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0338 - val_loss: 0.5956\n",
      "Epoch 9794/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0355 - val_loss: 0.6196\n",
      "Epoch 9795/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0362 - val_loss: 0.6118\n",
      "Epoch 9796/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0221 - val_loss: 0.6148\n",
      "Epoch 9797/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0144 - val_loss: 0.5925\n",
      "Epoch 9798/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0128 - val_loss: 0.5843\n",
      "Epoch 9799/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0191 - val_loss: 0.6087\n",
      "Epoch 9800/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0280 - val_loss: 0.6162\n",
      "Epoch 9801/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0241 - val_loss: 0.6139\n",
      "Epoch 9802/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0298 - val_loss: 0.6097\n",
      "Epoch 9803/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0145 - val_loss: 0.5753\n",
      "Epoch 9804/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0175 - val_loss: 0.5905\n",
      "Epoch 9805/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0215 - val_loss: 0.6041\n",
      "Epoch 9806/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0133 - val_loss: 0.5834\n",
      "Epoch 9807/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 746us/step - loss: 0.0089 - val_loss: 0.6063\n",
      "Epoch 9808/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0182 - val_loss: 0.6067\n",
      "Epoch 9809/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0252 - val_loss: 0.5882\n",
      "Epoch 9810/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0396 - val_loss: 0.5991\n",
      "Epoch 9811/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0338 - val_loss: 0.6168\n",
      "Epoch 9812/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0226 - val_loss: 0.5837\n",
      "Epoch 9813/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0352 - val_loss: 0.6325\n",
      "Epoch 9814/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0230 - val_loss: 0.6022\n",
      "Epoch 9815/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.6008\n",
      "Epoch 9816/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0125 - val_loss: 0.6280\n",
      "Epoch 9817/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0134 - val_loss: 0.6198\n",
      "Epoch 9818/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0091 - val_loss: 0.6185\n",
      "Epoch 9819/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0098 - val_loss: 0.5949\n",
      "Epoch 9820/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0096 - val_loss: 0.5951\n",
      "Epoch 9821/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0170 - val_loss: 0.5998\n",
      "Epoch 9822/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0178 - val_loss: 0.5942\n",
      "Epoch 9823/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0173 - val_loss: 0.6035\n",
      "Epoch 9824/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0241 - val_loss: 0.5997\n",
      "Epoch 9825/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0356 - val_loss: 0.6013\n",
      "Epoch 9826/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0475 - val_loss: 0.5806\n",
      "Epoch 9827/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0331 - val_loss: 0.6051\n",
      "Epoch 9828/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0167 - val_loss: 0.6107\n",
      "Epoch 9829/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0132 - val_loss: 0.5911\n",
      "Epoch 9830/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0109 - val_loss: 0.5952\n",
      "Epoch 9831/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0101 - val_loss: 0.6172\n",
      "Epoch 9832/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0111 - val_loss: 0.6111\n",
      "Epoch 9833/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0360 - val_loss: 0.6011\n",
      "Epoch 9834/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0320 - val_loss: 0.6146\n",
      "Epoch 9835/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0165 - val_loss: 0.5892\n",
      "Epoch 9836/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0109 - val_loss: 0.6180\n",
      "Epoch 9837/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0116 - val_loss: 0.6036\n",
      "Epoch 9838/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0156 - val_loss: 0.6339\n",
      "Epoch 9839/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0286 - val_loss: 0.6230\n",
      "Epoch 9840/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0450 - val_loss: 0.5951\n",
      "Epoch 9841/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0297 - val_loss: 0.6020\n",
      "Epoch 9842/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0215 - val_loss: 0.6159\n",
      "Epoch 9843/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0195 - val_loss: 0.6215\n",
      "Epoch 9844/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0188 - val_loss: 0.6099\n",
      "Epoch 9845/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0138 - val_loss: 0.6250\n",
      "Epoch 9846/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0180 - val_loss: 0.6061\n",
      "Epoch 9847/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0257 - val_loss: 0.6139\n",
      "Epoch 9848/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0195 - val_loss: 0.6292\n",
      "Epoch 9849/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0326 - val_loss: 0.6098\n",
      "Epoch 9850/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0237 - val_loss: 0.6289\n",
      "Epoch 9851/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0250 - val_loss: 0.5934\n",
      "Epoch 9852/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0206 - val_loss: 0.6257\n",
      "Epoch 9853/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0295 - val_loss: 0.6401\n",
      "Epoch 9854/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0339 - val_loss: 0.5875\n",
      "Epoch 9855/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0186 - val_loss: 0.6053\n",
      "Epoch 9856/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0187 - val_loss: 0.5948\n",
      "Epoch 9857/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0222 - val_loss: 0.6052\n",
      "Epoch 9858/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0097 - val_loss: 0.6199\n",
      "Epoch 9859/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0256 - val_loss: 0.6055\n",
      "Epoch 9860/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0162 - val_loss: 0.6085\n",
      "Epoch 9861/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0243 - val_loss: 0.5816\n",
      "Epoch 9862/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0149 - val_loss: 0.6164\n",
      "Epoch 9863/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0616 - val_loss: 0.6476\n",
      "Epoch 9864/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0470 - val_loss: 0.6039\n",
      "Epoch 9865/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0270 - val_loss: 0.6105\n",
      "Epoch 9866/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0151 - val_loss: 0.6124\n",
      "Epoch 9867/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0101 - val_loss: 0.5959\n",
      "Epoch 9868/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0076 - val_loss: 0.5890\n",
      "Epoch 9869/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0084 - val_loss: 0.6062\n",
      "Epoch 9870/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0309 - val_loss: 0.5794\n",
      "Epoch 9871/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0271 - val_loss: 0.6046\n",
      "Epoch 9872/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0197 - val_loss: 0.6403\n",
      "Epoch 9873/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0236 - val_loss: 0.5957\n",
      "Epoch 9874/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0237 - val_loss: 0.5797\n",
      "Epoch 9875/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0297 - val_loss: 0.5790\n",
      "Epoch 9876/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0270 - val_loss: 0.5918\n",
      "Epoch 9877/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0214 - val_loss: 0.6025\n",
      "Epoch 9878/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0140 - val_loss: 0.6073\n",
      "Epoch 9879/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0116 - val_loss: 0.5803\n",
      "Epoch 9880/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0085 - val_loss: 0.5866\n",
      "Epoch 9881/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0127 - val_loss: 0.6024\n",
      "Epoch 9882/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0112 - val_loss: 0.5976\n",
      "Epoch 9883/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 733us/step - loss: 0.0170 - val_loss: 0.6146\n",
      "Epoch 9884/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0180 - val_loss: 0.5935\n",
      "Epoch 9885/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0249 - val_loss: 0.6226\n",
      "Epoch 9886/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0370 - val_loss: 0.6018\n",
      "Epoch 9887/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0143 - val_loss: 0.6218\n",
      "Epoch 9888/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0140 - val_loss: 0.6058\n",
      "Epoch 9889/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0132 - val_loss: 0.5839\n",
      "Epoch 9890/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0195 - val_loss: 0.6379\n",
      "Epoch 9891/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0508 - val_loss: 0.6349\n",
      "Epoch 9892/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0494 - val_loss: 0.6235\n",
      "Epoch 9893/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0519 - val_loss: 0.5923\n",
      "Epoch 9894/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0235 - val_loss: 0.6160\n",
      "Epoch 9895/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0158 - val_loss: 0.5936\n",
      "Epoch 9896/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0173 - val_loss: 0.6217\n",
      "Epoch 9897/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0107 - val_loss: 0.6102\n",
      "Epoch 9898/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0104 - val_loss: 0.6138\n",
      "Epoch 9899/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0114 - val_loss: 0.6047\n",
      "Epoch 9900/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0135 - val_loss: 0.5843\n",
      "Epoch 9901/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0189 - val_loss: 0.5955\n",
      "Epoch 9902/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0199 - val_loss: 0.5928\n",
      "Epoch 9903/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0179 - val_loss: 0.6281\n",
      "Epoch 9904/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0164 - val_loss: 0.5881\n",
      "Epoch 9905/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0179 - val_loss: 0.6028\n",
      "Epoch 9906/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0231 - val_loss: 0.6347\n",
      "Epoch 9907/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0521 - val_loss: 0.6271\n",
      "Epoch 9908/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0455 - val_loss: 0.5731\n",
      "Epoch 9909/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0254 - val_loss: 0.6027\n",
      "Epoch 9910/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0162 - val_loss: 0.5946\n",
      "Epoch 9911/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0122 - val_loss: 0.6051\n",
      "Epoch 9912/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0058 - val_loss: 0.5821\n",
      "Epoch 9913/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0106 - val_loss: 0.5881\n",
      "Epoch 9914/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0298 - val_loss: 0.5906\n",
      "Epoch 9915/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0464 - val_loss: 0.6387\n",
      "Epoch 9916/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0459 - val_loss: 0.5933\n",
      "Epoch 9917/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0278 - val_loss: 0.6066\n",
      "Epoch 9918/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0119 - val_loss: 0.6040\n",
      "Epoch 9919/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0183 - val_loss: 0.6083\n",
      "Epoch 9920/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0460 - val_loss: 0.6106\n",
      "Epoch 9921/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0358 - val_loss: 0.6101\n",
      "Epoch 9922/10000\n",
      "130/130 [==============================] - 0s 878us/step - loss: 0.0184 - val_loss: 0.6003\n",
      "Epoch 9923/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0091 - val_loss: 0.5967\n",
      "Epoch 9924/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0062 - val_loss: 0.5985\n",
      "Epoch 9925/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0075 - val_loss: 0.6086\n",
      "Epoch 9926/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0170 - val_loss: 0.5748\n",
      "Epoch 9927/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0148 - val_loss: 0.5960\n",
      "Epoch 9928/10000\n",
      "130/130 [==============================] - 0s 821us/step - loss: 0.0190 - val_loss: 0.6202\n",
      "Epoch 9929/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0274 - val_loss: 0.5957\n",
      "Epoch 9930/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0167 - val_loss: 0.5969\n",
      "Epoch 9931/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0184 - val_loss: 0.6062\n",
      "Epoch 9932/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0199 - val_loss: 0.6010\n",
      "Epoch 9933/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0161 - val_loss: 0.5924\n",
      "Epoch 9934/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0094 - val_loss: 0.6157\n",
      "Epoch 9935/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0103 - val_loss: 0.6042\n",
      "Epoch 9936/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0385 - val_loss: 0.5963\n",
      "Epoch 9937/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0891 - val_loss: 0.5911\n",
      "Epoch 9938/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0564 - val_loss: 0.6258\n",
      "Epoch 9939/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0314 - val_loss: 0.6116\n",
      "Epoch 9940/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0185 - val_loss: 0.5965\n",
      "Epoch 9941/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0212 - val_loss: 0.6036\n",
      "Epoch 9942/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0122 - val_loss: 0.6053\n",
      "Epoch 9943/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0083 - val_loss: 0.6020\n",
      "Epoch 9944/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0105 - val_loss: 0.5889\n",
      "Epoch 9945/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0110 - val_loss: 0.6134\n",
      "Epoch 9946/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0125 - val_loss: 0.6165\n",
      "Epoch 9947/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0236 - val_loss: 0.6195\n",
      "Epoch 9948/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0285 - val_loss: 0.6149\n",
      "Epoch 9949/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0378 - val_loss: 0.6311\n",
      "Epoch 9950/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0266 - val_loss: 0.6177\n",
      "Epoch 9951/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0101 - val_loss: 0.6054\n",
      "Epoch 9952/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0099 - val_loss: 0.6079\n",
      "Epoch 9953/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0099 - val_loss: 0.6107\n",
      "Epoch 9954/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0136 - val_loss: 0.5671\n",
      "Epoch 9955/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0232 - val_loss: 0.5796\n",
      "Epoch 9956/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0311 - val_loss: 0.5924\n",
      "Epoch 9957/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0259 - val_loss: 0.5910\n",
      "Epoch 9958/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0215 - val_loss: 0.6095\n",
      "Epoch 9959/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 724us/step - loss: 0.0185 - val_loss: 0.6299\n",
      "Epoch 9960/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0189 - val_loss: 0.6214\n",
      "Epoch 9961/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0127 - val_loss: 0.6216\n",
      "Epoch 9962/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0117 - val_loss: 0.6162\n",
      "Epoch 9963/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0228 - val_loss: 0.5928\n",
      "Epoch 9964/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0225 - val_loss: 0.5891\n",
      "Epoch 9965/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0131 - val_loss: 0.5778\n",
      "Epoch 9966/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0145 - val_loss: 0.6326\n",
      "Epoch 9967/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0292 - val_loss: 0.6332\n",
      "Epoch 9968/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0340 - val_loss: 0.6220\n",
      "Epoch 9969/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0382 - val_loss: 0.6043\n",
      "Epoch 9970/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0357 - val_loss: 0.6053\n",
      "Epoch 9971/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0255 - val_loss: 0.6091\n",
      "Epoch 9972/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0175 - val_loss: 0.5818\n",
      "Epoch 9973/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0319 - val_loss: 0.5896\n",
      "Epoch 9974/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0263 - val_loss: 0.5857\n",
      "Epoch 9975/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0174 - val_loss: 0.6301\n",
      "Epoch 9976/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0209 - val_loss: 0.6675\n",
      "Epoch 9977/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0502 - val_loss: 0.6065\n",
      "Epoch 9978/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0248 - val_loss: 0.6049\n",
      "Epoch 9979/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0134 - val_loss: 0.6083\n",
      "Epoch 9980/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0103 - val_loss: 0.6103\n",
      "Epoch 9981/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0126 - val_loss: 0.5967\n",
      "Epoch 9982/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0129 - val_loss: 0.6153\n",
      "Epoch 9983/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0105 - val_loss: 0.6130\n",
      "Epoch 9984/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0076 - val_loss: 0.6215\n",
      "Epoch 9985/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0121 - val_loss: 0.6208\n",
      "Epoch 9986/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0105 - val_loss: 0.6169\n",
      "Epoch 9987/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0194 - val_loss: 0.6109\n",
      "Epoch 9988/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0280 - val_loss: 0.6264\n",
      "Epoch 9989/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0467 - val_loss: 0.6012\n",
      "Epoch 9990/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0427 - val_loss: 0.6149\n",
      "Epoch 9991/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0328 - val_loss: 0.6125\n",
      "Epoch 9992/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0220 - val_loss: 0.5940\n",
      "Epoch 9993/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0219 - val_loss: 0.5998\n",
      "Epoch 9994/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0122 - val_loss: 0.5872\n",
      "Epoch 9995/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0096 - val_loss: 0.5995\n",
      "Epoch 9996/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0220 - val_loss: 0.6224\n",
      "Epoch 9997/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0288 - val_loss: 0.6083\n",
      "Epoch 9998/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0348 - val_loss: 0.6254\n",
      "Epoch 9999/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0169 - val_loss: 0.6176\n",
      "Epoch 10000/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0178 - val_loss: 0.6131\n",
      "CPU times: user 35min 33s, sys: 6min 29s, total: 42min 3s\n",
      "Wall time: 16min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tmp = fp_datamodel.fit(\n",
    "    x[p],y[p],\n",
    "    epochs=10000,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(smooth(history['loss'],20)[100:])\n",
    "plt.plot(smooth(history['val_loss'],20)[100:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565715319027951\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.square(y.mean() - y.flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8150286108644117\n",
      "1.58125\n"
     ]
    }
   ],
   "source": [
    "pred = fp_datamodel.predict(test_dfs[-1].drop('quality',axis=1).to_numpy())\n",
    "print(np.mean(np.square(pred.flatten() - test_dfs[-1]['quality'].to_numpy().flatten())))\n",
    "print(np.mean(np.square(test_dfs[0]['quality'].mean() - test_dfs[-1]['quality'].to_numpy().flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36627927928501364\n",
      "0.6231343283582089\n"
     ]
    }
   ],
   "source": [
    "pred = fp_datamodel.predict(test_dfs[0].drop('quality',axis=1).to_numpy())\n",
    "print(np.mean(np.square(pred.flatten() - test_dfs[0]['quality'].to_numpy().flatten())))\n",
    "print(np.mean(np.square(test_dfs[0]['quality'].mean() - test_dfs[0]['quality'].to_numpy().flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CWAcc1(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx, name='classwise_accuracy1', num_classes=10, **kwargs):\n",
    "        super(CWAcc1, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.class_idx = class_idx\n",
    "        self.num_correct = self.add_weight(name='num_correct',initializer='zeros')\n",
    "        self.num_samples = self.add_weight(name='num_samples',initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.reshape(tf.cast(y_true, tf.int16),(1,-1))\n",
    "        y_pred = tf.reshape(tf.cast(tf.argmax(y_pred,axis=1), tf.int16),(1,-1))\n",
    "                \n",
    "        count_correct = tf.math.reduce_sum(tf.cast(tf.math.logical_and(\n",
    "            tf.equal(y_true,y_pred),\n",
    "            tf.equal(y_true,tf.math.multiply(tf.ones_like(y_true),self.class_idx))\n",
    "        ),dtype=tf.float32))\n",
    "        \n",
    "        count_class = tf.math.reduce_sum(tf.cast(\n",
    "            tf.equal(y_true,tf.math.multiply(tf.ones_like(y_true),self.class_idx)),\n",
    "            dtype=tf.float32\n",
    "        ))\n",
    "        \n",
    "        self.num_correct.assign_add(count_correct)\n",
    "        self.num_samples.assign_add(count_class)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.math.divide_no_nan(self.num_correct,self.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth[:-box_pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[0.7664722 , 0.        , 0.        , 0.8010844 , 0.26033926,\n",
       "        0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_mask(grads):\n",
    "    mask = []\n",
    "    for g in grads:\n",
    "        size = g.shape[0]\n",
    "        m = 2\n",
    "        assert m%1==0\n",
    "\n",
    "        split = tf.concat([tf.ones(size//m)*i for i in range(m)],0)\n",
    "        split = tf.random.shuffle(split)\n",
    "        mask.append(tf.reshape(split,(1,-1)))\n",
    "\n",
    "    return mask\n",
    "\n",
    "grads = [tf.random.uniform(((x+1)*2,)) for x in range(10)]\n",
    "\n",
    "res = gen_mask(grads)\n",
    "tf.math.multiply(res[2],grads[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import random\n",
    "\n",
    "class Car():\n",
    "    def __init__(self,neighbors,p=1.0):\n",
    "        self.neighbors = neighbors\n",
    "        self.fwd_q = []\n",
    "        self.rec_grad = set()\n",
    "        self.new_grad = []\n",
    "        self.p = p\n",
    "        \n",
    "    def forward(self,lst_cars,):\n",
    "        for n,c in enumerate(lst_cars):\n",
    "            if n in self.neighbors:\n",
    "                for grad in self.fwd_q:\n",
    "                    if self.p < random.random():\n",
    "                        c.receive(grad)\n",
    "                    \n",
    "    def _hash(self,data):\n",
    "        bts = str(data).encode('utf-8')#tf.io.serialize_tensor(grad)\n",
    "        return hashlib.sha256(bts).digest()\n",
    "    \n",
    "    def _mark_seen(self,data,hash=False):\n",
    "        tmp = self._hash(data) if hash else data\n",
    "        self.rec_grad.add(tmp)\n",
    "        \n",
    "    def already_rec(self,grad,):\n",
    "        hashed = self._hash(grad)\n",
    "        \n",
    "        if hashed in self.rec_grad:\n",
    "            return (True,hashed)\n",
    "        else:\n",
    "            return (False,hashed)\n",
    "        \n",
    "    def apply_grad(self,grad,hashed,target,):\n",
    "        self._mark_seen(hashed)\n",
    "        return [tf.math.add(t,g) for t,g in zip(target,grad)]\n",
    "    \n",
    "    def apply_grads(self,target,):\n",
    "        self.fwd_q=[]\n",
    "        for g in self.new_grad:\n",
    "            bl,hashed = self.already_rec(g)\n",
    "            if not bl:\n",
    "                target = self.apply_grad(g,hashed,target)\n",
    "                self.fwd_q.append(g)\n",
    "        self.new_grad=[]\n",
    "        return target\n",
    "    \n",
    "    def receive(self,grad,):\n",
    "        self.new_grad.append(grad)\n",
    "        \n",
    "    def load(self,grad,):\n",
    "        self.fwd_q.append(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from copy import deepcopy\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cw_acc(y_true,y_pred):\n",
    "    y_pred = np.argmax(y_pred,axis=1)\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    return matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "def gen_mask(grads,m=2):\n",
    "    mask = []\n",
    "    for g in grads:\n",
    "        size = g.shape[-1]\n",
    "        assert m%1==0\n",
    "\n",
    "        split = tf.concat([tf.ones(size//m)*i for i in range(m)],0)\n",
    "        split = tf.random.shuffle(split)\n",
    "        mask.append(tf.reshape(split,(1,-1)))\n",
    "\n",
    "    return mask\n",
    "\n",
    "class DistMLP(keras.Model):\n",
    "    def __init__(self,mode='none',p=1.0):\n",
    "        super(DistMLP, self).__init__()\n",
    "        self.mod1 = Sequential([\n",
    "            layers.Dense(64, activation='sigmoid', input_shape=(11,)),\n",
    "            layers.Dense(32, activation='sigmoid'),\n",
    "            layers.Dense(16, activation='sigmoid'),\n",
    "            layers.Dense(1, 'linear')\n",
    "        ])\n",
    "        \n",
    "        self.mod2 = tf.keras.models.clone_model(self.mod1)\n",
    "        self.mod3 = tf.keras.models.clone_model(self.mod1)\n",
    "        self.mod4 = tf.keras.models.clone_model(self.mod1)\n",
    "        \n",
    "        self.mode=mode\n",
    "        \n",
    "        self.cars = [Car([i%2,],p=p) for i in range(1,5)]\n",
    "        self.gradients = []\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.mod1(data)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x1,y1,x2,y2,x3,y3,x4,y4, = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred1 = self.mod1(x1,training=True)\n",
    "            y_pred2 = self.mod2(x2,training=True)\n",
    "            y_pred3 = self.mod3(x3,training=True)\n",
    "            y_pred4 = self.mod4(x4,training=True)\n",
    "            loss1 = self.compiled_loss(y1,y_pred1)\n",
    "            loss2 = self.compiled_loss(y2,y_pred2)\n",
    "            loss3 = self.compiled_loss(y3,y_pred3)\n",
    "            loss4 = self.compiled_loss(y4,y_pred4)\n",
    "\n",
    "        grads = tape.gradient([loss1,loss2,loss3,loss4], self.trainable_weights)\n",
    "        \n",
    "        if self.mode=='none':\n",
    "            # Independent Learning\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        elif self.mode=='simple_add':\n",
    "            # Traditional Federated Learning: https://www.cs.cornell.edu/~shmat/shmat_ccs15.pdf\n",
    "            temp = [tf.math.divide(tf.math.add_n([grads[n+i*(len(grads)//4)] for i in range(4)]) for n in range(len(grads)//4),4)]\n",
    "            self.optimizer.apply_gradients(zip([*temp,*temp,*temp,*temp], self.trainable_weights))\n",
    "        elif self.mode=='djgrad':\n",
    "            # Proposed Method\n",
    "            grad_mask = [tf.reshape(m,(-1,)) if len(g.shape)==1 else m for m,g in zip(gen_mask(grads),grads)]\n",
    "            masked_grads = [tf.math.multiply(g,m) for m,g in zip(grad_mask,grads)]\n",
    "            new_grads = []\n",
    "            \n",
    "            for n,c in enumerate(self.cars):\n",
    "                i1,i2 = (len(grads)//4)*n,(len(grads)//4)*(n+1)\n",
    "                new_grads+=c.apply_grads(grads[i1:i2])\n",
    "                c.load(masked_grads[i1:i2])\n",
    "                c._mark_seen(masked_grads[i1:i2],True)\n",
    "                c.forward(self.cars)\n",
    "                 \n",
    "            self.optimizer.apply_gradients(zip(\n",
    "                [tf.math.add(g,n) for g,n in zip(grads,new_grads)],\n",
    "                self.trainable_weights))\n",
    "        \n",
    "        # Need a metric that gives accuracy for each model individually\n",
    "        for m in self.compiled_metrics._user_metrics:\n",
    "            m.update_state(tf.concat([y1,y2,y3,y4],0), tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0),source_array=tf.concat([x1[:,-1],x2[:,-1],x3[:,-1],x4[:,-1]],0))\n",
    "\n",
    "        return {m.name: m.result() for m in self.compiled_metrics._user_metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        y_pred1 = self.mod1(x,training=False)\n",
    "        y_pred2 = self.mod2(x,training=False)\n",
    "        y_pred3 = self.mod3(x,training=False)\n",
    "        y_pred4 = self.mod4(x,training=False)\n",
    "                \n",
    "        self.compiled_loss(tf.concat([y,y,y,y,],0),tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0))\n",
    "        for m in self.compiled_metrics._user_metrics:\n",
    "            m.update_state(tf.concat([y,y,y,y],0),tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0),source_array=tf.concat([x[:,-1],x[:,-1],x[:,-1],x[:,-1]],0))\n",
    "\n",
    "        return {m.name: m.result() for m in self.compiled_metrics._user_metrics}\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        for m in self.compiled_metrics._user_metrics:\n",
    "            m.reset_state()\n",
    "        for m in self.metrics:\n",
    "            m.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CWMet(tf.keras.metrics.Metric):\n",
    "    def __init__(self, car_idx, minmax, name='classwise_accuracy', num_cars=4, **kwargs):\n",
    "        super(CWMet, self).__init__(name=name, **kwargs)\n",
    "        self.num_cars = num_cars\n",
    "        self.car_idx = car_idx\n",
    "        self.minmax = minmax\n",
    "        self.loss = self.add_weight(name='loss',initializer='zeros')\n",
    "        self.num_samples = self.add_weight(name='num_samples',initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, source_array=None, sample_weight=None):\n",
    "        y_true = tf.reshape(y_true, (4,-1))[self.car_idx]\n",
    "        y_pred = tf.reshape(y_pred, (4,-1))[self.car_idx]\n",
    "        source_array = tf.reshape(source_array, (4,-1))[self.car_idx]\n",
    "\n",
    "        bl_mask = tf.math.logical_and(\n",
    "            tf.math.greater_equal(source_array, self.minmax[0]),\n",
    "            tf.math.greater_equal(self.minmax[1],source_array),\n",
    "        )\n",
    "        \n",
    "#         print(source_array)\n",
    "        print(y_true.shape,tf.boolean_mask(tf.cast(y_true, tf.float32), bl_mask).shape)\n",
    "        \n",
    "        y_true = tf.boolean_mask(tf.cast(y_true, tf.float32), bl_mask)\n",
    "        y_pred = tf.boolean_mask(tf.cast(y_pred, tf.float32), bl_mask)\n",
    "        \n",
    "#         print(np.max(source_array),np.min(source_array),self.minmax,source_array.shape,y_true)\n",
    "#         print(tf.math.greater_equal(self.minmax[0],source_array))\n",
    "        \n",
    "        loss = tf.math.reduce_sum(tf.math.square(y_true-y_pred))\n",
    "\n",
    "        count_class = tf.math.reduce_sum(tf.cast(bl_mask,dtype=tf.float32))#tf.cast(y_true.get_shape().as_list()[0],dtype=tf.float32)\n",
    "        \n",
    "        self.loss.assign_add(loss)\n",
    "        self.num_samples.assign_add(count_class)\n",
    "\n",
    "    def result(self):\n",
    "#         print(self.num_samples)\n",
    "        return tf.math.divide_no_nan(self.loss,self.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len = min([x.shape[0] for x in train_dfs])\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    train_dfs[0].drop('quality',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[0]['quality'].to_numpy()[:min_len],\n",
    "    train_dfs[1].drop('quality',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[1]['quality'].to_numpy()[:min_len],\n",
    "    train_dfs[2].drop('quality',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[2]['quality'].to_numpy()[:min_len],\n",
    "    train_dfs[3].drop('quality',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[3]['quality'].to_numpy()[:min_len],\n",
    ")).shuffle(100).batch(128,True)\n",
    "\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    np.concatenate((\n",
    "        test_dfs[0].drop('quality',axis=1).to_numpy(),\n",
    "        test_dfs[1].drop('quality',axis=1).to_numpy(),\n",
    "        test_dfs[2].drop('quality',axis=1).to_numpy(),\n",
    "        test_dfs[3].drop('quality',axis=1).to_numpy(),\n",
    "    )),\n",
    "    np.concatenate((\n",
    "        test_dfs[0]['quality'].to_numpy(),\n",
    "        test_dfs[1]['quality'].to_numpy(),\n",
    "        test_dfs[2]['quality'].to_numpy(),\n",
    "        test_dfs[3]['quality'].to_numpy(),\n",
    "    ))\n",
    ")).shuffle(100).batch(128,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 35.2617 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 25.2402 - ca2-[9.5,10.3): 26.1241 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 26.6720 - ca3-[10.3,11.3): 29.7240 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 34.3360 - ca4-[11.3,14.9): 36.5978 - val_ca1-[8.0,9.5): 31.5946 - val_ca1-[9.5,10.3): 33.0574 - val_ca1-[10.3,11.3): 37.4782 - val_ca1-[11.3,14.9): 43.8057 - val_ca2-[8.0,9.5): 22.6141 - val_ca2-[9.5,10.3): 23.7830 - val_ca2-[10.3,11.3): 27.5970 - val_ca2-[11.3,14.9): 33.0448 - val_ca3-[8.0,9.5): 21.5477 - val_ca3-[9.5,10.3): 22.6995 - val_ca3-[10.3,11.3): 26.4370 - val_ca3-[11.3,14.9): 31.7492 - val_ca4-[8.0,9.5): 23.0317 - val_ca4-[9.5,10.3): 24.2364 - val_ca4-[10.3,11.3): 28.0360 - val_ca4-[11.3,14.9): 33.4734\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 31.1642 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 21.8687 - ca2-[9.5,10.3): 22.8079 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 22.8432 - ca3-[10.3,11.3): 25.6363 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 30.5075 - ca4-[11.3,14.9): 32.5921 - val_ca1-[8.0,9.5): 27.8593 - val_ca1-[9.5,10.3): 29.2114 - val_ca1-[10.3,11.3): 33.3605 - val_ca1-[11.3,14.9): 39.5640 - val_ca2-[8.0,9.5): 19.7112 - val_ca2-[9.5,10.3): 20.7947 - val_ca2-[10.3,11.3): 24.3554 - val_ca2-[11.3,14.9): 29.6616 - val_ca3-[8.0,9.5): 18.1308 - val_ca3-[9.5,10.3): 19.1838 - val_ca3-[10.3,11.3): 22.6341 - val_ca3-[11.3,14.9): 27.7296 - val_ca4-[8.0,9.5): 19.9751 - val_ca4-[9.5,10.3): 21.0660 - val_ca4-[10.3,11.3): 24.6024 - val_ca4-[11.3,14.9): 29.8838\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 27.5205 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 18.9372 - ca2-[9.5,10.3): 19.9333 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 19.3708 - ca3-[10.3,11.3): 21.8690 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 26.5994 - ca4-[11.3,14.9): 28.8835 - val_ca1-[8.0,9.5): 24.5031 - val_ca1-[9.5,10.3): 25.7639 - val_ca1-[10.3,11.3): 29.6956 - val_ca1-[11.3,14.9): 35.5634 - val_ca2-[8.0,9.5): 17.0958 - val_ca2-[9.5,10.3): 18.1086 - val_ca2-[10.3,11.3): 21.4527 - val_ca2-[11.3,14.9): 26.4418 - val_ca3-[8.0,9.5): 15.0913 - val_ca3-[9.5,10.3): 16.0487 - val_ca3-[10.3,11.3): 19.2378 - val_ca3-[11.3,14.9): 23.9511 - val_ca4-[8.0,9.5): 17.3981 - val_ca4-[9.5,10.3): 18.3971 - val_ca4-[10.3,11.3): 21.7347 - val_ca4-[11.3,14.9): 26.7186\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 24.2687 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 16.5538 - ca2-[9.5,10.3): 17.3664 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 16.2063 - ca3-[10.3,11.3): 18.6549 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 23.3267 - ca4-[11.3,14.9): 25.8155 - val_ca1-[8.0,9.5): 21.6315 - val_ca1-[9.5,10.3): 22.8040 - val_ca1-[10.3,11.3): 26.5529 - val_ca1-[11.3,14.9): 32.0257 - val_ca2-[8.0,9.5): 14.7603 - val_ca2-[9.5,10.3): 15.7025 - val_ca2-[10.3,11.3): 18.8708 - val_ca2-[11.3,14.9): 23.4904 - val_ca3-[8.0,9.5): 12.4432 - val_ca3-[9.5,10.3): 13.3116 - val_ca3-[10.3,11.3): 16.2877 - val_ca3-[11.3,14.9): 20.5874 - val_ca4-[8.0,9.5): 15.2677 - val_ca4-[9.5,10.3): 16.1847 - val_ca4-[10.3,11.3): 19.3681 - val_ca4-[11.3,14.9): 24.0224\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 21.4102 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 14.2779 - ca2-[9.5,10.3): 14.9749 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 13.5525 - ca3-[10.3,11.3): 15.7137 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 21.1085 - ca4-[11.3,14.9): 23.1893 - val_ca1-[8.0,9.5): 19.1844 - val_ca1-[9.5,10.3): 20.2644 - val_ca1-[10.3,11.3): 23.8125 - val_ca1-[11.3,14.9): 28.9432 - val_ca2-[8.0,9.5): 12.7219 - val_ca2-[9.5,10.3): 13.5903 - val_ca2-[10.3,11.3): 16.5629 - val_ca2-[11.3,14.9): 20.8473 - val_ca3-[8.0,9.5): 10.2022 - val_ca3-[9.5,10.3): 10.9647 - val_ca3-[10.3,11.3): 13.6987 - val_ca3-[11.3,14.9): 17.6042 - val_ca4-[8.0,9.5): 13.4608 - val_ca4-[9.5,10.3): 14.2997 - val_ca4-[10.3,11.3): 17.3064 - val_ca4-[11.3,14.9): 21.6662\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 18.9335 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 12.1594 - ca2-[9.5,10.3): 12.9065 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 11.1353 - ca3-[10.3,11.3): 13.2616 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 19.1786 - ca4-[11.3,14.9): 20.9419 - val_ca1-[8.0,9.5): 17.0683 - val_ca1-[9.5,10.3): 18.0600 - val_ca1-[10.3,11.3): 21.4191 - val_ca1-[11.3,14.9): 26.1542 - val_ca2-[8.0,9.5): 10.9765 - val_ca2-[9.5,10.3): 11.7699 - val_ca2-[10.3,11.3): 14.5569 - val_ca2-[11.3,14.9): 18.4696 - val_ca3-[8.0,9.5): 8.3992 - val_ca3-[9.5,10.3): 9.0616 - val_ca3-[10.3,11.3): 11.5509 - val_ca3-[11.3,14.9): 15.0276 - val_ca4-[8.0,9.5): 11.8586 - val_ca4-[9.5,10.3): 12.6392 - val_ca4-[10.3,11.3): 15.4749 - val_ca4-[11.3,14.9): 19.4999\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 16.9320 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 10.6113 - ca2-[9.5,10.3): 11.1828 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 9.3939 - ca3-[10.3,11.3): 11.2191 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 17.3299 - ca4-[11.3,14.9): 19.1167 - val_ca1-[8.0,9.5): 15.2723 - val_ca1-[9.5,10.3): 16.2079 - val_ca1-[10.3,11.3): 19.3882 - val_ca1-[11.3,14.9): 23.9315 - val_ca2-[8.0,9.5): 9.5159 - val_ca2-[9.5,10.3): 10.2373 - val_ca2-[10.3,11.3): 12.8406 - val_ca2-[11.3,14.9): 16.5479 - val_ca3-[8.0,9.5): 6.9634 - val_ca3-[9.5,10.3): 7.5461 - val_ca3-[10.3,11.3): 9.8297 - val_ca3-[11.3,14.9): 13.0724 - val_ca4-[8.0,9.5): 10.4467 - val_ca4-[9.5,10.3): 11.1816 - val_ca4-[10.3,11.3): 13.8611 - val_ca4-[11.3,14.9): 17.7126\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 15.1796 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 8.9984 - ca2-[9.5,10.3): 9.7792 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 7.7495 - ca3-[10.3,11.3): 9.6359 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 15.3015 - ca4-[11.3,14.9): 17.3039 - val_ca1-[8.0,9.5): 13.7890 - val_ca1-[9.5,10.3): 14.6770 - val_ca1-[10.3,11.3): 17.7268 - val_ca1-[11.3,14.9): 22.1134 - val_ca2-[8.0,9.5): 8.2960 - val_ca2-[9.5,10.3): 8.9547 - val_ca2-[10.3,11.3): 11.4068 - val_ca2-[11.3,14.9): 14.9290 - val_ca3-[8.0,9.5): 5.8132 - val_ca3-[9.5,10.3): 6.3276 - val_ca3-[10.3,11.3): 8.4417 - val_ca3-[11.3,14.9): 11.4688 - val_ca4-[8.0,9.5): 9.2595 - val_ca4-[9.5,10.3): 9.9488 - val_ca4-[10.3,11.3): 12.5030 - val_ca4-[11.3,14.9): 16.1913\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 13.7458 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 7.9122 - ca2-[9.5,10.3): 8.5527 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 6.5145 - ca3-[10.3,11.3): 8.2731 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 14.1492 - ca4-[11.3,14.9): 15.8119 - val_ca1-[8.0,9.5): 12.5406 - val_ca1-[9.5,10.3): 13.4022 - val_ca1-[10.3,11.3): 16.3553 - val_ca1-[11.3,14.9): 20.5556 - val_ca2-[8.0,9.5): 7.2664 - val_ca2-[9.5,10.3): 7.8782 - val_ca2-[10.3,11.3): 10.2125 - val_ca2-[11.3,14.9): 13.5344 - val_ca3-[8.0,9.5): 4.8809 - val_ca3-[9.5,10.3): 5.3381 - val_ca3-[10.3,11.3): 7.3125 - val_ca3-[11.3,14.9): 10.1164 - val_ca4-[8.0,9.5): 8.2399 - val_ca4-[9.5,10.3): 8.8990 - val_ca4-[10.3,11.3): 11.3502 - val_ca4-[11.3,14.9): 14.8530\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 12.4744 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 6.9463 - ca2-[9.5,10.3): 7.5533 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 5.5736 - ca3-[10.3,11.3): 7.1227 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 12.8298 - ca4-[11.3,14.9): 14.5038 - val_ca1-[8.0,9.5): 11.5038 - val_ca1-[9.5,10.3): 12.3112 - val_ca1-[10.3,11.3): 15.1409 - val_ca1-[11.3,14.9): 19.2884 - val_ca2-[8.0,9.5): 6.3874 - val_ca2-[9.5,10.3): 6.9407 - val_ca2-[10.3,11.3): 9.1450 - val_ca2-[11.3,14.9): 12.3697 - val_ca3-[8.0,9.5): 4.1021 - val_ca3-[9.5,10.3): 4.4950 - val_ca3-[10.3,11.3): 6.3244 - val_ca3-[11.3,14.9): 8.9965 - val_ca4-[8.0,9.5): 7.3631 - val_ca4-[9.5,10.3): 7.9717 - val_ca4-[10.3,11.3): 10.3032 - val_ca4-[11.3,14.9): 13.7255\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 11.5659 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 6.1515 - ca2-[9.5,10.3): 6.6958 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 4.7713 - ca3-[10.3,11.3): 6.2247 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 11.5160 - ca4-[11.3,14.9): 13.2924 - val_ca1-[8.0,9.5): 10.5938 - val_ca1-[9.5,10.3): 11.3626 - val_ca1-[10.3,11.3): 14.1438 - val_ca1-[11.3,14.9): 18.1403 - val_ca2-[8.0,9.5): 5.6445 - val_ca2-[9.5,10.3): 6.1538 - val_ca2-[10.3,11.3): 8.2859 - val_ca2-[11.3,14.9): 11.3358 - val_ca3-[8.0,9.5): 3.4657 - val_ca3-[9.5,10.3): 3.8076 - val_ca3-[10.3,11.3): 5.5445 - val_ca3-[11.3,14.9): 8.0244 - val_ca4-[8.0,9.5): 6.6023 - val_ca4-[9.5,10.3): 7.1680 - val_ca4-[10.3,11.3): 9.4370 - val_ca4-[11.3,14.9): 12.6941\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 10.6827 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 5.4198 - ca2-[9.5,10.3): 5.9147 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 4.3125 - ca3-[10.3,11.3): 5.4794 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 10.7182 - ca4-[11.3,14.9): 12.3179 - val_ca1-[8.0,9.5): 9.8174 - val_ca1-[9.5,10.3): 10.5473 - val_ca1-[10.3,11.3): 13.2169 - val_ca1-[11.3,14.9): 17.0809 - val_ca2-[8.0,9.5): 5.0259 - val_ca2-[9.5,10.3): 5.4916 - val_ca2-[10.3,11.3): 7.5096 - val_ca2-[11.3,14.9): 10.4186 - val_ca3-[8.0,9.5): 2.9432 - val_ca3-[9.5,10.3): 3.2388 - val_ca3-[10.3,11.3): 4.8505 - val_ca3-[11.3,14.9): 7.1743 - val_ca4-[8.0,9.5): 5.9321 - val_ca4-[9.5,10.3): 6.4553 - val_ca4-[10.3,11.3): 8.6125 - val_ca4-[11.3,14.9): 11.7296\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 9.9171 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 4.7604 - ca2-[9.5,10.3): 5.3121 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 3.5528 - ca3-[10.3,11.3): 4.7268 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 10.0213 - ca4-[11.3,14.9): 11.4384 - val_ca1-[8.0,9.5): 9.1324 - val_ca1-[9.5,10.3): 9.8284 - val_ca1-[10.3,11.3): 12.4133 - val_ca1-[11.3,14.9): 15.9827 - val_ca2-[8.0,9.5): 4.4871 - val_ca2-[9.5,10.3): 4.9143 - val_ca2-[10.3,11.3): 6.8395 - val_ca2-[11.3,14.9): 9.4807 - val_ca3-[8.0,9.5): 2.5084 - val_ca3-[9.5,10.3): 2.7630 - val_ca3-[10.3,11.3): 4.2730 - val_ca3-[11.3,14.9): 6.3396 - val_ca4-[8.0,9.5): 5.3385 - val_ca4-[9.5,10.3): 5.8234 - val_ca4-[10.3,11.3): 7.8914 - val_ca4-[11.3,14.9): 10.7328\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 9.1996 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 4.2234 - ca2-[9.5,10.3): 4.7340 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 3.1922 - ca3-[10.3,11.3): 4.2332 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 8.9767 - ca4-[11.3,14.9): 10.5397 - val_ca1-[8.0,9.5): 8.5086 - val_ca1-[9.5,10.3): 9.1754 - val_ca1-[10.3,11.3): 11.6857 - val_ca1-[11.3,14.9): 15.3763 - val_ca2-[8.0,9.5): 4.0057 - val_ca2-[9.5,10.3): 4.3968 - val_ca2-[10.3,11.3): 6.2342 - val_ca2-[11.3,14.9): 8.9174 - val_ca3-[8.0,9.5): 2.1558 - val_ca3-[9.5,10.3): 2.3723 - val_ca3-[10.3,11.3): 3.7884 - val_ca3-[11.3,14.9): 5.8501 - val_ca4-[8.0,9.5): 4.8113 - val_ca4-[9.5,10.3): 5.2607 - val_ca4-[10.3,11.3): 7.2424 - val_ca4-[11.3,14.9): 10.1412\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 8.5699 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 3.7090 - ca2-[9.5,10.3): 4.2316 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.6391 - ca3-[10.3,11.3): 3.7759 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 8.5536 - ca4-[11.3,14.9): 9.8738 - val_ca1-[8.0,9.5): 7.9459 - val_ca1-[9.5,10.3): 8.5836 - val_ca1-[10.3,11.3): 11.0201 - val_ca1-[11.3,14.9): 14.4746 - val_ca2-[8.0,9.5): 3.5739 - val_ca2-[9.5,10.3): 3.9303 - val_ca2-[10.3,11.3): 5.6788 - val_ca2-[11.3,14.9): 8.1468 - val_ca3-[8.0,9.5): 1.8577 - val_ca3-[9.5,10.3): 2.0395 - val_ca3-[10.3,11.3): 3.3636 - val_ca3-[11.3,14.9): 5.2289 - val_ca4-[8.0,9.5): 4.3377 - val_ca4-[9.5,10.3): 4.7529 - val_ca4-[10.3,11.3): 6.6471 - val_ca4-[11.3,14.9): 9.3237\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 8.0965 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 3.3316 - ca2-[9.5,10.3): 3.7835 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.2636 - ca3-[10.3,11.3): 3.3087 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 7.6057 - ca4-[11.3,14.9): 9.1836 - val_ca1-[8.0,9.5): 7.4455 - val_ca1-[9.5,10.3): 8.0560 - val_ca1-[10.3,11.3): 10.4395 - val_ca1-[11.3,14.9): 13.8331 - val_ca2-[8.0,9.5): 3.1863 - val_ca2-[9.5,10.3): 3.5090 - val_ca2-[10.3,11.3): 5.1838 - val_ca2-[11.3,14.9): 7.5548 - val_ca3-[8.0,9.5): 1.6137 - val_ca3-[9.5,10.3): 1.7641 - val_ca3-[10.3,11.3): 3.0173 - val_ca3-[11.3,14.9): 4.7821 - val_ca4-[8.0,9.5): 3.9141 - val_ca4-[9.5,10.3): 4.2967 - val_ca4-[10.3,11.3): 6.1199 - val_ca4-[11.3,14.9): 8.7058\n",
      "Epoch 17/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 7.5480 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.9895 - ca2-[9.5,10.3): 3.4055 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.0038 - ca3-[10.3,11.3): 2.9673 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 7.2304 - ca4-[11.3,14.9): 8.5130 - val_ca1-[8.0,9.5): 6.9946 - val_ca1-[9.5,10.3): 7.5803 - val_ca1-[10.3,11.3): 9.8452 - val_ca1-[11.3,14.9): 13.1565 - val_ca2-[8.0,9.5): 2.8372 - val_ca2-[9.5,10.3): 3.1275 - val_ca2-[10.3,11.3): 4.6837 - val_ca2-[11.3,14.9): 6.9386 - val_ca3-[8.0,9.5): 1.4187 - val_ca3-[9.5,10.3): 1.5398 - val_ca3-[10.3,11.3): 2.6918 - val_ca3-[11.3,14.9): 4.3458 - val_ca4-[8.0,9.5): 3.5322 - val_ca4-[9.5,10.3): 3.8837 - val_ca4-[10.3,11.3): 5.5876 - val_ca4-[11.3,14.9): 8.0637\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 7.0565 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.6137 - ca2-[9.5,10.3): 3.0463 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.7422 - ca3-[10.3,11.3): 2.6533 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 6.5722 - ca4-[11.3,14.9): 7.8718 - val_ca1-[8.0,9.5): 6.5822 - val_ca1-[9.5,10.3): 7.1442 - val_ca1-[10.3,11.3): 9.4037 - val_ca1-[11.3,14.9): 12.5854 - val_ca2-[8.0,9.5): 2.5242 - val_ca2-[9.5,10.3): 2.7834 - val_ca2-[10.3,11.3): 4.3030 - val_ca2-[11.3,14.9): 6.4291 - val_ca3-[8.0,9.5): 1.2553 - val_ca3-[9.5,10.3): 1.3496 - val_ca3-[10.3,11.3): 2.4678 - val_ca3-[11.3,14.9): 4.0219 - val_ca4-[8.0,9.5): 3.1869 - val_ca4-[9.5,10.3): 3.5086 - val_ca4-[10.3,11.3): 5.1816 - val_ca4-[11.3,14.9): 7.5277\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 6.6461 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.3012 - ca2-[9.5,10.3): 2.7344 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.6246 - ca3-[10.3,11.3): 2.4573 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 6.1740 - ca4-[11.3,14.9): 7.3523 - val_ca1-[8.0,9.5): 6.2029 - val_ca1-[9.5,10.3): 6.7421 - val_ca1-[10.3,11.3): 8.9463 - val_ca1-[11.3,14.9): 12.0551 - val_ca2-[8.0,9.5): 2.2457 - val_ca2-[9.5,10.3): 2.4749 - val_ca2-[10.3,11.3): 3.9217 - val_ca2-[11.3,14.9): 5.9456 - val_ca3-[8.0,9.5): 1.1207 - val_ca3-[9.5,10.3): 1.1900 - val_ca3-[10.3,11.3): 2.2479 - val_ca3-[11.3,14.9): 3.7151 - val_ca4-[8.0,9.5): 2.8741 - val_ca4-[9.5,10.3): 3.1670 - val_ca4-[10.3,11.3): 4.7701 - val_ca4-[11.3,14.9): 7.0187\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 6.3992 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.0173 - ca2-[9.5,10.3): 2.4058 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.3827 - ca3-[10.3,11.3): 2.2218 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.8625 - ca4-[11.3,14.9): 6.8229 - val_ca1-[8.0,9.5): 5.8636 - val_ca1-[9.5,10.3): 6.3662 - val_ca1-[10.3,11.3): 8.5169 - val_ca1-[11.3,14.9): 11.5653 - val_ca2-[8.0,9.5): 2.0062 - val_ca2-[9.5,10.3): 2.2011 - val_ca2-[10.3,11.3): 3.5776 - val_ca2-[11.3,14.9): 5.5118 - val_ca3-[8.0,9.5): 1.0109 - val_ca3-[9.5,10.3): 1.0557 - val_ca3-[10.3,11.3): 2.0562 - val_ca3-[11.3,14.9): 3.4496 - val_ca4-[8.0,9.5): 2.5986 - val_ca4-[9.5,10.3): 2.8561 - val_ca4-[10.3,11.3): 4.3907 - val_ca4-[11.3,14.9): 6.5530\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 5.9449 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.7803 - ca2-[9.5,10.3): 2.1645 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.2786 - ca3-[10.3,11.3): 2.0507 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.3850 - ca4-[11.3,14.9): 6.3934 - val_ca1-[8.0,9.5): 5.5187 - val_ca1-[9.5,10.3): 6.0150 - val_ca1-[10.3,11.3): 8.1151 - val_ca1-[11.3,14.9): 11.0409 - val_ca2-[8.0,9.5): 1.7851 - val_ca2-[9.5,10.3): 1.9586 - val_ca2-[10.3,11.3): 3.2714 - val_ca2-[11.3,14.9): 5.0794 - val_ca3-[8.0,9.5): 0.9172 - val_ca3-[9.5,10.3): 0.9419 - val_ca3-[10.3,11.3): 1.8930 - val_ca3-[11.3,14.9): 3.1878 - val_ca4-[8.0,9.5): 2.3351 - val_ca4-[9.5,10.3): 2.5733 - val_ca4-[10.3,11.3): 4.0445 - val_ca4-[11.3,14.9): 6.0778\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 5.6269 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.5929 - ca2-[9.5,10.3): 1.9276 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.1791 - ca3-[10.3,11.3): 1.8756 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.9909 - ca4-[11.3,14.9): 5.9867 - val_ca1-[8.0,9.5): 5.2101 - val_ca1-[9.5,10.3): 5.6861 - val_ca1-[10.3,11.3): 7.7160 - val_ca1-[11.3,14.9): 10.6783 - val_ca2-[8.0,9.5): 1.5982 - val_ca2-[9.5,10.3): 1.7462 - val_ca2-[10.3,11.3): 2.9824 - val_ca2-[11.3,14.9): 4.7658 - val_ca3-[8.0,9.5): 0.8406 - val_ca3-[9.5,10.3): 0.8451 - val_ca3-[10.3,11.3): 1.7354 - val_ca3-[11.3,14.9): 3.0050 - val_ca4-[8.0,9.5): 2.1046 - val_ca4-[9.5,10.3): 2.3170 - val_ca4-[10.3,11.3): 3.7095 - val_ca4-[11.3,14.9): 5.7254\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 5.2919 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.3964 - ca2-[9.5,10.3): 1.7394 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.0593 - ca3-[10.3,11.3): 1.7383 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.5200 - ca4-[11.3,14.9): 5.5247 - val_ca1-[8.0,9.5): 4.9209 - val_ca1-[9.5,10.3): 5.3773 - val_ca1-[10.3,11.3): 7.3596 - val_ca1-[11.3,14.9): 10.2155 - val_ca2-[8.0,9.5): 1.4367 - val_ca2-[9.5,10.3): 1.5607 - val_ca2-[10.3,11.3): 2.7390 - val_ca2-[11.3,14.9): 4.4227 - val_ca3-[8.0,9.5): 0.7774 - val_ca3-[9.5,10.3): 0.7630 - val_ca3-[10.3,11.3): 1.6074 - val_ca3-[11.3,14.9): 2.8048 - val_ca4-[8.0,9.5): 1.8969 - val_ca4-[9.5,10.3): 2.0842 - val_ca4-[10.3,11.3): 3.4162 - val_ca4-[11.3,14.9): 5.3243\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 4.9871 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.2665 - ca2-[9.5,10.3): 1.5303 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.9858 - ca3-[10.3,11.3): 1.5954 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.2026 - ca4-[11.3,14.9): 5.1960 - val_ca1-[8.0,9.5): 4.6496 - val_ca1-[9.5,10.3): 5.0870 - val_ca1-[10.3,11.3): 7.0425 - val_ca1-[11.3,14.9): 9.7462 - val_ca2-[8.0,9.5): 1.2982 - val_ca2-[9.5,10.3): 1.3997 - val_ca2-[10.3,11.3): 2.5347 - val_ca2-[11.3,14.9): 4.0776 - val_ca3-[8.0,9.5): 0.7260 - val_ca3-[9.5,10.3): 0.6937 - val_ca3-[10.3,11.3): 1.5028 - val_ca3-[11.3,14.9): 2.5848 - val_ca4-[8.0,9.5): 1.7100 - val_ca4-[9.5,10.3): 1.8731 - val_ca4-[10.3,11.3): 3.1588 - val_ca4-[11.3,14.9): 4.9153\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 4.7688 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.0745 - ca2-[9.5,10.3): 1.3860 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.8816 - ca3-[10.3,11.3): 1.5011 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.1080 - ca4-[11.3,14.9): 4.8631 - val_ca1-[8.0,9.5): 4.3952 - val_ca1-[9.5,10.3): 4.8141 - val_ca1-[10.3,11.3): 6.7247 - val_ca1-[11.3,14.9): 9.4507 - val_ca2-[8.0,9.5): 1.1797 - val_ca2-[9.5,10.3): 1.2602 - val_ca2-[10.3,11.3): 2.3440 - val_ca2-[11.3,14.9): 3.8622 - val_ca3-[8.0,9.5): 0.6847 - val_ca3-[9.5,10.3): 0.6356 - val_ca3-[10.3,11.3): 1.4039 - val_ca3-[11.3,14.9): 2.4613 - val_ca4-[8.0,9.5): 1.5427 - val_ca4-[9.5,10.3): 1.6822 - val_ca4-[10.3,11.3): 2.9106 - val_ca4-[11.3,14.9): 4.6403\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 4.4423 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.9632 - ca2-[9.5,10.3): 1.2551 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.7996 - ca3-[10.3,11.3): 1.3881 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.6215 - ca4-[11.3,14.9): 4.5377 - val_ca1-[8.0,9.5): 4.1566 - val_ca1-[9.5,10.3): 4.5577 - val_ca1-[10.3,11.3): 6.4253 - val_ca1-[11.3,14.9): 9.0355 - val_ca2-[8.0,9.5): 1.0784 - val_ca2-[9.5,10.3): 1.1391 - val_ca2-[10.3,11.3): 2.1764 - val_ca2-[11.3,14.9): 3.6021 - val_ca3-[8.0,9.5): 0.6521 - val_ca3-[9.5,10.3): 0.5872 - val_ca3-[10.3,11.3): 1.3188 - val_ca3-[11.3,14.9): 2.3086 - val_ca4-[8.0,9.5): 1.3933 - val_ca4-[9.5,10.3): 1.5100 - val_ca4-[10.3,11.3): 2.6840 - val_ca4-[11.3,14.9): 4.3052\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 4.2928 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.8705 - ca2-[9.5,10.3): 1.1672 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.7746 - ca3-[10.3,11.3): 1.3144 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.2614 - ca4-[11.3,14.9): 4.2133 - val_ca1-[8.0,9.5): 3.9327 - val_ca1-[9.5,10.3): 4.3165 - val_ca1-[10.3,11.3): 6.1600 - val_ca1-[11.3,14.9): 8.7357 - val_ca2-[8.0,9.5): 0.9919 - val_ca2-[9.5,10.3): 1.0342 - val_ca2-[10.3,11.3): 2.0296 - val_ca2-[11.3,14.9): 3.4011 - val_ca3-[8.0,9.5): 0.6267 - val_ca3-[9.5,10.3): 0.5470 - val_ca3-[10.3,11.3): 1.2400 - val_ca3-[11.3,14.9): 2.1823 - val_ca4-[8.0,9.5): 1.2607 - val_ca4-[9.5,10.3): 1.3553 - val_ca4-[10.3,11.3): 2.4809 - val_ca4-[11.3,14.9): 4.0376\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 4.0250 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.7818 - ca2-[9.5,10.3): 1.0459 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6850 - ca3-[10.3,11.3): 1.2312 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.9581 - ca4-[11.3,14.9): 3.9429 - val_ca1-[8.0,9.5): 3.7223 - val_ca1-[9.5,10.3): 4.0893 - val_ca1-[10.3,11.3): 5.8738 - val_ca1-[11.3,14.9): 8.3996 - val_ca2-[8.0,9.5): 0.9188 - val_ca2-[9.5,10.3): 0.9439 - val_ca2-[10.3,11.3): 1.8943 - val_ca2-[11.3,14.9): 3.2104 - val_ca3-[8.0,9.5): 0.6077 - val_ca3-[9.5,10.3): 0.5139 - val_ca3-[10.3,11.3): 1.1750 - val_ca3-[11.3,14.9): 2.0714 - val_ca4-[8.0,9.5): 1.1429 - val_ca4-[9.5,10.3): 1.2160 - val_ca4-[10.3,11.3): 2.2839 - val_ca4-[11.3,14.9): 3.7706\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 3.7976 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.7771 - ca2-[9.5,10.3): 0.9872 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6518 - ca3-[10.3,11.3): 1.1743 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.8651 - ca4-[11.3,14.9): 3.6562 - val_ca1-[8.0,9.5): 3.5237 - val_ca1-[9.5,10.3): 3.8743 - val_ca1-[10.3,11.3): 5.6182 - val_ca1-[11.3,14.9): 8.0838 - val_ca2-[8.0,9.5): 0.8572 - val_ca2-[9.5,10.3): 0.8663 - val_ca2-[10.3,11.3): 1.7764 - val_ca2-[11.3,14.9): 3.0392 - val_ca3-[8.0,9.5): 0.5942 - val_ca3-[9.5,10.3): 0.4872 - val_ca3-[10.3,11.3): 1.1142 - val_ca3-[11.3,14.9): 1.9688 - val_ca4-[8.0,9.5): 1.0397 - val_ca4-[9.5,10.3): 1.0921 - val_ca4-[10.3,11.3): 2.1080 - val_ca4-[11.3,14.9): 3.5238\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 3.6014 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.6753 - ca2-[9.5,10.3): 0.9262 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6422 - ca3-[10.3,11.3): 1.1062 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.6806 - ca4-[11.3,14.9): 3.4052 - val_ca1-[8.0,9.5): 3.3364 - val_ca1-[9.5,10.3): 3.6710 - val_ca1-[10.3,11.3): 5.3433 - val_ca1-[11.3,14.9): 7.7968 - val_ca2-[8.0,9.5): 0.8052 - val_ca2-[9.5,10.3): 0.7995 - val_ca2-[10.3,11.3): 1.6581 - val_ca2-[11.3,14.9): 2.8875 - val_ca3-[8.0,9.5): 0.5852 - val_ca3-[9.5,10.3): 0.4658 - val_ca3-[10.3,11.3): 1.0529 - val_ca3-[11.3,14.9): 1.8743 - val_ca4-[8.0,9.5): 0.9497 - val_ca4-[9.5,10.3): 0.9820 - val_ca4-[10.3,11.3): 1.9316 - val_ca4-[11.3,14.9): 3.2985\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 3.4351 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.5999 - ca2-[9.5,10.3): 0.8275 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5947 - ca3-[10.3,11.3): 1.0592 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.4115 - ca4-[11.3,14.9): 3.2074 - val_ca1-[8.0,9.5): 3.1602 - val_ca1-[9.5,10.3): 3.4793 - val_ca1-[10.3,11.3): 5.1465 - val_ca1-[11.3,14.9): 7.5427 - val_ca2-[8.0,9.5): 0.7616 - val_ca2-[9.5,10.3): 0.7420 - val_ca2-[10.3,11.3): 1.5819 - val_ca2-[11.3,14.9): 2.7698 - val_ca3-[8.0,9.5): 0.5803 - val_ca3-[9.5,10.3): 0.4490 - val_ca3-[10.3,11.3): 1.0168 - val_ca3-[11.3,14.9): 1.8074 - val_ca4-[8.0,9.5): 0.8718 - val_ca4-[9.5,10.3): 0.8846 - val_ca4-[10.3,11.3): 1.8039 - val_ca4-[11.3,14.9): 3.1082\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 3.2513 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.5647 - ca2-[9.5,10.3): 0.7951 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5748 - ca3-[10.3,11.3): 1.0092 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.1765 - ca4-[11.3,14.9): 2.9597 - val_ca1-[8.0,9.5): 2.9942 - val_ca1-[9.5,10.3): 3.2982 - val_ca1-[10.3,11.3): 4.9398 - val_ca1-[11.3,14.9): 7.2241 - val_ca2-[8.0,9.5): 0.7252 - val_ca2-[9.5,10.3): 0.6926 - val_ca2-[10.3,11.3): 1.5057 - val_ca2-[11.3,14.9): 2.6215 - val_ca3-[8.0,9.5): 0.5787 - val_ca3-[9.5,10.3): 0.4363 - val_ca3-[10.3,11.3): 0.9796 - val_ca3-[11.3,14.9): 1.7150 - val_ca4-[8.0,9.5): 0.8049 - val_ca4-[9.5,10.3): 0.7989 - val_ca4-[10.3,11.3): 1.6773 - val_ca4-[11.3,14.9): 2.8857\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 3.0526 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4914 - ca2-[9.5,10.3): 0.7400 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5125 - ca3-[10.3,11.3): 0.9792 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.2312 - ca4-[11.3,14.9): 2.8257 - val_ca1-[8.0,9.5): 2.8378 - val_ca1-[9.5,10.3): 3.1272 - val_ca1-[10.3,11.3): 4.7068 - val_ca1-[11.3,14.9): 6.9762 - val_ca2-[8.0,9.5): 0.6948 - val_ca2-[9.5,10.3): 0.6502 - val_ca2-[10.3,11.3): 1.4234 - val_ca2-[11.3,14.9): 2.5105 - val_ca3-[8.0,9.5): 0.5799 - val_ca3-[9.5,10.3): 0.4270 - val_ca3-[10.3,11.3): 0.9391 - val_ca3-[11.3,14.9): 1.6438 - val_ca4-[8.0,9.5): 0.7483 - val_ca4-[9.5,10.3): 0.7239 - val_ca4-[10.3,11.3): 1.5461 - val_ca4-[11.3,14.9): 2.7055\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 2.8980 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4843 - ca2-[9.5,10.3): 0.7069 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5333 - ca3-[10.3,11.3): 0.9433 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.9245 - ca4-[11.3,14.9): 2.5852 - val_ca1-[8.0,9.5): 2.6900 - val_ca1-[9.5,10.3): 2.9607 - val_ca1-[10.3,11.3): 4.5394 - val_ca1-[11.3,14.9): 6.7814 - val_ca2-[8.0,9.5): 0.6698 - val_ca2-[9.5,10.3): 0.6133 - val_ca2-[10.3,11.3): 1.3678 - val_ca2-[11.3,14.9): 2.4309 - val_ca3-[8.0,9.5): 0.5835 - val_ca3-[9.5,10.3): 0.4212 - val_ca3-[10.3,11.3): 0.9099 - val_ca3-[11.3,14.9): 1.5928 - val_ca4-[8.0,9.5): 0.7014 - val_ca4-[9.5,10.3): 0.6585 - val_ca4-[10.3,11.3): 1.4474 - val_ca4-[11.3,14.9): 2.5601\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 2.7855 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4629 - ca2-[9.5,10.3): 0.6789 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4986 - ca3-[10.3,11.3): 0.9149 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.8438 - ca4-[11.3,14.9): 2.4640 - val_ca1-[8.0,9.5): 2.5503 - val_ca1-[9.5,10.3): 2.8112 - val_ca1-[10.3,11.3): 4.3362 - val_ca1-[11.3,14.9): 6.4924 - val_ca2-[8.0,9.5): 0.6493 - val_ca2-[9.5,10.3): 0.5831 - val_ca2-[10.3,11.3): 1.3093 - val_ca2-[11.3,14.9): 2.3135 - val_ca3-[8.0,9.5): 0.5891 - val_ca3-[9.5,10.3): 0.4170 - val_ca3-[10.3,11.3): 0.8852 - val_ca3-[11.3,14.9): 1.5173 - val_ca4-[8.0,9.5): 0.6633 - val_ca4-[9.5,10.3): 0.6041 - val_ca4-[10.3,11.3): 1.3478 - val_ca4-[11.3,14.9): 2.3772\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 2.5925 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4550 - ca2-[9.5,10.3): 0.6560 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5120 - ca3-[10.3,11.3): 0.8739 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.6983 - ca4-[11.3,14.9): 2.2968 - val_ca1-[8.0,9.5): 2.4190 - val_ca1-[9.5,10.3): 2.6662 - val_ca1-[10.3,11.3): 4.1679 - val_ca1-[11.3,14.9): 6.3151 - val_ca2-[8.0,9.5): 0.6327 - val_ca2-[9.5,10.3): 0.5570 - val_ca2-[10.3,11.3): 1.2638 - val_ca2-[11.3,14.9): 2.2536 - val_ca3-[8.0,9.5): 0.5962 - val_ca3-[9.5,10.3): 0.4154 - val_ca3-[10.3,11.3): 0.8642 - val_ca3-[11.3,14.9): 1.4784 - val_ca4-[8.0,9.5): 0.6332 - val_ca4-[9.5,10.3): 0.5575 - val_ca4-[10.3,11.3): 1.2647 - val_ca4-[11.3,14.9): 2.2553\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 2.4571 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4160 - ca2-[9.5,10.3): 0.6325 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4905 - ca3-[10.3,11.3): 0.8427 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.5462 - ca4-[11.3,14.9): 2.1633 - val_ca1-[8.0,9.5): 2.2949 - val_ca1-[9.5,10.3): 2.5287 - val_ca1-[10.3,11.3): 3.9877 - val_ca1-[11.3,14.9): 6.0422 - val_ca2-[8.0,9.5): 0.6194 - val_ca2-[9.5,10.3): 0.5347 - val_ca2-[10.3,11.3): 1.2160 - val_ca2-[11.3,14.9): 2.1490 - val_ca3-[8.0,9.5): 0.6044 - val_ca3-[9.5,10.3): 0.4155 - val_ca3-[10.3,11.3): 0.8427 - val_ca3-[11.3,14.9): 1.4093 - val_ca4-[8.0,9.5): 0.6104 - val_ca4-[9.5,10.3): 0.5187 - val_ca4-[10.3,11.3): 1.1831 - val_ca4-[11.3,14.9): 2.0919\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 2.3391 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4171 - ca2-[9.5,10.3): 0.6189 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4890 - ca3-[10.3,11.3): 0.8459 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.4676 - ca4-[11.3,14.9): 2.0221 - val_ca1-[8.0,9.5): 2.1779 - val_ca1-[9.5,10.3): 2.3987 - val_ca1-[10.3,11.3): 3.8257 - val_ca1-[11.3,14.9): 5.7948 - val_ca2-[8.0,9.5): 0.6087 - val_ca2-[9.5,10.3): 0.5159 - val_ca2-[10.3,11.3): 1.1774 - val_ca2-[11.3,14.9): 2.0633 - val_ca3-[8.0,9.5): 0.6136 - val_ca3-[9.5,10.3): 0.4171 - val_ca3-[10.3,11.3): 0.8256 - val_ca3-[11.3,14.9): 1.3539 - val_ca4-[8.0,9.5): 0.5941 - val_ca4-[9.5,10.3): 0.4870 - val_ca4-[10.3,11.3): 1.1137 - val_ca4-[11.3,14.9): 1.9507\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 2.2287 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4185 - ca2-[9.5,10.3): 0.6023 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4846 - ca3-[10.3,11.3): 0.8186 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.4028 - ca4-[11.3,14.9): 1.8720 - val_ca1-[8.0,9.5): 2.0675 - val_ca1-[9.5,10.3): 2.2755 - val_ca1-[10.3,11.3): 3.6242 - val_ca1-[11.3,14.9): 5.6329 - val_ca2-[8.0,9.5): 0.6003 - val_ca2-[9.5,10.3): 0.5000 - val_ca2-[10.3,11.3): 1.1184 - val_ca2-[11.3,14.9): 2.0255 - val_ca3-[8.0,9.5): 0.6235 - val_ca3-[9.5,10.3): 0.4199 - val_ca3-[10.3,11.3): 0.7939 - val_ca3-[11.3,14.9): 1.3325 - val_ca4-[8.0,9.5): 0.5839 - val_ca4-[9.5,10.3): 0.4619 - val_ca4-[10.3,11.3): 1.0292 - val_ca4-[11.3,14.9): 1.8595\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 2.1455 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3765 - ca2-[9.5,10.3): 0.5738 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4811 - ca3-[10.3,11.3): 0.8096 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.2688 - ca4-[11.3,14.9): 1.7786 - val_ca1-[8.0,9.5): 1.9630 - val_ca1-[9.5,10.3): 2.1585 - val_ca1-[10.3,11.3): 3.4972 - val_ca1-[11.3,14.9): 5.4718 - val_ca2-[8.0,9.5): 0.5939 - val_ca2-[9.5,10.3): 0.4867 - val_ca2-[10.3,11.3): 1.1013 - val_ca2-[11.3,14.9): 1.9845 - val_ca3-[8.0,9.5): 0.6339 - val_ca3-[9.5,10.3): 0.4236 - val_ca3-[10.3,11.3): 0.7916 - val_ca3-[11.3,14.9): 1.3033 - val_ca4-[8.0,9.5): 0.5792 - val_ca4-[9.5,10.3): 0.4428 - val_ca4-[10.3,11.3): 0.9877 - val_ca4-[11.3,14.9): 1.7661\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 2.0164 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3950 - ca2-[9.5,10.3): 0.5703 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4906 - ca3-[10.3,11.3): 0.8005 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.2664 - ca4-[11.3,14.9): 1.6883 - val_ca1-[8.0,9.5): 1.8645 - val_ca1-[9.5,10.3): 2.0477 - val_ca1-[10.3,11.3): 3.3831 - val_ca1-[11.3,14.9): 5.2610 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4755 - val_ca2-[10.3,11.3): 1.0865 - val_ca2-[11.3,14.9): 1.9131 - val_ca3-[8.0,9.5): 0.6445 - val_ca3-[9.5,10.3): 0.4280 - val_ca3-[10.3,11.3): 0.7876 - val_ca3-[11.3,14.9): 1.2492 - val_ca4-[8.0,9.5): 0.5793 - val_ca4-[9.5,10.3): 0.4292 - val_ca4-[10.3,11.3): 0.9507 - val_ca4-[11.3,14.9): 1.6475\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 1.8878 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3795 - ca2-[9.5,10.3): 0.5467 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4919 - ca3-[10.3,11.3): 0.7696 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.1014 - ca4-[11.3,14.9): 1.6210 - val_ca1-[8.0,9.5): 1.7717 - val_ca1-[9.5,10.3): 1.9430 - val_ca1-[10.3,11.3): 3.2365 - val_ca1-[11.3,14.9): 5.1052 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.4662 - val_ca2-[10.3,11.3): 1.0578 - val_ca2-[11.3,14.9): 1.8839 - val_ca3-[8.0,9.5): 0.6553 - val_ca3-[9.5,10.3): 0.4330 - val_ca3-[10.3,11.3): 0.7752 - val_ca3-[11.3,14.9): 1.2312 - val_ca4-[8.0,9.5): 0.5839 - val_ca4-[9.5,10.3): 0.4204 - val_ca4-[10.3,11.3): 0.9048 - val_ca4-[11.3,14.9): 1.5720\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 1.8047 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3636 - ca2-[9.5,10.3): 0.5529 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4748 - ca3-[10.3,11.3): 0.7650 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.0251 - ca4-[11.3,14.9): 1.5153 - val_ca1-[8.0,9.5): 1.6842 - val_ca1-[9.5,10.3): 1.8437 - val_ca1-[10.3,11.3): 3.1224 - val_ca1-[11.3,14.9): 4.8991 - val_ca2-[8.0,9.5): 0.5827 - val_ca2-[9.5,10.3): 0.4584 - val_ca2-[10.3,11.3): 1.0447 - val_ca2-[11.3,14.9): 1.8339 - val_ca3-[8.0,9.5): 0.6662 - val_ca3-[9.5,10.3): 0.4384 - val_ca3-[10.3,11.3): 0.7725 - val_ca3-[11.3,14.9): 1.2022 - val_ca4-[8.0,9.5): 0.5923 - val_ca4-[9.5,10.3): 0.4160 - val_ca4-[10.3,11.3): 0.8755 - val_ca4-[11.3,14.9): 1.4842\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.7006 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3859 - ca2-[9.5,10.3): 0.5353 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4954 - ca3-[10.3,11.3): 0.7653 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.9264 - ca4-[11.3,14.9): 1.4563 - val_ca1-[8.0,9.5): 1.6017 - val_ca1-[9.5,10.3): 1.7497 - val_ca1-[10.3,11.3): 2.9882 - val_ca1-[11.3,14.9): 4.7370 - val_ca2-[8.0,9.5): 0.5809 - val_ca2-[9.5,10.3): 0.4517 - val_ca2-[10.3,11.3): 1.0209 - val_ca2-[11.3,14.9): 1.7987 - val_ca3-[8.0,9.5): 0.6767 - val_ca3-[9.5,10.3): 0.4439 - val_ca3-[10.3,11.3): 0.7632 - val_ca3-[11.3,14.9): 1.1785 - val_ca4-[8.0,9.5): 0.6043 - val_ca4-[9.5,10.3): 0.4155 - val_ca4-[10.3,11.3): 0.8407 - val_ca4-[11.3,14.9): 1.4099\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.6261 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3688 - ca2-[9.5,10.3): 0.5350 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4919 - ca3-[10.3,11.3): 0.7593 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8233 - ca4-[11.3,14.9): 1.3666 - val_ca1-[8.0,9.5): 1.5236 - val_ca1-[9.5,10.3): 1.6603 - val_ca1-[10.3,11.3): 2.8703 - val_ca1-[11.3,14.9): 4.6274 - val_ca2-[8.0,9.5): 0.5797 - val_ca2-[9.5,10.3): 0.4461 - val_ca2-[10.3,11.3): 1.0029 - val_ca2-[11.3,14.9): 1.7958 - val_ca3-[8.0,9.5): 0.6869 - val_ca3-[9.5,10.3): 0.4495 - val_ca3-[10.3,11.3): 0.7556 - val_ca3-[11.3,14.9): 1.1786 - val_ca4-[8.0,9.5): 0.6194 - val_ca4-[9.5,10.3): 0.4186 - val_ca4-[10.3,11.3): 0.8129 - val_ca4-[11.3,14.9): 1.3661\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.5358 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3679 - ca2-[9.5,10.3): 0.5412 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4895 - ca3-[10.3,11.3): 0.7210 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8841 - ca4-[11.3,14.9): 1.3228 - val_ca1-[8.0,9.5): 1.4497 - val_ca1-[9.5,10.3): 1.5753 - val_ca1-[10.3,11.3): 2.7711 - val_ca1-[11.3,14.9): 4.4823 - val_ca2-[8.0,9.5): 0.5790 - val_ca2-[9.5,10.3): 0.4413 - val_ca2-[10.3,11.3): 0.9953 - val_ca2-[11.3,14.9): 1.7674 - val_ca3-[8.0,9.5): 0.6968 - val_ca3-[9.5,10.3): 0.4552 - val_ca3-[10.3,11.3): 0.7558 - val_ca3-[11.3,14.9): 1.1574 - val_ca4-[8.0,9.5): 0.6373 - val_ca4-[9.5,10.3): 0.4249 - val_ca4-[10.3,11.3): 0.7966 - val_ca4-[11.3,14.9): 1.3022\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.4981 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3444 - ca2-[9.5,10.3): 0.5191 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5201 - ca3-[10.3,11.3): 0.7266 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8073 - ca4-[11.3,14.9): 1.2373 - val_ca1-[8.0,9.5): 1.3796 - val_ca1-[9.5,10.3): 1.4942 - val_ca1-[10.3,11.3): 2.6518 - val_ca1-[11.3,14.9): 4.3221 - val_ca2-[8.0,9.5): 0.5787 - val_ca2-[9.5,10.3): 0.4374 - val_ca2-[10.3,11.3): 0.9773 - val_ca2-[11.3,14.9): 1.7342 - val_ca3-[8.0,9.5): 0.7064 - val_ca3-[9.5,10.3): 0.4609 - val_ca3-[10.3,11.3): 0.7493 - val_ca3-[11.3,14.9): 1.1345 - val_ca4-[8.0,9.5): 0.6574 - val_ca4-[9.5,10.3): 0.4340 - val_ca4-[10.3,11.3): 0.7756 - val_ca4-[11.3,14.9): 1.2395\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 1.3937 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3755 - ca2-[9.5,10.3): 0.5317 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4944 - ca3-[10.3,11.3): 0.7378 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7722 - ca4-[11.3,14.9): 1.1789 - val_ca1-[8.0,9.5): 1.3131 - val_ca1-[9.5,10.3): 1.4167 - val_ca1-[10.3,11.3): 2.5590 - val_ca1-[11.3,14.9): 4.1222 - val_ca2-[8.0,9.5): 0.5787 - val_ca2-[9.5,10.3): 0.4341 - val_ca2-[10.3,11.3): 0.9713 - val_ca2-[11.3,14.9): 1.6768 - val_ca3-[8.0,9.5): 0.7155 - val_ca3-[9.5,10.3): 0.4664 - val_ca3-[10.3,11.3): 0.7486 - val_ca3-[11.3,14.9): 1.0930 - val_ca4-[8.0,9.5): 0.6795 - val_ca4-[9.5,10.3): 0.4454 - val_ca4-[10.3,11.3): 0.7643 - val_ca4-[11.3,14.9): 1.1608\n",
      "Epoch 49/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 1.3546 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3606 - ca2-[9.5,10.3): 0.5187 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5191 - ca3-[10.3,11.3): 0.7453 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7005 - ca4-[11.3,14.9): 1.1213 - val_ca1-[8.0,9.5): 1.2501 - val_ca1-[9.5,10.3): 1.3429 - val_ca1-[10.3,11.3): 2.4468 - val_ca1-[11.3,14.9): 4.0592 - val_ca2-[8.0,9.5): 0.5789 - val_ca2-[9.5,10.3): 0.4314 - val_ca2-[10.3,11.3): 0.9545 - val_ca2-[11.3,14.9): 1.7011 - val_ca3-[8.0,9.5): 0.7245 - val_ca3-[9.5,10.3): 0.4719 - val_ca3-[10.3,11.3): 0.7412 - val_ca3-[11.3,14.9): 1.1094 - val_ca4-[8.0,9.5): 0.7032 - val_ca4-[9.5,10.3): 0.4590 - val_ca4-[10.3,11.3): 0.7484 - val_ca4-[11.3,14.9): 1.1466\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 1.2628 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3740 - ca2-[9.5,10.3): 0.5232 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5110 - ca3-[10.3,11.3): 0.7263 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6850 - ca4-[11.3,14.9): 1.0777 - val_ca1-[8.0,9.5): 1.1903 - val_ca1-[9.5,10.3): 1.2723 - val_ca1-[10.3,11.3): 2.3608 - val_ca1-[11.3,14.9): 3.8687 - val_ca2-[8.0,9.5): 0.5793 - val_ca2-[9.5,10.3): 0.4293 - val_ca2-[10.3,11.3): 0.9511 - val_ca2-[11.3,14.9): 1.6471 - val_ca3-[8.0,9.5): 0.7334 - val_ca3-[9.5,10.3): 0.4775 - val_ca3-[10.3,11.3): 0.7411 - val_ca3-[11.3,14.9): 1.0672 - val_ca4-[8.0,9.5): 0.7282 - val_ca4-[9.5,10.3): 0.4743 - val_ca4-[10.3,11.3): 0.7425 - val_ca4-[11.3,14.9): 1.0752\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 1.1613 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3792 - ca2-[9.5,10.3): 0.5195 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5303 - ca3-[10.3,11.3): 0.7456 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7185 - ca4-[11.3,14.9): 1.0603 - val_ca1-[8.0,9.5): 1.1334 - val_ca1-[9.5,10.3): 1.2048 - val_ca1-[10.3,11.3): 2.2582 - val_ca1-[11.3,14.9): 3.7434 - val_ca2-[8.0,9.5): 0.5798 - val_ca2-[9.5,10.3): 0.4274 - val_ca2-[10.3,11.3): 0.9407 - val_ca2-[11.3,14.9): 1.6342 - val_ca3-[8.0,9.5): 0.7419 - val_ca3-[9.5,10.3): 0.4829 - val_ca3-[10.3,11.3): 0.7391 - val_ca3-[11.3,14.9): 1.0558 - val_ca4-[8.0,9.5): 0.7542 - val_ca4-[9.5,10.3): 0.4910 - val_ca4-[10.3,11.3): 0.7367 - val_ca4-[11.3,14.9): 1.0380\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.1438 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3569 - ca2-[9.5,10.3): 0.5140 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4961 - ca3-[10.3,11.3): 0.7383 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6774 - ca4-[11.3,14.9): 1.0178 - val_ca1-[8.0,9.5): 1.0792 - val_ca1-[9.5,10.3): 1.1398 - val_ca1-[10.3,11.3): 2.1759 - val_ca1-[11.3,14.9): 3.6166 - val_ca2-[8.0,9.5): 0.5803 - val_ca2-[9.5,10.3): 0.4258 - val_ca2-[10.3,11.3): 0.9368 - val_ca2-[11.3,14.9): 1.6297 - val_ca3-[8.0,9.5): 0.7494 - val_ca3-[9.5,10.3): 0.4878 - val_ca3-[10.3,11.3): 0.7375 - val_ca3-[11.3,14.9): 1.0584 - val_ca4-[8.0,9.5): 0.7811 - val_ca4-[9.5,10.3): 0.5090 - val_ca4-[10.3,11.3): 0.7329 - val_ca4-[11.3,14.9): 1.0171\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.0997 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3702 - ca2-[9.5,10.3): 0.5226 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5184 - ca3-[10.3,11.3): 0.7205 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6778 - ca4-[11.3,14.9): 0.9568 - val_ca1-[8.0,9.5): 1.0280 - val_ca1-[9.5,10.3): 1.0779 - val_ca1-[10.3,11.3): 2.0909 - val_ca1-[11.3,14.9): 3.5424 - val_ca2-[8.0,9.5): 0.5810 - val_ca2-[9.5,10.3): 0.4244 - val_ca2-[10.3,11.3): 0.9342 - val_ca2-[11.3,14.9): 1.6439 - val_ca3-[8.0,9.5): 0.7566 - val_ca3-[9.5,10.3): 0.4925 - val_ca3-[10.3,11.3): 0.7406 - val_ca3-[11.3,14.9): 1.0642 - val_ca4-[8.0,9.5): 0.8085 - val_ca4-[9.5,10.3): 0.5279 - val_ca4-[10.3,11.3): 0.7356 - val_ca4-[11.3,14.9): 0.9997\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 1.0479 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3735 - ca2-[9.5,10.3): 0.5245 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5365 - ca3-[10.3,11.3): 0.7205 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6257 - ca4-[11.3,14.9): 0.9532 - val_ca1-[8.0,9.5): 0.9800 - val_ca1-[9.5,10.3): 1.0194 - val_ca1-[10.3,11.3): 2.0097 - val_ca1-[11.3,14.9): 3.3756 - val_ca2-[8.0,9.5): 0.5816 - val_ca2-[9.5,10.3): 0.4233 - val_ca2-[10.3,11.3): 0.9272 - val_ca2-[11.3,14.9): 1.6071 - val_ca3-[8.0,9.5): 0.7632 - val_ca3-[9.5,10.3): 0.4969 - val_ca3-[10.3,11.3): 0.7353 - val_ca3-[11.3,14.9): 1.0408 - val_ca4-[8.0,9.5): 0.8366 - val_ca4-[9.5,10.3): 0.5478 - val_ca4-[10.3,11.3): 0.7308 - val_ca4-[11.3,14.9): 0.9583\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 1.0043 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3711 - ca2-[9.5,10.3): 0.5319 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5381 - ca3-[10.3,11.3): 0.7257 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6434 - ca4-[11.3,14.9): 0.9112 - val_ca1-[8.0,9.5): 0.9356 - val_ca1-[9.5,10.3): 0.9646 - val_ca1-[10.3,11.3): 1.9264 - val_ca1-[11.3,14.9): 3.2683 - val_ca2-[8.0,9.5): 0.5822 - val_ca2-[9.5,10.3): 0.4223 - val_ca2-[10.3,11.3): 0.9240 - val_ca2-[11.3,14.9): 1.5974 - val_ca3-[8.0,9.5): 0.7695 - val_ca3-[9.5,10.3): 0.5011 - val_ca3-[10.3,11.3): 0.7386 - val_ca3-[11.3,14.9): 1.0284 - val_ca4-[8.0,9.5): 0.8647 - val_ca4-[9.5,10.3): 0.5682 - val_ca4-[10.3,11.3): 0.7371 - val_ca4-[11.3,14.9): 0.9271\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.9377 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3629 - ca2-[9.5,10.3): 0.5230 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5050 - ca3-[10.3,11.3): 0.7153 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5235 - ca4-[11.3,14.9): 0.8959 - val_ca1-[8.0,9.5): 0.8952 - val_ca1-[9.5,10.3): 0.9141 - val_ca1-[10.3,11.3): 1.8501 - val_ca1-[11.3,14.9): 3.0936 - val_ca2-[8.0,9.5): 0.5829 - val_ca2-[9.5,10.3): 0.4214 - val_ca2-[10.3,11.3): 0.9174 - val_ca2-[11.3,14.9): 1.5471 - val_ca3-[8.0,9.5): 0.7750 - val_ca3-[9.5,10.3): 0.5048 - val_ca3-[10.3,11.3): 0.7357 - val_ca3-[11.3,14.9): 0.9957 - val_ca4-[8.0,9.5): 0.8931 - val_ca4-[9.5,10.3): 0.5891 - val_ca4-[10.3,11.3): 0.7375 - val_ca4-[11.3,14.9): 0.8825\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.8964 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3572 - ca2-[9.5,10.3): 0.5228 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5285 - ca3-[10.3,11.3): 0.7243 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5863 - ca4-[11.3,14.9): 0.8770 - val_ca1-[8.0,9.5): 0.8581 - val_ca1-[9.5,10.3): 0.8673 - val_ca1-[10.3,11.3): 1.7827 - val_ca1-[11.3,14.9): 3.0773 - val_ca2-[8.0,9.5): 0.5835 - val_ca2-[9.5,10.3): 0.4208 - val_ca2-[10.3,11.3): 0.9098 - val_ca2-[11.3,14.9): 1.5905 - val_ca3-[8.0,9.5): 0.7803 - val_ca3-[9.5,10.3): 0.5084 - val_ca3-[10.3,11.3): 0.7268 - val_ca3-[11.3,14.9): 1.0178 - val_ca4-[8.0,9.5): 0.9214 - val_ca4-[9.5,10.3): 0.6103 - val_ca4-[10.3,11.3): 0.7315 - val_ca4-[11.3,14.9): 0.8824\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.8621 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3777 - ca2-[9.5,10.3): 0.5278 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5080 - ca3-[10.3,11.3): 0.7157 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5507 - ca4-[11.3,14.9): 0.8566 - val_ca1-[8.0,9.5): 0.8248 - val_ca1-[9.5,10.3): 0.8247 - val_ca1-[10.3,11.3): 1.7056 - val_ca1-[11.3,14.9): 2.9602 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.4202 - val_ca2-[10.3,11.3): 0.9056 - val_ca2-[11.3,14.9): 1.5756 - val_ca3-[8.0,9.5): 0.7849 - val_ca3-[9.5,10.3): 0.5115 - val_ca3-[10.3,11.3): 0.7328 - val_ca3-[11.3,14.9): 1.0122 - val_ca4-[8.0,9.5): 0.9496 - val_ca4-[9.5,10.3): 0.6317 - val_ca4-[10.3,11.3): 0.7455 - val_ca4-[11.3,14.9): 0.8660\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.8246 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3798 - ca2-[9.5,10.3): 0.5203 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5245 - ca3-[10.3,11.3): 0.7157 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5759 - ca4-[11.3,14.9): 0.8164 - val_ca1-[8.0,9.5): 0.7951 - val_ca1-[9.5,10.3): 0.7860 - val_ca1-[10.3,11.3): 1.6454 - val_ca1-[11.3,14.9): 2.8397 - val_ca2-[8.0,9.5): 0.5846 - val_ca2-[9.5,10.3): 0.4197 - val_ca2-[10.3,11.3): 0.9027 - val_ca2-[11.3,14.9): 1.5456 - val_ca3-[8.0,9.5): 0.7896 - val_ca3-[9.5,10.3): 0.5147 - val_ca3-[10.3,11.3): 0.7324 - val_ca3-[11.3,14.9): 0.9865 - val_ca4-[8.0,9.5): 0.9774 - val_ca4-[9.5,10.3): 0.6531 - val_ca4-[10.3,11.3): 0.7513 - val_ca4-[11.3,14.9): 0.8302\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.7588 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3657 - ca2-[9.5,10.3): 0.5165 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5452 - ca3-[10.3,11.3): 0.7329 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5449 - ca4-[11.3,14.9): 0.8084 - val_ca1-[8.0,9.5): 0.7683 - val_ca1-[9.5,10.3): 0.7507 - val_ca1-[10.3,11.3): 1.5637 - val_ca1-[11.3,14.9): 2.7260 - val_ca2-[8.0,9.5): 0.5850 - val_ca2-[9.5,10.3): 0.4193 - val_ca2-[10.3,11.3): 0.8812 - val_ca2-[11.3,14.9): 1.5183 - val_ca3-[8.0,9.5): 0.7937 - val_ca3-[9.5,10.3): 0.5176 - val_ca3-[10.3,11.3): 0.7178 - val_ca3-[11.3,14.9): 0.9635 - val_ca4-[8.0,9.5): 1.0051 - val_ca4-[9.5,10.3): 0.6745 - val_ca4-[10.3,11.3): 0.7458 - val_ca4-[11.3,14.9): 0.7986\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.7538 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3908 - ca2-[9.5,10.3): 0.5179 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5065 - ca3-[10.3,11.3): 0.7147 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5471 - ca4-[11.3,14.9): 0.8173 - val_ca1-[8.0,9.5): 0.7443 - val_ca1-[9.5,10.3): 0.7185 - val_ca1-[10.3,11.3): 1.5438 - val_ca1-[11.3,14.9): 2.6814 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.4190 - val_ca2-[10.3,11.3): 0.9008 - val_ca2-[11.3,14.9): 1.5336 - val_ca3-[8.0,9.5): 0.7976 - val_ca3-[9.5,10.3): 0.5202 - val_ca3-[10.3,11.3): 0.7315 - val_ca3-[11.3,14.9): 0.9669 - val_ca4-[8.0,9.5): 1.0325 - val_ca4-[9.5,10.3): 0.6960 - val_ca4-[10.3,11.3): 0.7629 - val_ca4-[11.3,14.9): 0.7860\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.7273 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3828 - ca2-[9.5,10.3): 0.5135 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5347 - ca3-[10.3,11.3): 0.7106 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5504 - ca4-[11.3,14.9): 0.7866 - val_ca1-[8.0,9.5): 0.7229 - val_ca1-[9.5,10.3): 0.6893 - val_ca1-[10.3,11.3): 1.4988 - val_ca1-[11.3,14.9): 2.6404 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.4187 - val_ca2-[10.3,11.3): 0.9029 - val_ca2-[11.3,14.9): 1.5619 - val_ca3-[8.0,9.5): 0.8008 - val_ca3-[9.5,10.3): 0.5224 - val_ca3-[10.3,11.3): 0.7358 - val_ca3-[11.3,14.9): 0.9930 - val_ca4-[8.0,9.5): 1.0589 - val_ca4-[9.5,10.3): 0.7169 - val_ca4-[10.3,11.3): 0.7750 - val_ca4-[11.3,14.9): 0.8019\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.6999 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3706 - ca2-[9.5,10.3): 0.5123 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5474 - ca3-[10.3,11.3): 0.7214 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5757 - ca4-[11.3,14.9): 0.7737 - val_ca1-[8.0,9.5): 0.7041 - val_ca1-[9.5,10.3): 0.6631 - val_ca1-[10.3,11.3): 1.4438 - val_ca1-[11.3,14.9): 2.5225 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.4185 - val_ca2-[10.3,11.3): 0.8926 - val_ca2-[11.3,14.9): 1.5247 - val_ca3-[8.0,9.5): 0.8038 - val_ca3-[9.5,10.3): 0.5245 - val_ca3-[10.3,11.3): 0.7294 - val_ca3-[11.3,14.9): 0.9691 - val_ca4-[8.0,9.5): 1.0846 - val_ca4-[9.5,10.3): 0.7373 - val_ca4-[10.3,11.3): 0.7778 - val_ca4-[11.3,14.9): 0.7777\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.6895 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3803 - ca2-[9.5,10.3): 0.5345 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5586 - ca3-[10.3,11.3): 0.7232 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5647 - ca4-[11.3,14.9): 0.7765 - val_ca1-[8.0,9.5): 0.6873 - val_ca1-[9.5,10.3): 0.6394 - val_ca1-[10.3,11.3): 1.4120 - val_ca1-[11.3,14.9): 2.5109 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.4183 - val_ca2-[10.3,11.3): 0.8975 - val_ca2-[11.3,14.9): 1.5629 - val_ca3-[8.0,9.5): 0.8065 - val_ca3-[9.5,10.3): 0.5264 - val_ca3-[10.3,11.3): 0.7333 - val_ca3-[11.3,14.9): 0.9963 - val_ca4-[8.0,9.5): 1.1100 - val_ca4-[9.5,10.3): 0.7577 - val_ca4-[10.3,11.3): 0.7882 - val_ca4-[11.3,14.9): 0.7905\n",
      "Epoch 65/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.6582 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3665 - ca2-[9.5,10.3): 0.5193 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5287 - ca3-[10.3,11.3): 0.7303 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5399 - ca4-[11.3,14.9): 0.7670 - val_ca1-[8.0,9.5): 0.6725 - val_ca1-[9.5,10.3): 0.6178 - val_ca1-[10.3,11.3): 1.3652 - val_ca1-[11.3,14.9): 2.3901 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.4180 - val_ca2-[10.3,11.3): 0.8896 - val_ca2-[11.3,14.9): 1.5177 - val_ca3-[8.0,9.5): 0.8095 - val_ca3-[9.5,10.3): 0.5285 - val_ca3-[10.3,11.3): 0.7293 - val_ca3-[11.3,14.9): 0.9677 - val_ca4-[8.0,9.5): 1.1347 - val_ca4-[9.5,10.3): 0.7776 - val_ca4-[10.3,11.3): 0.7941 - val_ca4-[11.3,14.9): 0.7674\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.6359 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3820 - ca2-[9.5,10.3): 0.5174 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5541 - ca3-[10.3,11.3): 0.7133 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5291 - ca4-[11.3,14.9): 0.7431 - val_ca1-[8.0,9.5): 0.6595 - val_ca1-[9.5,10.3): 0.5985 - val_ca1-[10.3,11.3): 1.3394 - val_ca1-[11.3,14.9): 2.3541 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.4179 - val_ca2-[10.3,11.3): 0.8946 - val_ca2-[11.3,14.9): 1.5278 - val_ca3-[8.0,9.5): 0.8122 - val_ca3-[9.5,10.3): 0.5303 - val_ca3-[10.3,11.3): 0.7331 - val_ca3-[11.3,14.9): 0.9706 - val_ca4-[8.0,9.5): 1.1581 - val_ca4-[9.5,10.3): 0.7965 - val_ca4-[10.3,11.3): 0.8044 - val_ca4-[11.3,14.9): 0.7603\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.6230 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3710 - ca2-[9.5,10.3): 0.5250 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5411 - ca3-[10.3,11.3): 0.7092 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5394 - ca4-[11.3,14.9): 0.7430 - val_ca1-[8.0,9.5): 0.6482 - val_ca1-[9.5,10.3): 0.5812 - val_ca1-[10.3,11.3): 1.3058 - val_ca1-[11.3,14.9): 2.3277 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.4177 - val_ca2-[10.3,11.3): 0.8916 - val_ca2-[11.3,14.9): 1.5450 - val_ca3-[8.0,9.5): 0.8147 - val_ca3-[9.5,10.3): 0.5321 - val_ca3-[10.3,11.3): 0.7308 - val_ca3-[11.3,14.9): 0.9799 - val_ca4-[8.0,9.5): 1.1808 - val_ca4-[9.5,10.3): 0.8150 - val_ca4-[10.3,11.3): 0.8101 - val_ca4-[11.3,14.9): 0.7598\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.6143 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3798 - ca2-[9.5,10.3): 0.5223 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5561 - ca3-[10.3,11.3): 0.7106 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5166 - ca4-[11.3,14.9): 0.7202 - val_ca1-[8.0,9.5): 0.6380 - val_ca1-[9.5,10.3): 0.5653 - val_ca1-[10.3,11.3): 1.2641 - val_ca1-[11.3,14.9): 2.2595 - val_ca2-[8.0,9.5): 0.5876 - val_ca2-[9.5,10.3): 0.4176 - val_ca2-[10.3,11.3): 0.8840 - val_ca2-[11.3,14.9): 1.5263 - val_ca3-[8.0,9.5): 0.8170 - val_ca3-[9.5,10.3): 0.5337 - val_ca3-[10.3,11.3): 0.7297 - val_ca3-[11.3,14.9): 0.9615 - val_ca4-[8.0,9.5): 1.2027 - val_ca4-[9.5,10.3): 0.8328 - val_ca4-[10.3,11.3): 0.8215 - val_ca4-[11.3,14.9): 0.7383\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.6025 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3720 - ca2-[9.5,10.3): 0.5199 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5510 - ca3-[10.3,11.3): 0.7123 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5308 - ca4-[11.3,14.9): 0.7240 - val_ca1-[8.0,9.5): 0.6292 - val_ca1-[9.5,10.3): 0.5510 - val_ca1-[10.3,11.3): 1.2418 - val_ca1-[11.3,14.9): 2.2281 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4176 - val_ca2-[10.3,11.3): 0.8858 - val_ca2-[11.3,14.9): 1.5416 - val_ca3-[8.0,9.5): 0.8190 - val_ca3-[9.5,10.3): 0.5352 - val_ca3-[10.3,11.3): 0.7291 - val_ca3-[11.3,14.9): 0.9777 - val_ca4-[8.0,9.5): 1.2238 - val_ca4-[9.5,10.3): 0.8501 - val_ca4-[10.3,11.3): 0.8267 - val_ca4-[11.3,14.9): 0.7523\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5885 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3688 - ca2-[9.5,10.3): 0.5246 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5574 - ca3-[10.3,11.3): 0.7300 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5477 - ca4-[11.3,14.9): 0.7241 - val_ca1-[8.0,9.5): 0.6215 - val_ca1-[9.5,10.3): 0.5381 - val_ca1-[10.3,11.3): 1.2164 - val_ca1-[11.3,14.9): 2.1164 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4175 - val_ca2-[10.3,11.3): 0.8854 - val_ca2-[11.3,14.9): 1.4887 - val_ca3-[8.0,9.5): 0.8207 - val_ca3-[9.5,10.3): 0.5364 - val_ca3-[10.3,11.3): 0.7291 - val_ca3-[11.3,14.9): 0.9441 - val_ca4-[8.0,9.5): 1.2438 - val_ca4-[9.5,10.3): 0.8665 - val_ca4-[10.3,11.3): 0.8345 - val_ca4-[11.3,14.9): 0.7324\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5965 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3738 - ca2-[9.5,10.3): 0.5167 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5280 - ca3-[10.3,11.3): 0.7188 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5571 - ca4-[11.3,14.9): 0.7189 - val_ca1-[8.0,9.5): 0.6147 - val_ca1-[9.5,10.3): 0.5235 - val_ca1-[10.3,11.3): 1.1994 - val_ca1-[11.3,14.9): 2.1052 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4114 - val_ca2-[10.3,11.3): 0.8893 - val_ca2-[11.3,14.9): 1.5097 - val_ca3-[8.0,9.5): 0.8221 - val_ca3-[9.5,10.3): 0.5272 - val_ca3-[10.3,11.3): 0.7307 - val_ca3-[11.3,14.9): 0.9556 - val_ca4-[8.0,9.5): 1.2628 - val_ca4-[9.5,10.3): 0.8687 - val_ca4-[10.3,11.3): 0.8415 - val_ca4-[11.3,14.9): 0.7337\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5737 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3728 - ca2-[9.5,10.3): 0.5274 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5037 - ca3-[10.3,11.3): 0.7158 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5570 - ca4-[11.3,14.9): 0.7284 - val_ca1-[8.0,9.5): 0.6089 - val_ca1-[9.5,10.3): 0.5161 - val_ca1-[10.3,11.3): 1.1777 - val_ca1-[11.3,14.9): 2.0557 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4174 - val_ca2-[10.3,11.3): 0.8890 - val_ca2-[11.3,14.9): 1.4999 - val_ca3-[8.0,9.5): 0.8233 - val_ca3-[9.5,10.3): 0.5381 - val_ca3-[10.3,11.3): 0.7307 - val_ca3-[11.3,14.9): 0.9495 - val_ca4-[8.0,9.5): 1.2814 - val_ca4-[9.5,10.3): 0.8976 - val_ca4-[10.3,11.3): 0.8490 - val_ca4-[11.3,14.9): 0.7289\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5708 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3585 - ca2-[9.5,10.3): 0.5164 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5336 - ca3-[10.3,11.3): 0.7093 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5062 - ca4-[11.3,14.9): 0.7096 - val_ca1-[8.0,9.5): 0.6038 - val_ca1-[9.5,10.3): 0.5065 - val_ca1-[10.3,11.3): 1.1626 - val_ca1-[11.3,14.9): 2.0626 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4174 - val_ca2-[10.3,11.3): 0.8926 - val_ca2-[11.3,14.9): 1.5317 - val_ca3-[8.0,9.5): 0.8247 - val_ca3-[9.5,10.3): 0.5392 - val_ca3-[10.3,11.3): 0.7327 - val_ca3-[11.3,14.9): 0.9652 - val_ca4-[8.0,9.5): 1.2993 - val_ca4-[9.5,10.3): 0.9125 - val_ca4-[10.3,11.3): 0.8567 - val_ca4-[11.3,14.9): 0.7294\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5623 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3841 - ca2-[9.5,10.3): 0.5228 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5659 - ca3-[10.3,11.3): 0.7252 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5016 - ca4-[11.3,14.9): 0.7131 - val_ca1-[8.0,9.5): 0.5994 - val_ca1-[9.5,10.3): 0.4980 - val_ca1-[10.3,11.3): 1.1123 - val_ca1-[11.3,14.9): 2.0113 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8669 - val_ca2-[11.3,14.9): 1.5178 - val_ca3-[8.0,9.5): 0.8260 - val_ca3-[9.5,10.3): 0.5401 - val_ca3-[10.3,11.3): 0.7174 - val_ca3-[11.3,14.9): 0.9585 - val_ca4-[8.0,9.5): 1.3159 - val_ca4-[9.5,10.3): 0.9263 - val_ca4-[10.3,11.3): 0.8575 - val_ca4-[11.3,14.9): 0.7280\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5645 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3585 - ca2-[9.5,10.3): 0.5109 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5084 - ca3-[10.3,11.3): 0.7080 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5214 - ca4-[11.3,14.9): 0.7053 - val_ca1-[8.0,9.5): 0.5957 - val_ca1-[9.5,10.3): 0.4904 - val_ca1-[10.3,11.3): 1.1266 - val_ca1-[11.3,14.9): 2.0121 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8922 - val_ca2-[11.3,14.9): 1.5376 - val_ca3-[8.0,9.5): 0.8271 - val_ca3-[9.5,10.3): 0.5409 - val_ca3-[10.3,11.3): 0.7327 - val_ca3-[11.3,14.9): 0.9566 - val_ca4-[8.0,9.5): 1.3319 - val_ca4-[9.5,10.3): 0.9396 - val_ca4-[10.3,11.3): 0.8705 - val_ca4-[11.3,14.9): 0.7056\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5375 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3689 - ca2-[9.5,10.3): 0.5221 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5209 - ca3-[10.3,11.3): 0.7140 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5578 - ca4-[11.3,14.9): 0.7176 - val_ca1-[8.0,9.5): 0.5925 - val_ca1-[9.5,10.3): 0.4834 - val_ca1-[10.3,11.3): 1.1059 - val_ca1-[11.3,14.9): 1.9739 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4178 - val_ca2-[10.3,11.3): 0.8860 - val_ca2-[11.3,14.9): 1.5334 - val_ca3-[8.0,9.5): 0.8280 - val_ca3-[9.5,10.3): 0.5432 - val_ca3-[10.3,11.3): 0.7239 - val_ca3-[11.3,14.9): 0.9602 - val_ca4-[8.0,9.5): 1.3471 - val_ca4-[9.5,10.3): 0.9552 - val_ca4-[10.3,11.3): 0.8659 - val_ca4-[11.3,14.9): 0.7158\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5490 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3839 - ca2-[9.5,10.3): 0.5201 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5482 - ca3-[10.3,11.3): 0.7080 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5429 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5899 - val_ca1-[9.5,10.3): 0.4775 - val_ca1-[10.3,11.3): 1.0829 - val_ca1-[11.3,14.9): 1.9508 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8814 - val_ca2-[11.3,14.9): 1.5393 - val_ca3-[8.0,9.5): 0.8286 - val_ca3-[9.5,10.3): 0.5418 - val_ca3-[10.3,11.3): 0.7273 - val_ca3-[11.3,14.9): 0.9710 - val_ca4-[8.0,9.5): 1.3613 - val_ca4-[9.5,10.3): 0.9642 - val_ca4-[10.3,11.3): 0.8829 - val_ca4-[11.3,14.9): 0.7301\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5392 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3837 - ca2-[9.5,10.3): 0.5090 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5367 - ca3-[10.3,11.3): 0.7031 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5837 - ca4-[11.3,14.9): 0.7097 - val_ca1-[8.0,9.5): 0.5876 - val_ca1-[9.5,10.3): 0.4720 - val_ca1-[10.3,11.3): 1.0720 - val_ca1-[11.3,14.9): 1.9283 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8811 - val_ca2-[11.3,14.9): 1.5386 - val_ca3-[8.0,9.5): 0.8293 - val_ca3-[9.5,10.3): 0.5423 - val_ca3-[10.3,11.3): 0.7223 - val_ca3-[11.3,14.9): 0.9652 - val_ca4-[8.0,9.5): 1.3751 - val_ca4-[9.5,10.3): 0.9758 - val_ca4-[10.3,11.3): 0.8792 - val_ca4-[11.3,14.9): 0.7182\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5237 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3828 - ca2-[9.5,10.3): 0.5160 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5497 - ca3-[10.3,11.3): 0.7225 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5351 - ca4-[11.3,14.9): 0.6968 - val_ca1-[8.0,9.5): 0.5857 - val_ca1-[9.5,10.3): 0.4670 - val_ca1-[10.3,11.3): 1.0560 - val_ca1-[11.3,14.9): 1.8889 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8813 - val_ca2-[11.3,14.9): 1.5240 - val_ca3-[8.0,9.5): 0.8303 - val_ca3-[9.5,10.3): 0.5430 - val_ca3-[10.3,11.3): 0.7297 - val_ca3-[11.3,14.9): 0.9504 - val_ca4-[8.0,9.5): 1.3880 - val_ca4-[9.5,10.3): 0.9866 - val_ca4-[10.3,11.3): 0.9000 - val_ca4-[11.3,14.9): 0.7043\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5470 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3681 - ca2-[9.5,10.3): 0.5147 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5783 - ca3-[10.3,11.3): 0.7317 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5618 - ca4-[11.3,14.9): 0.7030 - val_ca1-[8.0,9.5): 0.5841 - val_ca1-[9.5,10.3): 0.4625 - val_ca1-[10.3,11.3): 1.0556 - val_ca1-[11.3,14.9): 1.8599 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8903 - val_ca2-[11.3,14.9): 1.5206 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5436 - val_ca3-[10.3,11.3): 0.7328 - val_ca3-[11.3,14.9): 0.9517 - val_ca4-[8.0,9.5): 1.4004 - val_ca4-[9.5,10.3): 0.9971 - val_ca4-[10.3,11.3): 0.9031 - val_ca4-[11.3,14.9): 0.7111\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5312 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3761 - ca2-[9.5,10.3): 0.5301 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5802 - ca3-[10.3,11.3): 0.7062 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5424 - ca4-[11.3,14.9): 0.7051 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4585 - val_ca1-[10.3,11.3): 1.0450 - val_ca1-[11.3,14.9): 1.8454 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8904 - val_ca2-[11.3,14.9): 1.5248 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5445 - val_ca3-[10.3,11.3): 0.7328 - val_ca3-[11.3,14.9): 0.9508 - val_ca4-[8.0,9.5): 1.4129 - val_ca4-[9.5,10.3): 1.0075 - val_ca4-[10.3,11.3): 0.9088 - val_ca4-[11.3,14.9): 0.7066\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5359 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3555 - ca2-[9.5,10.3): 0.5088 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5559 - ca3-[10.3,11.3): 0.7372 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5034 - ca4-[11.3,14.9): 0.6850 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4549 - val_ca1-[10.3,11.3): 1.0254 - val_ca1-[11.3,14.9): 1.8402 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8796 - val_ca2-[11.3,14.9): 1.5372 - val_ca3-[8.0,9.5): 0.8333 - val_ca3-[9.5,10.3): 0.5451 - val_ca3-[10.3,11.3): 0.7200 - val_ca3-[11.3,14.9): 0.9602 - val_ca4-[8.0,9.5): 1.4241 - val_ca4-[9.5,10.3): 1.0170 - val_ca4-[10.3,11.3): 0.8988 - val_ca4-[11.3,14.9): 0.7132\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5286 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3879 - ca2-[9.5,10.3): 0.5192 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5329 - ca3-[10.3,11.3): 0.6959 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5258 - ca4-[11.3,14.9): 0.6939 - val_ca1-[8.0,9.5): 0.5809 - val_ca1-[9.5,10.3): 0.4516 - val_ca1-[10.3,11.3): 1.0259 - val_ca1-[11.3,14.9): 1.8040 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8901 - val_ca2-[11.3,14.9): 1.5201 - val_ca3-[8.0,9.5): 0.8337 - val_ca3-[9.5,10.3): 0.5454 - val_ca3-[10.3,11.3): 0.7327 - val_ca3-[11.3,14.9): 0.9464 - val_ca4-[8.0,9.5): 1.4345 - val_ca4-[9.5,10.3): 1.0257 - val_ca4-[10.3,11.3): 0.9187 - val_ca4-[11.3,14.9): 0.7026\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5338 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3917 - ca2-[9.5,10.3): 0.5249 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5646 - ca3-[10.3,11.3): 0.7159 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5570 - ca4-[11.3,14.9): 0.6933 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4487 - val_ca1-[10.3,11.3): 1.0158 - val_ca1-[11.3,14.9): 1.7821 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4172 - val_ca2-[10.3,11.3): 0.8877 - val_ca2-[11.3,14.9): 1.5167 - val_ca3-[8.0,9.5): 0.8336 - val_ca3-[9.5,10.3): 0.5453 - val_ca3-[10.3,11.3): 0.7304 - val_ca3-[11.3,14.9): 0.9533 - val_ca4-[8.0,9.5): 1.4443 - val_ca4-[9.5,10.3): 1.0341 - val_ca4-[10.3,11.3): 0.9208 - val_ca4-[11.3,14.9): 0.7185\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5250 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3745 - ca2-[9.5,10.3): 0.5240 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5517 - ca3-[10.3,11.3): 0.7096 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5788 - ca4-[11.3,14.9): 0.6956 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4461 - val_ca1-[10.3,11.3): 1.0029 - val_ca1-[11.3,14.9): 1.7690 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4172 - val_ca2-[10.3,11.3): 0.8827 - val_ca2-[11.3,14.9): 1.5153 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5450 - val_ca3-[10.3,11.3): 0.7289 - val_ca3-[11.3,14.9): 0.9484 - val_ca4-[8.0,9.5): 1.4536 - val_ca4-[9.5,10.3): 1.0419 - val_ca4-[10.3,11.3): 0.9266 - val_ca4-[11.3,14.9): 0.7072\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5303 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3784 - ca2-[9.5,10.3): 0.5163 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5550 - ca3-[10.3,11.3): 0.7145 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5708 - ca4-[11.3,14.9): 0.6889 - val_ca1-[8.0,9.5): 0.5793 - val_ca1-[9.5,10.3): 0.4439 - val_ca1-[10.3,11.3): 1.0011 - val_ca1-[11.3,14.9): 1.7434 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4176 - val_ca2-[10.3,11.3): 0.8860 - val_ca2-[11.3,14.9): 1.5024 - val_ca3-[8.0,9.5): 0.8329 - val_ca3-[9.5,10.3): 0.5466 - val_ca3-[10.3,11.3): 0.7303 - val_ca3-[11.3,14.9): 0.9418 - val_ca4-[8.0,9.5): 1.4622 - val_ca4-[9.5,10.3): 1.0523 - val_ca4-[10.3,11.3): 0.9292 - val_ca4-[11.3,14.9): 0.7037\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5277 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3955 - ca2-[9.5,10.3): 0.5185 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5459 - ca3-[10.3,11.3): 0.7096 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5674 - ca4-[11.3,14.9): 0.6937 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4417 - val_ca1-[10.3,11.3): 0.9892 - val_ca1-[11.3,14.9): 1.7609 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8811 - val_ca2-[11.3,14.9): 1.5269 - val_ca3-[8.0,9.5): 0.8333 - val_ca3-[9.5,10.3): 0.5450 - val_ca3-[10.3,11.3): 0.7288 - val_ca3-[11.3,14.9): 0.9517 - val_ca4-[8.0,9.5): 1.4703 - val_ca4-[9.5,10.3): 1.0561 - val_ca4-[10.3,11.3): 0.9346 - val_ca4-[11.3,14.9): 0.6966\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5120 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3713 - ca2-[9.5,10.3): 0.5064 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5694 - ca3-[10.3,11.3): 0.7169 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5550 - ca4-[11.3,14.9): 0.6793 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4398 - val_ca1-[10.3,11.3): 0.9832 - val_ca1-[11.3,14.9): 1.7306 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8809 - val_ca2-[11.3,14.9): 1.5111 - val_ca3-[8.0,9.5): 0.8330 - val_ca3-[9.5,10.3): 0.5448 - val_ca3-[10.3,11.3): 0.7288 - val_ca3-[11.3,14.9): 0.9459 - val_ca4-[8.0,9.5): 1.4773 - val_ca4-[9.5,10.3): 1.0620 - val_ca4-[10.3,11.3): 0.9380 - val_ca4-[11.3,14.9): 0.7003\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5130 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3739 - ca2-[9.5,10.3): 0.5175 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5505 - ca3-[10.3,11.3): 0.7186 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5490 - ca4-[11.3,14.9): 0.6917 - val_ca1-[8.0,9.5): 0.5788 - val_ca1-[9.5,10.3): 0.4380 - val_ca1-[10.3,11.3): 0.9864 - val_ca1-[11.3,14.9): 1.7241 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8889 - val_ca2-[11.3,14.9): 1.5169 - val_ca3-[8.0,9.5): 0.8324 - val_ca3-[9.5,10.3): 0.5444 - val_ca3-[10.3,11.3): 0.7347 - val_ca3-[11.3,14.9): 0.9580 - val_ca4-[8.0,9.5): 1.4849 - val_ca4-[9.5,10.3): 1.0684 - val_ca4-[10.3,11.3): 0.9452 - val_ca4-[11.3,14.9): 0.7172\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3832 - ca2-[9.5,10.3): 0.5253 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5484 - ca3-[10.3,11.3): 0.7157 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5290 - ca4-[11.3,14.9): 0.6923 - val_ca1-[8.0,9.5): 0.5787 - val_ca1-[9.5,10.3): 0.4364 - val_ca1-[10.3,11.3): 0.9743 - val_ca1-[11.3,14.9): 1.7363 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8809 - val_ca2-[11.3,14.9): 1.5368 - val_ca3-[8.0,9.5): 0.8327 - val_ca3-[9.5,10.3): 0.5446 - val_ca3-[10.3,11.3): 0.7212 - val_ca3-[11.3,14.9): 0.9642 - val_ca4-[8.0,9.5): 1.4905 - val_ca4-[9.5,10.3): 1.0732 - val_ca4-[10.3,11.3): 0.9284 - val_ca4-[11.3,14.9): 0.7090\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5189 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3752 - ca2-[9.5,10.3): 0.5179 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5426 - ca3-[10.3,11.3): 0.7146 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5537 - ca4-[11.3,14.9): 0.6867 - val_ca1-[8.0,9.5): 0.5787 - val_ca1-[9.5,10.3): 0.4351 - val_ca1-[10.3,11.3): 0.9745 - val_ca1-[11.3,14.9): 1.6903 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8870 - val_ca2-[11.3,14.9): 1.5041 - val_ca3-[8.0,9.5): 0.8327 - val_ca3-[9.5,10.3): 0.5445 - val_ca3-[10.3,11.3): 0.7324 - val_ca3-[11.3,14.9): 0.9473 - val_ca4-[8.0,9.5): 1.4957 - val_ca4-[9.5,10.3): 1.0776 - val_ca4-[10.3,11.3): 0.9478 - val_ca4-[11.3,14.9): 0.7093\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5331 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3835 - ca2-[9.5,10.3): 0.5105 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5876 - ca3-[10.3,11.3): 0.7116 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5359 - ca4-[11.3,14.9): 0.6971 - val_ca1-[8.0,9.5): 0.5788 - val_ca1-[9.5,10.3): 0.4338 - val_ca1-[10.3,11.3): 0.9649 - val_ca1-[11.3,14.9): 1.6796 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8826 - val_ca2-[11.3,14.9): 1.5023 - val_ca3-[8.0,9.5): 0.8334 - val_ca3-[9.5,10.3): 0.5450 - val_ca3-[10.3,11.3): 0.7309 - val_ca3-[11.3,14.9): 0.9445 - val_ca4-[8.0,9.5): 1.5010 - val_ca4-[9.5,10.3): 1.0821 - val_ca4-[10.3,11.3): 0.9521 - val_ca4-[11.3,14.9): 0.7063\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5218 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3737 - ca2-[9.5,10.3): 0.5101 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5308 - ca3-[10.3,11.3): 0.7189 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5850 - ca4-[11.3,14.9): 0.6936 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4326 - val_ca1-[10.3,11.3): 0.9607 - val_ca1-[11.3,14.9): 1.7072 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8826 - val_ca2-[11.3,14.9): 1.5363 - val_ca3-[8.0,9.5): 0.8341 - val_ca3-[9.5,10.3): 0.5455 - val_ca3-[10.3,11.3): 0.7308 - val_ca3-[11.3,14.9): 0.9678 - val_ca4-[8.0,9.5): 1.5072 - val_ca4-[9.5,10.3): 1.0874 - val_ca4-[10.3,11.3): 0.9551 - val_ca4-[11.3,14.9): 0.7191\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5141 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3695 - ca2-[9.5,10.3): 0.5200 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5819 - ca3-[10.3,11.3): 0.7274 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5952 - ca4-[11.3,14.9): 0.6904 - val_ca1-[8.0,9.5): 0.5790 - val_ca1-[9.5,10.3): 0.4316 - val_ca1-[10.3,11.3): 0.9618 - val_ca1-[11.3,14.9): 1.6749 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8871 - val_ca2-[11.3,14.9): 1.5134 - val_ca3-[8.0,9.5): 0.8339 - val_ca3-[9.5,10.3): 0.5454 - val_ca3-[10.3,11.3): 0.7323 - val_ca3-[11.3,14.9): 0.9481 - val_ca4-[8.0,9.5): 1.5121 - val_ca4-[9.5,10.3): 1.0916 - val_ca4-[10.3,11.3): 0.9558 - val_ca4-[11.3,14.9): 0.7032\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5244 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3921 - ca2-[9.5,10.3): 0.5185 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5633 - ca3-[10.3,11.3): 0.7071 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5538 - ca4-[11.3,14.9): 0.6929 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4306 - val_ca1-[10.3,11.3): 0.9547 - val_ca1-[11.3,14.9): 1.6858 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8828 - val_ca2-[11.3,14.9): 1.5301 - val_ca3-[8.0,9.5): 0.8342 - val_ca3-[9.5,10.3): 0.5455 - val_ca3-[10.3,11.3): 0.7232 - val_ca3-[11.3,14.9): 0.9560 - val_ca4-[8.0,9.5): 1.5170 - val_ca4-[9.5,10.3): 1.0957 - val_ca4-[10.3,11.3): 0.9436 - val_ca4-[11.3,14.9): 0.7011\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5248 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3723 - ca2-[9.5,10.3): 0.5250 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5487 - ca3-[10.3,11.3): 0.7259 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5357 - ca4-[11.3,14.9): 0.7096 - val_ca1-[8.0,9.5): 0.5793 - val_ca1-[9.5,10.3): 0.4296 - val_ca1-[10.3,11.3): 0.9524 - val_ca1-[11.3,14.9): 1.6229 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8857 - val_ca2-[11.3,14.9): 1.4798 - val_ca3-[8.0,9.5): 0.8342 - val_ca3-[9.5,10.3): 0.5455 - val_ca3-[10.3,11.3): 0.7300 - val_ca3-[11.3,14.9): 0.9223 - val_ca4-[8.0,9.5): 1.5209 - val_ca4-[9.5,10.3): 1.0990 - val_ca4-[10.3,11.3): 0.9575 - val_ca4-[11.3,14.9): 0.6883\n",
      "Epoch 97/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5176 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3748 - ca2-[9.5,10.3): 0.5263 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5850 - ca3-[10.3,11.3): 0.7278 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5022 - ca4-[11.3,14.9): 0.6878 - val_ca1-[8.0,9.5): 0.5795 - val_ca1-[9.5,10.3): 0.4287 - val_ca1-[10.3,11.3): 0.9507 - val_ca1-[11.3,14.9): 1.6353 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8878 - val_ca2-[11.3,14.9): 1.4997 - val_ca3-[8.0,9.5): 0.8338 - val_ca3-[9.5,10.3): 0.5452 - val_ca3-[10.3,11.3): 0.7322 - val_ca3-[11.3,14.9): 0.9395 - val_ca4-[8.0,9.5): 1.5248 - val_ca4-[9.5,10.3): 1.1024 - val_ca4-[10.3,11.3): 0.9620 - val_ca4-[11.3,14.9): 0.7020\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5268 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3827 - ca2-[9.5,10.3): 0.5147 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5616 - ca3-[10.3,11.3): 0.7164 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5650 - ca4-[11.3,14.9): 0.6893 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4280 - val_ca1-[10.3,11.3): 0.9458 - val_ca1-[11.3,14.9): 1.6370 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8862 - val_ca2-[11.3,14.9): 1.5070 - val_ca3-[8.0,9.5): 0.8337 - val_ca3-[9.5,10.3): 0.5451 - val_ca3-[10.3,11.3): 0.7299 - val_ca3-[11.3,14.9): 0.9381 - val_ca4-[8.0,9.5): 1.5279 - val_ca4-[9.5,10.3): 1.1050 - val_ca4-[10.3,11.3): 0.9609 - val_ca4-[11.3,14.9): 0.6916\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5276 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4024 - ca2-[9.5,10.3): 0.5202 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5401 - ca3-[10.3,11.3): 0.7226 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5298 - ca4-[11.3,14.9): 0.6998 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4273 - val_ca1-[10.3,11.3): 0.9425 - val_ca1-[11.3,14.9): 1.6366 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8861 - val_ca2-[11.3,14.9): 1.5140 - val_ca3-[8.0,9.5): 0.8335 - val_ca3-[9.5,10.3): 0.5450 - val_ca3-[10.3,11.3): 0.7303 - val_ca3-[11.3,14.9): 0.9498 - val_ca4-[8.0,9.5): 1.5306 - val_ca4-[9.5,10.3): 1.1073 - val_ca4-[10.3,11.3): 0.9638 - val_ca4-[11.3,14.9): 0.7092\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5074 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3666 - ca2-[9.5,10.3): 0.5145 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5522 - ca3-[10.3,11.3): 0.7182 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5947 - ca4-[11.3,14.9): 0.6950 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4267 - val_ca1-[10.3,11.3): 0.9374 - val_ca1-[11.3,14.9): 1.6134 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8845 - val_ca2-[11.3,14.9): 1.4979 - val_ca3-[8.0,9.5): 0.8335 - val_ca3-[9.5,10.3): 0.5449 - val_ca3-[10.3,11.3): 0.7305 - val_ca3-[11.3,14.9): 0.9365 - val_ca4-[8.0,9.5): 1.5333 - val_ca4-[9.5,10.3): 1.1096 - val_ca4-[10.3,11.3): 0.9680 - val_ca4-[11.3,14.9): 0.7000\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5097 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3614 - ca2-[9.5,10.3): 0.5186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5307 - ca3-[10.3,11.3): 0.7042 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5964 - ca4-[11.3,14.9): 0.7014 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4261 - val_ca1-[10.3,11.3): 0.9285 - val_ca1-[11.3,14.9): 1.5986 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8783 - val_ca2-[11.3,14.9): 1.4893 - val_ca3-[8.0,9.5): 0.8336 - val_ca3-[9.5,10.3): 0.5449 - val_ca3-[10.3,11.3): 0.7267 - val_ca3-[11.3,14.9): 0.9341 - val_ca4-[8.0,9.5): 1.5363 - val_ca4-[9.5,10.3): 1.1121 - val_ca4-[10.3,11.3): 0.9686 - val_ca4-[11.3,14.9): 0.7057\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5264 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3584 - ca2-[9.5,10.3): 0.5080 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5432 - ca3-[10.3,11.3): 0.7270 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5526 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5805 - val_ca1-[9.5,10.3): 0.4257 - val_ca1-[10.3,11.3): 0.9359 - val_ca1-[11.3,14.9): 1.6290 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4172 - val_ca2-[10.3,11.3): 0.8876 - val_ca2-[11.3,14.9): 1.5232 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5446 - val_ca3-[10.3,11.3): 0.7297 - val_ca3-[11.3,14.9): 0.9513 - val_ca4-[8.0,9.5): 1.5387 - val_ca4-[9.5,10.3): 1.1143 - val_ca4-[10.3,11.3): 0.9663 - val_ca4-[11.3,14.9): 0.7042\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5106 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3850 - ca2-[9.5,10.3): 0.5205 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5411 - ca3-[10.3,11.3): 0.7276 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5532 - ca4-[11.3,14.9): 0.6978 - val_ca1-[8.0,9.5): 0.5806 - val_ca1-[9.5,10.3): 0.4253 - val_ca1-[10.3,11.3): 0.9299 - val_ca1-[11.3,14.9): 1.6295 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8829 - val_ca2-[11.3,14.9): 1.5258 - val_ca3-[8.0,9.5): 0.8321 - val_ca3-[9.5,10.3): 0.5438 - val_ca3-[10.3,11.3): 0.7236 - val_ca3-[11.3,14.9): 0.9455 - val_ca4-[8.0,9.5): 1.5420 - val_ca4-[9.5,10.3): 1.1171 - val_ca4-[10.3,11.3): 0.9602 - val_ca4-[11.3,14.9): 0.6862\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5083 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3800 - ca2-[9.5,10.3): 0.5166 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5221 - ca3-[10.3,11.3): 0.7034 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5876 - ca4-[11.3,14.9): 0.6990 - val_ca1-[8.0,9.5): 0.5808 - val_ca1-[9.5,10.3): 0.4250 - val_ca1-[10.3,11.3): 0.9328 - val_ca1-[11.3,14.9): 1.6296 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8872 - val_ca2-[11.3,14.9): 1.5292 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5431 - val_ca3-[10.3,11.3): 0.7295 - val_ca3-[11.3,14.9): 0.9545 - val_ca4-[8.0,9.5): 1.5438 - val_ca4-[9.5,10.3): 1.1186 - val_ca4-[10.3,11.3): 0.9688 - val_ca4-[11.3,14.9): 0.6992\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5337 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3818 - ca2-[9.5,10.3): 0.5197 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5711 - ca3-[10.3,11.3): 0.7169 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5540 - ca4-[11.3,14.9): 0.6896 - val_ca1-[8.0,9.5): 0.5809 - val_ca1-[9.5,10.3): 0.4246 - val_ca1-[10.3,11.3): 0.9265 - val_ca1-[11.3,14.9): 1.6122 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8821 - val_ca2-[11.3,14.9): 1.5144 - val_ca3-[8.0,9.5): 0.8309 - val_ca3-[9.5,10.3): 0.5429 - val_ca3-[10.3,11.3): 0.7280 - val_ca3-[11.3,14.9): 0.9495 - val_ca4-[8.0,9.5): 1.5465 - val_ca4-[9.5,10.3): 1.1208 - val_ca4-[10.3,11.3): 0.9719 - val_ca4-[11.3,14.9): 0.7032\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5273 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3727 - ca2-[9.5,10.3): 0.5225 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5701 - ca3-[10.3,11.3): 0.6987 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5664 - ca4-[11.3,14.9): 0.6846 - val_ca1-[8.0,9.5): 0.5811 - val_ca1-[9.5,10.3): 0.4243 - val_ca1-[10.3,11.3): 0.9250 - val_ca1-[11.3,14.9): 1.6165 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8817 - val_ca2-[11.3,14.9): 1.5200 - val_ca3-[8.0,9.5): 0.8308 - val_ca3-[9.5,10.3): 0.5428 - val_ca3-[10.3,11.3): 0.7279 - val_ca3-[11.3,14.9): 0.9482 - val_ca4-[8.0,9.5): 1.5490 - val_ca4-[9.5,10.3): 1.1230 - val_ca4-[10.3,11.3): 0.9732 - val_ca4-[11.3,14.9): 0.6926\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5330 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3744 - ca2-[9.5,10.3): 0.5124 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5628 - ca3-[10.3,11.3): 0.7280 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5534 - ca4-[11.3,14.9): 0.6853 - val_ca1-[8.0,9.5): 0.5813 - val_ca1-[9.5,10.3): 0.4243 - val_ca1-[10.3,11.3): 0.9272 - val_ca1-[11.3,14.9): 1.6272 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4174 - val_ca2-[10.3,11.3): 0.8855 - val_ca2-[11.3,14.9): 1.5350 - val_ca3-[8.0,9.5): 0.8304 - val_ca3-[9.5,10.3): 0.5443 - val_ca3-[10.3,11.3): 0.7324 - val_ca3-[11.3,14.9): 0.9699 - val_ca4-[8.0,9.5): 1.5511 - val_ca4-[9.5,10.3): 1.1281 - val_ca4-[10.3,11.3): 0.9795 - val_ca4-[11.3,14.9): 0.7214\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5224 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3768 - ca2-[9.5,10.3): 0.5175 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5658 - ca3-[10.3,11.3): 0.7286 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5755 - ca4-[11.3,14.9): 0.6982 - val_ca1-[8.0,9.5): 0.5814 - val_ca1-[9.5,10.3): 0.4237 - val_ca1-[10.3,11.3): 0.9308 - val_ca1-[11.3,14.9): 1.5951 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8902 - val_ca2-[11.3,14.9): 1.5060 - val_ca3-[8.0,9.5): 0.8309 - val_ca3-[9.5,10.3): 0.5429 - val_ca3-[10.3,11.3): 0.7338 - val_ca3-[11.3,14.9): 0.9406 - val_ca4-[8.0,9.5): 1.5528 - val_ca4-[9.5,10.3): 1.1263 - val_ca4-[10.3,11.3): 0.9785 - val_ca4-[11.3,14.9): 0.6939\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.4995 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3706 - ca2-[9.5,10.3): 0.5191 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5620 - ca3-[10.3,11.3): 0.7118 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5715 - ca4-[11.3,14.9): 0.6946 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4235 - val_ca1-[10.3,11.3): 0.9256 - val_ca1-[11.3,14.9): 1.6267 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8863 - val_ca2-[11.3,14.9): 1.5400 - val_ca3-[8.0,9.5): 0.8315 - val_ca3-[9.5,10.3): 0.5432 - val_ca3-[10.3,11.3): 0.7293 - val_ca3-[11.3,14.9): 0.9692 - val_ca4-[8.0,9.5): 1.5543 - val_ca4-[9.5,10.3): 1.1275 - val_ca4-[10.3,11.3): 0.9740 - val_ca4-[11.3,14.9): 0.7175\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5206 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3861 - ca2-[9.5,10.3): 0.5235 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5426 - ca3-[10.3,11.3): 0.7062 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6050 - ca4-[11.3,14.9): 0.7041 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4232 - val_ca1-[10.3,11.3): 0.9198 - val_ca1-[11.3,14.9): 1.5918 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8823 - val_ca2-[11.3,14.9): 1.5088 - val_ca3-[8.0,9.5): 0.8319 - val_ca3-[9.5,10.3): 0.5435 - val_ca3-[10.3,11.3): 0.7277 - val_ca3-[11.3,14.9): 0.9366 - val_ca4-[8.0,9.5): 1.5554 - val_ca4-[9.5,10.3): 1.1285 - val_ca4-[10.3,11.3): 0.9764 - val_ca4-[11.3,14.9): 0.6852\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5169 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3834 - ca2-[9.5,10.3): 0.5168 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5383 - ca3-[10.3,11.3): 0.7012 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5584 - ca4-[11.3,14.9): 0.6890 - val_ca1-[8.0,9.5): 0.5819 - val_ca1-[9.5,10.3): 0.4230 - val_ca1-[10.3,11.3): 0.9187 - val_ca1-[11.3,14.9): 1.5891 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8821 - val_ca2-[11.3,14.9): 1.5084 - val_ca3-[8.0,9.5): 0.8321 - val_ca3-[9.5,10.3): 0.5436 - val_ca3-[10.3,11.3): 0.7276 - val_ca3-[11.3,14.9): 0.9388 - val_ca4-[8.0,9.5): 1.5568 - val_ca4-[9.5,10.3): 1.1297 - val_ca4-[10.3,11.3): 0.9771 - val_ca4-[11.3,14.9): 0.6909\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5148 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3833 - ca2-[9.5,10.3): 0.5186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5780 - ca3-[10.3,11.3): 0.7063 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5742 - ca4-[11.3,14.9): 0.6851 - val_ca1-[8.0,9.5): 0.5820 - val_ca1-[9.5,10.3): 0.4227 - val_ca1-[10.3,11.3): 0.9166 - val_ca1-[11.3,14.9): 1.5858 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8815 - val_ca2-[11.3,14.9): 1.5080 - val_ca3-[8.0,9.5): 0.8324 - val_ca3-[9.5,10.3): 0.5437 - val_ca3-[10.3,11.3): 0.7306 - val_ca3-[11.3,14.9): 0.9435 - val_ca4-[8.0,9.5): 1.5580 - val_ca4-[9.5,10.3): 1.1307 - val_ca4-[10.3,11.3): 0.9848 - val_ca4-[11.3,14.9): 0.7022\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5241 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3942 - ca2-[9.5,10.3): 0.5172 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5440 - ca3-[10.3,11.3): 0.7202 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5378 - ca4-[11.3,14.9): 0.6862 - val_ca1-[8.0,9.5): 0.5821 - val_ca1-[9.5,10.3): 0.4226 - val_ca1-[10.3,11.3): 0.9212 - val_ca1-[11.3,14.9): 1.5904 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8867 - val_ca2-[11.3,14.9): 1.5154 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5442 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9491 - val_ca4-[8.0,9.5): 1.5592 - val_ca4-[9.5,10.3): 1.1317 - val_ca4-[10.3,11.3): 0.9764 - val_ca4-[11.3,14.9): 0.7087\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5099 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3773 - ca2-[9.5,10.3): 0.5301 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5492 - ca3-[10.3,11.3): 0.7185 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5539 - ca4-[11.3,14.9): 0.6877 - val_ca1-[8.0,9.5): 0.5822 - val_ca1-[9.5,10.3): 0.4225 - val_ca1-[10.3,11.3): 0.9180 - val_ca1-[11.3,14.9): 1.5752 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8843 - val_ca2-[11.3,14.9): 1.5010 - val_ca3-[8.0,9.5): 0.8338 - val_ca3-[9.5,10.3): 0.5446 - val_ca3-[10.3,11.3): 0.7297 - val_ca3-[11.3,14.9): 0.9306 - val_ca4-[8.0,9.5): 1.5605 - val_ca4-[9.5,10.3): 1.1328 - val_ca4-[10.3,11.3): 0.9815 - val_ca4-[11.3,14.9): 0.6873\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5203 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3844 - ca2-[9.5,10.3): 0.5190 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5595 - ca3-[10.3,11.3): 0.7030 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5827 - ca4-[11.3,14.9): 0.6972 - val_ca1-[8.0,9.5): 0.5823 - val_ca1-[9.5,10.3): 0.4224 - val_ca1-[10.3,11.3): 0.9174 - val_ca1-[11.3,14.9): 1.5876 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8833 - val_ca2-[11.3,14.9): 1.5130 - val_ca3-[8.0,9.5): 0.8338 - val_ca3-[9.5,10.3): 0.5445 - val_ca3-[10.3,11.3): 0.7296 - val_ca3-[11.3,14.9): 0.9506 - val_ca4-[8.0,9.5): 1.5614 - val_ca4-[9.5,10.3): 1.1336 - val_ca4-[10.3,11.3): 0.9820 - val_ca4-[11.3,14.9): 0.7143\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5275 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3917 - ca2-[9.5,10.3): 0.5252 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5473 - ca3-[10.3,11.3): 0.7095 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6217 - ca4-[11.3,14.9): 0.6997 - val_ca1-[8.0,9.5): 0.5824 - val_ca1-[9.5,10.3): 0.4222 - val_ca1-[10.3,11.3): 0.9124 - val_ca1-[11.3,14.9): 1.5853 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8784 - val_ca2-[11.3,14.9): 1.5102 - val_ca3-[8.0,9.5): 0.8340 - val_ca3-[9.5,10.3): 0.5446 - val_ca3-[10.3,11.3): 0.7255 - val_ca3-[11.3,14.9): 0.9430 - val_ca4-[8.0,9.5): 1.5623 - val_ca4-[9.5,10.3): 1.1344 - val_ca4-[10.3,11.3): 0.9788 - val_ca4-[11.3,14.9): 0.7001\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5102 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3829 - ca2-[9.5,10.3): 0.5100 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5523 - ca3-[10.3,11.3): 0.7120 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5617 - ca4-[11.3,14.9): 0.6883 - val_ca1-[8.0,9.5): 0.5824 - val_ca1-[9.5,10.3): 0.4221 - val_ca1-[10.3,11.3): 0.9190 - val_ca1-[11.3,14.9): 1.5788 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8845 - val_ca2-[11.3,14.9): 1.5041 - val_ca3-[8.0,9.5): 0.8342 - val_ca3-[9.5,10.3): 0.5447 - val_ca3-[10.3,11.3): 0.7287 - val_ca3-[11.3,14.9): 0.9436 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1356 - val_ca4-[10.3,11.3): 0.9787 - val_ca4-[11.3,14.9): 0.7079\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5081 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3725 - ca2-[9.5,10.3): 0.5054 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5464 - ca3-[10.3,11.3): 0.7071 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5614 - ca4-[11.3,14.9): 0.6953 - val_ca1-[8.0,9.5): 0.5825 - val_ca1-[9.5,10.3): 0.4221 - val_ca1-[10.3,11.3): 0.9102 - val_ca1-[11.3,14.9): 1.5678 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8759 - val_ca2-[11.3,14.9): 1.4937 - val_ca3-[8.0,9.5): 0.8346 - val_ca3-[9.5,10.3): 0.5449 - val_ca3-[10.3,11.3): 0.7181 - val_ca3-[11.3,14.9): 0.9309 - val_ca4-[8.0,9.5): 1.5647 - val_ca4-[9.5,10.3): 1.1364 - val_ca4-[10.3,11.3): 0.9662 - val_ca4-[11.3,14.9): 0.6940\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5269 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3651 - ca2-[9.5,10.3): 0.5199 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5711 - ca3-[10.3,11.3): 0.7201 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5903 - ca4-[11.3,14.9): 0.6883 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9174 - val_ca1-[11.3,14.9): 1.5921 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8847 - val_ca2-[11.3,14.9): 1.5209 - val_ca3-[8.0,9.5): 0.8339 - val_ca3-[9.5,10.3): 0.5444 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9547 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9813 - val_ca4-[11.3,14.9): 0.7140\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5266 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3785 - ca2-[9.5,10.3): 0.5094 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5416 - ca3-[10.3,11.3): 0.7213 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5906 - ca4-[11.3,14.9): 0.6793 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9210 - val_ca1-[11.3,14.9): 1.6146 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8897 - val_ca2-[11.3,14.9): 1.5460 - val_ca3-[8.0,9.5): 0.8336 - val_ca3-[9.5,10.3): 0.5441 - val_ca3-[10.3,11.3): 0.7304 - val_ca3-[11.3,14.9): 0.9669 - val_ca4-[8.0,9.5): 1.5651 - val_ca4-[9.5,10.3): 1.1367 - val_ca4-[10.3,11.3): 0.9790 - val_ca4-[11.3,14.9): 0.7123\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3686 - ca2-[9.5,10.3): 0.5111 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5605 - ca3-[10.3,11.3): 0.7067 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5925 - ca4-[11.3,14.9): 0.7056 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.5701 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8843 - val_ca2-[11.3,14.9): 1.5052 - val_ca3-[8.0,9.5): 0.8334 - val_ca3-[9.5,10.3): 0.5440 - val_ca3-[10.3,11.3): 0.7216 - val_ca3-[11.3,14.9): 0.9306 - val_ca4-[8.0,9.5): 1.5643 - val_ca4-[9.5,10.3): 1.1361 - val_ca4-[10.3,11.3): 0.9667 - val_ca4-[11.3,14.9): 0.6833\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5257 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3693 - ca2-[9.5,10.3): 0.5084 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5331 - ca3-[10.3,11.3): 0.7194 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5669 - ca4-[11.3,14.9): 0.6970 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9200 - val_ca1-[11.3,14.9): 1.5727 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8902 - val_ca2-[11.3,14.9): 1.5085 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5437 - val_ca3-[10.3,11.3): 0.7328 - val_ca3-[11.3,14.9): 0.9440 - val_ca4-[8.0,9.5): 1.5641 - val_ca4-[9.5,10.3): 1.1359 - val_ca4-[10.3,11.3): 0.9841 - val_ca4-[11.3,14.9): 0.7079\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5246 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3832 - ca2-[9.5,10.3): 0.5191 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5453 - ca3-[10.3,11.3): 0.6958 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5494 - ca4-[11.3,14.9): 0.6783 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9135 - val_ca1-[11.3,14.9): 1.5749 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8839 - val_ca2-[11.3,14.9): 1.5110 - val_ca3-[8.0,9.5): 0.8334 - val_ca3-[9.5,10.3): 0.5439 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9472 - val_ca4-[8.0,9.5): 1.5646 - val_ca4-[9.5,10.3): 1.1363 - val_ca4-[10.3,11.3): 0.9836 - val_ca4-[11.3,14.9): 0.7125\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5010 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3769 - ca2-[9.5,10.3): 0.5273 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5328 - ca3-[10.3,11.3): 0.7246 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5440 - ca4-[11.3,14.9): 0.6835 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9116 - val_ca1-[11.3,14.9): 1.5867 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8812 - val_ca2-[11.3,14.9): 1.5198 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5437 - val_ca3-[10.3,11.3): 0.7266 - val_ca3-[11.3,14.9): 0.9461 - val_ca4-[8.0,9.5): 1.5645 - val_ca4-[9.5,10.3): 1.1362 - val_ca4-[10.3,11.3): 0.9809 - val_ca4-[11.3,14.9): 0.6979\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5220 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3843 - ca2-[9.5,10.3): 0.5148 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5450 - ca3-[10.3,11.3): 0.7309 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5679 - ca4-[11.3,14.9): 0.6820 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9134 - val_ca1-[11.3,14.9): 1.5793 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4164 - val_ca2-[10.3,11.3): 0.8824 - val_ca2-[11.3,14.9): 1.5118 - val_ca3-[8.0,9.5): 0.8333 - val_ca3-[9.5,10.3): 0.5437 - val_ca3-[10.3,11.3): 0.7288 - val_ca3-[11.3,14.9): 0.9473 - val_ca4-[8.0,9.5): 1.5649 - val_ca4-[9.5,10.3): 1.1365 - val_ca4-[10.3,11.3): 0.9837 - val_ca4-[11.3,14.9): 0.7086\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3866 - ca2-[9.5,10.3): 0.5276 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5475 - ca3-[10.3,11.3): 0.7026 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5986 - ca4-[11.3,14.9): 0.6846 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9199 - val_ca1-[11.3,14.9): 1.5743 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8889 - val_ca2-[11.3,14.9): 1.5083 - val_ca3-[8.0,9.5): 0.8330 - val_ca3-[9.5,10.3): 0.5434 - val_ca3-[10.3,11.3): 0.7299 - val_ca3-[11.3,14.9): 0.9446 - val_ca4-[8.0,9.5): 1.5655 - val_ca4-[9.5,10.3): 1.1370 - val_ca4-[10.3,11.3): 0.9791 - val_ca4-[11.3,14.9): 0.7068\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5029 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3826 - ca2-[9.5,10.3): 0.5109 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5626 - ca3-[10.3,11.3): 0.7178 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5545 - ca4-[11.3,14.9): 0.6801 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4222 - val_ca1-[10.3,11.3): 0.9174 - val_ca1-[11.3,14.9): 1.5936 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8873 - val_ca2-[11.3,14.9): 1.5286 - val_ca3-[8.0,9.5): 0.8328 - val_ca3-[9.5,10.3): 0.5423 - val_ca3-[10.3,11.3): 0.7300 - val_ca3-[11.3,14.9): 0.9586 - val_ca4-[8.0,9.5): 1.5657 - val_ca4-[9.5,10.3): 1.1346 - val_ca4-[10.3,11.3): 0.9822 - val_ca4-[11.3,14.9): 0.7146\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5213 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3873 - ca2-[9.5,10.3): 0.5260 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5385 - ca3-[10.3,11.3): 0.7143 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5834 - ca4-[11.3,14.9): 0.6938 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9107 - val_ca1-[11.3,14.9): 1.5456 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4164 - val_ca2-[10.3,11.3): 0.8813 - val_ca2-[11.3,14.9): 1.4822 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5427 - val_ca3-[10.3,11.3): 0.7260 - val_ca3-[11.3,14.9): 0.9133 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9818 - val_ca4-[11.3,14.9): 0.6707\n",
      "Epoch 129/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5314 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3811 - ca2-[9.5,10.3): 0.5318 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5367 - ca3-[10.3,11.3): 0.7028 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5709 - ca4-[11.3,14.9): 0.6999 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9111 - val_ca1-[11.3,14.9): 1.5641 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8811 - val_ca2-[11.3,14.9): 1.5005 - val_ca3-[8.0,9.5): 0.8314 - val_ca3-[9.5,10.3): 0.5419 - val_ca3-[10.3,11.3): 0.7184 - val_ca3-[11.3,14.9): 0.9325 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9651 - val_ca4-[11.3,14.9): 0.6899\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5132 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3747 - ca2-[9.5,10.3): 0.5219 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5210 - ca3-[10.3,11.3): 0.7100 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5278 - ca4-[11.3,14.9): 0.6843 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9167 - val_ca1-[11.3,14.9): 1.5856 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4162 - val_ca2-[10.3,11.3): 0.8869 - val_ca2-[11.3,14.9): 1.5215 - val_ca3-[8.0,9.5): 0.8303 - val_ca3-[9.5,10.3): 0.5411 - val_ca3-[10.3,11.3): 0.7294 - val_ca3-[11.3,14.9): 0.9534 - val_ca4-[8.0,9.5): 1.5667 - val_ca4-[9.5,10.3): 1.1381 - val_ca4-[10.3,11.3): 0.9827 - val_ca4-[11.3,14.9): 0.7082\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5245 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3777 - ca2-[9.5,10.3): 0.5206 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5653 - ca3-[10.3,11.3): 0.7201 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5429 - ca4-[11.3,14.9): 0.7106 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9101 - val_ca1-[11.3,14.9): 1.5831 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4161 - val_ca2-[10.3,11.3): 0.8802 - val_ca2-[11.3,14.9): 1.5183 - val_ca3-[8.0,9.5): 0.8302 - val_ca3-[9.5,10.3): 0.5410 - val_ca3-[10.3,11.3): 0.7255 - val_ca3-[11.3,14.9): 0.9526 - val_ca4-[8.0,9.5): 1.5670 - val_ca4-[9.5,10.3): 1.1383 - val_ca4-[10.3,11.3): 0.9821 - val_ca4-[11.3,14.9): 0.7093\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5247 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3849 - ca2-[9.5,10.3): 0.5092 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5139 - ca3-[10.3,11.3): 0.6999 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5708 - ca4-[11.3,14.9): 0.6960 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9166 - val_ca1-[11.3,14.9): 1.5426 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8862 - val_ca2-[11.3,14.9): 1.4787 - val_ca3-[8.0,9.5): 0.8296 - val_ca3-[9.5,10.3): 0.5405 - val_ca3-[10.3,11.3): 0.7292 - val_ca3-[11.3,14.9): 0.9296 - val_ca4-[8.0,9.5): 1.5678 - val_ca4-[9.5,10.3): 1.1390 - val_ca4-[10.3,11.3): 0.9832 - val_ca4-[11.3,14.9): 0.7049\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5198 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3655 - ca2-[9.5,10.3): 0.5104 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5525 - ca3-[10.3,11.3): 0.7172 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5346 - ca4-[11.3,14.9): 0.6835 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5978 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8836 - val_ca2-[11.3,14.9): 1.5325 - val_ca3-[8.0,9.5): 0.8293 - val_ca3-[9.5,10.3): 0.5402 - val_ca3-[10.3,11.3): 0.7299 - val_ca3-[11.3,14.9): 0.9642 - val_ca4-[8.0,9.5): 1.5681 - val_ca4-[9.5,10.3): 1.1392 - val_ca4-[10.3,11.3): 0.9879 - val_ca4-[11.3,14.9): 0.7153\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5227 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3696 - ca2-[9.5,10.3): 0.5121 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5687 - ca3-[10.3,11.3): 0.7234 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5629 - ca4-[11.3,14.9): 0.6915 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.5958 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8848 - val_ca2-[11.3,14.9): 1.5323 - val_ca3-[8.0,9.5): 0.8301 - val_ca3-[9.5,10.3): 0.5407 - val_ca3-[10.3,11.3): 0.7268 - val_ca3-[11.3,14.9): 0.9625 - val_ca4-[8.0,9.5): 1.5678 - val_ca4-[9.5,10.3): 1.1390 - val_ca4-[10.3,11.3): 0.9806 - val_ca4-[11.3,14.9): 0.7164\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5273 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3684 - ca2-[9.5,10.3): 0.5168 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5265 - ca3-[10.3,11.3): 0.7178 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6045 - ca4-[11.3,14.9): 0.6907 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9119 - val_ca1-[11.3,14.9): 1.5589 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8828 - val_ca2-[11.3,14.9): 1.4971 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5414 - val_ca3-[10.3,11.3): 0.7275 - val_ca3-[11.3,14.9): 0.9317 - val_ca4-[8.0,9.5): 1.5681 - val_ca4-[9.5,10.3): 1.1392 - val_ca4-[10.3,11.3): 0.9852 - val_ca4-[11.3,14.9): 0.6938\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5108 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3905 - ca2-[9.5,10.3): 0.5091 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5435 - ca3-[10.3,11.3): 0.7299 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5414 - ca4-[11.3,14.9): 0.6832 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9028 - val_ca1-[11.3,14.9): 1.5611 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8739 - val_ca2-[11.3,14.9): 1.4991 - val_ca3-[8.0,9.5): 0.8312 - val_ca3-[9.5,10.3): 0.5414 - val_ca3-[10.3,11.3): 0.7244 - val_ca3-[11.3,14.9): 0.9397 - val_ca4-[8.0,9.5): 1.5685 - val_ca4-[9.5,10.3): 1.1395 - val_ca4-[10.3,11.3): 0.9893 - val_ca4-[11.3,14.9): 0.7098\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5221 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3755 - ca2-[9.5,10.3): 0.5201 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5414 - ca3-[10.3,11.3): 0.7288 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5481 - ca4-[11.3,14.9): 0.6994 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.5530 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4159 - val_ca2-[10.3,11.3): 0.8866 - val_ca2-[11.3,14.9): 1.4894 - val_ca3-[8.0,9.5): 0.8318 - val_ca3-[9.5,10.3): 0.5418 - val_ca3-[10.3,11.3): 0.7289 - val_ca3-[11.3,14.9): 0.9319 - val_ca4-[8.0,9.5): 1.5687 - val_ca4-[9.5,10.3): 1.1397 - val_ca4-[10.3,11.3): 0.9836 - val_ca4-[11.3,14.9): 0.7045\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5140 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3780 - ca2-[9.5,10.3): 0.5177 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5530 - ca3-[10.3,11.3): 0.7186 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5735 - ca4-[11.3,14.9): 0.6907 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9134 - val_ca1-[11.3,14.9): 1.5742 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4158 - val_ca2-[10.3,11.3): 0.8818 - val_ca2-[11.3,14.9): 1.5077 - val_ca3-[8.0,9.5): 0.8309 - val_ca3-[9.5,10.3): 0.5411 - val_ca3-[10.3,11.3): 0.7198 - val_ca3-[11.3,14.9): 0.9365 - val_ca4-[8.0,9.5): 1.5686 - val_ca4-[9.5,10.3): 1.1397 - val_ca4-[10.3,11.3): 0.9687 - val_ca4-[11.3,14.9): 0.6895\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5245 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3593 - ca2-[9.5,10.3): 0.5187 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5453 - ca3-[10.3,11.3): 0.7090 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5841 - ca4-[11.3,14.9): 0.6914 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9126 - val_ca1-[11.3,14.9): 1.5934 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4156 - val_ca2-[10.3,11.3): 0.8809 - val_ca2-[11.3,14.9): 1.5252 - val_ca3-[8.0,9.5): 0.8305 - val_ca3-[9.5,10.3): 0.5408 - val_ca3-[10.3,11.3): 0.7272 - val_ca3-[11.3,14.9): 0.9560 - val_ca4-[8.0,9.5): 1.5678 - val_ca4-[9.5,10.3): 1.1389 - val_ca4-[10.3,11.3): 0.9850 - val_ca4-[11.3,14.9): 0.7088\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5029 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3919 - ca2-[9.5,10.3): 0.5188 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5804 - ca3-[10.3,11.3): 0.7174 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5742 - ca4-[11.3,14.9): 0.6855 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9107 - val_ca1-[11.3,14.9): 1.5779 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4155 - val_ca2-[10.3,11.3): 0.8782 - val_ca2-[11.3,14.9): 1.5087 - val_ca3-[8.0,9.5): 0.8302 - val_ca3-[9.5,10.3): 0.5405 - val_ca3-[10.3,11.3): 0.7248 - val_ca3-[11.3,14.9): 0.9453 - val_ca4-[8.0,9.5): 1.5677 - val_ca4-[9.5,10.3): 1.1389 - val_ca4-[10.3,11.3): 0.9824 - val_ca4-[11.3,14.9): 0.7027\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.4991 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3765 - ca2-[9.5,10.3): 0.5150 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5542 - ca3-[10.3,11.3): 0.7103 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5160 - ca4-[11.3,14.9): 0.6868 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9175 - val_ca1-[11.3,14.9): 1.5802 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4154 - val_ca2-[10.3,11.3): 0.8842 - val_ca2-[11.3,14.9): 1.5103 - val_ca3-[8.0,9.5): 0.8303 - val_ca3-[9.5,10.3): 0.5405 - val_ca3-[10.3,11.3): 0.7260 - val_ca3-[11.3,14.9): 0.9481 - val_ca4-[8.0,9.5): 1.5673 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9773 - val_ca4-[11.3,14.9): 0.7073\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5126 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3876 - ca2-[9.5,10.3): 0.5159 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5636 - ca3-[10.3,11.3): 0.7228 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5767 - ca4-[11.3,14.9): 0.6939 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9153 - val_ca1-[11.3,14.9): 1.5714 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4153 - val_ca2-[10.3,11.3): 0.8818 - val_ca2-[11.3,14.9): 1.5006 - val_ca3-[8.0,9.5): 0.8295 - val_ca3-[9.5,10.3): 0.5399 - val_ca3-[10.3,11.3): 0.7261 - val_ca3-[11.3,14.9): 0.9389 - val_ca4-[8.0,9.5): 1.5662 - val_ca4-[9.5,10.3): 1.1375 - val_ca4-[10.3,11.3): 0.9796 - val_ca4-[11.3,14.9): 0.6962\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5131 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3573 - ca2-[9.5,10.3): 0.4988 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5248 - ca3-[10.3,11.3): 0.7186 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5665 - ca4-[11.3,14.9): 0.6936 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9210 - val_ca1-[11.3,14.9): 1.5710 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4153 - val_ca2-[10.3,11.3): 0.8884 - val_ca2-[11.3,14.9): 1.5025 - val_ca3-[8.0,9.5): 0.8299 - val_ca3-[9.5,10.3): 0.5401 - val_ca3-[10.3,11.3): 0.7328 - val_ca3-[11.3,14.9): 0.9386 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1373 - val_ca4-[10.3,11.3): 0.9874 - val_ca4-[11.3,14.9): 0.6962\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5203 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3776 - ca2-[9.5,10.3): 0.5204 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5427 - ca3-[10.3,11.3): 0.7299 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5833 - ca4-[11.3,14.9): 0.7006 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9152 - val_ca1-[11.3,14.9): 1.5572 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4152 - val_ca2-[10.3,11.3): 0.8819 - val_ca2-[11.3,14.9): 1.4883 - val_ca3-[8.0,9.5): 0.8314 - val_ca3-[9.5,10.3): 0.5412 - val_ca3-[10.3,11.3): 0.7260 - val_ca3-[11.3,14.9): 0.9344 - val_ca4-[8.0,9.5): 1.5656 - val_ca4-[9.5,10.3): 1.1370 - val_ca4-[10.3,11.3): 0.9793 - val_ca4-[11.3,14.9): 0.7062\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5288 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3754 - ca2-[9.5,10.3): 0.5276 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5702 - ca3-[10.3,11.3): 0.7200 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5562 - ca4-[11.3,14.9): 0.7124 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9149 - val_ca1-[11.3,14.9): 1.5902 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4151 - val_ca2-[10.3,11.3): 0.8815 - val_ca2-[11.3,14.9): 1.5198 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5417 - val_ca3-[10.3,11.3): 0.7259 - val_ca3-[11.3,14.9): 0.9527 - val_ca4-[8.0,9.5): 1.5657 - val_ca4-[9.5,10.3): 1.1371 - val_ca4-[10.3,11.3): 0.9793 - val_ca4-[11.3,14.9): 0.7098\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5112 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3808 - ca2-[9.5,10.3): 0.5179 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5510 - ca3-[10.3,11.3): 0.7088 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5700 - ca4-[11.3,14.9): 0.6879 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9093 - val_ca1-[11.3,14.9): 1.5986 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4151 - val_ca2-[10.3,11.3): 0.8769 - val_ca2-[11.3,14.9): 1.5294 - val_ca3-[8.0,9.5): 0.8327 - val_ca3-[9.5,10.3): 0.5420 - val_ca3-[10.3,11.3): 0.7274 - val_ca3-[11.3,14.9): 0.9595 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1372 - val_ca4-[10.3,11.3): 0.9885 - val_ca4-[11.3,14.9): 0.7152\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5076 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3747 - ca2-[9.5,10.3): 0.5152 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5451 - ca3-[10.3,11.3): 0.7107 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5739 - ca4-[11.3,14.9): 0.6992 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9165 - val_ca1-[11.3,14.9): 1.5802 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4155 - val_ca2-[10.3,11.3): 0.8835 - val_ca2-[11.3,14.9): 1.5126 - val_ca3-[8.0,9.5): 0.8321 - val_ca3-[9.5,10.3): 0.5432 - val_ca3-[10.3,11.3): 0.7254 - val_ca3-[11.3,14.9): 0.9494 - val_ca4-[8.0,9.5): 1.5672 - val_ca4-[9.5,10.3): 1.1416 - val_ca4-[10.3,11.3): 0.9771 - val_ca4-[11.3,14.9): 0.7119\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3684 - ca2-[9.5,10.3): 0.5133 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5410 - ca3-[10.3,11.3): 0.7203 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5791 - ca4-[11.3,14.9): 0.6809 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9143 - val_ca1-[11.3,14.9): 1.5821 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.4149 - val_ca2-[10.3,11.3): 0.8815 - val_ca2-[11.3,14.9): 1.5139 - val_ca3-[8.0,9.5): 0.8316 - val_ca3-[9.5,10.3): 0.5410 - val_ca3-[10.3,11.3): 0.7255 - val_ca3-[11.3,14.9): 0.9491 - val_ca4-[8.0,9.5): 1.5674 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9801 - val_ca4-[11.3,14.9): 0.7090\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5021 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3881 - ca2-[9.5,10.3): 0.5192 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5510 - ca3-[10.3,11.3): 0.7055 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5461 - ca4-[11.3,14.9): 0.6858 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.8959 - val_ca1-[11.3,14.9): 1.5484 - val_ca2-[8.0,9.5): 0.5876 - val_ca2-[9.5,10.3): 0.4148 - val_ca2-[10.3,11.3): 0.8642 - val_ca2-[11.3,14.9): 1.4821 - val_ca3-[8.0,9.5): 0.8317 - val_ca3-[9.5,10.3): 0.5409 - val_ca3-[10.3,11.3): 0.7194 - val_ca3-[11.3,14.9): 0.9324 - val_ca4-[8.0,9.5): 1.5674 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9878 - val_ca4-[11.3,14.9): 0.7111\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5110 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3589 - ca2-[9.5,10.3): 0.5199 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5297 - ca3-[10.3,11.3): 0.7335 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5328 - ca4-[11.3,14.9): 0.6779 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9142 - val_ca1-[11.3,14.9): 1.5559 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.4149 - val_ca2-[10.3,11.3): 0.8823 - val_ca2-[11.3,14.9): 1.4904 - val_ca3-[8.0,9.5): 0.8322 - val_ca3-[9.5,10.3): 0.5412 - val_ca3-[10.3,11.3): 0.7253 - val_ca3-[11.3,14.9): 0.9249 - val_ca4-[8.0,9.5): 1.5678 - val_ca4-[9.5,10.3): 1.1388 - val_ca4-[10.3,11.3): 0.9803 - val_ca4-[11.3,14.9): 0.6889\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5207 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3808 - ca2-[9.5,10.3): 0.5118 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5738 - ca3-[10.3,11.3): 0.7101 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5745 - ca4-[11.3,14.9): 0.6926 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9162 - val_ca1-[11.3,14.9): 1.5756 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.4147 - val_ca2-[10.3,11.3): 0.8840 - val_ca2-[11.3,14.9): 1.5098 - val_ca3-[8.0,9.5): 0.8321 - val_ca3-[9.5,10.3): 0.5411 - val_ca3-[10.3,11.3): 0.7274 - val_ca3-[11.3,14.9): 0.9420 - val_ca4-[8.0,9.5): 1.5684 - val_ca4-[9.5,10.3): 1.1393 - val_ca4-[10.3,11.3): 0.9832 - val_ca4-[11.3,14.9): 0.7025\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5084 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3947 - ca2-[9.5,10.3): 0.5156 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5519 - ca3-[10.3,11.3): 0.7198 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5926 - ca4-[11.3,14.9): 0.6717 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9203 - val_ca1-[11.3,14.9): 1.5890 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.4145 - val_ca2-[10.3,11.3): 0.8869 - val_ca2-[11.3,14.9): 1.5204 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5417 - val_ca3-[10.3,11.3): 0.7319 - val_ca3-[11.3,14.9): 0.9511 - val_ca4-[8.0,9.5): 1.5675 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9880 - val_ca4-[11.3,14.9): 0.7097\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5237 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3841 - ca2-[9.5,10.3): 0.5169 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5441 - ca3-[10.3,11.3): 0.7039 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5703 - ca4-[11.3,14.9): 0.6991 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9162 - val_ca1-[11.3,14.9): 1.5751 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.4144 - val_ca2-[10.3,11.3): 0.8830 - val_ca2-[11.3,14.9): 1.5079 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5417 - val_ca3-[10.3,11.3): 0.7273 - val_ca3-[11.3,14.9): 0.9460 - val_ca4-[8.0,9.5): 1.5667 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9823 - val_ca4-[11.3,14.9): 0.7139\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5253 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3844 - ca2-[9.5,10.3): 0.5172 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5418 - ca3-[10.3,11.3): 0.7076 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5663 - ca4-[11.3,14.9): 0.6904 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5962 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.4148 - val_ca2-[10.3,11.3): 0.8822 - val_ca2-[11.3,14.9): 1.5275 - val_ca3-[8.0,9.5): 0.8338 - val_ca3-[9.5,10.3): 0.5411 - val_ca3-[10.3,11.3): 0.7251 - val_ca3-[11.3,14.9): 0.9556 - val_ca4-[8.0,9.5): 1.5663 - val_ca4-[9.5,10.3): 1.1348 - val_ca4-[10.3,11.3): 0.9780 - val_ca4-[11.3,14.9): 0.7121\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5206 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3680 - ca2-[9.5,10.3): 0.5237 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5593 - ca3-[10.3,11.3): 0.7188 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5344 - ca4-[11.3,14.9): 0.6912 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9144 - val_ca1-[11.3,14.9): 1.5502 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.4142 - val_ca2-[10.3,11.3): 0.8805 - val_ca2-[11.3,14.9): 1.4814 - val_ca3-[8.0,9.5): 0.8329 - val_ca3-[9.5,10.3): 0.5413 - val_ca3-[10.3,11.3): 0.7247 - val_ca3-[11.3,14.9): 0.9146 - val_ca4-[8.0,9.5): 1.5660 - val_ca4-[9.5,10.3): 1.1372 - val_ca4-[10.3,11.3): 0.9793 - val_ca4-[11.3,14.9): 0.6766\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5299 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3730 - ca2-[9.5,10.3): 0.5138 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5376 - ca3-[10.3,11.3): 0.6936 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5648 - ca4-[11.3,14.9): 0.6877 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9147 - val_ca1-[11.3,14.9): 1.5836 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.4140 - val_ca2-[10.3,11.3): 0.8795 - val_ca2-[11.3,14.9): 1.5118 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5408 - val_ca3-[10.3,11.3): 0.7245 - val_ca3-[11.3,14.9): 0.9426 - val_ca4-[8.0,9.5): 1.5667 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9796 - val_ca4-[11.3,14.9): 0.6975\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5151 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3670 - ca2-[9.5,10.3): 0.5195 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5470 - ca3-[10.3,11.3): 0.7258 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5575 - ca4-[11.3,14.9): 0.6797 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9101 - val_ca1-[11.3,14.9): 1.5968 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.4137 - val_ca2-[10.3,11.3): 0.8741 - val_ca2-[11.3,14.9): 1.5225 - val_ca3-[8.0,9.5): 0.8321 - val_ca3-[9.5,10.3): 0.5405 - val_ca3-[10.3,11.3): 0.7229 - val_ca3-[11.3,14.9): 0.9529 - val_ca4-[8.0,9.5): 1.5670 - val_ca4-[9.5,10.3): 1.1380 - val_ca4-[10.3,11.3): 0.9816 - val_ca4-[11.3,14.9): 0.7046\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5097 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3763 - ca2-[9.5,10.3): 0.4971 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5405 - ca3-[10.3,11.3): 0.7201 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5794 - ca4-[11.3,14.9): 0.7002 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9167 - val_ca1-[11.3,14.9): 1.5765 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.4136 - val_ca2-[10.3,11.3): 0.8805 - val_ca2-[11.3,14.9): 1.5040 - val_ca3-[8.0,9.5): 0.8315 - val_ca3-[9.5,10.3): 0.5399 - val_ca3-[10.3,11.3): 0.7264 - val_ca3-[11.3,14.9): 0.9443 - val_ca4-[8.0,9.5): 1.5673 - val_ca4-[9.5,10.3): 1.1382 - val_ca4-[10.3,11.3): 0.9824 - val_ca4-[11.3,14.9): 0.7081\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5236 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3594 - ca2-[9.5,10.3): 0.5010 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5586 - ca3-[10.3,11.3): 0.7066 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5528 - ca4-[11.3,14.9): 0.6899 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9180 - val_ca1-[11.3,14.9): 1.5850 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.4136 - val_ca2-[10.3,11.3): 0.8834 - val_ca2-[11.3,14.9): 1.5157 - val_ca3-[8.0,9.5): 0.8306 - val_ca3-[9.5,10.3): 0.5391 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9499 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1375 - val_ca4-[10.3,11.3): 0.9862 - val_ca4-[11.3,14.9): 0.7077\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5073 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3590 - ca2-[9.5,10.3): 0.5176 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5311 - ca3-[10.3,11.3): 0.7052 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5897 - ca4-[11.3,14.9): 0.6913 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9143 - val_ca1-[11.3,14.9): 1.5755 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.4135 - val_ca2-[10.3,11.3): 0.8799 - val_ca2-[11.3,14.9): 1.5079 - val_ca3-[8.0,9.5): 0.8306 - val_ca3-[9.5,10.3): 0.5390 - val_ca3-[10.3,11.3): 0.7238 - val_ca3-[11.3,14.9): 0.9451 - val_ca4-[8.0,9.5): 1.5661 - val_ca4-[9.5,10.3): 1.1372 - val_ca4-[10.3,11.3): 0.9792 - val_ca4-[11.3,14.9): 0.7081\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5216 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3811 - ca2-[9.5,10.3): 0.5163 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5303 - ca3-[10.3,11.3): 0.7092 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5668 - ca4-[11.3,14.9): 0.6940 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9160 - val_ca1-[11.3,14.9): 1.5911 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.4134 - val_ca2-[10.3,11.3): 0.8817 - val_ca2-[11.3,14.9): 1.5229 - val_ca3-[8.0,9.5): 0.8298 - val_ca3-[9.5,10.3): 0.5382 - val_ca3-[10.3,11.3): 0.7258 - val_ca3-[11.3,14.9): 0.9515 - val_ca4-[8.0,9.5): 1.5670 - val_ca4-[9.5,10.3): 1.1379 - val_ca4-[10.3,11.3): 0.9822 - val_ca4-[11.3,14.9): 0.7027\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5227 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3682 - ca2-[9.5,10.3): 0.5193 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5438 - ca3-[10.3,11.3): 0.7093 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5897 - ca4-[11.3,14.9): 0.7103 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.8922 - val_ca1-[11.3,14.9): 1.5889 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.4132 - val_ca2-[10.3,11.3): 0.8582 - val_ca2-[11.3,14.9): 1.5197 - val_ca3-[8.0,9.5): 0.8281 - val_ca3-[9.5,10.3): 0.5366 - val_ca3-[10.3,11.3): 0.7100 - val_ca3-[11.3,14.9): 0.9521 - val_ca4-[8.0,9.5): 1.5681 - val_ca4-[9.5,10.3): 1.1389 - val_ca4-[10.3,11.3): 0.9770 - val_ca4-[11.3,14.9): 0.7038\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5166 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3588 - ca2-[9.5,10.3): 0.5173 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5315 - ca3-[10.3,11.3): 0.7307 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5750 - ca4-[11.3,14.9): 0.6989 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5736 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.4130 - val_ca2-[10.3,11.3): 0.8808 - val_ca2-[11.3,14.9): 1.5057 - val_ca3-[8.0,9.5): 0.8289 - val_ca3-[9.5,10.3): 0.5370 - val_ca3-[10.3,11.3): 0.7280 - val_ca3-[11.3,14.9): 0.9438 - val_ca4-[8.0,9.5): 1.5686 - val_ca4-[9.5,10.3): 1.1392 - val_ca4-[10.3,11.3): 0.9902 - val_ca4-[11.3,14.9): 0.7051\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5167 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3734 - ca2-[9.5,10.3): 0.5062 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5257 - ca3-[10.3,11.3): 0.7075 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5719 - ca4-[11.3,14.9): 0.7036 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9180 - val_ca1-[11.3,14.9): 1.5976 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.4127 - val_ca2-[10.3,11.3): 0.8820 - val_ca2-[11.3,14.9): 1.5269 - val_ca3-[8.0,9.5): 0.8286 - val_ca3-[9.5,10.3): 0.5365 - val_ca3-[10.3,11.3): 0.7268 - val_ca3-[11.3,14.9): 0.9587 - val_ca4-[8.0,9.5): 1.5692 - val_ca4-[9.5,10.3): 1.1397 - val_ca4-[10.3,11.3): 0.9859 - val_ca4-[11.3,14.9): 0.7092\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5231 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3637 - ca2-[9.5,10.3): 0.5072 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5600 - ca3-[10.3,11.3): 0.6994 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5645 - ca4-[11.3,14.9): 0.6879 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5713 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.4126 - val_ca2-[10.3,11.3): 0.8806 - val_ca2-[11.3,14.9): 1.5028 - val_ca3-[8.0,9.5): 0.8276 - val_ca3-[9.5,10.3): 0.5355 - val_ca3-[10.3,11.3): 0.7218 - val_ca3-[11.3,14.9): 0.9361 - val_ca4-[8.0,9.5): 1.5697 - val_ca4-[9.5,10.3): 1.1401 - val_ca4-[10.3,11.3): 0.9779 - val_ca4-[11.3,14.9): 0.6890\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5210 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3761 - ca2-[9.5,10.3): 0.5074 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5224 - ca3-[10.3,11.3): 0.7232 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5884 - ca4-[11.3,14.9): 0.7019 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9172 - val_ca1-[11.3,14.9): 1.5931 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.4123 - val_ca2-[10.3,11.3): 0.8814 - val_ca2-[11.3,14.9): 1.5234 - val_ca3-[8.0,9.5): 0.8265 - val_ca3-[9.5,10.3): 0.5344 - val_ca3-[10.3,11.3): 0.7267 - val_ca3-[11.3,14.9): 0.9522 - val_ca4-[8.0,9.5): 1.5696 - val_ca4-[9.5,10.3): 1.1400 - val_ca4-[10.3,11.3): 0.9877 - val_ca4-[11.3,14.9): 0.6957\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3678 - ca2-[9.5,10.3): 0.5137 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5349 - ca3-[10.3,11.3): 0.7283 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5630 - ca4-[11.3,14.9): 0.6808 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9160 - val_ca1-[11.3,14.9): 1.5707 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.4121 - val_ca2-[10.3,11.3): 0.8789 - val_ca2-[11.3,14.9): 1.4989 - val_ca3-[8.0,9.5): 0.8268 - val_ca3-[9.5,10.3): 0.5342 - val_ca3-[10.3,11.3): 0.7235 - val_ca3-[11.3,14.9): 0.9437 - val_ca4-[8.0,9.5): 1.5694 - val_ca4-[9.5,10.3): 1.1398 - val_ca4-[10.3,11.3): 0.9833 - val_ca4-[11.3,14.9): 0.7061\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5187 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3797 - ca2-[9.5,10.3): 0.5191 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5412 - ca3-[10.3,11.3): 0.7187 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5939 - ca4-[11.3,14.9): 0.6807 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9117 - val_ca1-[11.3,14.9): 1.5648 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.4125 - val_ca2-[10.3,11.3): 0.8751 - val_ca2-[11.3,14.9): 1.4955 - val_ca3-[8.0,9.5): 0.8292 - val_ca3-[9.5,10.3): 0.5373 - val_ca3-[10.3,11.3): 0.7218 - val_ca3-[11.3,14.9): 0.9384 - val_ca4-[8.0,9.5): 1.5696 - val_ca4-[9.5,10.3): 1.1432 - val_ca4-[10.3,11.3): 0.9853 - val_ca4-[11.3,14.9): 0.7054\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5162 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3563 - ca2-[9.5,10.3): 0.4992 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5238 - ca3-[10.3,11.3): 0.7026 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5702 - ca4-[11.3,14.9): 0.6821 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9101 - val_ca1-[11.3,14.9): 1.5634 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.4116 - val_ca2-[10.3,11.3): 0.8722 - val_ca2-[11.3,14.9): 1.4903 - val_ca3-[8.0,9.5): 0.8287 - val_ca3-[9.5,10.3): 0.5348 - val_ca3-[10.3,11.3): 0.7189 - val_ca3-[11.3,14.9): 0.9318 - val_ca4-[8.0,9.5): 1.5704 - val_ca4-[9.5,10.3): 1.1406 - val_ca4-[10.3,11.3): 0.9831 - val_ca4-[11.3,14.9): 0.6949\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5107 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3629 - ca2-[9.5,10.3): 0.5066 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5313 - ca3-[10.3,11.3): 0.7230 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5817 - ca4-[11.3,14.9): 0.7005 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9210 - val_ca1-[11.3,14.9): 1.6039 - val_ca2-[8.0,9.5): 0.5852 - val_ca2-[9.5,10.3): 0.4114 - val_ca2-[10.3,11.3): 0.8822 - val_ca2-[11.3,14.9): 1.5287 - val_ca3-[8.0,9.5): 0.8282 - val_ca3-[9.5,10.3): 0.5340 - val_ca3-[10.3,11.3): 0.7242 - val_ca3-[11.3,14.9): 0.9578 - val_ca4-[8.0,9.5): 1.5695 - val_ca4-[9.5,10.3): 1.1398 - val_ca4-[10.3,11.3): 0.9829 - val_ca4-[11.3,14.9): 0.7049\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5160 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3732 - ca2-[9.5,10.3): 0.5099 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5476 - ca3-[10.3,11.3): 0.7052 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5022 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5896 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.4111 - val_ca2-[10.3,11.3): 0.8774 - val_ca2-[11.3,14.9): 1.5140 - val_ca3-[8.0,9.5): 0.8287 - val_ca3-[9.5,10.3): 0.5339 - val_ca3-[10.3,11.3): 0.7214 - val_ca3-[11.3,14.9): 0.9565 - val_ca4-[8.0,9.5): 1.5698 - val_ca4-[9.5,10.3): 1.1400 - val_ca4-[10.3,11.3): 0.9834 - val_ca4-[11.3,14.9): 0.7206\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5285 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3579 - ca2-[9.5,10.3): 0.5110 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5384 - ca3-[10.3,11.3): 0.7294 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5655 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9110 - val_ca1-[11.3,14.9): 1.5768 - val_ca2-[8.0,9.5): 0.5846 - val_ca2-[9.5,10.3): 0.4109 - val_ca2-[10.3,11.3): 0.8721 - val_ca2-[11.3,14.9): 1.5034 - val_ca3-[8.0,9.5): 0.8273 - val_ca3-[9.5,10.3): 0.5323 - val_ca3-[10.3,11.3): 0.7099 - val_ca3-[11.3,14.9): 0.9425 - val_ca4-[8.0,9.5): 1.5693 - val_ca4-[9.5,10.3): 1.1396 - val_ca4-[10.3,11.3): 0.9658 - val_ca4-[11.3,14.9): 0.7020\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5263 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3547 - ca2-[9.5,10.3): 0.5045 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5444 - ca3-[10.3,11.3): 0.7203 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5627 - ca4-[11.3,14.9): 0.6908 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9103 - val_ca1-[11.3,14.9): 1.5730 - val_ca2-[8.0,9.5): 0.5842 - val_ca2-[9.5,10.3): 0.4106 - val_ca2-[10.3,11.3): 0.8712 - val_ca2-[11.3,14.9): 1.4981 - val_ca3-[8.0,9.5): 0.8273 - val_ca3-[9.5,10.3): 0.5317 - val_ca3-[10.3,11.3): 0.7158 - val_ca3-[11.3,14.9): 0.9380 - val_ca4-[8.0,9.5): 1.5694 - val_ca4-[9.5,10.3): 1.1396 - val_ca4-[10.3,11.3): 0.9824 - val_ca4-[11.3,14.9): 0.7002\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5052 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3772 - ca2-[9.5,10.3): 0.5084 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5193 - ca3-[10.3,11.3): 0.7187 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5425 - ca4-[11.3,14.9): 0.6953 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9069 - val_ca1-[11.3,14.9): 1.5856 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.4101 - val_ca2-[10.3,11.3): 0.8665 - val_ca2-[11.3,14.9): 1.5074 - val_ca3-[8.0,9.5): 0.8270 - val_ca3-[9.5,10.3): 0.5309 - val_ca3-[10.3,11.3): 0.7069 - val_ca3-[11.3,14.9): 0.9349 - val_ca4-[8.0,9.5): 1.5690 - val_ca4-[9.5,10.3): 1.1393 - val_ca4-[10.3,11.3): 0.9674 - val_ca4-[11.3,14.9): 0.6797\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5232 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3717 - ca2-[9.5,10.3): 0.5157 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5612 - ca3-[10.3,11.3): 0.7211 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5939 - ca4-[11.3,14.9): 0.6868 - val_ca1-[8.0,9.5): 0.5838 - val_ca1-[9.5,10.3): 0.4226 - val_ca1-[10.3,11.3): 0.9213 - val_ca1-[11.3,14.9): 1.5981 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.4109 - val_ca2-[10.3,11.3): 0.8789 - val_ca2-[11.3,14.9): 1.5184 - val_ca3-[8.0,9.5): 0.8279 - val_ca3-[9.5,10.3): 0.5303 - val_ca3-[10.3,11.3): 0.7202 - val_ca3-[11.3,14.9): 0.9582 - val_ca4-[8.0,9.5): 1.5726 - val_ca4-[9.5,10.3): 1.1394 - val_ca4-[10.3,11.3): 0.9822 - val_ca4-[11.3,14.9): 0.7116\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5157 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3633 - ca2-[9.5,10.3): 0.5122 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5346 - ca3-[10.3,11.3): 0.7027 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5874 - ca4-[11.3,14.9): 0.6973 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4149 - val_ca1-[10.3,11.3): 0.8883 - val_ca1-[11.3,14.9): 1.5830 - val_ca2-[8.0,9.5): 0.5834 - val_ca2-[9.5,10.3): 0.4028 - val_ca2-[10.3,11.3): 0.8480 - val_ca2-[11.3,14.9): 1.5067 - val_ca3-[8.0,9.5): 0.8261 - val_ca3-[9.5,10.3): 0.5263 - val_ca3-[10.3,11.3): 0.7002 - val_ca3-[11.3,14.9): 0.9387 - val_ca4-[8.0,9.5): 1.5677 - val_ca4-[9.5,10.3): 1.1407 - val_ca4-[10.3,11.3): 0.9783 - val_ca4-[11.3,14.9): 0.6885\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5147 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3645 - ca2-[9.5,10.3): 0.5025 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5267 - ca3-[10.3,11.3): 0.6983 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5633 - ca4-[11.3,14.9): 0.6750 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9125 - val_ca1-[11.3,14.9): 1.5572 - val_ca2-[8.0,9.5): 0.5826 - val_ca2-[9.5,10.3): 0.4089 - val_ca2-[10.3,11.3): 0.8723 - val_ca2-[11.3,14.9): 1.4846 - val_ca3-[8.0,9.5): 0.8270 - val_ca3-[9.5,10.3): 0.5289 - val_ca3-[10.3,11.3): 0.7146 - val_ca3-[11.3,14.9): 0.9296 - val_ca4-[8.0,9.5): 1.5665 - val_ca4-[9.5,10.3): 1.1371 - val_ca4-[10.3,11.3): 0.9835 - val_ca4-[11.3,14.9): 0.7054\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5063 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3577 - ca2-[9.5,10.3): 0.4995 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5203 - ca3-[10.3,11.3): 0.7020 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5278 - ca4-[11.3,14.9): 0.6943 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5970 - val_ca2-[8.0,9.5): 0.5816 - val_ca2-[9.5,10.3): 0.4083 - val_ca2-[10.3,11.3): 0.8772 - val_ca2-[11.3,14.9): 1.5274 - val_ca3-[8.0,9.5): 0.8281 - val_ca3-[9.5,10.3): 0.5289 - val_ca3-[10.3,11.3): 0.7150 - val_ca3-[11.3,14.9): 0.9517 - val_ca4-[8.0,9.5): 1.5647 - val_ca4-[9.5,10.3): 1.1355 - val_ca4-[10.3,11.3): 0.9807 - val_ca4-[11.3,14.9): 0.7097\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5130 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3657 - ca2-[9.5,10.3): 0.5106 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4998 - ca3-[10.3,11.3): 0.7076 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5887 - ca4-[11.3,14.9): 0.7035 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9167 - val_ca1-[11.3,14.9): 1.5696 - val_ca2-[8.0,9.5): 0.5808 - val_ca2-[9.5,10.3): 0.4075 - val_ca2-[10.3,11.3): 0.8765 - val_ca2-[11.3,14.9): 1.5021 - val_ca3-[8.0,9.5): 0.8287 - val_ca3-[9.5,10.3): 0.5285 - val_ca3-[10.3,11.3): 0.7139 - val_ca3-[11.3,14.9): 0.9382 - val_ca4-[8.0,9.5): 1.5628 - val_ca4-[9.5,10.3): 1.1338 - val_ca4-[10.3,11.3): 0.9797 - val_ca4-[11.3,14.9): 0.7125\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5270 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3731 - ca2-[9.5,10.3): 0.4950 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5293 - ca3-[10.3,11.3): 0.7071 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5769 - ca4-[11.3,14.9): 0.6938 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9148 - val_ca1-[11.3,14.9): 1.5775 - val_ca2-[8.0,9.5): 0.5796 - val_ca2-[9.5,10.3): 0.4071 - val_ca2-[10.3,11.3): 0.8761 - val_ca2-[11.3,14.9): 1.5133 - val_ca3-[8.0,9.5): 0.8282 - val_ca3-[9.5,10.3): 0.5270 - val_ca3-[10.3,11.3): 0.7059 - val_ca3-[11.3,14.9): 0.9370 - val_ca4-[8.0,9.5): 1.5613 - val_ca4-[9.5,10.3): 1.1326 - val_ca4-[10.3,11.3): 0.9667 - val_ca4-[11.3,14.9): 0.7036\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3621 - ca2-[9.5,10.3): 0.4916 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5214 - ca3-[10.3,11.3): 0.6981 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5122 - ca4-[11.3,14.9): 0.6891 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9059 - val_ca1-[11.3,14.9): 1.5831 - val_ca2-[8.0,9.5): 0.5791 - val_ca2-[9.5,10.3): 0.4063 - val_ca2-[10.3,11.3): 0.8679 - val_ca2-[11.3,14.9): 1.5189 - val_ca3-[8.0,9.5): 0.8254 - val_ca3-[9.5,10.3): 0.5238 - val_ca3-[10.3,11.3): 0.7003 - val_ca3-[11.3,14.9): 0.9385 - val_ca4-[8.0,9.5): 1.5615 - val_ca4-[9.5,10.3): 1.1327 - val_ca4-[10.3,11.3): 0.9635 - val_ca4-[11.3,14.9): 0.6911\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5297 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3613 - ca2-[9.5,10.3): 0.5061 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5173 - ca3-[10.3,11.3): 0.6958 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5741 - ca4-[11.3,14.9): 0.6803 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9162 - val_ca1-[11.3,14.9): 1.6022 - val_ca2-[8.0,9.5): 0.5786 - val_ca2-[9.5,10.3): 0.4055 - val_ca2-[10.3,11.3): 0.8763 - val_ca2-[11.3,14.9): 1.5363 - val_ca3-[8.0,9.5): 0.8242 - val_ca3-[9.5,10.3): 0.5214 - val_ca3-[10.3,11.3): 0.7088 - val_ca3-[11.3,14.9): 0.9542 - val_ca4-[8.0,9.5): 1.5616 - val_ca4-[9.5,10.3): 1.1327 - val_ca4-[10.3,11.3): 0.9790 - val_ca4-[11.3,14.9): 0.7105\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5240 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3435 - ca2-[9.5,10.3): 0.5006 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5497 - ca3-[10.3,11.3): 0.7048 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5908 - ca4-[11.3,14.9): 0.6960 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9115 - val_ca1-[11.3,14.9): 1.5708 - val_ca2-[8.0,9.5): 0.5788 - val_ca2-[9.5,10.3): 0.4044 - val_ca2-[10.3,11.3): 0.8686 - val_ca2-[11.3,14.9): 1.5004 - val_ca3-[8.0,9.5): 0.8179 - val_ca3-[9.5,10.3): 0.5148 - val_ca3-[10.3,11.3): 0.7057 - val_ca3-[11.3,14.9): 0.9434 - val_ca4-[8.0,9.5): 1.5623 - val_ca4-[9.5,10.3): 1.1333 - val_ca4-[10.3,11.3): 0.9812 - val_ca4-[11.3,14.9): 0.7113\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3569 - ca2-[9.5,10.3): 0.4962 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5178 - ca3-[10.3,11.3): 0.6829 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5469 - ca4-[11.3,14.9): 0.6896 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9118 - val_ca1-[11.3,14.9): 1.6023 - val_ca2-[8.0,9.5): 0.5783 - val_ca2-[9.5,10.3): 0.4036 - val_ca2-[10.3,11.3): 0.8679 - val_ca2-[11.3,14.9): 1.5287 - val_ca3-[8.0,9.5): 0.8248 - val_ca3-[9.5,10.3): 0.5192 - val_ca3-[10.3,11.3): 0.7026 - val_ca3-[11.3,14.9): 0.9488 - val_ca4-[8.0,9.5): 1.5631 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9760 - val_ca4-[11.3,14.9): 0.7046\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5308 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3643 - ca2-[9.5,10.3): 0.4924 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5119 - ca3-[10.3,11.3): 0.6627 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5809 - ca4-[11.3,14.9): 0.6983 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9097 - val_ca1-[11.3,14.9): 1.5821 - val_ca2-[8.0,9.5): 0.5775 - val_ca2-[9.5,10.3): 0.4032 - val_ca2-[10.3,11.3): 0.8661 - val_ca2-[11.3,14.9): 1.5129 - val_ca3-[8.0,9.5): 0.8243 - val_ca3-[9.5,10.3): 0.5174 - val_ca3-[10.3,11.3): 0.7005 - val_ca3-[11.3,14.9): 0.9390 - val_ca4-[8.0,9.5): 1.5630 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9789 - val_ca4-[11.3,14.9): 0.7081\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5183 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3493 - ca2-[9.5,10.3): 0.4896 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5155 - ca3-[10.3,11.3): 0.6763 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5746 - ca4-[11.3,14.9): 0.6911 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9113 - val_ca1-[11.3,14.9): 1.6013 - val_ca2-[8.0,9.5): 0.5768 - val_ca2-[9.5,10.3): 0.4026 - val_ca2-[10.3,11.3): 0.8677 - val_ca2-[11.3,14.9): 1.5315 - val_ca3-[8.0,9.5): 0.8180 - val_ca3-[9.5,10.3): 0.5110 - val_ca3-[10.3,11.3): 0.7009 - val_ca3-[11.3,14.9): 0.9601 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1344 - val_ca4-[10.3,11.3): 0.9819 - val_ca4-[11.3,14.9): 0.7161\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5190 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3483 - ca2-[9.5,10.3): 0.4812 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5018 - ca3-[10.3,11.3): 0.7101 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5529 - ca4-[11.3,14.9): 0.6923 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5529 - val_ca2-[8.0,9.5): 0.5764 - val_ca2-[9.5,10.3): 0.4019 - val_ca2-[10.3,11.3): 0.8662 - val_ca2-[11.3,14.9): 1.4853 - val_ca3-[8.0,9.5): 0.8236 - val_ca3-[9.5,10.3): 0.5147 - val_ca3-[10.3,11.3): 0.6951 - val_ca3-[11.3,14.9): 0.9223 - val_ca4-[8.0,9.5): 1.5644 - val_ca4-[9.5,10.3): 1.1350 - val_ca4-[10.3,11.3): 0.9736 - val_ca4-[11.3,14.9): 0.7022\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5210 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3541 - ca2-[9.5,10.3): 0.4754 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4970 - ca3-[10.3,11.3): 0.6725 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6039 - ca4-[11.3,14.9): 0.6875 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9140 - val_ca1-[11.3,14.9): 1.5822 - val_ca2-[8.0,9.5): 0.5755 - val_ca2-[9.5,10.3): 0.4018 - val_ca2-[10.3,11.3): 0.8697 - val_ca2-[11.3,14.9): 1.5169 - val_ca3-[8.0,9.5): 0.8211 - val_ca3-[9.5,10.3): 0.5107 - val_ca3-[10.3,11.3): 0.6967 - val_ca3-[11.3,14.9): 0.9365 - val_ca4-[8.0,9.5): 1.5637 - val_ca4-[9.5,10.3): 1.1343 - val_ca4-[10.3,11.3): 0.9773 - val_ca4-[11.3,14.9): 0.6967\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5186 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3569 - ca2-[9.5,10.3): 0.4866 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4808 - ca3-[10.3,11.3): 0.6848 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5146 - ca4-[11.3,14.9): 0.6963 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5895 - val_ca2-[8.0,9.5): 0.5762 - val_ca2-[9.5,10.3): 0.4014 - val_ca2-[10.3,11.3): 0.8653 - val_ca2-[11.3,14.9): 1.5100 - val_ca3-[8.0,9.5): 0.8160 - val_ca3-[9.5,10.3): 0.5065 - val_ca3-[10.3,11.3): 0.6983 - val_ca3-[11.3,14.9): 0.9499 - val_ca4-[8.0,9.5): 1.5639 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9845 - val_ca4-[11.3,14.9): 0.7104\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5127 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3569 - ca2-[9.5,10.3): 0.4881 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5072 - ca3-[10.3,11.3): 0.6762 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5756 - ca4-[11.3,14.9): 0.7041 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9133 - val_ca1-[11.3,14.9): 1.5641 - val_ca2-[8.0,9.5): 0.5754 - val_ca2-[9.5,10.3): 0.4009 - val_ca2-[10.3,11.3): 0.8684 - val_ca2-[11.3,14.9): 1.4972 - val_ca3-[8.0,9.5): 0.8228 - val_ca3-[9.5,10.3): 0.5097 - val_ca3-[10.3,11.3): 0.6977 - val_ca3-[11.3,14.9): 0.9293 - val_ca4-[8.0,9.5): 1.5643 - val_ca4-[9.5,10.3): 1.1347 - val_ca4-[10.3,11.3): 0.9846 - val_ca4-[11.3,14.9): 0.7046\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5102 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3599 - ca2-[9.5,10.3): 0.4865 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5146 - ca3-[10.3,11.3): 0.6965 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5669 - ca4-[11.3,14.9): 0.6842 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9158 - val_ca1-[11.3,14.9): 1.5796 - val_ca2-[8.0,9.5): 0.5756 - val_ca2-[9.5,10.3): 0.4013 - val_ca2-[10.3,11.3): 0.8681 - val_ca2-[11.3,14.9): 1.5096 - val_ca3-[8.0,9.5): 0.8253 - val_ca3-[9.5,10.3): 0.5119 - val_ca3-[10.3,11.3): 0.6956 - val_ca3-[11.3,14.9): 0.9338 - val_ca4-[8.0,9.5): 1.5636 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9797 - val_ca4-[11.3,14.9): 0.7050\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5283 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3516 - ca2-[9.5,10.3): 0.4802 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5471 - ca3-[10.3,11.3): 0.6778 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5445 - ca4-[11.3,14.9): 0.6852 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9110 - val_ca1-[11.3,14.9): 1.5609 - val_ca2-[8.0,9.5): 0.5756 - val_ca2-[9.5,10.3): 0.4006 - val_ca2-[10.3,11.3): 0.8648 - val_ca2-[11.3,14.9): 1.4928 - val_ca3-[8.0,9.5): 0.8282 - val_ca3-[9.5,10.3): 0.5108 - val_ca3-[10.3,11.3): 0.6936 - val_ca3-[11.3,14.9): 0.9206 - val_ca4-[8.0,9.5): 1.5624 - val_ca4-[9.5,10.3): 1.1330 - val_ca4-[10.3,11.3): 0.9810 - val_ca4-[11.3,14.9): 0.6999\n",
      "Epoch 193/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5101 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3506 - ca2-[9.5,10.3): 0.4979 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5001 - ca3-[10.3,11.3): 0.6771 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5251 - ca4-[11.3,14.9): 0.7011 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9064 - val_ca1-[11.3,14.9): 1.5792 - val_ca2-[8.0,9.5): 0.5767 - val_ca2-[9.5,10.3): 0.4007 - val_ca2-[10.3,11.3): 0.8576 - val_ca2-[11.3,14.9): 1.5045 - val_ca3-[8.0,9.5): 0.8319 - val_ca3-[9.5,10.3): 0.5118 - val_ca3-[10.3,11.3): 0.6919 - val_ca3-[11.3,14.9): 0.9292 - val_ca4-[8.0,9.5): 1.5621 - val_ca4-[9.5,10.3): 1.1301 - val_ca4-[10.3,11.3): 0.9827 - val_ca4-[11.3,14.9): 0.7049\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5261 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3539 - ca2-[9.5,10.3): 0.4873 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5042 - ca3-[10.3,11.3): 0.6866 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5576 - ca4-[11.3,14.9): 0.6995 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9139 - val_ca1-[11.3,14.9): 1.5682 - val_ca2-[8.0,9.5): 0.5782 - val_ca2-[9.5,10.3): 0.3994 - val_ca2-[10.3,11.3): 0.8566 - val_ca2-[11.3,14.9): 1.4826 - val_ca3-[8.0,9.5): 0.8437 - val_ca3-[9.5,10.3): 0.5220 - val_ca3-[10.3,11.3): 0.6917 - val_ca3-[11.3,14.9): 0.9068 - val_ca4-[8.0,9.5): 1.5627 - val_ca4-[9.5,10.3): 1.1332 - val_ca4-[10.3,11.3): 0.9766 - val_ca4-[11.3,14.9): 0.7007\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5115 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3512 - ca2-[9.5,10.3): 0.4953 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5165 - ca3-[10.3,11.3): 0.6645 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5740 - ca4-[11.3,14.9): 0.6978 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9115 - val_ca1-[11.3,14.9): 1.5579 - val_ca2-[8.0,9.5): 0.5788 - val_ca2-[9.5,10.3): 0.3993 - val_ca2-[10.3,11.3): 0.8547 - val_ca2-[11.3,14.9): 1.4751 - val_ca3-[8.0,9.5): 0.8289 - val_ca3-[9.5,10.3): 0.5056 - val_ca3-[10.3,11.3): 0.6918 - val_ca3-[11.3,14.9): 0.9271 - val_ca4-[8.0,9.5): 1.5630 - val_ca4-[9.5,10.3): 1.1334 - val_ca4-[10.3,11.3): 0.9812 - val_ca4-[11.3,14.9): 0.6982\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5162 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3492 - ca2-[9.5,10.3): 0.4695 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5064 - ca3-[10.3,11.3): 0.6747 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5418 - ca4-[11.3,14.9): 0.6604 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9118 - val_ca1-[11.3,14.9): 1.5692 - val_ca2-[8.0,9.5): 0.5794 - val_ca2-[9.5,10.3): 0.3994 - val_ca2-[10.3,11.3): 0.8545 - val_ca2-[11.3,14.9): 1.4865 - val_ca3-[8.0,9.5): 0.8407 - val_ca3-[9.5,10.3): 0.5143 - val_ca3-[10.3,11.3): 0.6902 - val_ca3-[11.3,14.9): 0.9209 - val_ca4-[8.0,9.5): 1.5637 - val_ca4-[9.5,10.3): 1.1340 - val_ca4-[10.3,11.3): 0.9815 - val_ca4-[11.3,14.9): 0.7063\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5201 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3486 - ca2-[9.5,10.3): 0.4737 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5206 - ca3-[10.3,11.3): 0.6754 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5776 - ca4-[11.3,14.9): 0.6857 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5983 - val_ca2-[8.0,9.5): 0.5797 - val_ca2-[9.5,10.3): 0.3998 - val_ca2-[10.3,11.3): 0.8568 - val_ca2-[11.3,14.9): 1.5085 - val_ca3-[8.0,9.5): 0.8525 - val_ca3-[9.5,10.3): 0.5227 - val_ca3-[10.3,11.3): 0.6907 - val_ca3-[11.3,14.9): 0.9175 - val_ca4-[8.0,9.5): 1.5640 - val_ca4-[9.5,10.3): 1.1342 - val_ca4-[10.3,11.3): 0.9842 - val_ca4-[11.3,14.9): 0.7024\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5217 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3488 - ca2-[9.5,10.3): 0.4871 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4791 - ca3-[10.3,11.3): 0.6586 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5516 - ca4-[11.3,14.9): 0.7032 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9164 - val_ca1-[11.3,14.9): 1.5899 - val_ca2-[8.0,9.5): 0.5821 - val_ca2-[9.5,10.3): 0.3987 - val_ca2-[10.3,11.3): 0.8484 - val_ca2-[11.3,14.9): 1.4703 - val_ca3-[8.0,9.5): 0.8489 - val_ca3-[9.5,10.3): 0.5167 - val_ca3-[10.3,11.3): 0.6883 - val_ca3-[11.3,14.9): 0.9107 - val_ca4-[8.0,9.5): 1.5632 - val_ca4-[9.5,10.3): 1.1334 - val_ca4-[10.3,11.3): 0.9793 - val_ca4-[11.3,14.9): 0.6968\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3561 - ca2-[9.5,10.3): 0.4869 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4818 - ca3-[10.3,11.3): 0.6595 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5709 - ca4-[11.3,14.9): 0.6856 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.5686 - val_ca2-[8.0,9.5): 0.5806 - val_ca2-[9.5,10.3): 0.4012 - val_ca2-[10.3,11.3): 0.8560 - val_ca2-[11.3,14.9): 1.4756 - val_ca3-[8.0,9.5): 0.8532 - val_ca3-[9.5,10.3): 0.5215 - val_ca3-[10.3,11.3): 0.6853 - val_ca3-[11.3,14.9): 0.8994 - val_ca4-[8.0,9.5): 1.5634 - val_ca4-[9.5,10.3): 1.1369 - val_ca4-[10.3,11.3): 0.9738 - val_ca4-[11.3,14.9): 0.7033\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5222 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3615 - ca2-[9.5,10.3): 0.4895 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5139 - ca3-[10.3,11.3): 0.6613 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5847 - ca4-[11.3,14.9): 0.6870 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.6026 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3986 - val_ca2-[10.3,11.3): 0.8430 - val_ca2-[11.3,14.9): 1.4864 - val_ca3-[8.0,9.5): 0.8546 - val_ca3-[9.5,10.3): 0.5194 - val_ca3-[10.3,11.3): 0.6855 - val_ca3-[11.3,14.9): 0.9269 - val_ca4-[8.0,9.5): 1.5627 - val_ca4-[9.5,10.3): 1.1330 - val_ca4-[10.3,11.3): 0.9764 - val_ca4-[11.3,14.9): 0.7154\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5168 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3550 - ca2-[9.5,10.3): 0.4772 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5068 - ca3-[10.3,11.3): 0.6593 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5702 - ca4-[11.3,14.9): 0.6743 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9093 - val_ca1-[11.3,14.9): 1.5680 - val_ca2-[8.0,9.5): 0.5833 - val_ca2-[9.5,10.3): 0.3992 - val_ca2-[10.3,11.3): 0.8422 - val_ca2-[11.3,14.9): 1.4642 - val_ca3-[8.0,9.5): 0.8699 - val_ca3-[9.5,10.3): 0.5315 - val_ca3-[10.3,11.3): 0.6838 - val_ca3-[11.3,14.9): 0.8907 - val_ca4-[8.0,9.5): 1.5635 - val_ca4-[9.5,10.3): 1.1336 - val_ca4-[10.3,11.3): 0.9787 - val_ca4-[11.3,14.9): 0.7062\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5060 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3606 - ca2-[9.5,10.3): 0.4748 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5147 - ca3-[10.3,11.3): 0.6435 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5862 - ca4-[11.3,14.9): 0.6914 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5846 - val_ca2-[8.0,9.5): 0.5825 - val_ca2-[9.5,10.3): 0.4003 - val_ca2-[10.3,11.3): 0.8538 - val_ca2-[11.3,14.9): 1.4872 - val_ca3-[8.0,9.5): 0.8552 - val_ca3-[9.5,10.3): 0.5169 - val_ca3-[10.3,11.3): 0.6845 - val_ca3-[11.3,14.9): 0.9103 - val_ca4-[8.0,9.5): 1.5652 - val_ca4-[9.5,10.3): 1.1351 - val_ca4-[10.3,11.3): 0.9802 - val_ca4-[11.3,14.9): 0.7066\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5245 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3490 - ca2-[9.5,10.3): 0.4771 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4987 - ca3-[10.3,11.3): 0.6677 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5663 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9104 - val_ca1-[11.3,14.9): 1.5895 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3986 - val_ca2-[10.3,11.3): 0.8412 - val_ca2-[11.3,14.9): 1.4751 - val_ca3-[8.0,9.5): 0.8635 - val_ca3-[9.5,10.3): 0.5240 - val_ca3-[10.3,11.3): 0.6787 - val_ca3-[11.3,14.9): 0.9058 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1356 - val_ca4-[10.3,11.3): 0.9632 - val_ca4-[11.3,14.9): 0.6913\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5232 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3634 - ca2-[9.5,10.3): 0.4760 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5118 - ca3-[10.3,11.3): 0.6653 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5931 - ca4-[11.3,14.9): 0.6866 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9101 - val_ca1-[11.3,14.9): 1.5755 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3975 - val_ca2-[10.3,11.3): 0.8330 - val_ca2-[11.3,14.9): 1.4362 - val_ca3-[8.0,9.5): 0.8690 - val_ca3-[9.5,10.3): 0.5280 - val_ca3-[10.3,11.3): 0.6779 - val_ca3-[11.3,14.9): 0.8864 - val_ca4-[8.0,9.5): 1.5681 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9643 - val_ca4-[11.3,14.9): 0.6896\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5108 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3590 - ca2-[9.5,10.3): 0.4796 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5177 - ca3-[10.3,11.3): 0.6708 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5893 - ca4-[11.3,14.9): 0.7008 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9142 - val_ca1-[11.3,14.9): 1.5429 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.3998 - val_ca2-[10.3,11.3): 0.8469 - val_ca2-[11.3,14.9): 1.4388 - val_ca3-[8.0,9.5): 0.8601 - val_ca3-[9.5,10.3): 0.5200 - val_ca3-[10.3,11.3): 0.6828 - val_ca3-[11.3,14.9): 0.8707 - val_ca4-[8.0,9.5): 1.5690 - val_ca4-[9.5,10.3): 1.1382 - val_ca4-[10.3,11.3): 0.9794 - val_ca4-[11.3,14.9): 0.6802\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.4981 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3724 - ca2-[9.5,10.3): 0.4806 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5259 - ca3-[10.3,11.3): 0.6517 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5698 - ca4-[11.3,14.9): 0.6926 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9096 - val_ca1-[11.3,14.9): 1.6019 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3983 - val_ca2-[10.3,11.3): 0.8353 - val_ca2-[11.3,14.9): 1.4709 - val_ca3-[8.0,9.5): 0.8633 - val_ca3-[9.5,10.3): 0.5211 - val_ca3-[10.3,11.3): 0.6803 - val_ca3-[11.3,14.9): 0.9182 - val_ca4-[8.0,9.5): 1.5694 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9815 - val_ca4-[11.3,14.9): 0.7154\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5266 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3555 - ca2-[9.5,10.3): 0.4794 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5093 - ca3-[10.3,11.3): 0.6520 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5633 - ca4-[11.3,14.9): 0.6817 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9051 - val_ca1-[11.3,14.9): 1.6027 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3984 - val_ca2-[10.3,11.3): 0.8351 - val_ca2-[11.3,14.9): 1.4822 - val_ca3-[8.0,9.5): 0.8737 - val_ca3-[9.5,10.3): 0.5276 - val_ca3-[10.3,11.3): 0.6780 - val_ca3-[11.3,14.9): 0.9064 - val_ca4-[8.0,9.5): 1.5686 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9734 - val_ca4-[11.3,14.9): 0.7039\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5265 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3513 - ca2-[9.5,10.3): 0.4779 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5036 - ca3-[10.3,11.3): 0.6679 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5932 - ca4-[11.3,14.9): 0.6814 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.5428 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3986 - val_ca2-[10.3,11.3): 0.8416 - val_ca2-[11.3,14.9): 1.4306 - val_ca3-[8.0,9.5): 0.8744 - val_ca3-[9.5,10.3): 0.5279 - val_ca3-[10.3,11.3): 0.6781 - val_ca3-[11.3,14.9): 0.8674 - val_ca4-[8.0,9.5): 1.5692 - val_ca4-[9.5,10.3): 1.1383 - val_ca4-[10.3,11.3): 0.9794 - val_ca4-[11.3,14.9): 0.6975\n",
      "Epoch 209/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5181 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3521 - ca2-[9.5,10.3): 0.4810 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5140 - ca3-[10.3,11.3): 0.6525 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5845 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9170 - val_ca1-[11.3,14.9): 1.5972 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.3983 - val_ca2-[10.3,11.3): 0.8428 - val_ca2-[11.3,14.9): 1.4780 - val_ca3-[8.0,9.5): 0.8701 - val_ca3-[9.5,10.3): 0.5244 - val_ca3-[10.3,11.3): 0.6807 - val_ca3-[11.3,14.9): 0.9091 - val_ca4-[8.0,9.5): 1.5679 - val_ca4-[9.5,10.3): 1.1371 - val_ca4-[10.3,11.3): 0.9813 - val_ca4-[11.3,14.9): 0.7144\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5267 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3599 - ca2-[9.5,10.3): 0.4751 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5238 - ca3-[10.3,11.3): 0.6653 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5526 - ca4-[11.3,14.9): 0.6884 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9101 - val_ca1-[11.3,14.9): 1.5525 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3981 - val_ca2-[10.3,11.3): 0.8352 - val_ca2-[11.3,14.9): 1.4371 - val_ca3-[8.0,9.5): 0.8826 - val_ca3-[9.5,10.3): 0.5346 - val_ca3-[10.3,11.3): 0.6778 - val_ca3-[11.3,14.9): 0.8675 - val_ca4-[8.0,9.5): 1.5666 - val_ca4-[9.5,10.3): 1.1360 - val_ca4-[10.3,11.3): 0.9800 - val_ca4-[11.3,14.9): 0.6970\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5159 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3584 - ca2-[9.5,10.3): 0.4785 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4972 - ca3-[10.3,11.3): 0.6442 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5761 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9121 - val_ca1-[11.3,14.9): 1.5862 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.3982 - val_ca2-[10.3,11.3): 0.8367 - val_ca2-[11.3,14.9): 1.4664 - val_ca3-[8.0,9.5): 0.8741 - val_ca3-[9.5,10.3): 0.5257 - val_ca3-[10.3,11.3): 0.6777 - val_ca3-[11.3,14.9): 0.8933 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1358 - val_ca4-[10.3,11.3): 0.9770 - val_ca4-[11.3,14.9): 0.6836\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5162 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3567 - ca2-[9.5,10.3): 0.4846 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5219 - ca3-[10.3,11.3): 0.6518 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5442 - ca4-[11.3,14.9): 0.7060 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5730 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3988 - val_ca2-[10.3,11.3): 0.8408 - val_ca2-[11.3,14.9): 1.4538 - val_ca3-[8.0,9.5): 0.8733 - val_ca3-[9.5,10.3): 0.5240 - val_ca3-[10.3,11.3): 0.6783 - val_ca3-[11.3,14.9): 0.8900 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1357 - val_ca4-[10.3,11.3): 0.9805 - val_ca4-[11.3,14.9): 0.6990\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5117 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3591 - ca2-[9.5,10.3): 0.4678 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5293 - ca3-[10.3,11.3): 0.6441 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5980 - ca4-[11.3,14.9): 0.7025 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9069 - val_ca1-[11.3,14.9): 1.5803 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3982 - val_ca2-[10.3,11.3): 0.8325 - val_ca2-[11.3,14.9): 1.4470 - val_ca3-[8.0,9.5): 0.8719 - val_ca3-[9.5,10.3): 0.5217 - val_ca3-[10.3,11.3): 0.6734 - val_ca3-[11.3,14.9): 0.8938 - val_ca4-[8.0,9.5): 1.5650 - val_ca4-[9.5,10.3): 1.1345 - val_ca4-[10.3,11.3): 0.9644 - val_ca4-[11.3,14.9): 0.7055\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5200 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3587 - ca2-[9.5,10.3): 0.4770 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5153 - ca3-[10.3,11.3): 0.6411 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5608 - ca4-[11.3,14.9): 0.6908 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.6040 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.3992 - val_ca2-[10.3,11.3): 0.8439 - val_ca2-[11.3,14.9): 1.4821 - val_ca3-[8.0,9.5): 0.8820 - val_ca3-[9.5,10.3): 0.5295 - val_ca3-[10.3,11.3): 0.6769 - val_ca3-[11.3,14.9): 0.8949 - val_ca4-[8.0,9.5): 1.5634 - val_ca4-[9.5,10.3): 1.1330 - val_ca4-[10.3,11.3): 0.9789 - val_ca4-[11.3,14.9): 0.7152\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5144 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3597 - ca2-[9.5,10.3): 0.4660 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5195 - ca3-[10.3,11.3): 0.6463 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5754 - ca4-[11.3,14.9): 0.7021 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9102 - val_ca1-[11.3,14.9): 1.6035 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.3987 - val_ca2-[10.3,11.3): 0.8362 - val_ca2-[11.3,14.9): 1.4756 - val_ca3-[8.0,9.5): 0.8871 - val_ca3-[9.5,10.3): 0.5332 - val_ca3-[10.3,11.3): 0.6736 - val_ca3-[11.3,14.9): 0.8896 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1334 - val_ca4-[10.3,11.3): 0.9784 - val_ca4-[11.3,14.9): 0.7097\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5132 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3538 - ca2-[9.5,10.3): 0.4685 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5135 - ca3-[10.3,11.3): 0.6343 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5801 - ca4-[11.3,14.9): 0.6870 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9141 - val_ca1-[11.3,14.9): 1.6077 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.3979 - val_ca2-[10.3,11.3): 0.8371 - val_ca2-[11.3,14.9): 1.4790 - val_ca3-[8.0,9.5): 0.8796 - val_ca3-[9.5,10.3): 0.5264 - val_ca3-[10.3,11.3): 0.6756 - val_ca3-[11.3,14.9): 0.9037 - val_ca4-[8.0,9.5): 1.5637 - val_ca4-[9.5,10.3): 1.1333 - val_ca4-[10.3,11.3): 0.9779 - val_ca4-[11.3,14.9): 0.7130\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5298 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3567 - ca2-[9.5,10.3): 0.4726 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4989 - ca3-[10.3,11.3): 0.6480 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5503 - ca4-[11.3,14.9): 0.6863 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9170 - val_ca1-[11.3,14.9): 1.5795 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.3987 - val_ca2-[10.3,11.3): 0.8416 - val_ca2-[11.3,14.9): 1.4542 - val_ca3-[8.0,9.5): 0.8845 - val_ca3-[9.5,10.3): 0.5293 - val_ca3-[10.3,11.3): 0.6725 - val_ca3-[11.3,14.9): 0.8659 - val_ca4-[8.0,9.5): 1.5637 - val_ca4-[9.5,10.3): 1.1332 - val_ca4-[10.3,11.3): 0.9735 - val_ca4-[11.3,14.9): 0.6995\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5203 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3508 - ca2-[9.5,10.3): 0.4816 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5106 - ca3-[10.3,11.3): 0.6328 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5774 - ca4-[11.3,14.9): 0.6914 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9147 - val_ca1-[11.3,14.9): 1.5837 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3978 - val_ca2-[10.3,11.3): 0.8337 - val_ca2-[11.3,14.9): 1.4534 - val_ca3-[8.0,9.5): 0.8891 - val_ca3-[9.5,10.3): 0.5319 - val_ca3-[10.3,11.3): 0.6705 - val_ca3-[11.3,14.9): 0.8733 - val_ca4-[8.0,9.5): 1.5619 - val_ca4-[9.5,10.3): 1.1317 - val_ca4-[10.3,11.3): 0.9754 - val_ca4-[11.3,14.9): 0.6958\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5184 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3535 - ca2-[9.5,10.3): 0.4605 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5464 - ca3-[10.3,11.3): 0.6353 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5101 - ca4-[11.3,14.9): 0.6823 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9147 - val_ca1-[11.3,14.9): 1.5572 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3992 - val_ca2-[10.3,11.3): 0.8426 - val_ca2-[11.3,14.9): 1.4423 - val_ca3-[8.0,9.5): 0.8856 - val_ca3-[9.5,10.3): 0.5284 - val_ca3-[10.3,11.3): 0.6706 - val_ca3-[11.3,14.9): 0.8583 - val_ca4-[8.0,9.5): 1.5614 - val_ca4-[9.5,10.3): 1.1312 - val_ca4-[10.3,11.3): 0.9751 - val_ca4-[11.3,14.9): 0.6870\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5162 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3663 - ca2-[9.5,10.3): 0.4695 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5172 - ca3-[10.3,11.3): 0.6403 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5801 - ca4-[11.3,14.9): 0.6772 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9119 - val_ca1-[11.3,14.9): 1.5633 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3970 - val_ca2-[10.3,11.3): 0.8318 - val_ca2-[11.3,14.9): 1.4355 - val_ca3-[8.0,9.5): 0.8826 - val_ca3-[9.5,10.3): 0.5257 - val_ca3-[10.3,11.3): 0.6718 - val_ca3-[11.3,14.9): 0.8721 - val_ca4-[8.0,9.5): 1.5618 - val_ca4-[9.5,10.3): 1.1315 - val_ca4-[10.3,11.3): 0.9798 - val_ca4-[11.3,14.9): 0.6935\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5097 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3447 - ca2-[9.5,10.3): 0.4660 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5001 - ca3-[10.3,11.3): 0.6430 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5691 - ca4-[11.3,14.9): 0.6985 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9072 - val_ca1-[11.3,14.9): 1.5894 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3969 - val_ca2-[10.3,11.3): 0.8296 - val_ca2-[11.3,14.9): 1.4658 - val_ca3-[8.0,9.5): 0.8752 - val_ca3-[9.5,10.3): 0.5198 - val_ca3-[10.3,11.3): 0.6723 - val_ca3-[11.3,14.9): 0.9005 - val_ca4-[8.0,9.5): 1.5627 - val_ca4-[9.5,10.3): 1.1322 - val_ca4-[10.3,11.3): 0.9821 - val_ca4-[11.3,14.9): 0.7078\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5282 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3596 - ca2-[9.5,10.3): 0.4758 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5207 - ca3-[10.3,11.3): 0.6439 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5158 - ca4-[11.3,14.9): 0.6894 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9098 - val_ca1-[11.3,14.9): 1.5889 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.3979 - val_ca2-[10.3,11.3): 0.8347 - val_ca2-[11.3,14.9): 1.4704 - val_ca3-[8.0,9.5): 0.8977 - val_ca3-[9.5,10.3): 0.5370 - val_ca3-[10.3,11.3): 0.6677 - val_ca3-[11.3,14.9): 0.8681 - val_ca4-[8.0,9.5): 1.5643 - val_ca4-[9.5,10.3): 1.1336 - val_ca4-[10.3,11.3): 0.9783 - val_ca4-[11.3,14.9): 0.7133\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5189 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3494 - ca2-[9.5,10.3): 0.4680 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5178 - ca3-[10.3,11.3): 0.6207 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5320 - ca4-[11.3,14.9): 0.6788 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9116 - val_ca1-[11.3,14.9): 1.5559 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3975 - val_ca2-[10.3,11.3): 0.8350 - val_ca2-[11.3,14.9): 1.4494 - val_ca3-[8.0,9.5): 0.8745 - val_ca3-[9.5,10.3): 0.5188 - val_ca3-[10.3,11.3): 0.6719 - val_ca3-[11.3,14.9): 0.8866 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1349 - val_ca4-[10.3,11.3): 0.9817 - val_ca4-[11.3,14.9): 0.6927\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5159 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3668 - ca2-[9.5,10.3): 0.4782 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5007 - ca3-[10.3,11.3): 0.6422 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5537 - ca4-[11.3,14.9): 0.6994 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9095 - val_ca1-[11.3,14.9): 1.5627 - val_ca2-[8.0,9.5): 0.5895 - val_ca2-[9.5,10.3): 0.3962 - val_ca2-[10.3,11.3): 0.8245 - val_ca2-[11.3,14.9): 1.4261 - val_ca3-[8.0,9.5): 0.8932 - val_ca3-[9.5,10.3): 0.5319 - val_ca3-[10.3,11.3): 0.6647 - val_ca3-[11.3,14.9): 0.8388 - val_ca4-[8.0,9.5): 1.5668 - val_ca4-[9.5,10.3): 1.1357 - val_ca4-[10.3,11.3): 0.9796 - val_ca4-[11.3,14.9): 0.6817\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5027 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3547 - ca2-[9.5,10.3): 0.4698 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5094 - ca3-[10.3,11.3): 0.6414 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5243 - ca4-[11.3,14.9): 0.6944 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9164 - val_ca1-[11.3,14.9): 1.5962 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.3967 - val_ca2-[10.3,11.3): 0.8338 - val_ca2-[11.3,14.9): 1.4640 - val_ca3-[8.0,9.5): 0.8921 - val_ca3-[9.5,10.3): 0.5309 - val_ca3-[10.3,11.3): 0.6676 - val_ca3-[11.3,14.9): 0.8756 - val_ca4-[8.0,9.5): 1.5687 - val_ca4-[9.5,10.3): 1.1372 - val_ca4-[10.3,11.3): 0.9811 - val_ca4-[11.3,14.9): 0.7084\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5147 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3534 - ca2-[9.5,10.3): 0.4683 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5148 - ca3-[10.3,11.3): 0.6212 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6499 - ca4-[11.3,14.9): 0.6858 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9149 - val_ca1-[11.3,14.9): 1.5842 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.3963 - val_ca2-[10.3,11.3): 0.8314 - val_ca2-[11.3,14.9): 1.4601 - val_ca3-[8.0,9.5): 0.8789 - val_ca3-[9.5,10.3): 0.5207 - val_ca3-[10.3,11.3): 0.6681 - val_ca3-[11.3,14.9): 0.8883 - val_ca4-[8.0,9.5): 1.5694 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9788 - val_ca4-[11.3,14.9): 0.6955\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5178 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3583 - ca2-[9.5,10.3): 0.4848 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5190 - ca3-[10.3,11.3): 0.6039 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5634 - ca4-[11.3,14.9): 0.6888 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9105 - val_ca1-[11.3,14.9): 1.6046 - val_ca2-[8.0,9.5): 0.5904 - val_ca2-[9.5,10.3): 0.3951 - val_ca2-[10.3,11.3): 0.8218 - val_ca2-[11.3,14.9): 1.4582 - val_ca3-[8.0,9.5): 0.8822 - val_ca3-[9.5,10.3): 0.5230 - val_ca3-[10.3,11.3): 0.6677 - val_ca3-[11.3,14.9): 0.8825 - val_ca4-[8.0,9.5): 1.5698 - val_ca4-[9.5,10.3): 1.1381 - val_ca4-[10.3,11.3): 0.9809 - val_ca4-[11.3,14.9): 0.7033\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5176 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3561 - ca2-[9.5,10.3): 0.4658 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5247 - ca3-[10.3,11.3): 0.6326 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5623 - ca4-[11.3,14.9): 0.6948 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9123 - val_ca1-[11.3,14.9): 1.5771 - val_ca2-[8.0,9.5): 0.5892 - val_ca2-[9.5,10.3): 0.3956 - val_ca2-[10.3,11.3): 0.8294 - val_ca2-[11.3,14.9): 1.4545 - val_ca3-[8.0,9.5): 0.8871 - val_ca3-[9.5,10.3): 0.5261 - val_ca3-[10.3,11.3): 0.6676 - val_ca3-[11.3,14.9): 0.8746 - val_ca4-[8.0,9.5): 1.5694 - val_ca4-[9.5,10.3): 1.1377 - val_ca4-[10.3,11.3): 0.9833 - val_ca4-[11.3,14.9): 0.7061\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5167 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3747 - ca2-[9.5,10.3): 0.4683 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5277 - ca3-[10.3,11.3): 0.6167 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5741 - ca4-[11.3,14.9): 0.6821 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9102 - val_ca1-[11.3,14.9): 1.5832 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3960 - val_ca2-[10.3,11.3): 0.8306 - val_ca2-[11.3,14.9): 1.4715 - val_ca3-[8.0,9.5): 0.8752 - val_ca3-[9.5,10.3): 0.5152 - val_ca3-[10.3,11.3): 0.6642 - val_ca3-[11.3,14.9): 0.8924 - val_ca4-[8.0,9.5): 1.5680 - val_ca4-[9.5,10.3): 1.1365 - val_ca4-[10.3,11.3): 0.9799 - val_ca4-[11.3,14.9): 0.7125\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5120 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3681 - ca2-[9.5,10.3): 0.4650 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5224 - ca3-[10.3,11.3): 0.6377 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5217 - ca4-[11.3,14.9): 0.6983 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9112 - val_ca1-[11.3,14.9): 1.5710 - val_ca2-[8.0,9.5): 0.5894 - val_ca2-[9.5,10.3): 0.3947 - val_ca2-[10.3,11.3): 0.8282 - val_ca2-[11.3,14.9): 1.4425 - val_ca3-[8.0,9.5): 0.8976 - val_ca3-[9.5,10.3): 0.5320 - val_ca3-[10.3,11.3): 0.6608 - val_ca3-[11.3,14.9): 0.8441 - val_ca4-[8.0,9.5): 1.5668 - val_ca4-[9.5,10.3): 1.1354 - val_ca4-[10.3,11.3): 0.9627 - val_ca4-[11.3,14.9): 0.6940\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5039 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3462 - ca2-[9.5,10.3): 0.4766 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5589 - ca3-[10.3,11.3): 0.6359 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5534 - ca4-[11.3,14.9): 0.6850 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9099 - val_ca1-[11.3,14.9): 1.5856 - val_ca2-[8.0,9.5): 0.5893 - val_ca2-[9.5,10.3): 0.3947 - val_ca2-[10.3,11.3): 0.8233 - val_ca2-[11.3,14.9): 1.4567 - val_ca3-[8.0,9.5): 0.8858 - val_ca3-[9.5,10.3): 0.5219 - val_ca3-[10.3,11.3): 0.6597 - val_ca3-[11.3,14.9): 0.8690 - val_ca4-[8.0,9.5): 1.5660 - val_ca4-[9.5,10.3): 1.1346 - val_ca4-[10.3,11.3): 0.9788 - val_ca4-[11.3,14.9): 0.6998\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3720 - ca2-[9.5,10.3): 0.4675 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5207 - ca3-[10.3,11.3): 0.6352 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5789 - ca4-[11.3,14.9): 0.6798 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9016 - val_ca1-[11.3,14.9): 1.5528 - val_ca2-[8.0,9.5): 0.5895 - val_ca2-[9.5,10.3): 0.3946 - val_ca2-[10.3,11.3): 0.8222 - val_ca2-[11.3,14.9): 1.4221 - val_ca3-[8.0,9.5): 0.8772 - val_ca3-[9.5,10.3): 0.5154 - val_ca3-[10.3,11.3): 0.6616 - val_ca3-[11.3,14.9): 0.8676 - val_ca4-[8.0,9.5): 1.5656 - val_ca4-[9.5,10.3): 1.1342 - val_ca4-[10.3,11.3): 0.9657 - val_ca4-[11.3,14.9): 0.6907\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5109 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3727 - ca2-[9.5,10.3): 0.4737 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5250 - ca3-[10.3,11.3): 0.6238 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5581 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9166 - val_ca1-[11.3,14.9): 1.5967 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.3947 - val_ca2-[10.3,11.3): 0.8335 - val_ca2-[11.3,14.9): 1.4840 - val_ca3-[8.0,9.5): 0.8836 - val_ca3-[9.5,10.3): 0.5200 - val_ca3-[10.3,11.3): 0.6651 - val_ca3-[11.3,14.9): 0.8890 - val_ca4-[8.0,9.5): 1.5652 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9790 - val_ca4-[11.3,14.9): 0.7081\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5163 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3686 - ca2-[9.5,10.3): 0.4613 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4958 - ca3-[10.3,11.3): 0.6253 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5853 - ca4-[11.3,14.9): 0.6983 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9184 - val_ca1-[11.3,14.9): 1.5624 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.3949 - val_ca2-[10.3,11.3): 0.8368 - val_ca2-[11.3,14.9): 1.4518 - val_ca3-[8.0,9.5): 0.8965 - val_ca3-[9.5,10.3): 0.5290 - val_ca3-[10.3,11.3): 0.6651 - val_ca3-[11.3,14.9): 0.8419 - val_ca4-[8.0,9.5): 1.5656 - val_ca4-[9.5,10.3): 1.1342 - val_ca4-[10.3,11.3): 0.9817 - val_ca4-[11.3,14.9): 0.6790\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3669 - ca2-[9.5,10.3): 0.4568 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5418 - ca3-[10.3,11.3): 0.6251 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5765 - ca4-[11.3,14.9): 0.6902 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9143 - val_ca1-[11.3,14.9): 1.5360 - val_ca2-[8.0,9.5): 0.5896 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8269 - val_ca2-[11.3,14.9): 1.4169 - val_ca3-[8.0,9.5): 0.8753 - val_ca3-[9.5,10.3): 0.5114 - val_ca3-[10.3,11.3): 0.6627 - val_ca3-[11.3,14.9): 0.8600 - val_ca4-[8.0,9.5): 1.5656 - val_ca4-[9.5,10.3): 1.1342 - val_ca4-[10.3,11.3): 0.9765 - val_ca4-[11.3,14.9): 0.6901\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3743 - ca2-[9.5,10.3): 0.4685 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4948 - ca3-[10.3,11.3): 0.6204 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5857 - ca4-[11.3,14.9): 0.6950 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9099 - val_ca1-[11.3,14.9): 1.5791 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3952 - val_ca2-[10.3,11.3): 0.8344 - val_ca2-[11.3,14.9): 1.4840 - val_ca3-[8.0,9.5): 0.8961 - val_ca3-[9.5,10.3): 0.5275 - val_ca3-[10.3,11.3): 0.6605 - val_ca3-[11.3,14.9): 0.8605 - val_ca4-[8.0,9.5): 1.5657 - val_ca4-[9.5,10.3): 1.1342 - val_ca4-[10.3,11.3): 0.9783 - val_ca4-[11.3,14.9): 0.6992\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5171 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3454 - ca2-[9.5,10.3): 0.4622 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5412 - ca3-[10.3,11.3): 0.6176 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5494 - ca4-[11.3,14.9): 0.6849 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9098 - val_ca1-[11.3,14.9): 1.5759 - val_ca2-[8.0,9.5): 0.5904 - val_ca2-[9.5,10.3): 0.3926 - val_ca2-[10.3,11.3): 0.8212 - val_ca2-[11.3,14.9): 1.4537 - val_ca3-[8.0,9.5): 0.8842 - val_ca3-[9.5,10.3): 0.5182 - val_ca3-[10.3,11.3): 0.6623 - val_ca3-[11.3,14.9): 0.8723 - val_ca4-[8.0,9.5): 1.5643 - val_ca4-[9.5,10.3): 1.1329 - val_ca4-[10.3,11.3): 0.9776 - val_ca4-[11.3,14.9): 0.7060\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5208 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3681 - ca2-[9.5,10.3): 0.4670 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5130 - ca3-[10.3,11.3): 0.6226 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5728 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9164 - val_ca1-[11.3,14.9): 1.6051 - val_ca2-[8.0,9.5): 0.5893 - val_ca2-[9.5,10.3): 0.3921 - val_ca2-[10.3,11.3): 0.8307 - val_ca2-[11.3,14.9): 1.4906 - val_ca3-[8.0,9.5): 0.8915 - val_ca3-[9.5,10.3): 0.5244 - val_ca3-[10.3,11.3): 0.6625 - val_ca3-[11.3,14.9): 0.8810 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1353 - val_ca4-[10.3,11.3): 0.9777 - val_ca4-[11.3,14.9): 0.7132\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5106 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3643 - ca2-[9.5,10.3): 0.4706 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5435 - ca3-[10.3,11.3): 0.6144 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5850 - ca4-[11.3,14.9): 0.7013 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9166 - val_ca1-[11.3,14.9): 1.5987 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.3924 - val_ca2-[10.3,11.3): 0.8316 - val_ca2-[11.3,14.9): 1.4700 - val_ca3-[8.0,9.5): 0.8800 - val_ca3-[9.5,10.3): 0.5149 - val_ca3-[10.3,11.3): 0.6631 - val_ca3-[11.3,14.9): 0.8802 - val_ca4-[8.0,9.5): 1.5642 - val_ca4-[9.5,10.3): 1.1327 - val_ca4-[10.3,11.3): 0.9780 - val_ca4-[11.3,14.9): 0.7180\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5149 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3461 - ca2-[9.5,10.3): 0.4574 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5307 - ca3-[10.3,11.3): 0.6215 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5697 - ca4-[11.3,14.9): 0.6952 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9195 - val_ca1-[11.3,14.9): 1.5897 - val_ca2-[8.0,9.5): 0.5904 - val_ca2-[9.5,10.3): 0.3912 - val_ca2-[10.3,11.3): 0.8270 - val_ca2-[11.3,14.9): 1.4617 - val_ca3-[8.0,9.5): 0.8929 - val_ca3-[9.5,10.3): 0.5235 - val_ca3-[10.3,11.3): 0.6584 - val_ca3-[11.3,14.9): 0.8608 - val_ca4-[8.0,9.5): 1.5634 - val_ca4-[9.5,10.3): 1.1320 - val_ca4-[10.3,11.3): 0.9746 - val_ca4-[11.3,14.9): 0.7042\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5148 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3425 - ca2-[9.5,10.3): 0.4595 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5298 - ca3-[10.3,11.3): 0.6219 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5781 - ca4-[11.3,14.9): 0.6942 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9105 - val_ca1-[11.3,14.9): 1.5646 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.3916 - val_ca2-[10.3,11.3): 0.8249 - val_ca2-[11.3,14.9): 1.4465 - val_ca3-[8.0,9.5): 0.8790 - val_ca3-[9.5,10.3): 0.5121 - val_ca3-[10.3,11.3): 0.6578 - val_ca3-[11.3,14.9): 0.8613 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1318 - val_ca4-[10.3,11.3): 0.9767 - val_ca4-[11.3,14.9): 0.6926\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5115 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3647 - ca2-[9.5,10.3): 0.4678 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5462 - ca3-[10.3,11.3): 0.6147 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5743 - ca4-[11.3,14.9): 0.6798 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9124 - val_ca1-[11.3,14.9): 1.5903 - val_ca2-[8.0,9.5): 0.5902 - val_ca2-[9.5,10.3): 0.3906 - val_ca2-[10.3,11.3): 0.8217 - val_ca2-[11.3,14.9): 1.4596 - val_ca3-[8.0,9.5): 0.8935 - val_ca3-[9.5,10.3): 0.5228 - val_ca3-[10.3,11.3): 0.6579 - val_ca3-[11.3,14.9): 0.8655 - val_ca4-[8.0,9.5): 1.5647 - val_ca4-[9.5,10.3): 1.1329 - val_ca4-[10.3,11.3): 0.9799 - val_ca4-[11.3,14.9): 0.7181\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5252 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3496 - ca2-[9.5,10.3): 0.4530 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5280 - ca3-[10.3,11.3): 0.6175 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5606 - ca4-[11.3,14.9): 0.6958 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9183 - val_ca1-[11.3,14.9): 1.5853 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3930 - val_ca2-[10.3,11.3): 0.8401 - val_ca2-[11.3,14.9): 1.5023 - val_ca3-[8.0,9.5): 0.8758 - val_ca3-[9.5,10.3): 0.5095 - val_ca3-[10.3,11.3): 0.6613 - val_ca3-[11.3,14.9): 0.8756 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1321 - val_ca4-[10.3,11.3): 0.9801 - val_ca4-[11.3,14.9): 0.7049\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5085 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3705 - ca2-[9.5,10.3): 0.4573 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5137 - ca3-[10.3,11.3): 0.6274 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6039 - ca4-[11.3,14.9): 0.6853 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9137 - val_ca1-[11.3,14.9): 1.6011 - val_ca2-[8.0,9.5): 0.5896 - val_ca2-[9.5,10.3): 0.3902 - val_ca2-[10.3,11.3): 0.8209 - val_ca2-[11.3,14.9): 1.4673 - val_ca3-[8.0,9.5): 0.8824 - val_ca3-[9.5,10.3): 0.5143 - val_ca3-[10.3,11.3): 0.6578 - val_ca3-[11.3,14.9): 0.8821 - val_ca4-[8.0,9.5): 1.5643 - val_ca4-[9.5,10.3): 1.1323 - val_ca4-[10.3,11.3): 0.9750 - val_ca4-[11.3,14.9): 0.7136\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5214 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3627 - ca2-[9.5,10.3): 0.4558 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5176 - ca3-[10.3,11.3): 0.6148 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5757 - ca4-[11.3,14.9): 0.6900 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9083 - val_ca1-[11.3,14.9): 1.5876 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.3906 - val_ca2-[10.3,11.3): 0.8228 - val_ca2-[11.3,14.9): 1.4768 - val_ca3-[8.0,9.5): 0.8869 - val_ca3-[9.5,10.3): 0.5165 - val_ca3-[10.3,11.3): 0.6579 - val_ca3-[11.3,14.9): 0.8746 - val_ca4-[8.0,9.5): 1.5650 - val_ca4-[9.5,10.3): 1.1328 - val_ca4-[10.3,11.3): 0.9786 - val_ca4-[11.3,14.9): 0.7139\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5122 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3454 - ca2-[9.5,10.3): 0.4534 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5080 - ca3-[10.3,11.3): 0.6218 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5926 - ca4-[11.3,14.9): 0.6871 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9067 - val_ca1-[11.3,14.9): 1.5510 - val_ca2-[8.0,9.5): 0.5908 - val_ca2-[9.5,10.3): 0.3897 - val_ca2-[10.3,11.3): 0.8155 - val_ca2-[11.3,14.9): 1.4235 - val_ca3-[8.0,9.5): 0.8824 - val_ca3-[9.5,10.3): 0.5127 - val_ca3-[10.3,11.3): 0.6589 - val_ca3-[11.3,14.9): 0.8547 - val_ca4-[8.0,9.5): 1.5648 - val_ca4-[9.5,10.3): 1.1325 - val_ca4-[10.3,11.3): 0.9814 - val_ca4-[11.3,14.9): 0.6953\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5053 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3580 - ca2-[9.5,10.3): 0.4557 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5267 - ca3-[10.3,11.3): 0.6169 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5440 - ca4-[11.3,14.9): 0.6913 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.5705 - val_ca2-[8.0,9.5): 0.5900 - val_ca2-[9.5,10.3): 0.3903 - val_ca2-[10.3,11.3): 0.8217 - val_ca2-[11.3,14.9): 1.4492 - val_ca3-[8.0,9.5): 0.8921 - val_ca3-[9.5,10.3): 0.5195 - val_ca3-[10.3,11.3): 0.6550 - val_ca3-[11.3,14.9): 0.8416 - val_ca4-[8.0,9.5): 1.5655 - val_ca4-[9.5,10.3): 1.1329 - val_ca4-[10.3,11.3): 0.9751 - val_ca4-[11.3,14.9): 0.6810\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5148 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3480 - ca2-[9.5,10.3): 0.4523 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5114 - ca3-[10.3,11.3): 0.6119 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5998 - ca4-[11.3,14.9): 0.6925 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9162 - val_ca1-[11.3,14.9): 1.5405 - val_ca2-[8.0,9.5): 0.5893 - val_ca2-[9.5,10.3): 0.3905 - val_ca2-[10.3,11.3): 0.8268 - val_ca2-[11.3,14.9): 1.4486 - val_ca3-[8.0,9.5): 0.8874 - val_ca3-[9.5,10.3): 0.5169 - val_ca3-[10.3,11.3): 0.6574 - val_ca3-[11.3,14.9): 0.8414 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1314 - val_ca4-[10.3,11.3): 0.9767 - val_ca4-[11.3,14.9): 0.6544\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5311 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3424 - ca2-[9.5,10.3): 0.4544 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5120 - ca3-[10.3,11.3): 0.6071 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5805 - ca4-[11.3,14.9): 0.6943 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9144 - val_ca1-[11.3,14.9): 1.5703 - val_ca2-[8.0,9.5): 0.5904 - val_ca2-[9.5,10.3): 0.3892 - val_ca2-[10.3,11.3): 0.8178 - val_ca2-[11.3,14.9): 1.4586 - val_ca3-[8.0,9.5): 0.8801 - val_ca3-[9.5,10.3): 0.5102 - val_ca3-[10.3,11.3): 0.6538 - val_ca3-[11.3,14.9): 0.8669 - val_ca4-[8.0,9.5): 1.5625 - val_ca4-[9.5,10.3): 1.1301 - val_ca4-[10.3,11.3): 0.9733 - val_ca4-[11.3,14.9): 0.6871\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5157 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3618 - ca2-[9.5,10.3): 0.4472 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5015 - ca3-[10.3,11.3): 0.6190 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5607 - ca4-[11.3,14.9): 0.6875 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9054 - val_ca1-[11.3,14.9): 1.5231 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.3898 - val_ca2-[10.3,11.3): 0.8166 - val_ca2-[11.3,14.9): 1.4093 - val_ca3-[8.0,9.5): 0.8876 - val_ca3-[9.5,10.3): 0.5164 - val_ca3-[10.3,11.3): 0.6528 - val_ca3-[11.3,14.9): 0.8226 - val_ca4-[8.0,9.5): 1.5632 - val_ca4-[9.5,10.3): 1.1305 - val_ca4-[10.3,11.3): 0.9772 - val_ca4-[11.3,14.9): 0.6926\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5135 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3657 - ca2-[9.5,10.3): 0.4477 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5337 - ca3-[10.3,11.3): 0.6060 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5616 - ca4-[11.3,14.9): 0.6915 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9104 - val_ca1-[11.3,14.9): 1.5698 - val_ca2-[8.0,9.5): 0.5900 - val_ca2-[9.5,10.3): 0.3883 - val_ca2-[10.3,11.3): 0.8141 - val_ca2-[11.3,14.9): 1.4402 - val_ca3-[8.0,9.5): 0.8745 - val_ca3-[9.5,10.3): 0.5074 - val_ca3-[10.3,11.3): 0.6537 - val_ca3-[11.3,14.9): 0.8679 - val_ca4-[8.0,9.5): 1.5623 - val_ca4-[9.5,10.3): 1.1296 - val_ca4-[10.3,11.3): 0.9582 - val_ca4-[11.3,14.9): 0.6867\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5213 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3530 - ca2-[9.5,10.3): 0.4500 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5237 - ca3-[10.3,11.3): 0.6137 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5972 - ca4-[11.3,14.9): 0.6871 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9135 - val_ca1-[11.3,14.9): 1.5401 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.3884 - val_ca2-[10.3,11.3): 0.8193 - val_ca2-[11.3,14.9): 1.4296 - val_ca3-[8.0,9.5): 0.8866 - val_ca3-[9.5,10.3): 0.5152 - val_ca3-[10.3,11.3): 0.6512 - val_ca3-[11.3,14.9): 0.8265 - val_ca4-[8.0,9.5): 1.5616 - val_ca4-[9.5,10.3): 1.1288 - val_ca4-[10.3,11.3): 0.9602 - val_ca4-[11.3,14.9): 0.6544\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5107 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3625 - ca2-[9.5,10.3): 0.4584 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5349 - ca3-[10.3,11.3): 0.6082 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5775 - ca4-[11.3,14.9): 0.6869 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9192 - val_ca1-[11.3,14.9): 1.5995 - val_ca2-[8.0,9.5): 0.5856 - val_ca2-[9.5,10.3): 0.3902 - val_ca2-[10.3,11.3): 0.8367 - val_ca2-[11.3,14.9): 1.5055 - val_ca3-[8.0,9.5): 0.8727 - val_ca3-[9.5,10.3): 0.5051 - val_ca3-[10.3,11.3): 0.6528 - val_ca3-[11.3,14.9): 0.8817 - val_ca4-[8.0,9.5): 1.5609 - val_ca4-[9.5,10.3): 1.1281 - val_ca4-[10.3,11.3): 0.9714 - val_ca4-[11.3,14.9): 0.7161\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5137 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3534 - ca2-[9.5,10.3): 0.4466 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5323 - ca3-[10.3,11.3): 0.6169 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5823 - ca4-[11.3,14.9): 0.7008 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9147 - val_ca1-[11.3,14.9): 1.5568 - val_ca2-[8.0,9.5): 0.5915 - val_ca2-[9.5,10.3): 0.3871 - val_ca2-[10.3,11.3): 0.8074 - val_ca2-[11.3,14.9): 1.4111 - val_ca3-[8.0,9.5): 0.8831 - val_ca3-[9.5,10.3): 0.5126 - val_ca3-[10.3,11.3): 0.6490 - val_ca3-[11.3,14.9): 0.8393 - val_ca4-[8.0,9.5): 1.5614 - val_ca4-[9.5,10.3): 1.1283 - val_ca4-[10.3,11.3): 0.9716 - val_ca4-[11.3,14.9): 0.6955\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5162 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3530 - ca2-[9.5,10.3): 0.4533 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5494 - ca3-[10.3,11.3): 0.6315 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5500 - ca4-[11.3,14.9): 0.6737 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9143 - val_ca1-[11.3,14.9): 1.5505 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.3882 - val_ca2-[10.3,11.3): 0.8220 - val_ca2-[11.3,14.9): 1.4459 - val_ca3-[8.0,9.5): 0.8890 - val_ca3-[9.5,10.3): 0.5159 - val_ca3-[10.3,11.3): 0.6484 - val_ca3-[11.3,14.9): 0.8241 - val_ca4-[8.0,9.5): 1.5609 - val_ca4-[9.5,10.3): 1.1277 - val_ca4-[10.3,11.3): 0.9711 - val_ca4-[11.3,14.9): 0.6717\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5115 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3676 - ca2-[9.5,10.3): 0.4568 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5272 - ca3-[10.3,11.3): 0.6101 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5743 - ca4-[11.3,14.9): 0.6915 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9119 - val_ca1-[11.3,14.9): 1.5960 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.3879 - val_ca2-[10.3,11.3): 0.8219 - val_ca2-[11.3,14.9): 1.4911 - val_ca3-[8.0,9.5): 0.8629 - val_ca3-[9.5,10.3): 0.4974 - val_ca3-[10.3,11.3): 0.6513 - val_ca3-[11.3,14.9): 0.8830 - val_ca4-[8.0,9.5): 1.5607 - val_ca4-[9.5,10.3): 1.1273 - val_ca4-[10.3,11.3): 0.9753 - val_ca4-[11.3,14.9): 0.7166\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5135 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3473 - ca2-[9.5,10.3): 0.4375 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5492 - ca3-[10.3,11.3): 0.6159 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5854 - ca4-[11.3,14.9): 0.6978 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9094 - val_ca1-[11.3,14.9): 1.6048 - val_ca2-[8.0,9.5): 0.5899 - val_ca2-[9.5,10.3): 0.3862 - val_ca2-[10.3,11.3): 0.8063 - val_ca2-[11.3,14.9): 1.4643 - val_ca3-[8.0,9.5): 0.8841 - val_ca3-[9.5,10.3): 0.5140 - val_ca3-[10.3,11.3): 0.6509 - val_ca3-[11.3,14.9): 0.8652 - val_ca4-[8.0,9.5): 1.5619 - val_ca4-[9.5,10.3): 1.1281 - val_ca4-[10.3,11.3): 0.9639 - val_ca4-[11.3,14.9): 0.6993\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5244 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3486 - ca2-[9.5,10.3): 0.4472 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5510 - ca3-[10.3,11.3): 0.6129 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5716 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9144 - val_ca1-[11.3,14.9): 1.5958 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3884 - val_ca2-[10.3,11.3): 0.8238 - val_ca2-[11.3,14.9): 1.4899 - val_ca3-[8.0,9.5): 0.8589 - val_ca3-[9.5,10.3): 0.4948 - val_ca3-[10.3,11.3): 0.6474 - val_ca3-[11.3,14.9): 0.8815 - val_ca4-[8.0,9.5): 1.5625 - val_ca4-[9.5,10.3): 1.1284 - val_ca4-[10.3,11.3): 0.9713 - val_ca4-[11.3,14.9): 0.7164\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5142 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3467 - ca2-[9.5,10.3): 0.4380 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5123 - ca3-[10.3,11.3): 0.6184 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5657 - ca4-[11.3,14.9): 0.6992 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9098 - val_ca1-[11.3,14.9): 1.5828 - val_ca2-[8.0,9.5): 0.5925 - val_ca2-[9.5,10.3): 0.3855 - val_ca2-[10.3,11.3): 0.7950 - val_ca2-[11.3,14.9): 1.4189 - val_ca3-[8.0,9.5): 0.8755 - val_ca3-[9.5,10.3): 0.5063 - val_ca3-[10.3,11.3): 0.6433 - val_ca3-[11.3,14.9): 0.8533 - val_ca4-[8.0,9.5): 1.5621 - val_ca4-[9.5,10.3): 1.1278 - val_ca4-[10.3,11.3): 0.9727 - val_ca4-[11.3,14.9): 0.7037\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5121 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3417 - ca2-[9.5,10.3): 0.4464 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5203 - ca3-[10.3,11.3): 0.6102 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5433 - ca4-[11.3,14.9): 0.6945 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9191 - val_ca1-[11.3,14.9): 1.5800 - val_ca2-[8.0,9.5): 0.5844 - val_ca2-[9.5,10.3): 0.3880 - val_ca2-[10.3,11.3): 0.8305 - val_ca2-[11.3,14.9): 1.4860 - val_ca3-[8.0,9.5): 0.8600 - val_ca3-[9.5,10.3): 0.4964 - val_ca3-[10.3,11.3): 0.6480 - val_ca3-[11.3,14.9): 0.8540 - val_ca4-[8.0,9.5): 1.5597 - val_ca4-[9.5,10.3): 1.1255 - val_ca4-[10.3,11.3): 0.9691 - val_ca4-[11.3,14.9): 0.6953\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5179 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3385 - ca2-[9.5,10.3): 0.4227 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5052 - ca3-[10.3,11.3): 0.6115 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5643 - ca4-[11.3,14.9): 0.6893 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9150 - val_ca1-[11.3,14.9): 1.6108 - val_ca2-[8.0,9.5): 0.5918 - val_ca2-[9.5,10.3): 0.3837 - val_ca2-[10.3,11.3): 0.7949 - val_ca2-[11.3,14.9): 1.4335 - val_ca3-[8.0,9.5): 0.8701 - val_ca3-[9.5,10.3): 0.5040 - val_ca3-[10.3,11.3): 0.6446 - val_ca3-[11.3,14.9): 0.8655 - val_ca4-[8.0,9.5): 1.5570 - val_ca4-[9.5,10.3): 1.1229 - val_ca4-[10.3,11.3): 0.9678 - val_ca4-[11.3,14.9): 0.7114\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5180 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3524 - ca2-[9.5,10.3): 0.4399 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5510 - ca3-[10.3,11.3): 0.6126 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5558 - ca4-[11.3,14.9): 0.6913 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9208 - val_ca1-[11.3,14.9): 1.5521 - val_ca2-[8.0,9.5): 0.5833 - val_ca2-[9.5,10.3): 0.3862 - val_ca2-[10.3,11.3): 0.8247 - val_ca2-[11.3,14.9): 1.4542 - val_ca3-[8.0,9.5): 0.8433 - val_ca3-[9.5,10.3): 0.4871 - val_ca3-[10.3,11.3): 0.6511 - val_ca3-[11.3,14.9): 0.8626 - val_ca4-[8.0,9.5): 1.5560 - val_ca4-[9.5,10.3): 1.1250 - val_ca4-[10.3,11.3): 0.9748 - val_ca4-[11.3,14.9): 0.6899\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5199 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3482 - ca2-[9.5,10.3): 0.4349 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4918 - ca3-[10.3,11.3): 0.6086 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5560 - ca4-[11.3,14.9): 0.6742 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9052 - val_ca1-[11.3,14.9): 1.5828 - val_ca2-[8.0,9.5): 0.5856 - val_ca2-[9.5,10.3): 0.3835 - val_ca2-[10.3,11.3): 0.7958 - val_ca2-[11.3,14.9): 1.4367 - val_ca3-[8.0,9.5): 0.8718 - val_ca3-[9.5,10.3): 0.5067 - val_ca3-[10.3,11.3): 0.6367 - val_ca3-[11.3,14.9): 0.8390 - val_ca4-[8.0,9.5): 1.5569 - val_ca4-[9.5,10.3): 1.1223 - val_ca4-[10.3,11.3): 0.9707 - val_ca4-[11.3,14.9): 0.7079\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5267 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3514 - ca2-[9.5,10.3): 0.4411 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5327 - ca3-[10.3,11.3): 0.6069 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5267 - ca4-[11.3,14.9): 0.6851 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9122 - val_ca1-[11.3,14.9): 1.5758 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3844 - val_ca2-[10.3,11.3): 0.8063 - val_ca2-[11.3,14.9): 1.4426 - val_ca3-[8.0,9.5): 0.8334 - val_ca3-[9.5,10.3): 0.4819 - val_ca3-[10.3,11.3): 0.6475 - val_ca3-[11.3,14.9): 0.8797 - val_ca4-[8.0,9.5): 1.5569 - val_ca4-[9.5,10.3): 1.1195 - val_ca4-[10.3,11.3): 0.9659 - val_ca4-[11.3,14.9): 0.6813\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5175 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3442 - ca2-[9.5,10.3): 0.4304 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4754 - ca3-[10.3,11.3): 0.5887 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6037 - ca4-[11.3,14.9): 0.6784 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9159 - val_ca1-[11.3,14.9): 1.5954 - val_ca2-[8.0,9.5): 0.5824 - val_ca2-[9.5,10.3): 0.3847 - val_ca2-[10.3,11.3): 0.8222 - val_ca2-[11.3,14.9): 1.4846 - val_ca3-[8.0,9.5): 0.8765 - val_ca3-[9.5,10.3): 0.5118 - val_ca3-[10.3,11.3): 0.6434 - val_ca3-[11.3,14.9): 0.8380 - val_ca4-[8.0,9.5): 1.5555 - val_ca4-[9.5,10.3): 1.1205 - val_ca4-[10.3,11.3): 0.9684 - val_ca4-[11.3,14.9): 0.7036\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3543 - ca2-[9.5,10.3): 0.4314 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5004 - ca3-[10.3,11.3): 0.5933 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5398 - ca4-[11.3,14.9): 0.6846 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9158 - val_ca1-[11.3,14.9): 1.5973 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3838 - val_ca2-[10.3,11.3): 0.8052 - val_ca2-[11.3,14.9): 1.4490 - val_ca3-[8.0,9.5): 0.8426 - val_ca3-[9.5,10.3): 0.4893 - val_ca3-[10.3,11.3): 0.6427 - val_ca3-[11.3,14.9): 0.8767 - val_ca4-[8.0,9.5): 1.5540 - val_ca4-[9.5,10.3): 1.1221 - val_ca4-[10.3,11.3): 0.9673 - val_ca4-[11.3,14.9): 0.7134\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5247 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3341 - ca2-[9.5,10.3): 0.4272 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5187 - ca3-[10.3,11.3): 0.5997 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5800 - ca4-[11.3,14.9): 0.6969 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9105 - val_ca1-[11.3,14.9): 1.5902 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.3807 - val_ca2-[10.3,11.3): 0.7894 - val_ca2-[11.3,14.9): 1.4124 - val_ca3-[8.0,9.5): 0.8481 - val_ca3-[9.5,10.3): 0.4922 - val_ca3-[10.3,11.3): 0.6395 - val_ca3-[11.3,14.9): 0.8562 - val_ca4-[8.0,9.5): 1.5561 - val_ca4-[9.5,10.3): 1.1202 - val_ca4-[10.3,11.3): 0.9512 - val_ca4-[11.3,14.9): 0.6854\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5187 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3293 - ca2-[9.5,10.3): 0.4324 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5243 - ca3-[10.3,11.3): 0.6056 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5264 - ca4-[11.3,14.9): 0.6979 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9096 - val_ca1-[11.3,14.9): 1.5629 - val_ca2-[8.0,9.5): 0.5826 - val_ca2-[9.5,10.3): 0.3828 - val_ca2-[10.3,11.3): 0.8072 - val_ca2-[11.3,14.9): 1.4396 - val_ca3-[8.0,9.5): 0.8442 - val_ca3-[9.5,10.3): 0.4904 - val_ca3-[10.3,11.3): 0.6381 - val_ca3-[11.3,14.9): 0.8411 - val_ca4-[8.0,9.5): 1.5570 - val_ca4-[9.5,10.3): 1.1205 - val_ca4-[10.3,11.3): 0.9673 - val_ca4-[11.3,14.9): 0.6876\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5126 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3492 - ca2-[9.5,10.3): 0.4396 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5261 - ca3-[10.3,11.3): 0.5948 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5455 - ca4-[11.3,14.9): 0.6754 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9053 - val_ca1-[11.3,14.9): 1.5896 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.3807 - val_ca2-[10.3,11.3): 0.7788 - val_ca2-[11.3,14.9): 1.4141 - val_ca3-[8.0,9.5): 0.8359 - val_ca3-[9.5,10.3): 0.4872 - val_ca3-[10.3,11.3): 0.6314 - val_ca3-[11.3,14.9): 0.8528 - val_ca4-[8.0,9.5): 1.5586 - val_ca4-[9.5,10.3): 1.1215 - val_ca4-[10.3,11.3): 0.9693 - val_ca4-[11.3,14.9): 0.7073\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5260 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3175 - ca2-[9.5,10.3): 0.4286 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5020 - ca3-[10.3,11.3): 0.6015 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5684 - ca4-[11.3,14.9): 0.6865 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9130 - val_ca1-[11.3,14.9): 1.5910 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3812 - val_ca2-[10.3,11.3): 0.7983 - val_ca2-[11.3,14.9): 1.4462 - val_ca3-[8.0,9.5): 0.8421 - val_ca3-[9.5,10.3): 0.4921 - val_ca3-[10.3,11.3): 0.6408 - val_ca3-[11.3,14.9): 0.8559 - val_ca4-[8.0,9.5): 1.5587 - val_ca4-[9.5,10.3): 1.1212 - val_ca4-[10.3,11.3): 0.9724 - val_ca4-[11.3,14.9): 0.6954\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5063 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3402 - ca2-[9.5,10.3): 0.4276 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5033 - ca3-[10.3,11.3): 0.5909 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5330 - ca4-[11.3,14.9): 0.6771 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9177 - val_ca1-[11.3,14.9): 1.6013 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.3805 - val_ca2-[10.3,11.3): 0.7980 - val_ca2-[11.3,14.9): 1.4368 - val_ca3-[8.0,9.5): 0.8242 - val_ca3-[9.5,10.3): 0.4812 - val_ca3-[10.3,11.3): 0.6408 - val_ca3-[11.3,14.9): 0.8726 - val_ca4-[8.0,9.5): 1.5554 - val_ca4-[9.5,10.3): 1.1177 - val_ca4-[10.3,11.3): 0.9626 - val_ca4-[11.3,14.9): 0.7020\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5206 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3151 - ca2-[9.5,10.3): 0.4234 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5077 - ca3-[10.3,11.3): 0.5940 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5957 - ca4-[11.3,14.9): 0.6896 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9174 - val_ca1-[11.3,14.9): 1.6074 - val_ca2-[8.0,9.5): 0.5941 - val_ca2-[9.5,10.3): 0.3793 - val_ca2-[10.3,11.3): 0.7741 - val_ca2-[11.3,14.9): 1.3805 - val_ca3-[8.0,9.5): 0.8350 - val_ca3-[9.5,10.3): 0.4904 - val_ca3-[10.3,11.3): 0.6383 - val_ca3-[11.3,14.9): 0.8613 - val_ca4-[8.0,9.5): 1.5563 - val_ca4-[9.5,10.3): 1.1180 - val_ca4-[10.3,11.3): 0.9681 - val_ca4-[11.3,14.9): 0.7135\n",
      "Epoch 273/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5042 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3348 - ca2-[9.5,10.3): 0.4346 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5276 - ca3-[10.3,11.3): 0.5991 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5477 - ca4-[11.3,14.9): 0.6859 - val_ca1-[8.0,9.5): 0.5837 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9132 - val_ca1-[11.3,14.9): 1.5695 - val_ca2-[8.0,9.5): 0.5800 - val_ca2-[9.5,10.3): 0.3796 - val_ca2-[10.3,11.3): 0.8065 - val_ca2-[11.3,14.9): 1.4367 - val_ca3-[8.0,9.5): 0.8190 - val_ca3-[9.5,10.3): 0.4782 - val_ca3-[10.3,11.3): 0.6330 - val_ca3-[11.3,14.9): 0.8479 - val_ca4-[8.0,9.5): 1.5632 - val_ca4-[9.5,10.3): 1.1229 - val_ca4-[10.3,11.3): 0.9636 - val_ca4-[11.3,14.9): 0.7023\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5144 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3299 - ca2-[9.5,10.3): 0.4228 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5076 - ca3-[10.3,11.3): 0.5898 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5826 - ca4-[11.3,14.9): 0.6749 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9087 - val_ca1-[11.3,14.9): 1.5938 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.3787 - val_ca2-[10.3,11.3): 0.7917 - val_ca2-[11.3,14.9): 1.4453 - val_ca3-[8.0,9.5): 0.8093 - val_ca3-[9.5,10.3): 0.4734 - val_ca3-[10.3,11.3): 0.6318 - val_ca3-[11.3,14.9): 0.8693 - val_ca4-[8.0,9.5): 1.5546 - val_ca4-[9.5,10.3): 1.1151 - val_ca4-[10.3,11.3): 0.9626 - val_ca4-[11.3,14.9): 0.7057\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5197 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3358 - ca2-[9.5,10.3): 0.4336 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5109 - ca3-[10.3,11.3): 0.5965 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5889 - ca4-[11.3,14.9): 0.6759 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9081 - val_ca1-[11.3,14.9): 1.5864 - val_ca2-[8.0,9.5): 0.5897 - val_ca2-[9.5,10.3): 0.3779 - val_ca2-[10.3,11.3): 0.7709 - val_ca2-[11.3,14.9): 1.3876 - val_ca3-[8.0,9.5): 0.8023 - val_ca3-[9.5,10.3): 0.4706 - val_ca3-[10.3,11.3): 0.6327 - val_ca3-[11.3,14.9): 0.8702 - val_ca4-[8.0,9.5): 1.5520 - val_ca4-[9.5,10.3): 1.1122 - val_ca4-[10.3,11.3): 0.9605 - val_ca4-[11.3,14.9): 0.6947\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3328 - ca2-[9.5,10.3): 0.4274 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5148 - ca3-[10.3,11.3): 0.5781 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5728 - ca4-[11.3,14.9): 0.6811 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9100 - val_ca1-[11.3,14.9): 1.5730 - val_ca2-[8.0,9.5): 0.5839 - val_ca2-[9.5,10.3): 0.3783 - val_ca2-[10.3,11.3): 0.7892 - val_ca2-[11.3,14.9): 1.4134 - val_ca3-[8.0,9.5): 0.8163 - val_ca3-[9.5,10.3): 0.4818 - val_ca3-[10.3,11.3): 0.6328 - val_ca3-[11.3,14.9): 0.8374 - val_ca4-[8.0,9.5): 1.5511 - val_ca4-[9.5,10.3): 1.1107 - val_ca4-[10.3,11.3): 0.9618 - val_ca4-[11.3,14.9): 0.6917\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5095 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3297 - ca2-[9.5,10.3): 0.4257 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5027 - ca3-[10.3,11.3): 0.5770 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5707 - ca4-[11.3,14.9): 0.6875 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9103 - val_ca1-[11.3,14.9): 1.5664 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.3783 - val_ca2-[10.3,11.3): 0.7893 - val_ca2-[11.3,14.9): 1.4102 - val_ca3-[8.0,9.5): 0.8064 - val_ca3-[9.5,10.3): 0.4752 - val_ca3-[10.3,11.3): 0.6308 - val_ca3-[11.3,14.9): 0.8418 - val_ca4-[8.0,9.5): 1.5540 - val_ca4-[9.5,10.3): 1.1126 - val_ca4-[10.3,11.3): 0.9624 - val_ca4-[11.3,14.9): 0.7011\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3295 - ca2-[9.5,10.3): 0.4193 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4926 - ca3-[10.3,11.3): 0.5873 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5265 - ca4-[11.3,14.9): 0.6946 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9116 - val_ca1-[11.3,14.9): 1.5877 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.3771 - val_ca2-[10.3,11.3): 0.7778 - val_ca2-[11.3,14.9): 1.3923 - val_ca3-[8.0,9.5): 0.8023 - val_ca3-[9.5,10.3): 0.4711 - val_ca3-[10.3,11.3): 0.6322 - val_ca3-[11.3,14.9): 0.8476 - val_ca4-[8.0,9.5): 1.5538 - val_ca4-[9.5,10.3): 1.1116 - val_ca4-[10.3,11.3): 0.9642 - val_ca4-[11.3,14.9): 0.7017\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5115 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3242 - ca2-[9.5,10.3): 0.4231 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4927 - ca3-[10.3,11.3): 0.5905 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5543 - ca4-[11.3,14.9): 0.6893 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9123 - val_ca1-[11.3,14.9): 1.5588 - val_ca2-[8.0,9.5): 0.5830 - val_ca2-[9.5,10.3): 0.3772 - val_ca2-[10.3,11.3): 0.7898 - val_ca2-[11.3,14.9): 1.3970 - val_ca3-[8.0,9.5): 0.7862 - val_ca3-[9.5,10.3): 0.4624 - val_ca3-[10.3,11.3): 0.6301 - val_ca3-[11.3,14.9): 0.8385 - val_ca4-[8.0,9.5): 1.5541 - val_ca4-[9.5,10.3): 1.1111 - val_ca4-[10.3,11.3): 0.9565 - val_ca4-[11.3,14.9): 0.6875\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3296 - ca2-[9.5,10.3): 0.4211 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4922 - ca3-[10.3,11.3): 0.5810 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5699 - ca4-[11.3,14.9): 0.6963 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9105 - val_ca1-[11.3,14.9): 1.5671 - val_ca2-[8.0,9.5): 0.5907 - val_ca2-[9.5,10.3): 0.3752 - val_ca2-[10.3,11.3): 0.7695 - val_ca2-[11.3,14.9): 1.3580 - val_ca3-[8.0,9.5): 0.8094 - val_ca3-[9.5,10.3): 0.4795 - val_ca3-[10.3,11.3): 0.6301 - val_ca3-[11.3,14.9): 0.8163 - val_ca4-[8.0,9.5): 1.5522 - val_ca4-[9.5,10.3): 1.1087 - val_ca4-[10.3,11.3): 0.9435 - val_ca4-[11.3,14.9): 0.6551\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5146 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3347 - ca2-[9.5,10.3): 0.4219 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5260 - ca3-[10.3,11.3): 0.5953 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5295 - ca4-[11.3,14.9): 0.6816 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9108 - val_ca1-[11.3,14.9): 1.5944 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3755 - val_ca2-[10.3,11.3): 0.7751 - val_ca2-[11.3,14.9): 1.3990 - val_ca3-[8.0,9.5): 0.7645 - val_ca3-[9.5,10.3): 0.4491 - val_ca3-[10.3,11.3): 0.6277 - val_ca3-[11.3,14.9): 0.8712 - val_ca4-[8.0,9.5): 1.5512 - val_ca4-[9.5,10.3): 1.1070 - val_ca4-[10.3,11.3): 0.9577 - val_ca4-[11.3,14.9): 0.7015\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5259 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3302 - ca2-[9.5,10.3): 0.4186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4941 - ca3-[10.3,11.3): 0.5895 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5686 - ca4-[11.3,14.9): 0.6870 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9085 - val_ca1-[11.3,14.9): 1.5735 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3751 - val_ca2-[10.3,11.3): 0.7703 - val_ca2-[11.3,14.9): 1.3734 - val_ca3-[8.0,9.5): 0.7768 - val_ca3-[9.5,10.3): 0.4593 - val_ca3-[10.3,11.3): 0.6234 - val_ca3-[11.3,14.9): 0.8439 - val_ca4-[8.0,9.5): 1.5506 - val_ca4-[9.5,10.3): 1.1057 - val_ca4-[10.3,11.3): 0.9540 - val_ca4-[11.3,14.9): 0.6998\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5118 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3186 - ca2-[9.5,10.3): 0.4168 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5053 - ca3-[10.3,11.3): 0.5882 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5681 - ca4-[11.3,14.9): 0.6765 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.8998 - val_ca1-[11.3,14.9): 1.5937 - val_ca2-[8.0,9.5): 0.5838 - val_ca2-[9.5,10.3): 0.3748 - val_ca2-[10.3,11.3): 0.7707 - val_ca2-[11.3,14.9): 1.4185 - val_ca3-[8.0,9.5): 0.8034 - val_ca3-[9.5,10.3): 0.4805 - val_ca3-[10.3,11.3): 0.6169 - val_ca3-[11.3,14.9): 0.8163 - val_ca4-[8.0,9.5): 1.5524 - val_ca4-[9.5,10.3): 1.1064 - val_ca4-[10.3,11.3): 0.9416 - val_ca4-[11.3,14.9): 0.6900\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5159 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3348 - ca2-[9.5,10.3): 0.4203 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5153 - ca3-[10.3,11.3): 0.5819 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5670 - ca4-[11.3,14.9): 0.6776 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9041 - val_ca1-[11.3,14.9): 1.5804 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.3726 - val_ca2-[10.3,11.3): 0.7596 - val_ca2-[11.3,14.9): 1.3644 - val_ca3-[8.0,9.5): 0.7376 - val_ca3-[9.5,10.3): 0.4369 - val_ca3-[10.3,11.3): 0.6254 - val_ca3-[11.3,14.9): 0.8814 - val_ca4-[8.0,9.5): 1.5510 - val_ca4-[9.5,10.3): 1.1043 - val_ca4-[10.3,11.3): 0.9541 - val_ca4-[11.3,14.9): 0.7047\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5290 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3313 - ca2-[9.5,10.3): 0.4132 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4614 - ca3-[10.3,11.3): 0.5700 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5636 - ca4-[11.3,14.9): 0.6837 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9131 - val_ca1-[11.3,14.9): 1.5673 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.3734 - val_ca2-[10.3,11.3): 0.7653 - val_ca2-[11.3,14.9): 1.3477 - val_ca3-[8.0,9.5): 0.7643 - val_ca3-[9.5,10.3): 0.4549 - val_ca3-[10.3,11.3): 0.6227 - val_ca3-[11.3,14.9): 0.8266 - val_ca4-[8.0,9.5): 1.5489 - val_ca4-[9.5,10.3): 1.1015 - val_ca4-[10.3,11.3): 0.9481 - val_ca4-[11.3,14.9): 0.6913\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5138 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3173 - ca2-[9.5,10.3): 0.4108 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4731 - ca3-[10.3,11.3): 0.5725 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5292 - ca4-[11.3,14.9): 0.6871 - val_ca1-[8.0,9.5): 0.5825 - val_ca1-[9.5,10.3): 0.4141 - val_ca1-[10.3,11.3): 0.9091 - val_ca1-[11.3,14.9): 1.5860 - val_ca2-[8.0,9.5): 0.5815 - val_ca2-[9.5,10.3): 0.3672 - val_ca2-[10.3,11.3): 0.7777 - val_ca2-[11.3,14.9): 1.4147 - val_ca3-[8.0,9.5): 0.7412 - val_ca3-[9.5,10.3): 0.4377 - val_ca3-[10.3,11.3): 0.6195 - val_ca3-[11.3,14.9): 0.8565 - val_ca4-[8.0,9.5): 1.5459 - val_ca4-[9.5,10.3): 1.1000 - val_ca4-[10.3,11.3): 0.9471 - val_ca4-[11.3,14.9): 0.6651\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5248 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3247 - ca2-[9.5,10.3): 0.4103 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4830 - ca3-[10.3,11.3): 0.5731 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5739 - ca4-[11.3,14.9): 0.6867 - val_ca1-[8.0,9.5): 0.5825 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.8952 - val_ca1-[11.3,14.9): 1.5841 - val_ca2-[8.0,9.5): 0.5902 - val_ca2-[9.5,10.3): 0.3707 - val_ca2-[10.3,11.3): 0.7326 - val_ca2-[11.3,14.9): 1.3268 - val_ca3-[8.0,9.5): 0.7249 - val_ca3-[9.5,10.3): 0.4327 - val_ca3-[10.3,11.3): 0.6136 - val_ca3-[11.3,14.9): 0.8664 - val_ca4-[8.0,9.5): 1.5424 - val_ca4-[9.5,10.3): 1.0938 - val_ca4-[10.3,11.3): 0.9436 - val_ca4-[11.3,14.9): 0.6909\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5261 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3228 - ca2-[9.5,10.3): 0.4074 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4655 - ca3-[10.3,11.3): 0.5675 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5648 - ca4-[11.3,14.9): 0.6815 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9129 - val_ca1-[11.3,14.9): 1.5605 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3699 - val_ca2-[10.3,11.3): 0.7564 - val_ca2-[11.3,14.9): 1.3203 - val_ca3-[8.0,9.5): 0.8023 - val_ca3-[9.5,10.3): 0.4857 - val_ca3-[10.3,11.3): 0.6203 - val_ca3-[11.3,14.9): 0.7765 - val_ca4-[8.0,9.5): 1.5372 - val_ca4-[9.5,10.3): 1.0867 - val_ca4-[10.3,11.3): 0.9369 - val_ca4-[11.3,14.9): 0.6818\n",
      "Epoch 289/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5203 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3189 - ca2-[9.5,10.3): 0.4111 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4834 - ca3-[10.3,11.3): 0.5753 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5311 - ca4-[11.3,14.9): 0.6706 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9140 - val_ca1-[11.3,14.9): 1.5787 - val_ca2-[8.0,9.5): 0.5832 - val_ca2-[9.5,10.3): 0.3704 - val_ca2-[10.3,11.3): 0.7697 - val_ca2-[11.3,14.9): 1.3529 - val_ca3-[8.0,9.5): 0.7845 - val_ca3-[9.5,10.3): 0.4751 - val_ca3-[10.3,11.3): 0.6197 - val_ca3-[11.3,14.9): 0.7868 - val_ca4-[8.0,9.5): 1.5325 - val_ca4-[9.5,10.3): 1.0805 - val_ca4-[10.3,11.3): 0.9345 - val_ca4-[11.3,14.9): 0.6815\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5246 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3191 - ca2-[9.5,10.3): 0.4211 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5392 - ca3-[10.3,11.3): 0.5718 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5956 - ca4-[11.3,14.9): 0.6739 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9097 - val_ca1-[11.3,14.9): 1.5816 - val_ca2-[8.0,9.5): 0.6055 - val_ca2-[9.5,10.3): 0.3727 - val_ca2-[10.3,11.3): 0.7164 - val_ca2-[11.3,14.9): 1.2268 - val_ca3-[8.0,9.5): 0.6934 - val_ca3-[9.5,10.3): 0.4157 - val_ca3-[10.3,11.3): 0.6192 - val_ca3-[11.3,14.9): 0.8782 - val_ca4-[8.0,9.5): 1.5387 - val_ca4-[9.5,10.3): 1.0840 - val_ca4-[10.3,11.3): 0.9370 - val_ca4-[11.3,14.9): 0.6895\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5163 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3391 - ca2-[9.5,10.3): 0.4182 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4897 - ca3-[10.3,11.3): 0.5709 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5564 - ca4-[11.3,14.9): 0.6793 - val_ca1-[8.0,9.5): 0.5823 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9131 - val_ca1-[11.3,14.9): 1.5678 - val_ca2-[8.0,9.5): 0.5828 - val_ca2-[9.5,10.3): 0.3710 - val_ca2-[10.3,11.3): 0.7645 - val_ca2-[11.3,14.9): 1.3276 - val_ca3-[8.0,9.5): 0.7155 - val_ca3-[9.5,10.3): 0.4329 - val_ca3-[10.3,11.3): 0.6173 - val_ca3-[11.3,14.9): 0.8276 - val_ca4-[8.0,9.5): 1.5404 - val_ca4-[9.5,10.3): 1.0835 - val_ca4-[10.3,11.3): 0.9306 - val_ca4-[11.3,14.9): 0.6751\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5234 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3226 - ca2-[9.5,10.3): 0.4119 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4849 - ca3-[10.3,11.3): 0.5642 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5526 - ca4-[11.3,14.9): 0.6703 - val_ca1-[8.0,9.5): 0.5821 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9143 - val_ca1-[11.3,14.9): 1.5646 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.3699 - val_ca2-[10.3,11.3): 0.7567 - val_ca2-[11.3,14.9): 1.3181 - val_ca3-[8.0,9.5): 0.7474 - val_ca3-[9.5,10.3): 0.4563 - val_ca3-[10.3,11.3): 0.6154 - val_ca3-[11.3,14.9): 0.7941 - val_ca4-[8.0,9.5): 1.5410 - val_ca4-[9.5,10.3): 1.0822 - val_ca4-[10.3,11.3): 0.9285 - val_ca4-[11.3,14.9): 0.6625\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5201 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3290 - ca2-[9.5,10.3): 0.4146 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5078 - ca3-[10.3,11.3): 0.5825 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5414 - ca4-[11.3,14.9): 0.6612 - val_ca1-[8.0,9.5): 0.5819 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9173 - val_ca1-[11.3,14.9): 1.6082 - val_ca2-[8.0,9.5): 0.5917 - val_ca2-[9.5,10.3): 0.3684 - val_ca2-[10.3,11.3): 0.7395 - val_ca2-[11.3,14.9): 1.3024 - val_ca3-[8.0,9.5): 0.7121 - val_ca3-[9.5,10.3): 0.4313 - val_ca3-[10.3,11.3): 0.6163 - val_ca3-[11.3,14.9): 0.8555 - val_ca4-[8.0,9.5): 1.5325 - val_ca4-[9.5,10.3): 1.0719 - val_ca4-[10.3,11.3): 0.9184 - val_ca4-[11.3,14.9): 0.6860\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3234 - ca2-[9.5,10.3): 0.4104 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4858 - ca3-[10.3,11.3): 0.5742 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5338 - ca4-[11.3,14.9): 0.6671 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5934 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3681 - val_ca2-[10.3,11.3): 0.7498 - val_ca2-[11.3,14.9): 1.3230 - val_ca3-[8.0,9.5): 0.7210 - val_ca3-[9.5,10.3): 0.4375 - val_ca3-[10.3,11.3): 0.6149 - val_ca3-[11.3,14.9): 0.8326 - val_ca4-[8.0,9.5): 1.5323 - val_ca4-[9.5,10.3): 1.0684 - val_ca4-[10.3,11.3): 0.9153 - val_ca4-[11.3,14.9): 0.6723\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5094 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3136 - ca2-[9.5,10.3): 0.4024 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4972 - ca3-[10.3,11.3): 0.5655 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5321 - ca4-[11.3,14.9): 0.6690 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9110 - val_ca1-[11.3,14.9): 1.5934 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.3670 - val_ca2-[10.3,11.3): 0.7414 - val_ca2-[11.3,14.9): 1.3120 - val_ca3-[8.0,9.5): 0.7162 - val_ca3-[9.5,10.3): 0.4380 - val_ca3-[10.3,11.3): 0.6135 - val_ca3-[11.3,14.9): 0.8339 - val_ca4-[8.0,9.5): 1.5434 - val_ca4-[9.5,10.3): 1.0755 - val_ca4-[10.3,11.3): 0.9183 - val_ca4-[11.3,14.9): 0.6826\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5197 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3113 - ca2-[9.5,10.3): 0.4029 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4699 - ca3-[10.3,11.3): 0.5567 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5525 - ca4-[11.3,14.9): 0.6607 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.8925 - val_ca1-[11.3,14.9): 1.5701 - val_ca2-[8.0,9.5): 0.5824 - val_ca2-[9.5,10.3): 0.3677 - val_ca2-[10.3,11.3): 0.7396 - val_ca2-[11.3,14.9): 1.3152 - val_ca3-[8.0,9.5): 0.7161 - val_ca3-[9.5,10.3): 0.4393 - val_ca3-[10.3,11.3): 0.6032 - val_ca3-[11.3,14.9): 0.8096 - val_ca4-[8.0,9.5): 1.5328 - val_ca4-[9.5,10.3): 1.0603 - val_ca4-[10.3,11.3): 0.8991 - val_ca4-[11.3,14.9): 0.6610\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3227 - ca2-[9.5,10.3): 0.4088 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4867 - ca3-[10.3,11.3): 0.5679 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5783 - ca4-[11.3,14.9): 0.6742 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9099 - val_ca1-[11.3,14.9): 1.5920 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3668 - val_ca2-[10.3,11.3): 0.7435 - val_ca2-[11.3,14.9): 1.3178 - val_ca3-[8.0,9.5): 0.7369 - val_ca3-[9.5,10.3): 0.4554 - val_ca3-[10.3,11.3): 0.6145 - val_ca3-[11.3,14.9): 0.7959 - val_ca4-[8.0,9.5): 1.5379 - val_ca4-[9.5,10.3): 1.0619 - val_ca4-[10.3,11.3): 0.9040 - val_ca4-[11.3,14.9): 0.6576\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5203 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3145 - ca2-[9.5,10.3): 0.4116 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5179 - ca3-[10.3,11.3): 0.5831 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5838 - ca4-[11.3,14.9): 0.6574 - val_ca1-[8.0,9.5): 0.5815 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9190 - val_ca1-[11.3,14.9): 1.5688 - val_ca2-[8.0,9.5): 0.5930 - val_ca2-[9.5,10.3): 0.3663 - val_ca2-[10.3,11.3): 0.7281 - val_ca2-[11.3,14.9): 1.2505 - val_ca3-[8.0,9.5): 0.7090 - val_ca3-[9.5,10.3): 0.4368 - val_ca3-[10.3,11.3): 0.6142 - val_ca3-[11.3,14.9): 0.8158 - val_ca4-[8.0,9.5): 1.5353 - val_ca4-[9.5,10.3): 1.0565 - val_ca4-[10.3,11.3): 0.8943 - val_ca4-[11.3,14.9): 0.6578\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5243 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3179 - ca2-[9.5,10.3): 0.4026 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4968 - ca3-[10.3,11.3): 0.5589 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5434 - ca4-[11.3,14.9): 0.6574 - val_ca1-[8.0,9.5): 0.5814 - val_ca1-[9.5,10.3): 0.4202 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.6082 - val_ca2-[8.0,9.5): 0.5823 - val_ca2-[9.5,10.3): 0.3676 - val_ca2-[10.3,11.3): 0.7564 - val_ca2-[11.3,14.9): 1.3541 - val_ca3-[8.0,9.5): 0.7107 - val_ca3-[9.5,10.3): 0.4396 - val_ca3-[10.3,11.3): 0.6125 - val_ca3-[11.3,14.9): 0.8236 - val_ca4-[8.0,9.5): 1.5364 - val_ca4-[9.5,10.3): 1.0557 - val_ca4-[10.3,11.3): 0.8844 - val_ca4-[11.3,14.9): 0.6697\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5280 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3245 - ca2-[9.5,10.3): 0.3988 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4752 - ca3-[10.3,11.3): 0.5509 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5352 - ca4-[11.3,14.9): 0.6497 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4199 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5833 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3669 - val_ca2-[10.3,11.3): 0.7539 - val_ca2-[11.3,14.9): 1.3299 - val_ca3-[8.0,9.5): 0.7317 - val_ca3-[9.5,10.3): 0.4529 - val_ca3-[10.3,11.3): 0.6177 - val_ca3-[11.3,14.9): 0.8013 - val_ca4-[8.0,9.5): 1.5394 - val_ca4-[9.5,10.3): 1.0541 - val_ca4-[10.3,11.3): 0.8774 - val_ca4-[11.3,14.9): 0.6570\n",
      "CPU times: user 4min 51s, sys: 3.58 s, total: 4min 54s\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('none')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2})') for ca,(q1,q2) in product(range(4),zip(quants[:-1],quants[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "\n",
    "history = m.fit(\n",
    "    train_dataset,\n",
    "#     validation_split=0.2,\n",
    "    epochs=300,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "# with open(os.path.join(fp_local,'no_sharing.pickle'), 'wb') as handle:\n",
    "#     pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "for k in [k for k in history.history if 'val_ca1' in k]:\n",
    "    plt.plot(history.history[k], label=k.split('-')[1])\n",
    "        \n",
    "plt.legend()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ca1-[8.0,9.5)</th>\n",
       "      <td>0.535245</td>\n",
       "      <td>0.581586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[9.5,10.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.419885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[10.3,11.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.913556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.583314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[8.0,9.5)</th>\n",
       "      <td>0.3199</td>\n",
       "      <td>0.584090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[9.5,10.3)</th>\n",
       "      <td>0.401625</td>\n",
       "      <td>0.366941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[10.3,11.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.753857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.329918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[8.0,9.5)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.731701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[9.5,10.3)</th>\n",
       "      <td>0.476711</td>\n",
       "      <td>0.452902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[10.3,11.3)</th>\n",
       "      <td>0.541894</td>\n",
       "      <td>0.617743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.801322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[8.0,9.5)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.539445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[9.5,10.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.054114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[10.3,11.3)</th>\n",
       "      <td>0.532472</td>\n",
       "      <td>0.877374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[11.3,14.9)</th>\n",
       "      <td>0.68225</td>\n",
       "      <td>0.657031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train      test\n",
       "ca1-[8.0,9.5)    0.535245  0.581586\n",
       "ca1-[9.5,10.3)          -  0.419885\n",
       "ca1-[10.3,11.3)         -  0.913556\n",
       "ca1-[11.3,14.9)         -  1.583314\n",
       "ca2-[8.0,9.5)      0.3199  0.584090\n",
       "ca2-[9.5,10.3)   0.401625  0.366941\n",
       "ca2-[10.3,11.3)         -  0.753857\n",
       "ca2-[11.3,14.9)         -  1.329918\n",
       "ca3-[8.0,9.5)           -  0.731701\n",
       "ca3-[9.5,10.3)   0.476711  0.452902\n",
       "ca3-[10.3,11.3)  0.541894  0.617743\n",
       "ca3-[11.3,14.9)         -  0.801322\n",
       "ca4-[8.0,9.5)           -  1.539445\n",
       "ca4-[9.5,10.3)          -  1.054114\n",
       "ca4-[10.3,11.3)  0.532472  0.877374\n",
       "ca4-[11.3,14.9)   0.68225  0.657031"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data=[[history.history[k][-1] if history.history[k][-1]!=0 else '-',history.history['val_'+k][-1]] for k in history.history if 'val' not in k],\n",
    "    index=[k for k in history.history if 'val' not in k],\n",
    "    columns=['train','test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 35.7258 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 25.1393 - ca2-[9.5,10.3): 26.3098 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 26.9516 - ca3-[10.3,11.3): 30.1896 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 33.9205 - ca4-[11.3,14.9): 36.9218 - val_ca1-[8.0,9.5): 33.2254 - val_ca1-[9.5,10.3): 34.7467 - val_ca1-[10.3,11.3): 39.3311 - val_ca1-[11.3,14.9): 45.7539 - val_ca2-[8.0,9.5): 23.8989 - val_ca2-[9.5,10.3): 25.1148 - val_ca2-[10.3,11.3): 29.0738 - val_ca2-[11.3,14.9): 34.6114 - val_ca3-[8.0,9.5): 22.7986 - val_ca3-[9.5,10.3): 24.0028 - val_ca3-[10.3,11.3): 27.8744 - val_ca3-[11.3,14.9): 33.2806 - val_ca4-[8.0,9.5): 24.2383 - val_ca4-[9.5,10.3): 25.4981 - val_ca4-[10.3,11.3): 29.4465 - val_ca4-[11.3,14.9): 34.9687\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 33.1961 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 23.4670 - ca2-[9.5,10.3): 24.4686 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 24.4398 - ca3-[10.3,11.3): 27.2946 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 31.6503 - ca4-[11.3,14.9): 34.1949 - val_ca1-[8.0,9.5): 30.8486 - val_ca1-[9.5,10.3): 32.3081 - val_ca1-[10.3,11.3): 36.7769 - val_ca1-[11.3,14.9): 43.2450 - val_ca2-[8.0,9.5): 22.1244 - val_ca2-[9.5,10.3): 23.2948 - val_ca2-[10.3,11.3): 27.1481 - val_ca2-[11.3,14.9): 32.7065 - val_ca3-[8.0,9.5): 20.4669 - val_ca3-[9.5,10.3): 21.6141 - val_ca3-[10.3,11.3): 25.3343 - val_ca3-[11.3,14.9): 30.6893 - val_ca4-[8.0,9.5): 22.1926 - val_ca4-[9.5,10.3): 23.3850 - val_ca4-[10.3,11.3): 27.2161 - val_ca4-[11.3,14.9): 32.7307\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 30.8041 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 21.4955 - ca2-[9.5,10.3): 22.5295 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 22.3297 - ca3-[10.3,11.3): 24.9286 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 29.5790 - ca4-[11.3,14.9): 31.8399 - val_ca1-[8.0,9.5): 28.5609 - val_ca1-[9.5,10.3): 29.9606 - val_ca1-[10.3,11.3): 34.1759 - val_ca1-[11.3,14.9): 40.4534 - val_ca2-[8.0,9.5): 20.4456 - val_ca2-[9.5,10.3): 21.5842 - val_ca2-[10.3,11.3): 25.2235 - val_ca2-[11.3,14.9): 30.6178 - val_ca3-[8.0,9.5): 18.3348 - val_ca3-[9.5,10.3): 19.4196 - val_ca3-[10.3,11.3): 22.8857 - val_ca3-[11.3,14.9): 28.0165 - val_ca4-[8.0,9.5): 20.3951 - val_ca4-[9.5,10.3): 21.5364 - val_ca4-[10.3,11.3): 25.1584 - val_ca4-[11.3,14.9): 30.5115\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 28.5347 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 20.1118 - ca2-[9.5,10.3): 20.8866 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 19.9292 - ca3-[10.3,11.3): 22.5084 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 27.7274 - ca4-[11.3,14.9): 29.7717 - val_ca1-[8.0,9.5): 26.3677 - val_ca1-[9.5,10.3): 27.7203 - val_ca1-[10.3,11.3): 31.8383 - val_ca1-[11.3,14.9): 37.9139 - val_ca2-[8.0,9.5): 18.8697 - val_ca2-[9.5,10.3): 19.9711 - val_ca2-[10.3,11.3): 23.5252 - val_ca2-[11.3,14.9): 28.7560 - val_ca3-[8.0,9.5): 16.4025 - val_ca3-[9.5,10.3): 17.4195 - val_ca3-[10.3,11.3): 20.7565 - val_ca3-[11.3,14.9): 25.6671 - val_ca4-[8.0,9.5): 18.8428 - val_ca4-[9.5,10.3): 19.9387 - val_ca4-[10.3,11.3): 23.4877 - val_ca4-[11.3,14.9): 28.6872\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 26.3318 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 18.4151 - ca2-[9.5,10.3): 19.4081 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 17.7157 - ca3-[10.3,11.3): 20.4025 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 25.3709 - ca4-[11.3,14.9): 28.0564 - val_ca1-[8.0,9.5): 24.3360 - val_ca1-[9.5,10.3): 25.6284 - val_ca1-[10.3,11.3): 29.6339 - val_ca1-[11.3,14.9): 35.2505 - val_ca2-[8.0,9.5): 17.3989 - val_ca2-[9.5,10.3): 18.4533 - val_ca2-[10.3,11.3): 21.9099 - val_ca2-[11.3,14.9): 26.7449 - val_ca3-[8.0,9.5): 14.6521 - val_ca3-[9.5,10.3): 15.6035 - val_ca3-[10.3,11.3): 18.8059 - val_ca3-[11.3,14.9): 23.2910 - val_ca4-[8.0,9.5): 17.4982 - val_ca4-[9.5,10.3): 18.5455 - val_ca4-[10.3,11.3): 22.0073 - val_ca4-[11.3,14.9): 26.8332\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 24.3896 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 17.1094 - ca2-[9.5,10.3): 18.0056 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 16.4028 - ca3-[10.3,11.3): 18.4630 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 24.3082 - ca4-[11.3,14.9): 26.4069 - val_ca1-[8.0,9.5): 22.4566 - val_ca1-[9.5,10.3): 23.6832 - val_ca1-[10.3,11.3): 27.5248 - val_ca1-[11.3,14.9): 32.8739 - val_ca2-[8.0,9.5): 16.0178 - val_ca2-[9.5,10.3): 17.0178 - val_ca2-[10.3,11.3): 20.3305 - val_ca2-[11.3,14.9): 24.9313 - val_ca3-[8.0,9.5): 13.0778 - val_ca3-[9.5,10.3): 13.9672 - val_ca3-[10.3,11.3): 16.9964 - val_ca3-[11.3,14.9): 21.2116 - val_ca4-[8.0,9.5): 16.2778 - val_ca4-[9.5,10.3): 17.2789 - val_ca4-[10.3,11.3): 20.6053 - val_ca4-[11.3,14.9): 25.2199\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 22.4155 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 15.5829 - ca2-[9.5,10.3): 16.4560 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 14.8242 - ca3-[10.3,11.3): 16.8171 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 22.7174 - ca4-[11.3,14.9): 24.8343 - val_ca1-[8.0,9.5): 20.7162 - val_ca1-[9.5,10.3): 21.8866 - val_ca1-[10.3,11.3): 25.6453 - val_ca1-[11.3,14.9): 30.8436 - val_ca2-[8.0,9.5): 14.7036 - val_ca2-[9.5,10.3): 15.6512 - val_ca2-[10.3,11.3): 18.8874 - val_ca2-[11.3,14.9): 23.3502 - val_ca3-[8.0,9.5): 11.6948 - val_ca3-[9.5,10.3): 12.5248 - val_ca3-[10.3,11.3): 15.4439 - val_ca3-[11.3,14.9): 19.4845 - val_ca4-[8.0,9.5): 15.1357 - val_ca4-[9.5,10.3): 16.0954 - val_ca4-[10.3,11.3): 19.3614 - val_ca4-[11.3,14.9): 23.8666\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 20.7461 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 14.1971 - ca2-[9.5,10.3): 15.0952 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 12.8437 - ca3-[10.3,11.3): 15.1714 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 21.0849 - ca4-[11.3,14.9): 23.5302 - val_ca1-[8.0,9.5): 19.1067 - val_ca1-[9.5,10.3): 20.2524 - val_ca1-[10.3,11.3): 23.7895 - val_ca1-[11.3,14.9): 28.8982 - val_ca2-[8.0,9.5): 13.4370 - val_ca2-[9.5,10.3): 14.3568 - val_ca2-[10.3,11.3): 17.3902 - val_ca2-[11.3,14.9): 21.7646 - val_ca3-[8.0,9.5): 10.4667 - val_ca3-[9.5,10.3): 11.2511 - val_ca3-[10.3,11.3): 13.9535 - val_ca3-[11.3,14.9): 17.8780 - val_ca4-[8.0,9.5): 14.0734 - val_ca4-[9.5,10.3): 15.0033 - val_ca4-[10.3,11.3): 18.0809 - val_ca4-[11.3,14.9): 22.5334\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 19.1940 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 13.1019 - ca2-[9.5,10.3): 13.9368 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 11.8617 - ca3-[10.3,11.3): 13.7542 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 20.2274 - ca4-[11.3,14.9): 22.1124 - val_ca1-[8.0,9.5): 17.6590 - val_ca1-[9.5,10.3): 18.7500 - val_ca1-[10.3,11.3): 22.1695 - val_ca1-[11.3,14.9): 27.3184 - val_ca2-[8.0,9.5): 12.2480 - val_ca2-[9.5,10.3): 13.1104 - val_ca2-[10.3,11.3): 16.0168 - val_ca2-[11.3,14.9): 20.4010 - val_ca3-[8.0,9.5): 9.3496 - val_ca3-[9.5,10.3): 10.0693 - val_ca3-[10.3,11.3): 12.6311 - val_ca3-[11.3,14.9): 16.5331 - val_ca4-[8.0,9.5): 13.0472 - val_ca4-[9.5,10.3): 13.9213 - val_ca4-[10.3,11.3): 16.8931 - val_ca4-[11.3,14.9): 21.3931\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 17.7674 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 11.8935 - ca2-[9.5,10.3): 12.6770 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 10.4863 - ca3-[10.3,11.3): 12.4852 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 19.1508 - ca4-[11.3,14.9): 20.7854 - val_ca1-[8.0,9.5): 16.3691 - val_ca1-[9.5,10.3): 17.4204 - val_ca1-[10.3,11.3): 20.7927 - val_ca1-[11.3,14.9): 25.4328 - val_ca2-[8.0,9.5): 11.1266 - val_ca2-[9.5,10.3): 11.9427 - val_ca2-[10.3,11.3): 14.7888 - val_ca2-[11.3,14.9): 18.7059 - val_ca3-[8.0,9.5): 8.3354 - val_ca3-[9.5,10.3): 9.0054 - val_ca3-[10.3,11.3): 11.4956 - val_ca3-[11.3,14.9): 14.9555 - val_ca4-[8.0,9.5): 12.0609 - val_ca4-[9.5,10.3): 12.8978 - val_ca4-[10.3,11.3): 15.8331 - val_ca4-[11.3,14.9): 19.8848\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 16.5079 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 10.6991 - ca2-[9.5,10.3): 11.5088 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 9.3907 - ca3-[10.3,11.3): 11.3383 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 17.6498 - ca4-[11.3,14.9): 19.6374 - val_ca1-[8.0,9.5): 15.1916 - val_ca1-[9.5,10.3): 16.2033 - val_ca1-[10.3,11.3): 19.4415 - val_ca1-[11.3,14.9): 23.9934 - val_ca2-[8.0,9.5): 10.0606 - val_ca2-[9.5,10.3): 10.8293 - val_ca2-[10.3,11.3): 13.5328 - val_ca2-[11.3,14.9): 17.3335 - val_ca3-[8.0,9.5): 7.4133 - val_ca3-[9.5,10.3): 8.0364 - val_ca3-[10.3,11.3): 10.3847 - val_ca3-[11.3,14.9): 13.7200 - val_ca4-[8.0,9.5): 11.1371 - val_ca4-[9.5,10.3): 11.9374 - val_ca4-[10.3,11.3): 14.7519 - val_ca4-[11.3,14.9): 18.7201\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 15.2283 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 9.8241 - ca2-[9.5,10.3): 10.4672 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 8.6765 - ca3-[10.3,11.3): 10.2870 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 16.3894 - ca4-[11.3,14.9): 18.4598 - val_ca1-[8.0,9.5): 14.0985 - val_ca1-[9.5,10.3): 15.0747 - val_ca1-[10.3,11.3): 18.2474 - val_ca1-[11.3,14.9): 22.5683 - val_ca2-[8.0,9.5): 9.0453 - val_ca2-[9.5,10.3): 9.7661 - val_ca2-[10.3,11.3): 12.3781 - val_ca2-[11.3,14.9): 15.9446 - val_ca3-[8.0,9.5): 6.5695 - val_ca3-[9.5,10.3): 7.1461 - val_ca3-[10.3,11.3): 9.4025 - val_ca3-[11.3,14.9): 12.5160 - val_ca4-[8.0,9.5): 10.2754 - val_ca4-[9.5,10.3): 11.0388 - val_ca4-[10.3,11.3): 13.7879 - val_ca4-[11.3,14.9): 17.5488\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 14.1972 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 8.6356 - ca2-[9.5,10.3): 9.3449 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 7.6186 - ca3-[10.3,11.3): 9.2956 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 15.6180 - ca4-[11.3,14.9): 17.3157 - val_ca1-[8.0,9.5): 13.1313 - val_ca1-[9.5,10.3): 14.0701 - val_ca1-[10.3,11.3): 17.1192 - val_ca1-[11.3,14.9): 21.5852 - val_ca2-[8.0,9.5): 8.0926 - val_ca2-[9.5,10.3): 8.7653 - val_ca2-[10.3,11.3): 11.2352 - val_ca2-[11.3,14.9): 14.8593 - val_ca3-[8.0,9.5): 5.8027 - val_ca3-[9.5,10.3): 6.3330 - val_ca3-[10.3,11.3): 8.4569 - val_ca3-[11.3,14.9): 11.6033 - val_ca4-[8.0,9.5): 9.4628 - val_ca4-[9.5,10.3): 10.1895 - val_ca4-[10.3,11.3): 12.8194 - val_ca4-[11.3,14.9): 16.6878\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 13.1797 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 7.7291 - ca2-[9.5,10.3): 8.4096 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 6.8764 - ca3-[10.3,11.3): 8.3032 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 14.6681 - ca4-[11.3,14.9): 16.1624 - val_ca1-[8.0,9.5): 12.2529 - val_ca1-[9.5,10.3): 13.1563 - val_ca1-[10.3,11.3): 16.1196 - val_ca1-[11.3,14.9): 20.3667 - val_ca2-[8.0,9.5): 7.2062 - val_ca2-[9.5,10.3): 7.8308 - val_ca2-[10.3,11.3): 10.1851 - val_ca2-[11.3,14.9): 13.5627 - val_ca3-[8.0,9.5): 5.1133 - val_ca3-[9.5,10.3): 5.5987 - val_ca3-[10.3,11.3): 7.6156 - val_ca3-[11.3,14.9): 10.5341 - val_ca4-[8.0,9.5): 8.6944 - val_ca4-[9.5,10.3): 9.3847 - val_ca4-[10.3,11.3): 11.9227 - val_ca4-[11.3,14.9): 15.5747\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 12.3214 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 6.9594 - ca2-[9.5,10.3): 7.5089 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 5.8323 - ca3-[10.3,11.3): 7.5013 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 13.5820 - ca4-[11.3,14.9): 15.1537 - val_ca1-[8.0,9.5): 11.4361 - val_ca1-[9.5,10.3): 12.3054 - val_ca1-[10.3,11.3): 15.1863 - val_ca1-[11.3,14.9): 19.3362 - val_ca2-[8.0,9.5): 6.3935 - val_ca2-[9.5,10.3): 6.9709 - val_ca2-[10.3,11.3): 9.2120 - val_ca2-[11.3,14.9): 12.4512 - val_ca3-[8.0,9.5): 4.4973 - val_ca3-[9.5,10.3): 4.9403 - val_ca3-[10.3,11.3): 6.8534 - val_ca3-[11.3,14.9): 9.6425 - val_ca4-[8.0,9.5): 7.9660 - val_ca4-[9.5,10.3): 8.6205 - val_ca4-[10.3,11.3): 11.0676 - val_ca4-[11.3,14.9): 14.6128\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 116ms/step - ca1-[8.0,9.5): 11.5362 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 6.0510 - ca2-[9.5,10.3): 6.6869 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 5.2929 - ca3-[10.3,11.3): 6.7702 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 12.8545 - ca4-[11.3,14.9): 14.3343 - val_ca1-[8.0,9.5): 10.6699 - val_ca1-[9.5,10.3): 11.5049 - val_ca1-[10.3,11.3): 14.3046 - val_ca1-[11.3,14.9): 18.1914 - val_ca2-[8.0,9.5): 5.6579 - val_ca2-[9.5,10.3): 6.1892 - val_ca2-[10.3,11.3): 8.3199 - val_ca2-[11.3,14.9): 11.2822 - val_ca3-[8.0,9.5): 3.9462 - val_ca3-[9.5,10.3): 4.3486 - val_ca3-[10.3,11.3): 6.1628 - val_ca3-[11.3,14.9): 8.7002 - val_ca4-[8.0,9.5): 7.2818 - val_ca4-[9.5,10.3): 7.9000 - val_ca4-[10.3,11.3): 10.2560 - val_ca4-[11.3,14.9): 13.5428\n",
      "Epoch 17/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 118ms/step - ca1-[8.0,9.5): 10.8251 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 5.3723 - ca2-[9.5,10.3): 5.9700 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 4.7088 - ca3-[10.3,11.3): 6.1380 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 11.7437 - ca4-[11.3,14.9): 13.3005 - val_ca1-[8.0,9.5): 9.9492 - val_ca1-[9.5,10.3): 10.7503 - val_ca1-[10.3,11.3): 13.4438 - val_ca1-[11.3,14.9): 17.2489 - val_ca2-[8.0,9.5): 4.9951 - val_ca2-[9.5,10.3): 5.4817 - val_ca2-[10.3,11.3): 7.4862 - val_ca2-[11.3,14.9): 10.3245 - val_ca3-[8.0,9.5): 3.4562 - val_ca3-[9.5,10.3): 3.8191 - val_ca3-[10.3,11.3): 5.5219 - val_ca3-[11.3,14.9): 7.9468 - val_ca4-[8.0,9.5): 6.6437 - val_ca4-[9.5,10.3): 7.2253 - val_ca4-[10.3,11.3): 9.4688 - val_ca4-[11.3,14.9): 12.6579\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 10.0799 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 4.7057 - ca2-[9.5,10.3): 5.2854 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 4.2300 - ca3-[10.3,11.3): 5.4749 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 11.0366 - ca4-[11.3,14.9): 12.4539 - val_ca1-[8.0,9.5): 9.2687 - val_ca1-[9.5,10.3): 10.0272 - val_ca1-[10.3,11.3): 12.7205 - val_ca1-[11.3,14.9): 16.5928 - val_ca2-[8.0,9.5): 4.4046 - val_ca2-[9.5,10.3): 4.8431 - val_ca2-[10.3,11.3): 6.8038 - val_ca2-[11.3,14.9): 9.6275 - val_ca3-[8.0,9.5): 3.0222 - val_ca3-[9.5,10.3): 3.3423 - val_ca3-[10.3,11.3): 5.0030 - val_ca3-[11.3,14.9): 7.4059 - val_ca4-[8.0,9.5): 6.0460 - val_ca4-[9.5,10.3): 6.5843 - val_ca4-[10.3,11.3): 8.8036 - val_ca4-[11.3,14.9): 12.0179\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 9.3567 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 4.2190 - ca2-[9.5,10.3): 4.6828 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 3.7410 - ca3-[10.3,11.3): 4.9666 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 9.8893 - ca4-[11.3,14.9): 11.5849 - val_ca1-[8.0,9.5): 8.6292 - val_ca1-[9.5,10.3): 9.3630 - val_ca1-[10.3,11.3): 11.9252 - val_ca1-[11.3,14.9): 15.6275 - val_ca2-[8.0,9.5): 3.8794 - val_ca2-[9.5,10.3): 4.2838 - val_ca2-[10.3,11.3): 6.1085 - val_ca2-[11.3,14.9): 8.7429 - val_ca3-[8.0,9.5): 2.6431 - val_ca3-[9.5,10.3): 2.9312 - val_ca3-[10.3,11.3): 4.4724 - val_ca3-[11.3,14.9): 6.7055 - val_ca4-[8.0,9.5): 5.4794 - val_ca4-[9.5,10.3): 5.9890 - val_ca4-[10.3,11.3): 8.0764 - val_ca4-[11.3,14.9): 11.1131\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 8.7198 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 3.5480 - ca2-[9.5,10.3): 4.1164 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 3.2932 - ca3-[10.3,11.3): 4.4411 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 9.2041 - ca4-[11.3,14.9): 10.7603 - val_ca1-[8.0,9.5): 8.0277 - val_ca1-[9.5,10.3): 8.7284 - val_ca1-[10.3,11.3): 11.1822 - val_ca1-[11.3,14.9): 14.8323 - val_ca2-[8.0,9.5): 3.4155 - val_ca2-[9.5,10.3): 3.7818 - val_ca2-[10.3,11.3): 5.4897 - val_ca2-[11.3,14.9): 8.0370 - val_ca3-[8.0,9.5): 2.3138 - val_ca3-[9.5,10.3): 2.5671 - val_ca3-[10.3,11.3): 4.0064 - val_ca3-[11.3,14.9): 6.1628 - val_ca4-[8.0,9.5): 4.9598 - val_ca4-[9.5,10.3): 5.4332 - val_ca4-[10.3,11.3): 7.4103 - val_ca4-[11.3,14.9): 10.3769\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 8.0994 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 3.2023 - ca2-[9.5,10.3): 3.6590 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.8533 - ca3-[10.3,11.3): 4.0112 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 8.6921 - ca4-[11.3,14.9): 10.1151 - val_ca1-[8.0,9.5): 7.4637 - val_ca1-[9.5,10.3): 8.1313 - val_ca1-[10.3,11.3): 10.5645 - val_ca1-[11.3,14.9): 13.8693 - val_ca2-[8.0,9.5): 3.0041 - val_ca2-[9.5,10.3): 3.3330 - val_ca2-[10.3,11.3): 4.9915 - val_ca2-[11.3,14.9): 7.2444 - val_ca3-[8.0,9.5): 2.0224 - val_ca3-[9.5,10.3): 2.2414 - val_ca3-[10.3,11.3): 3.6340 - val_ca3-[11.3,14.9): 5.5337 - val_ca4-[8.0,9.5): 4.4925 - val_ca4-[9.5,10.3): 4.9318 - val_ca4-[10.3,11.3): 6.8729 - val_ca4-[11.3,14.9): 9.5316\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 7.5686 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.8002 - ca2-[9.5,10.3): 3.2452 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.4701 - ca3-[10.3,11.3): 3.6000 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 7.8510 - ca4-[11.3,14.9): 9.2858 - val_ca1-[8.0,9.5): 6.9385 - val_ca1-[9.5,10.3): 7.5741 - val_ca1-[10.3,11.3): 9.9395 - val_ca1-[11.3,14.9): 13.2666 - val_ca2-[8.0,9.5): 2.6402 - val_ca2-[9.5,10.3): 2.9327 - val_ca2-[10.3,11.3): 4.5051 - val_ca2-[11.3,14.9): 6.7205 - val_ca3-[8.0,9.5): 1.7670 - val_ca3-[9.5,10.3): 1.9531 - val_ca3-[10.3,11.3): 3.2663 - val_ca3-[11.3,14.9): 5.1263 - val_ca4-[8.0,9.5): 4.0693 - val_ca4-[9.5,10.3): 4.4763 - val_ca4-[10.3,11.3): 6.3404 - val_ca4-[11.3,14.9): 8.9857\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 116ms/step - ca1-[8.0,9.5): 6.9846 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.4053 - ca2-[9.5,10.3): 2.8489 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.2715 - ca3-[10.3,11.3): 3.2479 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 7.4386 - ca4-[11.3,14.9): 8.7499 - val_ca1-[8.0,9.5): 6.4514 - val_ca1-[9.5,10.3): 7.0560 - val_ca1-[10.3,11.3): 9.3456 - val_ca1-[11.3,14.9): 12.4777 - val_ca2-[8.0,9.5): 2.3186 - val_ca2-[9.5,10.3): 2.5766 - val_ca2-[10.3,11.3): 4.0669 - val_ca2-[11.3,14.9): 6.1010 - val_ca3-[8.0,9.5): 1.5480 - val_ca3-[9.5,10.3): 1.7028 - val_ca3-[10.3,11.3): 2.9445 - val_ca3-[11.3,14.9): 4.6441 - val_ca4-[8.0,9.5): 3.6805 - val_ca4-[9.5,10.3): 4.0558 - val_ca4-[10.3,11.3): 5.8417 - val_ca4-[11.3,14.9): 8.3033\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 6.5443 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.1074 - ca2-[9.5,10.3): 2.4940 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.9872 - ca3-[10.3,11.3): 2.8942 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 6.9083 - ca4-[11.3,14.9): 8.1150 - val_ca1-[8.0,9.5): 5.9972 - val_ca1-[9.5,10.3): 6.5715 - val_ca1-[10.3,11.3): 8.8161 - val_ca1-[11.3,14.9): 11.9972 - val_ca2-[8.0,9.5): 2.0383 - val_ca2-[9.5,10.3): 2.2637 - val_ca2-[10.3,11.3): 3.6856 - val_ca2-[11.3,14.9): 5.7074 - val_ca3-[8.0,9.5): 1.3599 - val_ca3-[9.5,10.3): 1.4849 - val_ca3-[10.3,11.3): 2.6624 - val_ca3-[11.3,14.9): 4.3460 - val_ca4-[8.0,9.5): 3.3253 - val_ca4-[9.5,10.3): 3.6697 - val_ca4-[10.3,11.3): 5.3976 - val_ca4-[11.3,14.9): 7.8724\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 6.0754 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.8839 - ca2-[9.5,10.3): 2.2292 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.7421 - ca3-[10.3,11.3): 2.6289 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 6.2003 - ca4-[11.3,14.9): 7.5514 - val_ca1-[8.0,9.5): 5.5756 - val_ca1-[9.5,10.3): 6.1206 - val_ca1-[10.3,11.3): 8.2291 - val_ca1-[11.3,14.9): 11.3549 - val_ca2-[8.0,9.5): 1.7953 - val_ca2-[9.5,10.3): 1.9894 - val_ca2-[10.3,11.3): 3.2896 - val_ca2-[11.3,14.9): 5.2283 - val_ca3-[8.0,9.5): 1.1992 - val_ca3-[9.5,10.3): 1.2958 - val_ca3-[10.3,11.3): 2.3657 - val_ca3-[11.3,14.9): 3.9717 - val_ca4-[8.0,9.5): 3.0033 - val_ca4-[9.5,10.3): 3.3179 - val_ca4-[10.3,11.3): 4.9190 - val_ca4-[11.3,14.9): 7.3210\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 5.6930 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.6367 - ca2-[9.5,10.3): 1.9739 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.6098 - ca3-[10.3,11.3): 2.3570 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.9743 - ca4-[11.3,14.9): 7.0701 - val_ca1-[8.0,9.5): 5.1855 - val_ca1-[9.5,10.3): 5.7024 - val_ca1-[10.3,11.3): 7.7916 - val_ca1-[11.3,14.9): 10.7028 - val_ca2-[8.0,9.5): 1.5840 - val_ca2-[9.5,10.3): 1.7480 - val_ca2-[10.3,11.3): 3.0136 - val_ca2-[11.3,14.9): 4.7690 - val_ca3-[8.0,9.5): 1.0626 - val_ca3-[9.5,10.3): 1.1320 - val_ca3-[10.3,11.3): 2.1715 - val_ca3-[11.3,14.9): 3.6152 - val_ca4-[8.0,9.5): 2.7120 - val_ca4-[9.5,10.3): 2.9980 - val_ca4-[10.3,11.3): 4.5706 - val_ca4-[11.3,14.9): 6.7772\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 116ms/step - ca1-[8.0,9.5): 5.2822 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.3516 - ca2-[9.5,10.3): 1.6931 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.2475 - ca3-[10.3,11.3): 2.1608 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.5881 - ca4-[11.3,14.9): 6.6301 - val_ca1-[8.0,9.5): 4.8255 - val_ca1-[9.5,10.3): 5.3154 - val_ca1-[10.3,11.3): 7.3152 - val_ca1-[11.3,14.9): 10.1046 - val_ca2-[8.0,9.5): 1.4021 - val_ca2-[9.5,10.3): 1.5374 - val_ca2-[10.3,11.3): 2.7177 - val_ca2-[11.3,14.9): 4.3495 - val_ca3-[8.0,9.5): 0.9472 - val_ca3-[9.5,10.3): 0.9904 - val_ca3-[10.3,11.3): 1.9530 - val_ca3-[11.3,14.9): 3.2825 - val_ca4-[8.0,9.5): 2.4496 - val_ca4-[9.5,10.3): 2.7082 - val_ca4-[10.3,11.3): 4.1942 - val_ca4-[11.3,14.9): 6.2758\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 4.9429 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.2215 - ca2-[9.5,10.3): 1.5440 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.2165 - ca3-[10.3,11.3): 1.9374 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.0015 - ca4-[11.3,14.9): 6.1673 - val_ca1-[8.0,9.5): 4.4932 - val_ca1-[9.5,10.3): 4.9572 - val_ca1-[10.3,11.3): 6.9250 - val_ca1-[11.3,14.9): 9.6919 - val_ca2-[8.0,9.5): 1.2449 - val_ca2-[9.5,10.3): 1.3530 - val_ca2-[10.3,11.3): 2.4859 - val_ca2-[11.3,14.9): 4.0663 - val_ca3-[8.0,9.5): 0.8520 - val_ca3-[9.5,10.3): 0.8702 - val_ca3-[10.3,11.3): 1.7885 - val_ca3-[11.3,14.9): 3.0684 - val_ca4-[8.0,9.5): 2.2127 - val_ca4-[9.5,10.3): 2.4448 - val_ca4-[10.3,11.3): 3.8880 - val_ca4-[11.3,14.9): 5.9283\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 4.5643 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.0417 - ca2-[9.5,10.3): 1.3515 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.0946 - ca3-[10.3,11.3): 1.7745 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.5911 - ca4-[11.3,14.9): 5.7640 - val_ca1-[8.0,9.5): 4.1868 - val_ca1-[9.5,10.3): 4.6259 - val_ca1-[10.3,11.3): 6.5186 - val_ca1-[11.3,14.9): 9.2071 - val_ca2-[8.0,9.5): 1.1110 - val_ca2-[9.5,10.3): 1.1931 - val_ca2-[10.3,11.3): 2.2545 - val_ca2-[11.3,14.9): 3.7388 - val_ca3-[8.0,9.5): 0.7738 - val_ca3-[9.5,10.3): 0.7681 - val_ca3-[10.3,11.3): 1.6217 - val_ca3-[11.3,14.9): 2.8101 - val_ca4-[8.0,9.5): 1.9992 - val_ca4-[9.5,10.3): 2.2058 - val_ca4-[10.3,11.3): 3.5746 - val_ca4-[11.3,14.9): 5.5226\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 4.2576 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.8992 - ca2-[9.5,10.3): 1.1845 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.9691 - ca3-[10.3,11.3): 1.6050 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.4152 - ca4-[11.3,14.9): 5.3849 - val_ca1-[8.0,9.5): 3.9045 - val_ca1-[9.5,10.3): 4.3198 - val_ca1-[10.3,11.3): 6.1749 - val_ca1-[11.3,14.9): 8.7263 - val_ca2-[8.0,9.5): 0.9979 - val_ca2-[9.5,10.3): 1.0554 - val_ca2-[10.3,11.3): 2.0669 - val_ca2-[11.3,14.9): 3.4453 - val_ca3-[8.0,9.5): 0.7111 - val_ca3-[9.5,10.3): 0.6824 - val_ca3-[10.3,11.3): 1.4881 - val_ca3-[11.3,14.9): 2.5838 - val_ca4-[8.0,9.5): 1.8082 - val_ca4-[9.5,10.3): 1.9903 - val_ca4-[10.3,11.3): 3.3124 - val_ca4-[11.3,14.9): 5.1392\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 3.9848 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.8156 - ca2-[9.5,10.3): 1.0734 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.8573 - ca3-[10.3,11.3): 1.4615 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.2046 - ca4-[11.3,14.9): 5.0343 - val_ca1-[8.0,9.5): 3.6441 - val_ca1-[9.5,10.3): 4.0365 - val_ca1-[10.3,11.3): 5.8575 - val_ca1-[11.3,14.9): 8.2525 - val_ca2-[8.0,9.5): 0.9030 - val_ca2-[9.5,10.3): 0.9373 - val_ca2-[10.3,11.3): 1.8990 - val_ca2-[11.3,14.9): 3.1465 - val_ca3-[8.0,9.5): 0.6626 - val_ca3-[9.5,10.3): 0.6120 - val_ca3-[10.3,11.3): 1.3682 - val_ca3-[11.3,14.9): 2.3446 - val_ca4-[8.0,9.5): 1.6376 - val_ca4-[9.5,10.3): 1.7962 - val_ca4-[10.3,11.3): 3.0723 - val_ca4-[11.3,14.9): 4.7558\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 3.6678 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.7101 - ca2-[9.5,10.3): 0.9605 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.7552 - ca3-[10.3,11.3): 1.3502 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.8758 - ca4-[11.3,14.9): 4.7600 - val_ca1-[8.0,9.5): 3.4041 - val_ca1-[9.5,10.3): 3.7744 - val_ca1-[10.3,11.3): 5.5259 - val_ca1-[11.3,14.9): 8.0094 - val_ca2-[8.0,9.5): 0.8241 - val_ca2-[9.5,10.3): 0.8363 - val_ca2-[10.3,11.3): 1.7401 - val_ca2-[11.3,14.9): 3.0103 - val_ca3-[8.0,9.5): 0.6261 - val_ca3-[9.5,10.3): 0.5547 - val_ca3-[10.3,11.3): 1.2592 - val_ca3-[11.3,14.9): 2.2479 - val_ca4-[8.0,9.5): 1.4858 - val_ca4-[9.5,10.3): 1.6219 - val_ca4-[10.3,11.3): 2.8334 - val_ca4-[11.3,14.9): 4.5592\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 116ms/step - ca1-[8.0,9.5): 3.4619 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.6303 - ca2-[9.5,10.3): 0.8573 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.7138 - ca3-[10.3,11.3): 1.2482 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.5230 - ca4-[11.3,14.9): 4.3811 - val_ca1-[8.0,9.5): 3.1830 - val_ca1-[9.5,10.3): 3.5322 - val_ca1-[10.3,11.3): 5.2350 - val_ca1-[11.3,14.9): 7.6157 - val_ca2-[8.0,9.5): 0.7593 - val_ca2-[9.5,10.3): 0.7507 - val_ca2-[10.3,11.3): 1.6049 - val_ca2-[11.3,14.9): 2.7799 - val_ca3-[8.0,9.5): 0.6004 - val_ca3-[9.5,10.3): 0.5089 - val_ca3-[10.3,11.3): 1.1659 - val_ca3-[11.3,14.9): 2.0638 - val_ca4-[8.0,9.5): 1.3512 - val_ca4-[9.5,10.3): 1.4657 - val_ca4-[10.3,11.3): 2.6253 - val_ca4-[11.3,14.9): 4.2497\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 117ms/step - ca1-[8.0,9.5): 3.2315 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.5837 - ca2-[9.5,10.3): 0.7952 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6319 - ca3-[10.3,11.3): 1.1578 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.2579 - ca4-[11.3,14.9): 4.1281 - val_ca1-[8.0,9.5): 2.9799 - val_ca1-[9.5,10.3): 3.3089 - val_ca1-[10.3,11.3): 4.9515 - val_ca1-[11.3,14.9): 7.3285 - val_ca2-[8.0,9.5): 0.7070 - val_ca2-[9.5,10.3): 0.6786 - val_ca2-[10.3,11.3): 1.4819 - val_ca2-[11.3,14.9): 2.6268 - val_ca3-[8.0,9.5): 0.5843 - val_ca3-[9.5,10.3): 0.4737 - val_ca3-[10.3,11.3): 1.0837 - val_ca3-[11.3,14.9): 1.9482 - val_ca4-[8.0,9.5): 1.2321 - val_ca4-[9.5,10.3): 1.3260 - val_ca4-[10.3,11.3): 2.4279 - val_ca4-[11.3,14.9): 4.0266\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 3.0407 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4903 - ca2-[9.5,10.3): 0.7360 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6079 - ca3-[10.3,11.3): 1.0531 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.0186 - ca4-[11.3,14.9): 3.8579 - val_ca1-[8.0,9.5): 2.7933 - val_ca1-[9.5,10.3): 3.1031 - val_ca1-[10.3,11.3): 4.7166 - val_ca1-[11.3,14.9): 6.9973 - val_ca2-[8.0,9.5): 0.6655 - val_ca2-[9.5,10.3): 0.6185 - val_ca2-[10.3,11.3): 1.3847 - val_ca2-[11.3,14.9): 2.4265 - val_ca3-[8.0,9.5): 0.5766 - val_ca3-[9.5,10.3): 0.4478 - val_ca3-[10.3,11.3): 1.0207 - val_ca3-[11.3,14.9): 1.7828 - val_ca4-[8.0,9.5): 1.1271 - val_ca4-[9.5,10.3): 1.2011 - val_ca4-[10.3,11.3): 2.2659 - val_ca4-[11.3,14.9): 3.7575\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 2.8448 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4769 - ca2-[9.5,10.3): 0.6850 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5788 - ca3-[10.3,11.3): 1.0197 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.5482 - ca4-[11.3,14.9): 3.6074 - val_ca1-[8.0,9.5): 2.6216 - val_ca1-[9.5,10.3): 2.9131 - val_ca1-[10.3,11.3): 4.4832 - val_ca1-[11.3,14.9): 6.6851 - val_ca2-[8.0,9.5): 0.6334 - val_ca2-[9.5,10.3): 0.5688 - val_ca2-[10.3,11.3): 1.2913 - val_ca2-[11.3,14.9): 2.2793 - val_ca3-[8.0,9.5): 0.5761 - val_ca3-[9.5,10.3): 0.4299 - val_ca3-[10.3,11.3): 0.9600 - val_ca3-[11.3,14.9): 1.6748 - val_ca4-[8.0,9.5): 1.0352 - val_ca4-[9.5,10.3): 1.0902 - val_ca4-[10.3,11.3): 2.1078 - val_ca4-[11.3,14.9): 3.5311\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 2.6795 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4234 - ca2-[9.5,10.3): 0.6252 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5051 - ca3-[10.3,11.3): 0.9514 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.6666 - ca4-[11.3,14.9): 3.4188 - val_ca1-[8.0,9.5): 2.4641 - val_ca1-[9.5,10.3): 2.7380 - val_ca1-[10.3,11.3): 4.2520 - val_ca1-[11.3,14.9): 6.4104 - val_ca2-[8.0,9.5): 0.6096 - val_ca2-[9.5,10.3): 0.5285 - val_ca2-[10.3,11.3): 1.2037 - val_ca2-[11.3,14.9): 2.1460 - val_ca3-[8.0,9.5): 0.5817 - val_ca3-[9.5,10.3): 0.4192 - val_ca3-[10.3,11.3): 0.9043 - val_ca3-[11.3,14.9): 1.5737 - val_ca4-[8.0,9.5): 0.9551 - val_ca4-[9.5,10.3): 0.9920 - val_ca4-[10.3,11.3): 1.9551 - val_ca4-[11.3,14.9): 3.3275\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 2.4982 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4148 - ca2-[9.5,10.3): 0.6044 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5164 - ca3-[10.3,11.3): 0.8954 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.4874 - ca4-[11.3,14.9): 3.2816 - val_ca1-[8.0,9.5): 2.3191 - val_ca1-[9.5,10.3): 2.5762 - val_ca1-[10.3,11.3): 4.0372 - val_ca1-[11.3,14.9): 6.1167 - val_ca2-[8.0,9.5): 0.5928 - val_ca2-[9.5,10.3): 0.4961 - val_ca2-[10.3,11.3): 1.1285 - val_ca2-[11.3,14.9): 2.0069 - val_ca3-[8.0,9.5): 0.5927 - val_ca3-[9.5,10.3): 0.4145 - val_ca3-[10.3,11.3): 0.8590 - val_ca3-[11.3,14.9): 1.4678 - val_ca4-[8.0,9.5): 0.8855 - val_ca4-[9.5,10.3): 0.9050 - val_ca4-[10.3,11.3): 1.8175 - val_ca4-[11.3,14.9): 3.1132\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 2.3720 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3876 - ca2-[9.5,10.3): 0.5688 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4904 - ca3-[10.3,11.3): 0.8403 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.2008 - ca4-[11.3,14.9): 3.0375 - val_ca1-[8.0,9.5): 2.1858 - val_ca1-[9.5,10.3): 2.4267 - val_ca1-[10.3,11.3): 3.8787 - val_ca1-[11.3,14.9): 5.9355 - val_ca2-[8.0,9.5): 0.5819 - val_ca2-[9.5,10.3): 0.4705 - val_ca2-[10.3,11.3): 1.0797 - val_ca2-[11.3,14.9): 1.9163 - val_ca3-[8.0,9.5): 0.6081 - val_ca3-[9.5,10.3): 0.4151 - val_ca3-[10.3,11.3): 0.8329 - val_ca3-[11.3,14.9): 1.3949 - val_ca4-[8.0,9.5): 0.8255 - val_ca4-[9.5,10.3): 0.8283 - val_ca4-[10.3,11.3): 1.7185 - val_ca4-[11.3,14.9): 2.9720\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 2.2365 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3658 - ca2-[9.5,10.3): 0.5617 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4693 - ca3-[10.3,11.3): 0.8103 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.1297 - ca4-[11.3,14.9): 2.8898 - val_ca1-[8.0,9.5): 2.0636 - val_ca1-[9.5,10.3): 2.2892 - val_ca1-[10.3,11.3): 3.7055 - val_ca1-[11.3,14.9): 5.5996 - val_ca2-[8.0,9.5): 0.5761 - val_ca2-[9.5,10.3): 0.4511 - val_ca2-[10.3,11.3): 1.0278 - val_ca2-[11.3,14.9): 1.7685 - val_ca3-[8.0,9.5): 0.6273 - val_ca3-[9.5,10.3): 0.4202 - val_ca3-[10.3,11.3): 0.8047 - val_ca3-[11.3,14.9): 1.2849 - val_ca4-[8.0,9.5): 0.7744 - val_ca4-[9.5,10.3): 0.7612 - val_ca4-[10.3,11.3): 1.6131 - val_ca4-[11.3,14.9): 2.7430\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 2.1078 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3700 - ca2-[9.5,10.3): 0.5368 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4582 - ca3-[10.3,11.3): 0.7918 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.0702 - ca4-[11.3,14.9): 2.7239 - val_ca1-[8.0,9.5): 1.9512 - val_ca1-[9.5,10.3): 2.1623 - val_ca1-[10.3,11.3): 3.5183 - val_ca1-[11.3,14.9): 5.4196 - val_ca2-[8.0,9.5): 0.5745 - val_ca2-[9.5,10.3): 0.4367 - val_ca2-[10.3,11.3): 0.9728 - val_ca2-[11.3,14.9): 1.6942 - val_ca3-[8.0,9.5): 0.6495 - val_ca3-[9.5,10.3): 0.4290 - val_ca3-[10.3,11.3): 0.7760 - val_ca3-[11.3,14.9): 1.2276 - val_ca4-[8.0,9.5): 0.7309 - val_ca4-[9.5,10.3): 0.7026 - val_ca4-[10.3,11.3): 1.5022 - val_ca4-[11.3,14.9): 2.6120\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 1.9639 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3737 - ca2-[9.5,10.3): 0.5350 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4875 - ca3-[10.3,11.3): 0.7530 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.8970 - ca4-[11.3,14.9): 2.5430 - val_ca1-[8.0,9.5): 1.8484 - val_ca1-[9.5,10.3): 2.0455 - val_ca1-[10.3,11.3): 3.3838 - val_ca1-[11.3,14.9): 5.3115 - val_ca2-[8.0,9.5): 0.5763 - val_ca2-[9.5,10.3): 0.4266 - val_ca2-[10.3,11.3): 0.9416 - val_ca2-[11.3,14.9): 1.6544 - val_ca3-[8.0,9.5): 0.6740 - val_ca3-[9.5,10.3): 0.4409 - val_ca3-[10.3,11.3): 0.7639 - val_ca3-[11.3,14.9): 1.1962 - val_ca4-[8.0,9.5): 0.6944 - val_ca4-[9.5,10.3): 0.6516 - val_ca4-[10.3,11.3): 1.4259 - val_ca4-[11.3,14.9): 2.5309\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 1.8394 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3678 - ca2-[9.5,10.3): 0.5048 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5025 - ca3-[10.3,11.3): 0.7373 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.8143 - ca4-[11.3,14.9): 2.3999 - val_ca1-[8.0,9.5): 1.7543 - val_ca1-[9.5,10.3): 1.9382 - val_ca1-[10.3,11.3): 3.2573 - val_ca1-[11.3,14.9): 5.0732 - val_ca2-[8.0,9.5): 0.5808 - val_ca2-[9.5,10.3): 0.4201 - val_ca2-[10.3,11.3): 0.9116 - val_ca2-[11.3,14.9): 1.5570 - val_ca3-[8.0,9.5): 0.7004 - val_ca3-[9.5,10.3): 0.4554 - val_ca3-[10.3,11.3): 0.7510 - val_ca3-[11.3,14.9): 1.1221 - val_ca4-[8.0,9.5): 0.6643 - val_ca4-[9.5,10.3): 0.6076 - val_ca4-[10.3,11.3): 1.3543 - val_ca4-[11.3,14.9): 2.3689\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.7886 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3848 - ca2-[9.5,10.3): 0.5162 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4945 - ca3-[10.3,11.3): 0.7436 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.7044 - ca4-[11.3,14.9): 2.3106 - val_ca1-[8.0,9.5): 1.6679 - val_ca1-[9.5,10.3): 1.8393 - val_ca1-[10.3,11.3): 3.1055 - val_ca1-[11.3,14.9): 4.8827 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8773 - val_ca2-[11.3,14.9): 1.4914 - val_ca3-[8.0,9.5): 0.7281 - val_ca3-[9.5,10.3): 0.4718 - val_ca3-[10.3,11.3): 0.7387 - val_ca3-[11.3,14.9): 1.0758 - val_ca4-[8.0,9.5): 0.6398 - val_ca4-[9.5,10.3): 0.5700 - val_ca4-[10.3,11.3): 1.2729 - val_ca4-[11.3,14.9): 2.2447\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 1.6818 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3918 - ca2-[9.5,10.3): 0.5247 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5037 - ca3-[10.3,11.3): 0.7256 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.5556 - ca4-[11.3,14.9): 2.2149 - val_ca1-[8.0,9.5): 1.5890 - val_ca1-[9.5,10.3): 1.7485 - val_ca1-[10.3,11.3): 3.0287 - val_ca1-[11.3,14.9): 4.7136 - val_ca2-[8.0,9.5): 0.5952 - val_ca2-[9.5,10.3): 0.4151 - val_ca2-[10.3,11.3): 0.8599 - val_ca2-[11.3,14.9): 1.4117 - val_ca3-[8.0,9.5): 0.7561 - val_ca3-[9.5,10.3): 0.4893 - val_ca3-[10.3,11.3): 0.7295 - val_ca3-[11.3,14.9): 1.0062 - val_ca4-[8.0,9.5): 0.6202 - val_ca4-[9.5,10.3): 0.5378 - val_ca4-[10.3,11.3): 1.2273 - val_ca4-[11.3,14.9): 2.1182\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.6132 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3855 - ca2-[9.5,10.3): 0.5185 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5156 - ca3-[10.3,11.3): 0.7239 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.4688 - ca4-[11.3,14.9): 2.1015 - val_ca1-[8.0,9.5): 1.5166 - val_ca1-[9.5,10.3): 1.6649 - val_ca1-[10.3,11.3): 2.9003 - val_ca1-[11.3,14.9): 4.6522 - val_ca2-[8.0,9.5): 0.6039 - val_ca2-[9.5,10.3): 0.4155 - val_ca2-[10.3,11.3): 0.8411 - val_ca2-[11.3,14.9): 1.4177 - val_ca3-[8.0,9.5): 0.7845 - val_ca3-[9.5,10.3): 0.5079 - val_ca3-[10.3,11.3): 0.7304 - val_ca3-[11.3,14.9): 1.0155 - val_ca4-[8.0,9.5): 0.6051 - val_ca4-[9.5,10.3): 0.5107 - val_ca4-[10.3,11.3): 1.1662 - val_ca4-[11.3,14.9): 2.0840\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 1.5412 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4039 - ca2-[9.5,10.3): 0.5172 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5241 - ca3-[10.3,11.3): 0.7077 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.4181 - ca4-[11.3,14.9): 2.0164 - val_ca1-[8.0,9.5): 1.4502 - val_ca1-[9.5,10.3): 1.5877 - val_ca1-[10.3,11.3): 2.8074 - val_ca1-[11.3,14.9): 4.4374 - val_ca2-[8.0,9.5): 0.6127 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8219 - val_ca2-[11.3,14.9): 1.3358 - val_ca3-[8.0,9.5): 0.8131 - val_ca3-[9.5,10.3): 0.5272 - val_ca3-[10.3,11.3): 0.7220 - val_ca3-[11.3,14.9): 0.9503 - val_ca4-[8.0,9.5): 0.5937 - val_ca4-[9.5,10.3): 0.4878 - val_ca4-[10.3,11.3): 1.1160 - val_ca4-[11.3,14.9): 1.9409\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.4785 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3967 - ca2-[9.5,10.3): 0.5173 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5387 - ca3-[10.3,11.3): 0.7090 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.2931 - ca4-[11.3,14.9): 1.8994 - val_ca1-[8.0,9.5): 1.3892 - val_ca1-[9.5,10.3): 1.5165 - val_ca1-[10.3,11.3): 2.7118 - val_ca1-[11.3,14.9): 4.3378 - val_ca2-[8.0,9.5): 0.6201 - val_ca2-[9.5,10.3): 0.4184 - val_ca2-[10.3,11.3): 0.8160 - val_ca2-[11.3,14.9): 1.3289 - val_ca3-[8.0,9.5): 0.8410 - val_ca3-[9.5,10.3): 0.5463 - val_ca3-[10.3,11.3): 0.7300 - val_ca3-[11.3,14.9): 0.9475 - val_ca4-[8.0,9.5): 0.5857 - val_ca4-[9.5,10.3): 0.4690 - val_ca4-[10.3,11.3): 1.0755 - val_ca4-[11.3,14.9): 1.8870\n",
      "Epoch 49/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.4100 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3991 - ca2-[9.5,10.3): 0.5279 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5405 - ca3-[10.3,11.3): 0.7140 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.2185 - ca4-[11.3,14.9): 1.8365 - val_ca1-[8.0,9.5): 1.3332 - val_ca1-[9.5,10.3): 1.4508 - val_ca1-[10.3,11.3): 2.6156 - val_ca1-[11.3,14.9): 4.2059 - val_ca2-[8.0,9.5): 0.6199 - val_ca2-[9.5,10.3): 0.4176 - val_ca2-[10.3,11.3): 0.8138 - val_ca2-[11.3,14.9): 1.3225 - val_ca3-[8.0,9.5): 0.8684 - val_ca3-[9.5,10.3): 0.5655 - val_ca3-[10.3,11.3): 0.7312 - val_ca3-[11.3,14.9): 0.9196 - val_ca4-[8.0,9.5): 0.5808 - val_ca4-[9.5,10.3): 0.4536 - val_ca4-[10.3,11.3): 1.0319 - val_ca4-[11.3,14.9): 1.8033\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.3264 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4050 - ca2-[9.5,10.3): 0.5201 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5581 - ca3-[10.3,11.3): 0.6968 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.2716 - ca4-[11.3,14.9): 1.7614 - val_ca1-[8.0,9.5): 1.2820 - val_ca1-[9.5,10.3): 1.3906 - val_ca1-[10.3,11.3): 2.5339 - val_ca1-[11.3,14.9): 4.1077 - val_ca2-[8.0,9.5): 0.6244 - val_ca2-[9.5,10.3): 0.4196 - val_ca2-[10.3,11.3): 0.8089 - val_ca2-[11.3,14.9): 1.3124 - val_ca3-[8.0,9.5): 0.8932 - val_ca3-[9.5,10.3): 0.5830 - val_ca3-[10.3,11.3): 0.7331 - val_ca3-[11.3,14.9): 0.9013 - val_ca4-[8.0,9.5): 0.5784 - val_ca4-[9.5,10.3): 0.4414 - val_ca4-[10.3,11.3): 0.9956 - val_ca4-[11.3,14.9): 1.7384\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.2883 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3997 - ca2-[9.5,10.3): 0.5142 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5931 - ca3-[10.3,11.3): 0.6983 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.1877 - ca4-[11.3,14.9): 1.6950 - val_ca1-[8.0,9.5): 1.2348 - val_ca1-[9.5,10.3): 1.3348 - val_ca1-[10.3,11.3): 2.4275 - val_ca1-[11.3,14.9): 4.0002 - val_ca2-[8.0,9.5): 0.6308 - val_ca2-[9.5,10.3): 0.4217 - val_ca2-[10.3,11.3): 0.7847 - val_ca2-[11.3,14.9): 1.2857 - val_ca3-[8.0,9.5): 0.9155 - val_ca3-[9.5,10.3): 0.5988 - val_ca3-[10.3,11.3): 0.7225 - val_ca3-[11.3,14.9): 0.8777 - val_ca4-[8.0,9.5): 0.5784 - val_ca4-[9.5,10.3): 0.4318 - val_ca4-[10.3,11.3): 0.9431 - val_ca4-[11.3,14.9): 1.6689\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 1.2340 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4183 - ca2-[9.5,10.3): 0.5222 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5870 - ca3-[10.3,11.3): 0.7158 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.0638 - ca4-[11.3,14.9): 1.6378 - val_ca1-[8.0,9.5): 1.1913 - val_ca1-[9.5,10.3): 1.2832 - val_ca1-[10.3,11.3): 2.3869 - val_ca1-[11.3,14.9): 3.9571 - val_ca2-[8.0,9.5): 0.6366 - val_ca2-[9.5,10.3): 0.4237 - val_ca2-[10.3,11.3): 0.7961 - val_ca2-[11.3,14.9): 1.2890 - val_ca3-[8.0,9.5): 0.9345 - val_ca3-[9.5,10.3): 0.6122 - val_ca3-[10.3,11.3): 0.7379 - val_ca3-[11.3,14.9): 0.8756 - val_ca4-[8.0,9.5): 0.5804 - val_ca4-[9.5,10.3): 0.4247 - val_ca4-[10.3,11.3): 0.9337 - val_ca4-[11.3,14.9): 1.6354\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 1.2042 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4187 - ca2-[9.5,10.3): 0.5231 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5865 - ca3-[10.3,11.3): 0.7074 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.0513 - ca4-[11.3,14.9): 1.5595 - val_ca1-[8.0,9.5): 1.1514 - val_ca1-[9.5,10.3): 1.2358 - val_ca1-[10.3,11.3): 2.3199 - val_ca1-[11.3,14.9): 3.8223 - val_ca2-[8.0,9.5): 0.6408 - val_ca2-[9.5,10.3): 0.4251 - val_ca2-[10.3,11.3): 0.7902 - val_ca2-[11.3,14.9): 1.2602 - val_ca3-[8.0,9.5): 0.9467 - val_ca3-[9.5,10.3): 0.6208 - val_ca3-[10.3,11.3): 0.7372 - val_ca3-[11.3,14.9): 0.8559 - val_ca4-[8.0,9.5): 0.5842 - val_ca4-[9.5,10.3): 0.4197 - val_ca4-[10.3,11.3): 0.9056 - val_ca4-[11.3,14.9): 1.5557\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 1.1687 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4212 - ca2-[9.5,10.3): 0.5270 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5916 - ca3-[10.3,11.3): 0.7211 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.0578 - ca4-[11.3,14.9): 1.5328 - val_ca1-[8.0,9.5): 1.1144 - val_ca1-[9.5,10.3): 1.1918 - val_ca1-[10.3,11.3): 2.2588 - val_ca1-[11.3,14.9): 3.7732 - val_ca2-[8.0,9.5): 0.6431 - val_ca2-[9.5,10.3): 0.4258 - val_ca2-[10.3,11.3): 0.7886 - val_ca2-[11.3,14.9): 1.2734 - val_ca3-[8.0,9.5): 0.9524 - val_ca3-[9.5,10.3): 0.6247 - val_ca3-[10.3,11.3): 0.7374 - val_ca3-[11.3,14.9): 0.8592 - val_ca4-[8.0,9.5): 0.5896 - val_ca4-[9.5,10.3): 0.4166 - val_ca4-[10.3,11.3): 0.8821 - val_ca4-[11.3,14.9): 1.5222\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.1347 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4250 - ca2-[9.5,10.3): 0.5316 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6063 - ca3-[10.3,11.3): 0.7052 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.9868 - ca4-[11.3,14.9): 1.4589 - val_ca1-[8.0,9.5): 1.0805 - val_ca1-[9.5,10.3): 1.1512 - val_ca1-[10.3,11.3): 2.2020 - val_ca1-[11.3,14.9): 3.6241 - val_ca2-[8.0,9.5): 0.6428 - val_ca2-[9.5,10.3): 0.4256 - val_ca2-[10.3,11.3): 0.7904 - val_ca2-[11.3,14.9): 1.2527 - val_ca3-[8.0,9.5): 0.9618 - val_ca3-[9.5,10.3): 0.6305 - val_ca3-[10.3,11.3): 0.7382 - val_ca3-[11.3,14.9): 0.8436 - val_ca4-[8.0,9.5): 0.5964 - val_ca4-[9.5,10.3): 0.4153 - val_ca4-[10.3,11.3): 0.8610 - val_ca4-[11.3,14.9): 1.4412\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.0902 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4249 - ca2-[9.5,10.3): 0.5286 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5882 - ca3-[10.3,11.3): 0.7241 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.9941 - ca4-[11.3,14.9): 1.4067 - val_ca1-[8.0,9.5): 1.0490 - val_ca1-[9.5,10.3): 1.1133 - val_ca1-[10.3,11.3): 2.1617 - val_ca1-[11.3,14.9): 3.5746 - val_ca2-[8.0,9.5): 0.6380 - val_ca2-[9.5,10.3): 0.4238 - val_ca2-[10.3,11.3): 0.7944 - val_ca2-[11.3,14.9): 1.2751 - val_ca3-[8.0,9.5): 0.9731 - val_ca3-[9.5,10.3): 0.6375 - val_ca3-[10.3,11.3): 0.7313 - val_ca3-[11.3,14.9): 0.8354 - val_ca4-[8.0,9.5): 0.6044 - val_ca4-[9.5,10.3): 0.4155 - val_ca4-[10.3,11.3): 0.8410 - val_ca4-[11.3,14.9): 1.4031\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.0775 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4207 - ca2-[9.5,10.3): 0.5375 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6084 - ca3-[10.3,11.3): 0.7202 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.9275 - ca4-[11.3,14.9): 1.3691 - val_ca1-[8.0,9.5): 1.0192 - val_ca1-[9.5,10.3): 1.0753 - val_ca1-[10.3,11.3): 2.1029 - val_ca1-[11.3,14.9): 3.5047 - val_ca2-[8.0,9.5): 0.6242 - val_ca2-[9.5,10.3): 0.4187 - val_ca2-[10.3,11.3): 0.8188 - val_ca2-[11.3,14.9): 1.3154 - val_ca3-[8.0,9.5): 0.9830 - val_ca3-[9.5,10.3): 0.6476 - val_ca3-[10.3,11.3): 0.7516 - val_ca3-[11.3,14.9): 0.8261 - val_ca4-[8.0,9.5): 0.6136 - val_ca4-[9.5,10.3): 0.4179 - val_ca4-[10.3,11.3): 0.8335 - val_ca4-[11.3,14.9): 1.3573\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 1.0141 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3992 - ca2-[9.5,10.3): 0.5227 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5991 - ca3-[10.3,11.3): 0.7121 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8554 - ca4-[11.3,14.9): 1.3333 - val_ca1-[8.0,9.5): 0.9906 - val_ca1-[9.5,10.3): 1.0422 - val_ca1-[10.3,11.3): 2.0466 - val_ca1-[11.3,14.9): 3.4430 - val_ca2-[8.0,9.5): 0.6181 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8177 - val_ca2-[11.3,14.9): 1.3530 - val_ca3-[8.0,9.5): 0.9871 - val_ca3-[9.5,10.3): 0.6483 - val_ca3-[10.3,11.3): 0.7433 - val_ca3-[11.3,14.9): 0.8467 - val_ca4-[8.0,9.5): 0.6240 - val_ca4-[9.5,10.3): 0.4200 - val_ca4-[10.3,11.3): 0.8100 - val_ca4-[11.3,14.9): 1.3351\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.9979 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4061 - ca2-[9.5,10.3): 0.5240 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6443 - ca3-[10.3,11.3): 0.7051 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7834 - ca4-[11.3,14.9): 1.2793 - val_ca1-[8.0,9.5): 0.9635 - val_ca1-[9.5,10.3): 1.0090 - val_ca1-[10.3,11.3): 1.9798 - val_ca1-[11.3,14.9): 3.3717 - val_ca2-[8.0,9.5): 0.6194 - val_ca2-[9.5,10.3): 0.4159 - val_ca2-[10.3,11.3): 0.8086 - val_ca2-[11.3,14.9): 1.3425 - val_ca3-[8.0,9.5): 0.9798 - val_ca3-[9.5,10.3): 0.6422 - val_ca3-[10.3,11.3): 0.7405 - val_ca3-[11.3,14.9): 0.8434 - val_ca4-[8.0,9.5): 0.6356 - val_ca4-[9.5,10.3): 0.4242 - val_ca4-[10.3,11.3): 0.7895 - val_ca4-[11.3,14.9): 1.2883\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.9745 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3920 - ca2-[9.5,10.3): 0.5130 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5919 - ca3-[10.3,11.3): 0.6996 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8672 - ca4-[11.3,14.9): 1.2509 - val_ca1-[8.0,9.5): 0.9380 - val_ca1-[9.5,10.3): 0.9776 - val_ca1-[10.3,11.3): 1.9526 - val_ca1-[11.3,14.9): 3.2894 - val_ca2-[8.0,9.5): 0.6208 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8125 - val_ca2-[11.3,14.9): 1.3328 - val_ca3-[8.0,9.5): 0.9680 - val_ca3-[9.5,10.3): 0.6315 - val_ca3-[10.3,11.3): 0.7373 - val_ca3-[11.3,14.9): 0.8527 - val_ca4-[8.0,9.5): 0.6483 - val_ca4-[9.5,10.3): 0.4296 - val_ca4-[10.3,11.3): 0.7840 - val_ca4-[11.3,14.9): 1.2461\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.9666 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4023 - ca2-[9.5,10.3): 0.5189 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6143 - ca3-[10.3,11.3): 0.7087 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7531 - ca4-[11.3,14.9): 1.2114 - val_ca1-[8.0,9.5): 0.9141 - val_ca1-[9.5,10.3): 0.9480 - val_ca1-[10.3,11.3): 1.9040 - val_ca1-[11.3,14.9): 3.2696 - val_ca2-[8.0,9.5): 0.6223 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8020 - val_ca2-[11.3,14.9): 1.3416 - val_ca3-[8.0,9.5): 0.9416 - val_ca3-[9.5,10.3): 0.6099 - val_ca3-[10.3,11.3): 0.7193 - val_ca3-[11.3,14.9): 0.8649 - val_ca4-[8.0,9.5): 0.6618 - val_ca4-[9.5,10.3): 0.4361 - val_ca4-[10.3,11.3): 0.7637 - val_ca4-[11.3,14.9): 1.2181\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.9345 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4107 - ca2-[9.5,10.3): 0.5141 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5541 - ca3-[10.3,11.3): 0.7114 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7859 - ca4-[11.3,14.9): 1.1820 - val_ca1-[8.0,9.5): 0.8914 - val_ca1-[9.5,10.3): 0.9198 - val_ca1-[10.3,11.3): 1.8511 - val_ca1-[11.3,14.9): 3.1270 - val_ca2-[8.0,9.5): 0.6183 - val_ca2-[9.5,10.3): 0.4145 - val_ca2-[10.3,11.3): 0.8109 - val_ca2-[11.3,14.9): 1.3199 - val_ca3-[8.0,9.5): 0.9036 - val_ca3-[9.5,10.3): 0.5779 - val_ca3-[10.3,11.3): 0.7224 - val_ca3-[11.3,14.9): 0.8777 - val_ca4-[8.0,9.5): 0.6765 - val_ca4-[9.5,10.3): 0.4437 - val_ca4-[10.3,11.3): 0.7602 - val_ca4-[11.3,14.9): 1.1580\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.8786 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4099 - ca2-[9.5,10.3): 0.5237 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5552 - ca3-[10.3,11.3): 0.6959 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7026 - ca4-[11.3,14.9): 1.1472 - val_ca1-[8.0,9.5): 0.8695 - val_ca1-[9.5,10.3): 0.8921 - val_ca1-[10.3,11.3): 1.8001 - val_ca1-[11.3,14.9): 3.0433 - val_ca2-[8.0,9.5): 0.6176 - val_ca2-[9.5,10.3): 0.4140 - val_ca2-[10.3,11.3): 0.8003 - val_ca2-[11.3,14.9): 1.3067 - val_ca3-[8.0,9.5): 0.8909 - val_ca3-[9.5,10.3): 0.5669 - val_ca3-[10.3,11.3): 0.7075 - val_ca3-[11.3,14.9): 0.8724 - val_ca4-[8.0,9.5): 0.6918 - val_ca4-[9.5,10.3): 0.4522 - val_ca4-[10.3,11.3): 0.7420 - val_ca4-[11.3,14.9): 1.1139\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.8584 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3878 - ca2-[9.5,10.3): 0.5008 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5566 - ca3-[10.3,11.3): 0.6807 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7011 - ca4-[11.3,14.9): 1.0961 - val_ca1-[8.0,9.5): 0.8484 - val_ca1-[9.5,10.3): 0.8650 - val_ca1-[10.3,11.3): 1.7843 - val_ca1-[11.3,14.9): 3.0310 - val_ca2-[8.0,9.5): 0.6180 - val_ca2-[9.5,10.3): 0.4142 - val_ca2-[10.3,11.3): 0.8154 - val_ca2-[11.3,14.9): 1.3360 - val_ca3-[8.0,9.5): 0.8987 - val_ca3-[9.5,10.3): 0.5703 - val_ca3-[10.3,11.3): 0.7155 - val_ca3-[11.3,14.9): 0.8844 - val_ca4-[8.0,9.5): 0.7079 - val_ca4-[9.5,10.3): 0.4617 - val_ca4-[10.3,11.3): 0.7489 - val_ca4-[11.3,14.9): 1.1103\n",
      "Epoch 65/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.8236 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4120 - ca2-[9.5,10.3): 0.5246 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5368 - ca3-[10.3,11.3): 0.6871 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7297 - ca4-[11.3,14.9): 1.0846 - val_ca1-[8.0,9.5): 0.8284 - val_ca1-[9.5,10.3): 0.8391 - val_ca1-[10.3,11.3): 1.7460 - val_ca1-[11.3,14.9): 2.9732 - val_ca2-[8.0,9.5): 0.6201 - val_ca2-[9.5,10.3): 0.4144 - val_ca2-[10.3,11.3): 0.8146 - val_ca2-[11.3,14.9): 1.3268 - val_ca3-[8.0,9.5): 0.9107 - val_ca3-[9.5,10.3): 0.5769 - val_ca3-[10.3,11.3): 0.7175 - val_ca3-[11.3,14.9): 0.8695 - val_ca4-[8.0,9.5): 0.7248 - val_ca4-[9.5,10.3): 0.4720 - val_ca4-[10.3,11.3): 0.7455 - val_ca4-[11.3,14.9): 1.0800\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.8317 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3939 - ca2-[9.5,10.3): 0.5155 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5396 - ca3-[10.3,11.3): 0.6978 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5782 - ca4-[11.3,14.9): 1.0381 - val_ca1-[8.0,9.5): 0.8100 - val_ca1-[9.5,10.3): 0.8151 - val_ca1-[10.3,11.3): 1.6877 - val_ca1-[11.3,14.9): 2.9075 - val_ca2-[8.0,9.5): 0.6209 - val_ca2-[9.5,10.3): 0.4144 - val_ca2-[10.3,11.3): 0.8036 - val_ca2-[11.3,14.9): 1.3149 - val_ca3-[8.0,9.5): 0.9161 - val_ca3-[9.5,10.3): 0.5792 - val_ca3-[10.3,11.3): 0.7109 - val_ca3-[11.3,14.9): 0.8581 - val_ca4-[8.0,9.5): 0.7419 - val_ca4-[9.5,10.3): 0.4829 - val_ca4-[10.3,11.3): 0.7342 - val_ca4-[11.3,14.9): 1.0441\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.8167 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3977 - ca2-[9.5,10.3): 0.5232 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5533 - ca3-[10.3,11.3): 0.6860 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6578 - ca4-[11.3,14.9): 1.0271 - val_ca1-[8.0,9.5): 0.7930 - val_ca1-[9.5,10.3): 0.7929 - val_ca1-[10.3,11.3): 1.6738 - val_ca1-[11.3,14.9): 2.8660 - val_ca2-[8.0,9.5): 0.6206 - val_ca2-[9.5,10.3): 0.4142 - val_ca2-[10.3,11.3): 0.8148 - val_ca2-[11.3,14.9): 1.3265 - val_ca3-[8.0,9.5): 0.9124 - val_ca3-[9.5,10.3): 0.5756 - val_ca3-[10.3,11.3): 0.7174 - val_ca3-[11.3,14.9): 0.8701 - val_ca4-[8.0,9.5): 0.7591 - val_ca4-[9.5,10.3): 0.4941 - val_ca4-[10.3,11.3): 0.7377 - val_ca4-[11.3,14.9): 1.0295\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.7946 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4076 - ca2-[9.5,10.3): 0.5364 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5469 - ca3-[10.3,11.3): 0.6793 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6730 - ca4-[11.3,14.9): 0.9999 - val_ca1-[8.0,9.5): 0.7772 - val_ca1-[9.5,10.3): 0.7720 - val_ca1-[10.3,11.3): 1.6310 - val_ca1-[11.3,14.9): 2.8291 - val_ca2-[8.0,9.5): 0.6190 - val_ca2-[9.5,10.3): 0.4138 - val_ca2-[10.3,11.3): 0.8119 - val_ca2-[11.3,14.9): 1.3472 - val_ca3-[8.0,9.5): 0.9119 - val_ca3-[9.5,10.3): 0.5743 - val_ca3-[10.3,11.3): 0.7139 - val_ca3-[11.3,14.9): 0.8869 - val_ca4-[8.0,9.5): 0.7766 - val_ca4-[9.5,10.3): 0.5058 - val_ca4-[10.3,11.3): 0.7312 - val_ca4-[11.3,14.9): 1.0200\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.7741 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4038 - ca2-[9.5,10.3): 0.5285 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5424 - ca3-[10.3,11.3): 0.6957 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6600 - ca4-[11.3,14.9): 0.9995 - val_ca1-[8.0,9.5): 0.7622 - val_ca1-[9.5,10.3): 0.7520 - val_ca1-[10.3,11.3): 1.6036 - val_ca1-[11.3,14.9): 2.8150 - val_ca2-[8.0,9.5): 0.6193 - val_ca2-[9.5,10.3): 0.4137 - val_ca2-[10.3,11.3): 0.8137 - val_ca2-[11.3,14.9): 1.3704 - val_ca3-[8.0,9.5): 0.9196 - val_ca3-[9.5,10.3): 0.5784 - val_ca3-[10.3,11.3): 0.7141 - val_ca3-[11.3,14.9): 0.8945 - val_ca4-[8.0,9.5): 0.7946 - val_ca4-[9.5,10.3): 0.5181 - val_ca4-[10.3,11.3): 0.7297 - val_ca4-[11.3,14.9): 1.0149\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.7556 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3985 - ca2-[9.5,10.3): 0.5100 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5445 - ca3-[10.3,11.3): 0.7102 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5810 - ca4-[11.3,14.9): 0.9682 - val_ca1-[8.0,9.5): 0.7486 - val_ca1-[9.5,10.3): 0.7336 - val_ca1-[10.3,11.3): 1.5856 - val_ca1-[11.3,14.9): 2.7073 - val_ca2-[8.0,9.5): 0.6198 - val_ca2-[9.5,10.3): 0.4135 - val_ca2-[10.3,11.3): 0.8136 - val_ca2-[11.3,14.9): 1.3212 - val_ca3-[8.0,9.5): 0.9106 - val_ca3-[9.5,10.3): 0.5716 - val_ca3-[10.3,11.3): 0.7069 - val_ca3-[11.3,14.9): 0.8645 - val_ca4-[8.0,9.5): 0.8124 - val_ca4-[9.5,10.3): 0.5305 - val_ca4-[10.3,11.3): 0.7240 - val_ca4-[11.3,14.9): 0.9509\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.7223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4147 - ca2-[9.5,10.3): 0.5225 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5096 - ca3-[10.3,11.3): 0.6981 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6033 - ca4-[11.3,14.9): 0.9380 - val_ca1-[8.0,9.5): 0.7358 - val_ca1-[9.5,10.3): 0.7163 - val_ca1-[10.3,11.3): 1.5458 - val_ca1-[11.3,14.9): 2.7297 - val_ca2-[8.0,9.5): 0.6192 - val_ca2-[9.5,10.3): 0.4134 - val_ca2-[10.3,11.3): 0.8150 - val_ca2-[11.3,14.9): 1.3617 - val_ca3-[8.0,9.5): 0.9033 - val_ca3-[9.5,10.3): 0.5667 - val_ca3-[10.3,11.3): 0.7117 - val_ca3-[11.3,14.9): 0.8882 - val_ca4-[8.0,9.5): 0.8304 - val_ca4-[9.5,10.3): 0.5433 - val_ca4-[10.3,11.3): 0.7289 - val_ca4-[11.3,14.9): 0.9562\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.7254 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4094 - ca2-[9.5,10.3): 0.5145 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5296 - ca3-[10.3,11.3): 0.6909 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6599 - ca4-[11.3,14.9): 0.9391 - val_ca1-[8.0,9.5): 0.7238 - val_ca1-[9.5,10.3): 0.6996 - val_ca1-[10.3,11.3): 1.5210 - val_ca1-[11.3,14.9): 2.6717 - val_ca2-[8.0,9.5): 0.6185 - val_ca2-[9.5,10.3): 0.4132 - val_ca2-[10.3,11.3): 0.8174 - val_ca2-[11.3,14.9): 1.3553 - val_ca3-[8.0,9.5): 0.9083 - val_ca3-[9.5,10.3): 0.5698 - val_ca3-[10.3,11.3): 0.7122 - val_ca3-[11.3,14.9): 0.8784 - val_ca4-[8.0,9.5): 0.8487 - val_ca4-[9.5,10.3): 0.5564 - val_ca4-[10.3,11.3): 0.7312 - val_ca4-[11.3,14.9): 0.9333\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.7025 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4008 - ca2-[9.5,10.3): 0.5082 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5277 - ca3-[10.3,11.3): 0.7017 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5951 - ca4-[11.3,14.9): 0.8959 - val_ca1-[8.0,9.5): 0.7125 - val_ca1-[9.5,10.3): 0.6838 - val_ca1-[10.3,11.3): 1.5007 - val_ca1-[11.3,14.9): 2.6308 - val_ca2-[8.0,9.5): 0.6186 - val_ca2-[9.5,10.3): 0.4128 - val_ca2-[10.3,11.3): 0.8202 - val_ca2-[11.3,14.9): 1.3660 - val_ca3-[8.0,9.5): 0.9204 - val_ca3-[9.5,10.3): 0.5775 - val_ca3-[10.3,11.3): 0.7152 - val_ca3-[11.3,14.9): 0.8856 - val_ca4-[8.0,9.5): 0.8670 - val_ca4-[9.5,10.3): 0.5697 - val_ca4-[10.3,11.3): 0.7342 - val_ca4-[11.3,14.9): 0.9318\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.7028 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3983 - ca2-[9.5,10.3): 0.5143 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5392 - ca3-[10.3,11.3): 0.6923 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6442 - ca4-[11.3,14.9): 0.9064 - val_ca1-[8.0,9.5): 0.7021 - val_ca1-[9.5,10.3): 0.6692 - val_ca1-[10.3,11.3): 1.4621 - val_ca1-[11.3,14.9): 2.5700 - val_ca2-[8.0,9.5): 0.6183 - val_ca2-[9.5,10.3): 0.4124 - val_ca2-[10.3,11.3): 0.8125 - val_ca2-[11.3,14.9): 1.3496 - val_ca3-[8.0,9.5): 0.9219 - val_ca3-[9.5,10.3): 0.5783 - val_ca3-[10.3,11.3): 0.7125 - val_ca3-[11.3,14.9): 0.8709 - val_ca4-[8.0,9.5): 0.8851 - val_ca4-[9.5,10.3): 0.5831 - val_ca4-[10.3,11.3): 0.7328 - val_ca4-[11.3,14.9): 0.9058\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.6747 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3988 - ca2-[9.5,10.3): 0.5146 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5644 - ca3-[10.3,11.3): 0.6945 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5752 - ca4-[11.3,14.9): 0.8694 - val_ca1-[8.0,9.5): 0.6927 - val_ca1-[9.5,10.3): 0.6559 - val_ca1-[10.3,11.3): 1.4265 - val_ca1-[11.3,14.9): 2.4612 - val_ca2-[8.0,9.5): 0.6171 - val_ca2-[9.5,10.3): 0.4120 - val_ca2-[10.3,11.3): 0.8090 - val_ca2-[11.3,14.9): 1.3051 - val_ca3-[8.0,9.5): 0.9133 - val_ca3-[9.5,10.3): 0.5725 - val_ca3-[10.3,11.3): 0.7121 - val_ca3-[11.3,14.9): 0.8500 - val_ca4-[8.0,9.5): 0.9027 - val_ca4-[9.5,10.3): 0.5961 - val_ca4-[10.3,11.3): 0.7352 - val_ca4-[11.3,14.9): 0.8556\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.6724 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3978 - ca2-[9.5,10.3): 0.5181 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5438 - ca3-[10.3,11.3): 0.6947 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5455 - ca4-[11.3,14.9): 0.8567 - val_ca1-[8.0,9.5): 0.6836 - val_ca1-[9.5,10.3): 0.6427 - val_ca1-[10.3,11.3): 1.4185 - val_ca1-[11.3,14.9): 2.5213 - val_ca2-[8.0,9.5): 0.6169 - val_ca2-[9.5,10.3): 0.4118 - val_ca2-[10.3,11.3): 0.8158 - val_ca2-[11.3,14.9): 1.3741 - val_ca3-[8.0,9.5): 0.9195 - val_ca3-[9.5,10.3): 0.5761 - val_ca3-[10.3,11.3): 0.7147 - val_ca3-[11.3,14.9): 0.8923 - val_ca4-[8.0,9.5): 0.9207 - val_ca4-[9.5,10.3): 0.6097 - val_ca4-[10.3,11.3): 0.7400 - val_ca4-[11.3,14.9): 0.8953\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.6546 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3981 - ca2-[9.5,10.3): 0.5231 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5473 - ca3-[10.3,11.3): 0.6781 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5742 - ca4-[11.3,14.9): 0.8441 - val_ca1-[8.0,9.5): 0.6753 - val_ca1-[9.5,10.3): 0.6305 - val_ca1-[10.3,11.3): 1.3900 - val_ca1-[11.3,14.9): 2.4503 - val_ca2-[8.0,9.5): 0.6168 - val_ca2-[9.5,10.3): 0.4115 - val_ca2-[10.3,11.3): 0.8118 - val_ca2-[11.3,14.9): 1.3525 - val_ca3-[8.0,9.5): 0.9190 - val_ca3-[9.5,10.3): 0.5754 - val_ca3-[10.3,11.3): 0.7135 - val_ca3-[11.3,14.9): 0.8843 - val_ca4-[8.0,9.5): 0.9384 - val_ca4-[9.5,10.3): 0.6231 - val_ca4-[10.3,11.3): 0.7422 - val_ca4-[11.3,14.9): 0.8731\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.6451 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3866 - ca2-[9.5,10.3): 0.4953 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5378 - ca3-[10.3,11.3): 0.6989 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5627 - ca4-[11.3,14.9): 0.8414 - val_ca1-[8.0,9.5): 0.6676 - val_ca1-[9.5,10.3): 0.6190 - val_ca1-[10.3,11.3): 1.3751 - val_ca1-[11.3,14.9): 2.4498 - val_ca2-[8.0,9.5): 0.6163 - val_ca2-[9.5,10.3): 0.4112 - val_ca2-[10.3,11.3): 0.8133 - val_ca2-[11.3,14.9): 1.3681 - val_ca3-[8.0,9.5): 0.9199 - val_ca3-[9.5,10.3): 0.5758 - val_ca3-[10.3,11.3): 0.7122 - val_ca3-[11.3,14.9): 0.8849 - val_ca4-[8.0,9.5): 0.9559 - val_ca4-[9.5,10.3): 0.6364 - val_ca4-[10.3,11.3): 0.7440 - val_ca4-[11.3,14.9): 0.8649\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.6441 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3934 - ca2-[9.5,10.3): 0.5114 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5317 - ca3-[10.3,11.3): 0.6978 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5432 - ca4-[11.3,14.9): 0.8290 - val_ca1-[8.0,9.5): 0.6605 - val_ca1-[9.5,10.3): 0.6083 - val_ca1-[10.3,11.3): 1.3652 - val_ca1-[11.3,14.9): 2.3864 - val_ca2-[8.0,9.5): 0.6154 - val_ca2-[9.5,10.3): 0.4109 - val_ca2-[10.3,11.3): 0.8151 - val_ca2-[11.3,14.9): 1.3459 - val_ca3-[8.0,9.5): 0.9183 - val_ca3-[9.5,10.3): 0.5744 - val_ca3-[10.3,11.3): 0.7064 - val_ca3-[11.3,14.9): 0.8684 - val_ca4-[8.0,9.5): 0.9730 - val_ca4-[9.5,10.3): 0.6495 - val_ca4-[10.3,11.3): 0.7401 - val_ca4-[11.3,14.9): 0.8316\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.6322 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4000 - ca2-[9.5,10.3): 0.5116 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5356 - ca3-[10.3,11.3): 0.6843 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5897 - ca4-[11.3,14.9): 0.8189 - val_ca1-[8.0,9.5): 0.6537 - val_ca1-[9.5,10.3): 0.5980 - val_ca1-[10.3,11.3): 1.3442 - val_ca1-[11.3,14.9): 2.3764 - val_ca2-[8.0,9.5): 0.6152 - val_ca2-[9.5,10.3): 0.4107 - val_ca2-[10.3,11.3): 0.8180 - val_ca2-[11.3,14.9): 1.3635 - val_ca3-[8.0,9.5): 0.9173 - val_ca3-[9.5,10.3): 0.5735 - val_ca3-[10.3,11.3): 0.7125 - val_ca3-[11.3,14.9): 0.8804 - val_ca4-[8.0,9.5): 0.9900 - val_ca4-[9.5,10.3): 0.6627 - val_ca4-[10.3,11.3): 0.7520 - val_ca4-[11.3,14.9): 0.8375\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.6146 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3967 - ca2-[9.5,10.3): 0.5095 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5498 - ca3-[10.3,11.3): 0.6959 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5642 - ca4-[11.3,14.9): 0.8126 - val_ca1-[8.0,9.5): 0.6476 - val_ca1-[9.5,10.3): 0.5886 - val_ca1-[10.3,11.3): 1.3131 - val_ca1-[11.3,14.9): 2.3219 - val_ca2-[8.0,9.5): 0.6132 - val_ca2-[9.5,10.3): 0.4104 - val_ca2-[10.3,11.3): 0.8147 - val_ca2-[11.3,14.9): 1.3547 - val_ca3-[8.0,9.5): 0.9120 - val_ca3-[9.5,10.3): 0.5699 - val_ca3-[10.3,11.3): 0.7118 - val_ca3-[11.3,14.9): 0.8762 - val_ca4-[8.0,9.5): 1.0064 - val_ca4-[9.5,10.3): 0.6754 - val_ca4-[10.3,11.3): 0.7549 - val_ca4-[11.3,14.9): 0.8197\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.6199 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3872 - ca2-[9.5,10.3): 0.5110 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5406 - ca3-[10.3,11.3): 0.6946 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5725 - ca4-[11.3,14.9): 0.8036 - val_ca1-[8.0,9.5): 0.6418 - val_ca1-[9.5,10.3): 0.5794 - val_ca1-[10.3,11.3): 1.3047 - val_ca1-[11.3,14.9): 2.2897 - val_ca2-[8.0,9.5): 0.6134 - val_ca2-[9.5,10.3): 0.4101 - val_ca2-[10.3,11.3): 0.8187 - val_ca2-[11.3,14.9): 1.3472 - val_ca3-[8.0,9.5): 0.9131 - val_ca3-[9.5,10.3): 0.5702 - val_ca3-[10.3,11.3): 0.7143 - val_ca3-[11.3,14.9): 0.8670 - val_ca4-[8.0,9.5): 1.0228 - val_ca4-[9.5,10.3): 0.6883 - val_ca4-[10.3,11.3): 0.7619 - val_ca4-[11.3,14.9): 0.8051\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.6150 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3929 - ca2-[9.5,10.3): 0.5101 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5419 - ca3-[10.3,11.3): 0.7094 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5520 - ca4-[11.3,14.9): 0.7848 - val_ca1-[8.0,9.5): 0.6363 - val_ca1-[9.5,10.3): 0.5706 - val_ca1-[10.3,11.3): 1.2929 - val_ca1-[11.3,14.9): 2.2807 - val_ca2-[8.0,9.5): 0.6136 - val_ca2-[9.5,10.3): 0.4099 - val_ca2-[10.3,11.3): 0.8188 - val_ca2-[11.3,14.9): 1.3671 - val_ca3-[8.0,9.5): 0.9190 - val_ca3-[9.5,10.3): 0.5734 - val_ca3-[10.3,11.3): 0.7123 - val_ca3-[11.3,14.9): 0.8842 - val_ca4-[8.0,9.5): 1.0391 - val_ca4-[9.5,10.3): 0.7010 - val_ca4-[10.3,11.3): 0.7642 - val_ca4-[11.3,14.9): 0.8226\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5945 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3966 - ca2-[9.5,10.3): 0.5182 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5251 - ca3-[10.3,11.3): 0.6817 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5287 - ca4-[11.3,14.9): 0.7917 - val_ca1-[8.0,9.5): 0.6312 - val_ca1-[9.5,10.3): 0.5622 - val_ca1-[10.3,11.3): 1.2702 - val_ca1-[11.3,14.9): 2.2297 - val_ca2-[8.0,9.5): 0.6138 - val_ca2-[9.5,10.3): 0.4097 - val_ca2-[10.3,11.3): 0.8144 - val_ca2-[11.3,14.9): 1.3423 - val_ca3-[8.0,9.5): 0.9258 - val_ca3-[9.5,10.3): 0.5773 - val_ca3-[10.3,11.3): 0.7120 - val_ca3-[11.3,14.9): 0.8636 - val_ca4-[8.0,9.5): 1.0554 - val_ca4-[9.5,10.3): 0.7139 - val_ca4-[10.3,11.3): 0.7685 - val_ca4-[11.3,14.9): 0.7933\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.6082 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3728 - ca2-[9.5,10.3): 0.5116 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5489 - ca3-[10.3,11.3): 0.6777 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5505 - ca4-[11.3,14.9): 0.7762 - val_ca1-[8.0,9.5): 0.6266 - val_ca1-[9.5,10.3): 0.5546 - val_ca1-[10.3,11.3): 1.2617 - val_ca1-[11.3,14.9): 2.2626 - val_ca2-[8.0,9.5): 0.6117 - val_ca2-[9.5,10.3): 0.4094 - val_ca2-[10.3,11.3): 0.8167 - val_ca2-[11.3,14.9): 1.3865 - val_ca3-[8.0,9.5): 0.9244 - val_ca3-[9.5,10.3): 0.5762 - val_ca3-[10.3,11.3): 0.7037 - val_ca3-[11.3,14.9): 0.8774 - val_ca4-[8.0,9.5): 1.0708 - val_ca4-[9.5,10.3): 0.7261 - val_ca4-[10.3,11.3): 0.7618 - val_ca4-[11.3,14.9): 0.7909\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5873 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3887 - ca2-[9.5,10.3): 0.5178 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5273 - ca3-[10.3,11.3): 0.6948 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4941 - ca4-[11.3,14.9): 0.7804 - val_ca1-[8.0,9.5): 0.6224 - val_ca1-[9.5,10.3): 0.5475 - val_ca1-[10.3,11.3): 1.2538 - val_ca1-[11.3,14.9): 2.2228 - val_ca2-[8.0,9.5): 0.6106 - val_ca2-[9.5,10.3): 0.4092 - val_ca2-[10.3,11.3): 0.8274 - val_ca2-[11.3,14.9): 1.3777 - val_ca3-[8.0,9.5): 0.9162 - val_ca3-[9.5,10.3): 0.5711 - val_ca3-[10.3,11.3): 0.7146 - val_ca3-[11.3,14.9): 0.8707 - val_ca4-[8.0,9.5): 1.0859 - val_ca4-[9.5,10.3): 0.7381 - val_ca4-[10.3,11.3): 0.7788 - val_ca4-[11.3,14.9): 0.7751\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5727 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3949 - ca2-[9.5,10.3): 0.5127 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5324 - ca3-[10.3,11.3): 0.6837 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5097 - ca4-[11.3,14.9): 0.7576 - val_ca1-[8.0,9.5): 0.6184 - val_ca1-[9.5,10.3): 0.5406 - val_ca1-[10.3,11.3): 1.2292 - val_ca1-[11.3,14.9): 2.1708 - val_ca2-[8.0,9.5): 0.6099 - val_ca2-[9.5,10.3): 0.4089 - val_ca2-[10.3,11.3): 0.8181 - val_ca2-[11.3,14.9): 1.3668 - val_ca3-[8.0,9.5): 0.9172 - val_ca3-[9.5,10.3): 0.5714 - val_ca3-[10.3,11.3): 0.7054 - val_ca3-[11.3,14.9): 0.8713 - val_ca4-[8.0,9.5): 1.1009 - val_ca4-[9.5,10.3): 0.7501 - val_ca4-[10.3,11.3): 0.7731 - val_ca4-[11.3,14.9): 0.7733\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5824 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3884 - ca2-[9.5,10.3): 0.5073 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5276 - ca3-[10.3,11.3): 0.6840 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5340 - ca4-[11.3,14.9): 0.7731 - val_ca1-[8.0,9.5): 0.6147 - val_ca1-[9.5,10.3): 0.5337 - val_ca1-[10.3,11.3): 1.2228 - val_ca1-[11.3,14.9): 2.1669 - val_ca2-[8.0,9.5): 0.6100 - val_ca2-[9.5,10.3): 0.4093 - val_ca2-[10.3,11.3): 0.8247 - val_ca2-[11.3,14.9): 1.3837 - val_ca3-[8.0,9.5): 0.9213 - val_ca3-[9.5,10.3): 0.5754 - val_ca3-[10.3,11.3): 0.7137 - val_ca3-[11.3,14.9): 0.8894 - val_ca4-[8.0,9.5): 1.1154 - val_ca4-[9.5,10.3): 0.7643 - val_ca4-[10.3,11.3): 0.7894 - val_ca4-[11.3,14.9): 0.7911\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5952 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3865 - ca2-[9.5,10.3): 0.5107 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5495 - ca3-[10.3,11.3): 0.6783 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5353 - ca4-[11.3,14.9): 0.7583 - val_ca1-[8.0,9.5): 0.6113 - val_ca1-[9.5,10.3): 0.5280 - val_ca1-[10.3,11.3): 1.2023 - val_ca1-[11.3,14.9): 2.1452 - val_ca2-[8.0,9.5): 0.6091 - val_ca2-[9.5,10.3): 0.4084 - val_ca2-[10.3,11.3): 0.8209 - val_ca2-[11.3,14.9): 1.3841 - val_ca3-[8.0,9.5): 0.9195 - val_ca3-[9.5,10.3): 0.5723 - val_ca3-[10.3,11.3): 0.7111 - val_ca3-[11.3,14.9): 0.8828 - val_ca4-[8.0,9.5): 1.1293 - val_ca4-[9.5,10.3): 0.7729 - val_ca4-[10.3,11.3): 0.7917 - val_ca4-[11.3,14.9): 0.7781\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5784 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3944 - ca2-[9.5,10.3): 0.5025 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5495 - ca3-[10.3,11.3): 0.6957 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5435 - ca4-[11.3,14.9): 0.7491 - val_ca1-[8.0,9.5): 0.6082 - val_ca1-[9.5,10.3): 0.5222 - val_ca1-[10.3,11.3): 1.1778 - val_ca1-[11.3,14.9): 2.1103 - val_ca2-[8.0,9.5): 0.6082 - val_ca2-[9.5,10.3): 0.4082 - val_ca2-[10.3,11.3): 0.8117 - val_ca2-[11.3,14.9): 1.3767 - val_ca3-[8.0,9.5): 0.9173 - val_ca3-[9.5,10.3): 0.5708 - val_ca3-[10.3,11.3): 0.7047 - val_ca3-[11.3,14.9): 0.8790 - val_ca4-[8.0,9.5): 1.1431 - val_ca4-[9.5,10.3): 0.7841 - val_ca4-[10.3,11.3): 0.7903 - val_ca4-[11.3,14.9): 0.7646\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5836 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3822 - ca2-[9.5,10.3): 0.5149 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5259 - ca3-[10.3,11.3): 0.6758 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4810 - ca4-[11.3,14.9): 0.7312 - val_ca1-[8.0,9.5): 0.6053 - val_ca1-[9.5,10.3): 0.5168 - val_ca1-[10.3,11.3): 1.1853 - val_ca1-[11.3,14.9): 2.1044 - val_ca2-[8.0,9.5): 0.6068 - val_ca2-[9.5,10.3): 0.4079 - val_ca2-[10.3,11.3): 0.8273 - val_ca2-[11.3,14.9): 1.3935 - val_ca3-[8.0,9.5): 0.9158 - val_ca3-[9.5,10.3): 0.5696 - val_ca3-[10.3,11.3): 0.7109 - val_ca3-[11.3,14.9): 0.8876 - val_ca4-[8.0,9.5): 1.1563 - val_ca4-[9.5,10.3): 0.7948 - val_ca4-[10.3,11.3): 0.8007 - val_ca4-[11.3,14.9): 0.7691\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5663 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3919 - ca2-[9.5,10.3): 0.5108 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4969 - ca3-[10.3,11.3): 0.6835 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5047 - ca4-[11.3,14.9): 0.7514 - val_ca1-[8.0,9.5): 0.6026 - val_ca1-[9.5,10.3): 0.5117 - val_ca1-[10.3,11.3): 1.1751 - val_ca1-[11.3,14.9): 2.0334 - val_ca2-[8.0,9.5): 0.6057 - val_ca2-[9.5,10.3): 0.4076 - val_ca2-[10.3,11.3): 0.8259 - val_ca2-[11.3,14.9): 1.3529 - val_ca3-[8.0,9.5): 0.9192 - val_ca3-[9.5,10.3): 0.5713 - val_ca3-[10.3,11.3): 0.7045 - val_ca3-[11.3,14.9): 0.8491 - val_ca4-[8.0,9.5): 1.1694 - val_ca4-[9.5,10.3): 0.8053 - val_ca4-[10.3,11.3): 0.7956 - val_ca4-[11.3,14.9): 0.7368\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 0.5612 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3907 - ca2-[9.5,10.3): 0.5134 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5491 - ca3-[10.3,11.3): 0.6918 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5093 - ca4-[11.3,14.9): 0.7350 - val_ca1-[8.0,9.5): 0.6001 - val_ca1-[9.5,10.3): 0.5067 - val_ca1-[10.3,11.3): 1.1654 - val_ca1-[11.3,14.9): 2.0810 - val_ca2-[8.0,9.5): 0.6057 - val_ca2-[9.5,10.3): 0.4074 - val_ca2-[10.3,11.3): 0.8290 - val_ca2-[11.3,14.9): 1.4072 - val_ca3-[8.0,9.5): 0.9218 - val_ca3-[9.5,10.3): 0.5728 - val_ca3-[10.3,11.3): 0.7128 - val_ca3-[11.3,14.9): 0.8934 - val_ca4-[8.0,9.5): 1.1823 - val_ca4-[9.5,10.3): 0.8159 - val_ca4-[10.3,11.3): 0.8124 - val_ca4-[11.3,14.9): 0.7696\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5636 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3834 - ca2-[9.5,10.3): 0.5078 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5548 - ca3-[10.3,11.3): 0.6748 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5334 - ca4-[11.3,14.9): 0.7549 - val_ca1-[8.0,9.5): 0.5978 - val_ca1-[9.5,10.3): 0.5036 - val_ca1-[10.3,11.3): 1.1474 - val_ca1-[11.3,14.9): 2.0248 - val_ca2-[8.0,9.5): 0.6047 - val_ca2-[9.5,10.3): 0.4075 - val_ca2-[10.3,11.3): 0.8242 - val_ca2-[11.3,14.9): 1.3807 - val_ca3-[8.0,9.5): 0.9243 - val_ca3-[9.5,10.3): 0.5734 - val_ca3-[10.3,11.3): 0.7103 - val_ca3-[11.3,14.9): 0.8721 - val_ca4-[8.0,9.5): 1.1948 - val_ca4-[9.5,10.3): 0.8242 - val_ca4-[10.3,11.3): 0.8149 - val_ca4-[11.3,14.9): 0.7552\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5633 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3832 - ca2-[9.5,10.3): 0.4942 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5511 - ca3-[10.3,11.3): 0.6876 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5268 - ca4-[11.3,14.9): 0.7342 - val_ca1-[8.0,9.5): 0.5958 - val_ca1-[9.5,10.3): 0.4978 - val_ca1-[10.3,11.3): 1.1398 - val_ca1-[11.3,14.9): 2.0489 - val_ca2-[8.0,9.5): 0.6039 - val_ca2-[9.5,10.3): 0.4067 - val_ca2-[10.3,11.3): 0.8262 - val_ca2-[11.3,14.9): 1.4122 - val_ca3-[8.0,9.5): 0.9203 - val_ca3-[9.5,10.3): 0.5721 - val_ca3-[10.3,11.3): 0.7122 - val_ca3-[11.3,14.9): 0.8910 - val_ca4-[8.0,9.5): 1.2064 - val_ca4-[9.5,10.3): 0.8356 - val_ca4-[10.3,11.3): 0.8218 - val_ca4-[11.3,14.9): 0.7624\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5611 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3860 - ca2-[9.5,10.3): 0.5129 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5483 - ca3-[10.3,11.3): 0.6909 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5311 - ca4-[11.3,14.9): 0.7455 - val_ca1-[8.0,9.5): 0.5939 - val_ca1-[9.5,10.3): 0.4938 - val_ca1-[10.3,11.3): 1.1229 - val_ca1-[11.3,14.9): 2.0213 - val_ca2-[8.0,9.5): 0.6035 - val_ca2-[9.5,10.3): 0.4063 - val_ca2-[10.3,11.3): 0.8197 - val_ca2-[11.3,14.9): 1.4046 - val_ca3-[8.0,9.5): 0.9173 - val_ca3-[9.5,10.3): 0.5700 - val_ca3-[10.3,11.3): 0.7093 - val_ca3-[11.3,14.9): 0.8940 - val_ca4-[8.0,9.5): 1.2180 - val_ca4-[9.5,10.3): 0.8450 - val_ca4-[10.3,11.3): 0.8243 - val_ca4-[11.3,14.9): 0.7577\n",
      "Epoch 97/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5515 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3953 - ca2-[9.5,10.3): 0.4987 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5348 - ca3-[10.3,11.3): 0.6867 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5186 - ca4-[11.3,14.9): 0.7322 - val_ca1-[8.0,9.5): 0.5921 - val_ca1-[9.5,10.3): 0.4899 - val_ca1-[10.3,11.3): 1.1259 - val_ca1-[11.3,14.9): 1.9602 - val_ca2-[8.0,9.5): 0.6011 - val_ca2-[9.5,10.3): 0.4060 - val_ca2-[10.3,11.3): 0.8313 - val_ca2-[11.3,14.9): 1.3783 - val_ca3-[8.0,9.5): 0.9196 - val_ca3-[9.5,10.3): 0.5713 - val_ca3-[10.3,11.3): 0.7103 - val_ca3-[11.3,14.9): 0.8654 - val_ca4-[8.0,9.5): 1.2291 - val_ca4-[9.5,10.3): 0.8542 - val_ca4-[10.3,11.3): 0.8274 - val_ca4-[11.3,14.9): 0.7388\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5467 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3790 - ca2-[9.5,10.3): 0.5065 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5138 - ca3-[10.3,11.3): 0.6896 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5555 - ca4-[11.3,14.9): 0.7411 - val_ca1-[8.0,9.5): 0.5905 - val_ca1-[9.5,10.3): 0.4862 - val_ca1-[10.3,11.3): 1.1190 - val_ca1-[11.3,14.9): 1.9678 - val_ca2-[8.0,9.5): 0.6000 - val_ca2-[9.5,10.3): 0.4056 - val_ca2-[10.3,11.3): 0.8341 - val_ca2-[11.3,14.9): 1.3990 - val_ca3-[8.0,9.5): 0.9236 - val_ca3-[9.5,10.3): 0.5737 - val_ca3-[10.3,11.3): 0.7126 - val_ca3-[11.3,14.9): 0.8713 - val_ca4-[8.0,9.5): 1.2403 - val_ca4-[9.5,10.3): 0.8633 - val_ca4-[10.3,11.3): 0.8342 - val_ca4-[11.3,14.9): 0.7420\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5557 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3698 - ca2-[9.5,10.3): 0.5017 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5534 - ca3-[10.3,11.3): 0.6772 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5669 - ca4-[11.3,14.9): 0.7075 - val_ca1-[8.0,9.5): 0.5890 - val_ca1-[9.5,10.3): 0.4828 - val_ca1-[10.3,11.3): 1.1053 - val_ca1-[11.3,14.9): 1.9811 - val_ca2-[8.0,9.5): 0.5989 - val_ca2-[9.5,10.3): 0.4051 - val_ca2-[10.3,11.3): 0.8312 - val_ca2-[11.3,14.9): 1.4260 - val_ca3-[8.0,9.5): 0.9222 - val_ca3-[9.5,10.3): 0.5728 - val_ca3-[10.3,11.3): 0.7121 - val_ca3-[11.3,14.9): 0.8890 - val_ca4-[8.0,9.5): 1.2504 - val_ca4-[9.5,10.3): 0.8717 - val_ca4-[10.3,11.3): 0.8389 - val_ca4-[11.3,14.9): 0.7516\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5399 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3947 - ca2-[9.5,10.3): 0.4936 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5571 - ca3-[10.3,11.3): 0.6859 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4911 - ca4-[11.3,14.9): 0.7205 - val_ca1-[8.0,9.5): 0.5877 - val_ca1-[9.5,10.3): 0.4796 - val_ca1-[10.3,11.3): 1.0976 - val_ca1-[11.3,14.9): 1.9162 - val_ca2-[8.0,9.5): 0.5965 - val_ca2-[9.5,10.3): 0.4049 - val_ca2-[10.3,11.3): 0.8361 - val_ca2-[11.3,14.9): 1.3957 - val_ca3-[8.0,9.5): 0.9202 - val_ca3-[9.5,10.3): 0.5719 - val_ca3-[10.3,11.3): 0.7121 - val_ca3-[11.3,14.9): 0.8632 - val_ca4-[8.0,9.5): 1.2604 - val_ca4-[9.5,10.3): 0.8799 - val_ca4-[10.3,11.3): 0.8429 - val_ca4-[11.3,14.9): 0.7322\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5480 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3814 - ca2-[9.5,10.3): 0.5044 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5457 - ca3-[10.3,11.3): 0.7011 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4992 - ca4-[11.3,14.9): 0.7215 - val_ca1-[8.0,9.5): 0.5865 - val_ca1-[9.5,10.3): 0.4765 - val_ca1-[10.3,11.3): 1.0960 - val_ca1-[11.3,14.9): 1.9468 - val_ca2-[8.0,9.5): 0.5961 - val_ca2-[9.5,10.3): 0.4045 - val_ca2-[10.3,11.3): 0.8377 - val_ca2-[11.3,14.9): 1.4246 - val_ca3-[8.0,9.5): 0.9152 - val_ca3-[9.5,10.3): 0.5688 - val_ca3-[10.3,11.3): 0.7121 - val_ca3-[11.3,14.9): 0.8827 - val_ca4-[8.0,9.5): 1.2705 - val_ca4-[9.5,10.3): 0.8883 - val_ca4-[10.3,11.3): 0.8462 - val_ca4-[11.3,14.9): 0.7340\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5312 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3741 - ca2-[9.5,10.3): 0.5036 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5526 - ca3-[10.3,11.3): 0.6976 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5149 - ca4-[11.3,14.9): 0.7077 - val_ca1-[8.0,9.5): 0.5853 - val_ca1-[9.5,10.3): 0.4737 - val_ca1-[10.3,11.3): 1.0903 - val_ca1-[11.3,14.9): 1.9339 - val_ca2-[8.0,9.5): 0.5954 - val_ca2-[9.5,10.3): 0.4041 - val_ca2-[10.3,11.3): 0.8374 - val_ca2-[11.3,14.9): 1.4250 - val_ca3-[8.0,9.5): 0.9181 - val_ca3-[9.5,10.3): 0.5698 - val_ca3-[10.3,11.3): 0.7103 - val_ca3-[11.3,14.9): 0.8827 - val_ca4-[8.0,9.5): 1.2801 - val_ca4-[9.5,10.3): 0.8962 - val_ca4-[10.3,11.3): 0.8455 - val_ca4-[11.3,14.9): 0.7321\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5386 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3603 - ca2-[9.5,10.3): 0.4999 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5451 - ca3-[10.3,11.3): 0.6864 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4946 - ca4-[11.3,14.9): 0.7092 - val_ca1-[8.0,9.5): 0.5843 - val_ca1-[9.5,10.3): 0.4710 - val_ca1-[10.3,11.3): 1.0804 - val_ca1-[11.3,14.9): 1.8666 - val_ca2-[8.0,9.5): 0.5941 - val_ca2-[9.5,10.3): 0.4039 - val_ca2-[10.3,11.3): 0.8377 - val_ca2-[11.3,14.9): 1.3859 - val_ca3-[8.0,9.5): 0.9135 - val_ca3-[9.5,10.3): 0.5673 - val_ca3-[10.3,11.3): 0.7095 - val_ca3-[11.3,14.9): 0.8557 - val_ca4-[8.0,9.5): 1.2891 - val_ca4-[9.5,10.3): 0.9036 - val_ca4-[10.3,11.3): 0.8512 - val_ca4-[11.3,14.9): 0.7093\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5317 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3758 - ca2-[9.5,10.3): 0.4985 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5423 - ca3-[10.3,11.3): 0.6897 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5384 - ca4-[11.3,14.9): 0.7098 - val_ca1-[8.0,9.5): 0.5834 - val_ca1-[9.5,10.3): 0.4683 - val_ca1-[10.3,11.3): 1.0561 - val_ca1-[11.3,14.9): 1.8918 - val_ca2-[8.0,9.5): 0.5934 - val_ca2-[9.5,10.3): 0.4035 - val_ca2-[10.3,11.3): 0.8228 - val_ca2-[11.3,14.9): 1.4183 - val_ca3-[8.0,9.5): 0.9147 - val_ca3-[9.5,10.3): 0.5680 - val_ca3-[10.3,11.3): 0.7028 - val_ca3-[11.3,14.9): 0.8787 - val_ca4-[8.0,9.5): 1.2983 - val_ca4-[9.5,10.3): 0.9112 - val_ca4-[10.3,11.3): 0.8505 - val_ca4-[11.3,14.9): 0.7208\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5370 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3654 - ca2-[9.5,10.3): 0.4975 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5629 - ca3-[10.3,11.3): 0.6873 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5087 - ca4-[11.3,14.9): 0.7204 - val_ca1-[8.0,9.5): 0.5825 - val_ca1-[9.5,10.3): 0.4658 - val_ca1-[10.3,11.3): 1.0496 - val_ca1-[11.3,14.9): 1.8396 - val_ca2-[8.0,9.5): 0.5930 - val_ca2-[9.5,10.3): 0.4031 - val_ca2-[10.3,11.3): 0.8221 - val_ca2-[11.3,14.9): 1.3858 - val_ca3-[8.0,9.5): 0.9239 - val_ca3-[9.5,10.3): 0.5726 - val_ca3-[10.3,11.3): 0.7031 - val_ca3-[11.3,14.9): 0.8566 - val_ca4-[8.0,9.5): 1.3074 - val_ca4-[9.5,10.3): 0.9188 - val_ca4-[10.3,11.3): 0.8543 - val_ca4-[11.3,14.9): 0.7157\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5342 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3674 - ca2-[9.5,10.3): 0.4842 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5313 - ca3-[10.3,11.3): 0.7000 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5479 - ca4-[11.3,14.9): 0.7100 - val_ca1-[8.0,9.5): 0.5818 - val_ca1-[9.5,10.3): 0.4634 - val_ca1-[10.3,11.3): 1.0645 - val_ca1-[11.3,14.9): 1.8814 - val_ca2-[8.0,9.5): 0.5920 - val_ca2-[9.5,10.3): 0.4028 - val_ca2-[10.3,11.3): 0.8416 - val_ca2-[11.3,14.9): 1.4325 - val_ca3-[8.0,9.5): 0.9257 - val_ca3-[9.5,10.3): 0.5736 - val_ca3-[10.3,11.3): 0.7139 - val_ca3-[11.3,14.9): 0.8821 - val_ca4-[8.0,9.5): 1.3162 - val_ca4-[9.5,10.3): 0.9261 - val_ca4-[10.3,11.3): 0.8675 - val_ca4-[11.3,14.9): 0.7347\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5262 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3774 - ca2-[9.5,10.3): 0.4981 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5685 - ca3-[10.3,11.3): 0.6883 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5419 - ca4-[11.3,14.9): 0.7133 - val_ca1-[8.0,9.5): 0.5811 - val_ca1-[9.5,10.3): 0.4613 - val_ca1-[10.3,11.3): 1.0554 - val_ca1-[11.3,14.9): 1.8618 - val_ca2-[8.0,9.5): 0.5906 - val_ca2-[9.5,10.3): 0.4027 - val_ca2-[10.3,11.3): 0.8406 - val_ca2-[11.3,14.9): 1.4336 - val_ca3-[8.0,9.5): 0.9187 - val_ca3-[9.5,10.3): 0.5700 - val_ca3-[10.3,11.3): 0.7089 - val_ca3-[11.3,14.9): 0.8805 - val_ca4-[8.0,9.5): 1.3241 - val_ca4-[9.5,10.3): 0.9326 - val_ca4-[10.3,11.3): 0.8658 - val_ca4-[11.3,14.9): 0.7276\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5154 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3745 - ca2-[9.5,10.3): 0.4944 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5317 - ca3-[10.3,11.3): 0.6808 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5186 - ca4-[11.3,14.9): 0.6951 - val_ca1-[8.0,9.5): 0.5805 - val_ca1-[9.5,10.3): 0.4594 - val_ca1-[10.3,11.3): 1.0522 - val_ca1-[11.3,14.9): 1.8446 - val_ca2-[8.0,9.5): 0.5897 - val_ca2-[9.5,10.3): 0.4023 - val_ca2-[10.3,11.3): 0.8428 - val_ca2-[11.3,14.9): 1.4302 - val_ca3-[8.0,9.5): 0.9134 - val_ca3-[9.5,10.3): 0.5664 - val_ca3-[10.3,11.3): 0.7109 - val_ca3-[11.3,14.9): 0.8863 - val_ca4-[8.0,9.5): 1.3312 - val_ca4-[9.5,10.3): 0.9386 - val_ca4-[10.3,11.3): 0.8713 - val_ca4-[11.3,14.9): 0.7298\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5329 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3737 - ca2-[9.5,10.3): 0.4868 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5527 - ca3-[10.3,11.3): 0.7079 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5478 - ca4-[11.3,14.9): 0.7091 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4574 - val_ca1-[10.3,11.3): 1.0468 - val_ca1-[11.3,14.9): 1.8661 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4018 - val_ca2-[10.3,11.3): 0.8427 - val_ca2-[11.3,14.9): 1.4532 - val_ca3-[8.0,9.5): 0.9220 - val_ca3-[9.5,10.3): 0.5706 - val_ca3-[10.3,11.3): 0.7112 - val_ca3-[11.3,14.9): 0.8894 - val_ca4-[8.0,9.5): 1.3389 - val_ca4-[9.5,10.3): 0.9449 - val_ca4-[10.3,11.3): 0.8746 - val_ca4-[11.3,14.9): 0.7248\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5207 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3683 - ca2-[9.5,10.3): 0.4924 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5453 - ca3-[10.3,11.3): 0.6920 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5112 - ca4-[11.3,14.9): 0.7007 - val_ca1-[8.0,9.5): 0.5795 - val_ca1-[9.5,10.3): 0.4555 - val_ca1-[10.3,11.3): 1.0361 - val_ca1-[11.3,14.9): 1.8116 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4015 - val_ca2-[10.3,11.3): 0.8395 - val_ca2-[11.3,14.9): 1.4220 - val_ca3-[8.0,9.5): 0.9257 - val_ca3-[9.5,10.3): 0.5724 - val_ca3-[10.3,11.3): 0.7111 - val_ca3-[11.3,14.9): 0.8723 - val_ca4-[8.0,9.5): 1.3466 - val_ca4-[9.5,10.3): 0.9513 - val_ca4-[10.3,11.3): 0.8790 - val_ca4-[11.3,14.9): 0.7148\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5229 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3704 - ca2-[9.5,10.3): 0.4861 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5410 - ca3-[10.3,11.3): 0.6891 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5149 - ca4-[11.3,14.9): 0.7114 - val_ca1-[8.0,9.5): 0.5790 - val_ca1-[9.5,10.3): 0.4537 - val_ca1-[10.3,11.3): 1.0203 - val_ca1-[11.3,14.9): 1.8511 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4012 - val_ca2-[10.3,11.3): 0.8305 - val_ca2-[11.3,14.9): 1.4603 - val_ca3-[8.0,9.5): 0.9174 - val_ca3-[9.5,10.3): 0.5685 - val_ca3-[10.3,11.3): 0.7080 - val_ca3-[11.3,14.9): 0.9038 - val_ca4-[8.0,9.5): 1.3540 - val_ca4-[9.5,10.3): 0.9575 - val_ca4-[10.3,11.3): 0.8845 - val_ca4-[11.3,14.9): 0.7389\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5283 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3778 - ca2-[9.5,10.3): 0.4855 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5325 - ca3-[10.3,11.3): 0.6910 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4783 - ca4-[11.3,14.9): 0.6973 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4520 - val_ca1-[10.3,11.3): 1.0314 - val_ca1-[11.3,14.9): 1.8292 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4018 - val_ca2-[10.3,11.3): 0.8423 - val_ca2-[11.3,14.9): 1.4503 - val_ca3-[8.0,9.5): 0.9232 - val_ca3-[9.5,10.3): 0.5720 - val_ca3-[10.3,11.3): 0.7107 - val_ca3-[11.3,14.9): 0.8957 - val_ca4-[8.0,9.5): 1.3653 - val_ca4-[9.5,10.3): 0.9667 - val_ca4-[10.3,11.3): 0.8844 - val_ca4-[11.3,14.9): 0.7343\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5249 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3830 - ca2-[9.5,10.3): 0.4845 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5224 - ca3-[10.3,11.3): 0.6944 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5092 - ca4-[11.3,14.9): 0.6965 - val_ca1-[8.0,9.5): 0.5783 - val_ca1-[9.5,10.3): 0.4502 - val_ca1-[10.3,11.3): 1.0247 - val_ca1-[11.3,14.9): 1.7808 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.4007 - val_ca2-[10.3,11.3): 0.8399 - val_ca2-[11.3,14.9): 1.4162 - val_ca3-[8.0,9.5): 0.9187 - val_ca3-[9.5,10.3): 0.5692 - val_ca3-[10.3,11.3): 0.7082 - val_ca3-[11.3,14.9): 0.8679 - val_ca4-[8.0,9.5): 1.3691 - val_ca4-[9.5,10.3): 0.9700 - val_ca4-[10.3,11.3): 0.8851 - val_ca4-[11.3,14.9): 0.7117\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5246 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3691 - ca2-[9.5,10.3): 0.4958 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5472 - ca3-[10.3,11.3): 0.6968 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5702 - ca4-[11.3,14.9): 0.7107 - val_ca1-[8.0,9.5): 0.5779 - val_ca1-[9.5,10.3): 0.4487 - val_ca1-[10.3,11.3): 1.0081 - val_ca1-[11.3,14.9): 1.7933 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.4004 - val_ca2-[10.3,11.3): 0.8289 - val_ca2-[11.3,14.9): 1.4310 - val_ca3-[8.0,9.5): 0.9094 - val_ca3-[9.5,10.3): 0.5642 - val_ca3-[10.3,11.3): 0.7027 - val_ca3-[11.3,14.9): 0.8782 - val_ca4-[8.0,9.5): 1.3758 - val_ca4-[9.5,10.3): 0.9757 - val_ca4-[10.3,11.3): 0.8843 - val_ca4-[11.3,14.9): 0.7030\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5304 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3730 - ca2-[9.5,10.3): 0.4853 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5293 - ca3-[10.3,11.3): 0.6898 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5492 - ca4-[11.3,14.9): 0.6998 - val_ca1-[8.0,9.5): 0.5777 - val_ca1-[9.5,10.3): 0.4473 - val_ca1-[10.3,11.3): 1.0161 - val_ca1-[11.3,14.9): 1.7738 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.3999 - val_ca2-[10.3,11.3): 0.8377 - val_ca2-[11.3,14.9): 1.4192 - val_ca3-[8.0,9.5): 0.9193 - val_ca3-[9.5,10.3): 0.5689 - val_ca3-[10.3,11.3): 0.7081 - val_ca3-[11.3,14.9): 0.8721 - val_ca4-[8.0,9.5): 1.3821 - val_ca4-[9.5,10.3): 0.9809 - val_ca4-[10.3,11.3): 0.8909 - val_ca4-[11.3,14.9): 0.7117\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5260 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3689 - ca2-[9.5,10.3): 0.4958 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5736 - ca3-[10.3,11.3): 0.7053 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5441 - ca4-[11.3,14.9): 0.7091 - val_ca1-[8.0,9.5): 0.5775 - val_ca1-[9.5,10.3): 0.4460 - val_ca1-[10.3,11.3): 1.0069 - val_ca1-[11.3,14.9): 1.7781 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.3997 - val_ca2-[10.3,11.3): 0.8357 - val_ca2-[11.3,14.9): 1.4329 - val_ca3-[8.0,9.5): 0.9186 - val_ca3-[9.5,10.3): 0.5687 - val_ca3-[10.3,11.3): 0.7076 - val_ca3-[11.3,14.9): 0.8882 - val_ca4-[8.0,9.5): 1.3878 - val_ca4-[9.5,10.3): 0.9857 - val_ca4-[10.3,11.3): 0.8946 - val_ca4-[11.3,14.9): 0.7291\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5287 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3697 - ca2-[9.5,10.3): 0.4890 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5386 - ca3-[10.3,11.3): 0.6822 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5385 - ca4-[11.3,14.9): 0.6896 - val_ca1-[8.0,9.5): 0.5773 - val_ca1-[9.5,10.3): 0.4447 - val_ca1-[10.3,11.3): 1.0120 - val_ca1-[11.3,14.9): 1.7668 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3996 - val_ca2-[10.3,11.3): 0.8436 - val_ca2-[11.3,14.9): 1.4261 - val_ca3-[8.0,9.5): 0.9197 - val_ca3-[9.5,10.3): 0.5695 - val_ca3-[10.3,11.3): 0.7121 - val_ca3-[11.3,14.9): 0.8689 - val_ca4-[8.0,9.5): 1.3934 - val_ca4-[9.5,10.3): 0.9904 - val_ca4-[10.3,11.3): 0.9010 - val_ca4-[11.3,14.9): 0.7014\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5319 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3617 - ca2-[9.5,10.3): 0.4846 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5315 - ca3-[10.3,11.3): 0.6957 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5355 - ca4-[11.3,14.9): 0.6792 - val_ca1-[8.0,9.5): 0.5772 - val_ca1-[9.5,10.3): 0.4435 - val_ca1-[10.3,11.3): 0.9914 - val_ca1-[11.3,14.9): 1.7677 - val_ca2-[8.0,9.5): 0.5852 - val_ca2-[9.5,10.3): 0.3994 - val_ca2-[10.3,11.3): 0.8300 - val_ca2-[11.3,14.9): 1.4441 - val_ca3-[8.0,9.5): 0.9201 - val_ca3-[9.5,10.3): 0.5694 - val_ca3-[10.3,11.3): 0.6978 - val_ca3-[11.3,14.9): 0.8791 - val_ca4-[8.0,9.5): 1.3990 - val_ca4-[9.5,10.3): 0.9950 - val_ca4-[10.3,11.3): 0.8871 - val_ca4-[11.3,14.9): 0.7021\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5281 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3714 - ca2-[9.5,10.3): 0.4904 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5373 - ca3-[10.3,11.3): 0.6694 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5357 - ca4-[11.3,14.9): 0.6943 - val_ca1-[8.0,9.5): 0.5770 - val_ca1-[9.5,10.3): 0.4424 - val_ca1-[10.3,11.3): 1.0028 - val_ca1-[11.3,14.9): 1.7394 - val_ca2-[8.0,9.5): 0.5847 - val_ca2-[9.5,10.3): 0.3991 - val_ca2-[10.3,11.3): 0.8425 - val_ca2-[11.3,14.9): 1.4216 - val_ca3-[8.0,9.5): 0.9275 - val_ca3-[9.5,10.3): 0.5728 - val_ca3-[10.3,11.3): 0.7101 - val_ca3-[11.3,14.9): 0.8687 - val_ca4-[8.0,9.5): 1.4042 - val_ca4-[9.5,10.3): 0.9993 - val_ca4-[10.3,11.3): 0.9031 - val_ca4-[11.3,14.9): 0.7125\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3584 - ca2-[9.5,10.3): 0.4726 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5380 - ca3-[10.3,11.3): 0.6879 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5407 - ca4-[11.3,14.9): 0.7120 - val_ca1-[8.0,9.5): 0.5769 - val_ca1-[9.5,10.3): 0.4414 - val_ca1-[10.3,11.3): 1.0005 - val_ca1-[11.3,14.9): 1.7471 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.3990 - val_ca2-[10.3,11.3): 0.8421 - val_ca2-[11.3,14.9): 1.4390 - val_ca3-[8.0,9.5): 0.9153 - val_ca3-[9.5,10.3): 0.5668 - val_ca3-[10.3,11.3): 0.7069 - val_ca3-[11.3,14.9): 0.8890 - val_ca4-[8.0,9.5): 1.4087 - val_ca4-[9.5,10.3): 1.0031 - val_ca4-[10.3,11.3): 0.9002 - val_ca4-[11.3,14.9): 0.7200\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5229 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3692 - ca2-[9.5,10.3): 0.4902 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5443 - ca3-[10.3,11.3): 0.6832 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5346 - ca4-[11.3,14.9): 0.6862 - val_ca1-[8.0,9.5): 0.5769 - val_ca1-[9.5,10.3): 0.4404 - val_ca1-[10.3,11.3): 0.9915 - val_ca1-[11.3,14.9): 1.7847 - val_ca2-[8.0,9.5): 0.5850 - val_ca2-[9.5,10.3): 0.3985 - val_ca2-[10.3,11.3): 0.8366 - val_ca2-[11.3,14.9): 1.4702 - val_ca3-[8.0,9.5): 0.9146 - val_ca3-[9.5,10.3): 0.5663 - val_ca3-[10.3,11.3): 0.7080 - val_ca3-[11.3,14.9): 0.9051 - val_ca4-[8.0,9.5): 1.4133 - val_ca4-[9.5,10.3): 1.0069 - val_ca4-[10.3,11.3): 0.9086 - val_ca4-[11.3,14.9): 0.7215\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5233 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3523 - ca2-[9.5,10.3): 0.4857 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5645 - ca3-[10.3,11.3): 0.7016 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5227 - ca4-[11.3,14.9): 0.6885 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4393 - val_ca1-[10.3,11.3): 0.9911 - val_ca1-[11.3,14.9): 1.7122 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3980 - val_ca2-[10.3,11.3): 0.8341 - val_ca2-[11.3,14.9): 1.4034 - val_ca3-[8.0,9.5): 0.9285 - val_ca3-[9.5,10.3): 0.5734 - val_ca3-[10.3,11.3): 0.7068 - val_ca3-[11.3,14.9): 0.8532 - val_ca4-[8.0,9.5): 1.4189 - val_ca4-[9.5,10.3): 1.0115 - val_ca4-[10.3,11.3): 0.9072 - val_ca4-[11.3,14.9): 0.6897\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3684 - ca2-[9.5,10.3): 0.4814 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5371 - ca3-[10.3,11.3): 0.7083 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5721 - ca4-[11.3,14.9): 0.7043 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4384 - val_ca1-[10.3,11.3): 0.9881 - val_ca1-[11.3,14.9): 1.7277 - val_ca2-[8.0,9.5): 0.5850 - val_ca2-[9.5,10.3): 0.3981 - val_ca2-[10.3,11.3): 0.8367 - val_ca2-[11.3,14.9): 1.4244 - val_ca3-[8.0,9.5): 0.9276 - val_ca3-[9.5,10.3): 0.5730 - val_ca3-[10.3,11.3): 0.7064 - val_ca3-[11.3,14.9): 0.8647 - val_ca4-[8.0,9.5): 1.4233 - val_ca4-[9.5,10.3): 1.0152 - val_ca4-[10.3,11.3): 0.9092 - val_ca4-[11.3,14.9): 0.6984\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5238 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3731 - ca2-[9.5,10.3): 0.4857 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5498 - ca3-[10.3,11.3): 0.6755 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5584 - ca4-[11.3,14.9): 0.7143 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4377 - val_ca1-[10.3,11.3): 0.9856 - val_ca1-[11.3,14.9): 1.7142 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3981 - val_ca2-[10.3,11.3): 0.8386 - val_ca2-[11.3,14.9): 1.4232 - val_ca3-[8.0,9.5): 0.9168 - val_ca3-[9.5,10.3): 0.5670 - val_ca3-[10.3,11.3): 0.7060 - val_ca3-[11.3,14.9): 0.8699 - val_ca4-[8.0,9.5): 1.4271 - val_ca4-[9.5,10.3): 1.0183 - val_ca4-[10.3,11.3): 0.9109 - val_ca4-[11.3,14.9): 0.7019\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5263 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3588 - ca2-[9.5,10.3): 0.4929 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5381 - ca3-[10.3,11.3): 0.6879 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5725 - ca4-[11.3,14.9): 0.6920 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4369 - val_ca1-[10.3,11.3): 0.9849 - val_ca1-[11.3,14.9): 1.7338 - val_ca2-[8.0,9.5): 0.5848 - val_ca2-[9.5,10.3): 0.3976 - val_ca2-[10.3,11.3): 0.8375 - val_ca2-[11.3,14.9): 1.4417 - val_ca3-[8.0,9.5): 0.9165 - val_ca3-[9.5,10.3): 0.5665 - val_ca3-[10.3,11.3): 0.7082 - val_ca3-[11.3,14.9): 0.8953 - val_ca4-[8.0,9.5): 1.4311 - val_ca4-[9.5,10.3): 1.0217 - val_ca4-[10.3,11.3): 0.9152 - val_ca4-[11.3,14.9): 0.7271\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5260 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3679 - ca2-[9.5,10.3): 0.4964 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5459 - ca3-[10.3,11.3): 0.6689 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5463 - ca4-[11.3,14.9): 0.6683 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4361 - val_ca1-[10.3,11.3): 0.9673 - val_ca1-[11.3,14.9): 1.7019 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3971 - val_ca2-[10.3,11.3): 0.8231 - val_ca2-[11.3,14.9): 1.4051 - val_ca3-[8.0,9.5): 0.9221 - val_ca3-[9.5,10.3): 0.5695 - val_ca3-[10.3,11.3): 0.6967 - val_ca3-[11.3,14.9): 0.8500 - val_ca4-[8.0,9.5): 1.4353 - val_ca4-[9.5,10.3): 1.0251 - val_ca4-[10.3,11.3): 0.9033 - val_ca4-[11.3,14.9): 0.6684\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5328 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3617 - ca2-[9.5,10.3): 0.4917 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5418 - ca3-[10.3,11.3): 0.6846 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5662 - ca4-[11.3,14.9): 0.6970 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4354 - val_ca1-[10.3,11.3): 0.9778 - val_ca1-[11.3,14.9): 1.7334 - val_ca2-[8.0,9.5): 0.5842 - val_ca2-[9.5,10.3): 0.3973 - val_ca2-[10.3,11.3): 0.8360 - val_ca2-[11.3,14.9): 1.4527 - val_ca3-[8.0,9.5): 0.9224 - val_ca3-[9.5,10.3): 0.5695 - val_ca3-[10.3,11.3): 0.7055 - val_ca3-[11.3,14.9): 0.8886 - val_ca4-[8.0,9.5): 1.4389 - val_ca4-[9.5,10.3): 1.0282 - val_ca4-[10.3,11.3): 0.9162 - val_ca4-[11.3,14.9): 0.7123\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5101 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3646 - ca2-[9.5,10.3): 0.4896 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5524 - ca3-[10.3,11.3): 0.6878 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5406 - ca4-[11.3,14.9): 0.6980 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4347 - val_ca1-[10.3,11.3): 0.9694 - val_ca1-[11.3,14.9): 1.7315 - val_ca2-[8.0,9.5): 0.5833 - val_ca2-[9.5,10.3): 0.3974 - val_ca2-[10.3,11.3): 0.8308 - val_ca2-[11.3,14.9): 1.4541 - val_ca3-[8.0,9.5): 0.9129 - val_ca3-[9.5,10.3): 0.5641 - val_ca3-[10.3,11.3): 0.6973 - val_ca3-[11.3,14.9): 0.8949 - val_ca4-[8.0,9.5): 1.4424 - val_ca4-[9.5,10.3): 1.0311 - val_ca4-[10.3,11.3): 0.9077 - val_ca4-[11.3,14.9): 0.7161\n",
      "Epoch 129/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5283 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3748 - ca2-[9.5,10.3): 0.4888 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5488 - ca3-[10.3,11.3): 0.6907 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5119 - ca4-[11.3,14.9): 0.6880 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4342 - val_ca1-[10.3,11.3): 0.9736 - val_ca1-[11.3,14.9): 1.7249 - val_ca2-[8.0,9.5): 0.5820 - val_ca2-[9.5,10.3): 0.3976 - val_ca2-[10.3,11.3): 0.8412 - val_ca2-[11.3,14.9): 1.4601 - val_ca3-[8.0,9.5): 0.9126 - val_ca3-[9.5,10.3): 0.5634 - val_ca3-[10.3,11.3): 0.7047 - val_ca3-[11.3,14.9): 0.8951 - val_ca4-[8.0,9.5): 1.4444 - val_ca4-[9.5,10.3): 1.0327 - val_ca4-[10.3,11.3): 0.9187 - val_ca4-[11.3,14.9): 0.7168\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5303 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3592 - ca2-[9.5,10.3): 0.4821 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5314 - ca3-[10.3,11.3): 0.6839 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5652 - ca4-[11.3,14.9): 0.6940 - val_ca1-[8.0,9.5): 0.5769 - val_ca1-[9.5,10.3): 0.4336 - val_ca1-[10.3,11.3): 0.9714 - val_ca1-[11.3,14.9): 1.6984 - val_ca2-[8.0,9.5): 0.5827 - val_ca2-[9.5,10.3): 0.3968 - val_ca2-[10.3,11.3): 0.8375 - val_ca2-[11.3,14.9): 1.4387 - val_ca3-[8.0,9.5): 0.9215 - val_ca3-[9.5,10.3): 0.5679 - val_ca3-[10.3,11.3): 0.7049 - val_ca3-[11.3,14.9): 0.8816 - val_ca4-[8.0,9.5): 1.4471 - val_ca4-[9.5,10.3): 1.0349 - val_ca4-[10.3,11.3): 0.9198 - val_ca4-[11.3,14.9): 0.7127\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5174 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3570 - ca2-[9.5,10.3): 0.4894 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4957 - ca3-[10.3,11.3): 0.6935 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5509 - ca4-[11.3,14.9): 0.7021 - val_ca1-[8.0,9.5): 0.5770 - val_ca1-[9.5,10.3): 0.4330 - val_ca1-[10.3,11.3): 0.9730 - val_ca1-[11.3,14.9): 1.6393 - val_ca2-[8.0,9.5): 0.5825 - val_ca2-[9.5,10.3): 0.3968 - val_ca2-[10.3,11.3): 0.8405 - val_ca2-[11.3,14.9): 1.3824 - val_ca3-[8.0,9.5): 0.9136 - val_ca3-[9.5,10.3): 0.5635 - val_ca3-[10.3,11.3): 0.7085 - val_ca3-[11.3,14.9): 0.8456 - val_ca4-[8.0,9.5): 1.4500 - val_ca4-[9.5,10.3): 1.0373 - val_ca4-[10.3,11.3): 0.9263 - val_ca4-[11.3,14.9): 0.6855\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5149 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3704 - ca2-[9.5,10.3): 0.4885 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5452 - ca3-[10.3,11.3): 0.6822 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5842 - ca4-[11.3,14.9): 0.6888 - val_ca1-[8.0,9.5): 0.5770 - val_ca1-[9.5,10.3): 0.4324 - val_ca1-[10.3,11.3): 0.9587 - val_ca1-[11.3,14.9): 1.6954 - val_ca2-[8.0,9.5): 0.5835 - val_ca2-[9.5,10.3): 0.3963 - val_ca2-[10.3,11.3): 0.8278 - val_ca2-[11.3,14.9): 1.4407 - val_ca3-[8.0,9.5): 0.9082 - val_ca3-[9.5,10.3): 0.5607 - val_ca3-[10.3,11.3): 0.7032 - val_ca3-[11.3,14.9): 0.8945 - val_ca4-[8.0,9.5): 1.4535 - val_ca4-[9.5,10.3): 1.0403 - val_ca4-[10.3,11.3): 0.9283 - val_ca4-[11.3,14.9): 0.7161\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5189 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3588 - ca2-[9.5,10.3): 0.4771 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5328 - ca3-[10.3,11.3): 0.6554 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5112 - ca4-[11.3,14.9): 0.6775 - val_ca1-[8.0,9.5): 0.5771 - val_ca1-[9.5,10.3): 0.4319 - val_ca1-[10.3,11.3): 0.9652 - val_ca1-[11.3,14.9): 1.6815 - val_ca2-[8.0,9.5): 0.5815 - val_ca2-[9.5,10.3): 0.3969 - val_ca2-[10.3,11.3): 0.8400 - val_ca2-[11.3,14.9): 1.4369 - val_ca3-[8.0,9.5): 0.9131 - val_ca3-[9.5,10.3): 0.5630 - val_ca3-[10.3,11.3): 0.7033 - val_ca3-[11.3,14.9): 0.8734 - val_ca4-[8.0,9.5): 1.4551 - val_ca4-[9.5,10.3): 1.0416 - val_ca4-[10.3,11.3): 0.9235 - val_ca4-[11.3,14.9): 0.6951\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5149 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3552 - ca2-[9.5,10.3): 0.4737 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5614 - ca3-[10.3,11.3): 0.6947 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5482 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5772 - val_ca1-[9.5,10.3): 0.4314 - val_ca1-[10.3,11.3): 0.9471 - val_ca1-[11.3,14.9): 1.6774 - val_ca2-[8.0,9.5): 0.5829 - val_ca2-[9.5,10.3): 0.3962 - val_ca2-[10.3,11.3): 0.8206 - val_ca2-[11.3,14.9): 1.4273 - val_ca3-[8.0,9.5): 0.9112 - val_ca3-[9.5,10.3): 0.5619 - val_ca3-[10.3,11.3): 0.6962 - val_ca3-[11.3,14.9): 0.8775 - val_ca4-[8.0,9.5): 1.4581 - val_ca4-[9.5,10.3): 1.0441 - val_ca4-[10.3,11.3): 0.9216 - val_ca4-[11.3,14.9): 0.6951\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3587 - ca2-[9.5,10.3): 0.4729 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5388 - ca3-[10.3,11.3): 0.6685 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5668 - ca4-[11.3,14.9): 0.7020 - val_ca1-[8.0,9.5): 0.5773 - val_ca1-[9.5,10.3): 0.4239 - val_ca1-[10.3,11.3): 0.9605 - val_ca1-[11.3,14.9): 1.6736 - val_ca2-[8.0,9.5): 0.5833 - val_ca2-[9.5,10.3): 0.3890 - val_ca2-[10.3,11.3): 0.8324 - val_ca2-[11.3,14.9): 1.4259 - val_ca3-[8.0,9.5): 0.9143 - val_ca3-[9.5,10.3): 0.5611 - val_ca3-[10.3,11.3): 0.7053 - val_ca3-[11.3,14.9): 0.8849 - val_ca4-[8.0,9.5): 1.4602 - val_ca4-[9.5,10.3): 1.0478 - val_ca4-[10.3,11.3): 0.9325 - val_ca4-[11.3,14.9): 0.7205\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5217 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3580 - ca2-[9.5,10.3): 0.4829 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5275 - ca3-[10.3,11.3): 0.6707 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5589 - ca4-[11.3,14.9): 0.7112 - val_ca1-[8.0,9.5): 0.5773 - val_ca1-[9.5,10.3): 0.4305 - val_ca1-[10.3,11.3): 0.9618 - val_ca1-[11.3,14.9): 1.6819 - val_ca2-[8.0,9.5): 0.5819 - val_ca2-[9.5,10.3): 0.3962 - val_ca2-[10.3,11.3): 0.8393 - val_ca2-[11.3,14.9): 1.4442 - val_ca3-[8.0,9.5): 0.9165 - val_ca3-[9.5,10.3): 0.5644 - val_ca3-[10.3,11.3): 0.7048 - val_ca3-[11.3,14.9): 0.8892 - val_ca4-[8.0,9.5): 1.4615 - val_ca4-[9.5,10.3): 1.0469 - val_ca4-[10.3,11.3): 0.9290 - val_ca4-[11.3,14.9): 0.7235\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5136 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3555 - ca2-[9.5,10.3): 0.4955 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5372 - ca3-[10.3,11.3): 0.6881 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5520 - ca4-[11.3,14.9): 0.6849 - val_ca1-[8.0,9.5): 0.5774 - val_ca1-[9.5,10.3): 0.4304 - val_ca1-[10.3,11.3): 0.9581 - val_ca1-[11.3,14.9): 1.6614 - val_ca2-[8.0,9.5): 0.5824 - val_ca2-[9.5,10.3): 0.3968 - val_ca2-[10.3,11.3): 0.8353 - val_ca2-[11.3,14.9): 1.4209 - val_ca3-[8.0,9.5): 0.9146 - val_ca3-[9.5,10.3): 0.5649 - val_ca3-[10.3,11.3): 0.7025 - val_ca3-[11.3,14.9): 0.8701 - val_ca4-[8.0,9.5): 1.4639 - val_ca4-[9.5,10.3): 1.0520 - val_ca4-[10.3,11.3): 0.9276 - val_ca4-[11.3,14.9): 0.7035\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5123 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3563 - ca2-[9.5,10.3): 0.4884 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5292 - ca3-[10.3,11.3): 0.6902 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5703 - ca4-[11.3,14.9): 0.7018 - val_ca1-[8.0,9.5): 0.5775 - val_ca1-[9.5,10.3): 0.4297 - val_ca1-[10.3,11.3): 0.9605 - val_ca1-[11.3,14.9): 1.6797 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3952 - val_ca2-[10.3,11.3): 0.8341 - val_ca2-[11.3,14.9): 1.4329 - val_ca3-[8.0,9.5): 0.9031 - val_ca3-[9.5,10.3): 0.5563 - val_ca3-[10.3,11.3): 0.7064 - val_ca3-[11.3,14.9): 0.8925 - val_ca4-[8.0,9.5): 1.4665 - val_ca4-[9.5,10.3): 1.0511 - val_ca4-[10.3,11.3): 0.9340 - val_ca4-[11.3,14.9): 0.7063\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5133 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3647 - ca2-[9.5,10.3): 0.4792 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4946 - ca3-[10.3,11.3): 0.6888 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4909 - ca4-[11.3,14.9): 0.6928 - val_ca1-[8.0,9.5): 0.5776 - val_ca1-[9.5,10.3): 0.4293 - val_ca1-[10.3,11.3): 0.9502 - val_ca1-[11.3,14.9): 1.6245 - val_ca2-[8.0,9.5): 0.5839 - val_ca2-[9.5,10.3): 0.3951 - val_ca2-[10.3,11.3): 0.8269 - val_ca2-[11.3,14.9): 1.3909 - val_ca3-[8.0,9.5): 0.9081 - val_ca3-[9.5,10.3): 0.5589 - val_ca3-[10.3,11.3): 0.7013 - val_ca3-[11.3,14.9): 0.8687 - val_ca4-[8.0,9.5): 1.4685 - val_ca4-[9.5,10.3): 1.0528 - val_ca4-[10.3,11.3): 0.9314 - val_ca4-[11.3,14.9): 0.7050\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5163 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3540 - ca2-[9.5,10.3): 0.4773 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5152 - ca3-[10.3,11.3): 0.6801 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5365 - ca4-[11.3,14.9): 0.6967 - val_ca1-[8.0,9.5): 0.5777 - val_ca1-[9.5,10.3): 0.4289 - val_ca1-[10.3,11.3): 0.9579 - val_ca1-[11.3,14.9): 1.6378 - val_ca2-[8.0,9.5): 0.5820 - val_ca2-[9.5,10.3): 0.3957 - val_ca2-[10.3,11.3): 0.8397 - val_ca2-[11.3,14.9): 1.4118 - val_ca3-[8.0,9.5): 0.9137 - val_ca3-[9.5,10.3): 0.5621 - val_ca3-[10.3,11.3): 0.7036 - val_ca3-[11.3,14.9): 0.8671 - val_ca4-[8.0,9.5): 1.4701 - val_ca4-[9.5,10.3): 1.0541 - val_ca4-[10.3,11.3): 0.9303 - val_ca4-[11.3,14.9): 0.7061\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5266 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3659 - ca2-[9.5,10.3): 0.4758 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5060 - ca3-[10.3,11.3): 0.6696 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5646 - ca4-[11.3,14.9): 0.6948 - val_ca1-[8.0,9.5): 0.5778 - val_ca1-[9.5,10.3): 0.4285 - val_ca1-[10.3,11.3): 0.9558 - val_ca1-[11.3,14.9): 1.6573 - val_ca2-[8.0,9.5): 0.5832 - val_ca2-[9.5,10.3): 0.3952 - val_ca2-[10.3,11.3): 0.8360 - val_ca2-[11.3,14.9): 1.4199 - val_ca3-[8.0,9.5): 0.9111 - val_ca3-[9.5,10.3): 0.5608 - val_ca3-[10.3,11.3): 0.7053 - val_ca3-[11.3,14.9): 0.8800 - val_ca4-[8.0,9.5): 1.4722 - val_ca4-[9.5,10.3): 1.0559 - val_ca4-[10.3,11.3): 0.9366 - val_ca4-[11.3,14.9): 0.7134\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5075 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3597 - ca2-[9.5,10.3): 0.4796 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5283 - ca3-[10.3,11.3): 0.6886 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5269 - ca4-[11.3,14.9): 0.6941 - val_ca1-[8.0,9.5): 0.5779 - val_ca1-[9.5,10.3): 0.4282 - val_ca1-[10.3,11.3): 0.9569 - val_ca1-[11.3,14.9): 1.6619 - val_ca2-[8.0,9.5): 0.5832 - val_ca2-[9.5,10.3): 0.3952 - val_ca2-[10.3,11.3): 0.8378 - val_ca2-[11.3,14.9): 1.4293 - val_ca3-[8.0,9.5): 0.9061 - val_ca3-[9.5,10.3): 0.5578 - val_ca3-[10.3,11.3): 0.7052 - val_ca3-[11.3,14.9): 0.8848 - val_ca4-[8.0,9.5): 1.4743 - val_ca4-[9.5,10.3): 1.0577 - val_ca4-[10.3,11.3): 0.9350 - val_ca4-[11.3,14.9): 0.7088\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5101 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3648 - ca2-[9.5,10.3): 0.4869 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4952 - ca3-[10.3,11.3): 0.6825 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4983 - ca4-[11.3,14.9): 0.6878 - val_ca1-[8.0,9.5): 0.5779 - val_ca1-[9.5,10.3): 0.4279 - val_ca1-[10.3,11.3): 0.9377 - val_ca1-[11.3,14.9): 1.6442 - val_ca2-[8.0,9.5): 0.5834 - val_ca2-[9.5,10.3): 0.3949 - val_ca2-[10.3,11.3): 0.8234 - val_ca2-[11.3,14.9): 1.4188 - val_ca3-[8.0,9.5): 0.9015 - val_ca3-[9.5,10.3): 0.5546 - val_ca3-[10.3,11.3): 0.6990 - val_ca3-[11.3,14.9): 0.8834 - val_ca4-[8.0,9.5): 1.4752 - val_ca4-[9.5,10.3): 1.0584 - val_ca4-[10.3,11.3): 0.9349 - val_ca4-[11.3,14.9): 0.7026\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5320 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3638 - ca2-[9.5,10.3): 0.4865 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5238 - ca3-[10.3,11.3): 0.6822 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5481 - ca4-[11.3,14.9): 0.6856 - val_ca1-[8.0,9.5): 0.5780 - val_ca1-[9.5,10.3): 0.4277 - val_ca1-[10.3,11.3): 0.9424 - val_ca1-[11.3,14.9): 1.6613 - val_ca2-[8.0,9.5): 0.5823 - val_ca2-[9.5,10.3): 0.3951 - val_ca2-[10.3,11.3): 0.8296 - val_ca2-[11.3,14.9): 1.4433 - val_ca3-[8.0,9.5): 0.9064 - val_ca3-[9.5,10.3): 0.5572 - val_ca3-[10.3,11.3): 0.6936 - val_ca3-[11.3,14.9): 0.8849 - val_ca4-[8.0,9.5): 1.4762 - val_ca4-[9.5,10.3): 1.0591 - val_ca4-[10.3,11.3): 0.9231 - val_ca4-[11.3,14.9): 0.6957\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5276 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3656 - ca2-[9.5,10.3): 0.4789 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5128 - ca3-[10.3,11.3): 0.6928 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5495 - ca4-[11.3,14.9): 0.6888 - val_ca1-[8.0,9.5): 0.5781 - val_ca1-[9.5,10.3): 0.4274 - val_ca1-[10.3,11.3): 0.9513 - val_ca1-[11.3,14.9): 1.6628 - val_ca2-[8.0,9.5): 0.5827 - val_ca2-[9.5,10.3): 0.3948 - val_ca2-[10.3,11.3): 0.8353 - val_ca2-[11.3,14.9): 1.4374 - val_ca3-[8.0,9.5): 0.9045 - val_ca3-[9.5,10.3): 0.5559 - val_ca3-[10.3,11.3): 0.7037 - val_ca3-[11.3,14.9): 0.8901 - val_ca4-[8.0,9.5): 1.4772 - val_ca4-[9.5,10.3): 1.0600 - val_ca4-[10.3,11.3): 0.9389 - val_ca4-[11.3,14.9): 0.7097\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5186 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3645 - ca2-[9.5,10.3): 0.4822 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4896 - ca3-[10.3,11.3): 0.6721 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5225 - ca4-[11.3,14.9): 0.6824 - val_ca1-[8.0,9.5): 0.5782 - val_ca1-[9.5,10.3): 0.4271 - val_ca1-[10.3,11.3): 0.9435 - val_ca1-[11.3,14.9): 1.6074 - val_ca2-[8.0,9.5): 0.5827 - val_ca2-[9.5,10.3): 0.3948 - val_ca2-[10.3,11.3): 0.8304 - val_ca2-[11.3,14.9): 1.3925 - val_ca3-[8.0,9.5): 0.9072 - val_ca3-[9.5,10.3): 0.5572 - val_ca3-[10.3,11.3): 0.7009 - val_ca3-[11.3,14.9): 0.8613 - val_ca4-[8.0,9.5): 1.4786 - val_ca4-[9.5,10.3): 1.0611 - val_ca4-[10.3,11.3): 0.9385 - val_ca4-[11.3,14.9): 0.6989\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5279 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3547 - ca2-[9.5,10.3): 0.4768 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5450 - ca3-[10.3,11.3): 0.6805 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5278 - ca4-[11.3,14.9): 0.6886 - val_ca1-[8.0,9.5): 0.5783 - val_ca1-[9.5,10.3): 0.4269 - val_ca1-[10.3,11.3): 0.9418 - val_ca1-[11.3,14.9): 1.6408 - val_ca2-[8.0,9.5): 0.5827 - val_ca2-[9.5,10.3): 0.3948 - val_ca2-[10.3,11.3): 0.8292 - val_ca2-[11.3,14.9): 1.4231 - val_ca3-[8.0,9.5): 0.9090 - val_ca3-[9.5,10.3): 0.5581 - val_ca3-[10.3,11.3): 0.6908 - val_ca3-[11.3,14.9): 0.8641 - val_ca4-[8.0,9.5): 1.4801 - val_ca4-[9.5,10.3): 1.0624 - val_ca4-[10.3,11.3): 0.9208 - val_ca4-[11.3,14.9): 0.6763\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5188 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3648 - ca2-[9.5,10.3): 0.4758 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5396 - ca3-[10.3,11.3): 0.6686 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5454 - ca4-[11.3,14.9): 0.6879 - val_ca1-[8.0,9.5): 0.5784 - val_ca1-[9.5,10.3): 0.4266 - val_ca1-[10.3,11.3): 0.9461 - val_ca1-[11.3,14.9): 1.6658 - val_ca2-[8.0,9.5): 0.5835 - val_ca2-[9.5,10.3): 0.3945 - val_ca2-[10.3,11.3): 0.8312 - val_ca2-[11.3,14.9): 1.4416 - val_ca3-[8.0,9.5): 0.9121 - val_ca3-[9.5,10.3): 0.5600 - val_ca3-[10.3,11.3): 0.7006 - val_ca3-[11.3,14.9): 0.8811 - val_ca4-[8.0,9.5): 1.4817 - val_ca4-[9.5,10.3): 1.0637 - val_ca4-[10.3,11.3): 0.9383 - val_ca4-[11.3,14.9): 0.6971\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5115 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3654 - ca2-[9.5,10.3): 0.4726 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5429 - ca3-[10.3,11.3): 0.6807 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5460 - ca4-[11.3,14.9): 0.6890 - val_ca1-[8.0,9.5): 0.5784 - val_ca1-[9.5,10.3): 0.4264 - val_ca1-[10.3,11.3): 0.9157 - val_ca1-[11.3,14.9): 1.6193 - val_ca2-[8.0,9.5): 0.5834 - val_ca2-[9.5,10.3): 0.3947 - val_ca2-[10.3,11.3): 0.8032 - val_ca2-[11.3,14.9): 1.4020 - val_ca3-[8.0,9.5): 0.9024 - val_ca3-[9.5,10.3): 0.5546 - val_ca3-[10.3,11.3): 0.6852 - val_ca3-[11.3,14.9): 0.8728 - val_ca4-[8.0,9.5): 1.4834 - val_ca4-[9.5,10.3): 1.0651 - val_ca4-[10.3,11.3): 0.9340 - val_ca4-[11.3,14.9): 0.7069\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5228 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3559 - ca2-[9.5,10.3): 0.4826 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5236 - ca3-[10.3,11.3): 0.6852 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5739 - ca4-[11.3,14.9): 0.6728 - val_ca1-[8.0,9.5): 0.5785 - val_ca1-[9.5,10.3): 0.4262 - val_ca1-[10.3,11.3): 0.9422 - val_ca1-[11.3,14.9): 1.6325 - val_ca2-[8.0,9.5): 0.5847 - val_ca2-[9.5,10.3): 0.3942 - val_ca2-[10.3,11.3): 0.8262 - val_ca2-[11.3,14.9): 1.4032 - val_ca3-[8.0,9.5): 0.8984 - val_ca3-[9.5,10.3): 0.5520 - val_ca3-[10.3,11.3): 0.6974 - val_ca3-[11.3,14.9): 0.8769 - val_ca4-[8.0,9.5): 1.4849 - val_ca4-[9.5,10.3): 1.0664 - val_ca4-[10.3,11.3): 0.9372 - val_ca4-[11.3,14.9): 0.7034\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5207 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3605 - ca2-[9.5,10.3): 0.4835 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5356 - ca3-[10.3,11.3): 0.6862 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5621 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5786 - val_ca1-[9.5,10.3): 0.4260 - val_ca1-[10.3,11.3): 0.9440 - val_ca1-[11.3,14.9): 1.6116 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3939 - val_ca2-[10.3,11.3): 0.8268 - val_ca2-[11.3,14.9): 1.3908 - val_ca3-[8.0,9.5): 0.9106 - val_ca3-[9.5,10.3): 0.5589 - val_ca3-[10.3,11.3): 0.6974 - val_ca3-[11.3,14.9): 0.8581 - val_ca4-[8.0,9.5): 1.4854 - val_ca4-[9.5,10.3): 1.0667 - val_ca4-[10.3,11.3): 0.9349 - val_ca4-[11.3,14.9): 0.6897\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5248 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3683 - ca2-[9.5,10.3): 0.4810 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5399 - ca3-[10.3,11.3): 0.6743 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5109 - ca4-[11.3,14.9): 0.6911 - val_ca1-[8.0,9.5): 0.5786 - val_ca1-[9.5,10.3): 0.4259 - val_ca1-[10.3,11.3): 0.9376 - val_ca1-[11.3,14.9): 1.6126 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3940 - val_ca2-[10.3,11.3): 0.8248 - val_ca2-[11.3,14.9): 1.3993 - val_ca3-[8.0,9.5): 0.8994 - val_ca3-[9.5,10.3): 0.5523 - val_ca3-[10.3,11.3): 0.6885 - val_ca3-[11.3,14.9): 0.8574 - val_ca4-[8.0,9.5): 1.4844 - val_ca4-[9.5,10.3): 1.0658 - val_ca4-[10.3,11.3): 0.9226 - val_ca4-[11.3,14.9): 0.6678\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5216 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3555 - ca2-[9.5,10.3): 0.4758 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5147 - ca3-[10.3,11.3): 0.6714 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5146 - ca4-[11.3,14.9): 0.6934 - val_ca1-[8.0,9.5): 0.5786 - val_ca1-[9.5,10.3): 0.4258 - val_ca1-[10.3,11.3): 0.9405 - val_ca1-[11.3,14.9): 1.6629 - val_ca2-[8.0,9.5): 0.5846 - val_ca2-[9.5,10.3): 0.3937 - val_ca2-[10.3,11.3): 0.8251 - val_ca2-[11.3,14.9): 1.4362 - val_ca3-[8.0,9.5): 0.8971 - val_ca3-[9.5,10.3): 0.5510 - val_ca3-[10.3,11.3): 0.6959 - val_ca3-[11.3,14.9): 0.9028 - val_ca4-[8.0,9.5): 1.4844 - val_ca4-[9.5,10.3): 1.0658 - val_ca4-[10.3,11.3): 0.9368 - val_ca4-[11.3,14.9): 0.7191\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5229 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3558 - ca2-[9.5,10.3): 0.4750 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5132 - ca3-[10.3,11.3): 0.6721 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5695 - ca4-[11.3,14.9): 0.7030 - val_ca1-[8.0,9.5): 0.5788 - val_ca1-[9.5,10.3): 0.4256 - val_ca1-[10.3,11.3): 0.9435 - val_ca1-[11.3,14.9): 1.6429 - val_ca2-[8.0,9.5): 0.5843 - val_ca2-[9.5,10.3): 0.3938 - val_ca2-[10.3,11.3): 0.8302 - val_ca2-[11.3,14.9): 1.4215 - val_ca3-[8.0,9.5): 0.9103 - val_ca3-[9.5,10.3): 0.5592 - val_ca3-[10.3,11.3): 0.7002 - val_ca3-[11.3,14.9): 0.8796 - val_ca4-[8.0,9.5): 1.4851 - val_ca4-[9.5,10.3): 1.0663 - val_ca4-[10.3,11.3): 0.9422 - val_ca4-[11.3,14.9): 0.7094\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5097 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3593 - ca2-[9.5,10.3): 0.4632 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5307 - ca3-[10.3,11.3): 0.6620 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5636 - ca4-[11.3,14.9): 0.6950 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4254 - val_ca1-[10.3,11.3): 0.9445 - val_ca1-[11.3,14.9): 1.6391 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3938 - val_ca2-[10.3,11.3): 0.8295 - val_ca2-[11.3,14.9): 1.4188 - val_ca3-[8.0,9.5): 0.9035 - val_ca3-[9.5,10.3): 0.5551 - val_ca3-[10.3,11.3): 0.7021 - val_ca3-[11.3,14.9): 0.8851 - val_ca4-[8.0,9.5): 1.4873 - val_ca4-[9.5,10.3): 1.0681 - val_ca4-[10.3,11.3): 0.9457 - val_ca4-[11.3,14.9): 0.7106\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5076 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3558 - ca2-[9.5,10.3): 0.4668 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5224 - ca3-[10.3,11.3): 0.6718 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5767 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4252 - val_ca1-[10.3,11.3): 0.9370 - val_ca1-[11.3,14.9): 1.6427 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8201 - val_ca2-[11.3,14.9): 1.4141 - val_ca3-[8.0,9.5): 0.8930 - val_ca3-[9.5,10.3): 0.5488 - val_ca3-[10.3,11.3): 0.6992 - val_ca3-[11.3,14.9): 0.8916 - val_ca4-[8.0,9.5): 1.4889 - val_ca4-[9.5,10.3): 1.0694 - val_ca4-[10.3,11.3): 0.9455 - val_ca4-[11.3,14.9): 0.7085\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5052 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3536 - ca2-[9.5,10.3): 0.4650 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5193 - ca3-[10.3,11.3): 0.6622 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5242 - ca4-[11.3,14.9): 0.6791 - val_ca1-[8.0,9.5): 0.5790 - val_ca1-[9.5,10.3): 0.4250 - val_ca1-[10.3,11.3): 0.9294 - val_ca1-[11.3,14.9): 1.6348 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.3938 - val_ca2-[10.3,11.3): 0.8171 - val_ca2-[11.3,14.9): 1.4059 - val_ca3-[8.0,9.5): 0.9097 - val_ca3-[9.5,10.3): 0.5583 - val_ca3-[10.3,11.3): 0.6967 - val_ca3-[11.3,14.9): 0.8822 - val_ca4-[8.0,9.5): 1.4897 - val_ca4-[9.5,10.3): 1.0700 - val_ca4-[10.3,11.3): 0.9449 - val_ca4-[11.3,14.9): 0.7213\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3545 - ca2-[9.5,10.3): 0.4776 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5257 - ca3-[10.3,11.3): 0.6723 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5493 - ca4-[11.3,14.9): 0.6885 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4248 - val_ca1-[10.3,11.3): 0.9360 - val_ca1-[11.3,14.9): 1.5852 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3941 - val_ca2-[10.3,11.3): 0.8229 - val_ca2-[11.3,14.9): 1.3629 - val_ca3-[8.0,9.5): 0.9129 - val_ca3-[9.5,10.3): 0.5603 - val_ca3-[10.3,11.3): 0.6948 - val_ca3-[11.3,14.9): 0.8410 - val_ca4-[8.0,9.5): 1.4907 - val_ca4-[9.5,10.3): 1.0708 - val_ca4-[10.3,11.3): 0.9394 - val_ca4-[11.3,14.9): 0.6920\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5310 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3551 - ca2-[9.5,10.3): 0.4773 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5332 - ca3-[10.3,11.3): 0.6644 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5578 - ca4-[11.3,14.9): 0.6883 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4247 - val_ca1-[10.3,11.3): 0.9170 - val_ca1-[11.3,14.9): 1.5929 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8016 - val_ca2-[11.3,14.9): 1.3656 - val_ca3-[8.0,9.5): 0.8895 - val_ca3-[9.5,10.3): 0.5464 - val_ca3-[10.3,11.3): 0.6851 - val_ca3-[11.3,14.9): 0.8523 - val_ca4-[8.0,9.5): 1.4919 - val_ca4-[9.5,10.3): 1.0718 - val_ca4-[10.3,11.3): 0.9411 - val_ca4-[11.3,14.9): 0.6689\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5279 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3606 - ca2-[9.5,10.3): 0.4858 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5160 - ca3-[10.3,11.3): 0.6664 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5414 - ca4-[11.3,14.9): 0.6800 - val_ca1-[8.0,9.5): 0.5792 - val_ca1-[9.5,10.3): 0.4245 - val_ca1-[10.3,11.3): 0.9348 - val_ca1-[11.3,14.9): 1.6039 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.3934 - val_ca2-[10.3,11.3): 0.8157 - val_ca2-[11.3,14.9): 1.3747 - val_ca3-[8.0,9.5): 0.8960 - val_ca3-[9.5,10.3): 0.5495 - val_ca3-[10.3,11.3): 0.6938 - val_ca3-[11.3,14.9): 0.8714 - val_ca4-[8.0,9.5): 1.4931 - val_ca4-[9.5,10.3): 1.0728 - val_ca4-[10.3,11.3): 0.9405 - val_ca4-[11.3,14.9): 0.7068\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5222 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3610 - ca2-[9.5,10.3): 0.4710 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5297 - ca3-[10.3,11.3): 0.6756 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5574 - ca4-[11.3,14.9): 0.6948 - val_ca1-[8.0,9.5): 0.5792 - val_ca1-[9.5,10.3): 0.4245 - val_ca1-[10.3,11.3): 0.9367 - val_ca1-[11.3,14.9): 1.6308 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3947 - val_ca2-[10.3,11.3): 0.8276 - val_ca2-[11.3,14.9): 1.4199 - val_ca3-[8.0,9.5): 0.8926 - val_ca3-[9.5,10.3): 0.5469 - val_ca3-[10.3,11.3): 0.6954 - val_ca3-[11.3,14.9): 0.8858 - val_ca4-[8.0,9.5): 1.4917 - val_ca4-[9.5,10.3): 1.0716 - val_ca4-[10.3,11.3): 0.9423 - val_ca4-[11.3,14.9): 0.7104\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5175 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3520 - ca2-[9.5,10.3): 0.4657 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5307 - ca3-[10.3,11.3): 0.6597 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5117 - ca4-[11.3,14.9): 0.6823 - val_ca1-[8.0,9.5): 0.5792 - val_ca1-[9.5,10.3): 0.4244 - val_ca1-[10.3,11.3): 0.9316 - val_ca1-[11.3,14.9): 1.6368 - val_ca2-[8.0,9.5): 0.5838 - val_ca2-[9.5,10.3): 0.3949 - val_ca2-[10.3,11.3): 0.8294 - val_ca2-[11.3,14.9): 1.4308 - val_ca3-[8.0,9.5): 0.8971 - val_ca3-[9.5,10.3): 0.5494 - val_ca3-[10.3,11.3): 0.6795 - val_ca3-[11.3,14.9): 0.8726 - val_ca4-[8.0,9.5): 1.4909 - val_ca4-[9.5,10.3): 1.0708 - val_ca4-[10.3,11.3): 0.9102 - val_ca4-[11.3,14.9): 0.6866\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5197 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3618 - ca2-[9.5,10.3): 0.4842 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5377 - ca3-[10.3,11.3): 0.6748 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5597 - ca4-[11.3,14.9): 0.6871 - val_ca1-[8.0,9.5): 0.5793 - val_ca1-[9.5,10.3): 0.4242 - val_ca1-[10.3,11.3): 0.9378 - val_ca1-[11.3,14.9): 1.6199 - val_ca2-[8.0,9.5): 0.5876 - val_ca2-[9.5,10.3): 0.3934 - val_ca2-[10.3,11.3): 0.8207 - val_ca2-[11.3,14.9): 1.3921 - val_ca3-[8.0,9.5): 0.8965 - val_ca3-[9.5,10.3): 0.5490 - val_ca3-[10.3,11.3): 0.6928 - val_ca3-[11.3,14.9): 0.8790 - val_ca4-[8.0,9.5): 1.4935 - val_ca4-[9.5,10.3): 1.0730 - val_ca4-[10.3,11.3): 0.9402 - val_ca4-[11.3,14.9): 0.7121\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5144 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3586 - ca2-[9.5,10.3): 0.4640 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5140 - ca3-[10.3,11.3): 0.6773 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5516 - ca4-[11.3,14.9): 0.6708 - val_ca1-[8.0,9.5): 0.5793 - val_ca1-[9.5,10.3): 0.4241 - val_ca1-[10.3,11.3): 0.9296 - val_ca1-[11.3,14.9): 1.6151 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3937 - val_ca2-[10.3,11.3): 0.8164 - val_ca2-[11.3,14.9): 1.3922 - val_ca3-[8.0,9.5): 0.8830 - val_ca3-[9.5,10.3): 0.5412 - val_ca3-[10.3,11.3): 0.6846 - val_ca3-[11.3,14.9): 0.8783 - val_ca4-[8.0,9.5): 1.4946 - val_ca4-[9.5,10.3): 1.0738 - val_ca4-[10.3,11.3): 0.9265 - val_ca4-[11.3,14.9): 0.6915\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5247 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3532 - ca2-[9.5,10.3): 0.4769 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5255 - ca3-[10.3,11.3): 0.6706 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5871 - ca4-[11.3,14.9): 0.6976 - val_ca1-[8.0,9.5): 0.5794 - val_ca1-[9.5,10.3): 0.4239 - val_ca1-[10.3,11.3): 0.9343 - val_ca1-[11.3,14.9): 1.6216 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3935 - val_ca2-[10.3,11.3): 0.8197 - val_ca2-[11.3,14.9): 1.4001 - val_ca3-[8.0,9.5): 0.8953 - val_ca3-[9.5,10.3): 0.5483 - val_ca3-[10.3,11.3): 0.6942 - val_ca3-[11.3,14.9): 0.8834 - val_ca4-[8.0,9.5): 1.4954 - val_ca4-[9.5,10.3): 1.0745 - val_ca4-[10.3,11.3): 0.9437 - val_ca4-[11.3,14.9): 0.7137\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5178 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3575 - ca2-[9.5,10.3): 0.4772 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5285 - ca3-[10.3,11.3): 0.6652 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5159 - ca4-[11.3,14.9): 0.6782 - val_ca1-[8.0,9.5): 0.5795 - val_ca1-[9.5,10.3): 0.4238 - val_ca1-[10.3,11.3): 0.9262 - val_ca1-[11.3,14.9): 1.5914 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3940 - val_ca2-[10.3,11.3): 0.8205 - val_ca2-[11.3,14.9): 1.3863 - val_ca3-[8.0,9.5): 0.9063 - val_ca3-[9.5,10.3): 0.5549 - val_ca3-[10.3,11.3): 0.6951 - val_ca3-[11.3,14.9): 0.8553 - val_ca4-[8.0,9.5): 1.4953 - val_ca4-[9.5,10.3): 1.0742 - val_ca4-[10.3,11.3): 0.9495 - val_ca4-[11.3,14.9): 0.7000\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5086 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3667 - ca2-[9.5,10.3): 0.4682 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5127 - ca3-[10.3,11.3): 0.6792 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5541 - ca4-[11.3,14.9): 0.6827 - val_ca1-[8.0,9.5): 0.5795 - val_ca1-[9.5,10.3): 0.4237 - val_ca1-[10.3,11.3): 0.9312 - val_ca1-[11.3,14.9): 1.5969 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3938 - val_ca2-[10.3,11.3): 0.8204 - val_ca2-[11.3,14.9): 1.3800 - val_ca3-[8.0,9.5): 0.8850 - val_ca3-[9.5,10.3): 0.5428 - val_ca3-[10.3,11.3): 0.6913 - val_ca3-[11.3,14.9): 0.8580 - val_ca4-[8.0,9.5): 1.4966 - val_ca4-[9.5,10.3): 1.0754 - val_ca4-[10.3,11.3): 0.9416 - val_ca4-[11.3,14.9): 0.6781\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5239 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3669 - ca2-[9.5,10.3): 0.4702 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5014 - ca3-[10.3,11.3): 0.6739 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5450 - ca4-[11.3,14.9): 0.6862 - val_ca1-[8.0,9.5): 0.5796 - val_ca1-[9.5,10.3): 0.4236 - val_ca1-[10.3,11.3): 0.9306 - val_ca1-[11.3,14.9): 1.6291 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8198 - val_ca2-[11.3,14.9): 1.4122 - val_ca3-[8.0,9.5): 0.8914 - val_ca3-[9.5,10.3): 0.5466 - val_ca3-[10.3,11.3): 0.6910 - val_ca3-[11.3,14.9): 0.8860 - val_ca4-[8.0,9.5): 1.4972 - val_ca4-[9.5,10.3): 1.0758 - val_ca4-[10.3,11.3): 0.9418 - val_ca4-[11.3,14.9): 0.7107\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5207 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3552 - ca2-[9.5,10.3): 0.4631 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5225 - ca3-[10.3,11.3): 0.6671 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5073 - ca4-[11.3,14.9): 0.6943 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4234 - val_ca1-[10.3,11.3): 0.9164 - val_ca1-[11.3,14.9): 1.5840 - val_ca2-[8.0,9.5): 0.5852 - val_ca2-[9.5,10.3): 0.3941 - val_ca2-[10.3,11.3): 0.8114 - val_ca2-[11.3,14.9): 1.3794 - val_ca3-[8.0,9.5): 0.8921 - val_ca3-[9.5,10.3): 0.5465 - val_ca3-[10.3,11.3): 0.6855 - val_ca3-[11.3,14.9): 0.8519 - val_ca4-[8.0,9.5): 1.4974 - val_ca4-[9.5,10.3): 1.0759 - val_ca4-[10.3,11.3): 0.9414 - val_ca4-[11.3,14.9): 0.6862\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3631 - ca2-[9.5,10.3): 0.4657 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5222 - ca3-[10.3,11.3): 0.6677 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5455 - ca4-[11.3,14.9): 0.6926 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4234 - val_ca1-[10.3,11.3): 0.9272 - val_ca1-[11.3,14.9): 1.6095 - val_ca2-[8.0,9.5): 0.5843 - val_ca2-[9.5,10.3): 0.3943 - val_ca2-[10.3,11.3): 0.8244 - val_ca2-[11.3,14.9): 1.4119 - val_ca3-[8.0,9.5): 0.8915 - val_ca3-[9.5,10.3): 0.5459 - val_ca3-[10.3,11.3): 0.6914 - val_ca3-[11.3,14.9): 0.8771 - val_ca4-[8.0,9.5): 1.4971 - val_ca4-[9.5,10.3): 1.0756 - val_ca4-[10.3,11.3): 0.9458 - val_ca4-[11.3,14.9): 0.7120\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5169 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3574 - ca2-[9.5,10.3): 0.4688 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5191 - ca3-[10.3,11.3): 0.6939 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5315 - ca4-[11.3,14.9): 0.6798 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4233 - val_ca1-[10.3,11.3): 0.9202 - val_ca1-[11.3,14.9): 1.5993 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8154 - val_ca2-[11.3,14.9): 1.3951 - val_ca3-[8.0,9.5): 0.8968 - val_ca3-[9.5,10.3): 0.5489 - val_ca3-[10.3,11.3): 0.6891 - val_ca3-[11.3,14.9): 0.8704 - val_ca4-[8.0,9.5): 1.4977 - val_ca4-[9.5,10.3): 1.0760 - val_ca4-[10.3,11.3): 0.9452 - val_ca4-[11.3,14.9): 0.7122\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5129 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3433 - ca2-[9.5,10.3): 0.4620 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5366 - ca3-[10.3,11.3): 0.6656 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5907 - ca4-[11.3,14.9): 0.6767 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4233 - val_ca1-[10.3,11.3): 0.9247 - val_ca1-[11.3,14.9): 1.6331 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3933 - val_ca2-[10.3,11.3): 0.8157 - val_ca2-[11.3,14.9): 1.4202 - val_ca3-[8.0,9.5): 0.8796 - val_ca3-[9.5,10.3): 0.5388 - val_ca3-[10.3,11.3): 0.6897 - val_ca3-[11.3,14.9): 0.9002 - val_ca4-[8.0,9.5): 1.4975 - val_ca4-[9.5,10.3): 1.0758 - val_ca4-[10.3,11.3): 0.9434 - val_ca4-[11.3,14.9): 0.7167\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5083 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3512 - ca2-[9.5,10.3): 0.4641 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5206 - ca3-[10.3,11.3): 0.6683 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5574 - ca4-[11.3,14.9): 0.6900 - val_ca1-[8.0,9.5): 0.5798 - val_ca1-[9.5,10.3): 0.4231 - val_ca1-[10.3,11.3): 0.9324 - val_ca1-[11.3,14.9): 1.6144 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.3934 - val_ca2-[10.3,11.3): 0.8224 - val_ca2-[11.3,14.9): 1.4025 - val_ca3-[8.0,9.5): 0.8880 - val_ca3-[9.5,10.3): 0.5438 - val_ca3-[10.3,11.3): 0.6939 - val_ca3-[11.3,14.9): 0.8784 - val_ca4-[8.0,9.5): 1.4983 - val_ca4-[9.5,10.3): 1.0763 - val_ca4-[10.3,11.3): 0.9472 - val_ca4-[11.3,14.9): 0.7074\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3498 - ca2-[9.5,10.3): 0.4708 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5119 - ca3-[10.3,11.3): 0.6801 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5424 - ca4-[11.3,14.9): 0.6812 - val_ca1-[8.0,9.5): 0.5798 - val_ca1-[9.5,10.3): 0.4230 - val_ca1-[10.3,11.3): 0.9282 - val_ca1-[11.3,14.9): 1.6519 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8196 - val_ca2-[11.3,14.9): 1.4332 - val_ca3-[8.0,9.5): 0.8858 - val_ca3-[9.5,10.3): 0.5425 - val_ca3-[10.3,11.3): 0.6892 - val_ca3-[11.3,14.9): 0.8911 - val_ca4-[8.0,9.5): 1.4994 - val_ca4-[9.5,10.3): 1.0772 - val_ca4-[10.3,11.3): 0.9424 - val_ca4-[11.3,14.9): 0.7027\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5045 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3497 - ca2-[9.5,10.3): 0.4703 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5145 - ca3-[10.3,11.3): 0.6715 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5357 - ca4-[11.3,14.9): 0.6978 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4229 - val_ca1-[10.3,11.3): 0.9298 - val_ca1-[11.3,14.9): 1.5943 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.3931 - val_ca2-[10.3,11.3): 0.8187 - val_ca2-[11.3,14.9): 1.3736 - val_ca3-[8.0,9.5): 0.8937 - val_ca3-[9.5,10.3): 0.5469 - val_ca3-[10.3,11.3): 0.6912 - val_ca3-[11.3,14.9): 0.8309 - val_ca4-[8.0,9.5): 1.4996 - val_ca4-[9.5,10.3): 1.0773 - val_ca4-[10.3,11.3): 0.9450 - val_ca4-[11.3,14.9): 0.6342\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5163 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3642 - ca2-[9.5,10.3): 0.4785 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5287 - ca3-[10.3,11.3): 0.6598 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5394 - ca4-[11.3,14.9): 0.6868 - val_ca1-[8.0,9.5): 0.5798 - val_ca1-[9.5,10.3): 0.4229 - val_ca1-[10.3,11.3): 0.9319 - val_ca1-[11.3,14.9): 1.5938 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8240 - val_ca2-[11.3,14.9): 1.3899 - val_ca3-[8.0,9.5): 0.8828 - val_ca3-[9.5,10.3): 0.5399 - val_ca3-[10.3,11.3): 0.6929 - val_ca3-[11.3,14.9): 0.8719 - val_ca4-[8.0,9.5): 1.4994 - val_ca4-[9.5,10.3): 1.0771 - val_ca4-[10.3,11.3): 0.9474 - val_ca4-[11.3,14.9): 0.7083\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5116 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3507 - ca2-[9.5,10.3): 0.4679 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5301 - ca3-[10.3,11.3): 0.6752 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5200 - ca4-[11.3,14.9): 0.6812 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4229 - val_ca1-[10.3,11.3): 0.9249 - val_ca1-[11.3,14.9): 1.6125 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.3930 - val_ca2-[10.3,11.3): 0.8165 - val_ca2-[11.3,14.9): 1.3986 - val_ca3-[8.0,9.5): 0.8880 - val_ca3-[9.5,10.3): 0.5427 - val_ca3-[10.3,11.3): 0.6906 - val_ca3-[11.3,14.9): 0.8779 - val_ca4-[8.0,9.5): 1.5001 - val_ca4-[9.5,10.3): 1.0777 - val_ca4-[10.3,11.3): 0.9468 - val_ca4-[11.3,14.9): 0.7023\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3558 - ca2-[9.5,10.3): 0.4620 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4913 - ca3-[10.3,11.3): 0.6600 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5495 - ca4-[11.3,14.9): 0.6895 - val_ca1-[8.0,9.5): 0.5798 - val_ca1-[9.5,10.3): 0.4228 - val_ca1-[10.3,11.3): 0.9295 - val_ca1-[11.3,14.9): 1.6362 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.3931 - val_ca2-[10.3,11.3): 0.8205 - val_ca2-[11.3,14.9): 1.4189 - val_ca3-[8.0,9.5): 0.8780 - val_ca3-[9.5,10.3): 0.5364 - val_ca3-[10.3,11.3): 0.6903 - val_ca3-[11.3,14.9): 0.8967 - val_ca4-[8.0,9.5): 1.5002 - val_ca4-[9.5,10.3): 1.0776 - val_ca4-[10.3,11.3): 0.9451 - val_ca4-[11.3,14.9): 0.7171\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5274 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3641 - ca2-[9.5,10.3): 0.4786 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5119 - ca3-[10.3,11.3): 0.6762 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5203 - ca4-[11.3,14.9): 0.6770 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4228 - val_ca1-[10.3,11.3): 0.9226 - val_ca1-[11.3,14.9): 1.6284 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8187 - val_ca2-[11.3,14.9): 1.4250 - val_ca3-[8.0,9.5): 0.8853 - val_ca3-[9.5,10.3): 0.5405 - val_ca3-[10.3,11.3): 0.6873 - val_ca3-[11.3,14.9): 0.8868 - val_ca4-[8.0,9.5): 1.5001 - val_ca4-[9.5,10.3): 1.0775 - val_ca4-[10.3,11.3): 0.9440 - val_ca4-[11.3,14.9): 0.7107\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5171 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3511 - ca2-[9.5,10.3): 0.4668 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5317 - ca3-[10.3,11.3): 0.6700 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5474 - ca4-[11.3,14.9): 0.6791 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4227 - val_ca1-[10.3,11.3): 0.9269 - val_ca1-[11.3,14.9): 1.5883 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.3926 - val_ca2-[10.3,11.3): 0.8163 - val_ca2-[11.3,14.9): 1.3738 - val_ca3-[8.0,9.5): 0.8881 - val_ca3-[9.5,10.3): 0.5422 - val_ca3-[10.3,11.3): 0.6874 - val_ca3-[11.3,14.9): 0.8586 - val_ca4-[8.0,9.5): 1.5004 - val_ca4-[9.5,10.3): 1.0776 - val_ca4-[10.3,11.3): 0.9423 - val_ca4-[11.3,14.9): 0.6941\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5084 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3452 - ca2-[9.5,10.3): 0.4696 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4993 - ca3-[10.3,11.3): 0.6905 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5785 - ca4-[11.3,14.9): 0.6993 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4226 - val_ca1-[10.3,11.3): 0.9228 - val_ca1-[11.3,14.9): 1.5740 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3928 - val_ca2-[10.3,11.3): 0.8155 - val_ca2-[11.3,14.9): 1.3672 - val_ca3-[8.0,9.5): 0.8790 - val_ca3-[9.5,10.3): 0.5367 - val_ca3-[10.3,11.3): 0.6799 - val_ca3-[11.3,14.9): 0.8499 - val_ca4-[8.0,9.5): 1.5009 - val_ca4-[9.5,10.3): 1.0779 - val_ca4-[10.3,11.3): 0.9281 - val_ca4-[11.3,14.9): 0.6805\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5146 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3648 - ca2-[9.5,10.3): 0.4682 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5191 - ca3-[10.3,11.3): 0.6594 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5566 - ca4-[11.3,14.9): 0.6891 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4225 - val_ca1-[10.3,11.3): 0.9281 - val_ca1-[11.3,14.9): 1.5991 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3930 - val_ca2-[10.3,11.3): 0.8207 - val_ca2-[11.3,14.9): 1.3860 - val_ca3-[8.0,9.5): 0.8810 - val_ca3-[9.5,10.3): 0.5381 - val_ca3-[10.3,11.3): 0.6892 - val_ca3-[11.3,14.9): 0.8725 - val_ca4-[8.0,9.5): 1.5009 - val_ca4-[9.5,10.3): 1.0778 - val_ca4-[10.3,11.3): 0.9449 - val_ca4-[11.3,14.9): 0.7123\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5129 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3599 - ca2-[9.5,10.3): 0.4721 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5114 - ca3-[10.3,11.3): 0.6634 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5171 - ca4-[11.3,14.9): 0.6648 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4225 - val_ca1-[10.3,11.3): 0.9213 - val_ca1-[11.3,14.9): 1.5930 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3921 - val_ca2-[10.3,11.3): 0.8088 - val_ca2-[11.3,14.9): 1.3681 - val_ca3-[8.0,9.5): 0.8885 - val_ca3-[9.5,10.3): 0.5422 - val_ca3-[10.3,11.3): 0.6867 - val_ca3-[11.3,14.9): 0.8599 - val_ca4-[8.0,9.5): 1.5018 - val_ca4-[9.5,10.3): 1.0785 - val_ca4-[10.3,11.3): 0.9444 - val_ca4-[11.3,14.9): 0.6945\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5221 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3540 - ca2-[9.5,10.3): 0.4655 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5095 - ca3-[10.3,11.3): 0.6667 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5395 - ca4-[11.3,14.9): 0.6836 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4225 - val_ca1-[10.3,11.3): 0.9280 - val_ca1-[11.3,14.9): 1.6049 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3925 - val_ca2-[10.3,11.3): 0.8164 - val_ca2-[11.3,14.9): 1.3860 - val_ca3-[8.0,9.5): 0.8778 - val_ca3-[9.5,10.3): 0.5359 - val_ca3-[10.3,11.3): 0.6883 - val_ca3-[11.3,14.9): 0.8744 - val_ca4-[8.0,9.5): 1.5006 - val_ca4-[9.5,10.3): 1.0773 - val_ca4-[10.3,11.3): 0.9444 - val_ca4-[11.3,14.9): 0.7011\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5199 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3611 - ca2-[9.5,10.3): 0.4662 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5057 - ca3-[10.3,11.3): 0.6619 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5615 - ca4-[11.3,14.9): 0.6875 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4225 - val_ca1-[10.3,11.3): 0.9234 - val_ca1-[11.3,14.9): 1.6129 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3928 - val_ca2-[10.3,11.3): 0.8171 - val_ca2-[11.3,14.9): 1.4069 - val_ca3-[8.0,9.5): 0.8732 - val_ca3-[9.5,10.3): 0.5331 - val_ca3-[10.3,11.3): 0.6877 - val_ca3-[11.3,14.9): 0.8863 - val_ca4-[8.0,9.5): 1.5005 - val_ca4-[9.5,10.3): 1.0771 - val_ca4-[10.3,11.3): 0.9459 - val_ca4-[11.3,14.9): 0.7090\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5258 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3630 - ca2-[9.5,10.3): 0.4663 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5070 - ca3-[10.3,11.3): 0.6761 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5840 - ca4-[11.3,14.9): 0.7051 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4224 - val_ca1-[10.3,11.3): 0.9295 - val_ca1-[11.3,14.9): 1.6280 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.3930 - val_ca2-[10.3,11.3): 0.8237 - val_ca2-[11.3,14.9): 1.4254 - val_ca3-[8.0,9.5): 0.8866 - val_ca3-[9.5,10.3): 0.5408 - val_ca3-[10.3,11.3): 0.6901 - val_ca3-[11.3,14.9): 0.8830 - val_ca4-[8.0,9.5): 1.5011 - val_ca4-[9.5,10.3): 1.0774 - val_ca4-[10.3,11.3): 0.9468 - val_ca4-[11.3,14.9): 0.7099\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3568 - ca2-[9.5,10.3): 0.4688 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5136 - ca3-[10.3,11.3): 0.6722 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5401 - ca4-[11.3,14.9): 0.6821 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4224 - val_ca1-[10.3,11.3): 0.9228 - val_ca1-[11.3,14.9): 1.6179 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3920 - val_ca2-[10.3,11.3): 0.8131 - val_ca2-[11.3,14.9): 1.4043 - val_ca3-[8.0,9.5): 0.8876 - val_ca3-[9.5,10.3): 0.5413 - val_ca3-[10.3,11.3): 0.6876 - val_ca3-[11.3,14.9): 0.8847 - val_ca4-[8.0,9.5): 1.5011 - val_ca4-[9.5,10.3): 1.0774 - val_ca4-[10.3,11.3): 0.9458 - val_ca4-[11.3,14.9): 0.7202\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5191 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3527 - ca2-[9.5,10.3): 0.4664 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5086 - ca3-[10.3,11.3): 0.6689 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5520 - ca4-[11.3,14.9): 0.6787 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4223 - val_ca1-[10.3,11.3): 0.9252 - val_ca1-[11.3,14.9): 1.6177 - val_ca2-[8.0,9.5): 0.5892 - val_ca2-[9.5,10.3): 0.3915 - val_ca2-[10.3,11.3): 0.8087 - val_ca2-[11.3,14.9): 1.3863 - val_ca3-[8.0,9.5): 0.8678 - val_ca3-[9.5,10.3): 0.5296 - val_ca3-[10.3,11.3): 0.6850 - val_ca3-[11.3,14.9): 0.8931 - val_ca4-[8.0,9.5): 1.5020 - val_ca4-[9.5,10.3): 1.0781 - val_ca4-[10.3,11.3): 0.9419 - val_ca4-[11.3,14.9): 0.7144\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5233 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3562 - ca2-[9.5,10.3): 0.4697 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5092 - ca3-[10.3,11.3): 0.6776 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5262 - ca4-[11.3,14.9): 0.6843 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4223 - val_ca1-[10.3,11.3): 0.9275 - val_ca1-[11.3,14.9): 1.5918 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.3923 - val_ca2-[10.3,11.3): 0.8171 - val_ca2-[11.3,14.9): 1.3832 - val_ca3-[8.0,9.5): 0.8688 - val_ca3-[9.5,10.3): 0.5302 - val_ca3-[10.3,11.3): 0.6852 - val_ca3-[11.3,14.9): 0.8688 - val_ca4-[8.0,9.5): 1.5013 - val_ca4-[9.5,10.3): 1.0773 - val_ca4-[10.3,11.3): 0.9389 - val_ca4-[11.3,14.9): 0.6892\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5207 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3471 - ca2-[9.5,10.3): 0.4666 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5129 - ca3-[10.3,11.3): 0.6764 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5436 - ca4-[11.3,14.9): 0.6840 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4222 - val_ca1-[10.3,11.3): 0.9247 - val_ca1-[11.3,14.9): 1.6107 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3931 - val_ca2-[10.3,11.3): 0.8213 - val_ca2-[11.3,14.9): 1.4129 - val_ca3-[8.0,9.5): 0.8838 - val_ca3-[9.5,10.3): 0.5389 - val_ca3-[10.3,11.3): 0.6846 - val_ca3-[11.3,14.9): 0.8707 - val_ca4-[8.0,9.5): 1.5003 - val_ca4-[9.5,10.3): 1.0762 - val_ca4-[10.3,11.3): 0.9404 - val_ca4-[11.3,14.9): 0.7023\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5118 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3557 - ca2-[9.5,10.3): 0.4759 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5115 - ca3-[10.3,11.3): 0.6560 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5699 - ca4-[11.3,14.9): 0.6880 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4221 - val_ca1-[10.3,11.3): 0.9112 - val_ca1-[11.3,14.9): 1.6098 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.3920 - val_ca2-[10.3,11.3): 0.8060 - val_ca2-[11.3,14.9): 1.3979 - val_ca3-[8.0,9.5): 0.8854 - val_ca3-[9.5,10.3): 0.5398 - val_ca3-[10.3,11.3): 0.6768 - val_ca3-[11.3,14.9): 0.8643 - val_ca4-[8.0,9.5): 1.5017 - val_ca4-[9.5,10.3): 1.0773 - val_ca4-[10.3,11.3): 0.9299 - val_ca4-[11.3,14.9): 0.6910\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5200 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3435 - ca2-[9.5,10.3): 0.4673 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5299 - ca3-[10.3,11.3): 0.6716 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5483 - ca4-[11.3,14.9): 0.6891 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4221 - val_ca1-[10.3,11.3): 0.9242 - val_ca1-[11.3,14.9): 1.5953 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3922 - val_ca2-[10.3,11.3): 0.8161 - val_ca2-[11.3,14.9): 1.3907 - val_ca3-[8.0,9.5): 0.8749 - val_ca3-[9.5,10.3): 0.5334 - val_ca3-[10.3,11.3): 0.6836 - val_ca3-[11.3,14.9): 0.8720 - val_ca4-[8.0,9.5): 1.5001 - val_ca4-[9.5,10.3): 1.0758 - val_ca4-[10.3,11.3): 0.9399 - val_ca4-[11.3,14.9): 0.7057\n",
      "Epoch 193/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5121 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3607 - ca2-[9.5,10.3): 0.4718 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4961 - ca3-[10.3,11.3): 0.6645 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5457 - ca4-[11.3,14.9): 0.6923 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4221 - val_ca1-[10.3,11.3): 0.9259 - val_ca1-[11.3,14.9): 1.5954 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.3919 - val_ca2-[10.3,11.3): 0.8153 - val_ca2-[11.3,14.9): 1.3797 - val_ca3-[8.0,9.5): 0.8677 - val_ca3-[9.5,10.3): 0.5291 - val_ca3-[10.3,11.3): 0.6853 - val_ca3-[11.3,14.9): 0.8774 - val_ca4-[8.0,9.5): 1.5011 - val_ca4-[9.5,10.3): 1.0765 - val_ca4-[10.3,11.3): 0.9427 - val_ca4-[11.3,14.9): 0.7059\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5197 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3572 - ca2-[9.5,10.3): 0.4738 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5363 - ca3-[10.3,11.3): 0.6677 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5391 - ca4-[11.3,14.9): 0.6863 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9153 - val_ca1-[11.3,14.9): 1.6028 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3919 - val_ca2-[10.3,11.3): 0.8098 - val_ca2-[11.3,14.9): 1.3973 - val_ca3-[8.0,9.5): 0.8780 - val_ca3-[9.5,10.3): 0.5348 - val_ca3-[10.3,11.3): 0.6756 - val_ca3-[11.3,14.9): 0.8687 - val_ca4-[8.0,9.5): 1.5013 - val_ca4-[9.5,10.3): 1.0765 - val_ca4-[10.3,11.3): 0.9273 - val_ca4-[11.3,14.9): 0.6903\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5269 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3563 - ca2-[9.5,10.3): 0.4648 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5190 - ca3-[10.3,11.3): 0.6619 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5497 - ca4-[11.3,14.9): 0.6914 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9231 - val_ca1-[11.3,14.9): 1.5870 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.3919 - val_ca2-[10.3,11.3): 0.8142 - val_ca2-[11.3,14.9): 1.3788 - val_ca3-[8.0,9.5): 0.8864 - val_ca3-[9.5,10.3): 0.5401 - val_ca3-[10.3,11.3): 0.6828 - val_ca3-[11.3,14.9): 0.8501 - val_ca4-[8.0,9.5): 1.5023 - val_ca4-[9.5,10.3): 1.0772 - val_ca4-[10.3,11.3): 0.9401 - val_ca4-[11.3,14.9): 0.6985\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5209 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3478 - ca2-[9.5,10.3): 0.4622 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5215 - ca3-[10.3,11.3): 0.6667 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5998 - ca4-[11.3,14.9): 0.6962 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9251 - val_ca1-[11.3,14.9): 1.5763 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3921 - val_ca2-[10.3,11.3): 0.8171 - val_ca2-[11.3,14.9): 1.3725 - val_ca3-[8.0,9.5): 0.8696 - val_ca3-[9.5,10.3): 0.5301 - val_ca3-[10.3,11.3): 0.6840 - val_ca3-[11.3,14.9): 0.8602 - val_ca4-[8.0,9.5): 1.5026 - val_ca4-[9.5,10.3): 1.0773 - val_ca4-[10.3,11.3): 0.9426 - val_ca4-[11.3,14.9): 0.7011\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5089 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3512 - ca2-[9.5,10.3): 0.4571 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4926 - ca3-[10.3,11.3): 0.6647 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5528 - ca4-[11.3,14.9): 0.6928 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9194 - val_ca1-[11.3,14.9): 1.5685 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3918 - val_ca2-[10.3,11.3): 0.8141 - val_ca2-[11.3,14.9): 1.3678 - val_ca3-[8.0,9.5): 0.8735 - val_ca3-[9.5,10.3): 0.5321 - val_ca3-[10.3,11.3): 0.6748 - val_ca3-[11.3,14.9): 0.8393 - val_ca4-[8.0,9.5): 1.5012 - val_ca4-[9.5,10.3): 1.0760 - val_ca4-[10.3,11.3): 0.9248 - val_ca4-[11.3,14.9): 0.6685\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5185 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3658 - ca2-[9.5,10.3): 0.4629 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5153 - ca3-[10.3,11.3): 0.6856 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5803 - ca4-[11.3,14.9): 0.6915 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9195 - val_ca1-[11.3,14.9): 1.6027 - val_ca2-[8.0,9.5): 0.5844 - val_ca2-[9.5,10.3): 0.3920 - val_ca2-[10.3,11.3): 0.8123 - val_ca2-[11.3,14.9): 1.3980 - val_ca3-[8.0,9.5): 0.8733 - val_ca3-[9.5,10.3): 0.5314 - val_ca3-[10.3,11.3): 0.6721 - val_ca3-[11.3,14.9): 0.8752 - val_ca4-[8.0,9.5): 1.4995 - val_ca4-[9.5,10.3): 1.0743 - val_ca4-[10.3,11.3): 0.9236 - val_ca4-[11.3,14.9): 0.7101\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5096 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3646 - ca2-[9.5,10.3): 0.4592 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4967 - ca3-[10.3,11.3): 0.6820 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5737 - ca4-[11.3,14.9): 0.6852 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9277 - val_ca1-[11.3,14.9): 1.6129 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3918 - val_ca2-[10.3,11.3): 0.8209 - val_ca2-[11.3,14.9): 1.3995 - val_ca3-[8.0,9.5): 0.8736 - val_ca3-[9.5,10.3): 0.5317 - val_ca3-[10.3,11.3): 0.6824 - val_ca3-[11.3,14.9): 0.8727 - val_ca4-[8.0,9.5): 1.4980 - val_ca4-[9.5,10.3): 1.0728 - val_ca4-[10.3,11.3): 0.9337 - val_ca4-[11.3,14.9): 0.7046\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3574 - ca2-[9.5,10.3): 0.4710 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4982 - ca3-[10.3,11.3): 0.6604 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5227 - ca4-[11.3,14.9): 0.6821 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9004 - val_ca1-[11.3,14.9): 1.5825 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.3917 - val_ca2-[10.3,11.3): 0.7921 - val_ca2-[11.3,14.9): 1.3745 - val_ca3-[8.0,9.5): 0.8708 - val_ca3-[9.5,10.3): 0.5298 - val_ca3-[10.3,11.3): 0.6653 - val_ca3-[11.3,14.9): 0.8554 - val_ca4-[8.0,9.5): 1.4980 - val_ca4-[9.5,10.3): 1.0726 - val_ca4-[10.3,11.3): 0.9320 - val_ca4-[11.3,14.9): 0.7009\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5097 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3552 - ca2-[9.5,10.3): 0.4628 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5039 - ca3-[10.3,11.3): 0.6522 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5692 - ca4-[11.3,14.9): 0.6721 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9270 - val_ca1-[11.3,14.9): 1.5899 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.3912 - val_ca2-[10.3,11.3): 0.8128 - val_ca2-[11.3,14.9): 1.3697 - val_ca3-[8.0,9.5): 0.8766 - val_ca3-[9.5,10.3): 0.5337 - val_ca3-[10.3,11.3): 0.6809 - val_ca3-[11.3,14.9): 0.8624 - val_ca4-[8.0,9.5): 1.4985 - val_ca4-[9.5,10.3): 1.0728 - val_ca4-[10.3,11.3): 0.9319 - val_ca4-[11.3,14.9): 0.7069\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5126 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3549 - ca2-[9.5,10.3): 0.4658 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5050 - ca3-[10.3,11.3): 0.6594 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4922 - ca4-[11.3,14.9): 0.6948 - val_ca1-[8.0,9.5): 0.5805 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9221 - val_ca1-[11.3,14.9): 1.5496 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3918 - val_ca2-[10.3,11.3): 0.8123 - val_ca2-[11.3,14.9): 1.3388 - val_ca3-[8.0,9.5): 0.8655 - val_ca3-[9.5,10.3): 0.5272 - val_ca3-[10.3,11.3): 0.6796 - val_ca3-[11.3,14.9): 0.8417 - val_ca4-[8.0,9.5): 1.4992 - val_ca4-[9.5,10.3): 1.0732 - val_ca4-[10.3,11.3): 0.9367 - val_ca4-[11.3,14.9): 0.6970\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5244 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3569 - ca2-[9.5,10.3): 0.4743 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5089 - ca3-[10.3,11.3): 0.6672 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5538 - ca4-[11.3,14.9): 0.6827 - val_ca1-[8.0,9.5): 0.5805 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9284 - val_ca1-[11.3,14.9): 1.6123 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3922 - val_ca2-[10.3,11.3): 0.8218 - val_ca2-[11.3,14.9): 1.4073 - val_ca3-[8.0,9.5): 0.8751 - val_ca3-[9.5,10.3): 0.5326 - val_ca3-[10.3,11.3): 0.6785 - val_ca3-[11.3,14.9): 0.8740 - val_ca4-[8.0,9.5): 1.4977 - val_ca4-[9.5,10.3): 1.0716 - val_ca4-[10.3,11.3): 0.9325 - val_ca4-[11.3,14.9): 0.7136\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5267 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3553 - ca2-[9.5,10.3): 0.4716 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5103 - ca3-[10.3,11.3): 0.6461 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5744 - ca4-[11.3,14.9): 0.6931 - val_ca1-[8.0,9.5): 0.5805 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9220 - val_ca1-[11.3,14.9): 1.6042 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3912 - val_ca2-[10.3,11.3): 0.8115 - val_ca2-[11.3,14.9): 1.3897 - val_ca3-[8.0,9.5): 0.8727 - val_ca3-[9.5,10.3): 0.5311 - val_ca3-[10.3,11.3): 0.6791 - val_ca3-[11.3,14.9): 0.8694 - val_ca4-[8.0,9.5): 1.4984 - val_ca4-[9.5,10.3): 1.0720 - val_ca4-[10.3,11.3): 0.9356 - val_ca4-[11.3,14.9): 0.7055\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 0.5121 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3677 - ca2-[9.5,10.3): 0.4686 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5198 - ca3-[10.3,11.3): 0.6878 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5502 - ca4-[11.3,14.9): 0.6908 - val_ca1-[8.0,9.5): 0.5813 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9220 - val_ca1-[11.3,14.9): 1.5938 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3921 - val_ca2-[10.3,11.3): 0.8132 - val_ca2-[11.3,14.9): 1.3851 - val_ca3-[8.0,9.5): 0.8765 - val_ca3-[9.5,10.3): 0.5336 - val_ca3-[10.3,11.3): 0.6788 - val_ca3-[11.3,14.9): 0.8577 - val_ca4-[8.0,9.5): 1.5020 - val_ca4-[9.5,10.3): 1.0745 - val_ca4-[10.3,11.3): 0.9350 - val_ca4-[11.3,14.9): 0.6966\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5136 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3540 - ca2-[9.5,10.3): 0.4611 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5013 - ca3-[10.3,11.3): 0.6570 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5612 - ca4-[11.3,14.9): 0.6789 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9243 - val_ca1-[11.3,14.9): 1.6211 - val_ca2-[8.0,9.5): 0.5856 - val_ca2-[9.5,10.3): 0.3915 - val_ca2-[10.3,11.3): 0.8166 - val_ca2-[11.3,14.9): 1.4095 - val_ca3-[8.0,9.5): 0.8610 - val_ca3-[9.5,10.3): 0.5239 - val_ca3-[10.3,11.3): 0.6804 - val_ca3-[11.3,14.9): 0.8776 - val_ca4-[8.0,9.5): 1.4980 - val_ca4-[9.5,10.3): 1.0712 - val_ca4-[10.3,11.3): 0.9373 - val_ca4-[11.3,14.9): 0.6903\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5137 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3558 - ca2-[9.5,10.3): 0.4648 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4978 - ca3-[10.3,11.3): 0.6632 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5771 - ca4-[11.3,14.9): 0.7052 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.6051 - val_ca2-[8.0,9.5): 0.5876 - val_ca2-[9.5,10.3): 0.3909 - val_ca2-[10.3,11.3): 0.8065 - val_ca2-[11.3,14.9): 1.3796 - val_ca3-[8.0,9.5): 0.8565 - val_ca3-[9.5,10.3): 0.5213 - val_ca3-[10.3,11.3): 0.6728 - val_ca3-[11.3,14.9): 0.8774 - val_ca4-[8.0,9.5): 1.4973 - val_ca4-[9.5,10.3): 1.0703 - val_ca4-[10.3,11.3): 0.9245 - val_ca4-[11.3,14.9): 0.7069\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5190 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3460 - ca2-[9.5,10.3): 0.4639 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5194 - ca3-[10.3,11.3): 0.6677 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5499 - ca4-[11.3,14.9): 0.6891 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9210 - val_ca1-[11.3,14.9): 1.5950 - val_ca2-[8.0,9.5): 0.5843 - val_ca2-[9.5,10.3): 0.3919 - val_ca2-[10.3,11.3): 0.8188 - val_ca2-[11.3,14.9): 1.4017 - val_ca3-[8.0,9.5): 0.8641 - val_ca3-[9.5,10.3): 0.5253 - val_ca3-[10.3,11.3): 0.6732 - val_ca3-[11.3,14.9): 0.8629 - val_ca4-[8.0,9.5): 1.4942 - val_ca4-[9.5,10.3): 1.0673 - val_ca4-[10.3,11.3): 0.9204 - val_ca4-[11.3,14.9): 0.6814\n",
      "Epoch 209/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3544 - ca2-[9.5,10.3): 0.4658 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5083 - ca3-[10.3,11.3): 0.6400 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5523 - ca4-[11.3,14.9): 0.6754 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9196 - val_ca1-[11.3,14.9): 1.6222 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3915 - val_ca2-[10.3,11.3): 0.8128 - val_ca2-[11.3,14.9): 1.4127 - val_ca3-[8.0,9.5): 0.8755 - val_ca3-[9.5,10.3): 0.5322 - val_ca3-[10.3,11.3): 0.6794 - val_ca3-[11.3,14.9): 0.8754 - val_ca4-[8.0,9.5): 1.4935 - val_ca4-[9.5,10.3): 1.0662 - val_ca4-[10.3,11.3): 0.9352 - val_ca4-[11.3,14.9): 0.7105\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5095 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3601 - ca2-[9.5,10.3): 0.4621 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5146 - ca3-[10.3,11.3): 0.6743 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5376 - ca4-[11.3,14.9): 0.6822 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9220 - val_ca1-[11.3,14.9): 1.5715 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3909 - val_ca2-[10.3,11.3): 0.8076 - val_ca2-[11.3,14.9): 1.3529 - val_ca3-[8.0,9.5): 0.8670 - val_ca3-[9.5,10.3): 0.5276 - val_ca3-[10.3,11.3): 0.6774 - val_ca3-[11.3,14.9): 0.8512 - val_ca4-[8.0,9.5): 1.4939 - val_ca4-[9.5,10.3): 1.0664 - val_ca4-[10.3,11.3): 0.9310 - val_ca4-[11.3,14.9): 0.6981\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5184 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3592 - ca2-[9.5,10.3): 0.4681 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5039 - ca3-[10.3,11.3): 0.6683 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5215 - ca4-[11.3,14.9): 0.6832 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9261 - val_ca1-[11.3,14.9): 1.5856 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3909 - val_ca2-[10.3,11.3): 0.8135 - val_ca2-[11.3,14.9): 1.3714 - val_ca3-[8.0,9.5): 0.8572 - val_ca3-[9.5,10.3): 0.5215 - val_ca3-[10.3,11.3): 0.6811 - val_ca3-[11.3,14.9): 0.8699 - val_ca4-[8.0,9.5): 1.4935 - val_ca4-[9.5,10.3): 1.0659 - val_ca4-[10.3,11.3): 0.9356 - val_ca4-[11.3,14.9): 0.7058\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 0.5152 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3547 - ca2-[9.5,10.3): 0.4648 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4821 - ca3-[10.3,11.3): 0.6640 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5741 - ca4-[11.3,14.9): 0.6915 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9175 - val_ca1-[11.3,14.9): 1.6132 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3910 - val_ca2-[10.3,11.3): 0.8082 - val_ca2-[11.3,14.9): 1.3936 - val_ca3-[8.0,9.5): 0.8622 - val_ca3-[9.5,10.3): 0.5245 - val_ca3-[10.3,11.3): 0.6765 - val_ca3-[11.3,14.9): 0.8712 - val_ca4-[8.0,9.5): 1.4955 - val_ca4-[9.5,10.3): 1.0674 - val_ca4-[10.3,11.3): 0.9328 - val_ca4-[11.3,14.9): 0.6934\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5107 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3579 - ca2-[9.5,10.3): 0.4672 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5035 - ca3-[10.3,11.3): 0.6756 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5347 - ca4-[11.3,14.9): 0.6917 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9221 - val_ca1-[11.3,14.9): 1.6064 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3911 - val_ca2-[10.3,11.3): 0.8119 - val_ca2-[11.3,14.9): 1.3939 - val_ca3-[8.0,9.5): 0.8582 - val_ca3-[9.5,10.3): 0.5220 - val_ca3-[10.3,11.3): 0.6767 - val_ca3-[11.3,14.9): 0.8785 - val_ca4-[8.0,9.5): 1.4956 - val_ca4-[9.5,10.3): 1.0672 - val_ca4-[10.3,11.3): 0.9309 - val_ca4-[11.3,14.9): 0.7090\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5159 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3625 - ca2-[9.5,10.3): 0.4687 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4916 - ca3-[10.3,11.3): 0.6642 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5078 - ca4-[11.3,14.9): 0.6814 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9216 - val_ca1-[11.3,14.9): 1.6155 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.3907 - val_ca2-[10.3,11.3): 0.8117 - val_ca2-[11.3,14.9): 1.3986 - val_ca3-[8.0,9.5): 0.8574 - val_ca3-[9.5,10.3): 0.5212 - val_ca3-[10.3,11.3): 0.6801 - val_ca3-[11.3,14.9): 0.8882 - val_ca4-[8.0,9.5): 1.4943 - val_ca4-[9.5,10.3): 1.0660 - val_ca4-[10.3,11.3): 0.9366 - val_ca4-[11.3,14.9): 0.7137\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5210 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3532 - ca2-[9.5,10.3): 0.4627 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5045 - ca3-[10.3,11.3): 0.6649 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5279 - ca4-[11.3,14.9): 0.6788 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9261 - val_ca1-[11.3,14.9): 1.5939 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3907 - val_ca2-[10.3,11.3): 0.8163 - val_ca2-[11.3,14.9): 1.3793 - val_ca3-[8.0,9.5): 0.8634 - val_ca3-[9.5,10.3): 0.5239 - val_ca3-[10.3,11.3): 0.6799 - val_ca3-[11.3,14.9): 0.8576 - val_ca4-[8.0,9.5): 1.4921 - val_ca4-[9.5,10.3): 1.0638 - val_ca4-[10.3,11.3): 0.9335 - val_ca4-[11.3,14.9): 0.6893\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5059 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3645 - ca2-[9.5,10.3): 0.4710 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4813 - ca3-[10.3,11.3): 0.6625 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5086 - ca4-[11.3,14.9): 0.6823 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9173 - val_ca1-[11.3,14.9): 1.5789 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3903 - val_ca2-[10.3,11.3): 0.8062 - val_ca2-[11.3,14.9): 1.3639 - val_ca3-[8.0,9.5): 0.8673 - val_ca3-[9.5,10.3): 0.5261 - val_ca3-[10.3,11.3): 0.6755 - val_ca3-[11.3,14.9): 0.8539 - val_ca4-[8.0,9.5): 1.4919 - val_ca4-[9.5,10.3): 1.0634 - val_ca4-[10.3,11.3): 0.9297 - val_ca4-[11.3,14.9): 0.6979\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5213 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3478 - ca2-[9.5,10.3): 0.4609 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5014 - ca3-[10.3,11.3): 0.6363 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5214 - ca4-[11.3,14.9): 0.6977 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9128 - val_ca1-[11.3,14.9): 1.5857 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3909 - val_ca2-[10.3,11.3): 0.8092 - val_ca2-[11.3,14.9): 1.3842 - val_ca3-[8.0,9.5): 0.8518 - val_ca3-[9.5,10.3): 0.5172 - val_ca3-[10.3,11.3): 0.6732 - val_ca3-[11.3,14.9): 0.8692 - val_ca4-[8.0,9.5): 1.4919 - val_ca4-[9.5,10.3): 1.0630 - val_ca4-[10.3,11.3): 0.9309 - val_ca4-[11.3,14.9): 0.7044\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5135 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3495 - ca2-[9.5,10.3): 0.4561 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4950 - ca3-[10.3,11.3): 0.6647 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5577 - ca4-[11.3,14.9): 0.6872 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9277 - val_ca1-[11.3,14.9): 1.5954 - val_ca2-[8.0,9.5): 0.5853 - val_ca2-[9.5,10.3): 0.3902 - val_ca2-[10.3,11.3): 0.8159 - val_ca2-[11.3,14.9): 1.3796 - val_ca3-[8.0,9.5): 0.8690 - val_ca3-[9.5,10.3): 0.5278 - val_ca3-[10.3,11.3): 0.6789 - val_ca3-[11.3,14.9): 0.8523 - val_ca4-[8.0,9.5): 1.4939 - val_ca4-[9.5,10.3): 1.0644 - val_ca4-[10.3,11.3): 0.9303 - val_ca4-[11.3,14.9): 0.6832\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5076 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3586 - ca2-[9.5,10.3): 0.4631 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5194 - ca3-[10.3,11.3): 0.6598 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5248 - ca4-[11.3,14.9): 0.6883 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9170 - val_ca1-[11.3,14.9): 1.5918 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3901 - val_ca2-[10.3,11.3): 0.8067 - val_ca2-[11.3,14.9): 1.3724 - val_ca3-[8.0,9.5): 0.8490 - val_ca3-[9.5,10.3): 0.5158 - val_ca3-[10.3,11.3): 0.6747 - val_ca3-[11.3,14.9): 0.8676 - val_ca4-[8.0,9.5): 1.4967 - val_ca4-[9.5,10.3): 1.0666 - val_ca4-[10.3,11.3): 0.9310 - val_ca4-[11.3,14.9): 0.6993\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5152 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3480 - ca2-[9.5,10.3): 0.4684 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5027 - ca3-[10.3,11.3): 0.6670 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5302 - ca4-[11.3,14.9): 0.6838 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9185 - val_ca1-[11.3,14.9): 1.6110 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.3903 - val_ca2-[10.3,11.3): 0.8106 - val_ca2-[11.3,14.9): 1.3958 - val_ca3-[8.0,9.5): 0.8657 - val_ca3-[9.5,10.3): 0.5257 - val_ca3-[10.3,11.3): 0.6763 - val_ca3-[11.3,14.9): 0.8589 - val_ca4-[8.0,9.5): 1.4950 - val_ca4-[9.5,10.3): 1.0646 - val_ca4-[10.3,11.3): 0.9320 - val_ca4-[11.3,14.9): 0.6843\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5239 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3689 - ca2-[9.5,10.3): 0.4625 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5059 - ca3-[10.3,11.3): 0.6654 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5153 - ca4-[11.3,14.9): 0.6776 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9123 - val_ca1-[11.3,14.9): 1.5923 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.3901 - val_ca2-[10.3,11.3): 0.8044 - val_ca2-[11.3,14.9): 1.3771 - val_ca3-[8.0,9.5): 0.8532 - val_ca3-[9.5,10.3): 0.5181 - val_ca3-[10.3,11.3): 0.6728 - val_ca3-[11.3,14.9): 0.8615 - val_ca4-[8.0,9.5): 1.4946 - val_ca4-[9.5,10.3): 1.0641 - val_ca4-[10.3,11.3): 0.9307 - val_ca4-[11.3,14.9): 0.6875\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5198 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3395 - ca2-[9.5,10.3): 0.4539 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4844 - ca3-[10.3,11.3): 0.6386 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5361 - ca4-[11.3,14.9): 0.6910 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9270 - val_ca1-[11.3,14.9): 1.6208 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3897 - val_ca2-[10.3,11.3): 0.8138 - val_ca2-[11.3,14.9): 1.3969 - val_ca3-[8.0,9.5): 0.8622 - val_ca3-[9.5,10.3): 0.5232 - val_ca3-[10.3,11.3): 0.6795 - val_ca3-[11.3,14.9): 0.8757 - val_ca4-[8.0,9.5): 1.4951 - val_ca4-[9.5,10.3): 1.0643 - val_ca4-[10.3,11.3): 0.9348 - val_ca4-[11.3,14.9): 0.7109\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5100 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3477 - ca2-[9.5,10.3): 0.4514 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5134 - ca3-[10.3,11.3): 0.6304 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5597 - ca4-[11.3,14.9): 0.6853 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9232 - val_ca1-[11.3,14.9): 1.6246 - val_ca2-[8.0,9.5): 0.5856 - val_ca2-[9.5,10.3): 0.3897 - val_ca2-[10.3,11.3): 0.8116 - val_ca2-[11.3,14.9): 1.4065 - val_ca3-[8.0,9.5): 0.8549 - val_ca3-[9.5,10.3): 0.5187 - val_ca3-[10.3,11.3): 0.6750 - val_ca3-[11.3,14.9): 0.8824 - val_ca4-[8.0,9.5): 1.4967 - val_ca4-[9.5,10.3): 1.0655 - val_ca4-[10.3,11.3): 0.9302 - val_ca4-[11.3,14.9): 0.7082\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5255 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3632 - ca2-[9.5,10.3): 0.4547 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5049 - ca3-[10.3,11.3): 0.6555 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5445 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9125 - val_ca1-[11.3,14.9): 1.5637 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3902 - val_ca2-[10.3,11.3): 0.8105 - val_ca2-[11.3,14.9): 1.3705 - val_ca3-[8.0,9.5): 0.8587 - val_ca3-[9.5,10.3): 0.5217 - val_ca3-[10.3,11.3): 0.6665 - val_ca3-[11.3,14.9): 0.8433 - val_ca4-[8.0,9.5): 1.4975 - val_ca4-[9.5,10.3): 1.0658 - val_ca4-[10.3,11.3): 0.9155 - val_ca4-[11.3,14.9): 0.6845\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5174 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3572 - ca2-[9.5,10.3): 0.4684 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4781 - ca3-[10.3,11.3): 0.6621 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5232 - ca4-[11.3,14.9): 0.6636 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9179 - val_ca1-[11.3,14.9): 1.5760 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.3898 - val_ca2-[10.3,11.3): 0.8109 - val_ca2-[11.3,14.9): 1.3731 - val_ca3-[8.0,9.5): 0.8538 - val_ca3-[9.5,10.3): 0.5190 - val_ca3-[10.3,11.3): 0.6742 - val_ca3-[11.3,14.9): 0.8578 - val_ca4-[8.0,9.5): 1.5015 - val_ca4-[9.5,10.3): 1.0691 - val_ca4-[10.3,11.3): 0.9335 - val_ca4-[11.3,14.9): 0.7014\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5191 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3640 - ca2-[9.5,10.3): 0.4728 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4888 - ca3-[10.3,11.3): 0.6531 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5395 - ca4-[11.3,14.9): 0.7009 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9159 - val_ca1-[11.3,14.9): 1.5695 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3892 - val_ca2-[10.3,11.3): 0.8035 - val_ca2-[11.3,14.9): 1.3588 - val_ca3-[8.0,9.5): 0.8489 - val_ca3-[9.5,10.3): 0.5155 - val_ca3-[10.3,11.3): 0.6722 - val_ca3-[11.3,14.9): 0.8567 - val_ca4-[8.0,9.5): 1.5007 - val_ca4-[9.5,10.3): 1.0678 - val_ca4-[10.3,11.3): 0.9301 - val_ca4-[11.3,14.9): 0.6898\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5146 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3679 - ca2-[9.5,10.3): 0.4570 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4887 - ca3-[10.3,11.3): 0.6482 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5286 - ca4-[11.3,14.9): 0.6699 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9229 - val_ca1-[11.3,14.9): 1.6177 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3891 - val_ca2-[10.3,11.3): 0.8083 - val_ca2-[11.3,14.9): 1.4006 - val_ca3-[8.0,9.5): 0.8527 - val_ca3-[9.5,10.3): 0.5167 - val_ca3-[10.3,11.3): 0.6737 - val_ca3-[11.3,14.9): 0.8840 - val_ca4-[8.0,9.5): 1.5000 - val_ca4-[9.5,10.3): 1.0669 - val_ca4-[10.3,11.3): 0.9301 - val_ca4-[11.3,14.9): 0.7072\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5164 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3483 - ca2-[9.5,10.3): 0.4574 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4880 - ca3-[10.3,11.3): 0.6517 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5352 - ca4-[11.3,14.9): 0.6708 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9166 - val_ca1-[11.3,14.9): 1.6043 - val_ca2-[8.0,9.5): 0.5848 - val_ca2-[9.5,10.3): 0.3894 - val_ca2-[10.3,11.3): 0.8069 - val_ca2-[11.3,14.9): 1.3823 - val_ca3-[8.0,9.5): 0.8558 - val_ca3-[9.5,10.3): 0.5180 - val_ca3-[10.3,11.3): 0.6713 - val_ca3-[11.3,14.9): 0.8660 - val_ca4-[8.0,9.5): 1.4975 - val_ca4-[9.5,10.3): 1.0643 - val_ca4-[10.3,11.3): 0.9276 - val_ca4-[11.3,14.9): 0.7042\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5135 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3643 - ca2-[9.5,10.3): 0.4570 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4896 - ca3-[10.3,11.3): 0.6683 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5303 - ca4-[11.3,14.9): 0.6806 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9207 - val_ca1-[11.3,14.9): 1.5940 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3887 - val_ca2-[10.3,11.3): 0.8048 - val_ca2-[11.3,14.9): 1.3706 - val_ca3-[8.0,9.5): 0.8533 - val_ca3-[9.5,10.3): 0.5170 - val_ca3-[10.3,11.3): 0.6746 - val_ca3-[11.3,14.9): 0.8659 - val_ca4-[8.0,9.5): 1.4984 - val_ca4-[9.5,10.3): 1.0650 - val_ca4-[10.3,11.3): 0.9328 - val_ca4-[11.3,14.9): 0.6965\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5046 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3624 - ca2-[9.5,10.3): 0.4584 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5115 - ca3-[10.3,11.3): 0.6512 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5195 - ca4-[11.3,14.9): 0.6859 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9189 - val_ca1-[11.3,14.9): 1.6053 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3892 - val_ca2-[10.3,11.3): 0.8066 - val_ca2-[11.3,14.9): 1.3888 - val_ca3-[8.0,9.5): 0.8545 - val_ca3-[9.5,10.3): 0.5179 - val_ca3-[10.3,11.3): 0.6727 - val_ca3-[11.3,14.9): 0.8647 - val_ca4-[8.0,9.5): 1.4981 - val_ca4-[9.5,10.3): 1.0645 - val_ca4-[10.3,11.3): 0.9298 - val_ca4-[11.3,14.9): 0.6984\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5183 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3574 - ca2-[9.5,10.3): 0.4717 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4859 - ca3-[10.3,11.3): 0.6667 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5593 - ca4-[11.3,14.9): 0.6863 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.6015 - val_ca2-[8.0,9.5): 0.5828 - val_ca2-[9.5,10.3): 0.3901 - val_ca2-[10.3,11.3): 0.8109 - val_ca2-[11.3,14.9): 1.3989 - val_ca3-[8.0,9.5): 0.8571 - val_ca3-[9.5,10.3): 0.5198 - val_ca3-[10.3,11.3): 0.6683 - val_ca3-[11.3,14.9): 0.8541 - val_ca4-[8.0,9.5): 1.4978 - val_ca4-[9.5,10.3): 1.0639 - val_ca4-[10.3,11.3): 0.9265 - val_ca4-[11.3,14.9): 0.6907\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5092 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3465 - ca2-[9.5,10.3): 0.4662 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4752 - ca3-[10.3,11.3): 0.6475 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5241 - ca4-[11.3,14.9): 0.6733 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9259 - val_ca1-[11.3,14.9): 1.6140 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.3891 - val_ca2-[10.3,11.3): 0.8095 - val_ca2-[11.3,14.9): 1.3895 - val_ca3-[8.0,9.5): 0.8435 - val_ca3-[9.5,10.3): 0.5121 - val_ca3-[10.3,11.3): 0.6723 - val_ca3-[11.3,14.9): 0.8733 - val_ca4-[8.0,9.5): 1.4989 - val_ca4-[9.5,10.3): 1.0645 - val_ca4-[10.3,11.3): 0.9252 - val_ca4-[11.3,14.9): 0.6967\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5155 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3545 - ca2-[9.5,10.3): 0.4537 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5091 - ca3-[10.3,11.3): 0.6690 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5270 - ca4-[11.3,14.9): 0.6773 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9213 - val_ca1-[11.3,14.9): 1.5996 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3886 - val_ca2-[10.3,11.3): 0.8020 - val_ca2-[11.3,14.9): 1.3649 - val_ca3-[8.0,9.5): 0.8477 - val_ca3-[9.5,10.3): 0.5145 - val_ca3-[10.3,11.3): 0.6700 - val_ca3-[11.3,14.9): 0.8546 - val_ca4-[8.0,9.5): 1.4985 - val_ca4-[9.5,10.3): 1.0639 - val_ca4-[10.3,11.3): 0.9244 - val_ca4-[11.3,14.9): 0.6794\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5265 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3621 - ca2-[9.5,10.3): 0.4597 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4982 - ca3-[10.3,11.3): 0.6418 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5494 - ca4-[11.3,14.9): 0.6609 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9188 - val_ca1-[11.3,14.9): 1.5734 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.3889 - val_ca2-[10.3,11.3): 0.8044 - val_ca2-[11.3,14.9): 1.3588 - val_ca3-[8.0,9.5): 0.8510 - val_ca3-[9.5,10.3): 0.5159 - val_ca3-[10.3,11.3): 0.6689 - val_ca3-[11.3,14.9): 0.8480 - val_ca4-[8.0,9.5): 1.4991 - val_ca4-[9.5,10.3): 1.0642 - val_ca4-[10.3,11.3): 0.9232 - val_ca4-[11.3,14.9): 0.6919\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5109 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3531 - ca2-[9.5,10.3): 0.4575 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4874 - ca3-[10.3,11.3): 0.6640 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5493 - ca4-[11.3,14.9): 0.6712 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9230 - val_ca1-[11.3,14.9): 1.6010 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3887 - val_ca2-[10.3,11.3): 0.8081 - val_ca2-[11.3,14.9): 1.3829 - val_ca3-[8.0,9.5): 0.8555 - val_ca3-[9.5,10.3): 0.5179 - val_ca3-[10.3,11.3): 0.6708 - val_ca3-[11.3,14.9): 0.8518 - val_ca4-[8.0,9.5): 1.4994 - val_ca4-[9.5,10.3): 1.0640 - val_ca4-[10.3,11.3): 0.9264 - val_ca4-[11.3,14.9): 0.6786\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5264 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3577 - ca2-[9.5,10.3): 0.4639 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5025 - ca3-[10.3,11.3): 0.6421 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5292 - ca4-[11.3,14.9): 0.6801 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9225 - val_ca1-[11.3,14.9): 1.5702 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.3878 - val_ca2-[10.3,11.3): 0.7996 - val_ca2-[11.3,14.9): 1.3420 - val_ca3-[8.0,9.5): 0.8476 - val_ca3-[9.5,10.3): 0.5131 - val_ca3-[10.3,11.3): 0.6704 - val_ca3-[11.3,14.9): 0.8519 - val_ca4-[8.0,9.5): 1.5040 - val_ca4-[9.5,10.3): 1.0678 - val_ca4-[10.3,11.3): 0.9284 - val_ca4-[11.3,14.9): 0.6924\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5224 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3530 - ca2-[9.5,10.3): 0.4621 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4918 - ca3-[10.3,11.3): 0.6492 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5437 - ca4-[11.3,14.9): 0.6658 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9222 - val_ca1-[11.3,14.9): 1.6095 - val_ca2-[8.0,9.5): 0.5850 - val_ca2-[9.5,10.3): 0.3884 - val_ca2-[10.3,11.3): 0.8082 - val_ca2-[11.3,14.9): 1.3933 - val_ca3-[8.0,9.5): 0.8541 - val_ca3-[9.5,10.3): 0.5173 - val_ca3-[10.3,11.3): 0.6703 - val_ca3-[11.3,14.9): 0.8672 - val_ca4-[8.0,9.5): 1.5017 - val_ca4-[9.5,10.3): 1.0651 - val_ca4-[10.3,11.3): 0.9264 - val_ca4-[11.3,14.9): 0.7027\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5142 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3442 - ca2-[9.5,10.3): 0.4446 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4783 - ca3-[10.3,11.3): 0.6472 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5699 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9037 - val_ca1-[11.3,14.9): 1.5652 - val_ca2-[8.0,9.5): 0.5810 - val_ca2-[9.5,10.3): 0.3897 - val_ca2-[10.3,11.3): 0.7988 - val_ca2-[11.3,14.9): 1.3764 - val_ca3-[8.0,9.5): 0.8367 - val_ca3-[9.5,10.3): 0.5072 - val_ca3-[10.3,11.3): 0.6577 - val_ca3-[11.3,14.9): 0.8471 - val_ca4-[8.0,9.5): 1.4987 - val_ca4-[9.5,10.3): 1.0622 - val_ca4-[10.3,11.3): 0.9167 - val_ca4-[11.3,14.9): 0.6798\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5298 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3529 - ca2-[9.5,10.3): 0.4665 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5030 - ca3-[10.3,11.3): 0.6593 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5492 - ca4-[11.3,14.9): 0.6794 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9269 - val_ca1-[11.3,14.9): 1.6003 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3877 - val_ca2-[10.3,11.3): 0.8050 - val_ca2-[11.3,14.9): 1.3663 - val_ca3-[8.0,9.5): 0.8444 - val_ca3-[9.5,10.3): 0.5116 - val_ca3-[10.3,11.3): 0.6739 - val_ca3-[11.3,14.9): 0.8660 - val_ca4-[8.0,9.5): 1.5026 - val_ca4-[9.5,10.3): 1.0653 - val_ca4-[10.3,11.3): 0.9311 - val_ca4-[11.3,14.9): 0.6990\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5200 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3595 - ca2-[9.5,10.3): 0.4646 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4984 - ca3-[10.3,11.3): 0.6497 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5285 - ca4-[11.3,14.9): 0.6817 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9252 - val_ca1-[11.3,14.9): 1.6097 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3888 - val_ca2-[10.3,11.3): 0.8017 - val_ca2-[11.3,14.9): 1.3806 - val_ca3-[8.0,9.5): 0.8517 - val_ca3-[9.5,10.3): 0.5174 - val_ca3-[10.3,11.3): 0.6711 - val_ca3-[11.3,14.9): 0.8642 - val_ca4-[8.0,9.5): 1.5024 - val_ca4-[9.5,10.3): 1.0679 - val_ca4-[10.3,11.3): 0.9281 - val_ca4-[11.3,14.9): 0.6983\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5164 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3540 - ca2-[9.5,10.3): 0.4680 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5119 - ca3-[10.3,11.3): 0.6326 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5614 - ca4-[11.3,14.9): 0.6677 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9180 - val_ca1-[11.3,14.9): 1.6068 - val_ca2-[8.0,9.5): 0.5833 - val_ca2-[9.5,10.3): 0.3888 - val_ca2-[10.3,11.3): 0.8073 - val_ca2-[11.3,14.9): 1.3961 - val_ca3-[8.0,9.5): 0.8354 - val_ca3-[9.5,10.3): 0.5052 - val_ca3-[10.3,11.3): 0.6665 - val_ca3-[11.3,14.9): 0.8765 - val_ca4-[8.0,9.5): 1.5008 - val_ca4-[9.5,10.3): 1.0631 - val_ca4-[10.3,11.3): 0.9235 - val_ca4-[11.3,14.9): 0.7005\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5295 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3598 - ca2-[9.5,10.3): 0.4676 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4764 - ca3-[10.3,11.3): 0.6606 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5463 - ca4-[11.3,14.9): 0.6672 - val_ca1-[8.0,9.5): 0.5796 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9225 - val_ca1-[11.3,14.9): 1.6283 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.3878 - val_ca2-[10.3,11.3): 0.8001 - val_ca2-[11.3,14.9): 1.3886 - val_ca3-[8.0,9.5): 0.8340 - val_ca3-[9.5,10.3): 0.5051 - val_ca3-[10.3,11.3): 0.6662 - val_ca3-[11.3,14.9): 0.8803 - val_ca4-[8.0,9.5): 1.5025 - val_ca4-[9.5,10.3): 1.0641 - val_ca4-[10.3,11.3): 0.9221 - val_ca4-[11.3,14.9): 0.6981\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5244 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3626 - ca2-[9.5,10.3): 0.4617 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5008 - ca3-[10.3,11.3): 0.6324 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5716 - ca4-[11.3,14.9): 0.6875 - val_ca1-[8.0,9.5): 0.5796 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9224 - val_ca1-[11.3,14.9): 1.6071 - val_ca2-[8.0,9.5): 0.5844 - val_ca2-[9.5,10.3): 0.3882 - val_ca2-[10.3,11.3): 0.8065 - val_ca2-[11.3,14.9): 1.3806 - val_ca3-[8.0,9.5): 0.8432 - val_ca3-[9.5,10.3): 0.5113 - val_ca3-[10.3,11.3): 0.6660 - val_ca3-[11.3,14.9): 0.8623 - val_ca4-[8.0,9.5): 1.5022 - val_ca4-[9.5,10.3): 1.0635 - val_ca4-[10.3,11.3): 0.9214 - val_ca4-[11.3,14.9): 0.7002\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5153 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3622 - ca2-[9.5,10.3): 0.4500 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5030 - ca3-[10.3,11.3): 0.6503 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5490 - ca4-[11.3,14.9): 0.6782 - val_ca1-[8.0,9.5): 0.5795 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9228 - val_ca1-[11.3,14.9): 1.5878 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.3879 - val_ca2-[10.3,11.3): 0.8056 - val_ca2-[11.3,14.9): 1.3674 - val_ca3-[8.0,9.5): 0.8441 - val_ca3-[9.5,10.3): 0.5118 - val_ca3-[10.3,11.3): 0.6659 - val_ca3-[11.3,14.9): 0.8457 - val_ca4-[8.0,9.5): 1.5023 - val_ca4-[9.5,10.3): 1.0633 - val_ca4-[10.3,11.3): 0.9210 - val_ca4-[11.3,14.9): 0.6847\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5127 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3555 - ca2-[9.5,10.3): 0.4575 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4796 - ca3-[10.3,11.3): 0.6489 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5586 - ca4-[11.3,14.9): 0.6822 - val_ca1-[8.0,9.5): 0.5794 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9185 - val_ca1-[11.3,14.9): 1.6030 - val_ca2-[8.0,9.5): 0.5837 - val_ca2-[9.5,10.3): 0.3884 - val_ca2-[10.3,11.3): 0.8055 - val_ca2-[11.3,14.9): 1.3831 - val_ca3-[8.0,9.5): 0.8426 - val_ca3-[9.5,10.3): 0.5108 - val_ca3-[10.3,11.3): 0.6655 - val_ca3-[11.3,14.9): 0.8564 - val_ca4-[8.0,9.5): 1.5012 - val_ca4-[9.5,10.3): 1.0621 - val_ca4-[10.3,11.3): 0.9218 - val_ca4-[11.3,14.9): 0.6944\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5140 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3526 - ca2-[9.5,10.3): 0.4496 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4619 - ca3-[10.3,11.3): 0.6415 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5439 - ca4-[11.3,14.9): 0.6691 - val_ca1-[8.0,9.5): 0.5794 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9250 - val_ca1-[11.3,14.9): 1.6021 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.3873 - val_ca2-[10.3,11.3): 0.7978 - val_ca2-[11.3,14.9): 1.3541 - val_ca3-[8.0,9.5): 0.8420 - val_ca3-[9.5,10.3): 0.5105 - val_ca3-[10.3,11.3): 0.6674 - val_ca3-[11.3,14.9): 0.8577 - val_ca4-[8.0,9.5): 1.5045 - val_ca4-[9.5,10.3): 1.0647 - val_ca4-[10.3,11.3): 0.9237 - val_ca4-[11.3,14.9): 0.6980\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5163 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3495 - ca2-[9.5,10.3): 0.4628 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4993 - ca3-[10.3,11.3): 0.6434 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4766 - ca4-[11.3,14.9): 0.6737 - val_ca1-[8.0,9.5): 0.5792 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9231 - val_ca1-[11.3,14.9): 1.5764 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.3883 - val_ca2-[10.3,11.3): 0.8065 - val_ca2-[11.3,14.9): 1.3545 - val_ca3-[8.0,9.5): 0.8241 - val_ca3-[9.5,10.3): 0.4986 - val_ca3-[10.3,11.3): 0.6682 - val_ca3-[11.3,14.9): 0.8552 - val_ca4-[8.0,9.5): 1.5046 - val_ca4-[9.5,10.3): 1.0644 - val_ca4-[10.3,11.3): 0.9276 - val_ca4-[11.3,14.9): 0.6813\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5172 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3687 - ca2-[9.5,10.3): 0.4669 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4804 - ca3-[10.3,11.3): 0.6503 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5390 - ca4-[11.3,14.9): 0.6686 - val_ca1-[8.0,9.5): 0.5792 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9258 - val_ca1-[11.3,14.9): 1.6246 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3873 - val_ca2-[10.3,11.3): 0.7981 - val_ca2-[11.3,14.9): 1.3818 - val_ca3-[8.0,9.5): 0.8474 - val_ca3-[9.5,10.3): 0.5125 - val_ca3-[10.3,11.3): 0.6665 - val_ca3-[11.3,14.9): 0.8672 - val_ca4-[8.0,9.5): 1.5044 - val_ca4-[9.5,10.3): 1.0636 - val_ca4-[10.3,11.3): 0.9224 - val_ca4-[11.3,14.9): 0.6957\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5201 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3531 - ca2-[9.5,10.3): 0.4515 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5014 - ca3-[10.3,11.3): 0.6600 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5143 - ca4-[11.3,14.9): 0.6809 - val_ca1-[8.0,9.5): 0.5790 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9266 - val_ca1-[11.3,14.9): 1.5731 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3877 - val_ca2-[10.3,11.3): 0.8026 - val_ca2-[11.3,14.9): 1.3458 - val_ca3-[8.0,9.5): 0.8338 - val_ca3-[9.5,10.3): 0.5044 - val_ca3-[10.3,11.3): 0.6659 - val_ca3-[11.3,14.9): 0.8428 - val_ca4-[8.0,9.5): 1.5011 - val_ca4-[9.5,10.3): 1.0601 - val_ca4-[10.3,11.3): 0.9202 - val_ca4-[11.3,14.9): 0.6810\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5102 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3486 - ca2-[9.5,10.3): 0.4546 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4683 - ca3-[10.3,11.3): 0.6340 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5250 - ca4-[11.3,14.9): 0.6796 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9248 - val_ca1-[11.3,14.9): 1.5937 - val_ca2-[8.0,9.5): 0.5843 - val_ca2-[9.5,10.3): 0.3879 - val_ca2-[10.3,11.3): 0.8042 - val_ca2-[11.3,14.9): 1.3689 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5046 - val_ca3-[10.3,11.3): 0.6637 - val_ca3-[11.3,14.9): 0.8537 - val_ca4-[8.0,9.5): 1.5022 - val_ca4-[9.5,10.3): 1.0607 - val_ca4-[10.3,11.3): 0.9177 - val_ca4-[11.3,14.9): 0.6849\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3696 - ca2-[9.5,10.3): 0.4577 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4979 - ca3-[10.3,11.3): 0.6731 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5377 - ca4-[11.3,14.9): 0.6595 - val_ca1-[8.0,9.5): 0.5788 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9274 - val_ca1-[11.3,14.9): 1.6153 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3872 - val_ca2-[10.3,11.3): 0.8027 - val_ca2-[11.3,14.9): 1.3746 - val_ca3-[8.0,9.5): 0.8430 - val_ca3-[9.5,10.3): 0.5121 - val_ca3-[10.3,11.3): 0.6665 - val_ca3-[11.3,14.9): 0.8522 - val_ca4-[8.0,9.5): 1.5035 - val_ca4-[9.5,10.3): 1.0615 - val_ca4-[10.3,11.3): 0.9203 - val_ca4-[11.3,14.9): 0.6917\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5123 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3311 - ca2-[9.5,10.3): 0.4389 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4794 - ca3-[10.3,11.3): 0.6599 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5643 - ca4-[11.3,14.9): 0.6745 - val_ca1-[8.0,9.5): 0.5786 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9234 - val_ca1-[11.3,14.9): 1.6051 - val_ca2-[8.0,9.5): 0.5825 - val_ca2-[9.5,10.3): 0.3882 - val_ca2-[10.3,11.3): 0.8053 - val_ca2-[11.3,14.9): 1.3926 - val_ca3-[8.0,9.5): 0.8348 - val_ca3-[9.5,10.3): 0.5066 - val_ca3-[10.3,11.3): 0.6634 - val_ca3-[11.3,14.9): 0.8563 - val_ca4-[8.0,9.5): 1.5030 - val_ca4-[9.5,10.3): 1.0606 - val_ca4-[10.3,11.3): 0.9213 - val_ca4-[11.3,14.9): 0.6945\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5139 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3546 - ca2-[9.5,10.3): 0.4499 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4939 - ca3-[10.3,11.3): 0.6541 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5406 - ca4-[11.3,14.9): 0.6729 - val_ca1-[8.0,9.5): 0.5783 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9266 - val_ca1-[11.3,14.9): 1.5754 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3873 - val_ca2-[10.3,11.3): 0.7985 - val_ca2-[11.3,14.9): 1.3309 - val_ca3-[8.0,9.5): 0.8378 - val_ca3-[9.5,10.3): 0.5072 - val_ca3-[10.3,11.3): 0.6626 - val_ca3-[11.3,14.9): 0.8329 - val_ca4-[8.0,9.5): 1.5044 - val_ca4-[9.5,10.3): 1.0612 - val_ca4-[10.3,11.3): 0.9170 - val_ca4-[11.3,14.9): 0.6838\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5155 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3608 - ca2-[9.5,10.3): 0.4558 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4772 - ca3-[10.3,11.3): 0.6417 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5028 - ca4-[11.3,14.9): 0.6785 - val_ca1-[8.0,9.5): 0.5781 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9271 - val_ca1-[11.3,14.9): 1.6042 - val_ca2-[8.0,9.5): 0.5856 - val_ca2-[9.5,10.3): 0.3876 - val_ca2-[10.3,11.3): 0.8011 - val_ca2-[11.3,14.9): 1.3625 - val_ca3-[8.0,9.5): 0.8289 - val_ca3-[9.5,10.3): 0.5018 - val_ca3-[10.3,11.3): 0.6619 - val_ca3-[11.3,14.9): 0.8498 - val_ca4-[8.0,9.5): 1.5080 - val_ca4-[9.5,10.3): 1.0641 - val_ca4-[10.3,11.3): 0.9184 - val_ca4-[11.3,14.9): 0.6766\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5169 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3516 - ca2-[9.5,10.3): 0.4583 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4951 - ca3-[10.3,11.3): 0.6425 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5251 - ca4-[11.3,14.9): 0.6758 - val_ca1-[8.0,9.5): 0.5781 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9260 - val_ca1-[11.3,14.9): 1.6352 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3876 - val_ca2-[10.3,11.3): 0.8017 - val_ca2-[11.3,14.9): 1.3941 - val_ca3-[8.0,9.5): 0.8382 - val_ca3-[9.5,10.3): 0.5082 - val_ca3-[10.3,11.3): 0.6640 - val_ca3-[11.3,14.9): 0.8693 - val_ca4-[8.0,9.5): 1.5093 - val_ca4-[9.5,10.3): 1.0646 - val_ca4-[10.3,11.3): 0.9202 - val_ca4-[11.3,14.9): 0.7014\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5233 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3523 - ca2-[9.5,10.3): 0.4566 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5187 - ca3-[10.3,11.3): 0.6430 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5579 - ca4-[11.3,14.9): 0.6878 - val_ca1-[8.0,9.5): 0.5779 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9286 - val_ca1-[11.3,14.9): 1.5757 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3886 - val_ca2-[10.3,11.3): 0.8000 - val_ca2-[11.3,14.9): 1.3297 - val_ca3-[8.0,9.5): 0.8240 - val_ca3-[9.5,10.3): 0.4992 - val_ca3-[10.3,11.3): 0.6633 - val_ca3-[11.3,14.9): 0.8422 - val_ca4-[8.0,9.5): 1.5119 - val_ca4-[9.5,10.3): 1.0639 - val_ca4-[10.3,11.3): 0.9218 - val_ca4-[11.3,14.9): 0.6817\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5236 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3556 - ca2-[9.5,10.3): 0.4509 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5106 - ca3-[10.3,11.3): 0.6349 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5487 - ca4-[11.3,14.9): 0.6704 - val_ca1-[8.0,9.5): 0.5778 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9330 - val_ca1-[11.3,14.9): 1.6477 - val_ca2-[8.0,9.5): 0.5850 - val_ca2-[9.5,10.3): 0.3877 - val_ca2-[10.3,11.3): 0.8068 - val_ca2-[11.3,14.9): 1.4088 - val_ca3-[8.0,9.5): 0.8279 - val_ca3-[9.5,10.3): 0.5011 - val_ca3-[10.3,11.3): 0.6639 - val_ca3-[11.3,14.9): 0.8805 - val_ca4-[8.0,9.5): 1.5114 - val_ca4-[9.5,10.3): 1.0654 - val_ca4-[10.3,11.3): 0.9197 - val_ca4-[11.3,14.9): 0.6976\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5213 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3581 - ca2-[9.5,10.3): 0.4480 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4832 - ca3-[10.3,11.3): 0.6327 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5528 - ca4-[11.3,14.9): 0.6655 - val_ca1-[8.0,9.5): 0.5777 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9289 - val_ca1-[11.3,14.9): 1.5781 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.3873 - val_ca2-[10.3,11.3): 0.7995 - val_ca2-[11.3,14.9): 1.3315 - val_ca3-[8.0,9.5): 0.8337 - val_ca3-[9.5,10.3): 0.5043 - val_ca3-[10.3,11.3): 0.6628 - val_ca3-[11.3,14.9): 0.8305 - val_ca4-[8.0,9.5): 1.5126 - val_ca4-[9.5,10.3): 1.0659 - val_ca4-[10.3,11.3): 0.9203 - val_ca4-[11.3,14.9): 0.6761\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5167 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3529 - ca2-[9.5,10.3): 0.4645 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4802 - ca3-[10.3,11.3): 0.6539 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5123 - ca4-[11.3,14.9): 0.6657 - val_ca1-[8.0,9.5): 0.5774 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9317 - val_ca1-[11.3,14.9): 1.6228 - val_ca2-[8.0,9.5): 0.5821 - val_ca2-[9.5,10.3): 0.3883 - val_ca2-[10.3,11.3): 0.8113 - val_ca2-[11.3,14.9): 1.3970 - val_ca3-[8.0,9.5): 0.8227 - val_ca3-[9.5,10.3): 0.4970 - val_ca3-[10.3,11.3): 0.6639 - val_ca3-[11.3,14.9): 0.8690 - val_ca4-[8.0,9.5): 1.5108 - val_ca4-[9.5,10.3): 1.0638 - val_ca4-[10.3,11.3): 0.9214 - val_ca4-[11.3,14.9): 0.6926\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5191 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3420 - ca2-[9.5,10.3): 0.4544 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4844 - ca3-[10.3,11.3): 0.6340 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5800 - ca4-[11.3,14.9): 0.6666 - val_ca1-[8.0,9.5): 0.5774 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9258 - val_ca1-[11.3,14.9): 1.6089 - val_ca2-[8.0,9.5): 0.5835 - val_ca2-[9.5,10.3): 0.3876 - val_ca2-[10.3,11.3): 0.8044 - val_ca2-[11.3,14.9): 1.3764 - val_ca3-[8.0,9.5): 0.8299 - val_ca3-[9.5,10.3): 0.5025 - val_ca3-[10.3,11.3): 0.6566 - val_ca3-[11.3,14.9): 0.8415 - val_ca4-[8.0,9.5): 1.5113 - val_ca4-[9.5,10.3): 1.0636 - val_ca4-[10.3,11.3): 0.9053 - val_ca4-[11.3,14.9): 0.6562\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5147 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3628 - ca2-[9.5,10.3): 0.4537 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4988 - ca3-[10.3,11.3): 0.6437 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5383 - ca4-[11.3,14.9): 0.6857 - val_ca1-[8.0,9.5): 0.5773 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9210 - val_ca1-[11.3,14.9): 1.6027 - val_ca2-[8.0,9.5): 0.5903 - val_ca2-[9.5,10.3): 0.3860 - val_ca2-[10.3,11.3): 0.7771 - val_ca2-[11.3,14.9): 1.3222 - val_ca3-[8.0,9.5): 0.8259 - val_ca3-[9.5,10.3): 0.5005 - val_ca3-[10.3,11.3): 0.6481 - val_ca3-[11.3,14.9): 0.8391 - val_ca4-[8.0,9.5): 1.5158 - val_ca4-[9.5,10.3): 1.0671 - val_ca4-[10.3,11.3): 0.9023 - val_ca4-[11.3,14.9): 0.6680\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5161 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3622 - ca2-[9.5,10.3): 0.4635 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4838 - ca3-[10.3,11.3): 0.6177 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5490 - ca4-[11.3,14.9): 0.6733 - val_ca1-[8.0,9.5): 0.5771 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9233 - val_ca1-[11.3,14.9): 1.6208 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.3863 - val_ca2-[10.3,11.3): 0.7888 - val_ca2-[11.3,14.9): 1.3573 - val_ca3-[8.0,9.5): 0.8169 - val_ca3-[9.5,10.3): 0.4937 - val_ca3-[10.3,11.3): 0.6590 - val_ca3-[11.3,14.9): 0.8696 - val_ca4-[8.0,9.5): 1.5135 - val_ca4-[9.5,10.3): 1.0644 - val_ca4-[10.3,11.3): 0.9175 - val_ca4-[11.3,14.9): 0.6929\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5112 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3544 - ca2-[9.5,10.3): 0.4543 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5015 - ca3-[10.3,11.3): 0.6354 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4813 - ca4-[11.3,14.9): 0.6559 - val_ca1-[8.0,9.5): 0.5770 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9199 - val_ca1-[11.3,14.9): 1.6302 - val_ca2-[8.0,9.5): 0.5819 - val_ca2-[9.5,10.3): 0.3879 - val_ca2-[10.3,11.3): 0.8025 - val_ca2-[11.3,14.9): 1.3990 - val_ca3-[8.0,9.5): 0.8353 - val_ca3-[9.5,10.3): 0.5042 - val_ca3-[10.3,11.3): 0.6536 - val_ca3-[11.3,14.9): 0.8462 - val_ca4-[8.0,9.5): 1.5091 - val_ca4-[9.5,10.3): 1.0597 - val_ca4-[10.3,11.3): 0.9014 - val_ca4-[11.3,14.9): 0.6668\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5091 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3518 - ca2-[9.5,10.3): 0.4596 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4669 - ca3-[10.3,11.3): 0.6353 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5488 - ca4-[11.3,14.9): 0.6728 - val_ca1-[8.0,9.5): 0.5766 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9330 - val_ca1-[11.3,14.9): 1.6253 - val_ca2-[8.0,9.5): 0.5840 - val_ca2-[9.5,10.3): 0.3872 - val_ca2-[10.3,11.3): 0.8038 - val_ca2-[11.3,14.9): 1.3774 - val_ca3-[8.0,9.5): 0.8116 - val_ca3-[9.5,10.3): 0.4892 - val_ca3-[10.3,11.3): 0.6621 - val_ca3-[11.3,14.9): 0.8738 - val_ca4-[8.0,9.5): 1.5102 - val_ca4-[9.5,10.3): 1.0601 - val_ca4-[10.3,11.3): 0.9173 - val_ca4-[11.3,14.9): 0.6954\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.4966 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3436 - ca2-[9.5,10.3): 0.4502 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4930 - ca3-[10.3,11.3): 0.6450 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5318 - ca4-[11.3,14.9): 0.6756 - val_ca1-[8.0,9.5): 0.5765 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9205 - val_ca1-[11.3,14.9): 1.6226 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.3865 - val_ca2-[10.3,11.3): 0.7818 - val_ca2-[11.3,14.9): 1.3603 - val_ca3-[8.0,9.5): 0.8253 - val_ca3-[9.5,10.3): 0.4981 - val_ca3-[10.3,11.3): 0.6454 - val_ca3-[11.3,14.9): 0.8639 - val_ca4-[8.0,9.5): 1.5127 - val_ca4-[9.5,10.3): 1.0618 - val_ca4-[10.3,11.3): 0.8994 - val_ca4-[11.3,14.9): 0.6889\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 0.5169 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3545 - ca2-[9.5,10.3): 0.4626 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5016 - ca3-[10.3,11.3): 0.6519 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5305 - ca4-[11.3,14.9): 0.6764 - val_ca1-[8.0,9.5): 0.5763 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9251 - val_ca1-[11.3,14.9): 1.5904 - val_ca2-[8.0,9.5): 0.5837 - val_ca2-[9.5,10.3): 0.3876 - val_ca2-[10.3,11.3): 0.7995 - val_ca2-[11.3,14.9): 1.3422 - val_ca3-[8.0,9.5): 0.8095 - val_ca3-[9.5,10.3): 0.4893 - val_ca3-[10.3,11.3): 0.6575 - val_ca3-[11.3,14.9): 0.8430 - val_ca4-[8.0,9.5): 1.5145 - val_ca4-[9.5,10.3): 1.0630 - val_ca4-[10.3,11.3): 0.9150 - val_ca4-[11.3,14.9): 0.6792\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5029 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3525 - ca2-[9.5,10.3): 0.4476 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4664 - ca3-[10.3,11.3): 0.6384 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5599 - ca4-[11.3,14.9): 0.6794 - val_ca1-[8.0,9.5): 0.5760 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9259 - val_ca1-[11.3,14.9): 1.6008 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3867 - val_ca2-[10.3,11.3): 0.7923 - val_ca2-[11.3,14.9): 1.3463 - val_ca3-[8.0,9.5): 0.8164 - val_ca3-[9.5,10.3): 0.4939 - val_ca3-[10.3,11.3): 0.6571 - val_ca3-[11.3,14.9): 0.8526 - val_ca4-[8.0,9.5): 1.5131 - val_ca4-[9.5,10.3): 1.0607 - val_ca4-[10.3,11.3): 0.9133 - val_ca4-[11.3,14.9): 0.6816\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5169 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3549 - ca2-[9.5,10.3): 0.4646 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4907 - ca3-[10.3,11.3): 0.6254 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5275 - ca4-[11.3,14.9): 0.6800 - val_ca1-[8.0,9.5): 0.5758 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9238 - val_ca1-[11.3,14.9): 1.6065 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.3865 - val_ca2-[10.3,11.3): 0.7914 - val_ca2-[11.3,14.9): 1.3465 - val_ca3-[8.0,9.5): 0.8249 - val_ca3-[9.5,10.3): 0.4993 - val_ca3-[10.3,11.3): 0.6589 - val_ca3-[11.3,14.9): 0.8425 - val_ca4-[8.0,9.5): 1.5141 - val_ca4-[9.5,10.3): 1.0612 - val_ca4-[10.3,11.3): 0.9175 - val_ca4-[11.3,14.9): 0.6839\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5146 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3551 - ca2-[9.5,10.3): 0.4438 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4993 - ca3-[10.3,11.3): 0.6371 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5513 - ca4-[11.3,14.9): 0.6813 - val_ca1-[8.0,9.5): 0.5754 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9304 - val_ca1-[11.3,14.9): 1.6289 - val_ca2-[8.0,9.5): 0.5808 - val_ca2-[9.5,10.3): 0.3881 - val_ca2-[10.3,11.3): 0.8076 - val_ca2-[11.3,14.9): 1.3932 - val_ca3-[8.0,9.5): 0.8106 - val_ca3-[9.5,10.3): 0.4902 - val_ca3-[10.3,11.3): 0.6566 - val_ca3-[11.3,14.9): 0.8574 - val_ca4-[8.0,9.5): 1.5115 - val_ca4-[9.5,10.3): 1.0583 - val_ca4-[10.3,11.3): 0.9094 - val_ca4-[11.3,14.9): 0.6773\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5145 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3632 - ca2-[9.5,10.3): 0.4488 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5069 - ca3-[10.3,11.3): 0.6432 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5486 - ca4-[11.3,14.9): 0.6756 - val_ca1-[8.0,9.5): 0.5752 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9347 - val_ca1-[11.3,14.9): 1.6327 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3864 - val_ca2-[10.3,11.3): 0.7946 - val_ca2-[11.3,14.9): 1.3621 - val_ca3-[8.0,9.5): 0.8125 - val_ca3-[9.5,10.3): 0.4920 - val_ca3-[10.3,11.3): 0.6580 - val_ca3-[11.3,14.9): 0.8631 - val_ca4-[8.0,9.5): 1.5127 - val_ca4-[9.5,10.3): 1.0587 - val_ca4-[10.3,11.3): 0.9114 - val_ca4-[11.3,14.9): 0.6777\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5116 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3619 - ca2-[9.5,10.3): 0.4504 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5072 - ca3-[10.3,11.3): 0.6350 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5475 - ca4-[11.3,14.9): 0.6727 - val_ca1-[8.0,9.5): 0.5749 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9289 - val_ca1-[11.3,14.9): 1.6503 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3864 - val_ca2-[10.3,11.3): 0.7905 - val_ca2-[11.3,14.9): 1.3773 - val_ca3-[8.0,9.5): 0.8007 - val_ca3-[9.5,10.3): 0.4838 - val_ca3-[10.3,11.3): 0.6535 - val_ca3-[11.3,14.9): 0.8778 - val_ca4-[8.0,9.5): 1.5119 - val_ca4-[9.5,10.3): 1.0574 - val_ca4-[10.3,11.3): 0.9097 - val_ca4-[11.3,14.9): 0.6817\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5071 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3558 - ca2-[9.5,10.3): 0.4447 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4844 - ca3-[10.3,11.3): 0.6429 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5285 - ca4-[11.3,14.9): 0.6727 - val_ca1-[8.0,9.5): 0.5746 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9330 - val_ca1-[11.3,14.9): 1.6243 - val_ca2-[8.0,9.5): 0.5843 - val_ca2-[9.5,10.3): 0.3869 - val_ca2-[10.3,11.3): 0.7990 - val_ca2-[11.3,14.9): 1.3626 - val_ca3-[8.0,9.5): 0.8059 - val_ca3-[9.5,10.3): 0.4875 - val_ca3-[10.3,11.3): 0.6520 - val_ca3-[11.3,14.9): 0.8580 - val_ca4-[8.0,9.5): 1.5092 - val_ca4-[9.5,10.3): 1.0544 - val_ca4-[10.3,11.3): 0.8957 - val_ca4-[11.3,14.9): 0.6715\n",
      "Epoch 273/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5146 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3455 - ca2-[9.5,10.3): 0.4476 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4760 - ca3-[10.3,11.3): 0.6547 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5653 - ca4-[11.3,14.9): 0.6717 - val_ca1-[8.0,9.5): 0.5743 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9315 - val_ca1-[11.3,14.9): 1.6355 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3865 - val_ca2-[10.3,11.3): 0.7930 - val_ca2-[11.3,14.9): 1.3644 - val_ca3-[8.0,9.5): 0.8094 - val_ca3-[9.5,10.3): 0.4896 - val_ca3-[10.3,11.3): 0.6569 - val_ca3-[11.3,14.9): 0.8694 - val_ca4-[8.0,9.5): 1.5161 - val_ca4-[9.5,10.3): 1.0602 - val_ca4-[10.3,11.3): 0.9129 - val_ca4-[11.3,14.9): 0.6935\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5136 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3523 - ca2-[9.5,10.3): 0.4485 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4678 - ca3-[10.3,11.3): 0.6400 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4953 - ca4-[11.3,14.9): 0.6689 - val_ca1-[8.0,9.5): 0.5741 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9342 - val_ca1-[11.3,14.9): 1.6374 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3861 - val_ca2-[10.3,11.3): 0.7903 - val_ca2-[11.3,14.9): 1.3552 - val_ca3-[8.0,9.5): 0.8182 - val_ca3-[9.5,10.3): 0.4952 - val_ca3-[10.3,11.3): 0.6543 - val_ca3-[11.3,14.9): 0.8474 - val_ca4-[8.0,9.5): 1.5191 - val_ca4-[9.5,10.3): 1.0621 - val_ca4-[10.3,11.3): 0.9092 - val_ca4-[11.3,14.9): 0.6766\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5046 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3601 - ca2-[9.5,10.3): 0.4516 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4574 - ca3-[10.3,11.3): 0.6371 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5226 - ca4-[11.3,14.9): 0.6644 - val_ca1-[8.0,9.5): 0.5736 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9357 - val_ca1-[11.3,14.9): 1.6518 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3865 - val_ca2-[10.3,11.3): 0.7948 - val_ca2-[11.3,14.9): 1.3684 - val_ca3-[8.0,9.5): 0.7770 - val_ca3-[9.5,10.3): 0.4700 - val_ca3-[10.3,11.3): 0.6579 - val_ca3-[11.3,14.9): 0.8893 - val_ca4-[8.0,9.5): 1.5187 - val_ca4-[9.5,10.3): 1.0613 - val_ca4-[10.3,11.3): 0.9147 - val_ca4-[11.3,14.9): 0.6786\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.4987 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3596 - ca2-[9.5,10.3): 0.4408 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4774 - ca3-[10.3,11.3): 0.6311 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5127 - ca4-[11.3,14.9): 0.6602 - val_ca1-[8.0,9.5): 0.5735 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9347 - val_ca1-[11.3,14.9): 1.6421 - val_ca2-[8.0,9.5): 0.5853 - val_ca2-[9.5,10.3): 0.3863 - val_ca2-[10.3,11.3): 0.7883 - val_ca2-[11.3,14.9): 1.3604 - val_ca3-[8.0,9.5): 0.8214 - val_ca3-[9.5,10.3): 0.4987 - val_ca3-[10.3,11.3): 0.6541 - val_ca3-[11.3,14.9): 0.8478 - val_ca4-[8.0,9.5): 1.5147 - val_ca4-[9.5,10.3): 1.0564 - val_ca4-[10.3,11.3): 0.9099 - val_ca4-[11.3,14.9): 0.6881\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5193 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3663 - ca2-[9.5,10.3): 0.4482 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4805 - ca3-[10.3,11.3): 0.6284 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5343 - ca4-[11.3,14.9): 0.6671 - val_ca1-[8.0,9.5): 0.5731 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9376 - val_ca1-[11.3,14.9): 1.6222 - val_ca2-[8.0,9.5): 0.5843 - val_ca2-[9.5,10.3): 0.3866 - val_ca2-[10.3,11.3): 0.7969 - val_ca2-[11.3,14.9): 1.3466 - val_ca3-[8.0,9.5): 0.7865 - val_ca3-[9.5,10.3): 0.4768 - val_ca3-[10.3,11.3): 0.6527 - val_ca3-[11.3,14.9): 0.8528 - val_ca4-[8.0,9.5): 1.5200 - val_ca4-[9.5,10.3): 1.0607 - val_ca4-[10.3,11.3): 0.9069 - val_ca4-[11.3,14.9): 0.6645\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5213 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3517 - ca2-[9.5,10.3): 0.4513 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4870 - ca3-[10.3,11.3): 0.6393 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5173 - ca4-[11.3,14.9): 0.6694 - val_ca1-[8.0,9.5): 0.5728 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9310 - val_ca1-[11.3,14.9): 1.6319 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3863 - val_ca2-[10.3,11.3): 0.7903 - val_ca2-[11.3,14.9): 1.3530 - val_ca3-[8.0,9.5): 0.7957 - val_ca3-[9.5,10.3): 0.4823 - val_ca3-[10.3,11.3): 0.6542 - val_ca3-[11.3,14.9): 0.8645 - val_ca4-[8.0,9.5): 1.5205 - val_ca4-[9.5,10.3): 1.0603 - val_ca4-[10.3,11.3): 0.9119 - val_ca4-[11.3,14.9): 0.6883\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.4935 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3476 - ca2-[9.5,10.3): 0.4494 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4732 - ca3-[10.3,11.3): 0.6331 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5369 - ca4-[11.3,14.9): 0.6699 - val_ca1-[8.0,9.5): 0.5726 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9404 - val_ca1-[11.3,14.9): 1.6610 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.3862 - val_ca2-[10.3,11.3): 0.7932 - val_ca2-[11.3,14.9): 1.3758 - val_ca3-[8.0,9.5): 0.8029 - val_ca3-[9.5,10.3): 0.4863 - val_ca3-[10.3,11.3): 0.6541 - val_ca3-[11.3,14.9): 0.8733 - val_ca4-[8.0,9.5): 1.5187 - val_ca4-[9.5,10.3): 1.0574 - val_ca4-[10.3,11.3): 0.9059 - val_ca4-[11.3,14.9): 0.6911\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.4969 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3559 - ca2-[9.5,10.3): 0.4432 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4960 - ca3-[10.3,11.3): 0.6191 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5069 - ca4-[11.3,14.9): 0.6637 - val_ca1-[8.0,9.5): 0.5721 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9239 - val_ca1-[11.3,14.9): 1.5893 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3859 - val_ca2-[10.3,11.3): 0.7713 - val_ca2-[11.3,14.9): 1.3025 - val_ca3-[8.0,9.5): 0.7949 - val_ca3-[9.5,10.3): 0.4811 - val_ca3-[10.3,11.3): 0.6424 - val_ca3-[11.3,14.9): 0.8202 - val_ca4-[8.0,9.5): 1.5192 - val_ca4-[9.5,10.3): 1.0569 - val_ca4-[10.3,11.3): 0.9005 - val_ca4-[11.3,14.9): 0.6374\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.4924 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3624 - ca2-[9.5,10.3): 0.4547 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4761 - ca3-[10.3,11.3): 0.6202 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5724 - ca4-[11.3,14.9): 0.6671 - val_ca1-[8.0,9.5): 0.5718 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9393 - val_ca1-[11.3,14.9): 1.6468 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.3852 - val_ca2-[10.3,11.3): 0.7874 - val_ca2-[11.3,14.9): 1.3500 - val_ca3-[8.0,9.5): 0.7985 - val_ca3-[9.5,10.3): 0.4839 - val_ca3-[10.3,11.3): 0.6489 - val_ca3-[11.3,14.9): 0.8526 - val_ca4-[8.0,9.5): 1.5229 - val_ca4-[9.5,10.3): 1.0596 - val_ca4-[10.3,11.3): 0.8942 - val_ca4-[11.3,14.9): 0.6619\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5129 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3511 - ca2-[9.5,10.3): 0.4503 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4700 - ca3-[10.3,11.3): 0.6316 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5388 - ca4-[11.3,14.9): 0.6759 - val_ca1-[8.0,9.5): 0.5714 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9458 - val_ca1-[11.3,14.9): 1.6642 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3858 - val_ca2-[10.3,11.3): 0.7970 - val_ca2-[11.3,14.9): 1.3689 - val_ca3-[8.0,9.5): 0.7898 - val_ca3-[9.5,10.3): 0.4786 - val_ca3-[10.3,11.3): 0.6543 - val_ca3-[11.3,14.9): 0.8697 - val_ca4-[8.0,9.5): 1.5258 - val_ca4-[9.5,10.3): 1.0613 - val_ca4-[10.3,11.3): 0.9052 - val_ca4-[11.3,14.9): 0.6818\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5180 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3536 - ca2-[9.5,10.3): 0.4502 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4476 - ca3-[10.3,11.3): 0.6146 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5366 - ca4-[11.3,14.9): 0.6564 - val_ca1-[8.0,9.5): 0.5711 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9413 - val_ca1-[11.3,14.9): 1.6440 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3857 - val_ca2-[10.3,11.3): 0.7920 - val_ca2-[11.3,14.9): 1.3480 - val_ca3-[8.0,9.5): 0.8010 - val_ca3-[9.5,10.3): 0.4855 - val_ca3-[10.3,11.3): 0.6544 - val_ca3-[11.3,14.9): 0.8466 - val_ca4-[8.0,9.5): 1.5257 - val_ca4-[9.5,10.3): 1.0601 - val_ca4-[10.3,11.3): 0.9093 - val_ca4-[11.3,14.9): 0.6727\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5055 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3580 - ca2-[9.5,10.3): 0.4535 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4647 - ca3-[10.3,11.3): 0.6122 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5471 - ca4-[11.3,14.9): 0.6647 - val_ca1-[8.0,9.5): 0.5709 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9284 - val_ca1-[11.3,14.9): 1.6435 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3857 - val_ca2-[10.3,11.3): 0.7789 - val_ca2-[11.3,14.9): 1.3428 - val_ca3-[8.0,9.5): 0.7997 - val_ca3-[9.5,10.3): 0.4836 - val_ca3-[10.3,11.3): 0.6422 - val_ca3-[11.3,14.9): 0.8335 - val_ca4-[8.0,9.5): 1.5311 - val_ca4-[9.5,10.3): 1.0636 - val_ca4-[10.3,11.3): 0.8945 - val_ca4-[11.3,14.9): 0.6369\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5057 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3562 - ca2-[9.5,10.3): 0.4587 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4734 - ca3-[10.3,11.3): 0.6275 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5324 - ca4-[11.3,14.9): 0.6693 - val_ca1-[8.0,9.5): 0.5706 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9425 - val_ca1-[11.3,14.9): 1.5966 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.3852 - val_ca2-[10.3,11.3): 0.7821 - val_ca2-[11.3,14.9): 1.2905 - val_ca3-[8.0,9.5): 0.7955 - val_ca3-[9.5,10.3): 0.4805 - val_ca3-[10.3,11.3): 0.6494 - val_ca3-[11.3,14.9): 0.8247 - val_ca4-[8.0,9.5): 1.5340 - val_ca4-[9.5,10.3): 1.0649 - val_ca4-[10.3,11.3): 0.9045 - val_ca4-[11.3,14.9): 0.6574\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5133 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3537 - ca2-[9.5,10.3): 0.4578 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4738 - ca3-[10.3,11.3): 0.6267 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4877 - ca4-[11.3,14.9): 0.6579 - val_ca1-[8.0,9.5): 0.5701 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9452 - val_ca1-[11.3,14.9): 1.6430 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.3862 - val_ca2-[10.3,11.3): 0.7921 - val_ca2-[11.3,14.9): 1.3525 - val_ca3-[8.0,9.5): 0.8003 - val_ca3-[9.5,10.3): 0.4837 - val_ca3-[10.3,11.3): 0.6497 - val_ca3-[11.3,14.9): 0.8379 - val_ca4-[8.0,9.5): 1.5317 - val_ca4-[9.5,10.3): 1.0621 - val_ca4-[10.3,11.3): 0.9021 - val_ca4-[11.3,14.9): 0.6559\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5035 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3562 - ca2-[9.5,10.3): 0.4484 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4781 - ca3-[10.3,11.3): 0.6304 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5247 - ca4-[11.3,14.9): 0.6547 - val_ca1-[8.0,9.5): 0.5696 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9515 - val_ca1-[11.3,14.9): 1.6762 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3854 - val_ca2-[10.3,11.3): 0.7918 - val_ca2-[11.3,14.9): 1.3683 - val_ca3-[8.0,9.5): 0.7867 - val_ca3-[9.5,10.3): 0.4756 - val_ca3-[10.3,11.3): 0.6525 - val_ca3-[11.3,14.9): 0.8692 - val_ca4-[8.0,9.5): 1.5336 - val_ca4-[9.5,10.3): 1.0628 - val_ca4-[10.3,11.3): 0.9024 - val_ca4-[11.3,14.9): 0.6788\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.4996 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3607 - ca2-[9.5,10.3): 0.4549 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4875 - ca3-[10.3,11.3): 0.6257 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5300 - ca4-[11.3,14.9): 0.6695 - val_ca1-[8.0,9.5): 0.5690 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9491 - val_ca1-[11.3,14.9): 1.6340 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3861 - val_ca2-[10.3,11.3): 0.7942 - val_ca2-[11.3,14.9): 1.3424 - val_ca3-[8.0,9.5): 0.7842 - val_ca3-[9.5,10.3): 0.4740 - val_ca3-[10.3,11.3): 0.6491 - val_ca3-[11.3,14.9): 0.8361 - val_ca4-[8.0,9.5): 1.5368 - val_ca4-[9.5,10.3): 1.0650 - val_ca4-[10.3,11.3): 0.9027 - val_ca4-[11.3,14.9): 0.6439\n",
      "Epoch 289/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5109 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3621 - ca2-[9.5,10.3): 0.4639 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4868 - ca3-[10.3,11.3): 0.6095 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5246 - ca4-[11.3,14.9): 0.6555 - val_ca1-[8.0,9.5): 0.5692 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9532 - val_ca1-[11.3,14.9): 1.6738 - val_ca2-[8.0,9.5): 0.5840 - val_ca2-[9.5,10.3): 0.3874 - val_ca2-[10.3,11.3): 0.7981 - val_ca2-[11.3,14.9): 1.3815 - val_ca3-[8.0,9.5): 0.7872 - val_ca3-[9.5,10.3): 0.4761 - val_ca3-[10.3,11.3): 0.6504 - val_ca3-[11.3,14.9): 0.8636 - val_ca4-[8.0,9.5): 1.5421 - val_ca4-[9.5,10.3): 1.0683 - val_ca4-[10.3,11.3): 0.9046 - val_ca4-[11.3,14.9): 0.6716\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5028 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3545 - ca2-[9.5,10.3): 0.4460 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4546 - ca3-[10.3,11.3): 0.6094 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5199 - ca4-[11.3,14.9): 0.6520 - val_ca1-[8.0,9.5): 0.5680 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9548 - val_ca1-[11.3,14.9): 1.7001 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.3844 - val_ca2-[10.3,11.3): 0.7812 - val_ca2-[11.3,14.9): 1.3577 - val_ca3-[8.0,9.5): 0.7806 - val_ca3-[9.5,10.3): 0.4716 - val_ca3-[10.3,11.3): 0.6501 - val_ca3-[11.3,14.9): 0.8779 - val_ca4-[8.0,9.5): 1.5388 - val_ca4-[9.5,10.3): 1.0646 - val_ca4-[10.3,11.3): 0.9037 - val_ca4-[11.3,14.9): 0.6785\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.4997 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3505 - ca2-[9.5,10.3): 0.4561 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4622 - ca3-[10.3,11.3): 0.6145 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5299 - ca4-[11.3,14.9): 0.6492 - val_ca1-[8.0,9.5): 0.5676 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9553 - val_ca1-[11.3,14.9): 1.6341 - val_ca2-[8.0,9.5): 0.5838 - val_ca2-[9.5,10.3): 0.3855 - val_ca2-[10.3,11.3): 0.7928 - val_ca2-[11.3,14.9): 1.3322 - val_ca3-[8.0,9.5): 0.7860 - val_ca3-[9.5,10.3): 0.4747 - val_ca3-[10.3,11.3): 0.6499 - val_ca3-[11.3,14.9): 0.8334 - val_ca4-[8.0,9.5): 1.5343 - val_ca4-[9.5,10.3): 1.0597 - val_ca4-[10.3,11.3): 0.8995 - val_ca4-[11.3,14.9): 0.6594\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.4959 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3413 - ca2-[9.5,10.3): 0.4475 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4661 - ca3-[10.3,11.3): 0.6225 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5328 - ca4-[11.3,14.9): 0.6521 - val_ca1-[8.0,9.5): 0.5674 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9437 - val_ca1-[11.3,14.9): 1.5953 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.3845 - val_ca2-[10.3,11.3): 0.7747 - val_ca2-[11.3,14.9): 1.2701 - val_ca3-[8.0,9.5): 0.7858 - val_ca3-[9.5,10.3): 0.4750 - val_ca3-[10.3,11.3): 0.6471 - val_ca3-[11.3,14.9): 0.8100 - val_ca4-[8.0,9.5): 1.5456 - val_ca4-[9.5,10.3): 1.0691 - val_ca4-[10.3,11.3): 0.9064 - val_ca4-[11.3,14.9): 0.6431\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5012 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3456 - ca2-[9.5,10.3): 0.4417 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4911 - ca3-[10.3,11.3): 0.6112 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5235 - ca4-[11.3,14.9): 0.6504 - val_ca1-[8.0,9.5): 0.5669 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9460 - val_ca1-[11.3,14.9): 1.6462 - val_ca2-[8.0,9.5): 0.5837 - val_ca2-[9.5,10.3): 0.3854 - val_ca2-[10.3,11.3): 0.7853 - val_ca2-[11.3,14.9): 1.3439 - val_ca3-[8.0,9.5): 0.7678 - val_ca3-[9.5,10.3): 0.4635 - val_ca3-[10.3,11.3): 0.6448 - val_ca3-[11.3,14.9): 0.8578 - val_ca4-[8.0,9.5): 1.5461 - val_ca4-[9.5,10.3): 1.0680 - val_ca4-[10.3,11.3): 0.9049 - val_ca4-[11.3,14.9): 0.6663\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.4944 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3476 - ca2-[9.5,10.3): 0.4418 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4702 - ca3-[10.3,11.3): 0.6314 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5108 - ca4-[11.3,14.9): 0.6687 - val_ca1-[8.0,9.5): 0.5664 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9564 - val_ca1-[11.3,14.9): 1.6750 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3847 - val_ca2-[10.3,11.3): 0.7849 - val_ca2-[11.3,14.9): 1.3307 - val_ca3-[8.0,9.5): 0.7679 - val_ca3-[9.5,10.3): 0.4641 - val_ca3-[10.3,11.3): 0.6461 - val_ca3-[11.3,14.9): 0.8483 - val_ca4-[8.0,9.5): 1.5399 - val_ca4-[9.5,10.3): 1.0606 - val_ca4-[10.3,11.3): 0.8961 - val_ca4-[11.3,14.9): 0.6565\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5002 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3564 - ca2-[9.5,10.3): 0.4476 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4696 - ca3-[10.3,11.3): 0.6196 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5033 - ca4-[11.3,14.9): 0.6352 - val_ca1-[8.0,9.5): 0.5662 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9581 - val_ca1-[11.3,14.9): 1.7013 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.3837 - val_ca2-[10.3,11.3): 0.7796 - val_ca2-[11.3,14.9): 1.3485 - val_ca3-[8.0,9.5): 0.7989 - val_ca3-[9.5,10.3): 0.4846 - val_ca3-[10.3,11.3): 0.6488 - val_ca3-[11.3,14.9): 0.8436 - val_ca4-[8.0,9.5): 1.5423 - val_ca4-[9.5,10.3): 1.0617 - val_ca4-[10.3,11.3): 0.8980 - val_ca4-[11.3,14.9): 0.6642\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.4967 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3492 - ca2-[9.5,10.3): 0.4378 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4794 - ca3-[10.3,11.3): 0.6187 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4977 - ca4-[11.3,14.9): 0.6548 - val_ca1-[8.0,9.5): 0.5653 - val_ca1-[9.5,10.3): 0.4226 - val_ca1-[10.3,11.3): 0.9585 - val_ca1-[11.3,14.9): 1.7049 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3836 - val_ca2-[10.3,11.3): 0.7809 - val_ca2-[11.3,14.9): 1.3499 - val_ca3-[8.0,9.5): 0.7586 - val_ca3-[9.5,10.3): 0.4593 - val_ca3-[10.3,11.3): 0.6409 - val_ca3-[11.3,14.9): 0.8661 - val_ca4-[8.0,9.5): 1.5566 - val_ca4-[9.5,10.3): 1.0752 - val_ca4-[10.3,11.3): 0.8922 - val_ca4-[11.3,14.9): 0.6331\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.4970 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3544 - ca2-[9.5,10.3): 0.4362 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4562 - ca3-[10.3,11.3): 0.6087 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5115 - ca4-[11.3,14.9): 0.6490 - val_ca1-[8.0,9.5): 0.5649 - val_ca1-[9.5,10.3): 0.4228 - val_ca1-[10.3,11.3): 0.9628 - val_ca1-[11.3,14.9): 1.6929 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3841 - val_ca2-[10.3,11.3): 0.7867 - val_ca2-[11.3,14.9): 1.3536 - val_ca3-[8.0,9.5): 0.7925 - val_ca3-[9.5,10.3): 0.4818 - val_ca3-[10.3,11.3): 0.6455 - val_ca3-[11.3,14.9): 0.8321 - val_ca4-[8.0,9.5): 1.5458 - val_ca4-[9.5,10.3): 1.0637 - val_ca4-[10.3,11.3): 0.8955 - val_ca4-[11.3,14.9): 0.6506\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.4874 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3440 - ca2-[9.5,10.3): 0.4453 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4639 - ca3-[10.3,11.3): 0.6245 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5506 - ca4-[11.3,14.9): 0.6567 - val_ca1-[8.0,9.5): 0.5643 - val_ca1-[9.5,10.3): 0.4228 - val_ca1-[10.3,11.3): 0.9598 - val_ca1-[11.3,14.9): 1.7268 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3837 - val_ca2-[10.3,11.3): 0.7796 - val_ca2-[11.3,14.9): 1.3685 - val_ca3-[8.0,9.5): 0.7650 - val_ca3-[9.5,10.3): 0.4646 - val_ca3-[10.3,11.3): 0.6440 - val_ca3-[11.3,14.9): 0.8814 - val_ca4-[8.0,9.5): 1.5470 - val_ca4-[9.5,10.3): 1.0635 - val_ca4-[10.3,11.3): 0.8966 - val_ca4-[11.3,14.9): 0.6822\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5042 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3491 - ca2-[9.5,10.3): 0.4514 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4517 - ca3-[10.3,11.3): 0.6253 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5646 - ca4-[11.3,14.9): 0.6604 - val_ca1-[8.0,9.5): 0.5640 - val_ca1-[9.5,10.3): 0.4225 - val_ca1-[10.3,11.3): 0.9664 - val_ca1-[11.3,14.9): 1.6601 - val_ca2-[8.0,9.5): 0.5898 - val_ca2-[9.5,10.3): 0.3831 - val_ca2-[10.3,11.3): 0.7755 - val_ca2-[11.3,14.9): 1.2950 - val_ca3-[8.0,9.5): 0.7736 - val_ca3-[9.5,10.3): 0.4705 - val_ca3-[10.3,11.3): 0.6460 - val_ca3-[11.3,14.9): 0.8269 - val_ca4-[8.0,9.5): 1.5536 - val_ca4-[9.5,10.3): 1.0688 - val_ca4-[10.3,11.3): 0.8995 - val_ca4-[11.3,14.9): 0.6498\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5034 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3551 - ca2-[9.5,10.3): 0.4472 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4658 - ca3-[10.3,11.3): 0.6200 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5127 - ca4-[11.3,14.9): 0.6662 - val_ca1-[8.0,9.5): 0.5633 - val_ca1-[9.5,10.3): 0.4231 - val_ca1-[10.3,11.3): 0.9675 - val_ca1-[11.3,14.9): 1.6857 - val_ca2-[8.0,9.5): 0.5818 - val_ca2-[9.5,10.3): 0.3838 - val_ca2-[10.3,11.3): 0.7886 - val_ca2-[11.3,14.9): 1.3413 - val_ca3-[8.0,9.5): 0.7490 - val_ca3-[9.5,10.3): 0.4536 - val_ca3-[10.3,11.3): 0.6468 - val_ca3-[11.3,14.9): 0.8700 - val_ca4-[8.0,9.5): 1.5450 - val_ca4-[9.5,10.3): 1.0595 - val_ca4-[10.3,11.3): 0.8974 - val_ca4-[11.3,14.9): 0.6611\n",
      "CPU times: user 4min 53s, sys: 3.43 s, total: 4min 56s\n",
      "Wall time: 4min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('simple_add')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2})') for ca,(q1,q2) in product(range(4),zip(quants[:-1],quants[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "\n",
    "history = m.fit(\n",
    "    train_dataset,\n",
    "#     validation_split=0.2,\n",
    "    epochs=300,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "# with open(os.path.join(fp_local,'no_sharing.pickle'), 'wb') as handle:\n",
    "#     pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "for k in [k for k in history.history if 'val_ca1' in k]:\n",
    "    plt.plot(history.history[k][10:], label=k.split('-')[1])\n",
    "\n",
    "plt.plot(history.history['ca1-[8.0,9.5)'][10:],label='train')\n",
    "\n",
    "plt.legend()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in [k for k in history.history if 'val' not in k and 'ca1' in k]:\n",
    "    plt.plot(history.history[k][10:], label=k.split('-')[1])\n",
    "        \n",
    "plt.legend()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ca1-[8.0,9.5)</th>\n",
       "      <td>0.509308</td>\n",
       "      <td>0.563342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[9.5,10.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.423059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[10.3,11.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.967541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.685692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[8.0,9.5)</th>\n",
       "      <td>0.351837</td>\n",
       "      <td>0.581817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[9.5,10.3)</th>\n",
       "      <td>0.436321</td>\n",
       "      <td>0.383779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[10.3,11.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.788647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.341298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[8.0,9.5)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.749019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[9.5,10.3)</th>\n",
       "      <td>0.51047</td>\n",
       "      <td>0.453644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[10.3,11.3)</th>\n",
       "      <td>0.604297</td>\n",
       "      <td>0.646764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.869974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[8.0,9.5)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[9.5,10.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.059486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[10.3,11.3)</th>\n",
       "      <td>0.520998</td>\n",
       "      <td>0.897389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[11.3,14.9)</th>\n",
       "      <td>0.674339</td>\n",
       "      <td>0.661148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train      test\n",
       "ca1-[8.0,9.5)    0.509308  0.563342\n",
       "ca1-[9.5,10.3)          -  0.423059\n",
       "ca1-[10.3,11.3)         -  0.967541\n",
       "ca1-[11.3,14.9)         -  1.685692\n",
       "ca2-[8.0,9.5)    0.351837  0.581817\n",
       "ca2-[9.5,10.3)   0.436321  0.383779\n",
       "ca2-[10.3,11.3)         -  0.788647\n",
       "ca2-[11.3,14.9)         -  1.341298\n",
       "ca3-[8.0,9.5)           -  0.749019\n",
       "ca3-[9.5,10.3)    0.51047  0.453644\n",
       "ca3-[10.3,11.3)  0.604297  0.646764\n",
       "ca3-[11.3,14.9)         -  0.869974\n",
       "ca4-[8.0,9.5)           -  1.545000\n",
       "ca4-[9.5,10.3)          -  1.059486\n",
       "ca4-[10.3,11.3)  0.520998  0.897389\n",
       "ca4-[11.3,14.9)  0.674339  0.661148"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data=[[history.history[k][-1] if history.history[k][-1]!=0 else '-',history.history['val_'+k][-1]] for k in history.history if 'val' not in k],\n",
    "    index=[k for k in history.history if 'val' not in k],\n",
    "    columns=['train','test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 35.1123 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 25.0163 - ca2-[9.5,10.3): 26.0136 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 26.6120 - ca3-[10.3,11.3): 29.7198 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 33.9841 - ca4-[11.3,14.9): 36.5683 - val_ca1-[8.0,9.5): 31.5935 - val_ca1-[9.5,10.3): 33.0565 - val_ca1-[10.3,11.3): 37.4844 - val_ca1-[11.3,14.9): 43.8105 - val_ca2-[8.0,9.5): 22.6139 - val_ca2-[9.5,10.3): 23.7827 - val_ca2-[10.3,11.3): 27.6040 - val_ca2-[11.3,14.9): 33.0506 - val_ca3-[8.0,9.5): 21.5493 - val_ca3-[9.5,10.3): 22.7013 - val_ca3-[10.3,11.3): 26.4467 - val_ca3-[11.3,14.9): 31.7575 - val_ca4-[8.0,9.5): 23.0323 - val_ca4-[9.5,10.3): 24.2380 - val_ca4-[10.3,11.3): 28.0444 - val_ca4-[11.3,14.9): 33.4818\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 153ms/step - ca1-[8.0,9.5): 31.1776 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 21.7733 - ca2-[9.5,10.3): 22.7621 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 23.1198 - ca3-[10.3,11.3): 25.7265 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 29.4482 - ca4-[11.3,14.9): 32.4347 - val_ca1-[8.0,9.5): 27.8576 - val_ca1-[9.5,10.3): 29.2098 - val_ca1-[10.3,11.3): 33.2726 - val_ca1-[11.3,14.9): 39.4272 - val_ca2-[8.0,9.5): 19.7096 - val_ca2-[9.5,10.3): 20.7931 - val_ca2-[10.3,11.3): 24.2785 - val_ca2-[11.3,14.9): 29.5436 - val_ca3-[8.0,9.5): 18.1326 - val_ca3-[9.5,10.3): 19.1858 - val_ca3-[10.3,11.3): 22.5632 - val_ca3-[11.3,14.9): 27.6207 - val_ca4-[8.0,9.5): 19.9747 - val_ca4-[9.5,10.3): 21.0668 - val_ca4-[10.3,11.3): 24.5281 - val_ca4-[11.3,14.9): 29.7708\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 27.5578 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 18.8777 - ca2-[9.5,10.3): 19.8079 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 19.6818 - ca3-[10.3,11.3): 22.0109 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 26.0838 - ca4-[11.3,14.9): 28.8219 - val_ca1-[8.0,9.5): 24.5025 - val_ca1-[9.5,10.3): 25.7633 - val_ca1-[10.3,11.3): 29.7119 - val_ca1-[11.3,14.9): 35.5435 - val_ca2-[8.0,9.5): 17.0932 - val_ca2-[9.5,10.3): 18.1059 - val_ca2-[10.3,11.3): 21.4638 - val_ca2-[11.3,14.9): 26.4207 - val_ca3-[8.0,9.5): 15.0913 - val_ca3-[9.5,10.3): 16.0492 - val_ca3-[10.3,11.3): 19.2495 - val_ca3-[11.3,14.9): 23.9318 - val_ca4-[8.0,9.5): 17.3974 - val_ca4-[9.5,10.3): 18.3976 - val_ca4-[10.3,11.3): 21.7498 - val_ca4-[11.3,14.9): 26.7018\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 24.2374 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 16.5358 - ca2-[9.5,10.3): 17.3135 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 16.2057 - ca3-[10.3,11.3): 18.6462 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 23.4418 - ca4-[11.3,14.9): 25.9330 - val_ca1-[8.0,9.5): 21.6320 - val_ca1-[9.5,10.3): 22.8049 - val_ca1-[10.3,11.3): 26.6081 - val_ca1-[11.3,14.9): 32.1059 - val_ca2-[8.0,9.5): 14.7568 - val_ca2-[9.5,10.3): 15.6988 - val_ca2-[10.3,11.3): 18.9099 - val_ca2-[11.3,14.9): 23.5486 - val_ca3-[8.0,9.5): 12.4417 - val_ca3-[9.5,10.3): 13.3106 - val_ca3-[10.3,11.3): 16.3259 - val_ca3-[11.3,14.9): 20.6429 - val_ca4-[8.0,9.5): 15.2665 - val_ca4-[9.5,10.3): 16.1846 - val_ca4-[10.3,11.3): 19.4136 - val_ca4-[11.3,14.9): 24.0876\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 21.4996 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 14.1720 - ca2-[9.5,10.3): 14.8951 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 13.5260 - ca3-[10.3,11.3): 15.7176 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 21.2897 - ca4-[11.3,14.9): 23.3300 - val_ca1-[8.0,9.5): 19.1847 - val_ca1-[9.5,10.3): 20.2662 - val_ca1-[10.3,11.3): 23.8159 - val_ca1-[11.3,14.9): 28.7684 - val_ca2-[8.0,9.5): 12.7165 - val_ca2-[9.5,10.3): 13.5847 - val_ca2-[10.3,11.3): 16.5576 - val_ca2-[11.3,14.9): 20.6909 - val_ca3-[8.0,9.5): 10.2005 - val_ca3-[9.5,10.3): 10.9627 - val_ca3-[10.3,11.3): 13.6967 - val_ca3-[11.3,14.9): 17.4653 - val_ca4-[8.0,9.5): 13.4596 - val_ca4-[9.5,10.3): 14.2994 - val_ca4-[10.3,11.3): 17.3076 - val_ca4-[11.3,14.9): 21.5135\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 19.0414 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 12.0876 - ca2-[9.5,10.3): 12.9221 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 11.2958 - ca3-[10.3,11.3): 13.2561 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 19.1989 - ca4-[11.3,14.9): 21.0162 - val_ca1-[8.0,9.5): 17.0692 - val_ca1-[9.5,10.3): 18.0627 - val_ca1-[10.3,11.3): 21.3982 - val_ca1-[11.3,14.9): 26.1162 - val_ca2-[8.0,9.5): 10.9711 - val_ca2-[9.5,10.3): 11.7642 - val_ca2-[10.3,11.3): 14.5301 - val_ca2-[11.3,14.9): 18.4268 - val_ca3-[8.0,9.5): 8.3984 - val_ca3-[9.5,10.3): 9.0607 - val_ca3-[10.3,11.3): 11.5316 - val_ca3-[11.3,14.9): 14.9966 - val_ca4-[8.0,9.5): 11.8599 - val_ca4-[9.5,10.3): 12.6411 - val_ca4-[10.3,11.3): 15.4568 - val_ca4-[11.3,14.9): 19.4639\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 16.9665 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 10.5970 - ca2-[9.5,10.3): 11.2273 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 9.2292 - ca3-[10.3,11.3): 11.2708 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 17.2101 - ca4-[11.3,14.9): 18.9982 - val_ca1-[8.0,9.5): 15.2750 - val_ca1-[9.5,10.3): 16.2119 - val_ca1-[10.3,11.3): 19.4182 - val_ca1-[11.3,14.9): 23.9005 - val_ca2-[8.0,9.5): 9.5120 - val_ca2-[9.5,10.3): 10.2331 - val_ca2-[10.3,11.3): 12.8539 - val_ca2-[11.3,14.9): 16.5050 - val_ca3-[8.0,9.5): 6.9626 - val_ca3-[9.5,10.3): 7.5448 - val_ca3-[10.3,11.3): 9.8444 - val_ca3-[11.3,14.9): 13.0376 - val_ca4-[8.0,9.5): 10.4507 - val_ca4-[9.5,10.3): 11.1861 - val_ca4-[10.3,11.3): 13.8862 - val_ca4-[11.3,14.9): 17.6819\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 15.2805 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 9.1543 - ca2-[9.5,10.3): 9.8522 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 7.8681 - ca3-[10.3,11.3): 9.5202 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 15.5349 - ca4-[11.3,14.9): 17.2392 - val_ca1-[8.0,9.5): 13.7956 - val_ca1-[9.5,10.3): 14.6842 - val_ca1-[10.3,11.3): 17.7854 - val_ca1-[11.3,14.9): 22.2266 - val_ca2-[8.0,9.5): 8.2929 - val_ca2-[9.5,10.3): 8.9513 - val_ca2-[10.3,11.3): 11.4457 - val_ca2-[11.3,14.9): 15.0139 - val_ca3-[8.0,9.5): 5.8118 - val_ca3-[9.5,10.3): 6.3260 - val_ca3-[10.3,11.3): 8.4792 - val_ca3-[11.3,14.9): 11.5477 - val_ca4-[8.0,9.5): 9.2627 - val_ca4-[9.5,10.3): 9.9524 - val_ca4-[10.3,11.3): 12.5504 - val_ca4-[11.3,14.9): 16.2872\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 150ms/step - ca1-[8.0,9.5): 13.7535 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 7.9808 - ca2-[9.5,10.3): 8.6186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 6.7979 - ca3-[10.3,11.3): 8.2507 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 14.1647 - ca4-[11.3,14.9): 15.7672 - val_ca1-[8.0,9.5): 12.5473 - val_ca1-[9.5,10.3): 13.3953 - val_ca1-[10.3,11.3): 16.3033 - val_ca1-[11.3,14.9): 20.6629 - val_ca2-[8.0,9.5): 7.2633 - val_ca2-[9.5,10.3): 7.8647 - val_ca2-[10.3,11.3): 10.1625 - val_ca2-[11.3,14.9): 13.6105 - val_ca3-[8.0,9.5): 4.8804 - val_ca3-[9.5,10.3): 5.3291 - val_ca3-[10.3,11.3): 7.2726 - val_ca3-[11.3,14.9): 10.1854 - val_ca4-[8.0,9.5): 8.2412 - val_ca4-[9.5,10.3): 8.8901 - val_ca4-[10.3,11.3): 11.3036 - val_ca4-[11.3,14.9): 14.9386\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 12.5288 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 6.9741 - ca2-[9.5,10.3): 7.5220 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 5.5812 - ca3-[10.3,11.3): 7.0655 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 12.6786 - ca4-[11.3,14.9): 14.5147 - val_ca1-[8.0,9.5): 11.5089 - val_ca1-[9.5,10.3): 12.3165 - val_ca1-[10.3,11.3): 15.1677 - val_ca1-[11.3,14.9): 19.1870 - val_ca2-[8.0,9.5): 6.3852 - val_ca2-[9.5,10.3): 6.9383 - val_ca2-[10.3,11.3): 9.1576 - val_ca2-[11.3,14.9): 12.2732 - val_ca3-[8.0,9.5): 4.1024 - val_ca3-[9.5,10.3): 4.4951 - val_ca3-[10.3,11.3): 6.3374 - val_ca3-[11.3,14.9): 8.9142 - val_ca4-[8.0,9.5): 7.3628 - val_ca4-[9.5,10.3): 7.9719 - val_ca4-[10.3,11.3): 10.3200 - val_ca4-[11.3,14.9): 13.6284\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 11.5990 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 6.0051 - ca2-[9.5,10.3): 6.6160 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 4.8413 - ca3-[10.3,11.3): 6.1863 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 11.8350 - ca4-[11.3,14.9): 13.3720 - val_ca1-[8.0,9.5): 10.5984 - val_ca1-[9.5,10.3): 11.3675 - val_ca1-[10.3,11.3): 14.1285 - val_ca1-[11.3,14.9): 18.0965 - val_ca2-[8.0,9.5): 5.6438 - val_ca2-[9.5,10.3): 6.1530 - val_ca2-[10.3,11.3): 8.2703 - val_ca2-[11.3,14.9): 11.3023 - val_ca3-[8.0,9.5): 3.4664 - val_ca3-[9.5,10.3): 3.8081 - val_ca3-[10.3,11.3): 5.5336 - val_ca3-[11.3,14.9): 8.0028 - val_ca4-[8.0,9.5): 6.6013 - val_ca4-[9.5,10.3): 7.1670 - val_ca4-[10.3,11.3): 9.4199 - val_ca4-[11.3,14.9): 12.6562\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 10.6587 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 5.3179 - ca2-[9.5,10.3): 5.9368 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 4.1232 - ca3-[10.3,11.3): 5.3943 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 10.6443 - ca4-[11.3,14.9): 12.3342 - val_ca1-[8.0,9.5): 9.8197 - val_ca1-[9.5,10.3): 10.5501 - val_ca1-[10.3,11.3): 13.1929 - val_ca1-[11.3,14.9): 16.9261 - val_ca2-[8.0,9.5): 5.0269 - val_ca2-[9.5,10.3): 5.4927 - val_ca2-[10.3,11.3): 7.4918 - val_ca2-[11.3,14.9): 10.2972 - val_ca3-[8.0,9.5): 2.9437 - val_ca3-[9.5,10.3): 3.2392 - val_ca3-[10.3,11.3): 4.8369 - val_ca3-[11.3,14.9): 7.0732 - val_ca4-[8.0,9.5): 5.9310 - val_ca4-[9.5,10.3): 6.4541 - val_ca4-[10.3,11.3): 8.5907 - val_ca4-[11.3,14.9): 11.5978\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 9.8766 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 4.7727 - ca2-[9.5,10.3): 5.2622 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 3.5117 - ca3-[10.3,11.3): 4.7739 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 9.9282 - ca4-[11.3,14.9): 11.3751 - val_ca1-[8.0,9.5): 9.1334 - val_ca1-[9.5,10.3): 9.8299 - val_ca1-[10.3,11.3): 12.3891 - val_ca1-[11.3,14.9): 16.1400 - val_ca2-[8.0,9.5): 4.4890 - val_ca2-[9.5,10.3): 4.9164 - val_ca2-[10.3,11.3): 6.8242 - val_ca2-[11.3,14.9): 9.6029 - val_ca3-[8.0,9.5): 2.5086 - val_ca3-[9.5,10.3): 2.7632 - val_ca3-[10.3,11.3): 4.2602 - val_ca3-[11.3,14.9): 6.4367 - val_ca4-[8.0,9.5): 5.3385 - val_ca4-[9.5,10.3): 5.8232 - val_ca4-[10.3,11.3): 7.8716 - val_ca4-[11.3,14.9): 10.8600\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 9.2400 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 4.3393 - ca2-[9.5,10.3): 4.7428 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 3.0876 - ca3-[10.3,11.3): 4.2004 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 9.2265 - ca4-[11.3,14.9): 10.6470 - val_ca1-[8.0,9.5): 8.5088 - val_ca1-[9.5,10.3): 9.1757 - val_ca1-[10.3,11.3): 11.6365 - val_ca1-[11.3,14.9): 15.2070 - val_ca2-[8.0,9.5): 4.0088 - val_ca2-[9.5,10.3): 4.4001 - val_ca2-[10.3,11.3): 6.2021 - val_ca2-[11.3,14.9): 8.7993 - val_ca3-[8.0,9.5): 2.1558 - val_ca3-[9.5,10.3): 2.3722 - val_ca3-[10.3,11.3): 3.7604 - val_ca3-[11.3,14.9): 5.7548 - val_ca4-[8.0,9.5): 4.8120 - val_ca4-[9.5,10.3): 5.2612 - val_ca4-[10.3,11.3): 7.2040 - val_ca4-[11.3,14.9): 10.0090\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 8.5545 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 3.7515 - ca2-[9.5,10.3): 4.2552 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.7388 - ca3-[10.3,11.3): 3.7594 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 8.4735 - ca4-[11.3,14.9): 9.7979 - val_ca1-[8.0,9.5): 7.9451 - val_ca1-[9.5,10.3): 8.5830 - val_ca1-[10.3,11.3): 10.9481 - val_ca1-[11.3,14.9): 14.4297 - val_ca2-[8.0,9.5): 3.5773 - val_ca2-[9.5,10.3): 3.9340 - val_ca2-[10.3,11.3): 5.6294 - val_ca2-[11.3,14.9): 8.1176 - val_ca3-[8.0,9.5): 1.8569 - val_ca3-[9.5,10.3): 2.0387 - val_ca3-[10.3,11.3): 3.3208 - val_ca3-[11.3,14.9): 5.1998 - val_ca4-[8.0,9.5): 4.3384 - val_ca4-[9.5,10.3): 4.7536 - val_ca4-[10.3,11.3): 6.5902 - val_ca4-[11.3,14.9): 9.2880\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 151ms/step - ca1-[8.0,9.5): 8.0623 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 3.3025 - ca2-[9.5,10.3): 3.7870 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.2848 - ca3-[10.3,11.3): 3.2812 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 7.9327 - ca4-[11.3,14.9): 9.0876 - val_ca1-[8.0,9.5): 7.4481 - val_ca1-[9.5,10.3): 8.0586 - val_ca1-[10.3,11.3): 10.4378 - val_ca1-[11.3,14.9): 13.9573 - val_ca2-[8.0,9.5): 3.1889 - val_ca2-[9.5,10.3): 3.5119 - val_ca2-[10.3,11.3): 5.1850 - val_ca2-[11.3,14.9): 7.6469 - val_ca3-[8.0,9.5): 1.6142 - val_ca3-[9.5,10.3): 1.7645 - val_ca3-[10.3,11.3): 3.0175 - val_ca3-[11.3,14.9): 4.8517 - val_ca4-[8.0,9.5): 3.9141 - val_ca4-[9.5,10.3): 4.2967 - val_ca4-[10.3,11.3): 6.1171 - val_ca4-[11.3,14.9): 8.8003\n",
      "Epoch 17/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 7.6133 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.9717 - ca2-[9.5,10.3): 3.4421 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.0031 - ca3-[10.3,11.3): 2.9652 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 7.3601 - ca4-[11.3,14.9): 8.4864 - val_ca1-[8.0,9.5): 6.9975 - val_ca1-[9.5,10.3): 7.5833 - val_ca1-[10.3,11.3): 9.9007 - val_ca1-[11.3,14.9): 13.1822 - val_ca2-[8.0,9.5): 2.8390 - val_ca2-[9.5,10.3): 3.1295 - val_ca2-[10.3,11.3): 4.7259 - val_ca2-[11.3,14.9): 6.9658 - val_ca3-[8.0,9.5): 1.4188 - val_ca3-[9.5,10.3): 1.5398 - val_ca3-[10.3,11.3): 2.7246 - val_ca3-[11.3,14.9): 4.3714 - val_ca4-[8.0,9.5): 3.5321 - val_ca4-[9.5,10.3): 3.8836 - val_ca4-[10.3,11.3): 5.6299 - val_ca4-[11.3,14.9): 8.0871\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 7.0404 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.5673 - ca2-[9.5,10.3): 2.9896 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.7985 - ca3-[10.3,11.3): 2.6850 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 6.7384 - ca4-[11.3,14.9): 7.9200 - val_ca1-[8.0,9.5): 6.5836 - val_ca1-[9.5,10.3): 7.1456 - val_ca1-[10.3,11.3): 9.4051 - val_ca1-[11.3,14.9): 12.6072 - val_ca2-[8.0,9.5): 2.5257 - val_ca2-[9.5,10.3): 2.7851 - val_ca2-[10.3,11.3): 4.3041 - val_ca2-[11.3,14.9): 6.4381 - val_ca3-[8.0,9.5): 1.2551 - val_ca3-[9.5,10.3): 1.3493 - val_ca3-[10.3,11.3): 2.4661 - val_ca3-[11.3,14.9): 4.0206 - val_ca4-[8.0,9.5): 3.1865 - val_ca4-[9.5,10.3): 3.5081 - val_ca4-[10.3,11.3): 5.1803 - val_ca4-[11.3,14.9): 7.5363\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 6.6483 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.2800 - ca2-[9.5,10.3): 2.7216 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.6346 - ca3-[10.3,11.3): 2.4487 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 6.4852 - ca4-[11.3,14.9): 7.3967 - val_ca1-[8.0,9.5): 6.2038 - val_ca1-[9.5,10.3): 6.7431 - val_ca1-[10.3,11.3): 8.9257 - val_ca1-[11.3,14.9): 12.1082 - val_ca2-[8.0,9.5): 2.2464 - val_ca2-[9.5,10.3): 2.4757 - val_ca2-[10.3,11.3): 3.9078 - val_ca2-[11.3,14.9): 5.9751 - val_ca3-[8.0,9.5): 1.1204 - val_ca3-[9.5,10.3): 1.1896 - val_ca3-[10.3,11.3): 2.2357 - val_ca3-[11.3,14.9): 3.7302 - val_ca4-[8.0,9.5): 2.8743 - val_ca4-[9.5,10.3): 3.1672 - val_ca4-[10.3,11.3): 4.7539 - val_ca4-[11.3,14.9): 7.0520\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 6.3336 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.9975 - ca2-[9.5,10.3): 2.3831 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.3983 - ca3-[10.3,11.3): 2.2321 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.6296 - ca4-[11.3,14.9): 6.8393 - val_ca1-[8.0,9.5): 5.8497 - val_ca1-[9.5,10.3): 6.3671 - val_ca1-[10.3,11.3): 8.5183 - val_ca1-[11.3,14.9): 11.5391 - val_ca2-[8.0,9.5): 2.0003 - val_ca2-[9.5,10.3): 2.2010 - val_ca2-[10.3,11.3): 3.5786 - val_ca2-[11.3,14.9): 5.4957 - val_ca3-[8.0,9.5): 1.0090 - val_ca3-[9.5,10.3): 1.0551 - val_ca3-[10.3,11.3): 2.0567 - val_ca3-[11.3,14.9): 3.4380 - val_ca4-[8.0,9.5): 2.5918 - val_ca4-[9.5,10.3): 2.8570 - val_ca4-[10.3,11.3): 4.3927 - val_ca4-[11.3,14.9): 6.5362\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 6.0127 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.8138 - ca2-[9.5,10.3): 2.1403 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.1913 - ca3-[10.3,11.3): 2.0540 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.2486 - ca4-[11.3,14.9): 6.3381 - val_ca1-[8.0,9.5): 5.5192 - val_ca1-[9.5,10.3): 6.0155 - val_ca1-[10.3,11.3): 8.1304 - val_ca1-[11.3,14.9): 11.1076 - val_ca2-[8.0,9.5): 1.7854 - val_ca2-[9.5,10.3): 1.9590 - val_ca2-[10.3,11.3): 3.2795 - val_ca2-[11.3,14.9): 5.1227 - val_ca3-[8.0,9.5): 0.9164 - val_ca3-[9.5,10.3): 0.9410 - val_ca3-[10.3,11.3): 1.8959 - val_ca3-[11.3,14.9): 3.2176 - val_ca4-[8.0,9.5): 2.3366 - val_ca4-[9.5,10.3): 2.5751 - val_ca4-[10.3,11.3): 4.0556 - val_ca4-[11.3,14.9): 6.1280\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 5.5158 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.5738 - ca2-[9.5,10.3): 1.9180 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.1362 - ca3-[10.3,11.3): 1.8851 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.8348 - ca4-[11.3,14.9): 5.9724 - val_ca1-[8.0,9.5): 5.2106 - val_ca1-[9.5,10.3): 5.6866 - val_ca1-[10.3,11.3): 7.7311 - val_ca1-[11.3,14.9): 10.6919 - val_ca2-[8.0,9.5): 1.5986 - val_ca2-[9.5,10.3): 1.7466 - val_ca2-[10.3,11.3): 2.9912 - val_ca2-[11.3,14.9): 4.7794 - val_ca3-[8.0,9.5): 0.8398 - val_ca3-[9.5,10.3): 0.8441 - val_ca3-[10.3,11.3): 1.7392 - val_ca3-[11.3,14.9): 3.0155 - val_ca4-[8.0,9.5): 2.1058 - val_ca4-[9.5,10.3): 2.3183 - val_ca4-[10.3,11.3): 3.7205 - val_ca4-[11.3,14.9): 5.7404\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 154ms/step - ca1-[8.0,9.5): 5.2957 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.4129 - ca2-[9.5,10.3): 1.7307 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.0464 - ca3-[10.3,11.3): 1.7228 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.5954 - ca4-[11.3,14.9): 5.5503 - val_ca1-[8.0,9.5): 4.9213 - val_ca1-[9.5,10.3): 5.3778 - val_ca1-[10.3,11.3): 7.3803 - val_ca1-[11.3,14.9): 10.2824 - val_ca2-[8.0,9.5): 1.4372 - val_ca2-[9.5,10.3): 1.5612 - val_ca2-[10.3,11.3): 2.7524 - val_ca2-[11.3,14.9): 4.4629 - val_ca3-[8.0,9.5): 0.7768 - val_ca3-[9.5,10.3): 0.7621 - val_ca3-[10.3,11.3): 1.6159 - val_ca3-[11.3,14.9): 2.8309 - val_ca4-[8.0,9.5): 1.8981 - val_ca4-[9.5,10.3): 2.0856 - val_ca4-[10.3,11.3): 3.4321 - val_ca4-[11.3,14.9): 5.3710\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 5.0291 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.1945 - ca2-[9.5,10.3): 1.5438 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.9491 - ca3-[10.3,11.3): 1.5921 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.0129 - ca4-[11.3,14.9): 5.1997 - val_ca1-[8.0,9.5): 4.6501 - val_ca1-[9.5,10.3): 5.0875 - val_ca1-[10.3,11.3): 7.0432 - val_ca1-[11.3,14.9): 9.7526 - val_ca2-[8.0,9.5): 1.2985 - val_ca2-[9.5,10.3): 1.4001 - val_ca2-[10.3,11.3): 2.5352 - val_ca2-[11.3,14.9): 4.0912 - val_ca3-[8.0,9.5): 0.7257 - val_ca3-[9.5,10.3): 0.6933 - val_ca3-[10.3,11.3): 1.5021 - val_ca3-[11.3,14.9): 2.5997 - val_ca4-[8.0,9.5): 1.7106 - val_ca4-[9.5,10.3): 1.8737 - val_ca4-[10.3,11.3): 3.1596 - val_ca4-[11.3,14.9): 4.9281\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 4.7492 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.0932 - ca2-[9.5,10.3): 1.4067 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.8275 - ca3-[10.3,11.3): 1.5040 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.8520 - ca4-[11.3,14.9): 4.8591 - val_ca1-[8.0,9.5): 4.3960 - val_ca1-[9.5,10.3): 4.8149 - val_ca1-[10.3,11.3): 6.7257 - val_ca1-[11.3,14.9): 9.4184 - val_ca2-[8.0,9.5): 1.1799 - val_ca2-[9.5,10.3): 1.2604 - val_ca2-[10.3,11.3): 2.3442 - val_ca2-[11.3,14.9): 3.8518 - val_ca3-[8.0,9.5): 0.6843 - val_ca3-[9.5,10.3): 0.6350 - val_ca3-[10.3,11.3): 1.4028 - val_ca3-[11.3,14.9): 2.4575 - val_ca4-[8.0,9.5): 1.5431 - val_ca4-[9.5,10.3): 1.6826 - val_ca4-[10.3,11.3): 2.9111 - val_ca4-[11.3,14.9): 4.6263\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 4.4701 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.9387 - ca2-[9.5,10.3): 1.2625 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.8316 - ca3-[10.3,11.3): 1.4224 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.5225 - ca4-[11.3,14.9): 4.4732 - val_ca1-[8.0,9.5): 4.1577 - val_ca1-[9.5,10.3): 4.5588 - val_ca1-[10.3,11.3): 6.3904 - val_ca1-[11.3,14.9): 9.0732 - val_ca2-[8.0,9.5): 1.0787 - val_ca2-[9.5,10.3): 1.1396 - val_ca2-[10.3,11.3): 2.1583 - val_ca2-[11.3,14.9): 3.6267 - val_ca3-[8.0,9.5): 0.6514 - val_ca3-[9.5,10.3): 0.5863 - val_ca3-[10.3,11.3): 1.3048 - val_ca3-[11.3,14.9): 2.3249 - val_ca4-[8.0,9.5): 1.3936 - val_ca4-[9.5,10.3): 1.5104 - val_ca4-[10.3,11.3): 2.6629 - val_ca4-[11.3,14.9): 4.3316\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 4.2487 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.8499 - ca2-[9.5,10.3): 1.1480 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.7483 - ca3-[10.3,11.3): 1.2888 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.3049 - ca4-[11.3,14.9): 4.2236 - val_ca1-[8.0,9.5): 3.9337 - val_ca1-[9.5,10.3): 4.3176 - val_ca1-[10.3,11.3): 6.1438 - val_ca1-[11.3,14.9): 8.7543 - val_ca2-[8.0,9.5): 0.9930 - val_ca2-[9.5,10.3): 1.0355 - val_ca2-[10.3,11.3): 2.0299 - val_ca2-[11.3,14.9): 3.4316 - val_ca3-[8.0,9.5): 0.6262 - val_ca3-[9.5,10.3): 0.5461 - val_ca3-[10.3,11.3): 1.2423 - val_ca3-[11.3,14.9): 2.2111 - val_ca4-[8.0,9.5): 1.2607 - val_ca4-[9.5,10.3): 1.3554 - val_ca4-[10.3,11.3): 2.4769 - val_ca4-[11.3,14.9): 4.0639\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 4.0259 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.7980 - ca2-[9.5,10.3): 1.0672 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6990 - ca3-[10.3,11.3): 1.2122 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.0810 - ca4-[11.3,14.9): 3.9026 - val_ca1-[8.0,9.5): 3.7224 - val_ca1-[9.5,10.3): 4.0895 - val_ca1-[10.3,11.3): 5.8927 - val_ca1-[11.3,14.9): 8.4279 - val_ca2-[8.0,9.5): 0.9195 - val_ca2-[9.5,10.3): 0.9448 - val_ca2-[10.3,11.3): 1.9012 - val_ca2-[11.3,14.9): 3.2283 - val_ca3-[8.0,9.5): 0.6074 - val_ca3-[9.5,10.3): 0.5134 - val_ca3-[10.3,11.3): 1.1745 - val_ca3-[11.3,14.9): 2.0808 - val_ca4-[8.0,9.5): 1.1433 - val_ca4-[9.5,10.3): 1.2165 - val_ca4-[10.3,11.3): 2.2919 - val_ca4-[11.3,14.9): 3.7892\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 3.7857 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.7169 - ca2-[9.5,10.3): 0.9641 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6185 - ca3-[10.3,11.3): 1.1412 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.8203 - ca4-[11.3,14.9): 3.6529 - val_ca1-[8.0,9.5): 3.5238 - val_ca1-[9.5,10.3): 3.8745 - val_ca1-[10.3,11.3): 5.6357 - val_ca1-[11.3,14.9): 8.0893 - val_ca2-[8.0,9.5): 0.8574 - val_ca2-[9.5,10.3): 0.8667 - val_ca2-[10.3,11.3): 1.7802 - val_ca2-[11.3,14.9): 3.0376 - val_ca3-[8.0,9.5): 0.5939 - val_ca3-[9.5,10.3): 0.4867 - val_ca3-[10.3,11.3): 1.1115 - val_ca3-[11.3,14.9): 1.9618 - val_ca4-[8.0,9.5): 1.0399 - val_ca4-[9.5,10.3): 1.0923 - val_ca4-[10.3,11.3): 2.1133 - val_ca4-[11.3,14.9): 3.5228\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 154ms/step - ca1-[8.0,9.5): 3.5902 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.6510 - ca2-[9.5,10.3): 0.8957 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6214 - ca3-[10.3,11.3): 1.0970 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.6795 - ca4-[11.3,14.9): 3.4550 - val_ca1-[8.0,9.5): 3.3365 - val_ca1-[9.5,10.3): 3.6712 - val_ca1-[10.3,11.3): 5.3762 - val_ca1-[11.3,14.9): 7.7077 - val_ca2-[8.0,9.5): 0.8051 - val_ca2-[9.5,10.3): 0.7993 - val_ca2-[10.3,11.3): 1.6730 - val_ca2-[11.3,14.9): 2.8360 - val_ca3-[8.0,9.5): 0.5851 - val_ca3-[9.5,10.3): 0.4653 - val_ca3-[10.3,11.3): 1.0612 - val_ca3-[11.3,14.9): 1.8338 - val_ca4-[8.0,9.5): 0.9496 - val_ca4-[9.5,10.3): 0.9819 - val_ca4-[10.3,11.3): 1.9487 - val_ca4-[11.3,14.9): 3.2430\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 3.4121 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.6013 - ca2-[9.5,10.3): 0.8324 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5757 - ca3-[10.3,11.3): 1.0498 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.4908 - ca4-[11.3,14.9): 3.2267 - val_ca1-[8.0,9.5): 3.1601 - val_ca1-[9.5,10.3): 3.4793 - val_ca1-[10.3,11.3): 5.1749 - val_ca1-[11.3,14.9): 7.6136 - val_ca2-[8.0,9.5): 0.7614 - val_ca2-[9.5,10.3): 0.7417 - val_ca2-[10.3,11.3): 1.5900 - val_ca2-[11.3,14.9): 2.7867 - val_ca3-[8.0,9.5): 0.5802 - val_ca3-[9.5,10.3): 0.4487 - val_ca3-[10.3,11.3): 1.0179 - val_ca3-[11.3,14.9): 1.8054 - val_ca4-[8.0,9.5): 0.8717 - val_ca4-[9.5,10.3): 0.8846 - val_ca4-[10.3,11.3): 1.8145 - val_ca4-[11.3,14.9): 3.1309\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 3.2609 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.5490 - ca2-[9.5,10.3): 0.7707 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5894 - ca3-[10.3,11.3): 1.0083 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.2560 - ca4-[11.3,14.9): 3.0086 - val_ca1-[8.0,9.5): 2.9941 - val_ca1-[9.5,10.3): 3.2981 - val_ca1-[10.3,11.3): 4.9308 - val_ca1-[11.3,14.9): 7.2328 - val_ca2-[8.0,9.5): 0.7248 - val_ca2-[9.5,10.3): 0.6921 - val_ca2-[10.3,11.3): 1.5051 - val_ca2-[11.3,14.9): 2.6246 - val_ca3-[8.0,9.5): 0.5787 - val_ca3-[9.5,10.3): 0.4360 - val_ca3-[10.3,11.3): 0.9817 - val_ca3-[11.3,14.9): 1.7158 - val_ca4-[8.0,9.5): 0.8050 - val_ca4-[9.5,10.3): 0.7989 - val_ca4-[10.3,11.3): 1.6770 - val_ca4-[11.3,14.9): 2.8906\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 3.0746 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.5175 - ca2-[9.5,10.3): 0.7503 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5426 - ca3-[10.3,11.3): 0.9542 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.2299 - ca4-[11.3,14.9): 2.7964 - val_ca1-[8.0,9.5): 2.8421 - val_ca1-[9.5,10.3): 3.1330 - val_ca1-[10.3,11.3): 4.6513 - val_ca1-[11.3,14.9): 6.9211 - val_ca2-[8.0,9.5): 0.6964 - val_ca2-[9.5,10.3): 0.6517 - val_ca2-[10.3,11.3): 1.3901 - val_ca2-[11.3,14.9): 2.4721 - val_ca3-[8.0,9.5): 0.5811 - val_ca3-[9.5,10.3): 0.4277 - val_ca3-[10.3,11.3): 0.9139 - val_ca3-[11.3,14.9): 1.6117 - val_ca4-[8.0,9.5): 0.7508 - val_ca4-[9.5,10.3): 0.7267 - val_ca4-[10.3,11.3): 1.5132 - val_ca4-[11.3,14.9): 2.6686\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 2.8780 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4421 - ca2-[9.5,10.3): 0.6945 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5468 - ca3-[10.3,11.3): 0.9220 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.0300 - ca4-[11.3,14.9): 2.6302 - val_ca1-[8.0,9.5): 2.6893 - val_ca1-[9.5,10.3): 2.9642 - val_ca1-[10.3,11.3): 4.5233 - val_ca1-[11.3,14.9): 6.7783 - val_ca2-[8.0,9.5): 0.6696 - val_ca2-[9.5,10.3): 0.6136 - val_ca2-[10.3,11.3): 1.3649 - val_ca2-[11.3,14.9): 2.4324 - val_ca3-[8.0,9.5): 0.5836 - val_ca3-[9.5,10.3): 0.4207 - val_ca3-[10.3,11.3): 0.9113 - val_ca3-[11.3,14.9): 1.5958 - val_ca4-[8.0,9.5): 0.7017 - val_ca4-[9.5,10.3): 0.6598 - val_ca4-[10.3,11.3): 1.4454 - val_ca4-[11.3,14.9): 2.5637\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 2.7339 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4808 - ca2-[9.5,10.3): 0.6803 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5083 - ca3-[10.3,11.3): 0.9096 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.8155 - ca4-[11.3,14.9): 2.4463 - val_ca1-[8.0,9.5): 2.5497 - val_ca1-[9.5,10.3): 2.8105 - val_ca1-[10.3,11.3): 4.3214 - val_ca1-[11.3,14.9): 6.4655 - val_ca2-[8.0,9.5): 0.6494 - val_ca2-[9.5,10.3): 0.5832 - val_ca2-[10.3,11.3): 1.3043 - val_ca2-[11.3,14.9): 2.3025 - val_ca3-[8.0,9.5): 0.5891 - val_ca3-[9.5,10.3): 0.4170 - val_ca3-[10.3,11.3): 0.8827 - val_ca3-[11.3,14.9): 1.5105 - val_ca4-[8.0,9.5): 0.6636 - val_ca4-[9.5,10.3): 0.6046 - val_ca4-[10.3,11.3): 1.3432 - val_ca4-[11.3,14.9): 2.3671\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 2.6306 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4475 - ca2-[9.5,10.3): 0.6594 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4929 - ca3-[10.3,11.3): 0.8697 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.5928 - ca4-[11.3,14.9): 2.2944 - val_ca1-[8.0,9.5): 2.4180 - val_ca1-[9.5,10.3): 2.6651 - val_ca1-[10.3,11.3): 4.1429 - val_ca1-[11.3,14.9): 6.2483 - val_ca2-[8.0,9.5): 0.6330 - val_ca2-[9.5,10.3): 0.5573 - val_ca2-[10.3,11.3): 1.2557 - val_ca2-[11.3,14.9): 2.2231 - val_ca3-[8.0,9.5): 0.5961 - val_ca3-[9.5,10.3): 0.4154 - val_ca3-[10.3,11.3): 0.8602 - val_ca3-[11.3,14.9): 1.4575 - val_ca4-[8.0,9.5): 0.6334 - val_ca4-[9.5,10.3): 0.5579 - val_ca4-[10.3,11.3): 1.2566 - val_ca4-[11.3,14.9): 2.2248\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 149ms/step - ca1-[8.0,9.5): 2.4832 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4504 - ca2-[9.5,10.3): 0.6222 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5135 - ca3-[10.3,11.3): 0.8672 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.5087 - ca4-[11.3,14.9): 2.1718 - val_ca1-[8.0,9.5): 2.2938 - val_ca1-[9.5,10.3): 2.5275 - val_ca1-[10.3,11.3): 3.9861 - val_ca1-[11.3,14.9): 6.0284 - val_ca2-[8.0,9.5): 0.6198 - val_ca2-[9.5,10.3): 0.5354 - val_ca2-[10.3,11.3): 1.2175 - val_ca2-[11.3,14.9): 2.1539 - val_ca3-[8.0,9.5): 0.6045 - val_ca3-[9.5,10.3): 0.4155 - val_ca3-[10.3,11.3): 0.8424 - val_ca3-[11.3,14.9): 1.4157 - val_ca4-[8.0,9.5): 0.6105 - val_ca4-[9.5,10.3): 0.5190 - val_ca4-[10.3,11.3): 1.1837 - val_ca4-[11.3,14.9): 2.0957\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 2.3548 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4360 - ca2-[9.5,10.3): 0.6212 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5131 - ca3-[10.3,11.3): 0.8225 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.4452 - ca4-[11.3,14.9): 2.0361 - val_ca1-[8.0,9.5): 2.1766 - val_ca1-[9.5,10.3): 2.3972 - val_ca1-[10.3,11.3): 3.8057 - val_ca1-[11.3,14.9): 5.8309 - val_ca2-[8.0,9.5): 0.6091 - val_ca2-[9.5,10.3): 0.5166 - val_ca2-[10.3,11.3): 1.1698 - val_ca2-[11.3,14.9): 2.0859 - val_ca3-[8.0,9.5): 0.6137 - val_ca3-[9.5,10.3): 0.4171 - val_ca3-[10.3,11.3): 0.8195 - val_ca3-[11.3,14.9): 1.3673 - val_ca4-[8.0,9.5): 0.5943 - val_ca4-[9.5,10.3): 0.4874 - val_ca4-[10.3,11.3): 1.1059 - val_ca4-[11.3,14.9): 1.9713\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 2.2069 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4192 - ca2-[9.5,10.3): 0.5959 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4868 - ca3-[10.3,11.3): 0.8223 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.2662 - ca4-[11.3,14.9): 1.9091 - val_ca1-[8.0,9.5): 2.0662 - val_ca1-[9.5,10.3): 2.2741 - val_ca1-[10.3,11.3): 3.6696 - val_ca1-[11.3,14.9): 5.5726 - val_ca2-[8.0,9.5): 0.6008 - val_ca2-[9.5,10.3): 0.5010 - val_ca2-[10.3,11.3): 1.1452 - val_ca2-[11.3,14.9): 1.9923 - val_ca3-[8.0,9.5): 0.6237 - val_ca3-[9.5,10.3): 0.4199 - val_ca3-[10.3,11.3): 0.8108 - val_ca3-[11.3,14.9): 1.3018 - val_ca4-[8.0,9.5): 0.5841 - val_ca4-[9.5,10.3): 0.4622 - val_ca4-[10.3,11.3): 1.0530 - val_ca4-[11.3,14.9): 1.8251\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 2.0991 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3953 - ca2-[9.5,10.3): 0.5725 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5034 - ca3-[10.3,11.3): 0.8122 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.3466 - ca4-[11.3,14.9): 1.7847 - val_ca1-[8.0,9.5): 1.9619 - val_ca1-[9.5,10.3): 2.1573 - val_ca1-[10.3,11.3): 3.5090 - val_ca1-[11.3,14.9): 5.4413 - val_ca2-[8.0,9.5): 0.5943 - val_ca2-[9.5,10.3): 0.4877 - val_ca2-[10.3,11.3): 1.1094 - val_ca2-[11.3,14.9): 1.9708 - val_ca3-[8.0,9.5): 0.6341 - val_ca3-[9.5,10.3): 0.4236 - val_ca3-[10.3,11.3): 0.7948 - val_ca3-[11.3,14.9): 1.2888 - val_ca4-[8.0,9.5): 0.5792 - val_ca4-[9.5,10.3): 0.4430 - val_ca4-[10.3,11.3): 0.9933 - val_ca4-[11.3,14.9): 1.7502\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 2.0212 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3850 - ca2-[9.5,10.3): 0.5751 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5312 - ca3-[10.3,11.3): 0.8080 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.1761 - ca4-[11.3,14.9): 1.6954 - val_ca1-[8.0,9.5): 1.8634 - val_ca1-[9.5,10.3): 2.0465 - val_ca1-[10.3,11.3): 3.3556 - val_ca1-[11.3,14.9): 5.2919 - val_ca2-[8.0,9.5): 0.5894 - val_ca2-[9.5,10.3): 0.4765 - val_ca2-[10.3,11.3): 1.0774 - val_ca2-[11.3,14.9): 1.9465 - val_ca3-[8.0,9.5): 0.6448 - val_ca3-[9.5,10.3): 0.4281 - val_ca3-[10.3,11.3): 0.7808 - val_ca3-[11.3,14.9): 1.2761 - val_ca4-[8.0,9.5): 0.5793 - val_ca4-[9.5,10.3): 0.4292 - val_ca4-[10.3,11.3): 0.9409 - val_ca4-[11.3,14.9): 1.6759\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 1.9123 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3776 - ca2-[9.5,10.3): 0.5598 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4789 - ca3-[10.3,11.3): 0.7581 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.1158 - ca4-[11.3,14.9): 1.6018 - val_ca1-[8.0,9.5): 1.7705 - val_ca1-[9.5,10.3): 1.9415 - val_ca1-[10.3,11.3): 3.2433 - val_ca1-[11.3,14.9): 5.1483 - val_ca2-[8.0,9.5): 0.5856 - val_ca2-[9.5,10.3): 0.4668 - val_ca2-[10.3,11.3): 1.0623 - val_ca2-[11.3,14.9): 1.8961 - val_ca3-[8.0,9.5): 0.6556 - val_ca3-[9.5,10.3): 0.4331 - val_ca3-[10.3,11.3): 0.7761 - val_ca3-[11.3,14.9): 1.2268 - val_ca4-[8.0,9.5): 0.5839 - val_ca4-[9.5,10.3): 0.4203 - val_ca4-[10.3,11.3): 0.9067 - val_ca4-[11.3,14.9): 1.5749\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 1.7988 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4026 - ca2-[9.5,10.3): 0.5480 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4784 - ca3-[10.3,11.3): 0.7584 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.0006 - ca4-[11.3,14.9): 1.5086 - val_ca1-[8.0,9.5): 1.6831 - val_ca1-[9.5,10.3): 1.8425 - val_ca1-[10.3,11.3): 3.1073 - val_ca1-[11.3,14.9): 4.9816 - val_ca2-[8.0,9.5): 0.5829 - val_ca2-[9.5,10.3): 0.4589 - val_ca2-[10.3,11.3): 1.0388 - val_ca2-[11.3,14.9): 1.8767 - val_ca3-[8.0,9.5): 0.6664 - val_ca3-[9.5,10.3): 0.4385 - val_ca3-[10.3,11.3): 0.7673 - val_ca3-[11.3,14.9): 1.2254 - val_ca4-[8.0,9.5): 0.5925 - val_ca4-[9.5,10.3): 0.4159 - val_ca4-[10.3,11.3): 0.8688 - val_ca4-[11.3,14.9): 1.5147\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 1s 151ms/step - ca1-[8.0,9.5): 1.7323 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4079 - ca2-[9.5,10.3): 0.5567 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4846 - ca3-[10.3,11.3): 0.7620 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.9294 - ca4-[11.3,14.9): 1.4129 - val_ca1-[8.0,9.5): 1.6004 - val_ca1-[9.5,10.3): 1.7482 - val_ca1-[10.3,11.3): 2.9996 - val_ca1-[11.3,14.9): 4.7019 - val_ca2-[8.0,9.5): 0.5810 - val_ca2-[9.5,10.3): 0.4523 - val_ca2-[10.3,11.3): 1.0298 - val_ca2-[11.3,14.9): 1.7719 - val_ca3-[8.0,9.5): 0.6770 - val_ca3-[9.5,10.3): 0.4441 - val_ca3-[10.3,11.3): 0.7679 - val_ca3-[11.3,14.9): 1.1485 - val_ca4-[8.0,9.5): 0.6045 - val_ca4-[9.5,10.3): 0.4155 - val_ca4-[10.3,11.3): 0.8464 - val_ca4-[11.3,14.9): 1.3796\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 1.6424 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3801 - ca2-[9.5,10.3): 0.5494 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4993 - ca3-[10.3,11.3): 0.7601 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.9258 - ca4-[11.3,14.9): 1.3510 - val_ca1-[8.0,9.5): 1.5224 - val_ca1-[9.5,10.3): 1.6589 - val_ca1-[10.3,11.3): 2.8814 - val_ca1-[11.3,14.9): 4.6119 - val_ca2-[8.0,9.5): 0.5797 - val_ca2-[9.5,10.3): 0.4466 - val_ca2-[10.3,11.3): 1.0114 - val_ca2-[11.3,14.9): 1.7856 - val_ca3-[8.0,9.5): 0.6872 - val_ca3-[9.5,10.3): 0.4497 - val_ca3-[10.3,11.3): 0.7603 - val_ca3-[11.3,14.9): 1.1649 - val_ca4-[8.0,9.5): 0.6195 - val_ca4-[9.5,10.3): 0.4186 - val_ca4-[10.3,11.3): 0.8185 - val_ca4-[11.3,14.9): 1.3530\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 1.5324 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3632 - ca2-[9.5,10.3): 0.5364 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4807 - ca3-[10.3,11.3): 0.7597 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8629 - ca4-[11.3,14.9): 1.3015 - val_ca1-[8.0,9.5): 1.4488 - val_ca1-[9.5,10.3): 1.5741 - val_ca1-[10.3,11.3): 2.7580 - val_ca1-[11.3,14.9): 4.4145 - val_ca2-[8.0,9.5): 0.5790 - val_ca2-[9.5,10.3): 0.4418 - val_ca2-[10.3,11.3): 0.9916 - val_ca2-[11.3,14.9): 1.7341 - val_ca3-[8.0,9.5): 0.6974 - val_ca3-[9.5,10.3): 0.4555 - val_ca3-[10.3,11.3): 0.7529 - val_ca3-[11.3,14.9): 1.1317 - val_ca4-[8.0,9.5): 0.6372 - val_ca4-[9.5,10.3): 0.4249 - val_ca4-[10.3,11.3): 0.7934 - val_ca4-[11.3,14.9): 1.2747\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 1.4694 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3551 - ca2-[9.5,10.3): 0.5372 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5088 - ca3-[10.3,11.3): 0.7578 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8109 - ca4-[11.3,14.9): 1.2317 - val_ca1-[8.0,9.5): 1.3789 - val_ca1-[9.5,10.3): 1.4933 - val_ca1-[10.3,11.3): 2.6682 - val_ca1-[11.3,14.9): 4.2238 - val_ca2-[8.0,9.5): 0.5787 - val_ca2-[9.5,10.3): 0.4378 - val_ca2-[10.3,11.3): 0.9844 - val_ca2-[11.3,14.9): 1.6768 - val_ca3-[8.0,9.5): 0.7070 - val_ca3-[9.5,10.3): 0.4612 - val_ca3-[10.3,11.3): 0.7501 - val_ca3-[11.3,14.9): 1.0882 - val_ca4-[8.0,9.5): 0.6572 - val_ca4-[9.5,10.3): 0.4339 - val_ca4-[10.3,11.3): 0.7778 - val_ca4-[11.3,14.9): 1.1917\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 1.3984 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3845 - ca2-[9.5,10.3): 0.5260 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4932 - ca3-[10.3,11.3): 0.7438 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7523 - ca4-[11.3,14.9): 1.1752 - val_ca1-[8.0,9.5): 1.3126 - val_ca1-[9.5,10.3): 1.4137 - val_ca1-[10.3,11.3): 2.5608 - val_ca1-[11.3,14.9): 4.1525 - val_ca2-[8.0,9.5): 0.5787 - val_ca2-[9.5,10.3): 0.4346 - val_ca2-[10.3,11.3): 0.9757 - val_ca2-[11.3,14.9): 1.6972 - val_ca3-[8.0,9.5): 0.7163 - val_ca3-[9.5,10.3): 0.4683 - val_ca3-[10.3,11.3): 0.7527 - val_ca3-[11.3,14.9): 1.1055 - val_ca4-[8.0,9.5): 0.6792 - val_ca4-[9.5,10.3): 0.4465 - val_ca4-[10.3,11.3): 0.7688 - val_ca4-[11.3,14.9): 1.1761\n",
      "Epoch 49/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 1.3393 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3708 - ca2-[9.5,10.3): 0.5255 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4880 - ca3-[10.3,11.3): 0.7427 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7243 - ca4-[11.3,14.9): 1.1318 - val_ca1-[8.0,9.5): 1.2494 - val_ca1-[9.5,10.3): 1.3421 - val_ca1-[10.3,11.3): 2.4457 - val_ca1-[11.3,14.9): 3.9896 - val_ca2-[8.0,9.5): 0.5789 - val_ca2-[9.5,10.3): 0.4315 - val_ca2-[10.3,11.3): 0.9549 - val_ca2-[11.3,14.9): 1.6638 - val_ca3-[8.0,9.5): 0.7255 - val_ca3-[9.5,10.3): 0.4726 - val_ca3-[10.3,11.3): 0.7409 - val_ca3-[11.3,14.9): 1.0831 - val_ca4-[8.0,9.5): 0.7028 - val_ca4-[9.5,10.3): 0.4588 - val_ca4-[10.3,11.3): 0.7485 - val_ca4-[11.3,14.9): 1.1215\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 1.2681 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3619 - ca2-[9.5,10.3): 0.5260 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4844 - ca3-[10.3,11.3): 0.7295 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7669 - ca4-[11.3,14.9): 1.0783 - val_ca1-[8.0,9.5): 1.1894 - val_ca1-[9.5,10.3): 1.2713 - val_ca1-[10.3,11.3): 2.3594 - val_ca1-[11.3,14.9): 3.8489 - val_ca2-[8.0,9.5): 0.5793 - val_ca2-[9.5,10.3): 0.4292 - val_ca2-[10.3,11.3): 0.9507 - val_ca2-[11.3,14.9): 1.6387 - val_ca3-[8.0,9.5): 0.7340 - val_ca3-[9.5,10.3): 0.4779 - val_ca3-[10.3,11.3): 0.7410 - val_ca3-[11.3,14.9): 1.0635 - val_ca4-[8.0,9.5): 0.7279 - val_ca4-[9.5,10.3): 0.4741 - val_ca4-[10.3,11.3): 0.7426 - val_ca4-[11.3,14.9): 1.0728\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 1s 151ms/step - ca1-[8.0,9.5): 1.2100 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3666 - ca2-[9.5,10.3): 0.5074 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5007 - ca3-[10.3,11.3): 0.7329 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6857 - ca4-[11.3,14.9): 1.0355 - val_ca1-[8.0,9.5): 1.1324 - val_ca1-[9.5,10.3): 1.2035 - val_ca1-[10.3,11.3): 2.2551 - val_ca1-[11.3,14.9): 3.7416 - val_ca2-[8.0,9.5): 0.5798 - val_ca2-[9.5,10.3): 0.4272 - val_ca2-[10.3,11.3): 0.9380 - val_ca2-[11.3,14.9): 1.6363 - val_ca3-[8.0,9.5): 0.7420 - val_ca3-[9.5,10.3): 0.4830 - val_ca3-[10.3,11.3): 0.7368 - val_ca3-[11.3,14.9): 1.0607 - val_ca4-[8.0,9.5): 0.7540 - val_ca4-[9.5,10.3): 0.4909 - val_ca4-[10.3,11.3): 0.7345 - val_ca4-[11.3,14.9): 1.0436\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 1.1220 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3654 - ca2-[9.5,10.3): 0.5131 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5128 - ca3-[10.3,11.3): 0.7196 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6385 - ca4-[11.3,14.9): 1.0110 - val_ca1-[8.0,9.5): 1.0786 - val_ca1-[9.5,10.3): 1.1391 - val_ca1-[10.3,11.3): 2.1664 - val_ca1-[11.3,14.9): 3.6417 - val_ca2-[8.0,9.5): 0.5804 - val_ca2-[9.5,10.3): 0.4257 - val_ca2-[10.3,11.3): 0.9334 - val_ca2-[11.3,14.9): 1.6329 - val_ca3-[8.0,9.5): 0.7495 - val_ca3-[9.5,10.3): 0.4879 - val_ca3-[10.3,11.3): 0.7375 - val_ca3-[11.3,14.9): 1.0515 - val_ca4-[8.0,9.5): 0.7812 - val_ca4-[9.5,10.3): 0.5091 - val_ca4-[10.3,11.3): 0.7332 - val_ca4-[11.3,14.9): 1.0092\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 1.0710 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3566 - ca2-[9.5,10.3): 0.5148 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5061 - ca3-[10.3,11.3): 0.7298 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6380 - ca4-[11.3,14.9): 0.9800 - val_ca1-[8.0,9.5): 1.0277 - val_ca1-[9.5,10.3): 1.0776 - val_ca1-[10.3,11.3): 2.0778 - val_ca1-[11.3,14.9): 3.5252 - val_ca2-[8.0,9.5): 0.5810 - val_ca2-[9.5,10.3): 0.4243 - val_ca2-[10.3,11.3): 0.9252 - val_ca2-[11.3,14.9): 1.6357 - val_ca3-[8.0,9.5): 0.7572 - val_ca3-[9.5,10.3): 0.4929 - val_ca3-[10.3,11.3): 0.7339 - val_ca3-[11.3,14.9): 1.0610 - val_ca4-[8.0,9.5): 0.8090 - val_ca4-[9.5,10.3): 0.5282 - val_ca4-[10.3,11.3): 0.7294 - val_ca4-[11.3,14.9): 0.9975\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 1.0296 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3568 - ca2-[9.5,10.3): 0.5207 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5270 - ca3-[10.3,11.3): 0.7310 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6560 - ca4-[11.3,14.9): 0.9653 - val_ca1-[8.0,9.5): 0.9800 - val_ca1-[9.5,10.3): 1.0193 - val_ca1-[10.3,11.3): 2.0050 - val_ca1-[11.3,14.9): 3.3961 - val_ca2-[8.0,9.5): 0.5816 - val_ca2-[9.5,10.3): 0.4232 - val_ca2-[10.3,11.3): 0.9266 - val_ca2-[11.3,14.9): 1.5961 - val_ca3-[8.0,9.5): 0.7643 - val_ca3-[9.5,10.3): 0.4976 - val_ca3-[10.3,11.3): 0.7371 - val_ca3-[11.3,14.9): 1.0119 - val_ca4-[8.0,9.5): 0.8370 - val_ca4-[9.5,10.3): 0.5481 - val_ca4-[10.3,11.3): 0.7333 - val_ca4-[11.3,14.9): 0.9269\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.9804 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3733 - ca2-[9.5,10.3): 0.5236 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5194 - ca3-[10.3,11.3): 0.7213 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6271 - ca4-[11.3,14.9): 0.9380 - val_ca1-[8.0,9.5): 0.9359 - val_ca1-[9.5,10.3): 0.9650 - val_ca1-[10.3,11.3): 1.9256 - val_ca1-[11.3,14.9): 3.2881 - val_ca2-[8.0,9.5): 0.5822 - val_ca2-[9.5,10.3): 0.4223 - val_ca2-[10.3,11.3): 0.9219 - val_ca2-[11.3,14.9): 1.6142 - val_ca3-[8.0,9.5): 0.7707 - val_ca3-[9.5,10.3): 0.5019 - val_ca3-[10.3,11.3): 0.7362 - val_ca3-[11.3,14.9): 1.0428 - val_ca4-[8.0,9.5): 0.8650 - val_ca4-[9.5,10.3): 0.5684 - val_ca4-[10.3,11.3): 0.7348 - val_ca4-[11.3,14.9): 0.9427\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.9069 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3786 - ca2-[9.5,10.3): 0.5188 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5254 - ca3-[10.3,11.3): 0.7232 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5860 - ca4-[11.3,14.9): 0.8853 - val_ca1-[8.0,9.5): 0.8955 - val_ca1-[9.5,10.3): 0.9145 - val_ca1-[10.3,11.3): 1.8549 - val_ca1-[11.3,14.9): 3.1734 - val_ca2-[8.0,9.5): 0.5829 - val_ca2-[9.5,10.3): 0.4215 - val_ca2-[10.3,11.3): 0.9178 - val_ca2-[11.3,14.9): 1.5923 - val_ca3-[8.0,9.5): 0.7765 - val_ca3-[9.5,10.3): 0.5058 - val_ca3-[10.3,11.3): 0.7334 - val_ca3-[11.3,14.9): 1.0182 - val_ca4-[8.0,9.5): 0.8929 - val_ca4-[9.5,10.3): 0.5889 - val_ca4-[10.3,11.3): 0.7347 - val_ca4-[11.3,14.9): 0.9008\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.8990 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3708 - ca2-[9.5,10.3): 0.5181 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5306 - ca3-[10.3,11.3): 0.7420 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5995 - ca4-[11.3,14.9): 0.8661 - val_ca1-[8.0,9.5): 0.8587 - val_ca1-[9.5,10.3): 0.8681 - val_ca1-[10.3,11.3): 1.7791 - val_ca1-[11.3,14.9): 3.0475 - val_ca2-[8.0,9.5): 0.5835 - val_ca2-[9.5,10.3): 0.4208 - val_ca2-[10.3,11.3): 0.9117 - val_ca2-[11.3,14.9): 1.5705 - val_ca3-[8.0,9.5): 0.7816 - val_ca3-[9.5,10.3): 0.5092 - val_ca3-[10.3,11.3): 0.7327 - val_ca3-[11.3,14.9): 1.0034 - val_ca4-[8.0,9.5): 0.9211 - val_ca4-[9.5,10.3): 0.6101 - val_ca4-[10.3,11.3): 0.7391 - val_ca4-[11.3,14.9): 0.8726\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.8296 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3884 - ca2-[9.5,10.3): 0.5148 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5229 - ca3-[10.3,11.3): 0.7172 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5629 - ca4-[11.3,14.9): 0.8374 - val_ca1-[8.0,9.5): 0.8254 - val_ca1-[9.5,10.3): 0.8255 - val_ca1-[10.3,11.3): 1.7137 - val_ca1-[11.3,14.9): 2.9580 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.4202 - val_ca2-[10.3,11.3): 0.9081 - val_ca2-[11.3,14.9): 1.5752 - val_ca3-[8.0,9.5): 0.7864 - val_ca3-[9.5,10.3): 0.5125 - val_ca3-[10.3,11.3): 0.7323 - val_ca3-[11.3,14.9): 1.0126 - val_ca4-[8.0,9.5): 0.9493 - val_ca4-[9.5,10.3): 0.6315 - val_ca4-[10.3,11.3): 0.7439 - val_ca4-[11.3,14.9): 0.8694\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 1s 150ms/step - ca1-[8.0,9.5): 0.8150 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3585 - ca2-[9.5,10.3): 0.5157 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5431 - ca3-[10.3,11.3): 0.7275 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5433 - ca4-[11.3,14.9): 0.8312 - val_ca1-[8.0,9.5): 0.7955 - val_ca1-[9.5,10.3): 0.7866 - val_ca1-[10.3,11.3): 1.6530 - val_ca1-[11.3,14.9): 2.8188 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.4198 - val_ca2-[10.3,11.3): 0.9058 - val_ca2-[11.3,14.9): 1.5370 - val_ca3-[8.0,9.5): 0.7911 - val_ca3-[9.5,10.3): 0.5157 - val_ca3-[10.3,11.3): 0.7319 - val_ca3-[11.3,14.9): 0.9840 - val_ca4-[8.0,9.5): 0.9773 - val_ca4-[9.5,10.3): 0.6530 - val_ca4-[10.3,11.3): 0.7496 - val_ca4-[11.3,14.9): 0.8335\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.7605 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3795 - ca2-[9.5,10.3): 0.5240 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5180 - ca3-[10.3,11.3): 0.7013 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5537 - ca4-[11.3,14.9): 0.7988 - val_ca1-[8.0,9.5): 0.7689 - val_ca1-[9.5,10.3): 0.7504 - val_ca1-[10.3,11.3): 1.6038 - val_ca1-[11.3,14.9): 2.7332 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.4199 - val_ca2-[10.3,11.3): 0.9075 - val_ca2-[11.3,14.9): 1.5303 - val_ca3-[8.0,9.5): 0.7956 - val_ca3-[9.5,10.3): 0.5205 - val_ca3-[10.3,11.3): 0.7338 - val_ca3-[11.3,14.9): 0.9769 - val_ca4-[8.0,9.5): 1.0052 - val_ca4-[9.5,10.3): 0.6769 - val_ca4-[10.3,11.3): 0.7573 - val_ca4-[11.3,14.9): 0.8162\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.7441 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3893 - ca2-[9.5,10.3): 0.5270 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5152 - ca3-[10.3,11.3): 0.7198 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5067 - ca4-[11.3,14.9): 0.8021 - val_ca1-[8.0,9.5): 0.7449 - val_ca1-[9.5,10.3): 0.7194 - val_ca1-[10.3,11.3): 1.5216 - val_ca1-[11.3,14.9): 2.7061 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.4190 - val_ca2-[10.3,11.3): 0.8838 - val_ca2-[11.3,14.9): 1.5596 - val_ca3-[8.0,9.5): 0.7998 - val_ca3-[9.5,10.3): 0.5217 - val_ca3-[10.3,11.3): 0.7193 - val_ca3-[11.3,14.9): 0.9924 - val_ca4-[8.0,9.5): 1.0320 - val_ca4-[9.5,10.3): 0.6956 - val_ca4-[10.3,11.3): 0.7535 - val_ca4-[11.3,14.9): 0.8158\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.7297 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3726 - ca2-[9.5,10.3): 0.5081 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5350 - ca3-[10.3,11.3): 0.7172 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5626 - ca4-[11.3,14.9): 0.7940 - val_ca1-[8.0,9.5): 0.7236 - val_ca1-[9.5,10.3): 0.6902 - val_ca1-[10.3,11.3): 1.5003 - val_ca1-[11.3,14.9): 2.6279 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.4187 - val_ca2-[10.3,11.3): 0.9024 - val_ca2-[11.3,14.9): 1.5501 - val_ca3-[8.0,9.5): 0.8034 - val_ca3-[9.5,10.3): 0.5242 - val_ca3-[10.3,11.3): 0.7357 - val_ca3-[11.3,14.9): 0.9829 - val_ca4-[8.0,9.5): 1.0581 - val_ca4-[9.5,10.3): 0.7163 - val_ca4-[10.3,11.3): 0.7748 - val_ca4-[11.3,14.9): 0.7970\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.7081 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3803 - ca2-[9.5,10.3): 0.5161 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5476 - ca3-[10.3,11.3): 0.7271 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4801 - ca4-[11.3,14.9): 0.7792 - val_ca1-[8.0,9.5): 0.7046 - val_ca1-[9.5,10.3): 0.6639 - val_ca1-[10.3,11.3): 1.4375 - val_ca1-[11.3,14.9): 2.5258 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.4184 - val_ca2-[10.3,11.3): 0.8878 - val_ca2-[11.3,14.9): 1.5263 - val_ca3-[8.0,9.5): 0.8065 - val_ca3-[9.5,10.3): 0.5264 - val_ca3-[10.3,11.3): 0.7276 - val_ca3-[11.3,14.9): 0.9696 - val_ca4-[8.0,9.5): 1.0836 - val_ca4-[9.5,10.3): 0.7365 - val_ca4-[10.3,11.3): 0.7774 - val_ca4-[11.3,14.9): 0.7821\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.6620 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3622 - ca2-[9.5,10.3): 0.5080 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5023 - ca3-[10.3,11.3): 0.7012 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5738 - ca4-[11.3,14.9): 0.7786 - val_ca1-[8.0,9.5): 0.6877 - val_ca1-[9.5,10.3): 0.6398 - val_ca1-[10.3,11.3): 1.3886 - val_ca1-[11.3,14.9): 2.4554 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.4182 - val_ca2-[10.3,11.3): 0.8783 - val_ca2-[11.3,14.9): 1.5207 - val_ca3-[8.0,9.5): 0.8091 - val_ca3-[9.5,10.3): 0.5282 - val_ca3-[10.3,11.3): 0.7191 - val_ca3-[11.3,14.9): 0.9657 - val_ca4-[8.0,9.5): 1.1086 - val_ca4-[9.5,10.3): 0.7565 - val_ca4-[10.3,11.3): 0.7767 - val_ca4-[11.3,14.9): 0.7724\n",
      "Epoch 65/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.6637 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3780 - ca2-[9.5,10.3): 0.5080 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5465 - ca3-[10.3,11.3): 0.7225 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5251 - ca4-[11.3,14.9): 0.7551 - val_ca1-[8.0,9.5): 0.6728 - val_ca1-[9.5,10.3): 0.6183 - val_ca1-[10.3,11.3): 1.3732 - val_ca1-[11.3,14.9): 2.4033 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.4180 - val_ca2-[10.3,11.3): 0.8938 - val_ca2-[11.3,14.9): 1.5238 - val_ca3-[8.0,9.5): 0.8118 - val_ca3-[9.5,10.3): 0.5301 - val_ca3-[10.3,11.3): 0.7309 - val_ca3-[11.3,14.9): 0.9669 - val_ca4-[8.0,9.5): 1.1330 - val_ca4-[9.5,10.3): 0.7762 - val_ca4-[10.3,11.3): 0.7934 - val_ca4-[11.3,14.9): 0.7662\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.6292 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3692 - ca2-[9.5,10.3): 0.5203 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5412 - ca3-[10.3,11.3): 0.7093 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5472 - ca4-[11.3,14.9): 0.7362 - val_ca1-[8.0,9.5): 0.6598 - val_ca1-[9.5,10.3): 0.5989 - val_ca1-[10.3,11.3): 1.3334 - val_ca1-[11.3,14.9): 2.3435 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.4178 - val_ca2-[10.3,11.3): 0.8859 - val_ca2-[11.3,14.9): 1.5083 - val_ca3-[8.0,9.5): 0.8142 - val_ca3-[9.5,10.3): 0.5318 - val_ca3-[10.3,11.3): 0.7226 - val_ca3-[11.3,14.9): 0.9417 - val_ca4-[8.0,9.5): 1.1565 - val_ca4-[9.5,10.3): 0.7952 - val_ca4-[10.3,11.3): 0.7920 - val_ca4-[11.3,14.9): 0.7288\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.6274 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3847 - ca2-[9.5,10.3): 0.5151 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5575 - ca3-[10.3,11.3): 0.7108 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4826 - ca4-[11.3,14.9): 0.7420 - val_ca1-[8.0,9.5): 0.6483 - val_ca1-[9.5,10.3): 0.5815 - val_ca1-[10.3,11.3): 1.3080 - val_ca1-[11.3,14.9): 2.3045 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.4177 - val_ca2-[10.3,11.3): 0.8934 - val_ca2-[11.3,14.9): 1.5250 - val_ca3-[8.0,9.5): 0.8164 - val_ca3-[9.5,10.3): 0.5333 - val_ca3-[10.3,11.3): 0.7330 - val_ca3-[11.3,14.9): 0.9636 - val_ca4-[8.0,9.5): 1.1793 - val_ca4-[9.5,10.3): 0.8137 - val_ca4-[10.3,11.3): 0.8119 - val_ca4-[11.3,14.9): 0.7496\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.6294 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3823 - ca2-[9.5,10.3): 0.5268 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5345 - ca3-[10.3,11.3): 0.7249 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5086 - ca4-[11.3,14.9): 0.7410 - val_ca1-[8.0,9.5): 0.6383 - val_ca1-[9.5,10.3): 0.5658 - val_ca1-[10.3,11.3): 1.2729 - val_ca1-[11.3,14.9): 2.2271 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.4176 - val_ca2-[10.3,11.3): 0.8875 - val_ca2-[11.3,14.9): 1.5038 - val_ca3-[8.0,9.5): 0.8178 - val_ca3-[9.5,10.3): 0.5343 - val_ca3-[10.3,11.3): 0.7294 - val_ca3-[11.3,14.9): 0.9539 - val_ca4-[8.0,9.5): 1.2018 - val_ca4-[9.5,10.3): 0.8321 - val_ca4-[10.3,11.3): 0.8175 - val_ca4-[11.3,14.9): 0.7431\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5994 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3653 - ca2-[9.5,10.3): 0.5211 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5455 - ca3-[10.3,11.3): 0.6940 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5437 - ca4-[11.3,14.9): 0.7311 - val_ca1-[8.0,9.5): 0.6296 - val_ca1-[9.5,10.3): 0.5512 - val_ca1-[10.3,11.3): 1.2229 - val_ca1-[11.3,14.9): 2.1772 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4180 - val_ca2-[10.3,11.3): 0.8660 - val_ca2-[11.3,14.9): 1.4902 - val_ca3-[8.0,9.5): 0.8200 - val_ca3-[9.5,10.3): 0.5375 - val_ca3-[10.3,11.3): 0.7106 - val_ca3-[11.3,14.9): 0.9291 - val_ca4-[8.0,9.5): 1.2230 - val_ca4-[9.5,10.3): 0.8522 - val_ca4-[10.3,11.3): 0.8085 - val_ca4-[11.3,14.9): 0.7074\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5810 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3774 - ca2-[9.5,10.3): 0.5136 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5450 - ca3-[10.3,11.3): 0.7253 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5159 - ca4-[11.3,14.9): 0.7343 - val_ca1-[8.0,9.5): 0.6219 - val_ca1-[9.5,10.3): 0.5389 - val_ca1-[10.3,11.3): 1.2262 - val_ca1-[11.3,14.9): 2.1566 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4174 - val_ca2-[10.3,11.3): 0.8912 - val_ca2-[11.3,14.9): 1.5159 - val_ca3-[8.0,9.5): 0.8214 - val_ca3-[9.5,10.3): 0.5368 - val_ca3-[10.3,11.3): 0.7329 - val_ca3-[11.3,14.9): 0.9602 - val_ca4-[8.0,9.5): 1.2436 - val_ca4-[9.5,10.3): 0.8664 - val_ca4-[10.3,11.3): 0.8363 - val_ca4-[11.3,14.9): 0.7396\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 1s 148ms/step - ca1-[8.0,9.5): 0.5891 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3920 - ca2-[9.5,10.3): 0.5219 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5431 - ca3-[10.3,11.3): 0.7248 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5487 - ca4-[11.3,14.9): 0.7167 - val_ca1-[8.0,9.5): 0.6151 - val_ca1-[9.5,10.3): 0.5271 - val_ca1-[10.3,11.3): 1.2043 - val_ca1-[11.3,14.9): 2.1220 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4174 - val_ca2-[10.3,11.3): 0.8908 - val_ca2-[11.3,14.9): 1.5213 - val_ca3-[8.0,9.5): 0.8226 - val_ca3-[9.5,10.3): 0.5377 - val_ca3-[10.3,11.3): 0.7305 - val_ca3-[11.3,14.9): 0.9654 - val_ca4-[8.0,9.5): 1.2630 - val_ca4-[9.5,10.3): 0.8824 - val_ca4-[10.3,11.3): 0.8395 - val_ca4-[11.3,14.9): 0.7419\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 1s 148ms/step - ca1-[8.0,9.5): 0.5719 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3792 - ca2-[9.5,10.3): 0.5214 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5439 - ca3-[10.3,11.3): 0.7078 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5085 - ca4-[11.3,14.9): 0.7161 - val_ca1-[8.0,9.5): 0.6092 - val_ca1-[9.5,10.3): 0.5167 - val_ca1-[10.3,11.3): 1.1699 - val_ca1-[11.3,14.9): 2.0643 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8833 - val_ca2-[11.3,14.9): 1.5045 - val_ca3-[8.0,9.5): 0.8237 - val_ca3-[9.5,10.3): 0.5384 - val_ca3-[10.3,11.3): 0.7320 - val_ca3-[11.3,14.9): 0.9555 - val_ca4-[8.0,9.5): 1.2818 - val_ca4-[9.5,10.3): 0.8980 - val_ca4-[10.3,11.3): 0.8558 - val_ca4-[11.3,14.9): 0.7352\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5672 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3633 - ca2-[9.5,10.3): 0.5248 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5344 - ca3-[10.3,11.3): 0.7018 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5716 - ca4-[11.3,14.9): 0.7165 - val_ca1-[8.0,9.5): 0.6042 - val_ca1-[9.5,10.3): 0.5073 - val_ca1-[10.3,11.3): 1.1580 - val_ca1-[11.3,14.9): 2.0705 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4172 - val_ca2-[10.3,11.3): 0.8873 - val_ca2-[11.3,14.9): 1.5341 - val_ca3-[8.0,9.5): 0.8249 - val_ca3-[9.5,10.3): 0.5393 - val_ca3-[10.3,11.3): 0.7311 - val_ca3-[11.3,14.9): 0.9692 - val_ca4-[8.0,9.5): 1.2996 - val_ca4-[9.5,10.3): 0.9127 - val_ca4-[10.3,11.3): 0.8578 - val_ca4-[11.3,14.9): 0.7331\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5764 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3726 - ca2-[9.5,10.3): 0.5203 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5704 - ca3-[10.3,11.3): 0.7269 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5682 - ca4-[11.3,14.9): 0.7061 - val_ca1-[8.0,9.5): 0.5998 - val_ca1-[9.5,10.3): 0.4988 - val_ca1-[10.3,11.3): 1.1344 - val_ca1-[11.3,14.9): 2.0195 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4172 - val_ca2-[10.3,11.3): 0.8832 - val_ca2-[11.3,14.9): 1.5163 - val_ca3-[8.0,9.5): 0.8260 - val_ca3-[9.5,10.3): 0.5400 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9510 - val_ca4-[8.0,9.5): 1.3165 - val_ca4-[9.5,10.3): 0.9268 - val_ca4-[10.3,11.3): 0.8646 - val_ca4-[11.3,14.9): 0.7134\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5666 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3772 - ca2-[9.5,10.3): 0.5061 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5484 - ca3-[10.3,11.3): 0.7169 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5410 - ca4-[11.3,14.9): 0.7162 - val_ca1-[8.0,9.5): 0.5960 - val_ca1-[9.5,10.3): 0.4911 - val_ca1-[10.3,11.3): 1.1006 - val_ca1-[11.3,14.9): 1.9679 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4172 - val_ca2-[10.3,11.3): 0.8694 - val_ca2-[11.3,14.9): 1.5003 - val_ca3-[8.0,9.5): 0.8272 - val_ca3-[9.5,10.3): 0.5409 - val_ca3-[10.3,11.3): 0.7218 - val_ca3-[11.3,14.9): 0.9449 - val_ca4-[8.0,9.5): 1.3327 - val_ca4-[9.5,10.3): 0.9403 - val_ca4-[10.3,11.3): 0.8699 - val_ca4-[11.3,14.9): 0.7148\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5445 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3860 - ca2-[9.5,10.3): 0.5094 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5459 - ca3-[10.3,11.3): 0.7205 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4915 - ca4-[11.3,14.9): 0.6965 - val_ca1-[8.0,9.5): 0.5928 - val_ca1-[9.5,10.3): 0.4842 - val_ca1-[10.3,11.3): 1.1073 - val_ca1-[11.3,14.9): 1.9024 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8862 - val_ca2-[11.3,14.9): 1.4678 - val_ca3-[8.0,9.5): 0.8286 - val_ca3-[9.5,10.3): 0.5419 - val_ca3-[10.3,11.3): 0.7306 - val_ca3-[11.3,14.9): 0.9234 - val_ca4-[8.0,9.5): 1.3482 - val_ca4-[9.5,10.3): 0.9533 - val_ca4-[10.3,11.3): 0.8773 - val_ca4-[11.3,14.9): 0.7029\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 1s 151ms/step - ca1-[8.0,9.5): 0.5338 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3706 - ca2-[9.5,10.3): 0.4980 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5665 - ca3-[10.3,11.3): 0.7203 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5404 - ca4-[11.3,14.9): 0.7190 - val_ca1-[8.0,9.5): 0.5901 - val_ca1-[9.5,10.3): 0.4781 - val_ca1-[10.3,11.3): 1.0928 - val_ca1-[11.3,14.9): 1.9062 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8857 - val_ca2-[11.3,14.9): 1.4927 - val_ca3-[8.0,9.5): 0.8292 - val_ca3-[9.5,10.3): 0.5422 - val_ca3-[10.3,11.3): 0.7306 - val_ca3-[11.3,14.9): 0.9411 - val_ca4-[8.0,9.5): 1.3627 - val_ca4-[9.5,10.3): 0.9654 - val_ca4-[10.3,11.3): 0.8837 - val_ca4-[11.3,14.9): 0.7120\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5431 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3598 - ca2-[9.5,10.3): 0.5170 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5403 - ca3-[10.3,11.3): 0.7066 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5455 - ca4-[11.3,14.9): 0.6895 - val_ca1-[8.0,9.5): 0.5878 - val_ca1-[9.5,10.3): 0.4725 - val_ca1-[10.3,11.3): 1.0811 - val_ca1-[11.3,14.9): 1.9038 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8875 - val_ca2-[11.3,14.9): 1.5140 - val_ca3-[8.0,9.5): 0.8296 - val_ca3-[9.5,10.3): 0.5425 - val_ca3-[10.3,11.3): 0.7328 - val_ca3-[11.3,14.9): 0.9608 - val_ca4-[8.0,9.5): 1.3763 - val_ca4-[9.5,10.3): 0.9768 - val_ca4-[10.3,11.3): 0.8922 - val_ca4-[11.3,14.9): 0.7291\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5473 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3815 - ca2-[9.5,10.3): 0.5170 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5454 - ca3-[10.3,11.3): 0.7129 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5619 - ca4-[11.3,14.9): 0.7113 - val_ca1-[8.0,9.5): 0.5859 - val_ca1-[9.5,10.3): 0.4675 - val_ca1-[10.3,11.3): 1.0715 - val_ca1-[11.3,14.9): 1.8942 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8891 - val_ca2-[11.3,14.9): 1.5198 - val_ca3-[8.0,9.5): 0.8307 - val_ca3-[9.5,10.3): 0.5433 - val_ca3-[10.3,11.3): 0.7326 - val_ca3-[11.3,14.9): 0.9509 - val_ca4-[8.0,9.5): 1.3895 - val_ca4-[9.5,10.3): 0.9878 - val_ca4-[10.3,11.3): 0.8957 - val_ca4-[11.3,14.9): 0.7035\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5374 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3789 - ca2-[9.5,10.3): 0.5158 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5504 - ca3-[10.3,11.3): 0.7182 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5230 - ca4-[11.3,14.9): 0.7050 - val_ca1-[8.0,9.5): 0.5843 - val_ca1-[9.5,10.3): 0.4642 - val_ca1-[10.3,11.3): 1.0494 - val_ca1-[11.3,14.9): 1.8611 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4176 - val_ca2-[10.3,11.3): 0.8811 - val_ca2-[11.3,14.9): 1.5138 - val_ca3-[8.0,9.5): 0.8310 - val_ca3-[9.5,10.3): 0.5427 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9543 - val_ca4-[8.0,9.5): 1.4020 - val_ca4-[9.5,10.3): 0.9961 - val_ca4-[10.3,11.3): 0.9026 - val_ca4-[11.3,14.9): 0.7161\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5246 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3801 - ca2-[9.5,10.3): 0.5241 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5473 - ca3-[10.3,11.3): 0.7179 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5559 - ca4-[11.3,14.9): 0.6907 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4589 - val_ca1-[10.3,11.3): 1.0462 - val_ca1-[11.3,14.9): 1.8453 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8873 - val_ca2-[11.3,14.9): 1.5139 - val_ca3-[8.0,9.5): 0.8316 - val_ca3-[9.5,10.3): 0.5440 - val_ca3-[10.3,11.3): 0.7327 - val_ca3-[11.3,14.9): 0.9434 - val_ca4-[8.0,9.5): 1.4130 - val_ca4-[9.5,10.3): 1.0077 - val_ca4-[10.3,11.3): 0.9088 - val_ca4-[11.3,14.9): 0.6943\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5428 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3845 - ca2-[9.5,10.3): 0.5139 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5137 - ca3-[10.3,11.3): 0.7129 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5349 - ca4-[11.3,14.9): 0.6891 - val_ca1-[8.0,9.5): 0.5818 - val_ca1-[9.5,10.3): 0.4552 - val_ca1-[10.3,11.3): 1.0427 - val_ca1-[11.3,14.9): 1.8350 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8932 - val_ca2-[11.3,14.9): 1.5222 - val_ca3-[8.0,9.5): 0.8320 - val_ca3-[9.5,10.3): 0.5442 - val_ca3-[10.3,11.3): 0.7371 - val_ca3-[11.3,14.9): 0.9503 - val_ca4-[8.0,9.5): 1.4241 - val_ca4-[9.5,10.3): 1.0170 - val_ca4-[10.3,11.3): 0.9166 - val_ca4-[11.3,14.9): 0.6989\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 1s 149ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3749 - ca2-[9.5,10.3): 0.5084 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5586 - ca3-[10.3,11.3): 0.7187 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5361 - ca4-[11.3,14.9): 0.7022 - val_ca1-[8.0,9.5): 0.5810 - val_ca1-[9.5,10.3): 0.4518 - val_ca1-[10.3,11.3): 1.0140 - val_ca1-[11.3,14.9): 1.7672 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8769 - val_ca2-[11.3,14.9): 1.4795 - val_ca3-[8.0,9.5): 0.8321 - val_ca3-[9.5,10.3): 0.5443 - val_ca3-[10.3,11.3): 0.7274 - val_ca3-[11.3,14.9): 0.9225 - val_ca4-[8.0,9.5): 1.4343 - val_ca4-[9.5,10.3): 1.0256 - val_ca4-[10.3,11.3): 0.9190 - val_ca4-[11.3,14.9): 0.6870\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5320 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3382 - ca2-[9.5,10.3): 0.5190 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5620 - ca3-[10.3,11.3): 0.7326 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5749 - ca4-[11.3,14.9): 0.6931 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4489 - val_ca1-[10.3,11.3): 1.0162 - val_ca1-[11.3,14.9): 1.8190 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8859 - val_ca2-[11.3,14.9): 1.5450 - val_ca3-[8.0,9.5): 0.8322 - val_ca3-[9.5,10.3): 0.5443 - val_ca3-[10.3,11.3): 0.7304 - val_ca3-[11.3,14.9): 0.9766 - val_ca4-[8.0,9.5): 1.4437 - val_ca4-[9.5,10.3): 1.0335 - val_ca4-[10.3,11.3): 0.9205 - val_ca4-[11.3,14.9): 0.7296\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3511 - ca2-[9.5,10.3): 0.5100 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5385 - ca3-[10.3,11.3): 0.7177 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5583 - ca4-[11.3,14.9): 0.7059 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4463 - val_ca1-[10.3,11.3): 1.0132 - val_ca1-[11.3,14.9): 1.7581 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8902 - val_ca2-[11.3,14.9): 1.5028 - val_ca3-[8.0,9.5): 0.8320 - val_ca3-[9.5,10.3): 0.5441 - val_ca3-[10.3,11.3): 0.7324 - val_ca3-[11.3,14.9): 0.9427 - val_ca4-[8.0,9.5): 1.4525 - val_ca4-[9.5,10.3): 1.0410 - val_ca4-[10.3,11.3): 0.9246 - val_ca4-[11.3,14.9): 0.7043\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5311 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3915 - ca2-[9.5,10.3): 0.5197 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5344 - ca3-[10.3,11.3): 0.7214 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5245 - ca4-[11.3,14.9): 0.6987 - val_ca1-[8.0,9.5): 0.5794 - val_ca1-[9.5,10.3): 0.4439 - val_ca1-[10.3,11.3): 0.9988 - val_ca1-[11.3,14.9): 1.7928 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8818 - val_ca2-[11.3,14.9): 1.5474 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5443 - val_ca3-[10.3,11.3): 0.7214 - val_ca3-[11.3,14.9): 0.9771 - val_ca4-[8.0,9.5): 1.4608 - val_ca4-[9.5,10.3): 1.0480 - val_ca4-[10.3,11.3): 0.9144 - val_ca4-[11.3,14.9): 0.7274\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3814 - ca2-[9.5,10.3): 0.5257 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5462 - ca3-[10.3,11.3): 0.7008 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5203 - ca4-[11.3,14.9): 0.6912 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4418 - val_ca1-[10.3,11.3): 0.9897 - val_ca1-[11.3,14.9): 1.7454 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8812 - val_ca2-[11.3,14.9): 1.5119 - val_ca3-[8.0,9.5): 0.8325 - val_ca3-[9.5,10.3): 0.5444 - val_ca3-[10.3,11.3): 0.7288 - val_ca3-[11.3,14.9): 0.9413 - val_ca4-[8.0,9.5): 1.4685 - val_ca4-[9.5,10.3): 1.0545 - val_ca4-[10.3,11.3): 0.9337 - val_ca4-[11.3,14.9): 0.6901\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5193 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3755 - ca2-[9.5,10.3): 0.5104 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5431 - ca3-[10.3,11.3): 0.7181 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5667 - ca4-[11.3,14.9): 0.7037 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4398 - val_ca1-[10.3,11.3): 0.9875 - val_ca1-[11.3,14.9): 1.7325 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8833 - val_ca2-[11.3,14.9): 1.5119 - val_ca3-[8.0,9.5): 0.8328 - val_ca3-[9.5,10.3): 0.5447 - val_ca3-[10.3,11.3): 0.7235 - val_ca3-[11.3,14.9): 0.9410 - val_ca4-[8.0,9.5): 1.4761 - val_ca4-[9.5,10.3): 1.0610 - val_ca4-[10.3,11.3): 0.9241 - val_ca4-[11.3,14.9): 0.6896\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5353 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3735 - ca2-[9.5,10.3): 0.5135 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5764 - ca3-[10.3,11.3): 0.7416 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5650 - ca4-[11.3,14.9): 0.6938 - val_ca1-[8.0,9.5): 0.5788 - val_ca1-[9.5,10.3): 0.4380 - val_ca1-[10.3,11.3): 0.9824 - val_ca1-[11.3,14.9): 1.7165 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8860 - val_ca2-[11.3,14.9): 1.5129 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5449 - val_ca3-[10.3,11.3): 0.7302 - val_ca3-[11.3,14.9): 0.9533 - val_ca4-[8.0,9.5): 1.4828 - val_ca4-[9.5,10.3): 1.0667 - val_ca4-[10.3,11.3): 0.9390 - val_ca4-[11.3,14.9): 0.7163\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5304 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3800 - ca2-[9.5,10.3): 0.5088 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5515 - ca3-[10.3,11.3): 0.7358 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5684 - ca4-[11.3,14.9): 0.7026 - val_ca1-[8.0,9.5): 0.5787 - val_ca1-[9.5,10.3): 0.4364 - val_ca1-[10.3,11.3): 0.9587 - val_ca1-[11.3,14.9): 1.6670 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8693 - val_ca2-[11.3,14.9): 1.4745 - val_ca3-[8.0,9.5): 0.8333 - val_ca3-[9.5,10.3): 0.5450 - val_ca3-[10.3,11.3): 0.7186 - val_ca3-[11.3,14.9): 0.9145 - val_ca4-[8.0,9.5): 1.4892 - val_ca4-[9.5,10.3): 1.0721 - val_ca4-[10.3,11.3): 0.9365 - val_ca4-[11.3,14.9): 0.6774\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5188 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3805 - ca2-[9.5,10.3): 0.5179 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5450 - ca3-[10.3,11.3): 0.7150 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5854 - ca4-[11.3,14.9): 0.6957 - val_ca1-[8.0,9.5): 0.5787 - val_ca1-[9.5,10.3): 0.4349 - val_ca1-[10.3,11.3): 0.9671 - val_ca1-[11.3,14.9): 1.6364 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8819 - val_ca2-[11.3,14.9): 1.4551 - val_ca3-[8.0,9.5): 0.8337 - val_ca3-[9.5,10.3): 0.5452 - val_ca3-[10.3,11.3): 0.7286 - val_ca3-[11.3,14.9): 0.8999 - val_ca4-[8.0,9.5): 1.4952 - val_ca4-[9.5,10.3): 1.0772 - val_ca4-[10.3,11.3): 0.9467 - val_ca4-[11.3,14.9): 0.6687\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5067 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3689 - ca2-[9.5,10.3): 0.5114 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5293 - ca3-[10.3,11.3): 0.7288 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5524 - ca4-[11.3,14.9): 0.6916 - val_ca1-[8.0,9.5): 0.5788 - val_ca1-[9.5,10.3): 0.4337 - val_ca1-[10.3,11.3): 0.9626 - val_ca1-[11.3,14.9): 1.6680 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8817 - val_ca2-[11.3,14.9): 1.4936 - val_ca3-[8.0,9.5): 0.8337 - val_ca3-[9.5,10.3): 0.5452 - val_ca3-[10.3,11.3): 0.7285 - val_ca3-[11.3,14.9): 0.9307 - val_ca4-[8.0,9.5): 1.5006 - val_ca4-[9.5,10.3): 1.0818 - val_ca4-[10.3,11.3): 0.9493 - val_ca4-[11.3,14.9): 0.6908\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5111 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3909 - ca2-[9.5,10.3): 0.5190 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5551 - ca3-[10.3,11.3): 0.7094 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5605 - ca4-[11.3,14.9): 0.6813 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4325 - val_ca1-[10.3,11.3): 0.9550 - val_ca1-[11.3,14.9): 1.7010 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8776 - val_ca2-[11.3,14.9): 1.5349 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5448 - val_ca3-[10.3,11.3): 0.7196 - val_ca3-[11.3,14.9): 0.9682 - val_ca4-[8.0,9.5): 1.5060 - val_ca4-[9.5,10.3): 1.0864 - val_ca4-[10.3,11.3): 0.9375 - val_ca4-[11.3,14.9): 0.7228\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5256 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3892 - ca2-[9.5,10.3): 0.5292 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5781 - ca3-[10.3,11.3): 0.7270 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5054 - ca4-[11.3,14.9): 0.6971 - val_ca1-[8.0,9.5): 0.5790 - val_ca1-[9.5,10.3): 0.4314 - val_ca1-[10.3,11.3): 0.9543 - val_ca1-[11.3,14.9): 1.6842 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8811 - val_ca2-[11.3,14.9): 1.5246 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5448 - val_ca3-[10.3,11.3): 0.7285 - val_ca3-[11.3,14.9): 0.9583 - val_ca4-[8.0,9.5): 1.5114 - val_ca4-[9.5,10.3): 1.0910 - val_ca4-[10.3,11.3): 0.9546 - val_ca4-[11.3,14.9): 0.7116\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5190 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3797 - ca2-[9.5,10.3): 0.5178 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5477 - ca3-[10.3,11.3): 0.7229 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5251 - ca4-[11.3,14.9): 0.6753 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4304 - val_ca1-[10.3,11.3): 0.9575 - val_ca1-[11.3,14.9): 1.6698 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8871 - val_ca2-[11.3,14.9): 1.5174 - val_ca3-[8.0,9.5): 0.8339 - val_ca3-[9.5,10.3): 0.5453 - val_ca3-[10.3,11.3): 0.7322 - val_ca3-[11.3,14.9): 0.9536 - val_ca4-[8.0,9.5): 1.5159 - val_ca4-[9.5,10.3): 1.0948 - val_ca4-[10.3,11.3): 0.9576 - val_ca4-[11.3,14.9): 0.7105\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5186 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3590 - ca2-[9.5,10.3): 0.5157 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5393 - ca3-[10.3,11.3): 0.7039 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5299 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5793 - val_ca1-[9.5,10.3): 0.4296 - val_ca1-[10.3,11.3): 0.9474 - val_ca1-[11.3,14.9): 1.6569 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8808 - val_ca2-[11.3,14.9): 1.5111 - val_ca3-[8.0,9.5): 0.8352 - val_ca3-[9.5,10.3): 0.5462 - val_ca3-[10.3,11.3): 0.7285 - val_ca3-[11.3,14.9): 0.9433 - val_ca4-[8.0,9.5): 1.5201 - val_ca4-[9.5,10.3): 1.0984 - val_ca4-[10.3,11.3): 0.9588 - val_ca4-[11.3,14.9): 0.6983\n",
      "Epoch 97/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5157 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3755 - ca2-[9.5,10.3): 0.5158 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5502 - ca3-[10.3,11.3): 0.7218 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5161 - ca4-[11.3,14.9): 0.6927 - val_ca1-[8.0,9.5): 0.5795 - val_ca1-[9.5,10.3): 0.4287 - val_ca1-[10.3,11.3): 0.9479 - val_ca1-[11.3,14.9): 1.6661 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8848 - val_ca2-[11.3,14.9): 1.5264 - val_ca3-[8.0,9.5): 0.8356 - val_ca3-[9.5,10.3): 0.5464 - val_ca3-[10.3,11.3): 0.7330 - val_ca3-[11.3,14.9): 0.9539 - val_ca4-[8.0,9.5): 1.5233 - val_ca4-[9.5,10.3): 1.1011 - val_ca4-[10.3,11.3): 0.9656 - val_ca4-[11.3,14.9): 0.7046\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5267 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3901 - ca2-[9.5,10.3): 0.5197 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5514 - ca3-[10.3,11.3): 0.7097 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5606 - ca4-[11.3,14.9): 0.6862 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4280 - val_ca1-[10.3,11.3): 0.9479 - val_ca1-[11.3,14.9): 1.6732 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8870 - val_ca2-[11.3,14.9): 1.5390 - val_ca3-[8.0,9.5): 0.8360 - val_ca3-[9.5,10.3): 0.5467 - val_ca3-[10.3,11.3): 0.7321 - val_ca3-[11.3,14.9): 0.9638 - val_ca4-[8.0,9.5): 1.5263 - val_ca4-[9.5,10.3): 1.1037 - val_ca4-[10.3,11.3): 0.9627 - val_ca4-[11.3,14.9): 0.7117\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5254 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3751 - ca2-[9.5,10.3): 0.5198 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5566 - ca3-[10.3,11.3): 0.7368 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5705 - ca4-[11.3,14.9): 0.6918 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4274 - val_ca1-[10.3,11.3): 0.9452 - val_ca1-[11.3,14.9): 1.6351 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8866 - val_ca2-[11.3,14.9): 1.5038 - val_ca3-[8.0,9.5): 0.8360 - val_ca3-[9.5,10.3): 0.5467 - val_ca3-[10.3,11.3): 0.7321 - val_ca3-[11.3,14.9): 0.9178 - val_ca4-[8.0,9.5): 1.5302 - val_ca4-[9.5,10.3): 1.1070 - val_ca4-[10.3,11.3): 0.9647 - val_ca4-[11.3,14.9): 0.6524\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5356 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3863 - ca2-[9.5,10.3): 0.5095 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5690 - ca3-[10.3,11.3): 0.7321 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5196 - ca4-[11.3,14.9): 0.7008 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4268 - val_ca1-[10.3,11.3): 0.9343 - val_ca1-[11.3,14.9): 1.6284 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8781 - val_ca2-[11.3,14.9): 1.5061 - val_ca3-[8.0,9.5): 0.8360 - val_ca3-[9.5,10.3): 0.5467 - val_ca3-[10.3,11.3): 0.7215 - val_ca3-[11.3,14.9): 0.9392 - val_ca4-[8.0,9.5): 1.5336 - val_ca4-[9.5,10.3): 1.1099 - val_ca4-[10.3,11.3): 0.9535 - val_ca4-[11.3,14.9): 0.6961\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5127 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3778 - ca2-[9.5,10.3): 0.5006 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5578 - ca3-[10.3,11.3): 0.7278 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5655 - ca4-[11.3,14.9): 0.6838 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4263 - val_ca1-[10.3,11.3): 0.9321 - val_ca1-[11.3,14.9): 1.6487 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8781 - val_ca2-[11.3,14.9): 1.5298 - val_ca3-[8.0,9.5): 0.8356 - val_ca3-[9.5,10.3): 0.5463 - val_ca3-[10.3,11.3): 0.7214 - val_ca3-[11.3,14.9): 0.9542 - val_ca4-[8.0,9.5): 1.5364 - val_ca4-[9.5,10.3): 1.1123 - val_ca4-[10.3,11.3): 0.9548 - val_ca4-[11.3,14.9): 0.7003\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5131 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3732 - ca2-[9.5,10.3): 0.5186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5617 - ca3-[10.3,11.3): 0.7115 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5968 - ca4-[11.3,14.9): 0.6863 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4257 - val_ca1-[10.3,11.3): 0.9315 - val_ca1-[11.3,14.9): 1.5921 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8805 - val_ca2-[11.3,14.9): 1.4806 - val_ca3-[8.0,9.5): 0.8354 - val_ca3-[9.5,10.3): 0.5462 - val_ca3-[10.3,11.3): 0.7282 - val_ca3-[11.3,14.9): 0.9216 - val_ca4-[8.0,9.5): 1.5388 - val_ca4-[9.5,10.3): 1.1143 - val_ca4-[10.3,11.3): 0.9681 - val_ca4-[11.3,14.9): 0.6871\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5339 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3809 - ca2-[9.5,10.3): 0.5131 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5605 - ca3-[10.3,11.3): 0.7181 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5590 - ca4-[11.3,14.9): 0.6954 - val_ca1-[8.0,9.5): 0.5806 - val_ca1-[9.5,10.3): 0.4253 - val_ca1-[10.3,11.3): 0.9314 - val_ca1-[11.3,14.9): 1.6254 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8823 - val_ca2-[11.3,14.9): 1.5167 - val_ca3-[8.0,9.5): 0.8345 - val_ca3-[9.5,10.3): 0.5455 - val_ca3-[10.3,11.3): 0.7304 - val_ca3-[11.3,14.9): 0.9498 - val_ca4-[8.0,9.5): 1.5409 - val_ca4-[9.5,10.3): 1.1161 - val_ca4-[10.3,11.3): 0.9718 - val_ca4-[11.3,14.9): 0.7041\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5294 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3704 - ca2-[9.5,10.3): 0.5244 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5455 - ca3-[10.3,11.3): 0.7005 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5822 - ca4-[11.3,14.9): 0.6990 - val_ca1-[8.0,9.5): 0.5808 - val_ca1-[9.5,10.3): 0.4249 - val_ca1-[10.3,11.3): 0.9297 - val_ca1-[11.3,14.9): 1.6171 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8823 - val_ca2-[11.3,14.9): 1.5127 - val_ca3-[8.0,9.5): 0.8336 - val_ca3-[9.5,10.3): 0.5448 - val_ca3-[10.3,11.3): 0.7303 - val_ca3-[11.3,14.9): 0.9503 - val_ca4-[8.0,9.5): 1.5433 - val_ca4-[9.5,10.3): 1.1182 - val_ca4-[10.3,11.3): 0.9730 - val_ca4-[11.3,14.9): 0.7079\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5088 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3810 - ca2-[9.5,10.3): 0.5106 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5770 - ca3-[10.3,11.3): 0.7195 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5367 - ca4-[11.3,14.9): 0.7001 - val_ca1-[8.0,9.5): 0.5810 - val_ca1-[9.5,10.3): 0.4245 - val_ca1-[10.3,11.3): 0.9284 - val_ca1-[11.3,14.9): 1.6336 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8818 - val_ca2-[11.3,14.9): 1.5307 - val_ca3-[8.0,9.5): 0.8327 - val_ca3-[9.5,10.3): 0.5441 - val_ca3-[10.3,11.3): 0.7277 - val_ca3-[11.3,14.9): 0.9652 - val_ca4-[8.0,9.5): 1.5461 - val_ca4-[9.5,10.3): 1.1205 - val_ca4-[10.3,11.3): 0.9688 - val_ca4-[11.3,14.9): 0.7159\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5251 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3877 - ca2-[9.5,10.3): 0.5207 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5549 - ca3-[10.3,11.3): 0.7125 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5603 - ca4-[11.3,14.9): 0.7018 - val_ca1-[8.0,9.5): 0.5812 - val_ca1-[9.5,10.3): 0.4242 - val_ca1-[10.3,11.3): 0.9209 - val_ca1-[11.3,14.9): 1.6284 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8752 - val_ca2-[11.3,14.9): 1.5276 - val_ca3-[8.0,9.5): 0.8324 - val_ca3-[9.5,10.3): 0.5440 - val_ca3-[10.3,11.3): 0.7189 - val_ca3-[11.3,14.9): 0.9594 - val_ca4-[8.0,9.5): 1.5480 - val_ca4-[9.5,10.3): 1.1221 - val_ca4-[10.3,11.3): 0.9580 - val_ca4-[11.3,14.9): 0.7056\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5209 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3910 - ca2-[9.5,10.3): 0.5211 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5478 - ca3-[10.3,11.3): 0.7248 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6196 - ca4-[11.3,14.9): 0.7008 - val_ca1-[8.0,9.5): 0.5813 - val_ca1-[9.5,10.3): 0.4239 - val_ca1-[10.3,11.3): 0.9322 - val_ca1-[11.3,14.9): 1.6274 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8880 - val_ca2-[11.3,14.9): 1.5306 - val_ca3-[8.0,9.5): 0.8325 - val_ca3-[9.5,10.3): 0.5439 - val_ca3-[10.3,11.3): 0.7314 - val_ca3-[11.3,14.9): 0.9652 - val_ca4-[8.0,9.5): 1.5498 - val_ca4-[9.5,10.3): 1.1237 - val_ca4-[10.3,11.3): 0.9714 - val_ca4-[11.3,14.9): 0.7158\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5270 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3695 - ca2-[9.5,10.3): 0.5142 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5555 - ca3-[10.3,11.3): 0.7110 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5687 - ca4-[11.3,14.9): 0.6981 - val_ca1-[8.0,9.5): 0.5814 - val_ca1-[9.5,10.3): 0.4237 - val_ca1-[10.3,11.3): 0.9286 - val_ca1-[11.3,14.9): 1.5831 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8860 - val_ca2-[11.3,14.9): 1.4896 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5438 - val_ca3-[10.3,11.3): 0.7316 - val_ca3-[11.3,14.9): 0.9283 - val_ca4-[8.0,9.5): 1.5516 - val_ca4-[9.5,10.3): 1.1252 - val_ca4-[10.3,11.3): 0.9752 - val_ca4-[11.3,14.9): 0.6838\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5187 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3748 - ca2-[9.5,10.3): 0.5211 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5410 - ca3-[10.3,11.3): 0.7138 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5533 - ca4-[11.3,14.9): 0.6797 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4234 - val_ca1-[10.3,11.3): 0.9255 - val_ca1-[11.3,14.9): 1.6274 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8847 - val_ca2-[11.3,14.9): 1.5364 - val_ca3-[8.0,9.5): 0.8327 - val_ca3-[9.5,10.3): 0.5440 - val_ca3-[10.3,11.3): 0.7292 - val_ca3-[11.3,14.9): 0.9602 - val_ca4-[8.0,9.5): 1.5530 - val_ca4-[9.5,10.3): 1.1264 - val_ca4-[10.3,11.3): 0.9733 - val_ca4-[11.3,14.9): 0.7005\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5226 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3680 - ca2-[9.5,10.3): 0.5063 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5546 - ca3-[10.3,11.3): 0.7135 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5761 - ca4-[11.3,14.9): 0.6970 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4233 - val_ca1-[10.3,11.3): 0.9201 - val_ca1-[11.3,14.9): 1.5979 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8804 - val_ca2-[11.3,14.9): 1.5107 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5443 - val_ca3-[10.3,11.3): 0.7277 - val_ca3-[11.3,14.9): 0.9493 - val_ca4-[8.0,9.5): 1.5548 - val_ca4-[9.5,10.3): 1.1280 - val_ca4-[10.3,11.3): 0.9761 - val_ca4-[11.3,14.9): 0.7088\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5200 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3843 - ca2-[9.5,10.3): 0.5173 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5599 - ca3-[10.3,11.3): 0.7216 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5409 - ca4-[11.3,14.9): 0.6915 - val_ca1-[8.0,9.5): 0.5818 - val_ca1-[9.5,10.3): 0.4231 - val_ca1-[10.3,11.3): 0.9194 - val_ca1-[11.3,14.9): 1.6094 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8807 - val_ca2-[11.3,14.9): 1.5241 - val_ca3-[8.0,9.5): 0.8337 - val_ca3-[9.5,10.3): 0.5447 - val_ca3-[10.3,11.3): 0.7276 - val_ca3-[11.3,14.9): 0.9615 - val_ca4-[8.0,9.5): 1.5569 - val_ca4-[9.5,10.3): 1.1298 - val_ca4-[10.3,11.3): 0.9771 - val_ca4-[11.3,14.9): 0.7216\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5092 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3837 - ca2-[9.5,10.3): 0.5148 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5514 - ca3-[10.3,11.3): 0.7174 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5774 - ca4-[11.3,14.9): 0.6938 - val_ca1-[8.0,9.5): 0.5819 - val_ca1-[9.5,10.3): 0.4230 - val_ca1-[10.3,11.3): 0.9233 - val_ca1-[11.3,14.9): 1.5823 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8850 - val_ca2-[11.3,14.9): 1.4986 - val_ca3-[8.0,9.5): 0.8343 - val_ca3-[9.5,10.3): 0.5450 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9325 - val_ca4-[8.0,9.5): 1.5583 - val_ca4-[9.5,10.3): 1.1309 - val_ca4-[10.3,11.3): 0.9760 - val_ca4-[11.3,14.9): 0.6901\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5243 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3784 - ca2-[9.5,10.3): 0.5140 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5250 - ca3-[10.3,11.3): 0.7341 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6011 - ca4-[11.3,14.9): 0.7000 - val_ca1-[8.0,9.5): 0.5820 - val_ca1-[9.5,10.3): 0.4228 - val_ca1-[10.3,11.3): 0.9261 - val_ca1-[11.3,14.9): 1.6129 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8893 - val_ca2-[11.3,14.9): 1.5316 - val_ca3-[8.0,9.5): 0.8339 - val_ca3-[9.5,10.3): 0.5447 - val_ca3-[10.3,11.3): 0.7335 - val_ca3-[11.3,14.9): 0.9598 - val_ca4-[8.0,9.5): 1.5594 - val_ca4-[9.5,10.3): 1.1319 - val_ca4-[10.3,11.3): 0.9817 - val_ca4-[11.3,14.9): 0.7110\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5229 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3818 - ca2-[9.5,10.3): 0.5183 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5433 - ca3-[10.3,11.3): 0.7236 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6107 - ca4-[11.3,14.9): 0.6978 - val_ca1-[8.0,9.5): 0.5821 - val_ca1-[9.5,10.3): 0.4226 - val_ca1-[10.3,11.3): 0.9231 - val_ca1-[11.3,14.9): 1.5608 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8871 - val_ca2-[11.3,14.9): 1.4819 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5440 - val_ca3-[10.3,11.3): 0.7311 - val_ca3-[11.3,14.9): 0.9174 - val_ca4-[8.0,9.5): 1.5606 - val_ca4-[9.5,10.3): 1.1329 - val_ca4-[10.3,11.3): 0.9797 - val_ca4-[11.3,14.9): 0.6755\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5102 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3727 - ca2-[9.5,10.3): 0.5221 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5371 - ca3-[10.3,11.3): 0.7198 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5610 - ca4-[11.3,14.9): 0.7015 - val_ca1-[8.0,9.5): 0.5823 - val_ca1-[9.5,10.3): 0.4224 - val_ca1-[10.3,11.3): 0.9128 - val_ca1-[11.3,14.9): 1.5773 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8783 - val_ca2-[11.3,14.9): 1.5011 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5440 - val_ca3-[10.3,11.3): 0.7280 - val_ca3-[11.3,14.9): 0.9416 - val_ca4-[8.0,9.5): 1.5624 - val_ca4-[9.5,10.3): 1.1345 - val_ca4-[10.3,11.3): 0.9844 - val_ca4-[11.3,14.9): 0.7061\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5182 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3650 - ca2-[9.5,10.3): 0.5247 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5377 - ca3-[10.3,11.3): 0.7203 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6078 - ca4-[11.3,14.9): 0.6985 - val_ca1-[8.0,9.5): 0.5824 - val_ca1-[9.5,10.3): 0.4222 - val_ca1-[10.3,11.3): 0.9194 - val_ca1-[11.3,14.9): 1.5806 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8854 - val_ca2-[11.3,14.9): 1.5063 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5439 - val_ca3-[10.3,11.3): 0.7286 - val_ca3-[11.3,14.9): 0.9368 - val_ca4-[8.0,9.5): 1.5632 - val_ca4-[9.5,10.3): 1.1351 - val_ca4-[10.3,11.3): 0.9784 - val_ca4-[11.3,14.9): 0.6908\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5225 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3841 - ca2-[9.5,10.3): 0.5203 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5368 - ca3-[10.3,11.3): 0.7141 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5443 - ca4-[11.3,14.9): 0.6934 - val_ca1-[8.0,9.5): 0.5825 - val_ca1-[9.5,10.3): 0.4221 - val_ca1-[10.3,11.3): 0.9122 - val_ca1-[11.3,14.9): 1.5752 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8784 - val_ca2-[11.3,14.9): 1.5012 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5433 - val_ca3-[10.3,11.3): 0.7203 - val_ca3-[11.3,14.9): 0.9319 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1352 - val_ca4-[10.3,11.3): 0.9681 - val_ca4-[11.3,14.9): 0.6833\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5238 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3664 - ca2-[9.5,10.3): 0.5063 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5276 - ca3-[10.3,11.3): 0.7125 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5875 - ca4-[11.3,14.9): 0.6804 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9177 - val_ca1-[11.3,14.9): 1.5915 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8845 - val_ca2-[11.3,14.9): 1.5187 - val_ca3-[8.0,9.5): 0.8317 - val_ca3-[9.5,10.3): 0.5428 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9521 - val_ca4-[8.0,9.5): 1.5622 - val_ca4-[9.5,10.3): 1.1343 - val_ca4-[10.3,11.3): 0.9795 - val_ca4-[11.3,14.9): 0.7055\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5188 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3812 - ca2-[9.5,10.3): 0.5155 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5653 - ca3-[10.3,11.3): 0.7041 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6103 - ca4-[11.3,14.9): 0.6941 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9173 - val_ca1-[11.3,14.9): 1.5858 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8843 - val_ca2-[11.3,14.9): 1.5136 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5423 - val_ca3-[10.3,11.3): 0.7314 - val_ca3-[11.3,14.9): 0.9534 - val_ca4-[8.0,9.5): 1.5618 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9848 - val_ca4-[11.3,14.9): 0.7133\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5240 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3769 - ca2-[9.5,10.3): 0.5229 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5328 - ca3-[10.3,11.3): 0.7117 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5746 - ca4-[11.3,14.9): 0.6980 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9177 - val_ca1-[11.3,14.9): 1.6294 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4164 - val_ca2-[10.3,11.3): 0.8842 - val_ca2-[11.3,14.9): 1.5554 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5422 - val_ca3-[10.3,11.3): 0.7283 - val_ca3-[11.3,14.9): 0.9822 - val_ca4-[8.0,9.5): 1.5618 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9777 - val_ca4-[11.3,14.9): 0.7253\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5234 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3782 - ca2-[9.5,10.3): 0.5320 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5715 - ca3-[10.3,11.3): 0.7250 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5844 - ca4-[11.3,14.9): 0.7000 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9216 - val_ca1-[11.3,14.9): 1.5860 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4164 - val_ca2-[10.3,11.3): 0.8880 - val_ca2-[11.3,14.9): 1.5123 - val_ca3-[8.0,9.5): 0.8312 - val_ca3-[9.5,10.3): 0.5423 - val_ca3-[10.3,11.3): 0.7327 - val_ca3-[11.3,14.9): 0.9453 - val_ca4-[8.0,9.5): 1.5624 - val_ca4-[9.5,10.3): 1.1344 - val_ca4-[10.3,11.3): 0.9832 - val_ca4-[11.3,14.9): 0.6962\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5082 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3603 - ca2-[9.5,10.3): 0.4929 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5519 - ca3-[10.3,11.3): 0.7220 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5836 - ca4-[11.3,14.9): 0.7022 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9152 - val_ca1-[11.3,14.9): 1.6121 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4164 - val_ca2-[10.3,11.3): 0.8819 - val_ca2-[11.3,14.9): 1.5385 - val_ca3-[8.0,9.5): 0.8317 - val_ca3-[9.5,10.3): 0.5426 - val_ca3-[10.3,11.3): 0.7289 - val_ca3-[11.3,14.9): 0.9706 - val_ca4-[8.0,9.5): 1.5625 - val_ca4-[9.5,10.3): 1.1345 - val_ca4-[10.3,11.3): 0.9826 - val_ca4-[11.3,14.9): 0.7219\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5272 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3811 - ca2-[9.5,10.3): 0.5095 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5522 - ca3-[10.3,11.3): 0.6980 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5524 - ca4-[11.3,14.9): 0.6990 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9041 - val_ca1-[11.3,14.9): 1.5727 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4164 - val_ca2-[10.3,11.3): 0.8716 - val_ca2-[11.3,14.9): 1.5009 - val_ca3-[8.0,9.5): 0.8316 - val_ca3-[9.5,10.3): 0.5425 - val_ca3-[10.3,11.3): 0.7210 - val_ca3-[11.3,14.9): 0.9346 - val_ca4-[8.0,9.5): 1.5628 - val_ca4-[9.5,10.3): 1.1348 - val_ca4-[10.3,11.3): 0.9783 - val_ca4-[11.3,14.9): 0.6890\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5158 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3853 - ca2-[9.5,10.3): 0.5153 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5291 - ca3-[10.3,11.3): 0.7152 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5899 - ca4-[11.3,14.9): 0.6880 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9174 - val_ca1-[11.3,14.9): 1.5950 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8846 - val_ca2-[11.3,14.9): 1.5242 - val_ca3-[8.0,9.5): 0.8320 - val_ca3-[9.5,10.3): 0.5427 - val_ca3-[10.3,11.3): 0.7279 - val_ca3-[11.3,14.9): 0.9615 - val_ca4-[8.0,9.5): 1.5626 - val_ca4-[9.5,10.3): 1.1346 - val_ca4-[10.3,11.3): 0.9781 - val_ca4-[11.3,14.9): 0.7215\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5195 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3740 - ca2-[9.5,10.3): 0.5137 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5623 - ca3-[10.3,11.3): 0.7305 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5953 - ca4-[11.3,14.9): 0.7016 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9194 - val_ca1-[11.3,14.9): 1.5979 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8866 - val_ca2-[11.3,14.9): 1.5268 - val_ca3-[8.0,9.5): 0.8320 - val_ca3-[9.5,10.3): 0.5426 - val_ca3-[10.3,11.3): 0.7301 - val_ca3-[11.3,14.9): 0.9596 - val_ca4-[8.0,9.5): 1.5630 - val_ca4-[9.5,10.3): 1.1349 - val_ca4-[10.3,11.3): 0.9808 - val_ca4-[11.3,14.9): 0.7147\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5209 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3618 - ca2-[9.5,10.3): 0.5141 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5287 - ca3-[10.3,11.3): 0.7215 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5858 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9144 - val_ca1-[11.3,14.9): 1.5615 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8827 - val_ca2-[11.3,14.9): 1.4933 - val_ca3-[8.0,9.5): 0.8315 - val_ca3-[9.5,10.3): 0.5423 - val_ca3-[10.3,11.3): 0.7284 - val_ca3-[11.3,14.9): 0.9346 - val_ca4-[8.0,9.5): 1.5637 - val_ca4-[9.5,10.3): 1.1355 - val_ca4-[10.3,11.3): 0.9831 - val_ca4-[11.3,14.9): 0.7006\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5044 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3739 - ca2-[9.5,10.3): 0.5086 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5549 - ca3-[10.3,11.3): 0.7341 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5694 - ca4-[11.3,14.9): 0.6986 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.5962 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8846 - val_ca2-[11.3,14.9): 1.5247 - val_ca3-[8.0,9.5): 0.8313 - val_ca3-[9.5,10.3): 0.5420 - val_ca3-[10.3,11.3): 0.7275 - val_ca3-[11.3,14.9): 0.9461 - val_ca4-[8.0,9.5): 1.5641 - val_ca4-[9.5,10.3): 1.1358 - val_ca4-[10.3,11.3): 0.9788 - val_ca4-[11.3,14.9): 0.6872\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5116 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3827 - ca2-[9.5,10.3): 0.5146 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5501 - ca3-[10.3,11.3): 0.7197 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5670 - ca4-[11.3,14.9): 0.6979 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9124 - val_ca1-[11.3,14.9): 1.6082 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4162 - val_ca2-[10.3,11.3): 0.8795 - val_ca2-[11.3,14.9): 1.5362 - val_ca3-[8.0,9.5): 0.8303 - val_ca3-[9.5,10.3): 0.5412 - val_ca3-[10.3,11.3): 0.7255 - val_ca3-[11.3,14.9): 0.9643 - val_ca4-[8.0,9.5): 1.5651 - val_ca4-[9.5,10.3): 1.1367 - val_ca4-[10.3,11.3): 0.9812 - val_ca4-[11.3,14.9): 0.7115\n",
      "Epoch 129/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5088 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3630 - ca2-[9.5,10.3): 0.5064 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5684 - ca3-[10.3,11.3): 0.7131 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5644 - ca4-[11.3,14.9): 0.7059 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9190 - val_ca1-[11.3,14.9): 1.5843 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4161 - val_ca2-[10.3,11.3): 0.8858 - val_ca2-[11.3,14.9): 1.5127 - val_ca3-[8.0,9.5): 0.8301 - val_ca3-[9.5,10.3): 0.5409 - val_ca3-[10.3,11.3): 0.7294 - val_ca3-[11.3,14.9): 0.9474 - val_ca4-[8.0,9.5): 1.5660 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9823 - val_ca4-[11.3,14.9): 0.7018\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5182 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3780 - ca2-[9.5,10.3): 0.5196 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5492 - ca3-[10.3,11.3): 0.7268 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5582 - ca4-[11.3,14.9): 0.6762 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9188 - val_ca1-[11.3,14.9): 1.5671 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4161 - val_ca2-[10.3,11.3): 0.8857 - val_ca2-[11.3,14.9): 1.4969 - val_ca3-[8.0,9.5): 0.8301 - val_ca3-[9.5,10.3): 0.5409 - val_ca3-[10.3,11.3): 0.7293 - val_ca3-[11.3,14.9): 0.9434 - val_ca4-[8.0,9.5): 1.5672 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9829 - val_ca4-[11.3,14.9): 0.7128\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5215 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3681 - ca2-[9.5,10.3): 0.5075 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5596 - ca3-[10.3,11.3): 0.7086 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5816 - ca4-[11.3,14.9): 0.6911 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9187 - val_ca1-[11.3,14.9): 1.5762 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4161 - val_ca2-[10.3,11.3): 0.8860 - val_ca2-[11.3,14.9): 1.5067 - val_ca3-[8.0,9.5): 0.8316 - val_ca3-[9.5,10.3): 0.5419 - val_ca3-[10.3,11.3): 0.7267 - val_ca3-[11.3,14.9): 0.9417 - val_ca4-[8.0,9.5): 1.5675 - val_ca4-[9.5,10.3): 1.1388 - val_ca4-[10.3,11.3): 0.9775 - val_ca4-[11.3,14.9): 0.7010\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5072 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3738 - ca2-[9.5,10.3): 0.5103 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5465 - ca3-[10.3,11.3): 0.7331 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5798 - ca4-[11.3,14.9): 0.6928 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9201 - val_ca1-[11.3,14.9): 1.5812 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4161 - val_ca2-[10.3,11.3): 0.8883 - val_ca2-[11.3,14.9): 1.5139 - val_ca3-[8.0,9.5): 0.8313 - val_ca3-[9.5,10.3): 0.5416 - val_ca3-[10.3,11.3): 0.7288 - val_ca3-[11.3,14.9): 0.9508 - val_ca4-[8.0,9.5): 1.5672 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9800 - val_ca4-[11.3,14.9): 0.7132\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5208 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3715 - ca2-[9.5,10.3): 0.5270 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5454 - ca3-[10.3,11.3): 0.7172 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5170 - ca4-[11.3,14.9): 0.6933 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9176 - val_ca1-[11.3,14.9): 1.5876 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4161 - val_ca2-[10.3,11.3): 0.8866 - val_ca2-[11.3,14.9): 1.5212 - val_ca3-[8.0,9.5): 0.8313 - val_ca3-[9.5,10.3): 0.5415 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9519 - val_ca4-[8.0,9.5): 1.5667 - val_ca4-[9.5,10.3): 1.1381 - val_ca4-[10.3,11.3): 0.9827 - val_ca4-[11.3,14.9): 0.7082\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5195 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3785 - ca2-[9.5,10.3): 0.5127 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5179 - ca3-[10.3,11.3): 0.7084 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5686 - ca4-[11.3,14.9): 0.6873 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9156 - val_ca1-[11.3,14.9): 1.5583 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8849 - val_ca2-[11.3,14.9): 1.4934 - val_ca3-[8.0,9.5): 0.8313 - val_ca3-[9.5,10.3): 0.5415 - val_ca3-[10.3,11.3): 0.7267 - val_ca3-[11.3,14.9): 0.9327 - val_ca4-[8.0,9.5): 1.5665 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9799 - val_ca4-[11.3,14.9): 0.7006\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5299 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3670 - ca2-[9.5,10.3): 0.5221 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5822 - ca3-[10.3,11.3): 0.7158 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5750 - ca4-[11.3,14.9): 0.6852 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9129 - val_ca1-[11.3,14.9): 1.5874 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8823 - val_ca2-[11.3,14.9): 1.5218 - val_ca3-[8.0,9.5): 0.8316 - val_ca3-[9.5,10.3): 0.5416 - val_ca3-[10.3,11.3): 0.7274 - val_ca3-[11.3,14.9): 0.9514 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9841 - val_ca4-[11.3,14.9): 0.7081\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5243 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3885 - ca2-[9.5,10.3): 0.5181 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5632 - ca3-[10.3,11.3): 0.7177 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5365 - ca4-[11.3,14.9): 0.6946 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9073 - val_ca1-[11.3,14.9): 1.5791 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4159 - val_ca2-[10.3,11.3): 0.8763 - val_ca2-[11.3,14.9): 1.5132 - val_ca3-[8.0,9.5): 0.8319 - val_ca3-[9.5,10.3): 0.5419 - val_ca3-[10.3,11.3): 0.7162 - val_ca3-[11.3,14.9): 0.9412 - val_ca4-[8.0,9.5): 1.5655 - val_ca4-[9.5,10.3): 1.1370 - val_ca4-[10.3,11.3): 0.9665 - val_ca4-[11.3,14.9): 0.6970\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5218 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3698 - ca2-[9.5,10.3): 0.5156 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5477 - ca3-[10.3,11.3): 0.7221 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5847 - ca4-[11.3,14.9): 0.6959 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9109 - val_ca1-[11.3,14.9): 1.5446 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4159 - val_ca2-[10.3,11.3): 0.8800 - val_ca2-[11.3,14.9): 1.4801 - val_ca3-[8.0,9.5): 0.8320 - val_ca3-[9.5,10.3): 0.5418 - val_ca3-[10.3,11.3): 0.7250 - val_ca3-[11.3,14.9): 0.9244 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1377 - val_ca4-[10.3,11.3): 0.9817 - val_ca4-[11.3,14.9): 0.6991\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5182 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3813 - ca2-[9.5,10.3): 0.5155 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5780 - ca3-[10.3,11.3): 0.7159 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5962 - ca4-[11.3,14.9): 0.6895 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5763 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4157 - val_ca2-[10.3,11.3): 0.8857 - val_ca2-[11.3,14.9): 1.5110 - val_ca3-[8.0,9.5): 0.8314 - val_ca3-[9.5,10.3): 0.5414 - val_ca3-[10.3,11.3): 0.7286 - val_ca3-[11.3,14.9): 0.9492 - val_ca4-[8.0,9.5): 1.5675 - val_ca4-[9.5,10.3): 1.1387 - val_ca4-[10.3,11.3): 0.9830 - val_ca4-[11.3,14.9): 0.7142\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5092 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3659 - ca2-[9.5,10.3): 0.5148 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5331 - ca3-[10.3,11.3): 0.7141 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5777 - ca4-[11.3,14.9): 0.7068 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9164 - val_ca1-[11.3,14.9): 1.5499 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4157 - val_ca2-[10.3,11.3): 0.8858 - val_ca2-[11.3,14.9): 1.4857 - val_ca3-[8.0,9.5): 0.8310 - val_ca3-[9.5,10.3): 0.5410 - val_ca3-[10.3,11.3): 0.7285 - val_ca3-[11.3,14.9): 0.9210 - val_ca4-[8.0,9.5): 1.5670 - val_ca4-[9.5,10.3): 1.1382 - val_ca4-[10.3,11.3): 0.9827 - val_ca4-[11.3,14.9): 0.6826\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5226 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3634 - ca2-[9.5,10.3): 0.5103 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5597 - ca3-[10.3,11.3): 0.6993 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5659 - ca4-[11.3,14.9): 0.7071 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5685 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4156 - val_ca2-[10.3,11.3): 0.8856 - val_ca2-[11.3,14.9): 1.5046 - val_ca3-[8.0,9.5): 0.8312 - val_ca3-[9.5,10.3): 0.5411 - val_ca3-[10.3,11.3): 0.7284 - val_ca3-[11.3,14.9): 0.9425 - val_ca4-[8.0,9.5): 1.5672 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9828 - val_ca4-[11.3,14.9): 0.7077\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5181 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3623 - ca2-[9.5,10.3): 0.5155 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5462 - ca3-[10.3,11.3): 0.7086 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5154 - ca4-[11.3,14.9): 0.6942 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9094 - val_ca1-[11.3,14.9): 1.5825 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4156 - val_ca2-[10.3,11.3): 0.8792 - val_ca2-[11.3,14.9): 1.5175 - val_ca3-[8.0,9.5): 0.8308 - val_ca3-[9.5,10.3): 0.5407 - val_ca3-[10.3,11.3): 0.7246 - val_ca3-[11.3,14.9): 0.9402 - val_ca4-[8.0,9.5): 1.5672 - val_ca4-[9.5,10.3): 1.1384 - val_ca4-[10.3,11.3): 0.9821 - val_ca4-[11.3,14.9): 0.6862\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5193 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3585 - ca2-[9.5,10.3): 0.5071 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5600 - ca3-[10.3,11.3): 0.7252 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6044 - ca4-[11.3,14.9): 0.6963 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9183 - val_ca1-[11.3,14.9): 1.5710 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4155 - val_ca2-[10.3,11.3): 0.8871 - val_ca2-[11.3,14.9): 1.5062 - val_ca3-[8.0,9.5): 0.8310 - val_ca3-[9.5,10.3): 0.5408 - val_ca3-[10.3,11.3): 0.7279 - val_ca3-[11.3,14.9): 0.9433 - val_ca4-[8.0,9.5): 1.5668 - val_ca4-[9.5,10.3): 1.1381 - val_ca4-[10.3,11.3): 0.9796 - val_ca4-[11.3,14.9): 0.7066\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5140 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3712 - ca2-[9.5,10.3): 0.5128 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5254 - ca3-[10.3,11.3): 0.7313 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5718 - ca4-[11.3,14.9): 0.6957 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9165 - val_ca1-[11.3,14.9): 1.5960 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4153 - val_ca2-[10.3,11.3): 0.8840 - val_ca2-[11.3,14.9): 1.5276 - val_ca3-[8.0,9.5): 0.8319 - val_ca3-[9.5,10.3): 0.5414 - val_ca3-[10.3,11.3): 0.7282 - val_ca3-[11.3,14.9): 0.9574 - val_ca4-[8.0,9.5): 1.5683 - val_ca4-[9.5,10.3): 1.1393 - val_ca4-[10.3,11.3): 0.9833 - val_ca4-[11.3,14.9): 0.7106\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5172 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3872 - ca2-[9.5,10.3): 0.5232 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5252 - ca3-[10.3,11.3): 0.6963 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5580 - ca4-[11.3,14.9): 0.7017 - val_ca1-[8.0,9.5): 0.5839 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9119 - val_ca1-[11.3,14.9): 1.5873 - val_ca2-[8.0,9.5): 0.5892 - val_ca2-[9.5,10.3): 0.4157 - val_ca2-[10.3,11.3): 0.8790 - val_ca2-[11.3,14.9): 1.5178 - val_ca3-[8.0,9.5): 0.8354 - val_ca3-[9.5,10.3): 0.5439 - val_ca3-[10.3,11.3): 0.7266 - val_ca3-[11.3,14.9): 0.9551 - val_ca4-[8.0,9.5): 1.5736 - val_ca4-[9.5,10.3): 1.1436 - val_ca4-[10.3,11.3): 0.9858 - val_ca4-[11.3,14.9): 0.7183\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5222 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3841 - ca2-[9.5,10.3): 0.5136 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5493 - ca3-[10.3,11.3): 0.7258 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5910 - ca4-[11.3,14.9): 0.6912 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9101 - val_ca1-[11.3,14.9): 1.5829 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4152 - val_ca2-[10.3,11.3): 0.8777 - val_ca2-[11.3,14.9): 1.5148 - val_ca3-[8.0,9.5): 0.8327 - val_ca3-[9.5,10.3): 0.5419 - val_ca3-[10.3,11.3): 0.7243 - val_ca3-[11.3,14.9): 0.9488 - val_ca4-[8.0,9.5): 1.5699 - val_ca4-[9.5,10.3): 1.1407 - val_ca4-[10.3,11.3): 0.9834 - val_ca4-[11.3,14.9): 0.7091\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5179 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3722 - ca2-[9.5,10.3): 0.5109 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5805 - ca3-[10.3,11.3): 0.6996 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5787 - ca4-[11.3,14.9): 0.6918 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9146 - val_ca1-[11.3,14.9): 1.5822 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4151 - val_ca2-[10.3,11.3): 0.8819 - val_ca2-[11.3,14.9): 1.5147 - val_ca3-[8.0,9.5): 0.8322 - val_ca3-[9.5,10.3): 0.5414 - val_ca3-[10.3,11.3): 0.7256 - val_ca3-[11.3,14.9): 0.9541 - val_ca4-[8.0,9.5): 1.5700 - val_ca4-[9.5,10.3): 1.1408 - val_ca4-[10.3,11.3): 0.9815 - val_ca4-[11.3,14.9): 0.7205\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5084 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3723 - ca2-[9.5,10.3): 0.5143 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5392 - ca3-[10.3,11.3): 0.7196 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5813 - ca4-[11.3,14.9): 0.6835 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9121 - val_ca1-[11.3,14.9): 1.5797 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4150 - val_ca2-[10.3,11.3): 0.8794 - val_ca2-[11.3,14.9): 1.5104 - val_ca3-[8.0,9.5): 0.8320 - val_ca3-[9.5,10.3): 0.5412 - val_ca3-[10.3,11.3): 0.7263 - val_ca3-[11.3,14.9): 0.9382 - val_ca4-[8.0,9.5): 1.5701 - val_ca4-[9.5,10.3): 1.1408 - val_ca4-[10.3,11.3): 0.9861 - val_ca4-[11.3,14.9): 0.6901\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3787 - ca2-[9.5,10.3): 0.5015 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5692 - ca3-[10.3,11.3): 0.7021 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5740 - ca4-[11.3,14.9): 0.6848 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9151 - val_ca1-[11.3,14.9): 1.5841 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.4149 - val_ca2-[10.3,11.3): 0.8818 - val_ca2-[11.3,14.9): 1.5147 - val_ca3-[8.0,9.5): 0.8315 - val_ca3-[9.5,10.3): 0.5408 - val_ca3-[10.3,11.3): 0.7254 - val_ca3-[11.3,14.9): 0.9467 - val_ca4-[8.0,9.5): 1.5702 - val_ca4-[9.5,10.3): 1.1409 - val_ca4-[10.3,11.3): 0.9816 - val_ca4-[11.3,14.9): 0.7033\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5329 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3671 - ca2-[9.5,10.3): 0.5157 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5399 - ca3-[10.3,11.3): 0.7099 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5148 - ca4-[11.3,14.9): 0.6668 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9191 - val_ca1-[11.3,14.9): 1.5424 - val_ca2-[8.0,9.5): 0.5876 - val_ca2-[9.5,10.3): 0.4149 - val_ca2-[10.3,11.3): 0.8858 - val_ca2-[11.3,14.9): 1.4750 - val_ca3-[8.0,9.5): 0.8317 - val_ca3-[9.5,10.3): 0.5408 - val_ca3-[10.3,11.3): 0.7273 - val_ca3-[11.3,14.9): 0.9187 - val_ca4-[8.0,9.5): 1.5713 - val_ca4-[9.5,10.3): 1.1419 - val_ca4-[10.3,11.3): 0.9818 - val_ca4-[11.3,14.9): 0.6905\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5254 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3651 - ca2-[9.5,10.3): 0.5132 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5717 - ca3-[10.3,11.3): 0.7283 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5434 - ca4-[11.3,14.9): 0.6960 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.5441 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.4148 - val_ca2-[10.3,11.3): 0.8815 - val_ca2-[11.3,14.9): 1.4760 - val_ca3-[8.0,9.5): 0.8309 - val_ca3-[9.5,10.3): 0.5402 - val_ca3-[10.3,11.3): 0.7251 - val_ca3-[11.3,14.9): 0.9083 - val_ca4-[8.0,9.5): 1.5712 - val_ca4-[9.5,10.3): 1.1418 - val_ca4-[10.3,11.3): 0.9821 - val_ca4-[11.3,14.9): 0.6645\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5282 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3737 - ca2-[9.5,10.3): 0.5160 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5461 - ca3-[10.3,11.3): 0.7168 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5432 - ca4-[11.3,14.9): 0.6914 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5750 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.4146 - val_ca2-[10.3,11.3): 0.8832 - val_ca2-[11.3,14.9): 1.5077 - val_ca3-[8.0,9.5): 0.8307 - val_ca3-[9.5,10.3): 0.5399 - val_ca3-[10.3,11.3): 0.7272 - val_ca3-[11.3,14.9): 0.9484 - val_ca4-[8.0,9.5): 1.5705 - val_ca4-[9.5,10.3): 1.1411 - val_ca4-[10.3,11.3): 0.9843 - val_ca4-[11.3,14.9): 0.7140\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5209 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3648 - ca2-[9.5,10.3): 0.5135 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5841 - ca3-[10.3,11.3): 0.7186 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5593 - ca4-[11.3,14.9): 0.6974 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9141 - val_ca1-[11.3,14.9): 1.5733 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.4152 - val_ca2-[10.3,11.3): 0.8816 - val_ca2-[11.3,14.9): 1.5080 - val_ca3-[8.0,9.5): 0.8308 - val_ca3-[9.5,10.3): 0.5391 - val_ca3-[10.3,11.3): 0.7229 - val_ca3-[11.3,14.9): 0.9486 - val_ca4-[8.0,9.5): 1.5688 - val_ca4-[9.5,10.3): 1.1370 - val_ca4-[10.3,11.3): 0.9767 - val_ca4-[11.3,14.9): 0.7168\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5145 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3667 - ca2-[9.5,10.3): 0.5122 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5674 - ca3-[10.3,11.3): 0.7207 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5463 - ca4-[11.3,14.9): 0.6886 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9166 - val_ca1-[11.3,14.9): 1.5899 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.4145 - val_ca2-[10.3,11.3): 0.8837 - val_ca2-[11.3,14.9): 1.5221 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5401 - val_ca3-[10.3,11.3): 0.7270 - val_ca3-[11.3,14.9): 0.9502 - val_ca4-[8.0,9.5): 1.5676 - val_ca4-[9.5,10.3): 1.1386 - val_ca4-[10.3,11.3): 0.9828 - val_ca4-[11.3,14.9): 0.7040\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5161 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3640 - ca2-[9.5,10.3): 0.5099 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5550 - ca3-[10.3,11.3): 0.7112 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5252 - ca4-[11.3,14.9): 0.6935 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5570 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.4144 - val_ca2-[10.3,11.3): 0.8832 - val_ca2-[11.3,14.9): 1.4898 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5400 - val_ca3-[10.3,11.3): 0.7268 - val_ca3-[11.3,14.9): 0.9288 - val_ca4-[8.0,9.5): 1.5675 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9827 - val_ca4-[11.3,14.9): 0.6946\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5190 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3828 - ca2-[9.5,10.3): 0.5127 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5319 - ca3-[10.3,11.3): 0.6929 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5678 - ca4-[11.3,14.9): 0.6958 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9167 - val_ca1-[11.3,14.9): 1.6031 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.4143 - val_ca2-[10.3,11.3): 0.8833 - val_ca2-[11.3,14.9): 1.5350 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5413 - val_ca3-[10.3,11.3): 0.7268 - val_ca3-[11.3,14.9): 0.9611 - val_ca4-[8.0,9.5): 1.5684 - val_ca4-[9.5,10.3): 1.1392 - val_ca4-[10.3,11.3): 0.9831 - val_ca4-[11.3,14.9): 0.7168\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5131 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3703 - ca2-[9.5,10.3): 0.5097 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5830 - ca3-[10.3,11.3): 0.7258 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5964 - ca4-[11.3,14.9): 0.6913 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9058 - val_ca1-[11.3,14.9): 1.5597 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.4141 - val_ca2-[10.3,11.3): 0.8717 - val_ca2-[11.3,14.9): 1.4898 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5412 - val_ca3-[10.3,11.3): 0.7215 - val_ca3-[11.3,14.9): 0.9294 - val_ca4-[8.0,9.5): 1.5684 - val_ca4-[9.5,10.3): 1.1393 - val_ca4-[10.3,11.3): 0.9843 - val_ca4-[11.3,14.9): 0.6992\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5145 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3701 - ca2-[9.5,10.3): 0.5102 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5490 - ca3-[10.3,11.3): 0.7241 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5905 - ca4-[11.3,14.9): 0.6961 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9170 - val_ca1-[11.3,14.9): 1.5608 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.4140 - val_ca2-[10.3,11.3): 0.8827 - val_ca2-[11.3,14.9): 1.4923 - val_ca3-[8.0,9.5): 0.8330 - val_ca3-[9.5,10.3): 0.5410 - val_ca3-[10.3,11.3): 0.7264 - val_ca3-[11.3,14.9): 0.9202 - val_ca4-[8.0,9.5): 1.5682 - val_ca4-[9.5,10.3): 1.1390 - val_ca4-[10.3,11.3): 0.9830 - val_ca4-[11.3,14.9): 0.6766\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5267 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3914 - ca2-[9.5,10.3): 0.5207 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5510 - ca3-[10.3,11.3): 0.7262 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5746 - ca4-[11.3,14.9): 0.6808 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9169 - val_ca1-[11.3,14.9): 1.5774 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.4139 - val_ca2-[10.3,11.3): 0.8832 - val_ca2-[11.3,14.9): 1.5099 - val_ca3-[8.0,9.5): 0.8324 - val_ca3-[9.5,10.3): 0.5404 - val_ca3-[10.3,11.3): 0.7262 - val_ca3-[11.3,14.9): 0.9380 - val_ca4-[8.0,9.5): 1.5673 - val_ca4-[9.5,10.3): 1.1383 - val_ca4-[10.3,11.3): 0.9825 - val_ca4-[11.3,14.9): 0.6967\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5173 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3749 - ca2-[9.5,10.3): 0.5164 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5365 - ca3-[10.3,11.3): 0.7022 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6002 - ca4-[11.3,14.9): 0.7097 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9169 - val_ca1-[11.3,14.9): 1.6035 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.4138 - val_ca2-[10.3,11.3): 0.8833 - val_ca2-[11.3,14.9): 1.5364 - val_ca3-[8.0,9.5): 0.8316 - val_ca3-[9.5,10.3): 0.5396 - val_ca3-[10.3,11.3): 0.7259 - val_ca3-[11.3,14.9): 0.9618 - val_ca4-[8.0,9.5): 1.5668 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9822 - val_ca4-[11.3,14.9): 0.7167\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3612 - ca2-[9.5,10.3): 0.5091 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5449 - ca3-[10.3,11.3): 0.7218 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5379 - ca4-[11.3,14.9): 0.6804 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9149 - val_ca1-[11.3,14.9): 1.5840 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.4136 - val_ca2-[10.3,11.3): 0.8802 - val_ca2-[11.3,14.9): 1.5160 - val_ca3-[8.0,9.5): 0.8299 - val_ca3-[9.5,10.3): 0.5380 - val_ca3-[10.3,11.3): 0.7232 - val_ca3-[11.3,14.9): 0.9447 - val_ca4-[8.0,9.5): 1.5665 - val_ca4-[9.5,10.3): 1.1375 - val_ca4-[10.3,11.3): 0.9794 - val_ca4-[11.3,14.9): 0.6975\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5224 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3743 - ca2-[9.5,10.3): 0.5204 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5231 - ca3-[10.3,11.3): 0.7053 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5613 - ca4-[11.3,14.9): 0.6916 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9148 - val_ca1-[11.3,14.9): 1.5969 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.4133 - val_ca2-[10.3,11.3): 0.8793 - val_ca2-[11.3,14.9): 1.5264 - val_ca3-[8.0,9.5): 0.8299 - val_ca3-[9.5,10.3): 0.5378 - val_ca3-[10.3,11.3): 0.7186 - val_ca3-[11.3,14.9): 0.9517 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1370 - val_ca4-[10.3,11.3): 0.9695 - val_ca4-[11.3,14.9): 0.6988\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5074 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3852 - ca2-[9.5,10.3): 0.5064 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5502 - ca3-[10.3,11.3): 0.7067 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5413 - ca4-[11.3,14.9): 0.6998 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9098 - val_ca1-[11.3,14.9): 1.5692 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.4132 - val_ca2-[10.3,11.3): 0.8745 - val_ca2-[11.3,14.9): 1.4997 - val_ca3-[8.0,9.5): 0.8305 - val_ca3-[9.5,10.3): 0.5381 - val_ca3-[10.3,11.3): 0.7208 - val_ca3-[11.3,14.9): 0.9374 - val_ca4-[8.0,9.5): 1.5661 - val_ca4-[9.5,10.3): 1.1371 - val_ca4-[10.3,11.3): 0.9810 - val_ca4-[11.3,14.9): 0.7015\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5278 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3733 - ca2-[9.5,10.3): 0.5126 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5500 - ca3-[10.3,11.3): 0.7166 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5487 - ca4-[11.3,14.9): 0.6878 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9162 - val_ca1-[11.3,14.9): 1.5642 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.4129 - val_ca2-[10.3,11.3): 0.8805 - val_ca2-[11.3,14.9): 1.4951 - val_ca3-[8.0,9.5): 0.8300 - val_ca3-[9.5,10.3): 0.5374 - val_ca3-[10.3,11.3): 0.7221 - val_ca3-[11.3,14.9): 0.9353 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9763 - val_ca4-[11.3,14.9): 0.6998\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5265 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3773 - ca2-[9.5,10.3): 0.5016 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5352 - ca3-[10.3,11.3): 0.7073 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5790 - ca4-[11.3,14.9): 0.6902 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9117 - val_ca1-[11.3,14.9): 1.6006 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.4126 - val_ca2-[10.3,11.3): 0.8751 - val_ca2-[11.3,14.9): 1.5276 - val_ca3-[8.0,9.5): 0.8280 - val_ca3-[9.5,10.3): 0.5356 - val_ca3-[10.3,11.3): 0.7158 - val_ca3-[11.3,14.9): 0.9550 - val_ca4-[8.0,9.5): 1.5655 - val_ca4-[9.5,10.3): 1.1366 - val_ca4-[10.3,11.3): 0.9681 - val_ca4-[11.3,14.9): 0.6967\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5161 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3858 - ca2-[9.5,10.3): 0.5062 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5470 - ca3-[10.3,11.3): 0.7106 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5725 - ca4-[11.3,14.9): 0.6783 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9142 - val_ca1-[11.3,14.9): 1.5487 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.4126 - val_ca2-[10.3,11.3): 0.8783 - val_ca2-[11.3,14.9): 1.4802 - val_ca3-[8.0,9.5): 0.8286 - val_ca3-[9.5,10.3): 0.5356 - val_ca3-[10.3,11.3): 0.7216 - val_ca3-[11.3,14.9): 0.9277 - val_ca4-[8.0,9.5): 1.5655 - val_ca4-[9.5,10.3): 1.1366 - val_ca4-[10.3,11.3): 0.9788 - val_ca4-[11.3,14.9): 0.6993\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5182 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3760 - ca2-[9.5,10.3): 0.5159 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5228 - ca3-[10.3,11.3): 0.6970 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5564 - ca4-[11.3,14.9): 0.6929 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5737 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.4124 - val_ca2-[10.3,11.3): 0.8783 - val_ca2-[11.3,14.9): 1.5060 - val_ca3-[8.0,9.5): 0.8293 - val_ca3-[9.5,10.3): 0.5358 - val_ca3-[10.3,11.3): 0.7211 - val_ca3-[11.3,14.9): 0.9468 - val_ca4-[8.0,9.5): 1.5661 - val_ca4-[9.5,10.3): 1.1371 - val_ca4-[10.3,11.3): 0.9791 - val_ca4-[11.3,14.9): 0.7136\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5143 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3765 - ca2-[9.5,10.3): 0.5076 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5233 - ca3-[10.3,11.3): 0.7049 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6130 - ca4-[11.3,14.9): 0.6928 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9156 - val_ca1-[11.3,14.9): 1.5500 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.4122 - val_ca2-[10.3,11.3): 0.8801 - val_ca2-[11.3,14.9): 1.4837 - val_ca3-[8.0,9.5): 0.8294 - val_ca3-[9.5,10.3): 0.5354 - val_ca3-[10.3,11.3): 0.7202 - val_ca3-[11.3,14.9): 0.9226 - val_ca4-[8.0,9.5): 1.5657 - val_ca4-[9.5,10.3): 1.1367 - val_ca4-[10.3,11.3): 0.9759 - val_ca4-[11.3,14.9): 0.6870\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5154 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3728 - ca2-[9.5,10.3): 0.5095 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5338 - ca3-[10.3,11.3): 0.6915 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5678 - ca4-[11.3,14.9): 0.6911 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9135 - val_ca1-[11.3,14.9): 1.5471 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.4120 - val_ca2-[10.3,11.3): 0.8777 - val_ca2-[11.3,14.9): 1.4791 - val_ca3-[8.0,9.5): 0.8298 - val_ca3-[9.5,10.3): 0.5352 - val_ca3-[10.3,11.3): 0.7200 - val_ca3-[11.3,14.9): 0.9251 - val_ca4-[8.0,9.5): 1.5654 - val_ca4-[9.5,10.3): 1.1364 - val_ca4-[10.3,11.3): 0.9787 - val_ca4-[11.3,14.9): 0.6992\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5085 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3853 - ca2-[9.5,10.3): 0.5040 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4903 - ca3-[10.3,11.3): 0.6928 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6018 - ca4-[11.3,14.9): 0.7018 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9116 - val_ca1-[11.3,14.9): 1.5694 - val_ca2-[8.0,9.5): 0.5853 - val_ca2-[9.5,10.3): 0.4117 - val_ca2-[10.3,11.3): 0.8748 - val_ca2-[11.3,14.9): 1.4996 - val_ca3-[8.0,9.5): 0.8303 - val_ca3-[9.5,10.3): 0.5351 - val_ca3-[10.3,11.3): 0.7131 - val_ca3-[11.3,14.9): 0.9420 - val_ca4-[8.0,9.5): 1.5639 - val_ca4-[9.5,10.3): 1.1351 - val_ca4-[10.3,11.3): 0.9657 - val_ca4-[11.3,14.9): 0.7117\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3781 - ca2-[9.5,10.3): 0.5138 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5479 - ca3-[10.3,11.3): 0.6947 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5452 - ca4-[11.3,14.9): 0.7040 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5680 - val_ca2-[8.0,9.5): 0.5850 - val_ca2-[9.5,10.3): 0.4115 - val_ca2-[10.3,11.3): 0.8768 - val_ca2-[11.3,14.9): 1.4987 - val_ca3-[8.0,9.5): 0.8297 - val_ca3-[9.5,10.3): 0.5342 - val_ca3-[10.3,11.3): 0.7187 - val_ca3-[11.3,14.9): 0.9317 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1349 - val_ca4-[10.3,11.3): 0.9778 - val_ca4-[11.3,14.9): 0.6899\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5165 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3776 - ca2-[9.5,10.3): 0.5060 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5281 - ca3-[10.3,11.3): 0.7083 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5911 - ca4-[11.3,14.9): 0.6993 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5748 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.4111 - val_ca2-[10.3,11.3): 0.8757 - val_ca2-[11.3,14.9): 1.5019 - val_ca3-[8.0,9.5): 0.8284 - val_ca3-[9.5,10.3): 0.5326 - val_ca3-[10.3,11.3): 0.7179 - val_ca3-[11.3,14.9): 0.9355 - val_ca4-[8.0,9.5): 1.5623 - val_ca4-[9.5,10.3): 1.1337 - val_ca4-[10.3,11.3): 0.9771 - val_ca4-[11.3,14.9): 0.6906\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5215 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3858 - ca2-[9.5,10.3): 0.5104 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5360 - ca3-[10.3,11.3): 0.7154 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5556 - ca4-[11.3,14.9): 0.6794 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9134 - val_ca1-[11.3,14.9): 1.5674 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.4109 - val_ca2-[10.3,11.3): 0.8760 - val_ca2-[11.3,14.9): 1.4974 - val_ca3-[8.0,9.5): 0.8291 - val_ca3-[9.5,10.3): 0.5326 - val_ca3-[10.3,11.3): 0.7172 - val_ca3-[11.3,14.9): 0.9338 - val_ca4-[8.0,9.5): 1.5631 - val_ca4-[9.5,10.3): 1.1343 - val_ca4-[10.3,11.3): 0.9774 - val_ca4-[11.3,14.9): 0.6956\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5263 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3744 - ca2-[9.5,10.3): 0.5042 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5611 - ca3-[10.3,11.3): 0.6999 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5600 - ca4-[11.3,14.9): 0.6859 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9150 - val_ca1-[11.3,14.9): 1.5593 - val_ca2-[8.0,9.5): 0.5839 - val_ca2-[9.5,10.3): 0.4107 - val_ca2-[10.3,11.3): 0.8787 - val_ca2-[11.3,14.9): 1.4925 - val_ca3-[8.0,9.5): 0.8265 - val_ca3-[9.5,10.3): 0.5300 - val_ca3-[10.3,11.3): 0.7183 - val_ca3-[11.3,14.9): 0.9366 - val_ca4-[8.0,9.5): 1.5647 - val_ca4-[9.5,10.3): 1.1357 - val_ca4-[10.3,11.3): 0.9808 - val_ca4-[11.3,14.9): 0.7062\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5184 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3668 - ca2-[9.5,10.3): 0.5078 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5095 - ca3-[10.3,11.3): 0.7196 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5710 - ca4-[11.3,14.9): 0.6894 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.8952 - val_ca1-[11.3,14.9): 1.5863 - val_ca2-[8.0,9.5): 0.5834 - val_ca2-[9.5,10.3): 0.4104 - val_ca2-[10.3,11.3): 0.8600 - val_ca2-[11.3,14.9): 1.5190 - val_ca3-[8.0,9.5): 0.8255 - val_ca3-[9.5,10.3): 0.5286 - val_ca3-[10.3,11.3): 0.7047 - val_ca3-[11.3,14.9): 0.9520 - val_ca4-[8.0,9.5): 1.5662 - val_ca4-[9.5,10.3): 1.1369 - val_ca4-[10.3,11.3): 0.9753 - val_ca4-[11.3,14.9): 0.7091\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5226 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3690 - ca2-[9.5,10.3): 0.5134 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5321 - ca3-[10.3,11.3): 0.7096 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6274 - ca4-[11.3,14.9): 0.6932 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9152 - val_ca1-[11.3,14.9): 1.5935 - val_ca2-[8.0,9.5): 0.5832 - val_ca2-[9.5,10.3): 0.4099 - val_ca2-[10.3,11.3): 0.8780 - val_ca2-[11.3,14.9): 1.5248 - val_ca3-[8.0,9.5): 0.8263 - val_ca3-[9.5,10.3): 0.5286 - val_ca3-[10.3,11.3): 0.7164 - val_ca3-[11.3,14.9): 0.9522 - val_ca4-[8.0,9.5): 1.5675 - val_ca4-[9.5,10.3): 1.1380 - val_ca4-[10.3,11.3): 0.9822 - val_ca4-[11.3,14.9): 0.7041\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3635 - ca2-[9.5,10.3): 0.5111 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5365 - ca3-[10.3,11.3): 0.7163 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5488 - ca4-[11.3,14.9): 0.6901 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5602 - val_ca2-[8.0,9.5): 0.5827 - val_ca2-[9.5,10.3): 0.4095 - val_ca2-[10.3,11.3): 0.8779 - val_ca2-[11.3,14.9): 1.4936 - val_ca3-[8.0,9.5): 0.8255 - val_ca3-[9.5,10.3): 0.5272 - val_ca3-[10.3,11.3): 0.7153 - val_ca3-[11.3,14.9): 0.9356 - val_ca4-[8.0,9.5): 1.5678 - val_ca4-[9.5,10.3): 1.1383 - val_ca4-[10.3,11.3): 0.9823 - val_ca4-[11.3,14.9): 0.7061\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5202 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3594 - ca2-[9.5,10.3): 0.5040 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5237 - ca3-[10.3,11.3): 0.6965 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5434 - ca4-[11.3,14.9): 0.6864 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9097 - val_ca1-[11.3,14.9): 1.5499 - val_ca2-[8.0,9.5): 0.5815 - val_ca2-[9.5,10.3): 0.4095 - val_ca2-[10.3,11.3): 0.8754 - val_ca2-[11.3,14.9): 1.4907 - val_ca3-[8.0,9.5): 0.8245 - val_ca3-[9.5,10.3): 0.5256 - val_ca3-[10.3,11.3): 0.7039 - val_ca3-[11.3,14.9): 0.9259 - val_ca4-[8.0,9.5): 1.5680 - val_ca4-[9.5,10.3): 1.1384 - val_ca4-[10.3,11.3): 0.9651 - val_ca4-[11.3,14.9): 0.6979\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5226 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3694 - ca2-[9.5,10.3): 0.4990 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5342 - ca3-[10.3,11.3): 0.6971 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5830 - ca4-[11.3,14.9): 0.6858 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5871 - val_ca2-[8.0,9.5): 0.5812 - val_ca2-[9.5,10.3): 0.4086 - val_ca2-[10.3,11.3): 0.8764 - val_ca2-[11.3,14.9): 1.5216 - val_ca3-[8.0,9.5): 0.8263 - val_ca3-[9.5,10.3): 0.5262 - val_ca3-[10.3,11.3): 0.7110 - val_ca3-[11.3,14.9): 0.9483 - val_ca4-[8.0,9.5): 1.5690 - val_ca4-[9.5,10.3): 1.1393 - val_ca4-[10.3,11.3): 0.9802 - val_ca4-[11.3,14.9): 0.7147\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5152 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3726 - ca2-[9.5,10.3): 0.5026 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5509 - ca3-[10.3,11.3): 0.7052 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5720 - ca4-[11.3,14.9): 0.7045 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.8917 - val_ca1-[11.3,14.9): 1.5608 - val_ca2-[8.0,9.5): 0.5805 - val_ca2-[9.5,10.3): 0.4079 - val_ca2-[10.3,11.3): 0.8561 - val_ca2-[11.3,14.9): 1.4991 - val_ca3-[8.0,9.5): 0.8256 - val_ca3-[9.5,10.3): 0.5247 - val_ca3-[10.3,11.3): 0.6975 - val_ca3-[11.3,14.9): 0.9322 - val_ca4-[8.0,9.5): 1.5692 - val_ca4-[9.5,10.3): 1.1393 - val_ca4-[10.3,11.3): 0.9771 - val_ca4-[11.3,14.9): 0.7062\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5245 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3640 - ca2-[9.5,10.3): 0.4980 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5181 - ca3-[10.3,11.3): 0.7008 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5698 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9178 - val_ca1-[11.3,14.9): 1.5763 - val_ca2-[8.0,9.5): 0.5799 - val_ca2-[9.5,10.3): 0.4071 - val_ca2-[10.3,11.3): 0.8796 - val_ca2-[11.3,14.9): 1.5126 - val_ca3-[8.0,9.5): 0.8212 - val_ca3-[9.5,10.3): 0.5203 - val_ca3-[10.3,11.3): 0.7100 - val_ca3-[11.3,14.9): 0.9465 - val_ca4-[8.0,9.5): 1.5688 - val_ca4-[9.5,10.3): 1.1389 - val_ca4-[10.3,11.3): 0.9797 - val_ca4-[11.3,14.9): 0.7121\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5177 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3634 - ca2-[9.5,10.3): 0.5046 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5255 - ca3-[10.3,11.3): 0.7025 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5446 - ca4-[11.3,14.9): 0.6828 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9157 - val_ca1-[11.3,14.9): 1.6076 - val_ca2-[8.0,9.5): 0.5791 - val_ca2-[9.5,10.3): 0.4064 - val_ca2-[10.3,11.3): 0.8772 - val_ca2-[11.3,14.9): 1.5433 - val_ca3-[8.0,9.5): 0.8168 - val_ca3-[9.5,10.3): 0.5150 - val_ca3-[10.3,11.3): 0.7077 - val_ca3-[11.3,14.9): 0.9672 - val_ca4-[8.0,9.5): 1.5672 - val_ca4-[9.5,10.3): 1.1376 - val_ca4-[10.3,11.3): 0.9818 - val_ca4-[11.3,14.9): 0.7168\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5207 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3705 - ca2-[9.5,10.3): 0.4973 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5378 - ca3-[10.3,11.3): 0.6942 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6071 - ca4-[11.3,14.9): 0.6964 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9074 - val_ca1-[11.3,14.9): 1.5909 - val_ca2-[8.0,9.5): 0.5791 - val_ca2-[9.5,10.3): 0.4054 - val_ca2-[10.3,11.3): 0.8671 - val_ca2-[11.3,14.9): 1.5220 - val_ca3-[8.0,9.5): 0.8190 - val_ca3-[9.5,10.3): 0.5154 - val_ca3-[10.3,11.3): 0.6978 - val_ca3-[11.3,14.9): 0.9497 - val_ca4-[8.0,9.5): 1.5656 - val_ca4-[9.5,10.3): 1.1362 - val_ca4-[10.3,11.3): 0.9681 - val_ca4-[11.3,14.9): 0.7021\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.4995 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3664 - ca2-[9.5,10.3): 0.4900 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4942 - ca3-[10.3,11.3): 0.6907 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5716 - ca4-[11.3,14.9): 0.6971 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.8985 - val_ca1-[11.3,14.9): 1.5555 - val_ca2-[8.0,9.5): 0.5785 - val_ca2-[9.5,10.3): 0.4047 - val_ca2-[10.3,11.3): 0.8580 - val_ca2-[11.3,14.9): 1.4869 - val_ca3-[8.0,9.5): 0.8213 - val_ca3-[9.5,10.3): 0.5162 - val_ca3-[10.3,11.3): 0.6940 - val_ca3-[11.3,14.9): 0.9172 - val_ca4-[8.0,9.5): 1.5671 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9767 - val_ca4-[11.3,14.9): 0.6880\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5138 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3576 - ca2-[9.5,10.3): 0.5024 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5102 - ca3-[10.3,11.3): 0.6851 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5821 - ca4-[11.3,14.9): 0.6923 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5819 - val_ca2-[8.0,9.5): 0.5779 - val_ca2-[9.5,10.3): 0.4040 - val_ca2-[10.3,11.3): 0.8734 - val_ca2-[11.3,14.9): 1.5131 - val_ca3-[8.0,9.5): 0.8194 - val_ca3-[9.5,10.3): 0.5128 - val_ca3-[10.3,11.3): 0.7032 - val_ca3-[11.3,14.9): 0.9426 - val_ca4-[8.0,9.5): 1.5682 - val_ca4-[9.5,10.3): 1.1383 - val_ca4-[10.3,11.3): 0.9822 - val_ca4-[11.3,14.9): 0.7082\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5261 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3572 - ca2-[9.5,10.3): 0.4823 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5231 - ca3-[10.3,11.3): 0.6858 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5666 - ca4-[11.3,14.9): 0.6851 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9114 - val_ca1-[11.3,14.9): 1.5680 - val_ca2-[8.0,9.5): 0.5779 - val_ca2-[9.5,10.3): 0.4031 - val_ca2-[10.3,11.3): 0.8665 - val_ca2-[11.3,14.9): 1.4953 - val_ca3-[8.0,9.5): 0.8225 - val_ca3-[9.5,10.3): 0.5140 - val_ca3-[10.3,11.3): 0.7007 - val_ca3-[11.3,14.9): 0.9340 - val_ca4-[8.0,9.5): 1.5689 - val_ca4-[9.5,10.3): 1.1389 - val_ca4-[10.3,11.3): 0.9845 - val_ca4-[11.3,14.9): 0.7123\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5172 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3617 - ca2-[9.5,10.3): 0.4959 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5212 - ca3-[10.3,11.3): 0.6818 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5492 - ca4-[11.3,14.9): 0.6865 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9113 - val_ca1-[11.3,14.9): 1.5573 - val_ca2-[8.0,9.5): 0.5768 - val_ca2-[9.5,10.3): 0.4027 - val_ca2-[10.3,11.3): 0.8677 - val_ca2-[11.3,14.9): 1.4906 - val_ca3-[8.0,9.5): 0.8206 - val_ca3-[9.5,10.3): 0.5107 - val_ca3-[10.3,11.3): 0.6988 - val_ca3-[11.3,14.9): 0.9252 - val_ca4-[8.0,9.5): 1.5699 - val_ca4-[9.5,10.3): 1.1398 - val_ca4-[10.3,11.3): 0.9850 - val_ca4-[11.3,14.9): 0.7042\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5172 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3517 - ca2-[9.5,10.3): 0.4947 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4986 - ca3-[10.3,11.3): 0.6937 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5995 - ca4-[11.3,14.9): 0.6951 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9141 - val_ca1-[11.3,14.9): 1.5485 - val_ca2-[8.0,9.5): 0.5761 - val_ca2-[9.5,10.3): 0.4022 - val_ca2-[10.3,11.3): 0.8701 - val_ca2-[11.3,14.9): 1.4793 - val_ca3-[8.0,9.5): 0.8242 - val_ca3-[9.5,10.3): 0.5127 - val_ca3-[10.3,11.3): 0.6967 - val_ca3-[11.3,14.9): 0.9111 - val_ca4-[8.0,9.5): 1.5690 - val_ca4-[9.5,10.3): 1.1389 - val_ca4-[10.3,11.3): 0.9800 - val_ca4-[11.3,14.9): 0.6986\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5094 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3510 - ca2-[9.5,10.3): 0.4828 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4958 - ca3-[10.3,11.3): 0.7021 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5261 - ca4-[11.3,14.9): 0.6737 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.8970 - val_ca1-[11.3,14.9): 1.5830 - val_ca2-[8.0,9.5): 0.5757 - val_ca2-[9.5,10.3): 0.4015 - val_ca2-[10.3,11.3): 0.8526 - val_ca2-[11.3,14.9): 1.5176 - val_ca3-[8.0,9.5): 0.8172 - val_ca3-[9.5,10.3): 0.5049 - val_ca3-[10.3,11.3): 0.6849 - val_ca3-[11.3,14.9): 0.9430 - val_ca4-[8.0,9.5): 1.5677 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9743 - val_ca4-[11.3,14.9): 0.6966\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5264 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3610 - ca2-[9.5,10.3): 0.4869 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5124 - ca3-[10.3,11.3): 0.6879 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5759 - ca4-[11.3,14.9): 0.6946 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9147 - val_ca1-[11.3,14.9): 1.5628 - val_ca2-[8.0,9.5): 0.5739 - val_ca2-[9.5,10.3): 0.4025 - val_ca2-[10.3,11.3): 0.8756 - val_ca2-[11.3,14.9): 1.5193 - val_ca3-[8.0,9.5): 0.8204 - val_ca3-[9.5,10.3): 0.5062 - val_ca3-[10.3,11.3): 0.6944 - val_ca3-[11.3,14.9): 0.9361 - val_ca4-[8.0,9.5): 1.5666 - val_ca4-[9.5,10.3): 1.1368 - val_ca4-[10.3,11.3): 0.9787 - val_ca4-[11.3,14.9): 0.7115\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5140 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3527 - ca2-[9.5,10.3): 0.4886 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5099 - ca3-[10.3,11.3): 0.6792 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5776 - ca4-[11.3,14.9): 0.6916 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9123 - val_ca1-[11.3,14.9): 1.5857 - val_ca2-[8.0,9.5): 0.5757 - val_ca2-[9.5,10.3): 0.4009 - val_ca2-[10.3,11.3): 0.8629 - val_ca2-[11.3,14.9): 1.5125 - val_ca3-[8.0,9.5): 0.8280 - val_ca3-[9.5,10.3): 0.5116 - val_ca3-[10.3,11.3): 0.6942 - val_ca3-[11.3,14.9): 0.9395 - val_ca4-[8.0,9.5): 1.5649 - val_ca4-[9.5,10.3): 1.1353 - val_ca4-[10.3,11.3): 0.9823 - val_ca4-[11.3,14.9): 0.7182\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5137 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3381 - ca2-[9.5,10.3): 0.4854 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4879 - ca3-[10.3,11.3): 0.6783 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5181 - ca4-[11.3,14.9): 0.6869 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9190 - val_ca1-[11.3,14.9): 1.5799 - val_ca2-[8.0,9.5): 0.5752 - val_ca2-[9.5,10.3): 0.4012 - val_ca2-[10.3,11.3): 0.8706 - val_ca2-[11.3,14.9): 1.5076 - val_ca3-[8.0,9.5): 0.8263 - val_ca3-[9.5,10.3): 0.5077 - val_ca3-[10.3,11.3): 0.6967 - val_ca3-[11.3,14.9): 0.9304 - val_ca4-[8.0,9.5): 1.5641 - val_ca4-[9.5,10.3): 1.1346 - val_ca4-[10.3,11.3): 0.9826 - val_ca4-[11.3,14.9): 0.7060\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5129 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3456 - ca2-[9.5,10.3): 0.4912 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5080 - ca3-[10.3,11.3): 0.6797 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5626 - ca4-[11.3,14.9): 0.6897 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9152 - val_ca1-[11.3,14.9): 1.5316 - val_ca2-[8.0,9.5): 0.5778 - val_ca2-[9.5,10.3): 0.3995 - val_ca2-[10.3,11.3): 0.8578 - val_ca2-[11.3,14.9): 1.4471 - val_ca3-[8.0,9.5): 0.8299 - val_ca3-[9.5,10.3): 0.5086 - val_ca3-[10.3,11.3): 0.6912 - val_ca3-[11.3,14.9): 0.8959 - val_ca4-[8.0,9.5): 1.5644 - val_ca4-[9.5,10.3): 1.1348 - val_ca4-[10.3,11.3): 0.9775 - val_ca4-[11.3,14.9): 0.6793\n",
      "Epoch 193/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5233 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3631 - ca2-[9.5,10.3): 0.4863 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5003 - ca3-[10.3,11.3): 0.6626 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5669 - ca4-[11.3,14.9): 0.6860 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9169 - val_ca1-[11.3,14.9): 1.5662 - val_ca2-[8.0,9.5): 0.5775 - val_ca2-[9.5,10.3): 0.3995 - val_ca2-[10.3,11.3): 0.8620 - val_ca2-[11.3,14.9): 1.4869 - val_ca3-[8.0,9.5): 0.8436 - val_ca3-[9.5,10.3): 0.5208 - val_ca3-[10.3,11.3): 0.6920 - val_ca3-[11.3,14.9): 0.9097 - val_ca4-[8.0,9.5): 1.5651 - val_ca4-[9.5,10.3): 1.1386 - val_ca4-[10.3,11.3): 0.9804 - val_ca4-[11.3,14.9): 0.7045\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5236 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3433 - ca2-[9.5,10.3): 0.4623 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5270 - ca3-[10.3,11.3): 0.6797 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5958 - ca4-[11.3,14.9): 0.6941 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9099 - val_ca1-[11.3,14.9): 1.5558 - val_ca2-[8.0,9.5): 0.5789 - val_ca2-[9.5,10.3): 0.3995 - val_ca2-[10.3,11.3): 0.8512 - val_ca2-[11.3,14.9): 1.4603 - val_ca3-[8.0,9.5): 0.8453 - val_ca3-[9.5,10.3): 0.5187 - val_ca3-[10.3,11.3): 0.6883 - val_ca3-[11.3,14.9): 0.9009 - val_ca4-[8.0,9.5): 1.5663 - val_ca4-[9.5,10.3): 1.1363 - val_ca4-[10.3,11.3): 0.9803 - val_ca4-[11.3,14.9): 0.7049\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5136 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3563 - ca2-[9.5,10.3): 0.4871 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4995 - ca3-[10.3,11.3): 0.6562 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5411 - ca4-[11.3,14.9): 0.6958 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9189 - val_ca1-[11.3,14.9): 1.5610 - val_ca2-[8.0,9.5): 0.5784 - val_ca2-[9.5,10.3): 0.4004 - val_ca2-[10.3,11.3): 0.8600 - val_ca2-[11.3,14.9): 1.4784 - val_ca3-[8.0,9.5): 0.8374 - val_ca3-[9.5,10.3): 0.5091 - val_ca3-[10.3,11.3): 0.6862 - val_ca3-[11.3,14.9): 0.9211 - val_ca4-[8.0,9.5): 1.5685 - val_ca4-[9.5,10.3): 1.1382 - val_ca4-[10.3,11.3): 0.9735 - val_ca4-[11.3,14.9): 0.7027\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5165 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3462 - ca2-[9.5,10.3): 0.4705 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4916 - ca3-[10.3,11.3): 0.6876 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5761 - ca4-[11.3,14.9): 0.7052 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9163 - val_ca1-[11.3,14.9): 1.5754 - val_ca2-[8.0,9.5): 0.5800 - val_ca2-[9.5,10.3): 0.3995 - val_ca2-[10.3,11.3): 0.8526 - val_ca2-[11.3,14.9): 1.4708 - val_ca3-[8.0,9.5): 0.8493 - val_ca3-[9.5,10.3): 0.5181 - val_ca3-[10.3,11.3): 0.6890 - val_ca3-[11.3,14.9): 0.9129 - val_ca4-[8.0,9.5): 1.5703 - val_ca4-[9.5,10.3): 1.1397 - val_ca4-[10.3,11.3): 0.9830 - val_ca4-[11.3,14.9): 0.7126\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5154 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3565 - ca2-[9.5,10.3): 0.4845 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5056 - ca3-[10.3,11.3): 0.6713 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5828 - ca4-[11.3,14.9): 0.6940 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9060 - val_ca1-[11.3,14.9): 1.5903 - val_ca2-[8.0,9.5): 0.5805 - val_ca2-[9.5,10.3): 0.3996 - val_ca2-[10.3,11.3): 0.8458 - val_ca2-[11.3,14.9): 1.4906 - val_ca3-[8.0,9.5): 0.8584 - val_ca3-[9.5,10.3): 0.5248 - val_ca3-[10.3,11.3): 0.6805 - val_ca3-[11.3,14.9): 0.9055 - val_ca4-[8.0,9.5): 1.5697 - val_ca4-[9.5,10.3): 1.1391 - val_ca4-[10.3,11.3): 0.9672 - val_ca4-[11.3,14.9): 0.6856\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5303 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3651 - ca2-[9.5,10.3): 0.4862 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5103 - ca3-[10.3,11.3): 0.6571 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5711 - ca4-[11.3,14.9): 0.6822 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9098 - val_ca1-[11.3,14.9): 1.5690 - val_ca2-[8.0,9.5): 0.5811 - val_ca2-[9.5,10.3): 0.3998 - val_ca2-[10.3,11.3): 0.8476 - val_ca2-[11.3,14.9): 1.4710 - val_ca3-[8.0,9.5): 0.8468 - val_ca3-[9.5,10.3): 0.5130 - val_ca3-[10.3,11.3): 0.6852 - val_ca3-[11.3,14.9): 0.9155 - val_ca4-[8.0,9.5): 1.5684 - val_ca4-[9.5,10.3): 1.1379 - val_ca4-[10.3,11.3): 0.9812 - val_ca4-[11.3,14.9): 0.7063\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5278 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3439 - ca2-[9.5,10.3): 0.4683 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4911 - ca3-[10.3,11.3): 0.6697 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5536 - ca4-[11.3,14.9): 0.6997 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9167 - val_ca1-[11.3,14.9): 1.5863 - val_ca2-[8.0,9.5): 0.5831 - val_ca2-[9.5,10.3): 0.3988 - val_ca2-[10.3,11.3): 0.8468 - val_ca2-[11.3,14.9): 1.4761 - val_ca3-[8.0,9.5): 0.8617 - val_ca3-[9.5,10.3): 0.5254 - val_ca3-[10.3,11.3): 0.6873 - val_ca3-[11.3,14.9): 0.9044 - val_ca4-[8.0,9.5): 1.5670 - val_ca4-[9.5,10.3): 1.1367 - val_ca4-[10.3,11.3): 0.9812 - val_ca4-[11.3,14.9): 0.6952\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5158 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3531 - ca2-[9.5,10.3): 0.4817 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5026 - ca3-[10.3,11.3): 0.6493 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5965 - ca4-[11.3,14.9): 0.6932 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9153 - val_ca1-[11.3,14.9): 1.5515 - val_ca2-[8.0,9.5): 0.5823 - val_ca2-[9.5,10.3): 0.3999 - val_ca2-[10.3,11.3): 0.8500 - val_ca2-[11.3,14.9): 1.4509 - val_ca3-[8.0,9.5): 0.8614 - val_ca3-[9.5,10.3): 0.5236 - val_ca3-[10.3,11.3): 0.6842 - val_ca3-[11.3,14.9): 0.8805 - val_ca4-[8.0,9.5): 1.5655 - val_ca4-[9.5,10.3): 1.1354 - val_ca4-[10.3,11.3): 0.9778 - val_ca4-[11.3,14.9): 0.6926\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5235 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3610 - ca2-[9.5,10.3): 0.4872 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5124 - ca3-[10.3,11.3): 0.6623 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5977 - ca4-[11.3,14.9): 0.7024 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9194 - val_ca1-[11.3,14.9): 1.5941 - val_ca2-[8.0,9.5): 0.5840 - val_ca2-[9.5,10.3): 0.3988 - val_ca2-[10.3,11.3): 0.8469 - val_ca2-[11.3,14.9): 1.4784 - val_ca3-[8.0,9.5): 0.8677 - val_ca3-[9.5,10.3): 0.5281 - val_ca3-[10.3,11.3): 0.6882 - val_ca3-[11.3,14.9): 0.9050 - val_ca4-[8.0,9.5): 1.5650 - val_ca4-[9.5,10.3): 1.1349 - val_ca4-[10.3,11.3): 0.9827 - val_ca4-[11.3,14.9): 0.7072\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5232 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3610 - ca2-[9.5,10.3): 0.4824 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4829 - ca3-[10.3,11.3): 0.6643 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5760 - ca4-[11.3,14.9): 0.6805 - val_ca1-[8.0,9.5): 0.5838 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9153 - val_ca1-[11.3,14.9): 1.5870 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3997 - val_ca2-[10.3,11.3): 0.8396 - val_ca2-[11.3,14.9): 1.4669 - val_ca3-[8.0,9.5): 0.8613 - val_ca3-[9.5,10.3): 0.5210 - val_ca3-[10.3,11.3): 0.6839 - val_ca3-[11.3,14.9): 0.9146 - val_ca4-[8.0,9.5): 1.5698 - val_ca4-[9.5,10.3): 1.1387 - val_ca4-[10.3,11.3): 0.9778 - val_ca4-[11.3,14.9): 0.7064\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5075 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3415 - ca2-[9.5,10.3): 0.4701 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4889 - ca3-[10.3,11.3): 0.6494 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5828 - ca4-[11.3,14.9): 0.7044 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9197 - val_ca1-[11.3,14.9): 1.5612 - val_ca2-[8.0,9.5): 0.5846 - val_ca2-[9.5,10.3): 0.3979 - val_ca2-[10.3,11.3): 0.8427 - val_ca2-[11.3,14.9): 1.4367 - val_ca3-[8.0,9.5): 0.8671 - val_ca3-[9.5,10.3): 0.5268 - val_ca3-[10.3,11.3): 0.6860 - val_ca3-[11.3,14.9): 0.8865 - val_ca4-[8.0,9.5): 1.5666 - val_ca4-[9.5,10.3): 1.1395 - val_ca4-[10.3,11.3): 0.9835 - val_ca4-[11.3,14.9): 0.7037\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5221 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3670 - ca2-[9.5,10.3): 0.4828 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5010 - ca3-[10.3,11.3): 0.6427 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5162 - ca4-[11.3,14.9): 0.6709 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9200 - val_ca1-[11.3,14.9): 1.5943 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3982 - val_ca2-[10.3,11.3): 0.8386 - val_ca2-[11.3,14.9): 1.4554 - val_ca3-[8.0,9.5): 0.8714 - val_ca3-[9.5,10.3): 0.5283 - val_ca3-[10.3,11.3): 0.6810 - val_ca3-[11.3,14.9): 0.9002 - val_ca4-[8.0,9.5): 1.5667 - val_ca4-[9.5,10.3): 1.1363 - val_ca4-[10.3,11.3): 0.9779 - val_ca4-[11.3,14.9): 0.7185\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5217 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3417 - ca2-[9.5,10.3): 0.4791 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5115 - ca3-[10.3,11.3): 0.6505 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5373 - ca4-[11.3,14.9): 0.6912 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9176 - val_ca1-[11.3,14.9): 1.5872 - val_ca2-[8.0,9.5): 0.5844 - val_ca2-[9.5,10.3): 0.3988 - val_ca2-[10.3,11.3): 0.8404 - val_ca2-[11.3,14.9): 1.4647 - val_ca3-[8.0,9.5): 0.8683 - val_ca3-[9.5,10.3): 0.5249 - val_ca3-[10.3,11.3): 0.6819 - val_ca3-[11.3,14.9): 0.9041 - val_ca4-[8.0,9.5): 1.5666 - val_ca4-[9.5,10.3): 1.1361 - val_ca4-[10.3,11.3): 0.9808 - val_ca4-[11.3,14.9): 0.7178\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5160 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3514 - ca2-[9.5,10.3): 0.4747 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5185 - ca3-[10.3,11.3): 0.6574 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5754 - ca4-[11.3,14.9): 0.6965 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9174 - val_ca1-[11.3,14.9): 1.5512 - val_ca2-[8.0,9.5): 0.5832 - val_ca2-[9.5,10.3): 0.3999 - val_ca2-[10.3,11.3): 0.8476 - val_ca2-[11.3,14.9): 1.4463 - val_ca3-[8.0,9.5): 0.8802 - val_ca3-[9.5,10.3): 0.5341 - val_ca3-[10.3,11.3): 0.6800 - val_ca3-[11.3,14.9): 0.8676 - val_ca4-[8.0,9.5): 1.5677 - val_ca4-[9.5,10.3): 1.1371 - val_ca4-[10.3,11.3): 0.9813 - val_ca4-[11.3,14.9): 0.7038\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5211 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3590 - ca2-[9.5,10.3): 0.4771 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5287 - ca3-[10.3,11.3): 0.6485 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5769 - ca4-[11.3,14.9): 0.6920 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9150 - val_ca1-[11.3,14.9): 1.5380 - val_ca2-[8.0,9.5): 0.5852 - val_ca2-[9.5,10.3): 0.3984 - val_ca2-[10.3,11.3): 0.8366 - val_ca2-[11.3,14.9): 1.4025 - val_ca3-[8.0,9.5): 0.8728 - val_ca3-[9.5,10.3): 0.5269 - val_ca3-[10.3,11.3): 0.6766 - val_ca3-[11.3,14.9): 0.8514 - val_ca4-[8.0,9.5): 1.5681 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9789 - val_ca4-[11.3,14.9): 0.6793\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5147 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3489 - ca2-[9.5,10.3): 0.4801 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5158 - ca3-[10.3,11.3): 0.6529 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5316 - ca4-[11.3,14.9): 0.7010 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9152 - val_ca1-[11.3,14.9): 1.5906 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.3998 - val_ca2-[10.3,11.3): 0.8418 - val_ca2-[11.3,14.9): 1.4674 - val_ca3-[8.0,9.5): 0.8794 - val_ca3-[9.5,10.3): 0.5308 - val_ca3-[10.3,11.3): 0.6753 - val_ca3-[11.3,14.9): 0.8883 - val_ca4-[8.0,9.5): 1.5671 - val_ca4-[9.5,10.3): 1.1365 - val_ca4-[10.3,11.3): 0.9784 - val_ca4-[11.3,14.9): 0.7139\n",
      "Epoch 209/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5337 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3546 - ca2-[9.5,10.3): 0.4784 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5141 - ca3-[10.3,11.3): 0.6494 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5696 - ca4-[11.3,14.9): 0.6820 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.6174 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3987 - val_ca2-[10.3,11.3): 0.8398 - val_ca2-[11.3,14.9): 1.4863 - val_ca3-[8.0,9.5): 0.8666 - val_ca3-[9.5,10.3): 0.5201 - val_ca3-[10.3,11.3): 0.6788 - val_ca3-[11.3,14.9): 0.9204 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1354 - val_ca4-[10.3,11.3): 0.9803 - val_ca4-[11.3,14.9): 0.7166\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5227 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3584 - ca2-[9.5,10.3): 0.4850 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5245 - ca3-[10.3,11.3): 0.6461 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5821 - ca4-[11.3,14.9): 0.6912 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9149 - val_ca1-[11.3,14.9): 1.5647 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3991 - val_ca2-[10.3,11.3): 0.8395 - val_ca2-[11.3,14.9): 1.4409 - val_ca3-[8.0,9.5): 0.8730 - val_ca3-[9.5,10.3): 0.5251 - val_ca3-[10.3,11.3): 0.6773 - val_ca3-[11.3,14.9): 0.8680 - val_ca4-[8.0,9.5): 1.5661 - val_ca4-[9.5,10.3): 1.1355 - val_ca4-[10.3,11.3): 0.9778 - val_ca4-[11.3,14.9): 0.6765\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3695 - ca2-[9.5,10.3): 0.4731 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5415 - ca3-[10.3,11.3): 0.6504 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5419 - ca4-[11.3,14.9): 0.6794 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4148 - val_ca1-[10.3,11.3): 0.9074 - val_ca1-[11.3,14.9): 1.5947 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.3912 - val_ca2-[10.3,11.3): 0.8321 - val_ca2-[11.3,14.9): 1.4783 - val_ca3-[8.0,9.5): 0.8742 - val_ca3-[9.5,10.3): 0.5218 - val_ca3-[10.3,11.3): 0.6751 - val_ca3-[11.3,14.9): 0.8965 - val_ca4-[8.0,9.5): 1.5639 - val_ca4-[9.5,10.3): 1.1361 - val_ca4-[10.3,11.3): 0.9830 - val_ca4-[11.3,14.9): 0.7059\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5219 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3665 - ca2-[9.5,10.3): 0.4759 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5231 - ca3-[10.3,11.3): 0.6550 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5452 - ca4-[11.3,14.9): 0.6895 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9151 - val_ca1-[11.3,14.9): 1.5709 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3980 - val_ca2-[10.3,11.3): 0.8324 - val_ca2-[11.3,14.9): 1.4330 - val_ca3-[8.0,9.5): 0.8794 - val_ca3-[9.5,10.3): 0.5288 - val_ca3-[10.3,11.3): 0.6746 - val_ca3-[11.3,14.9): 0.8717 - val_ca4-[8.0,9.5): 1.5626 - val_ca4-[9.5,10.3): 1.1325 - val_ca4-[10.3,11.3): 0.9760 - val_ca4-[11.3,14.9): 0.7001\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5154 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3716 - ca2-[9.5,10.3): 0.4809 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5025 - ca3-[10.3,11.3): 0.6395 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5290 - ca4-[11.3,14.9): 0.6738 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9135 - val_ca1-[11.3,14.9): 1.5722 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3976 - val_ca2-[10.3,11.3): 0.8323 - val_ca2-[11.3,14.9): 1.4388 - val_ca3-[8.0,9.5): 0.8790 - val_ca3-[9.5,10.3): 0.5280 - val_ca3-[10.3,11.3): 0.6732 - val_ca3-[11.3,14.9): 0.8791 - val_ca4-[8.0,9.5): 1.5622 - val_ca4-[9.5,10.3): 1.1320 - val_ca4-[10.3,11.3): 0.9636 - val_ca4-[11.3,14.9): 0.6832\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5072 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3598 - ca2-[9.5,10.3): 0.4819 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5308 - ca3-[10.3,11.3): 0.6355 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5900 - ca4-[11.3,14.9): 0.6928 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9084 - val_ca1-[11.3,14.9): 1.5781 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3991 - val_ca2-[10.3,11.3): 0.8353 - val_ca2-[11.3,14.9): 1.4603 - val_ca3-[8.0,9.5): 0.8723 - val_ca3-[9.5,10.3): 0.5221 - val_ca3-[10.3,11.3): 0.6756 - val_ca3-[11.3,14.9): 0.8930 - val_ca4-[8.0,9.5): 1.5631 - val_ca4-[9.5,10.3): 1.1328 - val_ca4-[10.3,11.3): 0.9825 - val_ca4-[11.3,14.9): 0.7179\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5254 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3563 - ca2-[9.5,10.3): 0.4822 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5244 - ca3-[10.3,11.3): 0.6564 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6027 - ca4-[11.3,14.9): 0.6989 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9118 - val_ca1-[11.3,14.9): 1.5676 - val_ca2-[8.0,9.5): 0.5893 - val_ca2-[9.5,10.3): 0.3966 - val_ca2-[10.3,11.3): 0.8186 - val_ca2-[11.3,14.9): 1.4137 - val_ca3-[8.0,9.5): 0.8870 - val_ca3-[9.5,10.3): 0.5349 - val_ca3-[10.3,11.3): 0.6631 - val_ca3-[11.3,14.9): 0.8606 - val_ca4-[8.0,9.5): 1.5627 - val_ca4-[9.5,10.3): 1.1325 - val_ca4-[10.3,11.3): 0.9611 - val_ca4-[11.3,14.9): 0.7040\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5234 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3717 - ca2-[9.5,10.3): 0.4748 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5027 - ca3-[10.3,11.3): 0.6353 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5698 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9147 - val_ca1-[11.3,14.9): 1.5561 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3978 - val_ca2-[10.3,11.3): 0.8326 - val_ca2-[11.3,14.9): 1.4203 - val_ca3-[8.0,9.5): 0.8771 - val_ca3-[9.5,10.3): 0.5252 - val_ca3-[10.3,11.3): 0.6725 - val_ca3-[11.3,14.9): 0.8724 - val_ca4-[8.0,9.5): 1.5634 - val_ca4-[9.5,10.3): 1.1330 - val_ca4-[10.3,11.3): 0.9762 - val_ca4-[11.3,14.9): 0.7098\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5303 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3568 - ca2-[9.5,10.3): 0.4601 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5017 - ca3-[10.3,11.3): 0.6413 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5531 - ca4-[11.3,14.9): 0.6794 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5909 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3981 - val_ca2-[10.3,11.3): 0.8369 - val_ca2-[11.3,14.9): 1.4639 - val_ca3-[8.0,9.5): 0.8794 - val_ca3-[9.5,10.3): 0.5257 - val_ca3-[10.3,11.3): 0.6728 - val_ca3-[11.3,14.9): 0.8900 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1333 - val_ca4-[10.3,11.3): 0.9790 - val_ca4-[11.3,14.9): 0.7124\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5227 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3593 - ca2-[9.5,10.3): 0.4744 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5362 - ca3-[10.3,11.3): 0.6491 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5922 - ca4-[11.3,14.9): 0.6832 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9115 - val_ca1-[11.3,14.9): 1.5695 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3986 - val_ca2-[10.3,11.3): 0.8366 - val_ca2-[11.3,14.9): 1.4472 - val_ca3-[8.0,9.5): 0.8780 - val_ca3-[9.5,10.3): 0.5236 - val_ca3-[10.3,11.3): 0.6719 - val_ca3-[11.3,14.9): 0.8577 - val_ca4-[8.0,9.5): 1.5641 - val_ca4-[9.5,10.3): 1.1335 - val_ca4-[10.3,11.3): 0.9810 - val_ca4-[11.3,14.9): 0.6826\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5221 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3583 - ca2-[9.5,10.3): 0.4768 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5152 - ca3-[10.3,11.3): 0.6496 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5321 - ca4-[11.3,14.9): 0.6967 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9165 - val_ca1-[11.3,14.9): 1.5963 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3969 - val_ca2-[10.3,11.3): 0.8315 - val_ca2-[11.3,14.9): 1.4603 - val_ca3-[8.0,9.5): 0.8849 - val_ca3-[9.5,10.3): 0.5293 - val_ca3-[10.3,11.3): 0.6718 - val_ca3-[11.3,14.9): 0.8860 - val_ca4-[8.0,9.5): 1.5647 - val_ca4-[9.5,10.3): 1.1340 - val_ca4-[10.3,11.3): 0.9793 - val_ca4-[11.3,14.9): 0.7087\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5231 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3675 - ca2-[9.5,10.3): 0.4760 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5346 - ca3-[10.3,11.3): 0.6193 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5689 - ca4-[11.3,14.9): 0.6762 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9173 - val_ca1-[11.3,14.9): 1.5906 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3973 - val_ca2-[10.3,11.3): 0.8364 - val_ca2-[11.3,14.9): 1.4630 - val_ca3-[8.0,9.5): 0.8792 - val_ca3-[9.5,10.3): 0.5226 - val_ca3-[10.3,11.3): 0.6689 - val_ca3-[11.3,14.9): 0.8913 - val_ca4-[8.0,9.5): 1.5647 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9737 - val_ca4-[11.3,14.9): 0.7136\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5183 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3617 - ca2-[9.5,10.3): 0.4767 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4986 - ca3-[10.3,11.3): 0.6414 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5439 - ca4-[11.3,14.9): 0.6970 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9213 - val_ca1-[11.3,14.9): 1.5887 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.3980 - val_ca2-[10.3,11.3): 0.8437 - val_ca2-[11.3,14.9): 1.4670 - val_ca3-[8.0,9.5): 0.8718 - val_ca3-[9.5,10.3): 0.5160 - val_ca3-[10.3,11.3): 0.6695 - val_ca3-[11.3,14.9): 0.8922 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1327 - val_ca4-[10.3,11.3): 0.9782 - val_ca4-[11.3,14.9): 0.7161\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5061 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3597 - ca2-[9.5,10.3): 0.4735 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5317 - ca3-[10.3,11.3): 0.6299 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5689 - ca4-[11.3,14.9): 0.6908 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5761 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.3953 - val_ca2-[10.3,11.3): 0.8255 - val_ca2-[11.3,14.9): 1.4230 - val_ca3-[8.0,9.5): 0.8809 - val_ca3-[9.5,10.3): 0.5248 - val_ca3-[10.3,11.3): 0.6688 - val_ca3-[11.3,14.9): 0.8627 - val_ca4-[8.0,9.5): 1.5631 - val_ca4-[9.5,10.3): 1.1359 - val_ca4-[10.3,11.3): 0.9784 - val_ca4-[11.3,14.9): 0.6863\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5320 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3780 - ca2-[9.5,10.3): 0.4881 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5186 - ca3-[10.3,11.3): 0.6265 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5495 - ca4-[11.3,14.9): 0.6894 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9118 - val_ca1-[11.3,14.9): 1.5897 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3973 - val_ca2-[10.3,11.3): 0.8340 - val_ca2-[11.3,14.9): 1.4618 - val_ca3-[8.0,9.5): 0.8765 - val_ca3-[9.5,10.3): 0.5200 - val_ca3-[10.3,11.3): 0.6699 - val_ca3-[11.3,14.9): 0.8784 - val_ca4-[8.0,9.5): 1.5623 - val_ca4-[9.5,10.3): 1.1318 - val_ca4-[10.3,11.3): 0.9799 - val_ca4-[11.3,14.9): 0.7020\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5200 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3501 - ca2-[9.5,10.3): 0.4664 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4963 - ca3-[10.3,11.3): 0.6254 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5505 - ca4-[11.3,14.9): 0.6908 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9176 - val_ca1-[11.3,14.9): 1.5807 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.3961 - val_ca2-[10.3,11.3): 0.8339 - val_ca2-[11.3,14.9): 1.4450 - val_ca3-[8.0,9.5): 0.8760 - val_ca3-[9.5,10.3): 0.5193 - val_ca3-[10.3,11.3): 0.6723 - val_ca3-[11.3,14.9): 0.8864 - val_ca4-[8.0,9.5): 1.5603 - val_ca4-[9.5,10.3): 1.1300 - val_ca4-[10.3,11.3): 0.9795 - val_ca4-[11.3,14.9): 0.7126\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3545 - ca2-[9.5,10.3): 0.4725 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5135 - ca3-[10.3,11.3): 0.6360 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5457 - ca4-[11.3,14.9): 0.6846 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9199 - val_ca1-[11.3,14.9): 1.5419 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.3969 - val_ca2-[10.3,11.3): 0.8401 - val_ca2-[11.3,14.9): 1.4261 - val_ca3-[8.0,9.5): 0.8771 - val_ca3-[9.5,10.3): 0.5183 - val_ca3-[10.3,11.3): 0.6633 - val_ca3-[11.3,14.9): 0.8563 - val_ca4-[8.0,9.5): 1.5602 - val_ca4-[9.5,10.3): 1.1299 - val_ca4-[10.3,11.3): 0.9708 - val_ca4-[11.3,14.9): 0.6986\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5122 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3546 - ca2-[9.5,10.3): 0.4832 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5376 - ca3-[10.3,11.3): 0.6278 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5526 - ca4-[11.3,14.9): 0.6833 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5671 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3963 - val_ca2-[10.3,11.3): 0.8354 - val_ca2-[11.3,14.9): 1.4453 - val_ca3-[8.0,9.5): 0.8825 - val_ca3-[9.5,10.3): 0.5225 - val_ca3-[10.3,11.3): 0.6668 - val_ca3-[11.3,14.9): 0.8669 - val_ca4-[8.0,9.5): 1.5599 - val_ca4-[9.5,10.3): 1.1296 - val_ca4-[10.3,11.3): 0.9766 - val_ca4-[11.3,14.9): 0.7054\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5054 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3587 - ca2-[9.5,10.3): 0.4773 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5254 - ca3-[10.3,11.3): 0.6278 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5351 - ca4-[11.3,14.9): 0.6903 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5894 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.3944 - val_ca2-[10.3,11.3): 0.8246 - val_ca2-[11.3,14.9): 1.4361 - val_ca3-[8.0,9.5): 0.8780 - val_ca3-[9.5,10.3): 0.5179 - val_ca3-[10.3,11.3): 0.6669 - val_ca3-[11.3,14.9): 0.8792 - val_ca4-[8.0,9.5): 1.5606 - val_ca4-[9.5,10.3): 1.1302 - val_ca4-[10.3,11.3): 0.9769 - val_ca4-[11.3,14.9): 0.7180\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5358 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3551 - ca2-[9.5,10.3): 0.4600 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5301 - ca3-[10.3,11.3): 0.6335 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5695 - ca4-[11.3,14.9): 0.6866 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9141 - val_ca1-[11.3,14.9): 1.5755 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3948 - val_ca2-[10.3,11.3): 0.8267 - val_ca2-[11.3,14.9): 1.4388 - val_ca3-[8.0,9.5): 0.8892 - val_ca3-[9.5,10.3): 0.5264 - val_ca3-[10.3,11.3): 0.6647 - val_ca3-[11.3,14.9): 0.8642 - val_ca4-[8.0,9.5): 1.5618 - val_ca4-[9.5,10.3): 1.1311 - val_ca4-[10.3,11.3): 0.9748 - val_ca4-[11.3,14.9): 0.7003\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5047 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3477 - ca2-[9.5,10.3): 0.4721 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5294 - ca3-[10.3,11.3): 0.6299 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6193 - ca4-[11.3,14.9): 0.7030 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9162 - val_ca1-[11.3,14.9): 1.5707 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3951 - val_ca2-[10.3,11.3): 0.8303 - val_ca2-[11.3,14.9): 1.4426 - val_ca3-[8.0,9.5): 0.8806 - val_ca3-[9.5,10.3): 0.5186 - val_ca3-[10.3,11.3): 0.6641 - val_ca3-[11.3,14.9): 0.8743 - val_ca4-[8.0,9.5): 1.5616 - val_ca4-[9.5,10.3): 1.1309 - val_ca4-[10.3,11.3): 0.9717 - val_ca4-[11.3,14.9): 0.7099\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5193 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3648 - ca2-[9.5,10.3): 0.4678 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5537 - ca3-[10.3,11.3): 0.6151 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5707 - ca4-[11.3,14.9): 0.6958 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9160 - val_ca1-[11.3,14.9): 1.5755 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.3949 - val_ca2-[10.3,11.3): 0.8309 - val_ca2-[11.3,14.9): 1.4403 - val_ca3-[8.0,9.5): 0.8912 - val_ca3-[9.5,10.3): 0.5256 - val_ca3-[10.3,11.3): 0.6647 - val_ca3-[11.3,14.9): 0.8562 - val_ca4-[8.0,9.5): 1.5614 - val_ca4-[9.5,10.3): 1.1307 - val_ca4-[10.3,11.3): 0.9771 - val_ca4-[11.3,14.9): 0.7000\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5169 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3534 - ca2-[9.5,10.3): 0.4679 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5347 - ca3-[10.3,11.3): 0.6268 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5276 - ca4-[11.3,14.9): 0.6790 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9095 - val_ca1-[11.3,14.9): 1.6086 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3945 - val_ca2-[10.3,11.3): 0.8249 - val_ca2-[11.3,14.9): 1.4779 - val_ca3-[8.0,9.5): 0.8815 - val_ca3-[9.5,10.3): 0.5173 - val_ca3-[10.3,11.3): 0.6629 - val_ca3-[11.3,14.9): 0.8953 - val_ca4-[8.0,9.5): 1.5626 - val_ca4-[9.5,10.3): 1.1317 - val_ca4-[10.3,11.3): 0.9770 - val_ca4-[11.3,14.9): 0.7154\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5251 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3646 - ca2-[9.5,10.3): 0.4549 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4992 - ca3-[10.3,11.3): 0.6282 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5564 - ca4-[11.3,14.9): 0.7004 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9071 - val_ca1-[11.3,14.9): 1.5970 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3948 - val_ca2-[10.3,11.3): 0.8241 - val_ca2-[11.3,14.9): 1.4631 - val_ca3-[8.0,9.5): 0.8872 - val_ca3-[9.5,10.3): 0.5219 - val_ca3-[10.3,11.3): 0.6637 - val_ca3-[11.3,14.9): 0.8825 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1296 - val_ca4-[10.3,11.3): 0.9652 - val_ca4-[11.3,14.9): 0.7014\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3528 - ca2-[9.5,10.3): 0.4529 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5390 - ca3-[10.3,11.3): 0.6145 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5503 - ca4-[11.3,14.9): 0.6884 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5887 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.3945 - val_ca2-[10.3,11.3): 0.8229 - val_ca2-[11.3,14.9): 1.4454 - val_ca3-[8.0,9.5): 0.8846 - val_ca3-[9.5,10.3): 0.5197 - val_ca3-[10.3,11.3): 0.6587 - val_ca3-[11.3,14.9): 0.8741 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1297 - val_ca4-[10.3,11.3): 0.9739 - val_ca4-[11.3,14.9): 0.7034\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5258 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3567 - ca2-[9.5,10.3): 0.4592 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5124 - ca3-[10.3,11.3): 0.6312 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5521 - ca4-[11.3,14.9): 0.6913 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.6080 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.3934 - val_ca2-[10.3,11.3): 0.8240 - val_ca2-[11.3,14.9): 1.4676 - val_ca3-[8.0,9.5): 0.8819 - val_ca3-[9.5,10.3): 0.5154 - val_ca3-[10.3,11.3): 0.6615 - val_ca3-[11.3,14.9): 0.8873 - val_ca4-[8.0,9.5): 1.5632 - val_ca4-[9.5,10.3): 1.1321 - val_ca4-[10.3,11.3): 0.9752 - val_ca4-[11.3,14.9): 0.7037\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5069 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3680 - ca2-[9.5,10.3): 0.4595 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5068 - ca3-[10.3,11.3): 0.6245 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5568 - ca4-[11.3,14.9): 0.6899 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9157 - val_ca1-[11.3,14.9): 1.5886 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.3931 - val_ca2-[10.3,11.3): 0.8243 - val_ca2-[11.3,14.9): 1.4440 - val_ca3-[8.0,9.5): 0.8922 - val_ca3-[9.5,10.3): 0.5233 - val_ca3-[10.3,11.3): 0.6632 - val_ca3-[11.3,14.9): 0.8619 - val_ca4-[8.0,9.5): 1.5626 - val_ca4-[9.5,10.3): 1.1316 - val_ca4-[10.3,11.3): 0.9775 - val_ca4-[11.3,14.9): 0.6958\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5198 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3478 - ca2-[9.5,10.3): 0.4619 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5211 - ca3-[10.3,11.3): 0.6281 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5728 - ca4-[11.3,14.9): 0.6960 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9112 - val_ca1-[11.3,14.9): 1.5641 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3928 - val_ca2-[10.3,11.3): 0.8230 - val_ca2-[11.3,14.9): 1.4155 - val_ca3-[8.0,9.5): 0.8944 - val_ca3-[9.5,10.3): 0.5241 - val_ca3-[10.3,11.3): 0.6623 - val_ca3-[11.3,14.9): 0.8422 - val_ca4-[8.0,9.5): 1.5635 - val_ca4-[9.5,10.3): 1.1323 - val_ca4-[10.3,11.3): 0.9798 - val_ca4-[11.3,14.9): 0.6973\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5213 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3603 - ca2-[9.5,10.3): 0.4745 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5313 - ca3-[10.3,11.3): 0.6114 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5084 - ca4-[11.3,14.9): 0.6865 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9178 - val_ca1-[11.3,14.9): 1.5903 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.3922 - val_ca2-[10.3,11.3): 0.8252 - val_ca2-[11.3,14.9): 1.4484 - val_ca3-[8.0,9.5): 0.8742 - val_ca3-[9.5,10.3): 0.5076 - val_ca3-[10.3,11.3): 0.6657 - val_ca3-[11.3,14.9): 0.8922 - val_ca4-[8.0,9.5): 1.5648 - val_ca4-[9.5,10.3): 1.1333 - val_ca4-[10.3,11.3): 0.9756 - val_ca4-[11.3,14.9): 0.7059\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5177 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3560 - ca2-[9.5,10.3): 0.4624 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5483 - ca3-[10.3,11.3): 0.6163 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5329 - ca4-[11.3,14.9): 0.6865 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9087 - val_ca1-[11.3,14.9): 1.5536 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3915 - val_ca2-[10.3,11.3): 0.8172 - val_ca2-[11.3,14.9): 1.4175 - val_ca3-[8.0,9.5): 0.9039 - val_ca3-[9.5,10.3): 0.5315 - val_ca3-[10.3,11.3): 0.6583 - val_ca3-[11.3,14.9): 0.8392 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1320 - val_ca4-[10.3,11.3): 0.9769 - val_ca4-[11.3,14.9): 0.6976\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5142 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3678 - ca2-[9.5,10.3): 0.4601 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5398 - ca3-[10.3,11.3): 0.6060 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5593 - ca4-[11.3,14.9): 0.6866 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9043 - val_ca1-[11.3,14.9): 1.5603 - val_ca2-[8.0,9.5): 0.5902 - val_ca2-[9.5,10.3): 0.3906 - val_ca2-[10.3,11.3): 0.8123 - val_ca2-[11.3,14.9): 1.4196 - val_ca3-[8.0,9.5): 0.8740 - val_ca3-[9.5,10.3): 0.5073 - val_ca3-[10.3,11.3): 0.6603 - val_ca3-[11.3,14.9): 0.8767 - val_ca4-[8.0,9.5): 1.5642 - val_ca4-[9.5,10.3): 1.1326 - val_ca4-[10.3,11.3): 0.9626 - val_ca4-[11.3,14.9): 0.6755\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5147 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3571 - ca2-[9.5,10.3): 0.4613 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5290 - ca3-[10.3,11.3): 0.6233 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5578 - ca4-[11.3,14.9): 0.6813 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9106 - val_ca1-[11.3,14.9): 1.5466 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3917 - val_ca2-[10.3,11.3): 0.8262 - val_ca2-[11.3,14.9): 1.4321 - val_ca3-[8.0,9.5): 0.8883 - val_ca3-[9.5,10.3): 0.5177 - val_ca3-[10.3,11.3): 0.6600 - val_ca3-[11.3,14.9): 0.8505 - val_ca4-[8.0,9.5): 1.5639 - val_ca4-[9.5,10.3): 1.1323 - val_ca4-[10.3,11.3): 0.9631 - val_ca4-[11.3,14.9): 0.6684\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5086 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3614 - ca2-[9.5,10.3): 0.4522 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5230 - ca3-[10.3,11.3): 0.6175 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5768 - ca4-[11.3,14.9): 0.6884 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9092 - val_ca1-[11.3,14.9): 1.5469 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.3914 - val_ca2-[10.3,11.3): 0.8232 - val_ca2-[11.3,14.9): 1.4248 - val_ca3-[8.0,9.5): 0.8892 - val_ca3-[9.5,10.3): 0.5182 - val_ca3-[10.3,11.3): 0.6587 - val_ca3-[11.3,14.9): 0.8525 - val_ca4-[8.0,9.5): 1.5631 - val_ca4-[9.5,10.3): 1.1315 - val_ca4-[10.3,11.3): 0.9600 - val_ca4-[11.3,14.9): 0.6854\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5193 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3587 - ca2-[9.5,10.3): 0.4638 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4920 - ca3-[10.3,11.3): 0.6173 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5713 - ca4-[11.3,14.9): 0.6995 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9149 - val_ca1-[11.3,14.9): 1.5661 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.3901 - val_ca2-[10.3,11.3): 0.8177 - val_ca2-[11.3,14.9): 1.4211 - val_ca3-[8.0,9.5): 0.8967 - val_ca3-[9.5,10.3): 0.5225 - val_ca3-[10.3,11.3): 0.6593 - val_ca3-[11.3,14.9): 0.8474 - val_ca4-[8.0,9.5): 1.5624 - val_ca4-[9.5,10.3): 1.1308 - val_ca4-[10.3,11.3): 0.9767 - val_ca4-[11.3,14.9): 0.7044\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5160 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3580 - ca2-[9.5,10.3): 0.4608 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5377 - ca3-[10.3,11.3): 0.6159 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5491 - ca4-[11.3,14.9): 0.6885 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9153 - val_ca1-[11.3,14.9): 1.5746 - val_ca2-[8.0,9.5): 0.5895 - val_ca2-[9.5,10.3): 0.3899 - val_ca2-[10.3,11.3): 0.8154 - val_ca2-[11.3,14.9): 1.4140 - val_ca3-[8.0,9.5): 0.8889 - val_ca3-[9.5,10.3): 0.5161 - val_ca3-[10.3,11.3): 0.6590 - val_ca3-[11.3,14.9): 0.8391 - val_ca4-[8.0,9.5): 1.5637 - val_ca4-[9.5,10.3): 1.1318 - val_ca4-[10.3,11.3): 0.9773 - val_ca4-[11.3,14.9): 0.6879\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5228 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3601 - ca2-[9.5,10.3): 0.4504 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5102 - ca3-[10.3,11.3): 0.6069 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6024 - ca4-[11.3,14.9): 0.6817 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5780 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.3921 - val_ca2-[10.3,11.3): 0.8285 - val_ca2-[11.3,14.9): 1.4605 - val_ca3-[8.0,9.5): 0.8750 - val_ca3-[9.5,10.3): 0.5065 - val_ca3-[10.3,11.3): 0.6572 - val_ca3-[11.3,14.9): 0.8792 - val_ca4-[8.0,9.5): 1.5657 - val_ca4-[9.5,10.3): 1.1334 - val_ca4-[10.3,11.3): 0.9725 - val_ca4-[11.3,14.9): 0.6927\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5266 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3588 - ca2-[9.5,10.3): 0.4562 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5264 - ca3-[10.3,11.3): 0.6188 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5954 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9138 - val_ca1-[11.3,14.9): 1.5900 - val_ca2-[8.0,9.5): 0.5901 - val_ca2-[9.5,10.3): 0.3886 - val_ca2-[10.3,11.3): 0.8075 - val_ca2-[11.3,14.9): 1.4070 - val_ca3-[8.0,9.5): 0.9007 - val_ca3-[9.5,10.3): 0.5254 - val_ca3-[10.3,11.3): 0.6601 - val_ca3-[11.3,14.9): 0.8502 - val_ca4-[8.0,9.5): 1.5658 - val_ca4-[9.5,10.3): 1.1333 - val_ca4-[10.3,11.3): 0.9826 - val_ca4-[11.3,14.9): 0.7002\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5256 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3491 - ca2-[9.5,10.3): 0.4408 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5479 - ca3-[10.3,11.3): 0.6078 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5547 - ca4-[11.3,14.9): 0.6940 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9165 - val_ca1-[11.3,14.9): 1.5839 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3899 - val_ca2-[10.3,11.3): 0.8238 - val_ca2-[11.3,14.9): 1.4525 - val_ca3-[8.0,9.5): 0.8876 - val_ca3-[9.5,10.3): 0.5144 - val_ca3-[10.3,11.3): 0.6575 - val_ca3-[11.3,14.9): 0.8616 - val_ca4-[8.0,9.5): 1.5665 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9782 - val_ca4-[11.3,14.9): 0.6882\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5197 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3610 - ca2-[9.5,10.3): 0.4544 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5260 - ca3-[10.3,11.3): 0.6154 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5535 - ca4-[11.3,14.9): 0.7051 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9139 - val_ca1-[11.3,14.9): 1.5565 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.3876 - val_ca2-[10.3,11.3): 0.8102 - val_ca2-[11.3,14.9): 1.3952 - val_ca3-[8.0,9.5): 0.8818 - val_ca3-[9.5,10.3): 0.5095 - val_ca3-[10.3,11.3): 0.6546 - val_ca3-[11.3,14.9): 0.8446 - val_ca4-[8.0,9.5): 1.5670 - val_ca4-[9.5,10.3): 1.1341 - val_ca4-[10.3,11.3): 0.9757 - val_ca4-[11.3,14.9): 0.6678\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5139 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3418 - ca2-[9.5,10.3): 0.4465 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5210 - ca3-[10.3,11.3): 0.6146 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5757 - ca4-[11.3,14.9): 0.6899 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9092 - val_ca1-[11.3,14.9): 1.5882 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3899 - val_ca2-[10.3,11.3): 0.8229 - val_ca2-[11.3,14.9): 1.4721 - val_ca3-[8.0,9.5): 0.8830 - val_ca3-[9.5,10.3): 0.5106 - val_ca3-[10.3,11.3): 0.6542 - val_ca3-[11.3,14.9): 0.8745 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1335 - val_ca4-[10.3,11.3): 0.9772 - val_ca4-[11.3,14.9): 0.7058\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3412 - ca2-[9.5,10.3): 0.4442 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5414 - ca3-[10.3,11.3): 0.6209 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5923 - ca4-[11.3,14.9): 0.6954 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9087 - val_ca1-[11.3,14.9): 1.5865 - val_ca2-[8.0,9.5): 0.5915 - val_ca2-[9.5,10.3): 0.3855 - val_ca2-[10.3,11.3): 0.7959 - val_ca2-[11.3,14.9): 1.3987 - val_ca3-[8.0,9.5): 0.8818 - val_ca3-[9.5,10.3): 0.5104 - val_ca3-[10.3,11.3): 0.6549 - val_ca3-[11.3,14.9): 0.8660 - val_ca4-[8.0,9.5): 1.5669 - val_ca4-[9.5,10.3): 1.1337 - val_ca4-[10.3,11.3): 0.9772 - val_ca4-[11.3,14.9): 0.7170\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5026 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3441 - ca2-[9.5,10.3): 0.4382 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5007 - ca3-[10.3,11.3): 0.6042 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6059 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9045 - val_ca1-[11.3,14.9): 1.5540 - val_ca2-[8.0,9.5): 0.5814 - val_ca2-[9.5,10.3): 0.3888 - val_ca2-[10.3,11.3): 0.8260 - val_ca2-[11.3,14.9): 1.4510 - val_ca3-[8.0,9.5): 0.8905 - val_ca3-[9.5,10.3): 0.5167 - val_ca3-[10.3,11.3): 0.6517 - val_ca3-[11.3,14.9): 0.8422 - val_ca4-[8.0,9.5): 1.5682 - val_ca4-[9.5,10.3): 1.1347 - val_ca4-[10.3,11.3): 0.9631 - val_ca4-[11.3,14.9): 0.6738\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5291 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3532 - ca2-[9.5,10.3): 0.4552 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5732 - ca3-[10.3,11.3): 0.6311 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6216 - ca4-[11.3,14.9): 0.6911 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9111 - val_ca1-[11.3,14.9): 1.6071 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3847 - val_ca2-[10.3,11.3): 0.8048 - val_ca2-[11.3,14.9): 1.4367 - val_ca3-[8.0,9.5): 0.8937 - val_ca3-[9.5,10.3): 0.5181 - val_ca3-[10.3,11.3): 0.6519 - val_ca3-[11.3,14.9): 0.8631 - val_ca4-[8.0,9.5): 1.5675 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9632 - val_ca4-[11.3,14.9): 0.6962\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5068 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3541 - ca2-[9.5,10.3): 0.4409 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5262 - ca3-[10.3,11.3): 0.6063 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5444 - ca4-[11.3,14.9): 0.6770 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9139 - val_ca1-[11.3,14.9): 1.5482 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3867 - val_ca2-[10.3,11.3): 0.8181 - val_ca2-[11.3,14.9): 1.4176 - val_ca3-[8.0,9.5): 0.8765 - val_ca3-[9.5,10.3): 0.5066 - val_ca3-[10.3,11.3): 0.6521 - val_ca3-[11.3,14.9): 0.8464 - val_ca4-[8.0,9.5): 1.5682 - val_ca4-[9.5,10.3): 1.1344 - val_ca4-[10.3,11.3): 0.9753 - val_ca4-[11.3,14.9): 0.7010\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5191 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3488 - ca2-[9.5,10.3): 0.4413 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5326 - ca3-[10.3,11.3): 0.6012 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5625 - ca4-[11.3,14.9): 0.6795 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9146 - val_ca1-[11.3,14.9): 1.5644 - val_ca2-[8.0,9.5): 0.5900 - val_ca2-[9.5,10.3): 0.3838 - val_ca2-[10.3,11.3): 0.7979 - val_ca2-[11.3,14.9): 1.3707 - val_ca3-[8.0,9.5): 0.8842 - val_ca3-[9.5,10.3): 0.5127 - val_ca3-[10.3,11.3): 0.6553 - val_ca3-[11.3,14.9): 0.8388 - val_ca4-[8.0,9.5): 1.5661 - val_ca4-[9.5,10.3): 1.1324 - val_ca4-[10.3,11.3): 0.9646 - val_ca4-[11.3,14.9): 0.6680\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5233 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3473 - ca2-[9.5,10.3): 0.4411 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5526 - ca3-[10.3,11.3): 0.6100 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5651 - ca4-[11.3,14.9): 0.6963 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9105 - val_ca1-[11.3,14.9): 1.5515 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3857 - val_ca2-[10.3,11.3): 0.8115 - val_ca2-[11.3,14.9): 1.4234 - val_ca3-[8.0,9.5): 0.8804 - val_ca3-[9.5,10.3): 0.5081 - val_ca3-[10.3,11.3): 0.6501 - val_ca3-[11.3,14.9): 0.8494 - val_ca4-[8.0,9.5): 1.5641 - val_ca4-[9.5,10.3): 1.1305 - val_ca4-[10.3,11.3): 0.9747 - val_ca4-[11.3,14.9): 0.6838\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5096 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3535 - ca2-[9.5,10.3): 0.4490 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5365 - ca3-[10.3,11.3): 0.6185 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5407 - ca4-[11.3,14.9): 0.6798 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.6108 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3838 - val_ca2-[10.3,11.3): 0.8025 - val_ca2-[11.3,14.9): 1.4325 - val_ca3-[8.0,9.5): 0.8781 - val_ca3-[9.5,10.3): 0.5071 - val_ca3-[10.3,11.3): 0.6521 - val_ca3-[11.3,14.9): 0.8778 - val_ca4-[8.0,9.5): 1.5615 - val_ca4-[9.5,10.3): 1.1280 - val_ca4-[10.3,11.3): 0.9737 - val_ca4-[11.3,14.9): 0.7183\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5168 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3379 - ca2-[9.5,10.3): 0.4455 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5256 - ca3-[10.3,11.3): 0.6104 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5844 - ca4-[11.3,14.9): 0.6895 - val_ca1-[8.0,9.5): 0.5838 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9153 - val_ca1-[11.3,14.9): 1.5611 - val_ca2-[8.0,9.5): 0.5895 - val_ca2-[9.5,10.3): 0.3834 - val_ca2-[10.3,11.3): 0.7949 - val_ca2-[11.3,14.9): 1.3806 - val_ca3-[8.0,9.5): 0.8768 - val_ca3-[9.5,10.3): 0.5050 - val_ca3-[10.3,11.3): 0.6498 - val_ca3-[11.3,14.9): 0.8519 - val_ca4-[8.0,9.5): 1.5592 - val_ca4-[9.5,10.3): 1.1241 - val_ca4-[10.3,11.3): 0.9704 - val_ca4-[11.3,14.9): 0.6887\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5111 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3474 - ca2-[9.5,10.3): 0.4365 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5286 - ca3-[10.3,11.3): 0.6059 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6119 - ca4-[11.3,14.9): 0.6884 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9156 - val_ca1-[11.3,14.9): 1.5725 - val_ca2-[8.0,9.5): 0.5810 - val_ca2-[9.5,10.3): 0.3865 - val_ca2-[10.3,11.3): 0.8227 - val_ca2-[11.3,14.9): 1.4516 - val_ca3-[8.0,9.5): 0.8687 - val_ca3-[9.5,10.3): 0.5004 - val_ca3-[10.3,11.3): 0.6490 - val_ca3-[11.3,14.9): 0.8579 - val_ca4-[8.0,9.5): 1.5602 - val_ca4-[9.5,10.3): 1.1265 - val_ca4-[10.3,11.3): 0.9701 - val_ca4-[11.3,14.9): 0.6967\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5171 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3580 - ca2-[9.5,10.3): 0.4442 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5297 - ca3-[10.3,11.3): 0.6033 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5383 - ca4-[11.3,14.9): 0.6765 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9172 - val_ca1-[11.3,14.9): 1.6072 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.3814 - val_ca2-[10.3,11.3): 0.7945 - val_ca2-[11.3,14.9): 1.4101 - val_ca3-[8.0,9.5): 0.8735 - val_ca3-[9.5,10.3): 0.5041 - val_ca3-[10.3,11.3): 0.6493 - val_ca3-[11.3,14.9): 0.8738 - val_ca4-[8.0,9.5): 1.5608 - val_ca4-[9.5,10.3): 1.1268 - val_ca4-[10.3,11.3): 0.9727 - val_ca4-[11.3,14.9): 0.7098\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5191 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3395 - ca2-[9.5,10.3): 0.4348 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5329 - ca3-[10.3,11.3): 0.6289 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5610 - ca4-[11.3,14.9): 0.7001 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9148 - val_ca1-[11.3,14.9): 1.5836 - val_ca2-[8.0,9.5): 0.5825 - val_ca2-[9.5,10.3): 0.3837 - val_ca2-[10.3,11.3): 0.8122 - val_ca2-[11.3,14.9): 1.4398 - val_ca3-[8.0,9.5): 0.8665 - val_ca3-[9.5,10.3): 0.4999 - val_ca3-[10.3,11.3): 0.6473 - val_ca3-[11.3,14.9): 0.8645 - val_ca4-[8.0,9.5): 1.5607 - val_ca4-[9.5,10.3): 1.1265 - val_ca4-[10.3,11.3): 0.9699 - val_ca4-[11.3,14.9): 0.7086\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5209 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3416 - ca2-[9.5,10.3): 0.4454 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5523 - ca3-[10.3,11.3): 0.6107 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5790 - ca4-[11.3,14.9): 0.6862 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.5566 - val_ca2-[8.0,9.5): 0.5893 - val_ca2-[9.5,10.3): 0.3807 - val_ca2-[10.3,11.3): 0.7866 - val_ca2-[11.3,14.9): 1.3648 - val_ca3-[8.0,9.5): 0.8728 - val_ca3-[9.5,10.3): 0.5054 - val_ca3-[10.3,11.3): 0.6471 - val_ca3-[11.3,14.9): 0.8489 - val_ca4-[8.0,9.5): 1.5603 - val_ca4-[9.5,10.3): 1.1259 - val_ca4-[10.3,11.3): 0.9694 - val_ca4-[11.3,14.9): 0.6944\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5234 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3362 - ca2-[9.5,10.3): 0.4329 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5362 - ca3-[10.3,11.3): 0.5968 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5758 - ca4-[11.3,14.9): 0.6721 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9071 - val_ca1-[11.3,14.9): 1.5912 - val_ca2-[8.0,9.5): 0.5820 - val_ca2-[9.5,10.3): 0.3827 - val_ca2-[10.3,11.3): 0.8043 - val_ca2-[11.3,14.9): 1.4430 - val_ca3-[8.0,9.5): 0.8672 - val_ca3-[9.5,10.3): 0.5014 - val_ca3-[10.3,11.3): 0.6479 - val_ca3-[11.3,14.9): 0.8688 - val_ca4-[8.0,9.5): 1.5588 - val_ca4-[9.5,10.3): 1.1243 - val_ca4-[10.3,11.3): 0.9696 - val_ca4-[11.3,14.9): 0.7080\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5072 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3333 - ca2-[9.5,10.3): 0.4363 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5234 - ca3-[10.3,11.3): 0.6075 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5633 - ca4-[11.3,14.9): 0.6772 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9077 - val_ca1-[11.3,14.9): 1.5846 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.3806 - val_ca2-[10.3,11.3): 0.7942 - val_ca2-[11.3,14.9): 1.4112 - val_ca3-[8.0,9.5): 0.8667 - val_ca3-[9.5,10.3): 0.5004 - val_ca3-[10.3,11.3): 0.6429 - val_ca3-[11.3,14.9): 0.8632 - val_ca4-[8.0,9.5): 1.5594 - val_ca4-[9.5,10.3): 1.1245 - val_ca4-[10.3,11.3): 0.9531 - val_ca4-[11.3,14.9): 0.6964\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5129 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3335 - ca2-[9.5,10.3): 0.4342 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5037 - ca3-[10.3,11.3): 0.6124 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5731 - ca4-[11.3,14.9): 0.7020 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9108 - val_ca1-[11.3,14.9): 1.5634 - val_ca2-[8.0,9.5): 0.5814 - val_ca2-[9.5,10.3): 0.3803 - val_ca2-[10.3,11.3): 0.8017 - val_ca2-[11.3,14.9): 1.3981 - val_ca3-[8.0,9.5): 0.8575 - val_ca3-[9.5,10.3): 0.4937 - val_ca3-[10.3,11.3): 0.6454 - val_ca3-[11.3,14.9): 0.8472 - val_ca4-[8.0,9.5): 1.5576 - val_ca4-[9.5,10.3): 1.1227 - val_ca4-[10.3,11.3): 0.9717 - val_ca4-[11.3,14.9): 0.6986\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5191 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3235 - ca2-[9.5,10.3): 0.4312 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5366 - ca3-[10.3,11.3): 0.5945 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5831 - ca4-[11.3,14.9): 0.6982 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9132 - val_ca1-[11.3,14.9): 1.5865 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3781 - val_ca2-[10.3,11.3): 0.7829 - val_ca2-[11.3,14.9): 1.3716 - val_ca3-[8.0,9.5): 0.8734 - val_ca3-[9.5,10.3): 0.5071 - val_ca3-[10.3,11.3): 0.6435 - val_ca3-[11.3,14.9): 0.8479 - val_ca4-[8.0,9.5): 1.5572 - val_ca4-[9.5,10.3): 1.1220 - val_ca4-[10.3,11.3): 0.9667 - val_ca4-[11.3,14.9): 0.7139\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5273 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3393 - ca2-[9.5,10.3): 0.4349 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5173 - ca3-[10.3,11.3): 0.5984 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5778 - ca4-[11.3,14.9): 0.6856 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9073 - val_ca1-[11.3,14.9): 1.5648 - val_ca2-[8.0,9.5): 0.5813 - val_ca2-[9.5,10.3): 0.3804 - val_ca2-[10.3,11.3): 0.8042 - val_ca2-[11.3,14.9): 1.4103 - val_ca3-[8.0,9.5): 0.8583 - val_ca3-[9.5,10.3): 0.4968 - val_ca3-[10.3,11.3): 0.6442 - val_ca3-[11.3,14.9): 0.8474 - val_ca4-[8.0,9.5): 1.5554 - val_ca4-[9.5,10.3): 1.1200 - val_ca4-[10.3,11.3): 0.9556 - val_ca4-[11.3,14.9): 0.6817\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5180 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3404 - ca2-[9.5,10.3): 0.4363 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5019 - ca3-[10.3,11.3): 0.5967 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5631 - ca4-[11.3,14.9): 0.6776 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9092 - val_ca1-[11.3,14.9): 1.5744 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3774 - val_ca2-[10.3,11.3): 0.7743 - val_ca2-[11.3,14.9): 1.3646 - val_ca3-[8.0,9.5): 0.8478 - val_ca3-[9.5,10.3): 0.4895 - val_ca3-[10.3,11.3): 0.6409 - val_ca3-[11.3,14.9): 0.8722 - val_ca4-[8.0,9.5): 1.5519 - val_ca4-[9.5,10.3): 1.1166 - val_ca4-[10.3,11.3): 0.9651 - val_ca4-[11.3,14.9): 0.7123\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5155 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3287 - ca2-[9.5,10.3): 0.4250 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5136 - ca3-[10.3,11.3): 0.5987 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5881 - ca4-[11.3,14.9): 0.6878 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9139 - val_ca1-[11.3,14.9): 1.5621 - val_ca2-[8.0,9.5): 0.5805 - val_ca2-[9.5,10.3): 0.3786 - val_ca2-[10.3,11.3): 0.7987 - val_ca2-[11.3,14.9): 1.3808 - val_ca3-[8.0,9.5): 0.8612 - val_ca3-[9.5,10.3): 0.4997 - val_ca3-[10.3,11.3): 0.6397 - val_ca3-[11.3,14.9): 0.8263 - val_ca4-[8.0,9.5): 1.5534 - val_ca4-[9.5,10.3): 1.1175 - val_ca4-[10.3,11.3): 0.9636 - val_ca4-[11.3,14.9): 0.6930\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5072 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3259 - ca2-[9.5,10.3): 0.4236 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5163 - ca3-[10.3,11.3): 0.5907 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5720 - ca4-[11.3,14.9): 0.6896 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9074 - val_ca1-[11.3,14.9): 1.6115 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3778 - val_ca2-[10.3,11.3): 0.7913 - val_ca2-[11.3,14.9): 1.4366 - val_ca3-[8.0,9.5): 0.8531 - val_ca3-[9.5,10.3): 0.4940 - val_ca3-[10.3,11.3): 0.6397 - val_ca3-[11.3,14.9): 0.8760 - val_ca4-[8.0,9.5): 1.5562 - val_ca4-[9.5,10.3): 1.1194 - val_ca4-[10.3,11.3): 0.9547 - val_ca4-[11.3,14.9): 0.6976\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5265 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3364 - ca2-[9.5,10.3): 0.4310 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5049 - ca3-[10.3,11.3): 0.5974 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5021 - ca4-[11.3,14.9): 0.6853 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9061 - val_ca1-[11.3,14.9): 1.5737 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3761 - val_ca2-[10.3,11.3): 0.7659 - val_ca2-[11.3,14.9): 1.3296 - val_ca3-[8.0,9.5): 0.8391 - val_ca3-[9.5,10.3): 0.4861 - val_ca3-[10.3,11.3): 0.6414 - val_ca3-[11.3,14.9): 0.8666 - val_ca4-[8.0,9.5): 1.5578 - val_ca4-[9.5,10.3): 1.1203 - val_ca4-[10.3,11.3): 0.9712 - val_ca4-[11.3,14.9): 0.7048\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 1s 140ms/step - ca1-[8.0,9.5): 0.5158 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3411 - ca2-[9.5,10.3): 0.4186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5395 - ca3-[10.3,11.3): 0.6100 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5991 - ca4-[11.3,14.9): 0.6936 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9093 - val_ca1-[11.3,14.9): 1.6009 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3751 - val_ca2-[10.3,11.3): 0.7805 - val_ca2-[11.3,14.9): 1.3970 - val_ca3-[8.0,9.5): 0.8497 - val_ca3-[9.5,10.3): 0.4930 - val_ca3-[10.3,11.3): 0.6388 - val_ca3-[11.3,14.9): 0.8709 - val_ca4-[8.0,9.5): 1.5570 - val_ca4-[9.5,10.3): 1.1190 - val_ca4-[10.3,11.3): 0.9496 - val_ca4-[11.3,14.9): 0.6914\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5047 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3326 - ca2-[9.5,10.3): 0.4236 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5283 - ca3-[10.3,11.3): 0.5953 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5631 - ca4-[11.3,14.9): 0.6949 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5965 - val_ca2-[8.0,9.5): 0.5900 - val_ca2-[9.5,10.3): 0.3740 - val_ca2-[10.3,11.3): 0.7674 - val_ca2-[11.3,14.9): 1.3443 - val_ca3-[8.0,9.5): 0.8597 - val_ca3-[9.5,10.3): 0.5004 - val_ca3-[10.3,11.3): 0.6389 - val_ca3-[11.3,14.9): 0.8485 - val_ca4-[8.0,9.5): 1.5585 - val_ca4-[9.5,10.3): 1.1197 - val_ca4-[10.3,11.3): 0.9664 - val_ca4-[11.3,14.9): 0.7108\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5118 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3295 - ca2-[9.5,10.3): 0.4240 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5082 - ca3-[10.3,11.3): 0.5964 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5618 - ca4-[11.3,14.9): 0.6999 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9157 - val_ca1-[11.3,14.9): 1.5912 - val_ca2-[8.0,9.5): 0.5788 - val_ca2-[9.5,10.3): 0.3765 - val_ca2-[10.3,11.3): 0.7925 - val_ca2-[11.3,14.9): 1.4107 - val_ca3-[8.0,9.5): 0.8163 - val_ca3-[9.5,10.3): 0.4723 - val_ca3-[10.3,11.3): 0.6415 - val_ca3-[11.3,14.9): 0.8933 - val_ca4-[8.0,9.5): 1.5589 - val_ca4-[9.5,10.3): 1.1195 - val_ca4-[10.3,11.3): 0.9658 - val_ca4-[11.3,14.9): 0.6932\n",
      "Epoch 273/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5178 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3279 - ca2-[9.5,10.3): 0.4138 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5046 - ca3-[10.3,11.3): 0.6003 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5812 - ca4-[11.3,14.9): 0.6727 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9042 - val_ca1-[11.3,14.9): 1.5570 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.3739 - val_ca2-[10.3,11.3): 0.7671 - val_ca2-[11.3,14.9): 1.3361 - val_ca3-[8.0,9.5): 0.8503 - val_ca3-[9.5,10.3): 0.4952 - val_ca3-[10.3,11.3): 0.6337 - val_ca3-[11.3,14.9): 0.8218 - val_ca4-[8.0,9.5): 1.5570 - val_ca4-[9.5,10.3): 1.1171 - val_ca4-[10.3,11.3): 0.9655 - val_ca4-[11.3,14.9): 0.6888\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5216 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3294 - ca2-[9.5,10.3): 0.4270 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5188 - ca3-[10.3,11.3): 0.5973 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5627 - ca4-[11.3,14.9): 0.6873 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9130 - val_ca1-[11.3,14.9): 1.5816 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.3743 - val_ca2-[10.3,11.3): 0.7715 - val_ca2-[11.3,14.9): 1.3542 - val_ca3-[8.0,9.5): 0.8422 - val_ca3-[9.5,10.3): 0.4893 - val_ca3-[10.3,11.3): 0.6341 - val_ca3-[11.3,14.9): 0.8391 - val_ca4-[8.0,9.5): 1.5547 - val_ca4-[9.5,10.3): 1.1145 - val_ca4-[10.3,11.3): 0.9598 - val_ca4-[11.3,14.9): 0.6640\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5257 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3262 - ca2-[9.5,10.3): 0.4239 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5039 - ca3-[10.3,11.3): 0.5830 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5479 - ca4-[11.3,14.9): 0.6916 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.8999 - val_ca1-[11.3,14.9): 1.5793 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3728 - val_ca2-[10.3,11.3): 0.7427 - val_ca2-[11.3,14.9): 1.3172 - val_ca3-[8.0,9.5): 0.8200 - val_ca3-[9.5,10.3): 0.4754 - val_ca3-[10.3,11.3): 0.6260 - val_ca3-[11.3,14.9): 0.8643 - val_ca4-[8.0,9.5): 1.5538 - val_ca4-[9.5,10.3): 1.1130 - val_ca4-[10.3,11.3): 0.9532 - val_ca4-[11.3,14.9): 0.6887\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5209 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3169 - ca2-[9.5,10.3): 0.4015 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5028 - ca3-[10.3,11.3): 0.6013 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5624 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9156 - val_ca1-[11.3,14.9): 1.5909 - val_ca2-[8.0,9.5): 0.5846 - val_ca2-[9.5,10.3): 0.3725 - val_ca2-[10.3,11.3): 0.7741 - val_ca2-[11.3,14.9): 1.3738 - val_ca3-[8.0,9.5): 0.8523 - val_ca3-[9.5,10.3): 0.4991 - val_ca3-[10.3,11.3): 0.6353 - val_ca3-[11.3,14.9): 0.8326 - val_ca4-[8.0,9.5): 1.5534 - val_ca4-[9.5,10.3): 1.1119 - val_ca4-[10.3,11.3): 0.9599 - val_ca4-[11.3,14.9): 0.6964\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5195 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3210 - ca2-[9.5,10.3): 0.4160 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5226 - ca3-[10.3,11.3): 0.5969 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5572 - ca4-[11.3,14.9): 0.6902 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9057 - val_ca1-[11.3,14.9): 1.5864 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3727 - val_ca2-[10.3,11.3): 0.7514 - val_ca2-[11.3,14.9): 1.3297 - val_ca3-[8.0,9.5): 0.7924 - val_ca3-[9.5,10.3): 0.4599 - val_ca3-[10.3,11.3): 0.6215 - val_ca3-[11.3,14.9): 0.8886 - val_ca4-[8.0,9.5): 1.5565 - val_ca4-[9.5,10.3): 1.1139 - val_ca4-[10.3,11.3): 0.9300 - val_ca4-[11.3,14.9): 0.6829\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5198 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3358 - ca2-[9.5,10.3): 0.4166 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5209 - ca3-[10.3,11.3): 0.5897 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5758 - ca4-[11.3,14.9): 0.6740 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9040 - val_ca1-[11.3,14.9): 1.5739 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3718 - val_ca2-[10.3,11.3): 0.7561 - val_ca2-[11.3,14.9): 1.3282 - val_ca3-[8.0,9.5): 0.8287 - val_ca3-[9.5,10.3): 0.4857 - val_ca3-[10.3,11.3): 0.6298 - val_ca3-[11.3,14.9): 0.8422 - val_ca4-[8.0,9.5): 1.5517 - val_ca4-[9.5,10.3): 1.1088 - val_ca4-[10.3,11.3): 0.9587 - val_ca4-[11.3,14.9): 0.6953\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 1s 150ms/step - ca1-[8.0,9.5): 0.5056 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3261 - ca2-[9.5,10.3): 0.4170 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5519 - ca3-[10.3,11.3): 0.5892 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5793 - ca4-[11.3,14.9): 0.6816 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9118 - val_ca1-[11.3,14.9): 1.5673 - val_ca2-[8.0,9.5): 0.5916 - val_ca2-[9.5,10.3): 0.3705 - val_ca2-[10.3,11.3): 0.7527 - val_ca2-[11.3,14.9): 1.2904 - val_ca3-[8.0,9.5): 0.8035 - val_ca3-[9.5,10.3): 0.4690 - val_ca3-[10.3,11.3): 0.6233 - val_ca3-[11.3,14.9): 0.8399 - val_ca4-[8.0,9.5): 1.5474 - val_ca4-[9.5,10.3): 1.1042 - val_ca4-[10.3,11.3): 0.9390 - val_ca4-[11.3,14.9): 0.6792\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5045 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3372 - ca2-[9.5,10.3): 0.4121 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5161 - ca3-[10.3,11.3): 0.6099 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5074 - ca4-[11.3,14.9): 0.6850 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9199 - val_ca1-[11.3,14.9): 1.5711 - val_ca2-[8.0,9.5): 0.5916 - val_ca2-[9.5,10.3): 0.3705 - val_ca2-[10.3,11.3): 0.7506 - val_ca2-[11.3,14.9): 1.2775 - val_ca3-[8.0,9.5): 0.8165 - val_ca3-[9.5,10.3): 0.4769 - val_ca3-[10.3,11.3): 0.6348 - val_ca3-[11.3,14.9): 0.8323 - val_ca4-[8.0,9.5): 1.5456 - val_ca4-[9.5,10.3): 1.1018 - val_ca4-[10.3,11.3): 0.9528 - val_ca4-[11.3,14.9): 0.6917\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5288 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3392 - ca2-[9.5,10.3): 0.4193 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4956 - ca3-[10.3,11.3): 0.5874 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5913 - ca4-[11.3,14.9): 0.6752 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9107 - val_ca1-[11.3,14.9): 1.5635 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3725 - val_ca2-[10.3,11.3): 0.7660 - val_ca2-[11.3,14.9): 1.3233 - val_ca3-[8.0,9.5): 0.7880 - val_ca3-[9.5,10.3): 0.4593 - val_ca3-[10.3,11.3): 0.6296 - val_ca3-[11.3,14.9): 0.8543 - val_ca4-[8.0,9.5): 1.5489 - val_ca4-[9.5,10.3): 1.1038 - val_ca4-[10.3,11.3): 0.9551 - val_ca4-[11.3,14.9): 0.6916\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5167 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3322 - ca2-[9.5,10.3): 0.4186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4744 - ca3-[10.3,11.3): 0.5720 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5743 - ca4-[11.3,14.9): 0.6865 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9068 - val_ca1-[11.3,14.9): 1.5709 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3697 - val_ca2-[10.3,11.3): 0.7502 - val_ca2-[11.3,14.9): 1.2974 - val_ca3-[8.0,9.5): 0.8154 - val_ca3-[9.5,10.3): 0.4803 - val_ca3-[10.3,11.3): 0.6285 - val_ca3-[11.3,14.9): 0.8168 - val_ca4-[8.0,9.5): 1.5450 - val_ca4-[9.5,10.3): 1.0994 - val_ca4-[10.3,11.3): 0.9339 - val_ca4-[11.3,14.9): 0.6636\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5173 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3256 - ca2-[9.5,10.3): 0.4051 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5052 - ca3-[10.3,11.3): 0.5946 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6013 - ca4-[11.3,14.9): 0.6895 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9103 - val_ca1-[11.3,14.9): 1.5533 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3695 - val_ca2-[10.3,11.3): 0.7491 - val_ca2-[11.3,14.9): 1.2804 - val_ca3-[8.0,9.5): 0.8157 - val_ca3-[9.5,10.3): 0.4820 - val_ca3-[10.3,11.3): 0.6261 - val_ca3-[11.3,14.9): 0.8039 - val_ca4-[8.0,9.5): 1.5454 - val_ca4-[9.5,10.3): 1.0991 - val_ca4-[10.3,11.3): 0.9506 - val_ca4-[11.3,14.9): 0.6891\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5259 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3267 - ca2-[9.5,10.3): 0.4186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5286 - ca3-[10.3,11.3): 0.5934 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5625 - ca4-[11.3,14.9): 0.6738 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9184 - val_ca1-[11.3,14.9): 1.5708 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3684 - val_ca2-[10.3,11.3): 0.7514 - val_ca2-[11.3,14.9): 1.2927 - val_ca3-[8.0,9.5): 0.7698 - val_ca3-[9.5,10.3): 0.4517 - val_ca3-[10.3,11.3): 0.6307 - val_ca3-[11.3,14.9): 0.8571 - val_ca4-[8.0,9.5): 1.5390 - val_ca4-[9.5,10.3): 1.0914 - val_ca4-[10.3,11.3): 0.9490 - val_ca4-[11.3,14.9): 0.6927\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5069 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3305 - ca2-[9.5,10.3): 0.4094 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5023 - ca3-[10.3,11.3): 0.5799 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5517 - ca4-[11.3,14.9): 0.6768 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9138 - val_ca1-[11.3,14.9): 1.5739 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3705 - val_ca2-[10.3,11.3): 0.7557 - val_ca2-[11.3,14.9): 1.3037 - val_ca3-[8.0,9.5): 0.7818 - val_ca3-[9.5,10.3): 0.4600 - val_ca3-[10.3,11.3): 0.6251 - val_ca3-[11.3,14.9): 0.8399 - val_ca4-[8.0,9.5): 1.5334 - val_ca4-[9.5,10.3): 1.0825 - val_ca4-[10.3,11.3): 0.9172 - val_ca4-[11.3,14.9): 0.6592\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5156 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3173 - ca2-[9.5,10.3): 0.4025 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5149 - ca3-[10.3,11.3): 0.5733 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5609 - ca4-[11.3,14.9): 0.6769 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9084 - val_ca1-[11.3,14.9): 1.5601 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.3681 - val_ca2-[10.3,11.3): 0.7448 - val_ca2-[11.3,14.9): 1.2638 - val_ca3-[8.0,9.5): 0.7599 - val_ca3-[9.5,10.3): 0.4446 - val_ca3-[10.3,11.3): 0.6232 - val_ca3-[11.3,14.9): 0.8401 - val_ca4-[8.0,9.5): 1.5292 - val_ca4-[9.5,10.3): 1.0789 - val_ca4-[10.3,11.3): 0.9336 - val_ca4-[11.3,14.9): 0.6896\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5257 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3243 - ca2-[9.5,10.3): 0.4137 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5007 - ca3-[10.3,11.3): 0.5871 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5775 - ca4-[11.3,14.9): 0.6691 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.8950 - val_ca1-[11.3,14.9): 1.5654 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3672 - val_ca2-[10.3,11.3): 0.7212 - val_ca2-[11.3,14.9): 1.2606 - val_ca3-[8.0,9.5): 0.7803 - val_ca3-[9.5,10.3): 0.4617 - val_ca3-[10.3,11.3): 0.6121 - val_ca3-[11.3,14.9): 0.8206 - val_ca4-[8.0,9.5): 1.5322 - val_ca4-[9.5,10.3): 1.0796 - val_ca4-[10.3,11.3): 0.9259 - val_ca4-[11.3,14.9): 0.6914\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5163 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3250 - ca2-[9.5,10.3): 0.4103 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4803 - ca3-[10.3,11.3): 0.5768 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5474 - ca4-[11.3,14.9): 0.6919 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9053 - val_ca1-[11.3,14.9): 1.5795 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.3676 - val_ca2-[10.3,11.3): 0.7411 - val_ca2-[11.3,14.9): 1.2915 - val_ca3-[8.0,9.5): 0.7647 - val_ca3-[9.5,10.3): 0.4522 - val_ca3-[10.3,11.3): 0.6221 - val_ca3-[11.3,14.9): 0.8449 - val_ca4-[8.0,9.5): 1.5390 - val_ca4-[9.5,10.3): 1.0837 - val_ca4-[10.3,11.3): 0.9379 - val_ca4-[11.3,14.9): 0.6869\n",
      "Epoch 289/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5257 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3195 - ca2-[9.5,10.3): 0.4177 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5038 - ca3-[10.3,11.3): 0.5742 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5641 - ca4-[11.3,14.9): 0.6809 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9126 - val_ca1-[11.3,14.9): 1.5599 - val_ca2-[8.0,9.5): 0.5976 - val_ca2-[9.5,10.3): 0.3670 - val_ca2-[10.3,11.3): 0.7195 - val_ca2-[11.3,14.9): 1.2029 - val_ca3-[8.0,9.5): 0.7694 - val_ca3-[9.5,10.3): 0.4556 - val_ca3-[10.3,11.3): 0.6186 - val_ca3-[11.3,14.9): 0.8149 - val_ca4-[8.0,9.5): 1.5331 - val_ca4-[9.5,10.3): 1.0758 - val_ca4-[10.3,11.3): 0.9257 - val_ca4-[11.3,14.9): 0.6747\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5092 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3155 - ca2-[9.5,10.3): 0.4252 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4645 - ca3-[10.3,11.3): 0.5812 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5920 - ca4-[11.3,14.9): 0.6917 - val_ca1-[8.0,9.5): 0.5824 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9133 - val_ca1-[11.3,14.9): 1.6015 - val_ca2-[8.0,9.5): 0.5935 - val_ca2-[9.5,10.3): 0.3679 - val_ca2-[10.3,11.3): 0.7205 - val_ca2-[11.3,14.9): 1.2291 - val_ca3-[8.0,9.5): 0.7483 - val_ca3-[9.5,10.3): 0.4433 - val_ca3-[10.3,11.3): 0.6193 - val_ca3-[11.3,14.9): 0.8513 - val_ca4-[8.0,9.5): 1.5357 - val_ca4-[9.5,10.3): 1.0766 - val_ca4-[10.3,11.3): 0.9246 - val_ca4-[11.3,14.9): 0.6831\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5176 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3252 - ca2-[9.5,10.3): 0.4048 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4916 - ca3-[10.3,11.3): 0.5828 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5779 - ca4-[11.3,14.9): 0.6876 - val_ca1-[8.0,9.5): 0.5821 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5892 - val_ca2-[8.0,9.5): 0.5758 - val_ca2-[9.5,10.3): 0.3719 - val_ca2-[10.3,11.3): 0.7783 - val_ca2-[11.3,14.9): 1.3776 - val_ca3-[8.0,9.5): 0.7682 - val_ca3-[9.5,10.3): 0.4551 - val_ca3-[10.3,11.3): 0.6198 - val_ca3-[11.3,14.9): 0.8279 - val_ca4-[8.0,9.5): 1.5417 - val_ca4-[9.5,10.3): 1.0787 - val_ca4-[10.3,11.3): 0.9231 - val_ca4-[11.3,14.9): 0.6846\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5086 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3236 - ca2-[9.5,10.3): 0.4088 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5023 - ca3-[10.3,11.3): 0.5772 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5588 - ca4-[11.3,14.9): 0.6674 - val_ca1-[8.0,9.5): 0.5819 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9063 - val_ca1-[11.3,14.9): 1.5889 - val_ca2-[8.0,9.5): 0.5934 - val_ca2-[9.5,10.3): 0.3659 - val_ca2-[10.3,11.3): 0.7183 - val_ca2-[11.3,14.9): 1.2355 - val_ca3-[8.0,9.5): 0.7366 - val_ca3-[9.5,10.3): 0.4386 - val_ca3-[10.3,11.3): 0.6183 - val_ca3-[11.3,14.9): 0.8504 - val_ca4-[8.0,9.5): 1.5399 - val_ca4-[9.5,10.3): 1.0767 - val_ca4-[10.3,11.3): 0.9244 - val_ca4-[11.3,14.9): 0.6822\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5158 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3167 - ca2-[9.5,10.3): 0.4077 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5012 - ca3-[10.3,11.3): 0.5718 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5532 - ca4-[11.3,14.9): 0.6661 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.8992 - val_ca1-[11.3,14.9): 1.5595 - val_ca2-[8.0,9.5): 0.5898 - val_ca2-[9.5,10.3): 0.3654 - val_ca2-[10.3,11.3): 0.7120 - val_ca2-[11.3,14.9): 1.2111 - val_ca3-[8.0,9.5): 0.7126 - val_ca3-[9.5,10.3): 0.4236 - val_ca3-[10.3,11.3): 0.5985 - val_ca3-[11.3,14.9): 0.8490 - val_ca4-[8.0,9.5): 1.5319 - val_ca4-[9.5,10.3): 1.0640 - val_ca4-[10.3,11.3): 0.8840 - val_ca4-[11.3,14.9): 0.6695\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3207 - ca2-[9.5,10.3): 0.4091 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5038 - ca3-[10.3,11.3): 0.5812 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5500 - ca4-[11.3,14.9): 0.6771 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9155 - val_ca1-[11.3,14.9): 1.5975 - val_ca2-[8.0,9.5): 0.5943 - val_ca2-[9.5,10.3): 0.3657 - val_ca2-[10.3,11.3): 0.7210 - val_ca2-[11.3,14.9): 1.2419 - val_ca3-[8.0,9.5): 0.7066 - val_ca3-[9.5,10.3): 0.4238 - val_ca3-[10.3,11.3): 0.6195 - val_ca3-[11.3,14.9): 0.8721 - val_ca4-[8.0,9.5): 1.5303 - val_ca4-[9.5,10.3): 1.0622 - val_ca4-[10.3,11.3): 0.9117 - val_ca4-[11.3,14.9): 0.6740\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5170 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3103 - ca2-[9.5,10.3): 0.3954 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5078 - ca3-[10.3,11.3): 0.5784 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5500 - ca4-[11.3,14.9): 0.6677 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9109 - val_ca1-[11.3,14.9): 1.5532 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3663 - val_ca2-[10.3,11.3): 0.7326 - val_ca2-[11.3,14.9): 1.2403 - val_ca3-[8.0,9.5): 0.7580 - val_ca3-[9.5,10.3): 0.4563 - val_ca3-[10.3,11.3): 0.6157 - val_ca3-[11.3,14.9): 0.7984 - val_ca4-[8.0,9.5): 1.5433 - val_ca4-[9.5,10.3): 1.0715 - val_ca4-[10.3,11.3): 0.9089 - val_ca4-[11.3,14.9): 0.6703\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5281 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3284 - ca2-[9.5,10.3): 0.4109 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4736 - ca3-[10.3,11.3): 0.5566 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5138 - ca4-[11.3,14.9): 0.6506 - val_ca1-[8.0,9.5): 0.5815 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.6064 - val_ca2-[8.0,9.5): 0.5819 - val_ca2-[9.5,10.3): 0.3654 - val_ca2-[10.3,11.3): 0.7371 - val_ca2-[11.3,14.9): 1.2822 - val_ca3-[8.0,9.5): 0.7218 - val_ca3-[9.5,10.3): 0.4318 - val_ca3-[10.3,11.3): 0.6165 - val_ca3-[11.3,14.9): 0.8498 - val_ca4-[8.0,9.5): 1.5304 - val_ca4-[9.5,10.3): 1.0538 - val_ca4-[10.3,11.3): 0.8917 - val_ca4-[11.3,14.9): 0.6638\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5166 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3185 - ca2-[9.5,10.3): 0.4015 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4799 - ca3-[10.3,11.3): 0.5675 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5861 - ca4-[11.3,14.9): 0.6475 - val_ca1-[8.0,9.5): 0.5815 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9105 - val_ca1-[11.3,14.9): 1.5898 - val_ca2-[8.0,9.5): 0.6022 - val_ca2-[9.5,10.3): 0.3657 - val_ca2-[10.3,11.3): 0.6997 - val_ca2-[11.3,14.9): 1.1630 - val_ca3-[8.0,9.5): 0.7142 - val_ca3-[9.5,10.3): 0.4280 - val_ca3-[10.3,11.3): 0.6130 - val_ca3-[11.3,14.9): 0.8300 - val_ca4-[8.0,9.5): 1.5324 - val_ca4-[9.5,10.3): 1.0514 - val_ca4-[10.3,11.3): 0.8876 - val_ca4-[11.3,14.9): 0.6424\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5151 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3124 - ca2-[9.5,10.3): 0.3891 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4459 - ca3-[10.3,11.3): 0.5719 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5378 - ca4-[11.3,14.9): 0.6652 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4202 - val_ca1-[10.3,11.3): 0.9060 - val_ca1-[11.3,14.9): 1.5653 - val_ca2-[8.0,9.5): 0.5898 - val_ca2-[9.5,10.3): 0.3647 - val_ca2-[10.3,11.3): 0.7123 - val_ca2-[11.3,14.9): 1.2033 - val_ca3-[8.0,9.5): 0.7383 - val_ca3-[9.5,10.3): 0.4461 - val_ca3-[10.3,11.3): 0.6070 - val_ca3-[11.3,14.9): 0.7975 - val_ca4-[8.0,9.5): 1.5435 - val_ca4-[9.5,10.3): 1.0583 - val_ca4-[10.3,11.3): 0.8779 - val_ca4-[11.3,14.9): 0.6457\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5261 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3201 - ca2-[9.5,10.3): 0.4049 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4640 - ca3-[10.3,11.3): 0.5797 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5821 - ca4-[11.3,14.9): 0.6630 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4200 - val_ca1-[10.3,11.3): 0.9135 - val_ca1-[11.3,14.9): 1.5883 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3661 - val_ca2-[10.3,11.3): 0.7245 - val_ca2-[11.3,14.9): 1.2488 - val_ca3-[8.0,9.5): 0.7446 - val_ca3-[9.5,10.3): 0.4534 - val_ca3-[10.3,11.3): 0.6089 - val_ca3-[11.3,14.9): 0.8030 - val_ca4-[8.0,9.5): 1.5580 - val_ca4-[9.5,10.3): 1.0674 - val_ca4-[10.3,11.3): 0.8824 - val_ca4-[11.3,14.9): 0.6597\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5201 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3268 - ca2-[9.5,10.3): 0.4013 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5066 - ca3-[10.3,11.3): 0.5667 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5329 - ca4-[11.3,14.9): 0.6598 - val_ca1-[8.0,9.5): 0.5815 - val_ca1-[9.5,10.3): 0.4200 - val_ca1-[10.3,11.3): 0.9138 - val_ca1-[11.3,14.9): 1.5577 - val_ca2-[8.0,9.5): 0.5914 - val_ca2-[9.5,10.3): 0.3623 - val_ca2-[10.3,11.3): 0.7140 - val_ca2-[11.3,14.9): 1.1796 - val_ca3-[8.0,9.5): 0.7026 - val_ca3-[9.5,10.3): 0.4270 - val_ca3-[10.3,11.3): 0.6123 - val_ca3-[11.3,14.9): 0.8177 - val_ca4-[8.0,9.5): 1.5514 - val_ca4-[9.5,10.3): 1.0566 - val_ca4-[10.3,11.3): 0.8770 - val_ca4-[11.3,14.9): 0.6373\n",
      "CPU times: user 6min 26s, sys: 3.42 s, total: 6min 30s\n",
      "Wall time: 6min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('djgrad')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2})') for ca,(q1,q2) in product(range(4),zip(quants[:-1],quants[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "\n",
    "history = m.fit(\n",
    "    train_dataset,\n",
    "#     validation_split=0.2,\n",
    "    epochs=300,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "# with open(os.path.join(fp_local,'no_sharing.pickle'), 'wb') as handle:\n",
    "#     pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "for k in [k for k in history.history if 'val_ca1' in k]:\n",
    "    plt.plot(history.history[k], label=k.split('-')[1])\n",
    "        \n",
    "plt.legend()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ca1-[8.0,9.5)</th>\n",
       "      <td>0.527901</td>\n",
       "      <td>0.581487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[9.5,10.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.419987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[10.3,11.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.913848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.557681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[8.0,9.5)</th>\n",
       "      <td>0.320806</td>\n",
       "      <td>0.591429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[9.5,10.3)</th>\n",
       "      <td>0.394335</td>\n",
       "      <td>0.362250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[10.3,11.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.714011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.179638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[8.0,9.5)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.702616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[9.5,10.3)</th>\n",
       "      <td>0.482375</td>\n",
       "      <td>0.427019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[10.3,11.3)</th>\n",
       "      <td>0.558645</td>\n",
       "      <td>0.612300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.817746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[8.0,9.5)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.551364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[9.5,10.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.056619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[10.3,11.3)</th>\n",
       "      <td>0.520652</td>\n",
       "      <td>0.876950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[11.3,14.9)</th>\n",
       "      <td>0.668571</td>\n",
       "      <td>0.637342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train      test\n",
       "ca1-[8.0,9.5)    0.527901  0.581487\n",
       "ca1-[9.5,10.3)          -  0.419987\n",
       "ca1-[10.3,11.3)         -  0.913848\n",
       "ca1-[11.3,14.9)         -  1.557681\n",
       "ca2-[8.0,9.5)    0.320806  0.591429\n",
       "ca2-[9.5,10.3)   0.394335  0.362250\n",
       "ca2-[10.3,11.3)         -  0.714011\n",
       "ca2-[11.3,14.9)         -  1.179638\n",
       "ca3-[8.0,9.5)           -  0.702616\n",
       "ca3-[9.5,10.3)   0.482375  0.427019\n",
       "ca3-[10.3,11.3)  0.558645  0.612300\n",
       "ca3-[11.3,14.9)         -  0.817746\n",
       "ca4-[8.0,9.5)           -  1.551364\n",
       "ca4-[9.5,10.3)          -  1.056619\n",
       "ca4-[10.3,11.3)  0.520652  0.876950\n",
       "ca4-[11.3,14.9)  0.668571  0.637342"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data=[[history.history[k][-1] if history.history[k][-1]!=0 else '-',history.history['val_'+k][-1]] for k in history.history if 'val' not in k],\n",
    "    index=[k for k in history.history if 'val' not in k],\n",
    "    columns=['train','test']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike = pd.read_csv(os.path.join(fp_data,'hour.csv'),delimiter=',')\n",
    "# bike = bike.append(pd.read_csv(os.path.join(fp_data,'winequality-white.csv'),delimiter=';'))\n",
    "bike = bike.drop(['dteday','instant'],axis=1).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7764</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15063</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>52</td>\n",
       "      <td>380</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14817</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.6515</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>113</td>\n",
       "      <td>258</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.4478</td>\n",
       "      <td>143</td>\n",
       "      <td>163</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17046</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10539</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>6</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>129</td>\n",
       "      <td>239</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.6515</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>49</td>\n",
       "      <td>129</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "7764        4   0    11   3        0        5           1           1  0.28   \n",
       "15063       4   1     9  20        0        1           1           1  0.52   \n",
       "14817       3   1     9  14        0        5           1           2  0.72   \n",
       "2467        2   0     4  17        0        0           0           1  0.56   \n",
       "17046       4   1    12   1        0        2           1           2  0.44   \n",
       "...       ...  ..   ...  ..      ...      ...         ...         ...   ...   \n",
       "10539       1   1     3   6        0        2           1           2  0.52   \n",
       "192         1   0     1   7        0        0           0           1  0.08   \n",
       "10496       1   1     3  11        0        0           0           2  0.44   \n",
       "4576        3   0     7  14        0        4           1           1  0.74   \n",
       "1949        2   0     3   0        0        0           0           2  0.26   \n",
       "\n",
       "        atemp   hum  windspeed  casual  registered  cnt  \n",
       "7764   0.2879  0.75     0.1045       0           2    2  \n",
       "15063  0.5000  0.52     0.1045      52         380  432  \n",
       "14817  0.6515  0.45     0.1642     113         258  371  \n",
       "2467   0.5303  0.30     0.4478     143         163  306  \n",
       "17046  0.4394  0.94     0.1343       0          15   15  \n",
       "...       ...   ...        ...     ...         ...  ...  \n",
       "10539  0.5000  0.94     0.1642       6          94  100  \n",
       "192    0.0909  0.53     0.1940       1           5    6  \n",
       "10496  0.4394  0.82     0.1642     129         239  368  \n",
       "4576   0.6515  0.35     0.2836      49         129  178  \n",
       "1949   0.2576  0.41     0.1642       5          26   31  \n",
       "\n",
       "[17379 rows x 15 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda/lib/python3.8/site-packages/pandas/plotting/_matplotlib/tools.py:331: MatplotlibDeprecationWarning: \n",
      "The is_first_col function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use ax.get_subplotspec().is_first_col() instead.\n",
      "  if ax.is_first_col():\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bike.hist(figsize=(10,10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_datamodel = Sequential([\n",
    "    layers.Dense(128, activation='sigmoid', input_shape=(14,)),\n",
    "    layers.Dense(32, activation='sigmoid'),\n",
    "    layers.Dense(8, activation='sigmoid'),\n",
    "    layers.Dense(1, 'linear')\n",
    "])\n",
    "\n",
    "fp_datamodel.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(\n",
    "    ),\n",
    ")\n",
    "\n",
    "history = defaultdict(list)\n",
    "\n",
    "x = bike.drop('cnt',axis=1).to_numpy()\n",
    "y = bike['cnt'].to_numpy()\n",
    "p = np.random.permutation(y.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.2885 - val_loss: 15.4568\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25.2652 - val_loss: 15.4149\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25.2444 - val_loss: 15.3564\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25.0866 - val_loss: 15.2600\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25.0133 - val_loss: 15.2100\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.9435 - val_loss: 15.1501\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.8711 - val_loss: 15.1280\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.8091 - val_loss: 15.0073\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.7156 - val_loss: 14.9261\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.6424 - val_loss: 14.8784\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.5877 - val_loss: 14.7939\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 24.5453 - val_loss: 14.7940\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 978us/step - loss: 24.4635 - val_loss: 14.6776\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 950us/step - loss: 24.3614 - val_loss: 14.6578\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.3152 - val_loss: 14.5256\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 24.2166 - val_loss: 14.4676\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 24.1530 - val_loss: 14.4246\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.0899 - val_loss: 14.3555\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 24.0386 - val_loss: 14.3101\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.9799 - val_loss: 14.2498\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.9421 - val_loss: 14.1767\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 23.8314 - val_loss: 14.1177\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.7830 - val_loss: 14.1089\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 23.7228 - val_loss: 14.0024\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 23.6449 - val_loss: 13.9636\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 23.5814 - val_loss: 13.8810\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 23.5088 - val_loss: 13.8260\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.4411 - val_loss: 13.7863\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.3828 - val_loss: 13.7099\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 23.3082 - val_loss: 13.6434\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.2435 - val_loss: 13.5753\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 966us/step - loss: 23.1774 - val_loss: 13.5242\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 23.1143 - val_loss: 13.4587\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.0641 - val_loss: 13.3972\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 1000us/step - loss: 22.9812 - val_loss: 13.3365\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.9196 - val_loss: 13.2855\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.8560 - val_loss: 13.2253\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 984us/step - loss: 22.8113 - val_loss: 13.1792\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 999us/step - loss: 22.7387 - val_loss: 13.1132\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 997us/step - loss: 22.6699 - val_loss: 13.0719\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.6171 - val_loss: 13.0058\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.5577 - val_loss: 12.9418\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.4942 - val_loss: 12.8930\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.4320 - val_loss: 12.8621\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.3585 - val_loss: 12.7746\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.2760 - val_loss: 12.7016\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 22.2312 - val_loss: 12.7326\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 22.2373 - val_loss: 12.6367\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 22.1264 - val_loss: 12.5441\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.0315 - val_loss: 12.4742\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 960us/step - loss: 21.9732 - val_loss: 12.4338\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.9130 - val_loss: 12.3737\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.8571 - val_loss: 12.3242\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.7992 - val_loss: 12.2735\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.7469 - val_loss: 12.2114\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.6948 - val_loss: 12.2503\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 987us/step - loss: 21.6740 - val_loss: 12.1865\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.6124 - val_loss: 12.0758\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.5462 - val_loss: 12.5328\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 0s 983us/step - loss: 21.5732 - val_loss: 11.9547\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.3805 - val_loss: 11.8809\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 0s 944us/step - loss: 21.3116 - val_loss: 11.8258\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 21.2636 - val_loss: 11.7741\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 21.1900 - val_loss: 11.7163\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.1318 - val_loss: 11.6793\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 0s 999us/step - loss: 21.0672 - val_loss: 11.6038\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.0152 - val_loss: 11.5569\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 20.9608 - val_loss: 11.5827\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.9082 - val_loss: 11.4901\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.8399 - val_loss: 11.3991\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.7772 - val_loss: 11.3526\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.7169 - val_loss: 11.2921\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.6741 - val_loss: 11.2613\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.6183 - val_loss: 11.2126\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.5570 - val_loss: 11.1557\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.5059 - val_loss: 11.1183\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.4989 - val_loss: 11.0647\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.4209 - val_loss: 11.0793\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.3551 - val_loss: 10.9709\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.2828 - val_loss: 10.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.2328 - val_loss: 10.8434\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.1494 - val_loss: 10.7737\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.0954 - val_loss: 10.7392\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.0408 - val_loss: 10.6832\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.9931 - val_loss: 10.6493\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.9393 - val_loss: 10.5699\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.8980 - val_loss: 10.5362\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.8242 - val_loss: 10.4991\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.7625 - val_loss: 10.4341\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.7120 - val_loss: 10.3786\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.6569 - val_loss: 10.3559\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 0s 971us/step - loss: 19.6479 - val_loss: 10.2803\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 19.5773 - val_loss: 10.2334\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 19.5190 - val_loss: 10.1949\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 0s 999us/step - loss: 19.4358 - val_loss: 10.1895\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.4239 - val_loss: 10.2070\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.4027 - val_loss: 10.0617\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 0s 964us/step - loss: 19.3031 - val_loss: 10.0945\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 19.2514 - val_loss: 9.9402\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 19.1719 - val_loss: 9.8893\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 0s 961us/step - loss: 19.1123 - val_loss: 9.8472\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.0657 - val_loss: 9.8218\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 19.0103 - val_loss: 9.7609\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.9604 - val_loss: 9.7065\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.9028 - val_loss: 9.6622\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 0s 997us/step - loss: 18.8531 - val_loss: 9.6132\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.8100 - val_loss: 9.5548\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 0s 966us/step - loss: 18.7531 - val_loss: 9.5086\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.7011 - val_loss: 9.4700\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.6519 - val_loss: 9.4280\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.6026 - val_loss: 9.3835\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.5485 - val_loss: 9.3544\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.4933 - val_loss: 9.2787\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 0s 959us/step - loss: 18.4346 - val_loss: 9.2429\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 0s 974us/step - loss: 18.4057 - val_loss: 9.1686\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.3465 - val_loss: 9.1347\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.2991 - val_loss: 9.0913\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 0s 963us/step - loss: 18.2398 - val_loss: 9.0995\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 0s 970us/step - loss: 18.2359 - val_loss: 9.1662\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 0s 993us/step - loss: 18.1830 - val_loss: 8.9665\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.1077 - val_loss: 8.9503\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 0s 964us/step - loss: 18.0429 - val_loss: 8.8652\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 0s 970us/step - loss: 17.9923 - val_loss: 8.8208\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 0s 997us/step - loss: 17.9384 - val_loss: 8.8112\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 0s 956us/step - loss: 17.9385 - val_loss: 9.1002\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 18.0925 - val_loss: 8.9735\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.9405 - val_loss: 8.6757\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 17.7774 - val_loss: 8.6348\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.7074 - val_loss: 8.5811\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 17.6561 - val_loss: 8.5350\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 0s 989us/step - loss: 17.6108 - val_loss: 8.4902\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.5573 - val_loss: 8.4456\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.5280 - val_loss: 8.4123\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.4847 - val_loss: 8.3566\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.4303 - val_loss: 8.3259\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.3948 - val_loss: 8.3052\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.3482 - val_loss: 8.2273\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 0s 962us/step - loss: 17.3165 - val_loss: 8.2361\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.2916 - val_loss: 8.1722\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.2266 - val_loss: 8.1855\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 17.2076 - val_loss: 8.0932\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.1333 - val_loss: 8.0742\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.0886 - val_loss: 7.9908\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.0376 - val_loss: 7.9489\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.0018 - val_loss: 7.9136\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.9535 - val_loss: 7.9140\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 16.9206 - val_loss: 7.9057\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 16.8831 - val_loss: 7.8193\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 0s 974us/step - loss: 16.8220 - val_loss: 7.8165\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.8055 - val_loss: 7.7634\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 0s 986us/step - loss: 16.7659 - val_loss: 7.6939\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 0s 986us/step - loss: 16.7070 - val_loss: 7.6661\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.6583 - val_loss: 7.6333\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 0s 950us/step - loss: 16.6143 - val_loss: 7.5634\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 0s 971us/step - loss: 16.5778 - val_loss: 7.5588\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.5294 - val_loss: 7.4981\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.4892 - val_loss: 7.4744\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.4454 - val_loss: 7.4021\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.3979 - val_loss: 7.3737\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step - loss: 16.3608 - val_loss: 7.3800\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 0s 993us/step - loss: 16.3441 - val_loss: 7.3292\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.2986 - val_loss: 7.2714\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.2408 - val_loss: 7.2551\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 0s 968us/step - loss: 16.1968 - val_loss: 7.2045\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.1596 - val_loss: 7.1560\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.1456 - val_loss: 7.1503\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 16.0936 - val_loss: 7.0809\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 0s 993us/step - loss: 16.0482 - val_loss: 7.0819\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.0094 - val_loss: 7.0670\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 0s 984us/step - loss: 15.9874 - val_loss: 6.9868\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.9288 - val_loss: 6.9424\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 15.8932 - val_loss: 6.9416\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 15.8548 - val_loss: 6.8762\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 0s 993us/step - loss: 15.8123 - val_loss: 6.8457\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 0s 1000us/step - loss: 15.7698 - val_loss: 6.8160\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.7277 - val_loss: 6.8063\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.7257 - val_loss: 6.7631\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.6571 - val_loss: 6.7122\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 0s 963us/step - loss: 15.6237 - val_loss: 6.6778\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 15.5811 - val_loss: 6.6445\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.5506 - val_loss: 6.6717\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 15.5090 - val_loss: 6.5609\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.4675 - val_loss: 6.5274\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.4260 - val_loss: 6.4890\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 15.3881 - val_loss: 6.4664\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 15.3619 - val_loss: 6.4367\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 15.3134 - val_loss: 6.4079\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 0s 952us/step - loss: 15.2899 - val_loss: 6.4111\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.2445 - val_loss: 6.3254\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 0s 980us/step - loss: 15.1913 - val_loss: 6.2879\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 15.1661 - val_loss: 6.2433\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 0s 962us/step - loss: 15.1261 - val_loss: 6.2353\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 15.1535 - val_loss: 6.2231\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.0854 - val_loss: 6.1785\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.0318 - val_loss: 6.1204\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 0s 977us/step - loss: 15.0030 - val_loss: 6.1017\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 0s 970us/step - loss: 14.9593 - val_loss: 6.0536\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.9102 - val_loss: 6.0214\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 0s 959us/step - loss: 14.8723 - val_loss: 6.0048\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 14.8395 - val_loss: 5.9675\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.7975 - val_loss: 5.9101\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 0s 997us/step - loss: 14.7635 - val_loss: 5.9325\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.7418 - val_loss: 5.8605\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 0s 992us/step - loss: 14.7059 - val_loss: 5.8501\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 14.6689 - val_loss: 5.7901\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 14.6244 - val_loss: 5.7671\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.5894 - val_loss: 5.7267\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 0s 972us/step - loss: 14.5482 - val_loss: 5.7224\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.5252 - val_loss: 5.6846\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 0s 974us/step - loss: 14.4810 - val_loss: 5.6415\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.4452 - val_loss: 5.6246\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.4302 - val_loss: 5.7387\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 14.5015 - val_loss: 5.6119\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 14.4016 - val_loss: 5.5480\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.3374 - val_loss: 5.4956\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 0s 983us/step - loss: 14.2933 - val_loss: 5.4495\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.2381 - val_loss: 5.4167\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.1995 - val_loss: 5.3863\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 0s 986us/step - loss: 14.1703 - val_loss: 5.3619\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.1356 - val_loss: 5.3279\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.1039 - val_loss: 5.3100\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 0s 963us/step - loss: 14.0655 - val_loss: 5.2864\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 0s 979us/step - loss: 14.0406 - val_loss: 5.2654\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.0429 - val_loss: 5.2245\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.0598 - val_loss: 5.4172\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 0s 960us/step - loss: 14.3064 - val_loss: 5.3991\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.0488 - val_loss: 5.1922\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.9034 - val_loss: 5.0972\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.8366 - val_loss: 5.0686\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 0s 947us/step - loss: 13.8039 - val_loss: 5.0385\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.7652 - val_loss: 5.0112\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 0s 984us/step - loss: 13.7370 - val_loss: 4.9915\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.7078 - val_loss: 4.9544\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.6721 - val_loss: 4.9308\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.6397 - val_loss: 4.9235\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 13.6295 - val_loss: 4.8772\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 13.5900 - val_loss: 4.8440\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.5458 - val_loss: 4.8155\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step - loss: 13.5154 - val_loss: 4.8137\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 0s 952us/step - loss: 13.4843 - val_loss: 4.7624\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.4484 - val_loss: 4.7349\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 0s 989us/step - loss: 13.4211 - val_loss: 4.7231\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 0s 977us/step - loss: 13.3887 - val_loss: 4.6927\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 13.3606 - val_loss: 4.6585\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 13.3415 - val_loss: 4.6505\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 0s 947us/step - loss: 13.3114 - val_loss: 4.6121\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.2677 - val_loss: 4.5844\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.2365 - val_loss: 4.5472\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.2163 - val_loss: 4.5354\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.1714 - val_loss: 4.5002\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.1582 - val_loss: 4.4775\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.1116 - val_loss: 4.4560\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.0960 - val_loss: 4.4271\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.1072 - val_loss: 4.4363\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.0581 - val_loss: 4.3975\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.9952 - val_loss: 4.3553\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.9642 - val_loss: 4.3288\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.9214 - val_loss: 4.2975\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 0s 954us/step - loss: 12.8980 - val_loss: 4.2961\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 12.8712 - val_loss: 4.2375\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 0s 957us/step - loss: 12.8546 - val_loss: 4.2060\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.7902 - val_loss: 4.1833\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 0s 977us/step - loss: 12.7594 - val_loss: 4.1592\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 0s 948us/step - loss: 12.7299 - val_loss: 4.1271\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 12.6996 - val_loss: 4.1134\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 0s 999us/step - loss: 12.6733 - val_loss: 4.0827\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 0s 979us/step - loss: 12.6426 - val_loss: 4.0606\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.6120 - val_loss: 4.0468\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 0s 970us/step - loss: 12.5924 - val_loss: 4.0967\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.6080 - val_loss: 4.0118\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.5435 - val_loss: 3.9799\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 12.5024 - val_loss: 3.9454\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.4651 - val_loss: 3.9242\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 0s 991us/step - loss: 12.4474 - val_loss: 3.8933\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.4209 - val_loss: 3.8938\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.4554 - val_loss: 3.9325\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.3937 - val_loss: 3.8757\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.3848 - val_loss: 3.9473\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.4618 - val_loss: 3.9108\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 0s 984us/step - loss: 12.3501 - val_loss: 3.8666\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.2872 - val_loss: 3.7363\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.2249 - val_loss: 3.7583\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.2392 - val_loss: 3.7465\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.1919 - val_loss: 3.6989\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 0s 978us/step - loss: 12.1254 - val_loss: 3.6391\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.0916 - val_loss: 3.6284\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.0653 - val_loss: 3.5871\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 0s 955us/step - loss: 12.0265 - val_loss: 3.5742\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.0056 - val_loss: 3.5499\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 0s 979us/step - loss: 11.9752 - val_loss: 3.5187\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 0s 955us/step - loss: 11.9409 - val_loss: 3.4992\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 0s 984us/step - loss: 11.9150 - val_loss: 3.4789\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 11.8879 - val_loss: 3.4544\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 0s 964us/step - loss: 11.8595 - val_loss: 3.4320\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.8347 - val_loss: 3.4148\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.8075 - val_loss: 3.3961\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 11.7806 - val_loss: 3.3713\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.7535 - val_loss: 3.3469\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.7232 - val_loss: 3.3243\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 11.6952 - val_loss: 3.3075\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 0s 983us/step - loss: 11.6686 - val_loss: 3.2856\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 0s 970us/step - loss: 11.6417 - val_loss: 3.2750\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 0s 943us/step - loss: 11.6156 - val_loss: 3.2395\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.5997 - val_loss: 3.2388\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 0s 979us/step - loss: 11.5641 - val_loss: 3.1990\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.5385 - val_loss: 3.2714\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 0s 971us/step - loss: 11.5522 - val_loss: 3.1668\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.4786 - val_loss: 3.1473\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.4473 - val_loss: 3.1145\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 11.4175 - val_loss: 3.0855\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.3833 - val_loss: 3.0752\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.3849 - val_loss: 3.0553\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 11.3660 - val_loss: 3.1458\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 11.4388 - val_loss: 3.0303\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 0s 969us/step - loss: 11.3200 - val_loss: 3.0383\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 0s 999us/step - loss: 11.2740 - val_loss: 2.9822\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.2340 - val_loss: 2.9871\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 992us/step - loss: 11.2178 - val_loss: 2.9384\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.1809 - val_loss: 2.9175\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.1492 - val_loss: 2.8981\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 0s 982us/step - loss: 11.1245 - val_loss: 2.8773\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.0975 - val_loss: 2.8562\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.0725 - val_loss: 2.8384\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.0456 - val_loss: 2.8170\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 0s 960us/step - loss: 11.0184 - val_loss: 2.8017\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 0s 962us/step - loss: 10.9994 - val_loss: 2.7877\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 0s 964us/step - loss: 10.9719 - val_loss: 2.7642\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 0s 937us/step - loss: 10.9445 - val_loss: 2.7517\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 10.9245 - val_loss: 2.7262\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 10.8951 - val_loss: 2.7165\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 0s 939us/step - loss: 10.8725 - val_loss: 2.7555\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 0s 964us/step - loss: 10.8675 - val_loss: 2.6714\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.8284 - val_loss: 2.6761\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 10.8179 - val_loss: 2.6456\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 0s 978us/step - loss: 10.7725 - val_loss: 2.6206\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 10.7445 - val_loss: 2.6070\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 0s 975us/step - loss: 10.7184 - val_loss: 2.6019\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 0s 931us/step - loss: 10.6927 - val_loss: 2.5678\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 10.6749 - val_loss: 2.5633\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 0s 961us/step - loss: 10.6472 - val_loss: 2.5394\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 10.6217 - val_loss: 2.5204\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.5976 - val_loss: 2.5045\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.5707 - val_loss: 2.4893\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 0s 954us/step - loss: 10.5467 - val_loss: 2.4652\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.5135 - val_loss: 2.4468\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 0s 910us/step - loss: 10.4930 - val_loss: 2.4304\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.4775 - val_loss: 2.4443\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.4929 - val_loss: 2.4180\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.6677 - val_loss: 2.6174\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.5454 - val_loss: 2.4435\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 0s 960us/step - loss: 10.4144 - val_loss: 2.3581\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 10.3799 - val_loss: 2.3667\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 10.3408 - val_loss: 2.3194\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.3059 - val_loss: 2.3011\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 0s 974us/step - loss: 10.2813 - val_loss: 2.2848\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 0s 956us/step - loss: 10.2547 - val_loss: 2.2715\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.2305 - val_loss: 2.2706\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 0s 989us/step - loss: 10.2160 - val_loss: 2.2509\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.1935 - val_loss: 2.2276\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 0s 987us/step - loss: 10.1667 - val_loss: 2.2123\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.1627 - val_loss: 2.2029\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.1271 - val_loss: 2.1859\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 0s 997us/step - loss: 10.1408 - val_loss: 2.1764\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 0s 996us/step - loss: 10.0738 - val_loss: 2.1571\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 10.0487 - val_loss: 2.1682\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.0520 - val_loss: 2.1453\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 10.0039 - val_loss: 2.1001\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 0s 978us/step - loss: 9.9739 - val_loss: 2.0899\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 10.0117 - val_loss: 2.1060\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 9.9631 - val_loss: 2.0784\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 0s 978us/step - loss: 9.9164 - val_loss: 2.0436\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.8867 - val_loss: 2.0297\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 0s 954us/step - loss: 9.8719 - val_loss: 2.0109\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.8422 - val_loss: 2.0025\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.8435 - val_loss: 2.0889\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.9828 - val_loss: 2.0358\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 0s 966us/step - loss: 9.9230 - val_loss: 1.9893\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 0s 977us/step - loss: 9.8100 - val_loss: 1.9760\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.7549 - val_loss: 1.9289\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.7184 - val_loss: 1.9151\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.6929 - val_loss: 1.9067\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.6751 - val_loss: 1.8943\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.6552 - val_loss: 1.8938\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 0s 980us/step - loss: 9.6316 - val_loss: 1.8667\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.6063 - val_loss: 1.8584\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.5852 - val_loss: 1.8466\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.5636 - val_loss: 1.8249\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 0s 997us/step - loss: 9.5473 - val_loss: 1.8132\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 0s 959us/step - loss: 9.5306 - val_loss: 1.8246\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 0s 982us/step - loss: 9.5120 - val_loss: 1.7855\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 0s 968us/step - loss: 9.4876 - val_loss: 1.7743\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.4723 - val_loss: 1.8056\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 9.5759 - val_loss: 1.8878\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 0s 949us/step - loss: 9.4551 - val_loss: 1.7588\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 9.4928 - val_loss: 1.7542\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 0s 977us/step - loss: 9.4169 - val_loss: 1.7248\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 0s 972us/step - loss: 9.3730 - val_loss: 1.7089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.3458 - val_loss: 1.7113\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 9.3131 - val_loss: 1.6758\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 9.2927 - val_loss: 1.6588\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.2783 - val_loss: 1.6623\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 0s 958us/step - loss: 9.2748 - val_loss: 1.6449\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 9.2491 - val_loss: 1.6458\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.2148 - val_loss: 1.6156\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 0s 959us/step - loss: 9.1921 - val_loss: 1.6189\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.1765 - val_loss: 1.6078\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.1622 - val_loss: 1.5767\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.1402 - val_loss: 1.5730\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.1113 - val_loss: 1.5519\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.0921 - val_loss: 1.5419\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 9.0740 - val_loss: 1.5273\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 0s 991us/step - loss: 9.0494 - val_loss: 1.5172\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 9.0498 - val_loss: 1.5367\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 0s 952us/step - loss: 9.1155 - val_loss: 1.5628\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 9.0291 - val_loss: 1.4931\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 0s 991us/step - loss: 8.9892 - val_loss: 1.4738\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 8.9575 - val_loss: 1.4678\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 0s 963us/step - loss: 8.9380 - val_loss: 1.4506\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.9212 - val_loss: 1.4444\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.8948 - val_loss: 1.4416\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 0s 983us/step - loss: 8.8875 - val_loss: 1.4564\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.8697 - val_loss: 1.6166\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.1253 - val_loss: 2.0747\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.1567 - val_loss: 1.4544\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 0s 963us/step - loss: 8.8405 - val_loss: 1.3892\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 8.7995 - val_loss: 1.4090\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 0s 992us/step - loss: 8.7737 - val_loss: 1.3780\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.7441 - val_loss: 1.3444\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 0s 983us/step - loss: 8.7178 - val_loss: 1.3317\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.6977 - val_loss: 1.3222\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 8.6885 - val_loss: 1.3202\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 8.6651 - val_loss: 1.3032\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 8.6460 - val_loss: 1.2966\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 0s 993us/step - loss: 8.6250 - val_loss: 1.2896\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.6198 - val_loss: 1.3085\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 0s 945us/step - loss: 8.6552 - val_loss: 1.4274\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.6805 - val_loss: 1.3552\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.6060 - val_loss: 1.3184\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.5948 - val_loss: 1.2589\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 0s 1000us/step - loss: 8.5441 - val_loss: 1.2441\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.5351 - val_loss: 1.2453\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 0s 1000us/step - loss: 8.5141 - val_loss: 1.2306\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 8.4703 - val_loss: 1.1982\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 0s 955us/step - loss: 8.4574 - val_loss: 1.2013\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 0s 952us/step - loss: 8.4414 - val_loss: 1.1845\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 8.4099 - val_loss: 1.1686\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 8.3902 - val_loss: 1.1578\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.3749 - val_loss: 1.1552\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 0s 992us/step - loss: 8.3611 - val_loss: 1.1442\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.3469 - val_loss: 1.1279\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.3219 - val_loss: 1.1244\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.3046 - val_loss: 1.1146\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 0s 954us/step - loss: 8.2906 - val_loss: 1.1100\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 0s 1000us/step - loss: 8.2737 - val_loss: 1.1144\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 0s 959us/step - loss: 8.2591 - val_loss: 1.0880\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 0s 942us/step - loss: 8.2406 - val_loss: 1.0934\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.2324 - val_loss: 1.0755\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 8.2081 - val_loss: 1.0639\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.1852 - val_loss: 1.0581\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.1720 - val_loss: 1.0685\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 0s 941us/step - loss: 8.1586 - val_loss: 1.0534\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 0s 958us/step - loss: 8.1456 - val_loss: 1.0395\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 8.1279 - val_loss: 1.0240\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 8.1081 - val_loss: 1.0355\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.0909 - val_loss: 1.0274\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.0736 - val_loss: 1.0443\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 0s 935us/step - loss: 8.0683 - val_loss: 1.0051\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.0372 - val_loss: 0.9828\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 8.0178 - val_loss: 0.9791\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 0s 955us/step - loss: 8.0101 - val_loss: 0.9942\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 0s 950us/step - loss: 7.9902 - val_loss: 0.9662\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 7.9997 - val_loss: 1.0149\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.9946 - val_loss: 0.9561\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.9456 - val_loss: 0.9713\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 0s 954us/step - loss: 7.9294 - val_loss: 0.9308\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 0s 960us/step - loss: 7.9104 - val_loss: 0.9424\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.8951 - val_loss: 0.9157\n",
      "Epoch 478/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 976us/step - loss: 7.8872 - val_loss: 0.9345\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.8644 - val_loss: 0.8949\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.8413 - val_loss: 0.8991\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 7.8302 - val_loss: 0.8806\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 0s 982us/step - loss: 7.8191 - val_loss: 1.0044\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 7.8602 - val_loss: 0.8841\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 0s 955us/step - loss: 7.7908 - val_loss: 0.8741\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.7660 - val_loss: 0.8698\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 0s 945us/step - loss: 7.7475 - val_loss: 0.8519\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 0s 952us/step - loss: 7.7291 - val_loss: 0.8458\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 0s 974us/step - loss: 7.7154 - val_loss: 0.8341\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.7096 - val_loss: 0.8659\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 7.7007 - val_loss: 0.8273\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.6817 - val_loss: 0.8094\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 7.6589 - val_loss: 0.8003\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 0s 944us/step - loss: 7.6470 - val_loss: 0.7963\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.6220 - val_loss: 0.8022\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 0s 979us/step - loss: 7.6114 - val_loss: 0.8062\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 7.6310 - val_loss: 0.8794\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 0s 979us/step - loss: 7.6623 - val_loss: 0.9062\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 0s 974us/step - loss: 7.7061 - val_loss: 0.7777\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 0s 962us/step - loss: 7.5546 - val_loss: 0.7819\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 7.5456 - val_loss: 0.7573\n",
      "CPU times: user 16.2 s, sys: 2.04 s, total: 18.2 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x = train_dfs[0].drop('cnt',axis=1).to_numpy()\n",
    "y = train_dfs[0]['cnt'].to_numpy()\n",
    "p = np.random.permutation(y.shape[0])\n",
    "\n",
    "tmp = fp_datamodel.fit(\n",
    "    x[p],y[p],\n",
    "    epochs=500,\n",
    "    validation_split=0.2,\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuqElEQVR4nO3dd3yV5f3/8dfnrOxNSAIJKyBbVmS4BQfgwIparANHi1Vra/36bbW2X7u+v7rqqrtqS62zOEC+liHDisqUIVMTVoAEAgnZO9fvj/sOBMwkyVn5PB+P8zj3fd3XOeeTI77v+1znPtctxhiUUkoFF4evC1BKKdXxNNyVUioIabgrpVQQ0nBXSqkgpOGulFJByOXrAgC6detm+vTp4+sylFIqoKxbt+6wMSaxsW1+Ee59+vRh7dq1vi5DKaUCiojsaWqbDssopVQQ0nBXSqkgpOGulFJBSMNdKaWCkIa7UkoFIQ13pZQKQhruSikVhAI73LPXwCe/9XUVSinldwI73HM2wIonIe8bX1eilFJ+JbDDfeAU6377fN/WoZRSfiawwz0mFVJGwo6PfV2JUkr5lcAOd4BBl8K+tVB80NeVKKWU3wj8cB84FTDwzb99XYlSSvmNwA/3pKEQ2wu269CMUkrVC/xwF4GBl8LO5VBZ4utqlFLKLwR+uAMMmgq1lZC11NeVKKWUXwiOcO91JoTG6lkzSillC45wd7rgtEvgmwVQW+PrapRSyueCI9zBOiWyvACyV/q6EqWU8rngCff0SeAM0bNmlFKKVoa7iMSKyBwR2S4i20RkgojEi8hiEfnWvo+z+4qIPCMimSKySURGd+6fYAuJhH7nWVMRGOOVl1RKKX/V2iP3p4EFxphBwAhgG3A/sMQYMwBYYq8DTAEG2LdZwAsdWnFzBk6Fo3vg4BavvaRSSvmjFsNdRGKAc4FXAYwxVcaYo8A0YLbdbTZwpb08DfiHsawEYkUkpYPrbtygS0EcsPVDr7ycUkr5q9YcufcF8oC/ich6EXlFRCKAJGNMjt0nF0iyl3sC2Q0ev89uO4GIzBKRtSKyNi8v79T/goYiu0Ofc2Dz+zo0o5Tq0loT7i5gNPCCMWYUUMrxIRgAjDEGaFOaGmNeNsZkGGMyEhMT2/LQ5g27CvKzIHdTxz2nUkoFmNaE+z5gnzFmlb0+ByvsD9YPt9j3h+zt+4G0Bo9Ptdu8Y/AV4HDB5ve89pJKKeVvWgx3Y0wukC0iA+2mScBWYB4w026bCcy1l+cBN9lnzYwHChsM33S+8HjodwFs/kCHZpRSXZarlf3uBt4QEQ+wE7gFa8fwrojcBuwBrrX7fgxMBTKBMruvdw2bDh/+2JrnPe0Mr7+8Ukr5WqvC3RizAchoZNOkRvoa4K72ldVOg6aC0wNb3tdwV0p1ScHzC9WGQmOg/0Ww5QOoq/N1NUop5XUBHe7r9xbw2MLtjW8cdhUU58DeL71blFJK+YGADvfN+wt5blkWmYeKv7vxtMngCtOzZpRSXVJAh/vFQ5MBWLilkYtjh0TCwMmwda5OA6yU6nICOtyTokMZ1SuWBZtzG+8w9CooOwy7P/NuYUop5WMBHe4Ak4cm8/X+QvYVlH1344CLwBOlQzNKqS4n4MP9kuaGZtxh1mmR2z6CmiovV6aUUr4T8OHep1sEg5KjWNjc0EzFUdi5zKt1KaWULwV8uANMHpbMmj355BVXfndj+kTrvPfN73u/MKWU8pGgCXdjYNHWRo7eXR5rMrHt86GyxPvFKaWUDwRFuA9MiiI9MYL5G5uYn2zUDVBVohfxUEp1GUER7iLC5SN6sHLXEQ4VVXy3Q9o4SBgAX73u/eKUUsoHgiLcAS47vQfGwPxNjRy9i1hH79krIe8b7xenlFJeFjTh3r97JENSovlo04HGO4y4DsQJ6/XoXSkV/IIm3AEuH9GD9XuPkp3fyA+aopKs+WY2vgW11d4vTimlvCiowv2y01OAJoZmAEbfCKV58O0iL1allFLeF1ThnhYfzqhesXy0sYmhmf4XQWSyfrGqlAp6QRXuAJef3oOtOUVkHmrknHanC0ZeZx25Fzfxi1allAoCQRful56eggjMb+qL1ZE3gKmFDW96tzCllPKioAv3pOhQxvWN56ONB7Au53qSbv2h15mw/p/Q2HallAoCQRfuYJ01k5VXyracRq7QBNYXq/lZsOcL7xamlFJeEpThPmVYCi6HMHfj/sY7DJlmzfO+/p/eLUwppbykVeEuIrtF5GsR2SAia+22eBFZLCLf2vdxdruIyDMikikim0RkdGf+AY2Jj/Bw7mmJzF1/gNq6RoZePBEwfLo110xFkbfLU0qpTteWI/cLjDEjjTEZ9vr9wBJjzABgib0OMAUYYN9mAS90VLFtMX10KrlFFXyeebjxDqNuguoyvUqTUiootWdYZhow216eDVzZoP0fxrISiBWRlHa8zimZNLg7MWFu3vtqX+Mdeo6G7kN0OgKlVFBqbbgbYJGIrBORWXZbkjGm/qeguUCSvdwTyG7w2H122wlEZJaIrBWRtXl5eadQevNC3U4uH5HCwi25FFc0Mt1A/WRi+9fBwa0d/vpKKeVLrQ33s40xo7GGXO4SkXMbbjTWOYdtOq/QGPOyMSbDGJORmJjYloe22vTRqVRU1/Hx101MR3D6DHC49ehdKRV0WhXuxpj99v0h4ANgLHCwfrjFvj9kd98PpDV4eKrd5nUj02LplxjBe+uaePmIBOsC2hvf1gtoK6WCSovhLiIRIhJVvwxcDGwG5gEz7W4zgbn28jzgJvusmfFAYYPhG68SEaaPTmX17nz2HCltvNOom6A837oMn1JKBYnWHLknAStEZCOwGvg/Y8wC4GHgIhH5FrjQXgf4GNgJZAJ/Be7s8Krb4KrRPRGB975q4ug9/QKI7Q1rXvVuYUop1YlcLXUwxuwERjTSfgSY1Ei7Ae7qkOo6QEpMGGf378b7X+3jnkkDcDjkxA4OJ5zxQ1j8G8jdDMnDfFOoUkp1oKD8herJrh6Tyr6Ccr7IOtJ4h1E3gCsU1vzVu4UppVQn6RLhfsnQZOLC3by5ek/jHcLjYfg1sOldKC/wbnFKKdUJukS4h7qdTB+dyqItBzlUXNF4p7GzrF+srn/Du8UppVQn6BLhDnDduF7U1Bn+tbaJX6ymnA69JlhDM3V13i1OKaU6WJcJ9/TESCb0S+Ct1Xupa2wyMbCO3gt2Q+YnXq1NKaU6WpcJd4Drx/diX0E5//m2iekOBl9uXWN19UveLUwppTpYlwr3i4ck0y3Swxur9jbewem2TovM/AQObfNucUop1YG6VLh7XA6uHpPG0u2HyCksb7zTGbeBOxy+eNa7xSmlVAfqUuEO8IOxvaitM7yzJrvxDuHx1nnvm96BIp/MmqCUUu3W5cK9V0I45wzoxjtrsqmpbeKsmPF3gqmFVS96tzillOogXS7cAa4f15ucwgqW72jii9X4vjD4Clj7N6hs4iLbSinlx7pkuE8a3J3uUSG8saqJX6wCnPVTqCyEdbOb7qOUUn6qS4a72+ng+2eksfybPLLzyxrv1HMM9D4bVr4AtY1cyUkppfxYlwx3gOvG9sIhwj9XtnD0XrQPNr/vvcKUUqoDdNlw7xEbxuRhyby1ei+llTWNd+p/ESQOgi+eAdOmqwgqpZRPddlwB7j1rL4UVdTw3ldNzDfjcMCZd8PBzZC11LvFKaVUO3TpcB/TO46RabH87fPdTc83M/waa0qCL57xbnFKKdUOXTrcAW49uy+7Dpey/JtDjXdwhcD4H8PO5bD/K6/WppRSp6rLh/uUYcmkxITy6opdTXfKuA1CY+CzP3uvMKWUaocuH+5up4ObJvTh88wjbM8tarxTaDSMuwO2z7eus6qUUn6uy4c7wHVj0whzO3mtuaP3cbeDJ1KP3pVSAaHV4S4iThFZLyLz7fW+IrJKRDJF5B0R8djtIfZ6pr29TyfV3mFiwz1MH9OTDzcc4HBJZeOdwuNh7I9gywdw+FvvFqiUUm3UliP3nwENJzl/BHjSGNMfKABus9tvAwrs9iftfn7v5jP7UlVT1/yPmsbfBa5QPXpXSvm9VoW7iKQClwKv2OsCTATm2F1mA1fay9Psdeztk+z+fq1/90guHJzE7C92U1bVxI+aIhMh41bY9C4cyfJugUop1QatPXJ/CvgFUD9HbgJw1BhTn4L7gJ72ck8gG8DeXmj3P4GIzBKRtSKyNi+vidkZveyO89MpKKvm7dVNzPUOcPY91umRy/7Xa3UppVRbtRjuInIZcMgYs64jX9gY87IxJsMYk5GYmNiRT33KxvSOY2zfeF75bCdVNU3M9R7Z3ZrvffN7kLPJuwUqpVQrtebI/SzgChHZDbyNNRzzNBArIi67Tyqw317eD6QB2NtjgCMdWHOnuuP8dA4UVjBv44GmO515N4TGwpLfe60upZRqixbD3RjzgDEm1RjTB5gBLDXGXA8sA662u80E5trL8+x17O1LjQmcWbfOPy2RQclRvPhpVtNTEoTFwjn3QuZi2P25V+tTSqnWaM957r8E7hWRTKwx9Vft9leBBLv9XuD+9pXoXSLCHeenk3mohE+2HWy649hZEJUCS36nM0YqpfxOm8LdGLPcGHOZvbzTGDPWGNPfGHONMabSbq+w1/vb23d2RuGd6dLhKaTFh/H88iya/NDhDoPzfgnZq+CbBd4tUCmlWqC/UG2Ey+ng9nPT2ZB9lM8zm/m6YNQNEN/PGnuvq/VegUop1QIN9yZck5FKcnQoTy/5pumjd6cbJv4aDm2Fr+c03kcppXxAw70JIS4nd5yfzprdBXyZ1czR+5DvQfJw67z3mirvFaiUUs3QcG/G989IIyk6hKeXNDOXjMMBk34LR/fAV7Ob7qeUUl6k4d6MULeTH5+Xzqpd+azc2czRe/9J0Pts+PRRqCr1XoFKKdUEDfcWXDe2F4lRITzT3NG7CFz4EJQegpUveK84pZRqgoZ7C0LdTm4/tx9fZB1hze78pjumjYWBU+HzZ6CsmX5KKeUFGu6tcP243nSLDOHxhTuaPnMGYOJvoLIIPn/Ka7UppVRjNNxbIczj5O6J/Vm1K58VmYeb7pg0BE7/Pqx6CQr3ea9ApZQ6iYZ7K80Ym0bP2DAea/Ho/UHrfvFD3ilMKaUaoeHeSiEuJ/dcOIBN+wpZuCW36Y6xveDMn8LmObB3pfcKVEqpBjTc2+Cq0an07x7J44u+obapGSPBuqBHVA/49y+hrol54ZVSqhNpuLeB0yH810WnkXmohPfWNTOm7omAC38LORtg41veKk8ppY7RcG+jycOSGd0rlscW7aCksolrrQIMvwZ6ZlhTAlcWe69ApZRCw73NRITfXDaEvOJKXlzezEWyHQ6Y8giUHIT/PO69ApVSCg33UzKqVxxXjuzBy5/tZF9BWdMdUzNg5PXw5bNwaLv3ClRKdXka7qfoF5MH4RB4ZMGO5jte9HvwRMLH9+kVm5RSXqPhfop6xIYx65x+fLTxAOv2NDPdQEQ368vV3Z/Bpne9Vp9SqmvTcG+H289Lp3tUCL+fv63pi2kDjJ5pfbm66EEoL/BegUqpLkvDvR0iQlz8YvIgNmYfZd7GA013dDjgsieg7Ags/aP3ClRKdVka7u101aieDO8ZwyMLtlNe1cx1VFNGwNhZsOZV2L/OewUqpbokDfd2cjisUyNzCit4+T87m+98wYMQmQTzfqqX5FNKdaoWw11EQkVktYhsFJEtIvI7u72viKwSkUwReUdEPHZ7iL2eaW/v08l/g8+N7RvP1OHJvPhpFrmFFU13DI2Gy5+Cg5vhsz97rT6lVNfTmiP3SmCiMWYEMBKYLCLjgUeAJ40x/YEC4Da7/21Agd3+pN0v6N0/eTC1dYZHF7ZwPvvAKda0wJ89DjmbvFOcUqrLaTHcjaXEXnXbNwNMBObY7bOBK+3lafY69vZJIiIdVbC/6pUQzi1n9+H9r/azbk8LZ8RMfhjC4uHDO6G22jsFKqW6lFaNuYuIU0Q2AIeAxUAWcNQYUz+5yj6gp73cE8gGsLcXAgmNPOcsEVkrImvz8vLa9Uf4i7snDiA5OpQHP/ia6tpmZoMMj7eHZ76Gz57wWn1Kqa6jVeFujKk1xowEUoGxwKD2vrAx5mVjTIYxJiMxMbG9T+cXIkNc/PaKIWzPLebvn+9uvvOgS63Jxf7zKOR+7ZX6lFJdR5vOljHGHAWWAROAWBFx2ZtSgf328n4gDcDeHgMc6YhiA8ElQ5OZNKg7Tyz+hv1Hy5vvPOVRCIvT4RmlVIdrzdkyiSISay+HARcB27BC/mq720xgrr08z17H3r7UNHtduuAiIvxu2lAAHpq7pfnO4fFw6ROQuwlWPNX5xSmluozWHLmnAMtEZBOwBlhsjJkP/BK4V0QyscbUX7X7vwok2O33Avd3fNn+LTUunJ9dOIBPth1kUXOX5AMYcgUMvQo+fQQOtrAzUEqpVhJ/OKjOyMgwa9eu9XUZHaq6to7L/7KCovJqFt17HpEhrqY7lx6G58ZBTCr8cAk4m+mrlFI2EVlnjMlobJv+QrWTuJ0O/vd7w8kpquBPH29rvnNEN7j0z9Zl+Vbo2TNKqfbTcO9EY3rHcdtZfXlj1V4+zzzcfOehV1pnzyz/E+xe4ZX6lFLBS8O9k913yUD6dYvgF3M2NX/NVYDLnoT4fjDnNig55J0ClVJBScO9k4W6nTx2zekcKCzn4X+3MDwTEgXXzIaKo/D+j6CumVkmlVKqGRruXjCmdzy3ndWXf67cyxctDc8kD7POf9+5XCcXU0qdMg13L6kfnvnvOZsormjhB0ujb4Lh11rj77v+450ClVJBRcPdS6zhmRHkFlXw6w830+wpqCLW+HtCf2v8vfig9wpVSgUFDXcvGtM7jnsmDWDuhgO899X+5juHRFrj75XF8P4PdfxdKdUmGu5educF/RnXN57/mbuZnXklzXdOGgJTH7OGZj591DsFKqWCgoa7lzkdwlMzRuJxObj7rfVU1rRwRD7qBhhxnTU9QdYy7xSplAp4Gu4+kBITxmNXj2DLgSIeW7Cj+c4i1q9XEwdap0cWtzBXjVJKoeHuMxcNSWLmhN68smIXy3a08IMlT4Q1/l5VCu/cCNXNXKdVKaXQcPepB6YOZlByFPe9u5FDRS0EdvdBcOULsG81fPRT8IMJ35RS/kvD3YdC3U7+ct0oSqtquPfdjdTVtRDYQ6+EC34Nm97RHzgppZql4e5jA5KieOjyoazIPMxTn3zT8gPOvc+aYGzpH2DrvM4vUCkVkDTc/cCMM9K4NiOVZ5ZmsmBzTvOdReCKZ6FnBnxwOxzY4JUalVKBRcPdD4gIv582jJFpsdz77kZ25BY3/wB3KMx4E8Li4a0ZUNTCDkEp1eVouPuJULeTF28YQ0SIix/9Yy1Hy6qaf0BUEvzgbagogrevg6oy7xSqlAoIGu5+JDkmlBdvGE1OYTl3v7We2pa+YE0eDtNfsYZmdIpgpVQDGu5+ZkzveP4wbRiffXuYRxdsb/kBg6bCJf8Pts+H+T/XUySVUgDolZj90Iyxvdh8oJCX/rOTvt0imDG2V/MPmHAnlOZZ11+NSIRJv/FOoUopv9XikbuIpInIMhHZKiJbRORndnu8iCwWkW/t+zi7XUTkGRHJFJFNIjK6s/+IYPTQ5UM597REHvxwM0u2tWLK30n/Y80D/9njsPKFzi9QKeXXWjMsUwP8lzFmCDAeuEtEhgD3A0uMMQOAJfY6wBRggH2bBWjSnAK308EL149mSEo0P3lzPRuyjzb/ABG49EkYdBksuB82veuVOpVS/qnFcDfG5BhjvrKXi4FtQE9gGjDb7jYbuNJengb8w1hWArEiktLRhXcFESEuXrv5DLpFebj172vYfbi0+Qc4XTD9VehzDnx4p3UmjVKqS2rTF6oi0gcYBawCkowx9SdY5wJJ9nJPILvBw/bZbSc/1ywRWSsia/Py8tpad5eRGBXC7FvGYozhptdWk1dc2fwD3KHWL1jrqq0LfSiluqRWh7uIRALvAfcYY044JDTWNePadJqGMeZlY0yGMSYjMTGxLQ/tcvolRvLqzWdwqLiC22avobSypvkHiP2f1eipkUp1Va0KdxFxYwX7G8aY9+3mg/XDLfZ9/by1+4G0Bg9PtdtUO4zuFcez141m8/5C7nrzK6pr65ru7HBa93reu1JdVmvOlhHgVWCbMeaJBpvmATPt5ZnA3AbtN9lnzYwHChsM36h2uHBIEn+8cjjLd+Txyzmbmp5FUuxwN83sAJRSQa0157mfBdwIfC0iG+y2XwEPA++KyG3AHuBae9vHwFQgEygDbunIgru6H4zrxeGSSp5Y/A1up4M/XTUch0NO7HRsWEbDXamuqsVwN8asAKSJzZMa6W+Au9pZl2rG3RP7U11bx1+WZuJyCn+8chjWByybww53HZZRqsvSX6gGIBHh3otOo7rW8OKnWbidDh66fMixgC+thghg6fZcJnYf5NtilVI+oeEeoESEX04eSE1tHa+s2IXLITx46WBEhMMl1UQAjy/Yyn53H26c0MfX5SqlvEzDPYCJWIFeU2d4ZcUuROBXUwdTaY/G9Iz28Ju5WyiqqOHO89NPHLpRSgU1DfcAJyI8dPkQAP762S5KKmv5foy17Z4L+xORGcNjC3eQX1rFg1MHf/fLV6VUUNJwDwL1AR8Z4uLZZZnUxmQzEohwC09cO5LYcA+vrtjFvoIynvr+KMI8Tl+XrJTqZDqfe5AQEe67ZCAPTBlEbnE1AKFOcDiE314xlP+5bAiLth5kxl9XtjyFgVIq4Gm4B5nbz0vn5rPTAYgLP/7B7Naz+/LSDWPYkVvE957/nG8P6rwzSgUzDfcgNHFQMgAhjhN/wXrx0GTevX0CFdV1fO/5L1i0JdcX5SmlvEDDPRg1M7fM6amxzPvJWfRLjGDW6+t4cvE3TU9joJQKWBruwaiFuWV6xIbx7u0TmD46laeXfMus19dRXFHtxQKVUp1Nwz0YtWLK31C3k8evOZ3fXj6EZTsOceVzn5OVV+KlApVSnU3DPRgdG5ZpfuIwEeHms/ryz9vGUVBWzRV/WcHcDTo7s1LBQMM9GLVxVsgJ6QnMv/tsBqdE87O3N/CLORspq2rhgiBKKb+m4R6MTuFKTD1iw3h71nh+ckF//rVuH9Oe/ZytB/QarEoFKg33YHSKV2JyOR3cd8lAXr91HEfLq5n23AqeX55JrZ5No1TA0XAPRvVny5QXnNLDzx7QjUX3nMvFQ5J5dMEOrn3pS3YfLu3AApVSnU3DPRjF94X4frDgfshcckpPERfh4dkfjOLpGSP59mAxU5/5jL9/vkuP4pUKEBruwcgdBrcsgPh0ePP7sPn9lh/TCBFh2sieLPz5uWT0iee3H21l+gtfsD1Xx+KV8nca7sEqKglung+pGTDnVlj72ik/VUpMGLNvOYOnZ4wkO7+My55ZwaMLtlNRrZfxU8pfabgHs7BYuOF9GHAxzP85LPlDi+e+N6X+KP6Te8/jylE9eX55FpP+/Ckff52DddlcpZQ/0XAPdp5wmPEGjLoRPnsc5twMVWWn/HRxER4ev2YEb88aT1Soizvf+Irr/rqSbTk6VKOUP9Fw7wqcbrjiL3DxH2HrPPjbFCg60K6nHN/P+uHTH64cxvbcYi595jN+/eHXOle8Un6ixXAXkddE5JCIbG7QFi8ii0XkW/s+zm4XEXlGRDJFZJOIjO7M4lUbiMCZd8N1b8GRTPjrRDiwvl1P6XI6uHF8b5bfdz43ju/N26uzOe+xZTyxaIdORKaUj7XmyP3vwOST2u4HlhhjBgBL7HWAKcAA+zYLeKFjylQdZuAUuHUhOFzw6iXWF63tHDOPDffwu2nDWHzveVwwqDvPLM3kvMeW89qKXVTW6JeuSvlCi+FujPkPkH9S8zRgtr08G7iyQfs/jGUlECsiKR1Uq+ooycNg1nLoc7b1Ret7P4TK9l+ZqW+3CJ77wWjm/eQsBqdE8fv5W5n4+Ke8/uVuPbNGKS871TH3JGNMjr2cCyTZyz2B7Ab99tlt3yEis0RkrYiszcvLO8Uy1CmL6AbXz4GJv4Et78PL50Pu5hYf1hqnp8byxg/H8/ptY+keHcJv5m7h7EeW8eKnWTpco5SXtPsLVWOdB9fmz/XGmJeNMRnGmIzExMT2lqFOhcMB594HMz+CyhJ4ZRKsm93uYZp65wxI5P07zuStH41ncEoUD/97O2c9vJQnFu0gv7SqQ15DKdW4Uw33g/XDLfb9Ibt9P5DWoF+q3ab8WZ+z4ccroNcE+Oin8MHtUFHYIU8tIkxIT+D128Yx7ydnMSE9gWeWZnLWw0v53Udb2HNE56xRqjOcarjPA2bayzOBuQ3ab7LPmhkPFDYYvlH+LDIRbngPLngQvv4XPH8mZC3r0Jc4PTWWl27MYPHPz2XK8GRe/3IP5z++nFv+tpplOw7ptVyV6kDS0q8LReQt4HygG3AQeAj4EHgX6AXsAa41xuSLiADPYp1dUwbcYoxZ21IRGRkZZu3aFrspb9m31jp6P5IJo2+Ci/5g/dq1gx0squDNVXt5c/Ve8oor6Z0Qzo3je3PNmDRiwt0d/npKBRsRWWeMyWh0mz/8dFzD3Q9Vl8PyP8EXf4HIJLj0CRg0tVNeqqqmjgVbcnn9y92s2V1AiMvBlGHJXJuRxvh+CTgc0imvq1Sg03BXp27/VzD3J3BoCwy6DKY8AjGpnfZyWw4U8vbqbD7csJ/iihpS48K4ekwq00enkhYf3mmvq1Qg0nBX7VNTBV/+BT59zLqE3zk/h/F3giei016yorqWhVty+dfafazIPAzAyLRYrhjRg0tPTyEpOrTTXlupQKHhrjpGwR5Y+CvYPh8iusO5/w1jbgaXp1Nfdl9BGR9tzOGjjQfYmlOECIzvm8DlI3pwydAkEiJDOvX1lfJXGu6qY+1dBUt+D3tWQGxvuOBXMPya49du7USZh4qPBf3Ow6U4BDJ6x3Px0CQuGpJE74TO+zShlL/RcFcdzxjIWmKFfM5GSBwMk34DA6dak5R1+ssbtuYUsXDLQRZvPXhsyuGBSVFcPDSJiYO6M7xnDC6nTnyqgpeGu+o8dXWwbS4s/aN16mTqGTDpIeh7jlfLyM4vY9HWgyzaksua3fnUGYgMcTGubzwT0hOYkJ7A4ORoPfNGBRUNd9X5amtgwxvw6SNQtB96nQkT7rJmofTCcE1D+aVVfJF1mC+yjvBl1hF2HbZ+BRsb7mZ83wTO7J/AmekJpCdGIl74lKFUZ9FwV95TXQHr/gYrn4ejeyGuL4y/A0ZeDyGRPikpp7CcL7OOHAv7/UfLAUiMCmFCPyvoJ6Qn0Cs+XMNeBRQNd+V9tTXWWTUrn4fsVRASA2NmWmfXJKT7rCxjDNn55XyRdZgvd1qBX3/1qJ6xYYzrF8+Y3nGMTItlYFKUjtkrv6bhrnwrew2sfA62zgVTB2njYMQMGPo9CIvzaWnGGLLySvnSHsZZvSufI/aMlWFuJ8NTYzi9ZwxDekQzpEc06YmRuDXwlZ/QcFf+oegAbHoXNr4FedvB6bHG5EdcB/0vtK716mP1R/brswtYv/coG7KPsi2niMqaOgA8LgcDk6IYaof9kJRoBqdEExHi8nHlqivScFf+xRjr9MmNb1szUJYdhvBu1rnyp18LPUZ55XTK1qqprWPX4VK2HChia04RWw4UsuVAEUfLrAuPiECfhAgGJUfRv3sk6YmR9O8eSb/ECMI9Gvqq82i4K/9VWw2Zn1hH8zv+DbVVEJMGgy615rLpNQGc/heQxhhyCivYeqDIDv1CduQWsze/jIYzF/eMDaNfYsSxwE9PjCS9ewSJkSH65a1qNw13FRjK8mH7/1m3rKVQWwlh8ZA+EfpPsu6jkn1dZbMqa2rZc6SMrEMlZB4qISuvhKy8UrLySiirOn4d2ehQF30TI0mLCyMtPpxe8eGkxVn3KbGhOq6vWkXDXQWeyhLrF7DbP7aCvtS+2FfSMCvk+54HvcZBSJRv62yl+iP9rLwSK/jzSthzpIy9+WXsLyinpsHhvtMhpMSEHgv7tHhrB5CeGMnQHtF6xK+O0XBXga2uDg5+DZlLrKDf+yXU1YA4ocdI6zKBvc+yfh0bHu/ratusts6QU1hOdn452fllZBeUkZ1vBX92QfmxUzUBHpk+nDP6xNMtKoSoEJcGfRen4a6CS1UpZK+G3Stgz+fWlaPqrC836TYQ0sZCz9GQMtI60u/kWSs7W3lVLbsOlzL9hS8orz4+tONxOUiMDCEh0kN8hIeEiOPL8REe4sI9xIW7iYvw0C3S2hno9AvBRcNdBbeqMjjwFexdaYV+9iqoOGptc3qg+2BIGg7Jw6yw7z7EOsIPsKPe/UfL2ZVXSl5JBYeLqzhcUklecSVHSqs4UlpJfkkVR0qrjp22eTKHQGy4h9gwN7Hhbms53E1smHUfF+4mxt4hRIe6iQp1EWXfh7q9O4WEah0Nd9W1GANH98CB9bB/HeRuhoOboTTveJ/QWOuXsgn9IT7dXk63lkOjfVZ6s3K/hvKjENENIhKtH4CdNG+PMYbSqloKSqsoKKuioKyaIyWV5JdWcbSsmqPlVlthWTUFZVZbYXk1JZU1zb60x+UgukHYR4W6iPC4iAhxERHiJMLjItxjLdffR3hchNv3x9tdRHic+svfDqLhrhRA8UFr7D5vBxzJsmaxzN8Jhdkn9ovobgV9XF+I6WldVjA61VqO7gEh0d4/6q+pgj+lWmcQHSNWwIcn2Ld4+5ZgnWUUHg+eSOtXwd1Os/qGxVlX0Dqp/qqaOgrLqzlq7xCKK6oprqih6OT7cuu+uKKasqpaSiprKKuqpbSypslPDI3xuBxEeJyICMnRoYR7nIS6rVuYx0mY20GY++Q2J6Fuh7V+QlsjfVzOLjEE1Vy4+98JxEp1lqgk69b/whPbq8shfxfk24F/JMu67VwOJblWODbkjoDoFIhKsS4eHtndPprubh1RRyZa9xHdwd1BlwOsOGoF+9hZ1vQNZUesTyJl+dZyeb41UduB9dZ6bVXTz+Vw20EfC6ExEBqLJzSGRPtGaLS1AwuJhignxIdZO7XQWOvspJCoRn9NXFNbR1l1LWWV9aFfQ2llrXVv7wBK63cGVTWUVdZSXm19yqiosfodKa2istpqL6+upbyqtk07jYY8TgchbgchruM7BY/TgcflIMR14r3HafXz1K9/Z1t9m5MQlwOX04HbKXicx5fdTod9O2nZ5cDtsJadDvHal+CdEu4iMhl4GnACrxhjHu6M11GqQ7jDIGmIdTtZbQ0U51jTGBfus6ZQKM6x23KsYZ/Sw1BV3Phze6KsI+j6MK0PzdCG91ENlmNObHOHWUfZ5Uet50sdC8Ovbv7vMcb60rk8HyoKrdCvq7Geo7zAvtnbKgqtncSRzOPrprb55wdwhlizfHoirU8Cnghc7nCiPRFEu8OPteEOB0+4tUP0REB4OLhC7fZIwFifNNxhVrsrFFwhJww31dUZKmvqTgj8Cnu5wl4/cbmOyppaKqrrqKi2dg6V1bVU1NRSVVNnrdfUUVxRw5GaOqpqrf5VNXXHb7V1VNd2/KiGCMeC3mXvAB6YMojpYzr+ovMdHu4i4gSeAy4C9gFrRGSeMWZrR7+WUp3O6YLYNOvWnOpyKyRL8qz70jzr3PySPCtIy+wwLc6FiiKoLG56h9CQw2WFvMu+TmxYbMuPEbGCt36K5eThLT+mnjFQXWbVV1FkLdfVQvEBq/7KkuO1VxZbO5H6W3WZ9amhfrmqDKpLv/vJpzUcbjvwQ3C4QglzhRDmstatnUODHYEr1HqfnG7rcQ6ntRzihjCX9d/Q4bK2Oe3tDneDx7hOWg4Bp5s6nFTjpAon1XUOqnFSWStU4cSUF1Ia3pMqCaW6DmtnUFNHTZ2hutbaQXxnuabOWq811NQeX+4ZF9b296cVOuPIfSyQaYzZCSAibwPTAA13FbzcYRDby7q1Vl2tFZCVRcfDtLLIvi/8bhtAaqPDqx1H5PhR9wm/Bh5zas9nDNRUHA/6qjJrvbrM2gmYOmvHV1MBNZX2fcVJ65XWzrPhennB8fXqCuuTSV219Unr2HI1cOpH3w4gxL61SJzWTkOcIA572XG8reE2kePbxQGn3Q9MP+U6m9IZ4d4TaPgN1T5g3MmdRGQWMAugV682/A+hVLBwOK0j8dYcjQcqEWvH5w4DErz/+nV1VtDX1VhhX1fTYLna2sEeW66xdw6NLdt963caBbutobPaKqvd1B6/N+a7bXW11o7MmOPr2P06adprn32haox5GXgZrLNlfFWHUiqIORzWMEvrjr+DSmecbLofaDhAmWq3KaWU8pLOCPc1wAAR6SsiHmAGMK8TXkcppVQTOnxYxhhTIyI/ARZinQr5mjFmS0e/jlJKqaZ1ypi7MeZj4OPOeG6llFIt0wkelFIqCGm4K6VUENJwV0qpIKThrpRSQcgvpvwVkTxgzyk+vBtwuAPL8Sat3Te0dt8I1Nr9ue7expjExjb4Rbi3h4isbWo+Y3+ntfuG1u4bgVp7oNatwzJKKRWENNyVUioIBUO4v+zrAtpBa/cNrd03ArX2gKw74MfclVJKfVcwHLkrpZQ6iYa7UkoFoYAOdxGZLCI7RCRTRO73dT0NiUiaiCwTka0iskVEfma3x4vIYhH51r6Ps9tFRJ6x/5ZNIjLat3+BdT1cEVkvIvPt9b4issqu8R17SmdEJMRez7S39/Fx3bEiMkdEtovINhGZECjvu4j83P73sllE3hKRUH9930XkNRE5JCKbG7S1+X0WkZl2/29FZKYPa3/M/jezSUQ+EJHYBtsesGvfISKXNGj32wzCGBOQN6zphLOAfoAH2AgM8XVdDepLAUbby1HAN8AQ4FHgfrv9fuARe3kq8G9AgPHAKj/4G+4F3gTm2+vvAjPs5ReBO+zlO4EX7eUZwDs+rns28EN72QPEBsL7jnWJyl1AWIP3+2Z/fd+Bc4HRwOYGbW16n4F4YKd9H2cvx/mo9osBl738SIPah9j5EgL0tXPH6fcZ5OsC2vEfZwKwsMH6A8ADvq6rmXrnAhcBO4AUuy0F2GEvvwRc16D/sX4+qjcVWAJMBObb/1MebvCP/9j7jzV3/wR72WX3Ex/VHWMHpJzU7vfvO8evPxxvv4/zgUv8+X0H+pwUkG16n4HrgJcatJ/Qz5u1n7Tte8Ab9vIJ2VL/vvt7BgXysExjF+Lu6aNammV/XB4FrAKSjDE59qZcIMle9re/5yngF0CdvZ4AHDXG1NjrDes7Vru9vRCfXA0ZsI6s8oC/2UNKr4hIBAHwvhtj9gOPA3uBHKz3cR2B8b7Xa+v77Dfv/0luxfqkAYFXOxDgY+6BQEQigfeAe4wxRQ23GWt373fnoorIZcAhY8w6X9dyClxYH7dfMMaMAkqxhgeO8eP3PQ6YhrWD6gFEAJN9WlQ7+Ov73BIReRCoAd7wdS3tEcjh7vcX4hYRN1awv2GMed9uPigiKfb2FOCQ3e5Pf89ZwBUisht4G2to5mkgVkTqr97VsL5jtdvbY4Aj3iy4gX3APmPMKnt9DlbYB8L7fiGwyxiTZ4ypBt7H+m8RCO97vba+z/70/iMiNwOXAdfbOycIkNpPFsjh7tcX4hYRAV4FthljnmiwaR5Qf0bATKyx+Pr2m+yzCsYDhQ0+3nqVMeYBY0yqMaYP1vu61BhzPbAMuNrudnLt9X/T1XZ/nxyxGWNygWwRGWg3TQK2EgDvO9ZwzHgRCbf//dTX7vfvewNtfZ8XAheLSJz9yeViu83rRGQy1lDkFcaYsgab5gEz7LOT+gIDgNX4eQb5fNC/PTesb+C/wfrG+kFf13NSbWdjfSTdBGywb1OxxkSXAN8CnwDxdn8BnrP/lq+BDF//DXZd53P8bJl+WP+oM4F/ASF2e6i9nmlv7+fjmkcCa+33/kOsszAC4n0HfgdsBzYDr2OdoeGX7zvwFtZ3A9VYn5huO5X3GWt8O9O+3eLD2jOxxtDr/399sUH/B+3adwBTGrT7bQbp9ANKKRWEAnlYRimlVBM03JVSKghpuCulVBDScFdKqSCk4a6UUkFIw10ppYKQhrtSSgWh/w8pWcgV7Pp0hAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'][200:])\n",
    "plt.plot(history['val_loss'][200:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 0s 531us/step - loss: 18170.5566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18170.556640625"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_datamodel.evaluate(\n",
    "    train_dfs[1].drop('cnt',axis=1).to_numpy(),\n",
    "    train_dfs[1].drop('cnt',axis=1).to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [bike[(bike['hr']>=sr)&(bike['hr']<=so)] for sr,so in zip(range(0,25,6)[:-1],range(-1,24,6)[1:])]\n",
    "\n",
    "train_dfs = [q.sample(frac=0.8) for q in res]\n",
    "test_dfs = [q.drop(t.index) for q,t in zip(res,train_dfs)]\n",
    "\n",
    "# y_train = [x.pop('cnt') for x in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from copy import deepcopy\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cw_acc(y_true,y_pred):\n",
    "    y_pred = np.argmax(y_pred,axis=1)\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    return matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "def gen_mask(grads,m=2):\n",
    "    mask = []\n",
    "    for g in grads:\n",
    "        size = g.shape[-1]\n",
    "        assert m%1==0\n",
    "\n",
    "        split = tf.concat([tf.ones(size//m)*i for i in range(m)],0)\n",
    "        split = tf.random.shuffle(split)\n",
    "        mask.append(tf.reshape(split,(1,-1)))\n",
    "\n",
    "    return mask\n",
    "\n",
    "class DistMLP(keras.Model):\n",
    "    def __init__(self,mode='none',p=1.0):\n",
    "        super(DistMLP, self).__init__()\n",
    "        self.mod1 = Sequential([\n",
    "            layers.Dense(128, activation='sigmoid', input_shape=(14,)),\n",
    "            layers.Dense(32, activation='sigmoid'),\n",
    "            layers.Dense(8, activation='sigmoid'),\n",
    "            layers.Dense(1, 'linear')\n",
    "        ])\n",
    "        \n",
    "        self.mod2 = tf.keras.models.clone_model(self.mod1)\n",
    "        self.mod3 = tf.keras.models.clone_model(self.mod1)\n",
    "        self.mod4 = tf.keras.models.clone_model(self.mod1)\n",
    "        \n",
    "        self.mode=mode\n",
    "        \n",
    "        self.cars = [Car([i%2,],p=p) for i in range(1,5)]\n",
    "        self.gradients = []\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.mod1(data)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x1,y1,x2,y2,x3,y3,x4,y4, = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred1 = self.mod1(x1,training=True)\n",
    "            y_pred2 = self.mod2(x2,training=True)\n",
    "            y_pred3 = self.mod3(x3,training=True)\n",
    "            y_pred4 = self.mod4(x4,training=True)\n",
    "            loss1 = self.compiled_loss(y1,y_pred1)\n",
    "            loss2 = self.compiled_loss(y2,y_pred2)\n",
    "            loss3 = self.compiled_loss(y3,y_pred3)\n",
    "            loss4 = self.compiled_loss(y4,y_pred4)\n",
    "\n",
    "        grads = tape.gradient([loss1,loss2,loss3,loss4], self.trainable_weights)\n",
    "        \n",
    "        if self.mode=='none':\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        elif self.mode=='simple_add':\n",
    "            temp = [tf.math.add_n([grads[n+i*(len(grads)//4)] for i in range(4)]) for n in range(len(grads)//4)]\n",
    "            self.optimizer.apply_gradients(zip([*temp,*temp,*temp,*temp], self.trainable_weights))\n",
    "        elif self.mode=='djgrad':\n",
    "            grad_mask = [tf.reshape(m,(-1,)) if len(g.shape)==1 else m for m,g in zip(gen_mask(grads),grads)]\n",
    "            masked_grads = [tf.math.multiply(g,m) for m,g in zip(grad_mask,grads)]\n",
    "            new_grads = []\n",
    "            \n",
    "            for n,c in enumerate(self.cars):\n",
    "                i1,i2 = (len(grads)//4)*n,(len(grads)//4)*(n+1)\n",
    "                new_grads+=c.apply_grads(grads[i1:i2])\n",
    "                c.load(masked_grads[i1:i2])\n",
    "                c._mark_seen(masked_grads[i1:i2],True)\n",
    "                c.forward(self.cars)\n",
    "                 \n",
    "            self.optimizer.apply_gradients(zip(\n",
    "                [tf.math.add(g,n) for g,n in zip(grads,new_grads)],\n",
    "                self.trainable_weights))\n",
    "        \n",
    "        # Need a metric that gives accuracy for each model individually\n",
    "        for m in self.compiled_metrics._user_metrics:\n",
    "            m.update_state(tf.concat([y1,y2,y3,y4],0), tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0),source_array=tf.concat([x1[:,3],x2[:,3],x3[:,3],x4[:,3]],0))\n",
    "\n",
    "        res = {k.name:k.result() for k in self.compiled_loss.metrics}\n",
    "    \n",
    "        res.update({m.name: m.result() for m in self.compiled_metrics._user_metrics})\n",
    "            \n",
    "        return res\n",
    "    \n",
    "    # Need to add loss here as well\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        y_pred1 = self.mod1(x,training=False)\n",
    "        y_pred2 = self.mod2(x,training=False)\n",
    "        y_pred3 = self.mod3(x,training=False)\n",
    "        y_pred4 = self.mod4(x,training=False)\n",
    "                \n",
    "        self.compiled_loss(tf.concat([y,y,y,y,],0),tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0))\n",
    "        for m in self.compiled_metrics._user_metrics:\n",
    "            m.update_state(tf.concat([y,y,y,y],0),tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0),source_array=tf.concat([x[:,3],x[:,3],x[:,3],x[:,3]],0))\n",
    "\n",
    "        return {m.name: m.result() for m in self.compiled_metrics._user_metrics}\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        for m in self.compiled_metrics._user_metrics:\n",
    "            m.reset_state()\n",
    "        for m in self.metrics:\n",
    "            m.reset_state()\n",
    "        for m in self.compiled_loss.metrics:\n",
    "            m.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CWMet(tf.keras.metrics.Metric):\n",
    "    def __init__(self, car_idx, minmax, name='classwise_accuracy', num_cars=4, **kwargs):\n",
    "        super(CWMet, self).__init__(name=name, **kwargs)\n",
    "        self.num_cars = num_cars\n",
    "        self.car_idx = car_idx\n",
    "        self.minmax = minmax\n",
    "        self.loss = self.add_weight(name='loss',initializer='zeros')\n",
    "        self.num_samples = self.add_weight(name='num_samples',initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, source_array=None, sample_weight=None):\n",
    "        y_true = tf.cast(tf.reshape(y_true, (4,-1))[self.car_idx], tf.float32)\n",
    "        y_pred = tf.cast(tf.reshape(y_pred, (4,-1))[self.car_idx], tf.float32)\n",
    "        source_array = tf.reshape(source_array, (4,-1))[self.car_idx]\n",
    "\n",
    "        bl_mask = tf.math.logical_and(\n",
    "            tf.math.greater_equal(source_array, self.minmax[0]),\n",
    "            tf.math.greater_equal(self.minmax[1],source_array),\n",
    "        )\n",
    "        \n",
    "#         print(source_array.shape, tf.math.reduce_min(source_array),tf.math.reduce_max(source_array))\n",
    "        \n",
    "#         print(source_array)\n",
    "#         print(y_true.shape,tf.boolean_mask(tf.cast(y_true, tf.float32), bl_mask).shape)\n",
    "        \n",
    "        y_true = tf.boolean_mask(tf.cast(y_true, tf.float32), bl_mask)\n",
    "        y_pred = tf.boolean_mask(tf.cast(y_pred, tf.float32), bl_mask)\n",
    "        \n",
    "#         print(np.max(source_array),np.min(source_array),self.minmax,source_array.shape,y_true)\n",
    "#         print(tf.math.greater_equal(self.minmax[0],source_array))\n",
    "        \n",
    "        loss = tf.math.reduce_sum(tf.math.square(y_true-y_pred))\n",
    "\n",
    "        count_class = tf.math.reduce_sum(tf.cast(bl_mask,dtype=tf.float32))#tf.cast(y_true.get_shape().as_list()[0],dtype=tf.float32)\n",
    "        \n",
    "        self.loss.assign_add(loss)\n",
    "        self.num_samples.assign_add(count_class)\n",
    "\n",
    "    def result(self):\n",
    "#         print(self.num_samples)\n",
    "        return tf.math.divide_no_nan(self.loss,self.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len = min([x.shape[0] for x in train_dfs])\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    train_dfs[0].drop('cnt',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[0]['cnt'].to_numpy()[:min_len],\n",
    "    train_dfs[1].drop('cnt',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[1]['cnt'].to_numpy()[:min_len],\n",
    "    train_dfs[2].drop('cnt',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[2]['cnt'].to_numpy()[:min_len],\n",
    "    train_dfs[3].drop('cnt',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[3]['cnt'].to_numpy()[:min_len],\n",
    ")).shuffle(100).batch(128,True)\n",
    "\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    np.concatenate((\n",
    "        test_dfs[0].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[1].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[2].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[3].drop('cnt',axis=1).to_numpy(),\n",
    "    )),\n",
    "    np.concatenate((\n",
    "        test_dfs[0]['cnt'].to_numpy(),\n",
    "        test_dfs[1]['cnt'].to_numpy(),\n",
    "        test_dfs[2]['cnt'].to_numpy(),\n",
    "        test_dfs[3]['cnt'].to_numpy(),\n",
    "    ))\n",
    ")).shuffle(100).batch(128,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('none')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2}]') for ca,(q1,q2) in product(range(4),zip(range(0,25,6)[:-1],range(-1,24,6)[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 69440.9375 - ca1-[0,5]: 1380.8282 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 73177.2948 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 125378.7755 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 83991.7766 - val_ca1-[0,5]: 1548.2408 - val_ca1-[6,11]: 65430.5742 - val_ca1-[12,17]: 111161.9531 - val_ca1-[18,23]: 79718.3359 - val_ca2-[0,5]: 1524.4581 - val_ca2-[6,11]: 65232.0078 - val_ca2-[12,17]: 110886.1250 - val_ca2-[18,23]: 79497.6328 - val_ca3-[0,5]: 1521.6747 - val_ca3-[6,11]: 65218.0586 - val_ca3-[12,17]: 110865.6328 - val_ca3-[18,23]: 79485.1016 - val_ca4-[0,5]: 1538.1637 - val_ca4-[6,11]: 65346.4727 - val_ca4-[12,17]: 111048.0156 - val_ca4-[18,23]: 79626.4375\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 69117.5625 - ca1-[0,5]: 1374.4160 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 72245.6892 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 124879.8452 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 83921.6357 - val_ca1-[0,5]: 1532.0088 - val_ca1-[6,11]: 65293.7305 - val_ca1-[12,17]: 110973.1953 - val_ca1-[18,23]: 78511.8281 - val_ca2-[0,5]: 1499.8105 - val_ca2-[6,11]: 65024.2266 - val_ca2-[12,17]: 110597.4297 - val_ca2-[18,23]: 78215.5859 - val_ca3-[0,5]: 1497.9000 - val_ca3-[6,11]: 65009.0430 - val_ca3-[12,17]: 110574.5391 - val_ca3-[18,23]: 78198.9766 - val_ca4-[0,5]: 1510.9865 - val_ca4-[6,11]: 65121.2734 - val_ca4-[12,17]: 110731.5234 - val_ca4-[18,23]: 78321.4688\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 68948.3359 - ca1-[0,5]: 1332.8381 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 72621.9951 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 124694.8909 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 83054.4126 - val_ca1-[0,5]: 1522.5347 - val_ca1-[6,11]: 65214.3867 - val_ca1-[12,17]: 110863.3047 - val_ca1-[18,23]: 79577.4922 - val_ca2-[0,5]: 1483.3032 - val_ca2-[6,11]: 64883.2539 - val_ca2-[12,17]: 110399.4844 - val_ca2-[18,23]: 79211.5391 - val_ca3-[0,5]: 1481.5498 - val_ca3-[6,11]: 64868.1250 - val_ca3-[12,17]: 110378.5234 - val_ca3-[18,23]: 79194.6484 - val_ca4-[0,5]: 1493.9053 - val_ca4-[6,11]: 64974.6875 - val_ca4-[12,17]: 110527.6719 - val_ca4-[18,23]: 79312.2500\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 68303.1797 - ca1-[0,5]: 1334.2541 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 72225.9997 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 124678.0182 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 82666.2908 - val_ca1-[0,5]: 1514.9611 - val_ca1-[6,11]: 65150.5273 - val_ca1-[12,17]: 110774.6250 - val_ca1-[18,23]: 79681.1172 - val_ca2-[0,5]: 1469.2928 - val_ca2-[6,11]: 64762.3320 - val_ca2-[12,17]: 110229.9531 - val_ca2-[18,23]: 79251.8125 - val_ca3-[0,5]: 1468.0635 - val_ca3-[6,11]: 64751.7852 - val_ca3-[12,17]: 110214.8906 - val_ca3-[18,23]: 79240.1328 - val_ca4-[0,5]: 1479.4304 - val_ca4-[6,11]: 64850.6055 - val_ca4-[12,17]: 110353.5234 - val_ca4-[18,23]: 79349.0547\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 68338.9688 - ca1-[0,5]: 1340.1563 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 72402.8822 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 124167.8212 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 83096.7613 - val_ca1-[0,5]: 1508.3542 - val_ca1-[6,11]: 65095.1055 - val_ca1-[12,17]: 110697.0156 - val_ca1-[18,23]: 78733.3281 - val_ca2-[0,5]: 1456.8180 - val_ca2-[6,11]: 64653.9102 - val_ca2-[12,17]: 110077.6328 - val_ca2-[18,23]: 78244.8594 - val_ca3-[0,5]: 1456.9364 - val_ca3-[6,11]: 64655.1211 - val_ca3-[12,17]: 110079.0391 - val_ca3-[18,23]: 78246.0938 - val_ca4-[0,5]: 1466.2620 - val_ca4-[6,11]: 64736.1016 - val_ca4-[12,17]: 110193.1875 - val_ca4-[18,23]: 78335.8203\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 68533.8438 - ca1-[0,5]: 1313.4092 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 72878.9702 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 124344.0773 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 82067.7873 - val_ca1-[0,5]: 1502.2969 - val_ca1-[6,11]: 65044.0312 - val_ca1-[12,17]: 110625.5234 - val_ca1-[18,23]: 80046.6406 - val_ca2-[0,5]: 1445.4480 - val_ca2-[6,11]: 64554.0898 - val_ca2-[12,17]: 109937.3359 - val_ca2-[18,23]: 79500.6719 - val_ca3-[0,5]: 1447.0784 - val_ca3-[6,11]: 64568.4570 - val_ca3-[12,17]: 109957.4375 - val_ca3-[18,23]: 79516.6641 - val_ca4-[0,5]: 1454.5555 - val_ca4-[6,11]: 64634.1016 - val_ca4-[12,17]: 110049.8594 - val_ca4-[18,23]: 79589.8359\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 68474.6094 - ca1-[0,5]: 1308.0602 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71659.9858 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 124110.7193 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 82328.6791 - val_ca1-[0,5]: 1496.5782 - val_ca1-[6,11]: 64995.7383 - val_ca1-[12,17]: 110557.7891 - val_ca1-[18,23]: 79656.8438 - val_ca2-[0,5]: 1434.8763 - val_ca2-[6,11]: 64460.4375 - val_ca2-[12,17]: 109805.6250 - val_ca2-[18,23]: 79061.8672 - val_ca3-[0,5]: 1437.9497 - val_ca3-[6,11]: 64487.7305 - val_ca3-[12,17]: 109843.9297 - val_ca3-[18,23]: 79092.1797 - val_ca4-[0,5]: 1443.7946 - val_ca4-[6,11]: 64539.5000 - val_ca4-[12,17]: 109916.8281 - val_ca4-[18,23]: 79149.7734\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 68515.2109 - ca1-[0,5]: 1311.3201 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 72264.7723 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 123031.1155 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 82077.6499 - val_ca1-[0,5]: 1491.0732 - val_ca1-[6,11]: 64949.0430 - val_ca1-[12,17]: 110492.2734 - val_ca1-[18,23]: 78877.9609 - val_ca2-[0,5]: 1424.8612 - val_ca2-[6,11]: 64370.8984 - val_ca2-[12,17]: 109679.6094 - val_ca2-[18,23]: 78239.4297 - val_ca3-[0,5]: 1429.3612 - val_ca3-[6,11]: 64411.1836 - val_ca3-[12,17]: 109736.2812 - val_ca3-[18,23]: 78283.9453 - val_ca4-[0,5]: 1433.7006 - val_ca4-[6,11]: 64449.9648 - val_ca4-[12,17]: 109790.8672 - val_ca4-[18,23]: 78326.7656\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 68250.4531 - ca1-[0,5]: 1308.1841 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71619.6606 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 123900.7144 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 82001.3478 - val_ca1-[0,5]: 1485.7495 - val_ca1-[6,11]: 64903.7031 - val_ca1-[12,17]: 110428.6172 - val_ca1-[18,23]: 79863.4375 - val_ca2-[0,5]: 1415.2775 - val_ca2-[6,11]: 64284.4492 - val_ca2-[12,17]: 109557.9453 - val_ca2-[18,23]: 79173.4922 - val_ca3-[0,5]: 1421.2145 - val_ca3-[6,11]: 64338.0703 - val_ca3-[12,17]: 109633.3750 - val_ca3-[18,23]: 79233.2422 - val_ca4-[0,5]: 1424.0709 - val_ca4-[6,11]: 64363.7812 - val_ca4-[12,17]: 109669.6250 - val_ca4-[18,23]: 79261.9219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 68144.1797 - ca1-[0,5]: 1312.9534 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71673.3443 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 123572.3293 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 80311.6398 - val_ca1-[0,5]: 1480.5453 - val_ca1-[6,11]: 64859.2031 - val_ca1-[12,17]: 110366.1406 - val_ca1-[18,23]: 80133.4766 - val_ca2-[0,5]: 1406.0369 - val_ca2-[6,11]: 64200.3750 - val_ca2-[12,17]: 109439.5703 - val_ca2-[18,23]: 79399.0625 - val_ca3-[0,5]: 1413.3918 - val_ca3-[6,11]: 64267.3398 - val_ca3-[12,17]: 109533.8125 - val_ca3-[18,23]: 79473.7266 - val_ca4-[0,5]: 1414.7838 - val_ca4-[6,11]: 64279.9766 - val_ca4-[12,17]: 109551.6562 - val_ca4-[18,23]: 79487.8281\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 68120.6875 - ca1-[0,5]: 1300.6431 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71908.2578 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 123527.1612 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81667.3223 - val_ca1-[0,5]: 1475.4392 - val_ca1-[6,11]: 64815.3633 - val_ca1-[12,17]: 110304.5469 - val_ca1-[18,23]: 79356.4688 - val_ca2-[0,5]: 1397.0663 - val_ca2-[6,11]: 64118.0547 - val_ca2-[12,17]: 109323.6172 - val_ca2-[18,23]: 78581.1328 - val_ca3-[0,5]: 1405.7979 - val_ca3-[6,11]: 64198.1758 - val_ca3-[12,17]: 109436.4531 - val_ca3-[18,23]: 78670.2578 - val_ca4-[0,5]: 1405.7793 - val_ca4-[6,11]: 64198.0195 - val_ca4-[12,17]: 109436.2422 - val_ca4-[18,23]: 78670.0703\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 68156.7344 - ca1-[0,5]: 1300.5205 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71734.4809 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 122724.2457 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 82162.1447 - val_ca1-[0,5]: 1470.4333 - val_ca1-[6,11]: 64772.2109 - val_ca1-[12,17]: 110243.9297 - val_ca1-[18,23]: 79263.6562 - val_ca2-[0,5]: 1388.3337 - val_ca2-[6,11]: 64037.2539 - val_ca2-[12,17]: 109209.7812 - val_ca2-[18,23]: 78445.5703 - val_ca3-[0,5]: 1398.3834 - val_ca3-[6,11]: 64130.1797 - val_ca3-[12,17]: 109340.6875 - val_ca3-[18,23]: 78549.0547 - val_ca4-[0,5]: 1397.0156 - val_ca4-[6,11]: 64117.5859 - val_ca4-[12,17]: 109322.9609 - val_ca4-[18,23]: 78535.0312\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 67834.5703 - ca1-[0,5]: 1286.7015 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71267.4181 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 123861.6918 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81442.2341 - val_ca1-[0,5]: 1465.4944 - val_ca1-[6,11]: 64729.4570 - val_ca1-[12,17]: 110183.8750 - val_ca1-[18,23]: 79095.9531 - val_ca2-[0,5]: 1379.7943 - val_ca2-[6,11]: 63957.5508 - val_ca2-[12,17]: 109097.4453 - val_ca2-[18,23]: 78239.0000 - val_ca3-[0,5]: 1391.1063 - val_ca3-[6,11]: 64062.9727 - val_ca3-[12,17]: 109246.0000 - val_ca3-[18,23]: 78356.0781 - val_ca4-[0,5]: 1388.4282 - val_ca4-[6,11]: 64038.1211 - val_ca4-[12,17]: 109211.0000 - val_ca4-[18,23]: 78328.4766\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 68114.9922 - ca1-[0,5]: 1279.3655 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70627.2436 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 123106.2057 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81805.1956 - val_ca1-[0,5]: 1460.6097 - val_ca1-[6,11]: 64687.0078 - val_ca1-[12,17]: 110124.2188 - val_ca1-[18,23]: 78626.4141 - val_ca2-[0,5]: 1371.4432 - val_ca2-[6,11]: 63878.9570 - val_ca2-[12,17]: 108986.6484 - val_ca2-[18,23]: 77732.6875 - val_ca3-[0,5]: 1383.9695 - val_ca3-[6,11]: 63996.6016 - val_ca3-[12,17]: 109152.4766 - val_ca3-[18,23]: 77862.8516 - val_ca4-[0,5]: 1380.0205 - val_ca4-[6,11]: 63959.6680 - val_ca4-[12,17]: 109100.4375 - val_ca4-[18,23]: 77821.9922\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 67860.1562 - ca1-[0,5]: 1284.0626 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71515.0613 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 122294.4207 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81542.0243 - val_ca1-[0,5]: 1455.7920 - val_ca1-[6,11]: 64644.9727 - val_ca1-[12,17]: 110065.1172 - val_ca1-[18,23]: 78893.7578 - val_ca2-[0,5]: 1363.2384 - val_ca2-[6,11]: 63801.0820 - val_ca2-[12,17]: 108876.8438 - val_ca2-[18,23]: 77958.3672 - val_ca3-[0,5]: 1376.9258 - val_ca3-[6,11]: 63930.6250 - val_ca3-[12,17]: 109059.4922 - val_ca3-[18,23]: 78102.0156 - val_ca4-[0,5]: 1371.7588 - val_ca4-[6,11]: 63881.9375 - val_ca4-[12,17]: 108990.8750 - val_ca4-[18,23]: 78048.0312\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 67768.1562 - ca1-[0,5]: 1272.6509 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70187.6425 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 123474.3443 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81174.4774 - val_ca1-[0,5]: 1451.0212 - val_ca1-[6,11]: 64603.1680 - val_ca1-[12,17]: 110006.3516 - val_ca1-[18,23]: 78748.5312 - val_ca2-[0,5]: 1355.1700 - val_ca2-[6,11]: 63723.8594 - val_ca2-[12,17]: 108767.9375 - val_ca2-[18,23]: 77772.8516 - val_ca3-[0,5]: 1369.9861 - val_ca3-[6,11]: 63865.1680 - val_ca3-[12,17]: 108967.2266 - val_ca3-[18,23]: 77929.7109 - val_ca4-[0,5]: 1363.6414 - val_ca4-[6,11]: 63804.9219 - val_ca4-[12,17]: 108882.2656 - val_ca4-[18,23]: 77862.8359\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 67510.4141 - ca1-[0,5]: 1275.0474 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71122.7173 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 123602.1322 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 80954.6302 - val_ca1-[0,5]: 1446.3027 - val_ca1-[6,11]: 64561.6758 - val_ca1-[12,17]: 109947.9766 - val_ca1-[18,23]: 78143.8594 - val_ca2-[0,5]: 1347.2362 - val_ca2-[6,11]: 63647.2695 - val_ca2-[12,17]: 108659.8750 - val_ca2-[18,23]: 77131.4453 - val_ca3-[0,5]: 1363.1315 - val_ca3-[6,11]: 63800.0586 - val_ca3-[12,17]: 108875.4219 - val_ca3-[18,23]: 77300.6875 - val_ca4-[0,5]: 1355.6604 - val_ca4-[6,11]: 63728.5703 - val_ca4-[12,17]: 108774.5703 - val_ca4-[18,23]: 77221.5000\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 67555.0547 - ca1-[0,5]: 1272.3710 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70781.0984 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 122494.9499 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81232.3872 - val_ca1-[0,5]: 1441.6130 - val_ca1-[6,11]: 64520.2578 - val_ca1-[12,17]: 109889.7344 - val_ca1-[18,23]: 78517.9219 - val_ca2-[0,5]: 1339.4463 - val_ca2-[6,11]: 63571.4531 - val_ca2-[12,17]: 108552.8516 - val_ca2-[18,23]: 77465.1953 - val_ca3-[0,5]: 1356.3726 - val_ca3-[6,11]: 63735.3984 - val_ca3-[12,17]: 108784.2031 - val_ca3-[18,23]: 77647.1953 - val_ca4-[0,5]: 1347.7994 - val_ca4-[6,11]: 63652.7383 - val_ca4-[12,17]: 108667.5859 - val_ca4-[18,23]: 77555.4297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 67257.3828 - ca1-[0,5]: 1268.5693 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71030.9728 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 122750.9204 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81213.9592 - val_ca1-[0,5]: 1436.9783 - val_ca1-[6,11]: 64479.1602 - val_ca1-[12,17]: 109831.9297 - val_ca1-[18,23]: 78863.5859 - val_ca2-[0,5]: 1331.7687 - val_ca2-[6,11]: 63496.0703 - val_ca2-[12,17]: 108446.4531 - val_ca2-[18,23]: 77772.1250 - val_ca3-[0,5]: 1349.6997 - val_ca3-[6,11]: 63671.1211 - val_ca3-[12,17]: 108693.5156 - val_ca3-[18,23]: 77966.5781 - val_ca4-[0,5]: 1340.0476 - val_ca4-[6,11]: 63577.3125 - val_ca4-[12,17]: 108561.1406 - val_ca4-[18,23]: 77862.3750\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 67532.8281 - ca1-[0,5]: 1246.1039 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71242.7726 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121912.2454 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 80438.2587 - val_ca1-[0,5]: 1432.4004 - val_ca1-[6,11]: 64438.3984 - val_ca1-[12,17]: 109774.6094 - val_ca1-[18,23]: 78662.5703 - val_ca2-[0,5]: 1324.1914 - val_ca2-[6,11]: 63421.0430 - val_ca2-[12,17]: 108340.4922 - val_ca2-[18,23]: 77534.0703 - val_ca3-[0,5]: 1343.1093 - val_ca3-[6,11]: 63607.1836 - val_ca3-[12,17]: 108603.2812 - val_ca3-[18,23]: 77740.6484 - val_ca4-[0,5]: 1332.4110 - val_ca4-[6,11]: 63502.3906 - val_ca4-[12,17]: 108455.3906 - val_ca4-[18,23]: 77624.3672\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 67617.9531 - ca1-[0,5]: 1247.5462 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70801.2002 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 122536.7873 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 80648.4363 - val_ca1-[0,5]: 1427.8492 - val_ca1-[6,11]: 64397.7148 - val_ca1-[12,17]: 109717.3359 - val_ca1-[18,23]: 78713.2109 - val_ca2-[0,5]: 1316.6748 - val_ca2-[6,11]: 63345.9648 - val_ca2-[12,17]: 108234.4531 - val_ca2-[18,23]: 77545.3203 - val_ca3-[0,5]: 1336.5925 - val_ca3-[6,11]: 63543.4961 - val_ca3-[12,17]: 108513.4141 - val_ca3-[18,23]: 77764.7969 - val_ca4-[0,5]: 1324.8541 - val_ca4-[6,11]: 63427.6289 - val_ca4-[12,17]: 108349.7891 - val_ca4-[18,23]: 77636.0547\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 67297.0781 - ca1-[0,5]: 1269.6739 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70535.2214 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121987.8111 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81233.2726 - val_ca1-[0,5]: 1423.3112 - val_ca1-[6,11]: 64356.9922 - val_ca1-[12,17]: 109660.0312 - val_ca1-[18,23]: 78685.7500 - val_ca2-[0,5]: 1309.2756 - val_ca2-[6,11]: 63271.4141 - val_ca2-[12,17]: 108129.1094 - val_ca2-[18,23]: 77479.1484 - val_ca3-[0,5]: 1330.1384 - val_ca3-[6,11]: 63479.9805 - val_ca3-[12,17]: 108423.7266 - val_ca3-[18,23]: 77711.0938 - val_ca4-[0,5]: 1317.3899 - val_ca4-[6,11]: 63353.1250 - val_ca4-[12,17]: 108244.5703 - val_ca4-[18,23]: 77570.0312\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 67291.7031 - ca1-[0,5]: 1228.5524 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70975.0153 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121769.5605 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 80176.3197 - val_ca1-[0,5]: 1418.7787 - val_ca1-[6,11]: 64316.1367 - val_ca1-[12,17]: 109602.5391 - val_ca1-[18,23]: 79763.0781 - val_ca2-[0,5]: 1301.9690 - val_ca2-[6,11]: 63197.1484 - val_ca2-[12,17]: 108024.1562 - val_ca2-[18,23]: 78509.6641 - val_ca3-[0,5]: 1323.7670 - val_ca3-[6,11]: 63416.8125 - val_ca3-[12,17]: 108334.5312 - val_ca3-[18,23]: 78755.8672 - val_ca4-[0,5]: 1310.0297 - val_ca4-[6,11]: 63279.0352 - val_ca4-[12,17]: 108139.9062 - val_ca4-[18,23]: 78601.4609\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 67135.5312 - ca1-[0,5]: 1240.2681 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70414.0567 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121883.5026 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 80492.6600 - val_ca1-[0,5]: 1414.0598 - val_ca1-[6,11]: 64273.4375 - val_ca1-[12,17]: 109542.3984 - val_ca1-[18,23]: 78281.4531 - val_ca2-[0,5]: 1294.7728 - val_ca2-[6,11]: 63123.3633 - val_ca2-[12,17]: 107919.8359 - val_ca2-[18,23]: 77007.0781 - val_ca3-[0,5]: 1317.4603 - val_ca3-[6,11]: 63353.8398 - val_ca3-[12,17]: 108245.5703 - val_ca3-[18,23]: 77262.6250 - val_ca4-[0,5]: 1302.7670 - val_ca4-[6,11]: 63205.3047 - val_ca4-[12,17]: 108035.6875 - val_ca4-[18,23]: 77097.9219\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 67004.1641 - ca1-[0,5]: 1231.6656 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70100.6311 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 122570.1661 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 80460.4161 - val_ca1-[0,5]: 1406.5331 - val_ca1-[6,11]: 64204.9414 - val_ca1-[12,17]: 109445.9219 - val_ca1-[18,23]: 78764.4219 - val_ca2-[0,5]: 1287.6871 - val_ca2-[6,11]: 63050.0586 - val_ca2-[12,17]: 107816.2031 - val_ca2-[18,23]: 77480.1094 - val_ca3-[0,5]: 1311.2152 - val_ca3-[6,11]: 63291.0156 - val_ca3-[12,17]: 108156.8203 - val_ca3-[18,23]: 77748.2422 - val_ca4-[0,5]: 1295.5989 - val_ca4-[6,11]: 63131.8672 - val_ca4-[12,17]: 107931.8984 - val_ca4-[18,23]: 77571.1562\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 67225.8125 - ca1-[0,5]: 1222.1421 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70052.5492 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121824.5477 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 80121.2879 - val_ca1-[0,5]: 1394.4456 - val_ca1-[6,11]: 64093.9141 - val_ca1-[12,17]: 109289.5547 - val_ca1-[18,23]: 78344.7578 - val_ca2-[0,5]: 1280.6769 - val_ca2-[6,11]: 62976.8906 - val_ca2-[12,17]: 107712.6875 - val_ca2-[18,23]: 77106.2578 - val_ca3-[0,5]: 1305.0287 - val_ca3-[6,11]: 63228.3242 - val_ca3-[12,17]: 108068.2188 - val_ca3-[18,23]: 77385.1953 - val_ca4-[0,5]: 1288.5223 - val_ca4-[6,11]: 63058.7305 - val_ca4-[12,17]: 107828.4609 - val_ca4-[18,23]: 77197.0625\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 67236.9219 - ca1-[0,5]: 1239.1788 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70239.8397 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 122010.2908 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81015.2975 - val_ca1-[0,5]: 1385.5222 - val_ca1-[6,11]: 64011.1250 - val_ca1-[12,17]: 109172.9062 - val_ca1-[18,23]: 78080.3906 - val_ca2-[0,5]: 1273.7479 - val_ca2-[6,11]: 62903.9023 - val_ca2-[12,17]: 107609.4297 - val_ca2-[18,23]: 76851.4922 - val_ca3-[0,5]: 1298.8994 - val_ca3-[6,11]: 63165.7578 - val_ca3-[12,17]: 107979.7812 - val_ca3-[18,23]: 77142.2891 - val_ca4-[0,5]: 1281.5231 - val_ca4-[6,11]: 62985.7617 - val_ca4-[12,17]: 107725.2422 - val_ca4-[18,23]: 76942.3984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "26/26 [==============================] - 3s 114ms/step - loss: 66955.5156 - ca1-[0,5]: 1205.4909 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 69905.3819 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121535.5822 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 80614.1117 - val_ca1-[0,5]: 1377.9320 - val_ca1-[6,11]: 63940.1055 - val_ca1-[12,17]: 109072.8438 - val_ca1-[18,23]: 78487.1172 - val_ca2-[0,5]: 1266.8914 - val_ca2-[6,11]: 62831.0312 - val_ca2-[12,17]: 107506.2969 - val_ca2-[18,23]: 77253.4766 - val_ca3-[0,5]: 1292.8324 - val_ca3-[6,11]: 63103.3516 - val_ca3-[12,17]: 107891.5547 - val_ca3-[18,23]: 77556.5625 - val_ca4-[0,5]: 1274.5956 - val_ca4-[6,11]: 62912.8750 - val_ca4-[12,17]: 107622.1250 - val_ca4-[18,23]: 77344.5703\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 66937.9766 - ca1-[0,5]: 1208.9141 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70335.9170 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121576.1942 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 80140.3944 - val_ca1-[0,5]: 1371.0228 - val_ca1-[6,11]: 63874.9922 - val_ca1-[12,17]: 108981.0625 - val_ca1-[18,23]: 77828.8828 - val_ca2-[0,5]: 1260.1492 - val_ca2-[6,11]: 62758.7109 - val_ca2-[12,17]: 107403.9062 - val_ca2-[18,23]: 76590.1953 - val_ca3-[0,5]: 1286.8296 - val_ca3-[6,11]: 63041.1406 - val_ca3-[12,17]: 107803.5938 - val_ca3-[18,23]: 76903.7578 - val_ca4-[0,5]: 1267.7565 - val_ca4-[6,11]: 62840.2617 - val_ca4-[12,17]: 107519.3594 - val_ca4-[18,23]: 76680.7422\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 66899.7812 - ca1-[0,5]: 1200.3216 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 69623.3595 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121592.2512 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 79937.2141 - val_ca1-[0,5]: 1364.5054 - val_ca1-[6,11]: 63813.1562 - val_ca1-[12,17]: 108893.8750 - val_ca1-[18,23]: 79138.3828 - val_ca2-[0,5]: 1253.4581 - val_ca2-[6,11]: 62686.2695 - val_ca2-[12,17]: 107301.3516 - val_ca2-[18,23]: 77875.9453 - val_ca3-[0,5]: 1280.8767 - val_ca3-[6,11]: 62978.9844 - val_ca3-[12,17]: 107715.6562 - val_ca3-[18,23]: 78204.0547 - val_ca4-[0,5]: 1261.0065 - val_ca4-[6,11]: 62767.9375 - val_ca4-[12,17]: 107416.9844 - val_ca4-[18,23]: 77967.4922\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 66852.0234 - ca1-[0,5]: 1187.0034 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70385.1600 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 120614.0911 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 79853.5833 - val_ca1-[0,5]: 1358.2811 - val_ca1-[6,11]: 63753.7148 - val_ca1-[12,17]: 108810.0391 - val_ca1-[18,23]: 77837.8984 - val_ca2-[0,5]: 1246.8579 - val_ca2-[6,11]: 62614.1367 - val_ca2-[12,17]: 107199.1719 - val_ca2-[18,23]: 76572.1797 - val_ca3-[0,5]: 1274.9861 - val_ca3-[6,11]: 62916.9961 - val_ca3-[12,17]: 107627.9688 - val_ca3-[18,23]: 76908.7422 - val_ca4-[0,5]: 1254.3357 - val_ca4-[6,11]: 62695.8086 - val_ca4-[12,17]: 107314.8281 - val_ca4-[18,23]: 76662.9531\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 66838.9453 - ca1-[0,5]: 1192.3100 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70415.3898 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121353.0023 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 79676.9282 - val_ca1-[0,5]: 1352.2758 - val_ca1-[6,11]: 63696.0078 - val_ca1-[12,17]: 108728.6328 - val_ca1-[18,23]: 77396.0547 - val_ca2-[0,5]: 1240.3344 - val_ca2-[6,11]: 62542.1680 - val_ca2-[12,17]: 107097.1953 - val_ca2-[18,23]: 76115.6016 - val_ca3-[0,5]: 1269.1504 - val_ca3-[6,11]: 62855.1133 - val_ca3-[12,17]: 107540.3828 - val_ca3-[18,23]: 76463.0781 - val_ca4-[0,5]: 1247.7367 - val_ca4-[6,11]: 62623.7812 - val_ca4-[12,17]: 107212.8203 - val_ca4-[18,23]: 76206.2422\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 66713.1328 - ca1-[0,5]: 1177.0993 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 69857.5012 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 120322.6296 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 80039.2037 - val_ca1-[0,5]: 1346.4529 - val_ca1-[6,11]: 63639.6875 - val_ca1-[12,17]: 108649.1641 - val_ca1-[18,23]: 77508.6641 - val_ca2-[0,5]: 1233.8824 - val_ca2-[6,11]: 62470.3125 - val_ca2-[12,17]: 106995.3672 - val_ca2-[18,23]: 76212.8828 - val_ca3-[0,5]: 1263.3734 - val_ca3-[6,11]: 62793.3789 - val_ca3-[12,17]: 107452.9844 - val_ca3-[18,23]: 76571.0625 - val_ca4-[0,5]: 1241.2098 - val_ca4-[6,11]: 62551.8750 - val_ca4-[12,17]: 107110.9375 - val_ca4-[18,23]: 76303.3281\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 66875.6406 - ca1-[0,5]: 1176.7675 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 69193.8877 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121162.4187 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 80088.1250 - val_ca1-[0,5]: 1340.7909 - val_ca1-[6,11]: 63584.5859 - val_ca1-[12,17]: 108571.3906 - val_ca1-[18,23]: 77915.0000 - val_ca2-[0,5]: 1227.5175 - val_ca2-[6,11]: 62398.7305 - val_ca2-[12,17]: 106893.8672 - val_ca2-[18,23]: 76594.3672 - val_ca3-[0,5]: 1257.6578 - val_ca3-[6,11]: 62731.8164 - val_ca3-[12,17]: 107365.8125 - val_ca3-[18,23]: 76965.5234 - val_ca4-[0,5]: 1234.7638 - val_ca4-[6,11]: 62480.1680 - val_ca4-[12,17]: 107009.3359 - val_ca4-[18,23]: 76685.1250\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 66423.9297 - ca1-[0,5]: 1179.5777 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 70125.0454 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 120890.5159 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 79983.5266 - val_ca1-[0,5]: 1335.2675 - val_ca1-[6,11]: 63530.5039 - val_ca1-[12,17]: 108495.0469 - val_ca1-[18,23]: 77686.1641 - val_ca2-[0,5]: 1221.2195 - val_ca2-[6,11]: 62327.2188 - val_ca2-[12,17]: 106792.4688 - val_ca2-[18,23]: 76348.7188 - val_ca3-[0,5]: 1251.9895 - val_ca3-[6,11]: 62670.2695 - val_ca3-[12,17]: 107278.6719 - val_ca3-[18,23]: 76730.2500 - val_ca4-[0,5]: 1228.3971 - val_ca4-[6,11]: 62408.6680 - val_ca4-[12,17]: 106907.9688 - val_ca4-[18,23]: 76439.3203\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 66623.6562 - ca1-[0,5]: 1160.9375 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 69330.9936 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121186.2361 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 79848.9731 - val_ca1-[0,5]: 1329.8583 - val_ca1-[6,11]: 63477.2266 - val_ca1-[12,17]: 108419.8203 - val_ca1-[18,23]: 77125.2656 - val_ca2-[0,5]: 1215.0056 - val_ca2-[6,11]: 62255.9688 - val_ca2-[12,17]: 106691.3906 - val_ca2-[18,23]: 75773.9062 - val_ca3-[0,5]: 1246.3844 - val_ca3-[6,11]: 62608.9414 - val_ca3-[12,17]: 107191.7891 - val_ca3-[18,23]: 76164.7031 - val_ca4-[0,5]: 1222.1165 - val_ca4-[6,11]: 62337.4414 - val_ca4-[12,17]: 106806.9609 - val_ca4-[18,23]: 75864.1406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 66247.3672 - ca1-[0,5]: 1152.5926 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 69639.2465 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121195.2584 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78924.0081 - val_ca1-[0,5]: 1324.5587 - val_ca1-[6,11]: 63424.6914 - val_ca1-[12,17]: 108345.6562 - val_ca1-[18,23]: 78223.6797 - val_ca2-[0,5]: 1208.8507 - val_ca2-[6,11]: 62184.6758 - val_ca2-[12,17]: 106590.2500 - val_ca2-[18,23]: 76842.0547 - val_ca3-[0,5]: 1240.8313 - val_ca3-[6,11]: 62547.6758 - val_ca3-[12,17]: 107105.0078 - val_ca3-[18,23]: 77246.7578 - val_ca4-[0,5]: 1215.9037 - val_ca4-[6,11]: 62266.3047 - val_ca4-[12,17]: 106706.0781 - val_ca4-[18,23]: 76933.0859\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 66449.2656 - ca1-[0,5]: 1153.4121 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 69377.0000 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121343.4505 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78765.7341 - val_ca1-[0,5]: 1319.3557 - val_ca1-[6,11]: 63372.8203 - val_ca1-[12,17]: 108272.3906 - val_ca1-[18,23]: 77797.8281 - val_ca2-[0,5]: 1202.7722 - val_ca2-[6,11]: 62113.5547 - val_ca2-[12,17]: 106489.3047 - val_ca2-[18,23]: 76396.0078 - val_ca3-[0,5]: 1235.3477 - val_ca3-[6,11]: 62486.6914 - val_ca3-[12,17]: 107018.5703 - val_ca3-[18,23]: 76811.6250 - val_ca4-[0,5]: 1209.7677 - val_ca4-[6,11]: 62195.3359 - val_ca4-[12,17]: 106605.3828 - val_ca4-[18,23]: 76487.1094\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 66364.1953 - ca1-[0,5]: 1152.9950 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 69071.3646 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 120966.3174 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 79678.9086 - val_ca1-[0,5]: 1314.2395 - val_ca1-[6,11]: 63321.4961 - val_ca1-[12,17]: 108199.8906 - val_ca1-[18,23]: 76532.1328 - val_ca2-[0,5]: 1196.7904 - val_ca2-[6,11]: 62042.8633 - val_ca2-[12,17]: 106388.9531 - val_ca2-[18,23]: 75121.8594 - val_ca3-[0,5]: 1229.9016 - val_ca3-[6,11]: 62425.6250 - val_ca3-[12,17]: 106932.0078 - val_ca3-[18,23]: 75544.2656 - val_ca4-[0,5]: 1203.6940 - val_ca4-[6,11]: 62124.3867 - val_ca4-[12,17]: 106504.6953 - val_ca4-[18,23]: 75211.8516\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 66490.6172 - ca1-[0,5]: 1155.8143 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 69372.7920 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 120197.7433 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 79886.8304 - val_ca1-[0,5]: 1309.2192 - val_ca1-[6,11]: 63270.8477 - val_ca1-[12,17]: 108128.3047 - val_ca1-[18,23]: 78151.3125 - val_ca2-[0,5]: 1190.8647 - val_ca2-[6,11]: 61972.1016 - val_ca2-[12,17]: 106288.4766 - val_ca2-[18,23]: 76696.7344 - val_ca3-[0,5]: 1224.5098 - val_ca3-[6,11]: 62364.6641 - val_ca3-[12,17]: 106845.5703 - val_ca3-[18,23]: 77136.6875 - val_ca4-[0,5]: 1197.7040 - val_ca4-[6,11]: 62053.7031 - val_ca4-[12,17]: 106404.3516 - val_ca4-[18,23]: 76788.2188\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 66137.0547 - ca1-[0,5]: 1151.1657 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 69137.3718 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 120587.1788 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 79335.7486 - val_ca1-[0,5]: 1304.2731 - val_ca1-[6,11]: 63220.6406 - val_ca1-[12,17]: 108057.3594 - val_ca1-[18,23]: 77087.4453 - val_ca2-[0,5]: 1185.0156 - val_ca2-[6,11]: 61901.5312 - val_ca2-[12,17]: 106188.2344 - val_ca2-[18,23]: 75624.5156 - val_ca3-[0,5]: 1219.1656 - val_ca3-[6,11]: 62303.7344 - val_ca3-[12,17]: 106759.1875 - val_ca3-[18,23]: 76070.8516 - val_ca4-[0,5]: 1191.7606 - val_ca4-[6,11]: 61982.8438 - val_ca4-[12,17]: 106303.7422 - val_ca4-[18,23]: 75714.7656\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 65951.7812 - ca1-[0,5]: 1138.2775 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 69335.8469 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 120920.1097 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78680.2219 - val_ca1-[0,5]: 1299.4204 - val_ca1-[6,11]: 63171.1016 - val_ca1-[12,17]: 107987.3281 - val_ca1-[18,23]: 77372.9531 - val_ca2-[0,5]: 1179.2445 - val_ca2-[6,11]: 61831.1602 - val_ca2-[12,17]: 106088.2656 - val_ca2-[18,23]: 75879.6328 - val_ca3-[0,5]: 1213.8820 - val_ca3-[6,11]: 62242.9961 - val_ca3-[12,17]: 106673.0156 - val_ca3-[18,23]: 76338.9062 - val_ca4-[0,5]: 1185.9188 - val_ca4-[6,11]: 61912.4766 - val_ca4-[12,17]: 106203.7969 - val_ca4-[18,23]: 75970.3359\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 3s 115ms/step - loss: 66187.0156 - ca1-[0,5]: 1133.2354 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 69289.4106 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 120792.3715 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78886.8990 - val_ca1-[0,5]: 1294.6198 - val_ca1-[6,11]: 63121.7891 - val_ca1-[12,17]: 107917.6250 - val_ca1-[18,23]: 77174.6719 - val_ca2-[0,5]: 1173.5555 - val_ca2-[6,11]: 61761.0703 - val_ca2-[12,17]: 105988.6484 - val_ca2-[18,23]: 75661.8672 - val_ca3-[0,5]: 1208.6500 - val_ca3-[6,11]: 62182.3398 - val_ca3-[12,17]: 106586.9453 - val_ca3-[18,23]: 76130.5078 - val_ca4-[0,5]: 1180.1576 - val_ca4-[6,11]: 61842.3438 - val_ca4-[12,17]: 106104.1641 - val_ca4-[18,23]: 75752.3203\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 3s 124ms/step - loss: 66057.6719 - ca1-[0,5]: 1130.6918 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 69655.0796 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 119970.4795 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78966.0480 - val_ca1-[0,5]: 1289.8806 - val_ca1-[6,11]: 63072.8203 - val_ca1-[12,17]: 107848.3828 - val_ca1-[18,23]: 76181.1953 - val_ca2-[0,5]: 1167.9247 - val_ca2-[6,11]: 61690.9258 - val_ca2-[12,17]: 105888.9297 - val_ca2-[18,23]: 74651.3125 - val_ca3-[0,5]: 1203.4572 - val_ca3-[6,11]: 62121.6055 - val_ca3-[12,17]: 106500.7344 - val_ca3-[18,23]: 75128.4062 - val_ca4-[0,5]: 1174.4606 - val_ca4-[6,11]: 61772.2656 - val_ca4-[12,17]: 106004.5625 - val_ca4-[18,23]: 74741.4375\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 66014.4453 - ca1-[0,5]: 1116.7950 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68915.3351 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 120197.6372 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 79191.7274 - val_ca1-[0,5]: 1285.2062 - val_ca1-[6,11]: 63024.2383 - val_ca1-[12,17]: 107779.6641 - val_ca1-[18,23]: 77154.4219 - val_ca2-[0,5]: 1162.3689 - val_ca2-[6,11]: 61620.9727 - val_ca2-[12,17]: 105789.4609 - val_ca2-[18,23]: 75593.9375 - val_ca3-[0,5]: 1198.3301 - val_ca3-[6,11]: 62061.1250 - val_ca3-[12,17]: 106414.8828 - val_ca3-[18,23]: 76083.7188 - val_ca4-[0,5]: 1168.8275 - val_ca4-[6,11]: 61702.2188 - val_ca4-[12,17]: 105904.9766 - val_ca4-[18,23]: 75684.3672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "26/26 [==============================] - 3s 117ms/step - loss: 65988.0312 - ca1-[0,5]: 1111.5864 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68971.8848 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 120318.8611 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 79652.9638 - val_ca1-[0,5]: 1280.5938 - val_ca1-[6,11]: 62976.0156 - val_ca1-[12,17]: 107711.4609 - val_ca1-[18,23]: 76014.6953 - val_ca2-[0,5]: 1156.8824 - val_ca2-[6,11]: 61551.1289 - val_ca2-[12,17]: 105690.1094 - val_ca2-[18,23]: 74439.0234 - val_ca3-[0,5]: 1193.2485 - val_ca3-[6,11]: 62000.6562 - val_ca3-[12,17]: 106329.0312 - val_ca3-[18,23]: 74936.4297 - val_ca4-[0,5]: 1163.2644 - val_ca4-[6,11]: 61632.2969 - val_ca4-[12,17]: 105805.5703 - val_ca4-[18,23]: 74528.8672\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 65703.5703 - ca1-[0,5]: 1123.5055 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68699.6372 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 119470.9832 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78636.0208 - val_ca1-[0,5]: 1276.0435 - val_ca1-[6,11]: 62928.1562 - val_ca1-[12,17]: 107643.7500 - val_ca1-[18,23]: 77536.6875 - val_ca2-[0,5]: 1151.4655 - val_ca2-[6,11]: 61481.3945 - val_ca2-[12,17]: 105590.8906 - val_ca2-[18,23]: 75922.0391 - val_ca3-[0,5]: 1188.2229 - val_ca3-[6,11]: 61940.3125 - val_ca3-[12,17]: 106243.3359 - val_ca3-[18,23]: 76434.5625 - val_ca4-[0,5]: 1157.7601 - val_ca4-[6,11]: 61562.3477 - val_ca4-[12,17]: 105706.0625 - val_ca4-[18,23]: 76012.4766\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 65786.7578 - ca1-[0,5]: 1114.3156 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68104.1667 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 119589.7894 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78731.1105 - val_ca1-[0,5]: 1271.5345 - val_ca1-[6,11]: 62880.4648 - val_ca1-[12,17]: 107576.2578 - val_ca1-[18,23]: 76121.0156 - val_ca2-[0,5]: 1146.1212 - val_ca2-[6,11]: 61411.8203 - val_ca2-[12,17]: 105491.8672 - val_ca2-[18,23]: 74495.8125 - val_ca3-[0,5]: 1183.2500 - val_ca3-[6,11]: 61880.0781 - val_ca3-[12,17]: 106157.7578 - val_ca3-[18,23]: 75014.3203 - val_ca4-[0,5]: 1152.3441 - val_ca4-[6,11]: 61492.7617 - val_ca4-[12,17]: 105607.0703 - val_ca4-[18,23]: 74585.4609\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 65761.4453 - ca1-[0,5]: 1114.7038 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68443.5062 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 119941.1392 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 79302.0567 - val_ca1-[0,5]: 1267.0890 - val_ca1-[6,11]: 62833.1406 - val_ca1-[12,17]: 107509.2812 - val_ca1-[18,23]: 77088.2188 - val_ca2-[0,5]: 1140.8542 - val_ca2-[6,11]: 61342.4648 - val_ca2-[12,17]: 105393.1406 - val_ca2-[18,23]: 75431.2656 - val_ca3-[0,5]: 1178.3281 - val_ca3-[6,11]: 61819.9180 - val_ca3-[12,17]: 106072.2734 - val_ca3-[18,23]: 75962.3359 - val_ca4-[0,5]: 1146.9880 - val_ca4-[6,11]: 61423.1562 - val_ca4-[12,17]: 105508.0156 - val_ca4-[18,23]: 75521.0469\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 65555.2344 - ca1-[0,5]: 1108.8062 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68901.0012 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 120280.2488 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78272.9742 - val_ca1-[0,5]: 1262.7115 - val_ca1-[6,11]: 62786.2734 - val_ca1-[12,17]: 107442.9219 - val_ca1-[18,23]: 77082.8516 - val_ca2-[0,5]: 1135.6414 - val_ca2-[6,11]: 61273.0234 - val_ca2-[12,17]: 105294.2734 - val_ca2-[18,23]: 75399.9609 - val_ca3-[0,5]: 1173.4573 - val_ca3-[6,11]: 61759.8477 - val_ca3-[12,17]: 105986.8984 - val_ca3-[18,23]: 75941.7344 - val_ca4-[0,5]: 1141.7045 - val_ca4-[6,11]: 61353.7148 - val_ca4-[12,17]: 105409.1719 - val_ca4-[18,23]: 75489.7812\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 65547.0156 - ca1-[0,5]: 1098.2810 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68246.9054 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 119610.4731 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78490.1030 - val_ca1-[0,5]: 1258.4039 - val_ca1-[6,11]: 62739.8750 - val_ca1-[12,17]: 107377.2422 - val_ca1-[18,23]: 76912.3984 - val_ca2-[0,5]: 1130.5079 - val_ca2-[6,11]: 61203.8398 - val_ca2-[12,17]: 105195.7109 - val_ca2-[18,23]: 75200.8125 - val_ca3-[0,5]: 1168.6489 - val_ca3-[6,11]: 61699.9961 - val_ca3-[12,17]: 105901.8125 - val_ca3-[18,23]: 75754.0625 - val_ca4-[0,5]: 1136.4877 - val_ca4-[6,11]: 61284.3516 - val_ca4-[12,17]: 105310.3984 - val_ca4-[18,23]: 75290.6094\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 3s 125ms/step - loss: 65517.6680 - ca1-[0,5]: 1085.5014 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 67991.0272 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 118608.2662 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 79084.9251 - val_ca1-[0,5]: 1254.1351 - val_ca1-[6,11]: 62693.6328 - val_ca1-[12,17]: 107311.7422 - val_ca1-[18,23]: 76684.8125 - val_ca2-[0,5]: 1125.4366 - val_ca2-[6,11]: 61134.6758 - val_ca2-[12,17]: 105097.1797 - val_ca2-[18,23]: 74953.1641 - val_ca3-[0,5]: 1163.8865 - val_ca3-[6,11]: 61640.1562 - val_ca3-[12,17]: 105816.7422 - val_ca3-[18,23]: 75515.0312 - val_ca4-[0,5]: 1131.3367 - val_ca4-[6,11]: 61215.0625 - val_ca4-[12,17]: 105211.7109 - val_ca4-[18,23]: 75042.5391\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 65548.3672 - ca1-[0,5]: 1097.0760 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68711.0813 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 119182.8206 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78408.8614 - val_ca1-[0,5]: 1249.8988 - val_ca1-[6,11]: 62647.4648 - val_ca1-[12,17]: 107246.3672 - val_ca1-[18,23]: 76962.4531 - val_ca2-[0,5]: 1120.4415 - val_ca2-[6,11]: 61065.7305 - val_ca2-[12,17]: 104998.9141 - val_ca2-[18,23]: 75203.2109 - val_ca3-[0,5]: 1159.1654 - val_ca3-[6,11]: 61580.2812 - val_ca3-[12,17]: 105731.5781 - val_ca3-[18,23]: 75775.9219 - val_ca4-[0,5]: 1126.2610 - val_ca4-[6,11]: 61145.9766 - val_ca4-[12,17]: 105113.2734 - val_ca4-[18,23]: 75292.5547\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 3s 125ms/step - loss: 65479.1172 - ca1-[0,5]: 1097.5574 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68276.4170 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 119529.6146 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 77796.8643 - val_ca1-[0,5]: 1245.7269 - val_ca1-[6,11]: 62601.7070 - val_ca1-[12,17]: 107181.5625 - val_ca1-[18,23]: 77433.3750 - val_ca2-[0,5]: 1115.5145 - val_ca2-[6,11]: 60996.8945 - val_ca2-[12,17]: 104900.7891 - val_ca2-[18,23]: 75638.1484 - val_ca3-[0,5]: 1154.4866 - val_ca3-[6,11]: 61520.3867 - val_ca3-[12,17]: 105646.3750 - val_ca3-[18,23]: 76224.2031 - val_ca4-[0,5]: 1121.2532 - val_ca4-[6,11]: 61076.9922 - val_ca4-[12,17]: 105014.9609 - val_ca4-[18,23]: 75727.8516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 65340.1953 - ca1-[0,5]: 1096.1579 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68402.1409 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 119839.2989 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 79505.6774 - val_ca1-[0,5]: 1241.5897 - val_ca1-[6,11]: 62556.0859 - val_ca1-[12,17]: 107116.9062 - val_ca1-[18,23]: 77402.2109 - val_ca2-[0,5]: 1110.6508 - val_ca2-[6,11]: 60928.1016 - val_ca2-[12,17]: 104802.6719 - val_ca2-[18,23]: 75581.2109 - val_ca3-[0,5]: 1149.8627 - val_ca3-[6,11]: 61460.6055 - val_ca3-[12,17]: 105561.3047 - val_ca3-[18,23]: 76177.3281 - val_ca4-[0,5]: 1116.3175 - val_ca4-[6,11]: 61008.1680 - val_ca4-[12,17]: 104916.8672 - val_ca4-[18,23]: 75670.8750\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 65218.3906 - ca1-[0,5]: 1083.9614 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68280.5926 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 118784.9627 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78176.5576 - val_ca1-[0,5]: 1237.4988 - val_ca1-[6,11]: 62510.6836 - val_ca1-[12,17]: 107052.5625 - val_ca1-[18,23]: 77023.0703 - val_ca2-[0,5]: 1105.8512 - val_ca2-[6,11]: 60859.3594 - val_ca2-[12,17]: 104704.6094 - val_ca2-[18,23]: 75182.2891 - val_ca3-[0,5]: 1145.2908 - val_ca3-[6,11]: 61400.9414 - val_ca3-[12,17]: 105476.3984 - val_ca3-[18,23]: 75786.4766 - val_ca4-[0,5]: 1111.4409 - val_ca4-[6,11]: 60939.3320 - val_ca4-[12,17]: 104818.6875 - val_ca4-[18,23]: 75271.5312\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 65316.7539 - ca1-[0,5]: 1078.7009 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 67943.4479 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 119153.3247 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 77928.3866 - val_ca1-[0,5]: 1233.4475 - val_ca1-[6,11]: 62465.4414 - val_ca1-[12,17]: 106988.4453 - val_ca1-[18,23]: 76971.5078 - val_ca2-[0,5]: 1101.1158 - val_ca2-[6,11]: 60790.6680 - val_ca2-[12,17]: 104606.6094 - val_ca2-[18,23]: 75100.3125 - val_ca3-[0,5]: 1140.7726 - val_ca3-[6,11]: 61341.3867 - val_ca3-[12,17]: 105391.6016 - val_ca3-[18,23]: 75716.1094 - val_ca4-[0,5]: 1106.6511 - val_ca4-[6,11]: 60870.8789 - val_ca4-[12,17]: 104721.0547 - val_ca4-[18,23]: 75190.0234\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 65130.9648 - ca1-[0,5]: 1075.3223 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68336.0567 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 119335.1652 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78099.5709 - val_ca1-[0,5]: 1229.4388 - val_ca1-[6,11]: 62420.4180 - val_ca1-[12,17]: 106924.6328 - val_ca1-[18,23]: 75536.5938 - val_ca2-[0,5]: 1096.4535 - val_ca2-[6,11]: 60722.1562 - val_ca2-[12,17]: 104508.8359 - val_ca2-[18,23]: 73653.9219 - val_ca3-[0,5]: 1136.3038 - val_ca3-[6,11]: 61281.8945 - val_ca3-[12,17]: 105306.8984 - val_ca3-[18,23]: 74274.9062 - val_ca4-[0,5]: 1101.9047 - val_ca4-[6,11]: 60802.1680 - val_ca4-[12,17]: 104623.0234 - val_ca4-[18,23]: 73742.7188\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 65053.1055 - ca1-[0,5]: 1073.8098 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 67682.2522 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 119262.6377 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 77485.2130 - val_ca1-[0,5]: 1225.4673 - val_ca1-[6,11]: 62375.5352 - val_ca1-[12,17]: 106860.9922 - val_ca1-[18,23]: 76279.0312 - val_ca2-[0,5]: 1091.8716 - val_ca2-[6,11]: 60653.9531 - val_ca2-[12,17]: 104411.4766 - val_ca2-[18,23]: 74362.2031 - val_ca3-[0,5]: 1131.8804 - val_ca3-[6,11]: 61222.4180 - val_ca3-[12,17]: 105222.1797 - val_ca3-[18,23]: 74995.6406 - val_ca4-[0,5]: 1097.2448 - val_ca4-[6,11]: 60733.8516 - val_ca4-[12,17]: 104525.5312 - val_ca4-[18,23]: 74451.2578\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 64981.5039 - ca1-[0,5]: 1064.8982 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68043.5289 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 118502.4337 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 77627.4618 - val_ca1-[0,5]: 1221.5565 - val_ca1-[6,11]: 62331.0625 - val_ca1-[12,17]: 106797.9219 - val_ca1-[18,23]: 75936.5547 - val_ca2-[0,5]: 1087.3612 - val_ca2-[6,11]: 60585.9180 - val_ca2-[12,17]: 104314.3125 - val_ca2-[18,23]: 73994.0781 - val_ca3-[0,5]: 1127.5128 - val_ca3-[6,11]: 61163.1016 - val_ca3-[12,17]: 105137.6562 - val_ca3-[18,23]: 74637.0391 - val_ca4-[0,5]: 1092.6395 - val_ca4-[6,11]: 60665.4531 - val_ca4-[12,17]: 104427.8828 - val_ca4-[18,23]: 74082.7109\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 64970.1250 - ca1-[0,5]: 1051.6824 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 67648.2882 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 118595.9907 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 77710.9089 - val_ca1-[0,5]: 1217.6771 - val_ca1-[6,11]: 62286.6875 - val_ca1-[12,17]: 106734.9766 - val_ca1-[18,23]: 76414.3594 - val_ca2-[0,5]: 1082.9027 - val_ca2-[6,11]: 60517.7617 - val_ca2-[12,17]: 104216.9609 - val_ca2-[18,23]: 74446.0391 - val_ca3-[0,5]: 1123.1940 - val_ca3-[6,11]: 61103.8242 - val_ca3-[12,17]: 105053.2109 - val_ca3-[18,23]: 75098.7031 - val_ca4-[0,5]: 1088.1119 - val_ca4-[6,11]: 60597.3164 - val_ca4-[12,17]: 104330.5859 - val_ca4-[18,23]: 74534.6641\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 64886.0000 - ca1-[0,5]: 1063.3645 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 67291.0483 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 119263.5200 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78291.3284 - val_ca1-[0,5]: 1213.8400 - val_ca1-[6,11]: 62242.5195 - val_ca1-[12,17]: 106672.3203 - val_ca1-[18,23]: 76409.4844 - val_ca2-[0,5]: 1078.5170 - val_ca2-[6,11]: 60449.7969 - val_ca2-[12,17]: 104119.8594 - val_ca2-[18,23]: 74414.5547 - val_ca3-[0,5]: 1118.9232 - val_ca3-[6,11]: 61044.6094 - val_ca3-[12,17]: 104968.7969 - val_ca3-[18,23]: 75077.0000 - val_ca4-[0,5]: 1083.6464 - val_ca4-[6,11]: 60529.2070 - val_ca4-[12,17]: 104233.2969 - val_ca4-[18,23]: 74503.0156\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 64733.5430 - ca1-[0,5]: 1055.1541 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 68345.1664 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 119060.9543 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 77234.7361 - val_ca1-[0,5]: 1210.0598 - val_ca1-[6,11]: 62198.7305 - val_ca1-[12,17]: 106610.1953 - val_ca1-[18,23]: 76465.7266 - val_ca2-[0,5]: 1074.1956 - val_ca2-[6,11]: 60381.9023 - val_ca2-[12,17]: 104022.8203 - val_ca2-[18,23]: 74435.2188 - val_ca3-[0,5]: 1114.7063 - val_ca3-[6,11]: 60985.5195 - val_ca3-[12,17]: 104884.5625 - val_ca3-[18,23]: 75110.4141 - val_ca4-[0,5]: 1079.2335 - val_ca4-[6,11]: 60460.9688 - val_ca4-[12,17]: 104135.8203 - val_ca4-[18,23]: 74523.6953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 64709.2148 - ca1-[0,5]: 1043.7617 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 67315.4039 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 117888.2810 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 77236.0660 - val_ca1-[0,5]: 1206.3185 - val_ca1-[6,11]: 62155.1289 - val_ca1-[12,17]: 106548.3125 - val_ca1-[18,23]: 76552.7422 - val_ca2-[0,5]: 1069.9392 - val_ca2-[6,11]: 60314.0820 - val_ca2-[12,17]: 103925.8594 - val_ca2-[18,23]: 74500.3828 - val_ca3-[0,5]: 1110.5430 - val_ca3-[6,11]: 60926.5586 - val_ca3-[12,17]: 104800.4922 - val_ca3-[18,23]: 75183.7500 - val_ca4-[0,5]: 1074.8977 - val_ca4-[6,11]: 60393.0000 - val_ca4-[12,17]: 104038.6797 - val_ca4-[18,23]: 74588.4609\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 64615.8789 - ca1-[0,5]: 1051.5108 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 67455.6317 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 118445.4042 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 77044.1950 - val_ca1-[0,5]: 1202.6102 - val_ca1-[6,11]: 62111.6562 - val_ca1-[12,17]: 106486.6172 - val_ca1-[18,23]: 76030.0156 - val_ca2-[0,5]: 1065.7540 - val_ca2-[6,11]: 60246.4375 - val_ca2-[12,17]: 103829.1328 - val_ca2-[18,23]: 73950.5703 - val_ca3-[0,5]: 1106.4244 - val_ca3-[6,11]: 60867.6055 - val_ca3-[12,17]: 104716.3906 - val_ca3-[18,23]: 74643.7031 - val_ca4-[0,5]: 1070.6252 - val_ca4-[6,11]: 60325.0781 - val_ca4-[12,17]: 103941.5938 - val_ca4-[18,23]: 74038.3516\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 64527.9609 - ca1-[0,5]: 1054.4632 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 67494.5363 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 118683.4146 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 77845.0379 - val_ca1-[0,5]: 1198.9490 - val_ca1-[6,11]: 62068.4570 - val_ca1-[12,17]: 106425.2891 - val_ca1-[18,23]: 76051.7812 - val_ca2-[0,5]: 1061.6313 - val_ca2-[6,11]: 60178.8359 - val_ca2-[12,17]: 103732.4141 - val_ca2-[18,23]: 73946.7734 - val_ca3-[0,5]: 1102.3580 - val_ca3-[6,11]: 60808.7695 - val_ca3-[12,17]: 104632.4609 - val_ca3-[18,23]: 74649.1406 - val_ca4-[0,5]: 1066.4189 - val_ca4-[6,11]: 60257.2578 - val_ca4-[12,17]: 103844.5703 - val_ca4-[18,23]: 74034.2500\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 64520.0391 - ca1-[0,5]: 1057.0847 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66699.8911 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 117797.7798 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 78187.0579 - val_ca1-[0,5]: 1195.3080 - val_ca1-[6,11]: 62025.2344 - val_ca1-[12,17]: 106363.9297 - val_ca1-[18,23]: 75749.6484 - val_ca2-[0,5]: 1057.5790 - val_ca2-[6,11]: 60111.3984 - val_ca2-[12,17]: 103635.9375 - val_ca2-[18,23]: 73624.1953 - val_ca3-[0,5]: 1098.3376 - val_ca3-[6,11]: 60749.9492 - val_ca3-[12,17]: 104548.5078 - val_ca3-[18,23]: 74333.9688 - val_ca4-[0,5]: 1062.2856 - val_ca4-[6,11]: 60189.6367 - val_ca4-[12,17]: 103747.8672 - val_ca4-[18,23]: 73711.1875\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 64492.3711 - ca1-[0,5]: 1048.5282 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 67704.7468 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 118288.3134 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 77113.7975 - val_ca1-[0,5]: 1191.6899 - val_ca1-[6,11]: 61982.0039 - val_ca1-[12,17]: 106302.5469 - val_ca1-[18,23]: 75287.6719 - val_ca2-[0,5]: 1053.5759 - val_ca2-[6,11]: 60043.7891 - val_ca2-[12,17]: 103539.1562 - val_ca2-[18,23]: 73139.6484 - val_ca3-[0,5]: 1094.3691 - val_ca3-[6,11]: 60691.2422 - val_ca3-[12,17]: 104464.7109 - val_ca3-[18,23]: 73857.8125 - val_ca4-[0,5]: 1058.2146 - val_ca4-[6,11]: 60122.0508 - val_ca4-[12,17]: 103651.1797 - val_ca4-[18,23]: 73226.4922\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 64548.7266 - ca1-[0,5]: 1039.3135 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66918.0343 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 117688.5830 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 77733.5411 - val_ca1-[0,5]: 1188.1078 - val_ca1-[6,11]: 61938.9297 - val_ca1-[12,17]: 106241.3750 - val_ca1-[18,23]: 76248.2266 - val_ca2-[0,5]: 1049.6503 - val_ca2-[6,11]: 59976.4492 - val_ca2-[12,17]: 103442.7500 - val_ca2-[18,23]: 74058.6875 - val_ca3-[0,5]: 1090.4459 - val_ca3-[6,11]: 60632.5469 - val_ca3-[12,17]: 104380.9062 - val_ca3-[18,23]: 74791.3750 - val_ca4-[0,5]: 1054.2102 - val_ca4-[6,11]: 60054.5703 - val_ca4-[12,17]: 103554.5938 - val_ca4-[18,23]: 74145.9609\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 64508.0391 - ca1-[0,5]: 1041.7788 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 67695.6241 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 118460.5515 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 77032.0266 - val_ca1-[0,5]: 1184.5942 - val_ca1-[6,11]: 61896.4219 - val_ca1-[12,17]: 106180.9844 - val_ca1-[18,23]: 75975.7109 - val_ca2-[0,5]: 1045.7892 - val_ca2-[6,11]: 59909.2070 - val_ca2-[12,17]: 103346.4375 - val_ca2-[18,23]: 73761.2344 - val_ca3-[0,5]: 1086.5642 - val_ca3-[6,11]: 60573.8125 - val_ca3-[12,17]: 104297.0078 - val_ca3-[18,23]: 74502.5312 - val_ca4-[0,5]: 1050.2657 - val_ca4-[6,11]: 59987.0820 - val_ca4-[12,17]: 103457.9688 - val_ca4-[18,23]: 73848.1406\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 64409.3320 - ca1-[0,5]: 1025.1993 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66949.2396 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 117661.9878 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76642.4630 - val_ca1-[0,5]: 1181.0771 - val_ca1-[6,11]: 61853.5977 - val_ca1-[12,17]: 106120.1250 - val_ca1-[18,23]: 74933.8125 - val_ca2-[0,5]: 1041.9929 - val_ca2-[6,11]: 59842.0352 - val_ca2-[12,17]: 103250.2422 - val_ca2-[18,23]: 72704.3438 - val_ca3-[0,5]: 1082.7322 - val_ca3-[6,11]: 60515.1484 - val_ca3-[12,17]: 104213.2266 - val_ca3-[18,23]: 73451.0469 - val_ca4-[0,5]: 1046.3835 - val_ca4-[6,11]: 59919.6250 - val_ca4-[12,17]: 103361.3906 - val_ca4-[18,23]: 72790.4609\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 64405.6953 - ca1-[0,5]: 1047.8462 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 67295.4120 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 117818.4048 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76924.4673 - val_ca1-[0,5]: 1177.6051 - val_ca1-[6,11]: 61811.0430 - val_ca1-[12,17]: 106059.6641 - val_ca1-[18,23]: 76302.5234 - val_ca2-[0,5]: 1038.2620 - val_ca2-[6,11]: 59774.9492 - val_ca2-[12,17]: 103154.1094 - val_ca2-[18,23]: 74028.3359 - val_ca3-[0,5]: 1078.9532 - val_ca3-[6,11]: 60456.6016 - val_ca3-[12,17]: 104129.5625 - val_ca3-[18,23]: 74790.4453 - val_ca4-[0,5]: 1042.5659 - val_ca4-[6,11]: 59852.2461 - val_ca4-[12,17]: 103264.8516 - val_ca4-[18,23]: 74114.7891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 64102.4297 - ca1-[0,5]: 1028.5108 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66726.8168 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116907.9172 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76650.8380 - val_ca1-[0,5]: 1174.1733 - val_ca1-[6,11]: 61768.7070 - val_ca1-[12,17]: 105999.5078 - val_ca1-[18,23]: 75753.0156 - val_ca2-[0,5]: 1034.5996 - val_ca2-[6,11]: 59708.0273 - val_ca2-[12,17]: 103058.1797 - val_ca2-[18,23]: 73457.1953 - val_ca3-[0,5]: 1075.2202 - val_ca3-[6,11]: 60398.0859 - val_ca3-[12,17]: 104045.9453 - val_ca3-[18,23]: 74226.7500 - val_ca4-[0,5]: 1038.8221 - val_ca4-[6,11]: 59785.0977 - val_ca4-[12,17]: 103168.6562 - val_ca4-[18,23]: 73543.1875\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 64155.6836 - ca1-[0,5]: 1024.9134 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66880.9774 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 117206.7251 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76839.4233 - val_ca1-[0,5]: 1170.7993 - val_ca1-[6,11]: 61726.8242 - val_ca1-[12,17]: 105939.9766 - val_ca1-[18,23]: 75047.1484 - val_ca2-[0,5]: 1030.9984 - val_ca2-[6,11]: 59641.1211 - val_ca2-[12,17]: 102962.2500 - val_ca2-[18,23]: 72733.7422 - val_ca3-[0,5]: 1071.5449 - val_ca3-[6,11]: 60339.7812 - val_ca3-[12,17]: 103962.5859 - val_ca3-[18,23]: 73509.4141 - val_ca4-[0,5]: 1035.1459 - val_ca4-[6,11]: 59718.0742 - val_ca4-[12,17]: 103072.5859 - val_ca4-[18,23]: 72819.2266\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 64121.4844 - ca1-[0,5]: 1027.7330 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66998.5595 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 118137.9861 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76735.6172 - val_ca1-[0,5]: 1167.4233 - val_ca1-[6,11]: 61684.6523 - val_ca1-[12,17]: 105880.0000 - val_ca1-[18,23]: 75510.6172 - val_ca2-[0,5]: 1027.4678 - val_ca2-[6,11]: 59574.3984 - val_ca2-[12,17]: 102866.5703 - val_ca2-[18,23]: 73152.6641 - val_ca3-[0,5]: 1067.9058 - val_ca3-[6,11]: 60281.3398 - val_ca3-[12,17]: 103879.0391 - val_ca3-[18,23]: 73943.3906 - val_ca4-[0,5]: 1031.5361 - val_ca4-[6,11]: 59651.1797 - val_ca4-[12,17]: 102976.6797 - val_ca4-[18,23]: 73238.5781\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 63950.2031 - ca1-[0,5]: 1023.9001 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66906.6751 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 117080.5003 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76995.3411 - val_ca1-[0,5]: 1164.1019 - val_ca1-[6,11]: 61642.8789 - val_ca1-[12,17]: 105820.6172 - val_ca1-[18,23]: 75431.2969 - val_ca2-[0,5]: 1023.9986 - val_ca2-[6,11]: 59507.7070 - val_ca2-[12,17]: 102770.8906 - val_ca2-[18,23]: 73051.0312 - val_ca3-[0,5]: 1064.3170 - val_ca3-[6,11]: 60222.9844 - val_ca3-[12,17]: 103795.5859 - val_ca3-[18,23]: 73849.2344 - val_ca4-[0,5]: 1027.9916 - val_ca4-[6,11]: 59584.3672 - val_ca4-[12,17]: 102880.8594 - val_ca4-[18,23]: 73136.6250\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 63894.7852 - ca1-[0,5]: 1012.2187 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 67067.1055 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116963.8307 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76747.5544 - val_ca1-[0,5]: 1160.8197 - val_ca1-[6,11]: 61601.3242 - val_ca1-[12,17]: 105761.5156 - val_ca1-[18,23]: 75594.8984 - val_ca2-[0,5]: 1020.5905 - val_ca2-[6,11]: 59441.0312 - val_ca2-[12,17]: 102675.2266 - val_ca2-[18,23]: 73191.3516 - val_ca3-[0,5]: 1060.7899 - val_ca3-[6,11]: 60164.9258 - val_ca3-[12,17]: 103712.5234 - val_ca3-[18,23]: 73997.5703 - val_ca4-[0,5]: 1024.5105 - val_ca4-[6,11]: 59517.6133 - val_ca4-[12,17]: 102785.1094 - val_ca4-[18,23]: 73276.6875\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 63990.2031 - ca1-[0,5]: 1017.3754 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66647.6726 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 118028.9453 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76059.8345 - val_ca1-[0,5]: 1157.5613 - val_ca1-[6,11]: 61559.8164 - val_ca1-[12,17]: 105702.4766 - val_ca1-[18,23]: 75589.7500 - val_ca2-[0,5]: 1017.2504 - val_ca2-[6,11]: 59374.5078 - val_ca2-[12,17]: 102579.7422 - val_ca2-[18,23]: 73153.5312 - val_ca3-[0,5]: 1057.3015 - val_ca3-[6,11]: 60106.7539 - val_ca3-[12,17]: 103629.2812 - val_ca3-[18,23]: 73970.7109 - val_ca4-[0,5]: 1021.0925 - val_ca4-[6,11]: 59450.9180 - val_ca4-[12,17]: 102689.4141 - val_ca4-[18,23]: 73238.8516\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 63856.3398 - ca1-[0,5]: 1000.1953 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66272.2221 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 117104.4190 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76786.9407 - val_ca1-[0,5]: 1154.3395 - val_ca1-[6,11]: 61518.4844 - val_ca1-[12,17]: 105643.6562 - val_ca1-[18,23]: 76022.6719 - val_ca2-[0,5]: 1013.9802 - val_ca2-[6,11]: 59308.1797 - val_ca2-[12,17]: 102484.4922 - val_ca2-[18,23]: 73550.9688 - val_ca3-[0,5]: 1053.8589 - val_ca3-[6,11]: 60048.5977 - val_ca3-[12,17]: 103546.0391 - val_ca3-[18,23]: 74379.8594 - val_ca4-[0,5]: 1017.7413 - val_ca4-[6,11]: 59384.3633 - val_ca4-[12,17]: 102593.8750 - val_ca4-[18,23]: 73636.2969\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 63833.9023 - ca1-[0,5]: 1028.5006 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66430.3074 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116717.4181 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76480.6713 - val_ca1-[0,5]: 1151.1726 - val_ca1-[6,11]: 61477.6055 - val_ca1-[12,17]: 105585.4922 - val_ca1-[18,23]: 76063.3047 - val_ca2-[0,5]: 1010.7747 - val_ca2-[6,11]: 59241.9414 - val_ca2-[12,17]: 102389.3672 - val_ca2-[18,23]: 73558.2109 - val_ca3-[0,5]: 1050.4691 - val_ca3-[6,11]: 59990.5859 - val_ca3-[12,17]: 103462.9922 - val_ca3-[18,23]: 74398.0312 - val_ca4-[0,5]: 1014.4530 - val_ca4-[6,11]: 59317.8359 - val_ca4-[12,17]: 102498.3594 - val_ca4-[18,23]: 73643.3984\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 63783.7148 - ca1-[0,5]: 993.7210 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66409.8319 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 117318.9815 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76831.4907 - val_ca1-[0,5]: 1148.0353 - val_ca1-[6,11]: 61436.8320 - val_ca1-[12,17]: 105527.4844 - val_ca1-[18,23]: 75733.0078 - val_ca2-[0,5]: 1007.6263 - val_ca2-[6,11]: 59175.6484 - val_ca2-[12,17]: 102294.1094 - val_ca2-[18,23]: 73209.5859 - val_ca3-[0,5]: 1047.1289 - val_ca3-[6,11]: 59932.6523 - val_ca3-[12,17]: 103380.0391 - val_ca3-[18,23]: 74055.3203 - val_ca4-[0,5]: 1011.2181 - val_ca4-[6,11]: 59251.1758 - val_ca4-[12,17]: 102402.6328 - val_ca4-[18,23]: 73294.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 63602.8047 - ca1-[0,5]: 1003.9254 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 65894.5692 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 117739.2928 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76246.3061 - val_ca1-[0,5]: 1144.9160 - val_ca1-[6,11]: 61396.0273 - val_ca1-[12,17]: 105469.3828 - val_ca1-[18,23]: 75426.2500 - val_ca2-[0,5]: 1004.5417 - val_ca2-[6,11]: 59109.4102 - val_ca2-[12,17]: 102198.9453 - val_ca2-[18,23]: 72876.0469 - val_ca3-[0,5]: 1043.8387 - val_ca3-[6,11]: 59874.8242 - val_ca3-[12,17]: 103297.2031 - val_ca3-[18,23]: 73730.6406 - val_ca4-[0,5]: 1008.0546 - val_ca4-[6,11]: 59184.7383 - val_ca4-[12,17]: 102307.1875 - val_ca4-[18,23]: 72960.1875\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 63645.8711 - ca1-[0,5]: 998.2303 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66556.7185 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116790.5344 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76730.8090 - val_ca1-[0,5]: 1141.8300 - val_ca1-[6,11]: 61355.3750 - val_ca1-[12,17]: 105411.5234 - val_ca1-[18,23]: 75477.5859 - val_ca2-[0,5]: 1001.5228 - val_ca2-[6,11]: 59043.3047 - val_ca2-[12,17]: 102103.9062 - val_ca2-[18,23]: 72898.9297 - val_ca3-[0,5]: 1040.5912 - val_ca3-[6,11]: 59816.9570 - val_ca3-[12,17]: 103214.3047 - val_ca3-[18,23]: 73762.7656 - val_ca4-[0,5]: 1004.9687 - val_ca4-[6,11]: 59118.6641 - val_ca4-[12,17]: 102212.2266 - val_ca4-[18,23]: 72983.1172\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 63644.3828 - ca1-[0,5]: 983.1820 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 65749.6648 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 117377.8631 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76231.7257 - val_ca1-[0,5]: 1138.7865 - val_ca1-[6,11]: 61315.0195 - val_ca1-[12,17]: 105354.0625 - val_ca1-[18,23]: 75539.1406 - val_ca2-[0,5]: 998.5614 - val_ca2-[6,11]: 58977.1133 - val_ca2-[12,17]: 102008.7344 - val_ca2-[18,23]: 72924.3750 - val_ca3-[0,5]: 1037.3917 - val_ca3-[6,11]: 59759.1562 - val_ca3-[12,17]: 103131.4531 - val_ca3-[18,23]: 73800.0469 - val_ca4-[0,5]: 1001.9432 - val_ca4-[6,11]: 59052.5859 - val_ca4-[12,17]: 102117.2500 - val_ca4-[18,23]: 73008.9375\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 63518.2109 - ca1-[0,5]: 979.5950 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 65889.9790 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116716.6270 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 75518.4427 - val_ca1-[0,5]: 1135.8046 - val_ca1-[6,11]: 61275.2109 - val_ca1-[12,17]: 105297.3828 - val_ca1-[18,23]: 75278.7188 - val_ca2-[0,5]: 995.6682 - val_ca2-[6,11]: 58911.1133 - val_ca2-[12,17]: 101913.8047 - val_ca2-[18,23]: 72636.3828 - val_ca3-[0,5]: 1034.2368 - val_ca3-[6,11]: 59701.3242 - val_ca3-[12,17]: 103048.5859 - val_ca3-[18,23]: 73520.6406 - val_ca4-[0,5]: 998.9826 - val_ca4-[6,11]: 58986.6289 - val_ca4-[12,17]: 102022.4062 - val_ca4-[18,23]: 72720.9297\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 63462.6016 - ca1-[0,5]: 986.9364 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66043.8786 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116312.2804 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 75761.0466 - val_ca1-[0,5]: 1132.8142 - val_ca1-[6,11]: 61235.0234 - val_ca1-[12,17]: 105240.1406 - val_ca1-[18,23]: 75325.3984 - val_ca2-[0,5]: 992.8415 - val_ca2-[6,11]: 58845.2383 - val_ca2-[12,17]: 101819.0391 - val_ca2-[18,23]: 72651.0234 - val_ca3-[0,5]: 1031.1382 - val_ca3-[6,11]: 59643.7422 - val_ca3-[12,17]: 102966.0156 - val_ca3-[18,23]: 73545.6797 - val_ca4-[0,5]: 996.0761 - val_ca4-[6,11]: 58920.5039 - val_ca4-[12,17]: 101927.2969 - val_ca4-[18,23]: 72735.3906\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 3s 124ms/step - loss: 63715.6406 - ca1-[0,5]: 987.7981 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66177.4897 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116569.9164 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76282.4248 - val_ca1-[0,5]: 1129.8485 - val_ca1-[6,11]: 61194.8945 - val_ca1-[12,17]: 105182.9688 - val_ca1-[18,23]: 75083.4375 - val_ca2-[0,5]: 990.0751 - val_ca2-[6,11]: 58779.3711 - val_ca2-[12,17]: 101724.2422 - val_ca2-[18,23]: 72388.7188 - val_ca3-[0,5]: 1028.0815 - val_ca3-[6,11]: 59586.0742 - val_ca3-[12,17]: 102883.3203 - val_ca3-[18,23]: 73289.7344 - val_ca4-[0,5]: 993.2322 - val_ca4-[6,11]: 58854.4297 - val_ca4-[12,17]: 101832.2500 - val_ca4-[18,23]: 72472.6016\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 63194.5156 - ca1-[0,5]: 991.7283 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 66169.0362 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 117302.6684 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 75289.6435 - val_ca1-[0,5]: 1126.9120 - val_ca1-[6,11]: 61154.8867 - val_ca1-[12,17]: 105125.9609 - val_ca1-[18,23]: 75569.7031 - val_ca2-[0,5]: 987.3653 - val_ca2-[6,11]: 58713.3789 - val_ca2-[12,17]: 101629.2500 - val_ca2-[18,23]: 72833.3594 - val_ca3-[0,5]: 1025.0770 - val_ca3-[6,11]: 59528.5586 - val_ca3-[12,17]: 102800.8203 - val_ca3-[18,23]: 73748.1172 - val_ca4-[0,5]: 990.4510 - val_ca4-[6,11]: 58788.4023 - val_ca4-[12,17]: 101737.2422 - val_ca4-[18,23]: 72917.5938\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 63389.9727 - ca1-[0,5]: 962.6549 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 65560.5674 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116782.2856 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 75610.4172 - val_ca1-[0,5]: 1124.0068 - val_ca1-[6,11]: 61115.0312 - val_ca1-[12,17]: 105069.1719 - val_ca1-[18,23]: 75551.0469 - val_ca2-[0,5]: 984.7332 - val_ca2-[6,11]: 58647.8203 - val_ca2-[12,17]: 101534.8203 - val_ca2-[18,23]: 72789.3828 - val_ca3-[0,5]: 1022.1152 - val_ca3-[6,11]: 59471.0078 - val_ca3-[12,17]: 102718.2422 - val_ca3-[18,23]: 73711.9609 - val_ca4-[0,5]: 987.7492 - val_ca4-[6,11]: 58722.8164 - val_ca4-[12,17]: 101642.8281 - val_ca4-[18,23]: 72873.4844\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 63384.4922 - ca1-[0,5]: 969.4491 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 65770.3712 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116076.9439 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 76159.6820 - val_ca1-[0,5]: 1121.1284 - val_ca1-[6,11]: 61075.2656 - val_ca1-[12,17]: 105012.5156 - val_ca1-[18,23]: 75300.2734 - val_ca2-[0,5]: 982.1623 - val_ca2-[6,11]: 58582.2852 - val_ca2-[12,17]: 101440.4219 - val_ca2-[18,23]: 72516.1016 - val_ca3-[0,5]: 1019.1993 - val_ca3-[6,11]: 59413.4648 - val_ca3-[12,17]: 102635.6641 - val_ca3-[18,23]: 73445.5156 - val_ca4-[0,5]: 985.0984 - val_ca4-[6,11]: 58657.0156 - val_ca4-[12,17]: 101548.0781 - val_ca4-[18,23]: 72599.7109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 63197.0859 - ca1-[0,5]: 987.1020 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 65321.6337 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116387.8380 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 75220.7844 - val_ca1-[0,5]: 1118.2867 - val_ca1-[6,11]: 61035.7305 - val_ca1-[12,17]: 104956.1562 - val_ca1-[18,23]: 75340.8594 - val_ca2-[0,5]: 979.6617 - val_ca2-[6,11]: 58517.0000 - val_ca2-[12,17]: 101346.3672 - val_ca2-[18,23]: 72523.1250 - val_ca3-[0,5]: 1016.3344 - val_ca3-[6,11]: 59356.0469 - val_ca3-[12,17]: 102553.2188 - val_ca3-[18,23]: 73462.9688 - val_ca4-[0,5]: 982.5041 - val_ca4-[6,11]: 58591.0898 - val_ca4-[12,17]: 101453.1328 - val_ca4-[18,23]: 72606.1719\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 3s 121ms/step - loss: 63169.9961 - ca1-[0,5]: 980.1960 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 65516.4952 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116839.3458 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 75945.6999 - val_ca1-[0,5]: 1115.4760 - val_ca1-[6,11]: 60996.3516 - val_ca1-[12,17]: 104900.0078 - val_ca1-[18,23]: 74357.3125 - val_ca2-[0,5]: 977.2224 - val_ca2-[6,11]: 58451.7344 - val_ca2-[12,17]: 101252.2969 - val_ca2-[18,23]: 71522.9922 - val_ca3-[0,5]: 1013.5208 - val_ca3-[6,11]: 59298.7617 - val_ca3-[12,17]: 102470.9688 - val_ca3-[18,23]: 72467.6172 - val_ca4-[0,5]: 979.9756 - val_ca4-[6,11]: 58525.2812 - val_ca4-[12,17]: 101358.3047 - val_ca4-[18,23]: 71605.0547\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 63202.6016 - ca1-[0,5]: 982.0915 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 65120.2244 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 115853.3192 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 75500.7161 - val_ca1-[0,5]: 1112.7115 - val_ca1-[6,11]: 60957.3516 - val_ca1-[12,17]: 104844.3906 - val_ca1-[18,23]: 74330.3047 - val_ca2-[0,5]: 974.8447 - val_ca2-[6,11]: 58386.5156 - val_ca2-[12,17]: 101158.2734 - val_ca2-[18,23]: 71471.4297 - val_ca3-[0,5]: 1010.7501 - val_ca3-[6,11]: 59241.4219 - val_ca3-[12,17]: 102388.6172 - val_ca3-[18,23]: 72423.3125 - val_ca4-[0,5]: 977.5206 - val_ca4-[6,11]: 58459.8047 - val_ca4-[12,17]: 101263.9375 - val_ca4-[18,23]: 71553.0938\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 62923.5586 - ca1-[0,5]: 973.9744 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 65835.0369 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116284.0694 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 75349.9742 - val_ca1-[0,5]: 1109.9570 - val_ca1-[6,11]: 60918.2148 - val_ca1-[12,17]: 104788.5781 - val_ca1-[18,23]: 74968.5703 - val_ca2-[0,5]: 972.5289 - val_ca2-[6,11]: 58321.3125 - val_ca2-[12,17]: 101064.2578 - val_ca2-[18,23]: 72067.1250 - val_ca3-[0,5]: 1008.0237 - val_ca3-[6,11]: 59184.0781 - val_ca3-[12,17]: 102306.2500 - val_ca3-[18,23]: 73032.3203 - val_ca4-[0,5]: 975.1310 - val_ca4-[6,11]: 58394.4531 - val_ca4-[12,17]: 101169.7266 - val_ca4-[18,23]: 72148.9922\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 3s 123ms/step - loss: 63196.5195 - ca1-[0,5]: 958.8063 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 65350.2729 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116531.2063 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 75643.9216 - val_ca1-[0,5]: 1107.2253 - val_ca1-[6,11]: 60879.1328 - val_ca1-[12,17]: 104732.8359 - val_ca1-[18,23]: 75625.0547 - val_ca2-[0,5]: 970.2727 - val_ca2-[6,11]: 58256.0898 - val_ca2-[12,17]: 100970.1797 - val_ca2-[18,23]: 72680.0078 - val_ca3-[0,5]: 1005.3488 - val_ca3-[6,11]: 59126.8750 - val_ca3-[12,17]: 102224.0312 - val_ca3-[18,23]: 73659.0312 - val_ca4-[0,5]: 972.8037 - val_ca4-[6,11]: 58329.1406 - val_ca4-[12,17]: 101075.5391 - val_ca4-[18,23]: 72762.2031\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 62764.0273 - ca1-[0,5]: 966.3714 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 65391.3006 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116285.1019 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 75481.5616 - val_ca1-[0,5]: 1104.5461 - val_ca1-[6,11]: 60840.5078 - val_ca1-[12,17]: 104677.7500 - val_ca1-[18,23]: 75213.2812 - val_ca2-[0,5]: 968.0801 - val_ca2-[6,11]: 58190.9492 - val_ca2-[12,17]: 100876.1562 - val_ca2-[18,23]: 72246.4766 - val_ca3-[0,5]: 1002.7219 - val_ca3-[6,11]: 59069.7070 - val_ca3-[12,17]: 102141.8750 - val_ca3-[18,23]: 73231.8047 - val_ca4-[0,5]: 970.5330 - val_ca4-[6,11]: 58263.7148 - val_ca4-[12,17]: 100981.1562 - val_ca4-[18,23]: 72328.1172\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 3s 119ms/step - loss: 62871.0352 - ca1-[0,5]: 974.5200 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 64994.0288 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 115296.1777 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 75207.2242 - val_ca1-[0,5]: 1101.8685 - val_ca1-[6,11]: 60801.6523 - val_ca1-[12,17]: 104622.2969 - val_ca1-[18,23]: 74408.9844 - val_ca2-[0,5]: 965.9559 - val_ca2-[6,11]: 58126.0352 - val_ca2-[12,17]: 100782.4531 - val_ca2-[18,23]: 71428.9141 - val_ca3-[0,5]: 1000.1481 - val_ca3-[6,11]: 59012.7422 - val_ca3-[12,17]: 102059.9766 - val_ca3-[18,23]: 72417.8281 - val_ca4-[0,5]: 968.3309 - val_ca4-[6,11]: 58198.4961 - val_ca4-[12,17]: 100887.0547 - val_ca4-[18,23]: 71509.7812\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 3s 122ms/step - loss: 63079.2266 - ca1-[0,5]: 950.4250 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 65253.5208 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 116491.0680 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 74835.7595 - val_ca1-[0,5]: 1099.2375 - val_ca1-[6,11]: 60763.1836 - val_ca1-[12,17]: 104567.3984 - val_ca1-[18,23]: 74614.9062 - val_ca2-[0,5]: 963.8904 - val_ca2-[6,11]: 58061.0586 - val_ca2-[12,17]: 100688.6484 - val_ca2-[18,23]: 71599.0938 - val_ca3-[0,5]: 997.6218 - val_ca3-[6,11]: 58955.8398 - val_ca3-[12,17]: 101978.1328 - val_ca3-[18,23]: 72599.1016 - val_ca4-[0,5]: 966.1922 - val_ca4-[6,11]: 58133.3438 - val_ca4-[12,17]: 100793.0234 - val_ca4-[18,23]: 71679.9375\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 62662.4844 - ca1-[0,5]: 957.6423 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 64922.6081 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 114770.6615 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 74593.5272 - val_ca1-[0,5]: 1096.6023 - val_ca1-[6,11]: 60724.3633 - val_ca1-[12,17]: 104511.9844 - val_ca1-[18,23]: 73774.2266 - val_ca2-[0,5]: 961.8857 - val_ca2-[6,11]: 57996.0742 - val_ca2-[12,17]: 100594.8125 - val_ca2-[18,23]: 70739.9688 - val_ca3-[0,5]: 995.1368 - val_ca3-[6,11]: 58898.8242 - val_ca3-[12,17]: 101896.1484 - val_ca3-[18,23]: 71745.3047 - val_ca4-[0,5]: 964.1154 - val_ca4-[6,11]: 58068.2305 - val_ca4-[12,17]: 100699.0078 - val_ca4-[18,23]: 70820.3672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "26/26 [==============================] - 3s 120ms/step - loss: 62727.8164 - ca1-[0,5]: 947.6367 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 65220.0587 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 115597.3012 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 75144.0911 - val_ca1-[0,5]: 1094.0326 - val_ca1-[6,11]: 60686.2422 - val_ca1-[12,17]: 104457.5625 - val_ca1-[18,23]: 75270.3906 - val_ca2-[0,5]: 959.9480 - val_ca2-[6,11]: 57931.2930 - val_ca2-[12,17]: 100501.2188 - val_ca2-[18,23]: 72179.0469 - val_ca3-[0,5]: 992.7002 - val_ca3-[6,11]: 58841.9141 - val_ca3-[12,17]: 101814.2422 - val_ca3-[18,23]: 73202.3438 - val_ca4-[0,5]: 962.1066 - val_ca4-[6,11]: 58003.3398 - val_ca4-[12,17]: 100605.2812 - val_ca4-[18,23]: 72260.0625\n",
      "CPU times: user 5min 6s, sys: 2.51 s, total: 5min 9s\n",
      "Wall time: 5min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 4, sharey=True, figsize=(24, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    for k in [k for k in history if f'val_ca{n+1}' in k]:\n",
    "        ax.plot(history[k], label=k.split('-')[1])\n",
    "        \n",
    "    ax.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True,  figsize=(22, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    for k in [k for k in history if f'ca{n+1}' in k and 'val' not in k]:\n",
    "        ax.plot(history[k], label=('train '+k.split('-')[1]),linestyle=':')\n",
    "        \n",
    "    ax.legend()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('simple_add')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2}]') for ca,(q1,q2) in product(range(4),zip(range(0,25,6)[:-1],range(-1,24,6)[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 3s 116ms/step - ca1-[0,5]: 21.7418 - ca1-[6,11]: 113.6604 - ca1-[12,17]: 322.3574 - ca1-[18,23]: 659.9173 - ca2-[0,5]: 11.7400 - ca2-[6,11]: 103.9308 - ca2-[12,17]: 340.1681 - ca2-[18,23]: 631.5350 - ca3-[0,5]: 41.0419 - ca3-[6,11]: 116.3564 - ca3-[12,17]: 297.5274 - ca3-[18,23]: 504.7423 - ca4-[0,5]: 6.6454 - ca4-[6,11]: 173.8995 - ca4-[12,17]: 324.8108 - ca4-[18,23]: 568.0325 - val_ca1-[0,5]: 22.5789 - val_ca1-[6,11]: 116.4363 - val_ca1-[12,17]: 322.3521 - val_ca1-[18,23]: 602.2889 - val_ca2-[0,5]: 16.5768 - val_ca2-[6,11]: 99.3704 - val_ca2-[12,17]: 291.2619 - val_ca2-[18,23]: 557.1222 - val_ca3-[0,5]: 15.1868 - val_ca3-[6,11]: 95.5569 - val_ca3-[12,17]: 285.1296 - val_ca3-[18,23]: 549.1183 - val_ca4-[0,5]: 18.0498 - val_ca4-[6,11]: 103.3745 - val_ca4-[12,17]: 298.0153 - val_ca4-[18,23]: 566.5291\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 3s 117ms/step - ca1-[0,5]: 22.5367 - ca1-[6,11]: 114.2215 - ca1-[12,17]: 321.0421 - ca1-[18,23]: 655.5247 - ca2-[0,5]: 9.5855 - ca2-[6,11]: 91.6703 - ca2-[12,17]: 322.5316 - ca2-[18,23]: 628.2565 - ca3-[0,5]: 30.4738 - ca3-[6,11]: 105.4069 - ca3-[12,17]: 261.9767 - ca3-[18,23]: 458.0588 - ca4-[0,5]: 4.8377 - ca4-[6,11]: 153.9256 - ca4-[12,17]: 297.9909 - ca4-[18,23]: 527.9561 - val_ca1-[0,5]: 22.6764 - val_ca1-[6,11]: 116.4943 - val_ca1-[12,17]: 321.5815 - val_ca1-[18,23]: 600.7189 - val_ca2-[0,5]: 14.4124 - val_ca2-[6,11]: 92.5852 - val_ca2-[12,17]: 278.2663 - val_ca2-[18,23]: 538.1118 - val_ca3-[0,5]: 12.8389 - val_ca3-[6,11]: 88.0345 - val_ca3-[12,17]: 270.9767 - val_ca3-[18,23]: 528.5601 - val_ca4-[0,5]: 14.7688 - val_ca4-[6,11]: 93.7650 - val_ca4-[12,17]: 280.5317 - val_ca4-[18,23]: 541.4556\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 3s 116ms/step - ca1-[0,5]: 22.2286 - ca1-[6,11]: 113.3246 - ca1-[12,17]: 317.9030 - ca1-[18,23]: 655.8787 - ca2-[0,5]: 8.2605 - ca2-[6,11]: 86.5264 - ca2-[12,17]: 308.8851 - ca2-[18,23]: 594.3674 - ca3-[0,5]: 26.4213 - ca3-[6,11]: 96.4630 - ca3-[12,17]: 248.9676 - ca3-[18,23]: 453.6879 - ca4-[0,5]: 3.3442 - ca4-[6,11]: 151.1781 - ca4-[12,17]: 277.8563 - ca4-[18,23]: 506.4250 - val_ca1-[0,5]: 21.8209 - val_ca1-[6,11]: 114.0130 - val_ca1-[12,17]: 317.4267 - val_ca1-[18,23]: 595.7689 - val_ca2-[0,5]: 13.0048 - val_ca2-[6,11]: 87.4936 - val_ca2-[12,17]: 268.6229 - val_ca2-[18,23]: 524.5709 - val_ca3-[0,5]: 11.2117 - val_ca3-[6,11]: 81.9712 - val_ca3-[12,17]: 259.7413 - val_ca3-[18,23]: 512.9733 - val_ca4-[0,5]: 12.9900 - val_ca4-[6,11]: 87.8207 - val_ca4-[12,17]: 269.9273 - val_ca4-[18,23]: 527.0601\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 3s 119ms/step - ca1-[0,5]: 21.0173 - ca1-[6,11]: 111.2866 - ca1-[12,17]: 314.1623 - ca1-[18,23]: 645.6776 - ca2-[0,5]: 6.8942 - ca2-[6,11]: 83.0449 - ca2-[12,17]: 296.5961 - ca2-[18,23]: 584.9094 - ca3-[0,5]: 23.5706 - ca3-[6,11]: 90.8147 - ca3-[12,17]: 249.1772 - ca3-[18,23]: 439.4723 - ca4-[0,5]: 2.7549 - ca4-[6,11]: 133.3356 - ca4-[12,17]: 267.1022 - ca4-[18,23]: 490.8363 - val_ca1-[0,5]: 20.7312 - val_ca1-[6,11]: 111.0537 - val_ca1-[12,17]: 312.2437 - val_ca1-[18,23]: 587.5618 - val_ca2-[0,5]: 11.4987 - val_ca2-[6,11]: 82.1765 - val_ca2-[12,17]: 258.5907 - val_ca2-[18,23]: 508.8750 - val_ca3-[0,5]: 10.0277 - val_ca3-[6,11]: 77.2930 - val_ca3-[12,17]: 250.7931 - val_ca3-[18,23]: 498.9431 - val_ca4-[0,5]: 11.5255 - val_ca4-[6,11]: 82.7206 - val_ca4-[12,17]: 260.4185 - val_ca4-[18,23]: 512.1462\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 3s 123ms/step - ca1-[0,5]: 20.1896 - ca1-[6,11]: 107.9693 - ca1-[12,17]: 311.4686 - ca1-[18,23]: 638.7154 - ca2-[0,5]: 6.2498 - ca2-[6,11]: 78.3943 - ca2-[12,17]: 287.9094 - ca2-[18,23]: 561.6458 - ca3-[0,5]: 21.5242 - ca3-[6,11]: 87.6475 - ca3-[12,17]: 236.3329 - ca3-[18,23]: 429.2201 - ca4-[0,5]: 2.0195 - ca4-[6,11]: 122.3965 - ca4-[12,17]: 260.3951 - ca4-[18,23]: 473.9390 - val_ca1-[0,5]: 19.1843 - val_ca1-[6,11]: 106.8472 - val_ca1-[12,17]: 304.9612 - val_ca1-[18,23]: 577.7132 - val_ca2-[0,5]: 10.2556 - val_ca2-[6,11]: 77.5142 - val_ca2-[12,17]: 249.8171 - val_ca2-[18,23]: 496.2013 - val_ca3-[0,5]: 8.9987 - val_ca3-[6,11]: 72.9439 - val_ca3-[12,17]: 242.5512 - val_ca3-[18,23]: 487.2624 - val_ca4-[0,5]: 10.4063 - val_ca4-[6,11]: 78.4602 - val_ca4-[12,17]: 252.2282 - val_ca4-[18,23]: 500.1813\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 3s 116ms/step - ca1-[0,5]: 18.5294 - ca1-[6,11]: 103.9934 - ca1-[12,17]: 300.0741 - ca1-[18,23]: 621.4878 - ca2-[0,5]: 5.2021 - ca2-[6,11]: 71.3216 - ca2-[12,17]: 278.9312 - ca2-[18,23]: 563.8415 - ca3-[0,5]: 21.3474 - ca3-[6,11]: 71.7229 - ca3-[12,17]: 222.0116 - ca3-[18,23]: 419.0044 - ca4-[0,5]: 1.3452 - ca4-[6,11]: 123.8554 - ca4-[12,17]: 244.1163 - ca4-[18,23]: 465.8993 - val_ca1-[0,5]: 17.4339 - val_ca1-[6,11]: 102.0156 - val_ca1-[12,17]: 296.6504 - val_ca1-[18,23]: 566.3204 - val_ca2-[0,5]: 9.2053 - val_ca2-[6,11]: 73.1865 - val_ca2-[12,17]: 241.5612 - val_ca2-[18,23]: 484.1035 - val_ca3-[0,5]: 8.1557 - val_ca3-[6,11]: 69.0285 - val_ca3-[12,17]: 235.0782 - val_ca3-[18,23]: 476.4780 - val_ca4-[0,5]: 9.4971 - val_ca4-[6,11]: 74.6803 - val_ca4-[12,17]: 244.8097 - val_ca4-[18,23]: 489.0583\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 3s 114ms/step - ca1-[0,5]: 16.5327 - ca1-[6,11]: 98.9382 - ca1-[12,17]: 291.5904 - ca1-[18,23]: 608.6770 - ca2-[0,5]: 4.7277 - ca2-[6,11]: 70.1127 - ca2-[12,17]: 267.5571 - ca2-[18,23]: 541.2986 - ca3-[0,5]: 18.0532 - ca3-[6,11]: 82.5623 - ca3-[12,17]: 208.9161 - ca3-[18,23]: 409.0363 - ca4-[0,5]: 1.0216 - ca4-[6,11]: 115.3438 - ca4-[12,17]: 245.1358 - ca4-[18,23]: 446.6303 - val_ca1-[0,5]: 15.6903 - val_ca1-[6,11]: 96.9890 - val_ca1-[12,17]: 287.8747 - val_ca1-[18,23]: 554.0460 - val_ca2-[0,5]: 8.2748 - val_ca2-[6,11]: 68.9968 - val_ca2-[12,17]: 233.5832 - val_ca2-[18,23]: 472.3029 - val_ca3-[0,5]: 7.5208 - val_ca3-[6,11]: 65.7077 - val_ca3-[12,17]: 228.5511 - val_ca3-[18,23]: 466.7001 - val_ca4-[0,5]: 8.7073 - val_ca4-[6,11]: 71.1022 - val_ca4-[12,17]: 237.6693 - val_ca4-[18,23]: 478.0634\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 3s 115ms/step - ca1-[0,5]: 14.7786 - ca1-[6,11]: 93.5385 - ca1-[12,17]: 282.1860 - ca1-[18,23]: 598.5134 - ca2-[0,5]: 4.0728 - ca2-[6,11]: 64.5937 - ca2-[12,17]: 257.8060 - ca2-[18,23]: 529.7860 - ca3-[0,5]: 16.7310 - ca3-[6,11]: 79.1392 - ca3-[12,17]: 220.0358 - ca3-[18,23]: 398.7265 - ca4-[0,5]: 0.6757 - ca4-[6,11]: 115.4222 - ca4-[12,17]: 233.5093 - ca4-[18,23]: 445.2222 - val_ca1-[0,5]: 14.0343 - val_ca1-[6,11]: 91.9546 - val_ca1-[12,17]: 278.9674 - val_ca1-[18,23]: 541.5728 - val_ca2-[0,5]: 7.4816 - val_ca2-[6,11]: 65.0215 - val_ca2-[12,17]: 226.0099 - val_ca2-[18,23]: 461.3532 - val_ca3-[0,5]: 7.0338 - val_ca3-[6,11]: 62.8265 - val_ca3-[12,17]: 222.7014 - val_ca3-[18,23]: 457.9546 - val_ca4-[0,5]: 8.0402 - val_ca4-[6,11]: 67.7909 - val_ca4-[12,17]: 230.9368 - val_ca4-[18,23]: 467.9021\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 3s 114ms/step - ca1-[0,5]: 13.1649 - ca1-[6,11]: 89.3329 - ca1-[12,17]: 276.4445 - ca1-[18,23]: 581.7804 - ca2-[0,5]: 3.7442 - ca2-[6,11]: 60.7897 - ca2-[12,17]: 247.4674 - ca2-[18,23]: 508.5494 - ca3-[0,5]: 15.5357 - ca3-[6,11]: 76.0260 - ca3-[12,17]: 214.5749 - ca3-[18,23]: 377.4758 - ca4-[0,5]: 0.4142 - ca4-[6,11]: 111.5650 - ca4-[12,17]: 220.6599 - ca4-[18,23]: 434.0599 - val_ca1-[0,5]: 12.6258 - val_ca1-[6,11]: 87.4508 - val_ca1-[12,17]: 270.9717 - val_ca1-[18,23]: 530.3205 - val_ca2-[0,5]: 6.8466 - val_ca2-[6,11]: 61.3234 - val_ca2-[12,17]: 218.8032 - val_ca2-[18,23]: 450.8446 - val_ca3-[0,5]: 6.6276 - val_ca3-[6,11]: 60.1249 - val_ca3-[12,17]: 217.1373 - val_ca3-[18,23]: 449.5989 - val_ca4-[0,5]: 7.4626 - val_ca4-[6,11]: 64.6551 - val_ca4-[12,17]: 224.5071 - val_ca4-[18,23]: 458.1807\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 3s 115ms/step - ca1-[0,5]: 11.8926 - ca1-[6,11]: 85.0324 - ca1-[12,17]: 266.8346 - ca1-[18,23]: 574.5537 - ca2-[0,5]: 3.7725 - ca2-[6,11]: 55.9052 - ca2-[12,17]: 241.5682 - ca2-[18,23]: 496.8384 - ca3-[0,5]: 14.9437 - ca3-[6,11]: 71.0848 - ca3-[12,17]: 206.3787 - ca3-[18,23]: 383.3698 - ca4-[0,5]: 0.2228 - ca4-[6,11]: 100.6221 - ca4-[12,17]: 220.1210 - ca4-[18,23]: 421.9913 - val_ca1-[0,5]: 11.4487 - val_ca1-[6,11]: 83.4220 - val_ca1-[12,17]: 263.6964 - val_ca1-[18,23]: 519.9738 - val_ca2-[0,5]: 6.3381 - val_ca2-[6,11]: 57.7672 - val_ca2-[12,17]: 211.8043 - val_ca2-[18,23]: 440.6573 - val_ca3-[0,5]: 6.2876 - val_ca3-[6,11]: 57.5355 - val_ca3-[12,17]: 211.7432 - val_ca3-[18,23]: 441.4801 - val_ca4-[0,5]: 6.9509 - val_ca4-[6,11]: 61.5786 - val_ca4-[12,17]: 218.1874 - val_ca4-[18,23]: 448.6599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000\n",
      "26/26 [==============================] - 3s 115ms/step - ca1-[0,5]: 10.6413 - ca1-[6,11]: 80.8166 - ca1-[12,17]: 260.8289 - ca1-[18,23]: 565.9561 - ca2-[0,5]: 3.8951 - ca2-[6,11]: 52.8304 - ca2-[12,17]: 234.6977 - ca2-[18,23]: 497.4328 - ca3-[0,5]: 13.1949 - ca3-[6,11]: 66.8903 - ca3-[12,17]: 197.9624 - ca3-[18,23]: 376.4304 - ca4-[0,5]: 0.0923 - ca4-[6,11]: 101.7949 - ca4-[12,17]: 211.1116 - ca4-[18,23]: 415.3393 - val_ca1-[0,5]: 10.4225 - val_ca1-[6,11]: 79.6398 - val_ca1-[12,17]: 256.7578 - val_ca1-[18,23]: 510.0474 - val_ca2-[0,5]: 5.9694 - val_ca2-[6,11]: 54.4636 - val_ca2-[12,17]: 205.1942 - val_ca2-[18,23]: 430.9662 - val_ca3-[0,5]: 6.0051 - val_ca3-[6,11]: 55.0019 - val_ca3-[12,17]: 206.4495 - val_ca3-[18,23]: 433.5165 - val_ca4-[0,5]: 6.5052 - val_ca4-[6,11]: 58.5083 - val_ca4-[12,17]: 211.8682 - val_ca4-[18,23]: 439.2062\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 3s 120ms/step - ca1-[0,5]: 9.6970 - ca1-[6,11]: 77.2524 - ca1-[12,17]: 255.2908 - ca1-[18,23]: 552.7188 - ca2-[0,5]: 3.8211 - ca2-[6,11]: 50.6222 - ca2-[12,17]: 229.8503 - ca2-[18,23]: 475.7556 - ca3-[0,5]: 12.0570 - ca3-[6,11]: 62.6210 - ca3-[12,17]: 192.2474 - ca3-[18,23]: 366.3983 - ca4-[0,5]: 0.0182 - ca4-[6,11]: 99.3151 - ca4-[12,17]: 206.0690 - ca4-[18,23]: 413.7971 - val_ca1-[0,5]: 9.5229 - val_ca1-[6,11]: 76.0495 - val_ca1-[12,17]: 250.0770 - val_ca1-[18,23]: 501.6488 - val_ca2-[0,5]: 5.7300 - val_ca2-[6,11]: 51.4083 - val_ca2-[12,17]: 198.9531 - val_ca2-[18,23]: 422.9220 - val_ca3-[0,5]: 5.7818 - val_ca3-[6,11]: 52.4707 - val_ca3-[12,17]: 201.1781 - val_ca3-[18,23]: 426.7528 - val_ca4-[0,5]: 6.1149 - val_ca4-[6,11]: 55.2746 - val_ca4-[12,17]: 205.2914 - val_ca4-[18,23]: 430.8147\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 3s 122ms/step - ca1-[0,5]: 8.7002 - ca1-[6,11]: 74.1716 - ca1-[12,17]: 243.8409 - ca1-[18,23]: 547.3408 - ca2-[0,5]: 4.1441 - ca2-[6,11]: 47.5293 - ca2-[12,17]: 225.7688 - ca2-[18,23]: 475.4556 - ca3-[0,5]: 10.8925 - ca3-[6,11]: 63.5456 - ca3-[12,17]: 179.5932 - ca3-[18,23]: 355.0277 - ca4-[0,5]: 0.0018 - ca4-[6,11]: 93.4294 - ca4-[12,17]: 197.2870 - ca4-[18,23]: 401.3939 - val_ca1-[0,5]: 8.7307 - val_ca1-[6,11]: 72.6057 - val_ca1-[12,17]: 243.6002 - val_ca1-[18,23]: 491.1036 - val_ca2-[0,5]: 5.6048 - val_ca2-[6,11]: 48.4978 - val_ca2-[12,17]: 192.9282 - val_ca2-[18,23]: 412.8200 - val_ca3-[0,5]: 5.6242 - val_ca3-[6,11]: 49.8958 - val_ca3-[12,17]: 195.7934 - val_ca3-[18,23]: 417.5245 - val_ca4-[0,5]: 5.8163 - val_ca4-[6,11]: 51.9726 - val_ca4-[12,17]: 198.7405 - val_ca4-[18,23]: 420.1684\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 3s 119ms/step - ca1-[0,5]: 8.0328 - ca1-[6,11]: 70.1020 - ca1-[12,17]: 238.1889 - ca1-[18,23]: 534.9136 - ca2-[0,5]: 4.1937 - ca2-[6,11]: 44.1970 - ca2-[12,17]: 211.9680 - ca2-[18,23]: 455.0100 - ca3-[0,5]: 10.5166 - ca3-[6,11]: 56.7288 - ca3-[12,17]: 181.2804 - ca3-[18,23]: 349.7464 - ca4-[0,5]: 0.0445 - ca4-[6,11]: 83.2137 - ca4-[12,17]: 196.1549 - ca4-[18,23]: 375.7647 - val_ca1-[0,5]: 8.0420 - val_ca1-[6,11]: 69.2981 - val_ca1-[12,17]: 237.3095 - val_ca1-[18,23]: 481.9849 - val_ca2-[0,5]: 5.5995 - val_ca2-[6,11]: 45.6268 - val_ca2-[12,17]: 186.9613 - val_ca2-[18,23]: 404.0277 - val_ca3-[0,5]: 5.5447 - val_ca3-[6,11]: 47.2831 - val_ca3-[12,17]: 190.1387 - val_ca3-[18,23]: 408.8893 - val_ca4-[0,5]: 5.6548 - val_ca4-[6,11]: 48.4827 - val_ca4-[12,17]: 191.9832 - val_ca4-[18,23]: 410.5914\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 3s 116ms/step - ca1-[0,5]: 7.7505 - ca1-[6,11]: 67.8170 - ca1-[12,17]: 232.3141 - ca1-[18,23]: 525.4005 - ca2-[0,5]: 4.6490 - ca2-[6,11]: 42.3911 - ca2-[12,17]: 211.3119 - ca2-[18,23]: 455.9421 - ca3-[0,5]: 8.0952 - ca3-[6,11]: 57.3419 - ca3-[12,17]: 176.2903 - ca3-[18,23]: 344.2496 - ca4-[0,5]: 0.1507 - ca4-[6,11]: 87.3798 - ca4-[12,17]: 187.7204 - ca4-[18,23]: 378.7896 - val_ca1-[0,5]: 7.4281 - val_ca1-[6,11]: 65.9737 - val_ca1-[12,17]: 230.9049 - val_ca1-[18,23]: 470.9883 - val_ca2-[0,5]: 5.7367 - val_ca2-[6,11]: 42.7550 - val_ca2-[12,17]: 180.9416 - val_ca2-[18,23]: 393.9724 - val_ca3-[0,5]: 5.5563 - val_ca3-[6,11]: 44.5017 - val_ca3-[12,17]: 183.8259 - val_ca3-[18,23]: 397.7955 - val_ca4-[0,5]: 5.7101 - val_ca4-[6,11]: 44.9345 - val_ca4-[12,17]: 185.1378 - val_ca4-[18,23]: 399.7913\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - ETA: 0s - ca1-[0,5]: 6.9679 - ca1-[6,11]: 63.8673 - ca1-[12,17]: 230.9457 - ca1-[18,23]: 518.8080 - ca2-[0,5]: 5.1759 - ca2-[6,11]: 37.9629 - ca2-[12,17]: 201.4243 - ca2-[18,23]: 433.1642 - ca3-[0,5]: 7.8793 - ca3-[6,11]: 51.6556 - ca3-[12,17]: 174.4056 - ca3-[18,23]: 333.8509 - ca4-[0,5]: 0.3081 - ca4-[6,11]: 85.0760 - ca4-[12,17]: 185.9425 - ca4-[18,23]: 374.2015"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1215\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1216\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m   1328\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;34m\"\"\"Runs an evaluation execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1322\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1284\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1285\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1286\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2847\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2849\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3632\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `test_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-379-8ce8c477b334>\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_user_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msource_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_user_metrics\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/utils/metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# update_op will be None in eager execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/keras/metrics.py\u001b[0m in \u001b[0;36mupdate_state_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mcontrol_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mag_update_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_update_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mag_update_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/tmpnwg66rg0.py\u001b[0m in \u001b[0;36mtf__update_state\u001b[0;34m(self, y_true, y_pred, source_array, sample_weight)\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0msource_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcar_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mbl_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater_equal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater_equal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbl_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbl_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mboolean_mask_v2\u001b[0;34m(tensor, mask, axis, name)\u001b[0m\n\u001b[1;32m   1921\u001b[0m   \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m   \"\"\"\n\u001b[0;32m-> 1923\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mboolean_mask\u001b[0;34m(tensor, mask, name, axis)\u001b[0m\n\u001b[1;32m   1848\u001b[0m         concat([\n\u001b[1;32m   1849\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleading_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m             \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mndims_mask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m         ], 0))\n\u001b[1;32m   1852\u001b[0m     \u001b[0;31m# TODO(yongtang): tf.reshape in C++ kernel might have set the shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0mvar_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m       \u001b[0mpacked_begin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpacked_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpacked_strides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m     return strided_slice(\n\u001b[0m\u001b[1;32m   1042\u001b[0m         \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0mpacked_begin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=1000,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 4, sharey=True, figsize=(24, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    for k in [k for k in history if f'val_ca{n+1}' in k]:\n",
    "        ax.plot(history[k], label=k.split('-')[1])\n",
    "        \n",
    "    ax.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True,  figsize=(22, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    for k in [k for k in history if f'ca{n+1}' in k and 'val' not in k]:\n",
    "        ax.plot(history[k], label=('train '+k.split('-')[1]),linestyle=':')\n",
    "        \n",
    "    ax.legend()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('djgrad')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2}]') for ca,(q1,q2) in product(range(4),zip(range(0,25,6)[:-1],range(-1,24,6)[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "26/26 [==============================] - 3s 129ms/step - ca1-[0,5]: 20.0455 - ca1-[6,11]: 111.1926 - ca1-[12,17]: 305.2244 - ca1-[18,23]: 638.0256 - ca2-[0,5]: 16.2862 - ca2-[6,11]: 118.6290 - ca2-[12,17]: 368.6289 - ca2-[18,23]: 605.2649 - ca3-[0,5]: 31.4048 - ca3-[6,11]: 120.9641 - ca3-[12,17]: 193.2314 - ca3-[18,23]: 427.9946 - ca4-[0,5]: 45.0867 - ca4-[6,11]: 82.5814 - ca4-[12,17]: 327.1979 - ca4-[18,23]: 579.8145 - val_ca1-[0,5]: 15.7862 - val_ca1-[6,11]: 105.5965 - val_ca1-[12,17]: 310.7755 - val_ca1-[18,23]: 616.6304 - val_ca2-[0,5]: 13.1781 - val_ca2-[6,11]: 97.1647 - val_ca2-[12,17]: 295.0539 - val_ca2-[18,23]: 593.9686 - val_ca3-[0,5]: 12.7304 - val_ca3-[6,11]: 95.6861 - val_ca3-[12,17]: 292.5689 - val_ca3-[18,23]: 590.6292 - val_ca4-[0,5]: 14.6536 - val_ca4-[6,11]: 101.9888 - val_ca4-[12,17]: 304.0363 - val_ca4-[18,23]: 606.8354\n",
      "Epoch 2/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 15.5654 - ca1-[6,11]: 98.7966 - ca1-[12,17]: 281.5946 - ca1-[18,23]: 605.5466 - ca2-[0,5]: 10.7527 - ca2-[6,11]: 99.3836 - ca2-[12,17]: 335.5858 - ca2-[18,23]: 547.9271 - ca3-[0,5]: 21.3343 - ca3-[6,11]: 100.5903 - ca3-[12,17]: 161.9480 - ca3-[18,23]: 384.4599 - ca4-[0,5]: 34.6455 - ca4-[6,11]: 84.0537 - ca4-[12,17]: 284.2789 - ca4-[18,23]: 532.7583 - val_ca1-[0,5]: 13.9614 - val_ca1-[6,11]: 99.8339 - val_ca1-[12,17]: 300.1156 - val_ca1-[18,23]: 601.2481 - val_ca2-[0,5]: 10.6404 - val_ca2-[6,11]: 88.0373 - val_ca2-[12,17]: 278.1553 - val_ca2-[18,23]: 569.8102 - val_ca3-[0,5]: 10.4581 - val_ca3-[6,11]: 87.3372 - val_ca3-[12,17]: 276.8891 - val_ca3-[18,23]: 568.0069 - val_ca4-[0,5]: 11.7108 - val_ca4-[6,11]: 92.0820 - val_ca4-[12,17]: 285.7693 - val_ca4-[18,23]: 580.7625\n",
      "Epoch 3/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 14.0067 - ca1-[6,11]: 93.0850 - ca1-[12,17]: 264.3775 - ca1-[18,23]: 594.2401 - ca2-[0,5]: 9.4388 - ca2-[6,11]: 89.8846 - ca2-[12,17]: 317.8126 - ca2-[18,23]: 525.7759 - ca3-[0,5]: 16.2868 - ca3-[6,11]: 92.2332 - ca3-[12,17]: 150.5198 - ca3-[18,23]: 369.0086 - ca4-[0,5]: 35.7648 - ca4-[6,11]: 74.0661 - ca4-[12,17]: 265.4110 - ca4-[18,23]: 516.6080 - val_ca1-[0,5]: 12.9004 - val_ca1-[6,11]: 96.3209 - val_ca1-[12,17]: 293.6729 - val_ca1-[18,23]: 592.0601 - val_ca2-[0,5]: 9.2349 - val_ca2-[6,11]: 82.1913 - val_ca2-[12,17]: 267.0564 - val_ca2-[18,23]: 553.8081 - val_ca3-[0,5]: 9.0925 - val_ca3-[6,11]: 81.5573 - val_ca3-[12,17]: 265.8622 - val_ca3-[18,23]: 552.0945 - val_ca4-[0,5]: 10.1111 - val_ca4-[6,11]: 85.9500 - val_ca4-[12,17]: 274.2608 - val_ca4-[18,23]: 564.2305\n",
      "Epoch 4/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 12.9618 - ca1-[6,11]: 90.8651 - ca1-[12,17]: 265.3401 - ca1-[18,23]: 586.9318 - ca2-[0,5]: 8.1684 - ca2-[6,11]: 87.2692 - ca2-[12,17]: 305.5437 - ca2-[18,23]: 523.5708 - ca3-[0,5]: 16.1952 - ca3-[6,11]: 85.8051 - ca3-[12,17]: 147.0327 - ca3-[18,23]: 371.3386 - ca4-[0,5]: 26.3616 - ca4-[6,11]: 65.6581 - ca4-[12,17]: 259.0007 - ca4-[18,23]: 499.5029 - val_ca1-[0,5]: 12.0964 - val_ca1-[6,11]: 93.5254 - val_ca1-[12,17]: 288.5036 - val_ca1-[18,23]: 584.6764 - val_ca2-[0,5]: 8.2250 - val_ca2-[6,11]: 77.3514 - val_ca2-[12,17]: 257.6704 - val_ca2-[18,23]: 540.1942 - val_ca3-[0,5]: 8.1442 - val_ca3-[6,11]: 76.9324 - val_ca3-[12,17]: 256.8565 - val_ca3-[18,23]: 539.0121 - val_ca4-[0,5]: 8.9478 - val_ca4-[6,11]: 80.8969 - val_ca4-[12,17]: 264.5912 - val_ca4-[18,23]: 550.2631\n",
      "Epoch 5/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 12.0339 - ca1-[6,11]: 87.6086 - ca1-[12,17]: 258.8325 - ca1-[18,23]: 577.5990 - ca2-[0,5]: 7.3611 - ca2-[6,11]: 83.6166 - ca2-[12,17]: 302.5937 - ca2-[18,23]: 499.6032 - ca3-[0,5]: 13.8778 - ca3-[6,11]: 80.6955 - ca3-[12,17]: 140.8308 - ca3-[18,23]: 361.2649 - ca4-[0,5]: 34.9781 - ca4-[6,11]: 67.0017 - ca4-[12,17]: 242.9223 - ca4-[18,23]: 472.5680 - val_ca1-[0,5]: 11.4322 - val_ca1-[6,11]: 91.1151 - val_ca1-[12,17]: 284.0162 - val_ca1-[18,23]: 578.2560 - val_ca2-[0,5]: 7.4698 - val_ca2-[6,11]: 73.1357 - val_ca2-[12,17]: 249.3401 - val_ca2-[18,23]: 528.0366 - val_ca3-[0,5]: 7.4753 - val_ca3-[6,11]: 73.1701 - val_ca3-[12,17]: 249.4133 - val_ca3-[18,23]: 528.1445 - val_ca4-[0,5]: 8.0391 - val_ca4-[6,11]: 76.3777 - val_ca4-[12,17]: 255.7682 - val_ca4-[18,23]: 537.4309\n",
      "Epoch 6/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 11.5959 - ca1-[6,11]: 86.2262 - ca1-[12,17]: 259.0583 - ca1-[18,23]: 568.9570 - ca2-[0,5]: 6.4126 - ca2-[6,11]: 78.8559 - ca2-[12,17]: 296.3605 - ca2-[18,23]: 487.1968 - ca3-[0,5]: 11.3771 - ca3-[6,11]: 76.5390 - ca3-[12,17]: 125.6010 - ca3-[18,23]: 350.7289 - ca4-[0,5]: 28.3154 - ca4-[6,11]: 62.9153 - ca4-[12,17]: 240.9526 - ca4-[18,23]: 465.3909 - val_ca1-[0,5]: 10.8519 - val_ca1-[6,11]: 88.9194 - val_ca1-[12,17]: 279.8987 - val_ca1-[18,23]: 573.1826 - val_ca2-[0,5]: 6.9039 - val_ca2-[6,11]: 69.3754 - val_ca2-[12,17]: 241.7788 - val_ca2-[18,23]: 517.7422 - val_ca3-[0,5]: 6.9768 - val_ca3-[6,11]: 69.9044 - val_ca3-[12,17]: 242.8553 - val_ca3-[18,23]: 519.3281 - val_ca4-[0,5]: 7.3568 - val_ca4-[6,11]: 72.4393 - val_ca4-[12,17]: 247.9539 - val_ca4-[18,23]: 526.8181\n",
      "Epoch 7/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 10.8219 - ca1-[6,11]: 82.0680 - ca1-[12,17]: 250.6899 - ca1-[18,23]: 558.4437 - ca2-[0,5]: 5.9909 - ca2-[6,11]: 75.2529 - ca2-[12,17]: 287.3021 - ca2-[18,23]: 477.8928 - ca3-[0,5]: 10.1875 - ca3-[6,11]: 69.1338 - ca3-[12,17]: 130.6737 - ca3-[18,23]: 342.5059 - ca4-[0,5]: 31.3985 - ca4-[6,11]: 58.8879 - ca4-[12,17]: 233.3491 - ca4-[18,23]: 443.3348 - val_ca1-[0,5]: 10.3304 - val_ca1-[6,11]: 86.8626 - val_ca1-[12,17]: 276.0143 - val_ca1-[18,23]: 566.7654 - val_ca2-[0,5]: 6.4870 - val_ca2-[6,11]: 65.9626 - val_ca2-[12,17]: 234.7998 - val_ca2-[18,23]: 506.6409 - val_ca3-[0,5]: 6.5971 - val_ca3-[6,11]: 66.9468 - val_ca3-[12,17]: 236.8293 - val_ca3-[18,23]: 509.6428 - val_ca4-[0,5]: 6.8407 - val_ca4-[6,11]: 68.9047 - val_ca4-[12,17]: 240.8261 - val_ca4-[18,23]: 515.5381\n",
      "Epoch 8/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 10.4553 - ca1-[6,11]: 80.6826 - ca1-[12,17]: 248.7676 - ca1-[18,23]: 557.0418 - ca2-[0,5]: 5.3662 - ca2-[6,11]: 71.7899 - ca2-[12,17]: 280.9868 - ca2-[18,23]: 469.8708 - ca3-[0,5]: 10.0393 - ca3-[6,11]: 66.9278 - ca3-[12,17]: 128.9164 - ca3-[18,23]: 337.7024 - ca4-[0,5]: 28.4864 - ca4-[6,11]: 56.0178 - ca4-[12,17]: 226.9791 - ca4-[18,23]: 449.9033 - val_ca1-[0,5]: 9.8536 - val_ca1-[6,11]: 84.9004 - val_ca1-[12,17]: 272.2838 - val_ca1-[18,23]: 561.3892 - val_ca2-[0,5]: 6.1917 - val_ca2-[6,11]: 62.8054 - val_ca2-[12,17]: 228.2352 - val_ca2-[18,23]: 496.9049 - val_ca3-[0,5]: 6.3125 - val_ca3-[6,11]: 64.2183 - val_ca3-[12,17]: 231.1895 - val_ca3-[18,23]: 501.2927 - val_ca4-[0,5]: 6.4539 - val_ca4-[6,11]: 65.6508 - val_ca4-[12,17]: 234.1582 - val_ca4-[18,23]: 505.6926\n",
      "Epoch 9/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 9.8379 - ca1-[6,11]: 80.5863 - ca1-[12,17]: 241.4855 - ca1-[18,23]: 554.7560 - ca2-[0,5]: 5.6797 - ca2-[6,11]: 65.2050 - ca2-[12,17]: 272.2146 - ca2-[18,23]: 465.8609 - ca3-[0,5]: 8.5854 - ca3-[6,11]: 66.0831 - ca3-[12,17]: 121.1314 - ca3-[18,23]: 330.3120 - ca4-[0,5]: 24.4177 - ca4-[6,11]: 48.4297 - ca4-[12,17]: 221.7909 - ca4-[18,23]: 435.5395 - val_ca1-[0,5]: 9.4149 - val_ca1-[6,11]: 83.0131 - val_ca1-[12,17]: 268.6718 - val_ca1-[18,23]: 556.1721 - val_ca2-[0,5]: 6.0015 - val_ca2-[6,11]: 59.8465 - val_ca2-[12,17]: 221.9795 - val_ca2-[18,23]: 487.5805 - val_ca3-[0,5]: 6.1085 - val_ca3-[6,11]: 61.6729 - val_ca3-[12,17]: 225.8550 - val_ca3-[18,23]: 493.3624 - val_ca4-[0,5]: 6.1770 - val_ca4-[6,11]: 62.6167 - val_ca4-[12,17]: 227.8408 - val_ca4-[18,23]: 496.3191\n",
      "Epoch 10/300\n",
      "26/26 [==============================] - 3s 129ms/step - ca1-[0,5]: 9.3352 - ca1-[6,11]: 78.0336 - ca1-[12,17]: 238.5478 - ca1-[18,23]: 546.5236 - ca2-[0,5]: 5.1127 - ca2-[6,11]: 65.0279 - ca2-[12,17]: 266.9114 - ca2-[18,23]: 453.1669 - ca3-[0,5]: 8.4285 - ca3-[6,11]: 63.5090 - ca3-[12,17]: 122.4073 - ca3-[18,23]: 322.9420 - ca4-[0,5]: 24.5278 - ca4-[6,11]: 53.5926 - ca4-[12,17]: 215.1093 - ca4-[18,23]: 431.9438 - val_ca1-[0,5]: 9.0107 - val_ca1-[6,11]: 81.1922 - val_ca1-[12,17]: 266.4070 - val_ca1-[18,23]: 551.0947 - val_ca2-[0,5]: 5.9066 - val_ca2-[6,11]: 57.0587 - val_ca2-[12,17]: 217.0899 - val_ca2-[18,23]: 478.6007 - val_ca3-[0,5]: 5.9749 - val_ca3-[6,11]: 59.2696 - val_ca3-[12,17]: 221.8678 - val_ca3-[18,23]: 485.7405 - val_ca4-[0,5]: 5.9971 - val_ca4-[6,11]: 59.7552 - val_ca4-[12,17]: 222.9078 - val_ca4-[18,23]: 487.2914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 8.9426 - ca1-[6,11]: 75.9758 - ca1-[12,17]: 237.4840 - ca1-[18,23]: 540.7293 - ca2-[0,5]: 5.0499 - ca2-[6,11]: 60.3738 - ca2-[12,17]: 256.9599 - ca2-[18,23]: 439.6260 - ca3-[0,5]: 7.4631 - ca3-[6,11]: 60.7869 - ca3-[12,17]: 105.4515 - ca3-[18,23]: 305.1403 - ca4-[0,5]: 22.2583 - ca4-[6,11]: 47.2957 - ca4-[12,17]: 206.9365 - ca4-[18,23]: 436.5586 - val_ca1-[0,5]: 8.6359 - val_ca1-[6,11]: 79.4187 - val_ca1-[12,17]: 261.7253 - val_ca1-[18,23]: 546.1057 - val_ca2-[0,5]: 5.8998 - val_ca2-[6,11]: 54.4187 - val_ca2-[12,17]: 210.2090 - val_ca2-[18,23]: 469.9058 - val_ca3-[0,5]: 5.9054 - val_ca3-[6,11]: 56.9849 - val_ca3-[12,17]: 215.8259 - val_ca3-[18,23]: 478.3621 - val_ca4-[0,5]: 5.9064 - val_ca4-[6,11]: 57.0395 - val_ca4-[12,17]: 215.9439 - val_ca4-[18,23]: 478.5396\n",
      "Epoch 12/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 8.5644 - ca1-[6,11]: 75.3257 - ca1-[12,17]: 233.6107 - ca1-[18,23]: 537.8436 - ca2-[0,5]: 5.6022 - ca2-[6,11]: 58.1578 - ca2-[12,17]: 258.9471 - ca2-[18,23]: 433.7275 - ca3-[0,5]: 6.9218 - ca3-[6,11]: 57.1779 - ca3-[12,17]: 115.6550 - ca3-[18,23]: 311.0596 - ca4-[0,5]: 21.2654 - ca4-[6,11]: 46.6155 - ca4-[12,17]: 203.8712 - ca4-[18,23]: 412.5703 - val_ca1-[0,5]: 8.2900 - val_ca1-[6,11]: 77.6944 - val_ca1-[12,17]: 258.3595 - val_ca1-[18,23]: 541.2119 - val_ca2-[0,5]: 5.9760 - val_ca2-[6,11]: 51.9054 - val_ca2-[12,17]: 204.6117 - val_ca2-[18,23]: 461.4378 - val_ca3-[0,5]: 5.8957 - val_ca3-[6,11]: 54.7907 - val_ca3-[12,17]: 211.0301 - val_ca3-[18,23]: 471.1446 - val_ca4-[0,5]: 5.8996 - val_ca4-[6,11]: 54.4440 - val_ca4-[12,17]: 210.2654 - val_ca4-[18,23]: 469.9912\n",
      "Epoch 13/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 8.1013 - ca1-[6,11]: 72.8188 - ca1-[12,17]: 227.8886 - ca1-[18,23]: 533.7114 - ca2-[0,5]: 5.7046 - ca2-[6,11]: 56.5979 - ca2-[12,17]: 247.8417 - ca2-[18,23]: 424.4143 - ca3-[0,5]: 6.1512 - ca3-[6,11]: 56.5933 - ca3-[12,17]: 110.4977 - ca3-[18,23]: 306.3141 - ca4-[0,5]: 22.5551 - ca4-[6,11]: 41.7493 - ca4-[12,17]: 199.4692 - ca4-[18,23]: 417.4042 - val_ca1-[0,5]: 7.9696 - val_ca1-[6,11]: 76.0051 - val_ca1-[12,17]: 255.0402 - val_ca1-[18,23]: 536.3755 - val_ca2-[0,5]: 6.1325 - val_ca2-[6,11]: 49.4970 - val_ca2-[12,17]: 199.1485 - val_ca2-[18,23]: 453.1310 - val_ca3-[0,5]: 5.9436 - val_ca3-[6,11]: 52.6800 - val_ca3-[12,17]: 206.3485 - val_ca3-[18,23]: 464.0700 - val_ca4-[0,5]: 5.9733 - val_ca4-[6,11]: 51.9662 - val_ca4-[12,17]: 204.7489 - val_ca4-[18,23]: 461.6459\n",
      "Epoch 14/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 7.8925 - ca1-[6,11]: 72.1074 - ca1-[12,17]: 227.0848 - ca1-[18,23]: 528.3202 - ca2-[0,5]: 5.7448 - ca2-[6,11]: 51.8849 - ca2-[12,17]: 241.4181 - ca2-[18,23]: 419.0712 - ca3-[0,5]: 5.6880 - ca3-[6,11]: 52.7787 - ca3-[12,17]: 104.7908 - ca3-[18,23]: 300.4991 - ca4-[0,5]: 13.1190 - ca4-[6,11]: 43.8357 - ca4-[12,17]: 194.3075 - ca4-[18,23]: 405.5252 - val_ca1-[0,5]: 7.6758 - val_ca1-[6,11]: 74.3598 - val_ca1-[12,17]: 251.7854 - val_ca1-[18,23]: 531.6226 - val_ca2-[0,5]: 6.3664 - val_ca2-[6,11]: 47.1955 - val_ca2-[12,17]: 193.8277 - val_ca2-[18,23]: 444.9994 - val_ca3-[0,5]: 6.0472 - val_ca3-[6,11]: 50.6465 - val_ca3-[12,17]: 201.7697 - val_ca3-[18,23]: 457.1219 - val_ca4-[0,5]: 6.1244 - val_ca4-[6,11]: 49.5965 - val_ca4-[12,17]: 199.3769 - val_ca4-[18,23]: 453.4792\n",
      "Epoch 15/300\n",
      "26/26 [==============================] - 3s 129ms/step - ca1-[0,5]: 7.5219 - ca1-[6,11]: 68.5851 - ca1-[12,17]: 224.2535 - ca1-[18,23]: 520.1538 - ca2-[0,5]: 6.1852 - ca2-[6,11]: 50.9553 - ca2-[12,17]: 231.6694 - ca2-[18,23]: 413.5085 - ca3-[0,5]: 5.1626 - ca3-[6,11]: 50.9251 - ca3-[12,17]: 105.1586 - ca3-[18,23]: 272.3686 - ca4-[0,5]: 20.5876 - ca4-[6,11]: 40.3638 - ca4-[12,17]: 186.3644 - ca4-[18,23]: 393.4285 - val_ca1-[0,5]: 7.4063 - val_ca1-[6,11]: 72.7485 - val_ca1-[12,17]: 248.5762 - val_ca1-[18,23]: 526.9260 - val_ca2-[0,5]: 6.6749 - val_ca2-[6,11]: 44.9990 - val_ca2-[12,17]: 188.6477 - val_ca2-[18,23]: 437.0424 - val_ca3-[0,5]: 6.2054 - val_ca3-[6,11]: 48.6834 - val_ca3-[12,17]: 197.2799 - val_ca3-[18,23]: 450.2802 - val_ca4-[0,5]: 6.3510 - val_ca4-[6,11]: 47.3252 - val_ca4-[12,17]: 194.1306 - val_ca4-[18,23]: 445.4638\n",
      "Epoch 16/300\n",
      "26/26 [==============================] - 3s 133ms/step - ca1-[0,5]: 7.3014 - ca1-[6,11]: 67.2806 - ca1-[12,17]: 225.1321 - ca1-[18,23]: 519.3743 - ca2-[0,5]: 6.4329 - ca2-[6,11]: 50.0896 - ca2-[12,17]: 230.6085 - ca2-[18,23]: 403.3403 - ca3-[0,5]: 4.6464 - ca3-[6,11]: 48.9156 - ca3-[12,17]: 104.1087 - ca3-[18,23]: 287.4065 - ca4-[0,5]: 17.7655 - ca4-[6,11]: 31.8262 - ca4-[12,17]: 181.1473 - ca4-[18,23]: 388.9816 - val_ca1-[0,5]: 7.1593 - val_ca1-[6,11]: 71.1622 - val_ca1-[12,17]: 244.4425 - val_ca1-[18,23]: 522.2599 - val_ca2-[0,5]: 7.0570 - val_ca2-[6,11]: 42.8951 - val_ca2-[12,17]: 182.7714 - val_ca2-[18,23]: 429.2213 - val_ca3-[0,5]: 6.4171 - val_ca3-[6,11]: 46.7889 - val_ca3-[12,17]: 192.0429 - val_ca3-[18,23]: 443.5425 - val_ca4-[0,5]: 6.6517 - val_ca4-[6,11]: 45.1451 - val_ca4-[12,17]: 188.1709 - val_ca4-[18,23]: 437.5784\n",
      "Epoch 17/300\n",
      "26/26 [==============================] - 4s 139ms/step - ca1-[0,5]: 7.0767 - ca1-[6,11]: 66.2519 - ca1-[12,17]: 221.5082 - ca1-[18,23]: 513.5013 - ca2-[0,5]: 7.1394 - ca2-[6,11]: 44.8380 - ca2-[12,17]: 222.9681 - ca2-[18,23]: 398.9755 - ca3-[0,5]: 3.8778 - ca3-[6,11]: 46.1453 - ca3-[12,17]: 99.0983 - ca3-[18,23]: 284.6056 - ca4-[0,5]: 12.3245 - ca4-[6,11]: 31.6166 - ca4-[12,17]: 172.1852 - ca4-[18,23]: 379.7207 - val_ca1-[0,5]: 6.9347 - val_ca1-[6,11]: 69.6010 - val_ca1-[12,17]: 242.2419 - val_ca1-[18,23]: 517.6250 - val_ca2-[0,5]: 7.5117 - val_ca2-[6,11]: 40.8797 - val_ca2-[12,17]: 178.6257 - val_ca2-[18,23]: 421.5256 - val_ca3-[0,5]: 6.6815 - val_ca3-[6,11]: 44.9584 - val_ca3-[12,17]: 188.5517 - val_ca3-[18,23]: 436.8943 - val_ca4-[0,5]: 7.0254 - val_ca4-[6,11]: 43.0522 - val_ca4-[12,17]: 183.9652 - val_ca4-[18,23]: 429.8131\n",
      "Epoch 18/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 6.6970 - ca1-[6,11]: 64.0041 - ca1-[12,17]: 217.4512 - ca1-[18,23]: 510.0979 - ca2-[0,5]: 7.2753 - ca2-[6,11]: 43.0215 - ca2-[12,17]: 221.6506 - ca2-[18,23]: 390.8138 - ca3-[0,5]: 3.7601 - ca3-[6,11]: 43.5646 - ca3-[12,17]: 94.7462 - ca3-[18,23]: 275.7677 - ca4-[0,5]: 16.2570 - ca4-[6,11]: 32.0888 - ca4-[12,17]: 171.4417 - ca4-[18,23]: 363.1435 - val_ca1-[0,5]: 6.7335 - val_ca1-[6,11]: 68.0735 - val_ca1-[12,17]: 239.1348 - val_ca1-[18,23]: 513.0475 - val_ca2-[0,5]: 8.0387 - val_ca2-[6,11]: 38.9474 - val_ca2-[12,17]: 173.7644 - val_ca2-[18,23]: 413.9375 - val_ca3-[0,5]: 6.9982 - val_ca3-[6,11]: 43.1895 - val_ca3-[12,17]: 184.2987 - val_ca3-[18,23]: 430.3290 - val_ca4-[0,5]: 7.4706 - val_ca4-[6,11]: 41.0469 - val_ca4-[12,17]: 179.0413 - val_ca4-[18,23]: 422.1722\n",
      "Epoch 19/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 6.4782 - ca1-[6,11]: 64.1740 - ca1-[12,17]: 212.5403 - ca1-[18,23]: 505.6243 - ca2-[0,5]: 8.2218 - ca2-[6,11]: 41.4673 - ca2-[12,17]: 217.3393 - ca2-[18,23]: 385.0776 - ca3-[0,5]: 3.3647 - ca3-[6,11]: 42.4904 - ca3-[12,17]: 89.2832 - ca3-[18,23]: 274.0606 - ca4-[0,5]: 13.9543 - ca4-[6,11]: 32.9566 - ca4-[12,17]: 167.0725 - ca4-[18,23]: 361.7374 - val_ca1-[0,5]: 6.5552 - val_ca1-[6,11]: 66.5796 - val_ca1-[12,17]: 236.0740 - val_ca1-[18,23]: 509.3271 - val_ca2-[0,5]: 8.6348 - val_ca2-[6,11]: 37.1037 - val_ca2-[12,17]: 169.0149 - val_ca2-[18,23]: 407.2230 - val_ca3-[0,5]: 7.3660 - val_ca3-[6,11]: 41.4832 - val_ca3-[12,17]: 180.1220 - val_ca3-[18,23]: 424.6031 - val_ca4-[0,5]: 7.9865 - val_ca4-[6,11]: 39.1244 - val_ca4-[12,17]: 174.2145 - val_ca4-[18,23]: 415.3868\n",
      "Epoch 20/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 6.2696 - ca1-[6,11]: 60.4780 - ca1-[12,17]: 209.0745 - ca1-[18,23]: 502.5854 - ca2-[0,5]: 8.7230 - ca2-[6,11]: 39.1139 - ca2-[12,17]: 206.4946 - ca2-[18,23]: 368.9139 - ca3-[0,5]: 3.4138 - ca3-[6,11]: 39.4226 - ca3-[12,17]: 80.4451 - ca3-[18,23]: 257.1906 - ca4-[0,5]: 15.9189 - ca4-[6,11]: 29.0010 - ca4-[12,17]: 162.0610 - ca4-[18,23]: 340.1023 - val_ca1-[0,5]: 6.3990 - val_ca1-[6,11]: 65.1155 - val_ca1-[12,17]: 233.0523 - val_ca1-[18,23]: 504.8530 - val_ca2-[0,5]: 9.3025 - val_ca2-[6,11]: 35.3361 - val_ca2-[12,17]: 164.3469 - val_ca2-[18,23]: 399.8506 - val_ca3-[0,5]: 7.7845 - val_ca3-[6,11]: 39.8368 - val_ca3-[12,17]: 176.0162 - val_ca3-[18,23]: 418.2042 - val_ca4-[0,5]: 8.5726 - val_ca4-[6,11]: 37.2830 - val_ca4-[12,17]: 169.4821 - val_ca4-[18,23]: 407.9587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/300\n",
      "26/26 [==============================] - 3s 131ms/step - ca1-[0,5]: 6.0946 - ca1-[6,11]: 60.6336 - ca1-[12,17]: 209.7614 - ca1-[18,23]: 498.6435 - ca2-[0,5]: 9.5906 - ca2-[6,11]: 38.7070 - ca2-[12,17]: 199.8420 - ca2-[18,23]: 363.9763 - ca3-[0,5]: 2.9909 - ca3-[6,11]: 35.0168 - ca3-[12,17]: 84.4615 - ca3-[18,23]: 257.2926 - ca4-[0,5]: 12.8437 - ca4-[6,11]: 33.3183 - ca4-[12,17]: 159.4883 - ca4-[18,23]: 335.1552 - val_ca1-[0,5]: 6.2644 - val_ca1-[6,11]: 63.6791 - val_ca1-[12,17]: 230.0656 - val_ca1-[18,23]: 499.6269 - val_ca2-[0,5]: 10.0378 - val_ca2-[6,11]: 33.6519 - val_ca2-[12,17]: 159.7809 - val_ca2-[18,23]: 391.8662 - val_ca3-[0,5]: 8.2541 - val_ca3-[6,11]: 38.2465 - val_ca3-[12,17]: 171.9726 - val_ca3-[18,23]: 411.1302 - val_ca4-[0,5]: 9.2276 - val_ca4-[6,11]: 35.5217 - val_ca4-[12,17]: 164.8428 - val_ca4-[18,23]: 399.8999\n",
      "Epoch 22/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 5.8665 - ca1-[6,11]: 58.1518 - ca1-[12,17]: 203.1457 - ca1-[18,23]: 492.9344 - ca2-[0,5]: 10.3532 - ca2-[6,11]: 36.8973 - ca2-[12,17]: 196.8653 - ca2-[18,23]: 359.6765 - ca3-[0,5]: 3.0124 - ca3-[6,11]: 35.8881 - ca3-[12,17]: 83.8856 - ca3-[18,23]: 259.3719 - ca4-[0,5]: 9.3293 - ca4-[6,11]: 31.1856 - ca4-[12,17]: 153.1502 - ca4-[18,23]: 345.4638 - val_ca1-[0,5]: 6.1503 - val_ca1-[6,11]: 62.2606 - val_ca1-[12,17]: 227.0935 - val_ca1-[18,23]: 495.2088 - val_ca2-[0,5]: 10.8442 - val_ca2-[6,11]: 32.0407 - val_ca2-[12,17]: 155.2905 - val_ca2-[18,23]: 384.6956 - val_ca3-[0,5]: 8.7744 - val_ca3-[6,11]: 36.7117 - val_ca3-[12,17]: 167.9901 - val_ca3-[18,23]: 404.8690 - val_ca4-[0,5]: 9.9508 - val_ca4-[6,11]: 33.8395 - val_ca4-[12,17]: 160.2957 - val_ca4-[18,23]: 392.6859\n",
      "Epoch 23/300\n",
      "26/26 [==============================] - 3s 129ms/step - ca1-[0,5]: 5.8641 - ca1-[6,11]: 57.5360 - ca1-[12,17]: 200.2752 - ca1-[18,23]: 485.7716 - ca2-[0,5]: 11.2867 - ca2-[6,11]: 32.3015 - ca2-[12,17]: 197.4168 - ca2-[18,23]: 356.5902 - ca3-[0,5]: 3.0332 - ca3-[6,11]: 34.2091 - ca3-[12,17]: 78.9501 - ca3-[18,23]: 244.4661 - ca4-[0,5]: 13.6779 - ca4-[6,11]: 28.4247 - ca4-[12,17]: 145.3223 - ca4-[18,23]: 334.5142 - val_ca1-[0,5]: 6.0573 - val_ca1-[6,11]: 60.8671 - val_ca1-[12,17]: 224.1513 - val_ca1-[18,23]: 491.6136 - val_ca2-[0,5]: 11.7198 - val_ca2-[6,11]: 30.5051 - val_ca2-[12,17]: 150.8828 - val_ca2-[18,23]: 378.3365 - val_ca3-[0,5]: 9.3461 - val_ca3-[6,11]: 35.2295 - val_ca3-[12,17]: 164.0616 - val_ca3-[18,23]: 399.3985 - val_ca4-[0,5]: 10.7425 - val_ca4-[6,11]: 32.2326 - val_ca4-[12,17]: 155.8321 - val_ca4-[18,23]: 386.2899\n",
      "Epoch 24/300\n",
      "26/26 [==============================] - 3s 131ms/step - ca1-[0,5]: 5.7212 - ca1-[6,11]: 55.7267 - ca1-[12,17]: 197.5768 - ca1-[18,23]: 481.1530 - ca2-[0,5]: 12.0553 - ca2-[6,11]: 30.1229 - ca2-[12,17]: 187.9838 - ca2-[18,23]: 342.9440 - ca3-[0,5]: 2.9584 - ca3-[6,11]: 31.6125 - ca3-[12,17]: 74.6736 - ca3-[18,23]: 239.6924 - ca4-[0,5]: 13.7689 - ca4-[6,11]: 30.1689 - ca4-[12,17]: 144.9484 - ca4-[18,23]: 331.7150 - val_ca1-[0,5]: 5.9825 - val_ca1-[6,11]: 59.4393 - val_ca1-[12,17]: 221.1120 - val_ca1-[18,23]: 486.2850 - val_ca2-[0,5]: 12.6653 - val_ca2-[6,11]: 29.0428 - val_ca2-[12,17]: 146.5529 - val_ca2-[18,23]: 370.6151 - val_ca3-[0,5]: 9.9667 - val_ca3-[6,11]: 33.8051 - val_ca3-[12,17]: 160.2016 - val_ca3-[18,23]: 392.5360 - val_ca4-[0,5]: 11.6036 - val_ca4-[6,11]: 30.6980 - val_ca4-[12,17]: 151.4440 - val_ca4-[18,23]: 378.5183\n",
      "Epoch 25/300\n",
      "26/26 [==============================] - 3s 132ms/step - ca1-[0,5]: 5.6891 - ca1-[6,11]: 55.7271 - ca1-[12,17]: 193.1537 - ca1-[18,23]: 480.6149 - ca2-[0,5]: 13.1681 - ca2-[6,11]: 32.4999 - ca2-[12,17]: 177.0524 - ca2-[18,23]: 339.0015 - ca3-[0,5]: 3.0289 - ca3-[6,11]: 30.0922 - ca3-[12,17]: 76.9300 - ca3-[18,23]: 243.8120 - ca4-[0,5]: 12.0921 - ca4-[6,11]: 30.0640 - ca4-[12,17]: 138.4992 - ca4-[18,23]: 320.4047 - val_ca1-[0,5]: 5.9133 - val_ca1-[6,11]: 57.3920 - val_ca1-[12,17]: 216.7079 - val_ca1-[18,23]: 479.6861 - val_ca2-[0,5]: 13.6734 - val_ca2-[6,11]: 27.6622 - val_ca2-[12,17]: 142.3273 - val_ca2-[18,23]: 363.7408 - val_ca3-[0,5]: 10.6370 - val_ca3-[6,11]: 32.4349 - val_ca3-[12,17]: 156.4011 - val_ca3-[18,23]: 386.4731 - val_ca4-[0,5]: 12.5328 - val_ca4-[6,11]: 29.2372 - val_ca4-[12,17]: 147.1366 - val_ca4-[18,23]: 371.5612\n",
      "Epoch 26/300\n",
      "26/26 [==============================] - 3s 130ms/step - ca1-[0,5]: 5.4839 - ca1-[6,11]: 52.8060 - ca1-[12,17]: 194.3881 - ca1-[18,23]: 470.2695 - ca2-[0,5]: 13.9311 - ca2-[6,11]: 30.3352 - ca2-[12,17]: 177.0749 - ca2-[18,23]: 335.3804 - ca3-[0,5]: 3.0764 - ca3-[6,11]: 28.7277 - ca3-[12,17]: 72.1705 - ca3-[18,23]: 239.4646 - ca4-[0,5]: 11.7038 - ca4-[6,11]: 27.2737 - ca4-[12,17]: 136.1303 - ca4-[18,23]: 324.7316 - val_ca1-[0,5]: 5.9109 - val_ca1-[6,11]: 53.7968 - val_ca1-[12,17]: 209.9179 - val_ca1-[18,23]: 468.6065 - val_ca2-[0,5]: 14.7470 - val_ca2-[6,11]: 26.3568 - val_ca2-[12,17]: 139.0344 - val_ca2-[18,23]: 357.6731 - val_ca3-[0,5]: 11.3566 - val_ca3-[6,11]: 31.1186 - val_ca3-[12,17]: 153.5593 - val_ca3-[18,23]: 381.1985 - val_ca4-[0,5]: 13.5281 - val_ca4-[6,11]: 27.8513 - val_ca4-[12,17]: 143.7785 - val_ca4-[18,23]: 365.4129\n",
      "Epoch 27/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 5.5106 - ca1-[6,11]: 49.9867 - ca1-[12,17]: 180.7649 - ca1-[18,23]: 459.9375 - ca2-[0,5]: 15.3706 - ca2-[6,11]: 28.3988 - ca2-[12,17]: 175.7580 - ca2-[18,23]: 324.2603 - ca3-[0,5]: 3.2208 - ca3-[6,11]: 27.0759 - ca3-[12,17]: 69.2926 - ca3-[18,23]: 234.6801 - ca4-[0,5]: 12.1653 - ca4-[6,11]: 27.4466 - ca4-[12,17]: 126.2385 - ca4-[18,23]: 312.9422 - val_ca1-[0,5]: 6.0155 - val_ca1-[6,11]: 51.1601 - val_ca1-[12,17]: 202.9331 - val_ca1-[18,23]: 459.6616 - val_ca2-[0,5]: 15.8903 - val_ca2-[6,11]: 25.1203 - val_ca2-[12,17]: 134.1174 - val_ca2-[18,23]: 350.9590 - val_ca3-[0,5]: 12.1238 - val_ca3-[6,11]: 29.8581 - val_ca3-[12,17]: 148.9843 - val_ca3-[18,23]: 375.2710 - val_ca4-[0,5]: 14.5899 - val_ca4-[6,11]: 26.5384 - val_ca4-[12,17]: 138.7735 - val_ca4-[18,23]: 358.6343\n",
      "Epoch 28/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 5.6790 - ca1-[6,11]: 46.2354 - ca1-[12,17]: 178.4160 - ca1-[18,23]: 449.2294 - ca2-[0,5]: 16.4126 - ca2-[6,11]: 24.9353 - ca2-[12,17]: 170.2546 - ca2-[18,23]: 319.4389 - ca3-[0,5]: 3.3900 - ca3-[6,11]: 25.1141 - ca3-[12,17]: 67.4591 - ca3-[18,23]: 226.7405 - ca4-[0,5]: 11.6280 - ca4-[6,11]: 26.4816 - ca4-[12,17]: 125.2276 - ca4-[18,23]: 306.2636 - val_ca1-[0,5]: 6.1742 - val_ca1-[6,11]: 49.0177 - val_ca1-[12,17]: 198.0494 - val_ca1-[18,23]: 451.4547 - val_ca2-[0,5]: 17.0962 - val_ca2-[6,11]: 23.9594 - val_ca2-[12,17]: 130.1377 - val_ca2-[18,23]: 343.6509 - val_ca3-[0,5]: 12.9416 - val_ca3-[6,11]: 28.6477 - val_ca3-[12,17]: 145.3584 - val_ca3-[18,23]: 368.6763 - val_ca4-[0,5]: 15.7194 - val_ca4-[6,11]: 25.2961 - val_ca4-[12,17]: 134.7064 - val_ca4-[18,23]: 351.2284\n",
      "Epoch 29/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 5.6936 - ca1-[6,11]: 44.5756 - ca1-[12,17]: 174.4477 - ca1-[18,23]: 441.6875 - ca2-[0,5]: 17.9642 - ca2-[6,11]: 26.3768 - ca2-[12,17]: 164.8361 - ca2-[18,23]: 317.5533 - ca3-[0,5]: 3.6030 - ca3-[6,11]: 23.7809 - ca3-[12,17]: 66.6845 - ca3-[18,23]: 227.5201 - ca4-[0,5]: 11.1252 - ca4-[6,11]: 24.7199 - ca4-[12,17]: 120.9763 - ca4-[18,23]: 296.5857 - val_ca1-[0,5]: 6.3784 - val_ca1-[6,11]: 47.1391 - val_ca1-[12,17]: 193.5988 - val_ca1-[18,23]: 444.6488 - val_ca2-[0,5]: 18.3666 - val_ca2-[6,11]: 22.9256 - val_ca2-[12,17]: 126.2385 - val_ca2-[18,23]: 337.1357 - val_ca3-[0,5]: 13.8074 - val_ca3-[6,11]: 27.5426 - val_ca3-[12,17]: 141.7925 - val_ca3-[18,23]: 362.8678 - val_ca4-[0,5]: 16.9161 - val_ca4-[6,11]: 24.1786 - val_ca4-[12,17]: 130.7137 - val_ca4-[18,23]: 344.6096\n",
      "Epoch 30/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 5.9251 - ca1-[6,11]: 43.6888 - ca1-[12,17]: 172.5302 - ca1-[18,23]: 433.8170 - ca2-[0,5]: 18.9733 - ca2-[6,11]: 21.8701 - ca2-[12,17]: 156.9919 - ca2-[18,23]: 308.3142 - ca3-[0,5]: 2.7137 - ca3-[6,11]: 22.2508 - ca3-[12,17]: 64.6585 - ca3-[18,23]: 214.3589 - ca4-[0,5]: 10.8566 - ca4-[6,11]: 23.3634 - ca4-[12,17]: 121.7447 - ca4-[18,23]: 288.9670 - val_ca1-[0,5]: 6.6226 - val_ca1-[6,11]: 45.3312 - val_ca1-[12,17]: 189.4382 - val_ca1-[18,23]: 438.2593 - val_ca2-[0,5]: 19.7083 - val_ca2-[6,11]: 21.8475 - val_ca2-[12,17]: 122.3994 - val_ca2-[18,23]: 330.6749 - val_ca3-[0,5]: 14.7215 - val_ca3-[6,11]: 26.3861 - val_ca3-[12,17]: 138.2831 - val_ca3-[18,23]: 357.1198 - val_ca4-[0,5]: 18.1787 - val_ca4-[6,11]: 23.0237 - val_ca4-[12,17]: 126.7983 - val_ca4-[18,23]: 338.0739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 6.0444 - ca1-[6,11]: 41.0866 - ca1-[12,17]: 164.1928 - ca1-[18,23]: 428.7214 - ca2-[0,5]: 20.6047 - ca2-[6,11]: 24.1779 - ca2-[12,17]: 155.8895 - ca2-[18,23]: 304.2110 - ca3-[0,5]: 4.1854 - ca3-[6,11]: 20.8185 - ca3-[12,17]: 56.2222 - ca3-[18,23]: 217.0843 - ca4-[0,5]: 10.4907 - ca4-[6,11]: 23.0282 - ca4-[12,17]: 115.1798 - ca4-[18,23]: 286.9723 - val_ca1-[0,5]: 6.9026 - val_ca1-[6,11]: 43.6871 - val_ca1-[12,17]: 185.5024 - val_ca1-[18,23]: 426.9734 - val_ca2-[0,5]: 21.1151 - val_ca2-[6,11]: 20.8953 - val_ca2-[12,17]: 118.6375 - val_ca2-[18,23]: 319.7069 - val_ca3-[0,5]: 15.6855 - val_ca3-[6,11]: 25.3314 - val_ca3-[12,17]: 134.8242 - val_ca3-[18,23]: 346.6653 - val_ca4-[0,5]: 19.5070 - val_ca4-[6,11]: 21.9934 - val_ca4-[12,17]: 122.9589 - val_ca4-[18,23]: 326.9830\n",
      "Epoch 32/300\n",
      "26/26 [==============================] - 3s 131ms/step - ca1-[0,5]: 6.5278 - ca1-[6,11]: 39.2858 - ca1-[12,17]: 167.5805 - ca1-[18,23]: 424.5598 - ca2-[0,5]: 21.9198 - ca2-[6,11]: 23.3785 - ca2-[12,17]: 153.0687 - ca2-[18,23]: 294.8626 - ca3-[0,5]: 4.5454 - ca3-[6,11]: 19.6164 - ca3-[12,17]: 58.7031 - ca3-[18,23]: 203.7524 - ca4-[0,5]: 10.1582 - ca4-[6,11]: 23.5773 - ca4-[12,17]: 112.9748 - ca4-[18,23]: 280.7399 - val_ca1-[0,5]: 7.2171 - val_ca1-[6,11]: 42.1381 - val_ca1-[12,17]: 182.0940 - val_ca1-[18,23]: 426.3557 - val_ca2-[0,5]: 22.5900 - val_ca2-[6,11]: 20.0112 - val_ca2-[12,17]: 115.2507 - val_ca2-[18,23]: 317.9883 - val_ca3-[0,5]: 16.6991 - val_ca3-[6,11]: 24.3270 - val_ca3-[12,17]: 131.7375 - val_ca3-[18,23]: 345.7773 - val_ca4-[0,5]: 20.8994 - val_ca4-[6,11]: 21.0339 - val_ca4-[12,17]: 119.5089 - val_ca4-[18,23]: 325.2510\n",
      "Epoch 33/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 6.6181 - ca1-[6,11]: 38.1537 - ca1-[12,17]: 160.4095 - ca1-[18,23]: 420.7213 - ca2-[0,5]: 23.3095 - ca2-[6,11]: 21.4234 - ca2-[12,17]: 149.1811 - ca2-[18,23]: 291.8896 - ca3-[0,5]: 4.5977 - ca3-[6,11]: 17.1926 - ca3-[12,17]: 55.7294 - ca3-[18,23]: 199.7406 - ca4-[0,5]: 8.6898 - ca4-[6,11]: 22.4249 - ca4-[12,17]: 107.6433 - ca4-[18,23]: 269.1911 - val_ca1-[0,5]: 7.5659 - val_ca1-[6,11]: 40.7574 - val_ca1-[12,17]: 178.0896 - val_ca1-[18,23]: 420.6907 - val_ca2-[0,5]: 24.1295 - val_ca2-[6,11]: 19.2761 - val_ca2-[12,17]: 111.3266 - val_ca2-[18,23]: 311.7617 - val_ca3-[0,5]: 17.7613 - val_ca3-[6,11]: 23.4564 - val_ca3-[12,17]: 128.0620 - val_ca3-[18,23]: 340.1882 - val_ca4-[0,5]: 22.3594 - val_ca4-[6,11]: 20.2223 - val_ca4-[12,17]: 115.5058 - val_ca4-[18,23]: 318.9514\n",
      "Epoch 34/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 7.0213 - ca1-[6,11]: 37.5648 - ca1-[12,17]: 154.1182 - ca1-[18,23]: 412.8646 - ca2-[0,5]: 25.4418 - ca2-[6,11]: 20.8027 - ca2-[12,17]: 149.9964 - ca2-[18,23]: 272.0626 - ca3-[0,5]: 5.4100 - ca3-[6,11]: 17.1225 - ca3-[12,17]: 54.1688 - ca3-[18,23]: 197.2774 - ca4-[0,5]: 9.5917 - ca4-[6,11]: 20.9446 - ca4-[12,17]: 102.2786 - ca4-[18,23]: 250.6606 - val_ca1-[0,5]: 7.9440 - val_ca1-[6,11]: 39.2704 - val_ca1-[12,17]: 174.5849 - val_ca1-[18,23]: 415.9666 - val_ca2-[0,5]: 25.7352 - val_ca2-[6,11]: 18.4518 - val_ca2-[12,17]: 107.7809 - val_ca2-[18,23]: 306.2826 - val_ca3-[0,5]: 18.8692 - val_ca3-[6,11]: 22.4730 - val_ca3-[12,17]: 124.7694 - val_ca3-[18,23]: 335.3627 - val_ca4-[0,5]: 23.8852 - val_ca4-[6,11]: 19.3196 - val_ca4-[12,17]: 111.8857 - val_ca4-[18,23]: 313.4057\n",
      "Epoch 35/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 7.3666 - ca1-[6,11]: 35.8127 - ca1-[12,17]: 152.9202 - ca1-[18,23]: 407.8646 - ca2-[0,5]: 26.6519 - ca2-[6,11]: 19.6306 - ca2-[12,17]: 133.7361 - ca2-[18,23]: 279.8608 - ca3-[0,5]: 5.9124 - ca3-[6,11]: 15.8940 - ca3-[12,17]: 52.2371 - ca3-[18,23]: 195.1260 - ca4-[0,5]: 8.8756 - ca4-[6,11]: 20.1248 - ca4-[12,17]: 99.4057 - ca4-[18,23]: 257.9575 - val_ca1-[0,5]: 8.3572 - val_ca1-[6,11]: 37.9254 - val_ca1-[12,17]: 171.1461 - val_ca1-[18,23]: 409.8331 - val_ca2-[0,5]: 27.3995 - val_ca2-[6,11]: 17.7775 - val_ca2-[12,17]: 104.3214 - val_ca2-[18,23]: 299.5568 - val_ca3-[0,5]: 20.0259 - val_ca3-[6,11]: 21.6225 - val_ca3-[12,17]: 121.5282 - val_ca3-[18,23]: 329.2022 - val_ca4-[0,5]: 25.4731 - val_ca4-[6,11]: 18.5668 - val_ca4-[12,17]: 108.3451 - val_ca4-[18,23]: 306.5915\n",
      "Epoch 36/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 7.6881 - ca1-[6,11]: 33.8467 - ca1-[12,17]: 152.3521 - ca1-[18,23]: 401.7964 - ca2-[0,5]: 28.4496 - ca2-[6,11]: 17.0633 - ca2-[12,17]: 141.3677 - ca2-[18,23]: 276.1405 - ca3-[0,5]: 6.3482 - ca3-[6,11]: 14.8097 - ca3-[12,17]: 50.8844 - ca3-[18,23]: 188.4415 - ca4-[0,5]: 7.2515 - ca4-[6,11]: 20.9686 - ca4-[12,17]: 96.4025 - ca4-[18,23]: 257.0469 - val_ca1-[0,5]: 8.8008 - val_ca1-[6,11]: 36.6386 - val_ca1-[12,17]: 167.7983 - val_ca1-[18,23]: 404.5668 - val_ca2-[0,5]: 29.1333 - val_ca2-[6,11]: 17.1695 - val_ca2-[12,17]: 100.9242 - val_ca2-[18,23]: 293.5630 - val_ca3-[0,5]: 21.2294 - val_ca3-[6,11]: 20.8228 - val_ca3-[12,17]: 118.3427 - val_ca3-[18,23]: 323.7956 - val_ca4-[0,5]: 27.1243 - val_ca4-[6,11]: 17.8826 - val_ca4-[12,17]: 104.8795 - val_ca4-[18,23]: 300.5366\n",
      "Epoch 37/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 8.1942 - ca1-[6,11]: 33.7059 - ca1-[12,17]: 144.7720 - ca1-[18,23]: 397.5625 - ca2-[0,5]: 30.1888 - ca2-[6,11]: 17.9745 - ca2-[12,17]: 129.7608 - ca2-[18,23]: 269.7410 - ca3-[0,5]: 7.0576 - ca3-[6,11]: 13.3399 - ca3-[12,17]: 50.2713 - ca3-[18,23]: 183.4117 - ca4-[0,5]: 8.9889 - ca4-[6,11]: 19.9113 - ca4-[12,17]: 90.0587 - ca4-[18,23]: 247.8694 - val_ca1-[0,5]: 9.2743 - val_ca1-[6,11]: 35.4055 - val_ca1-[12,17]: 163.7693 - val_ca1-[18,23]: 399.4088 - val_ca2-[0,5]: 30.9254 - val_ca2-[6,11]: 16.6311 - val_ca2-[12,17]: 97.0489 - val_ca2-[18,23]: 287.6650 - val_ca3-[0,5]: 22.4839 - val_ca3-[6,11]: 20.0713 - val_ca3-[12,17]: 114.5814 - val_ca3-[18,23]: 318.4308 - val_ca4-[0,5]: 28.8430 - val_ca4-[6,11]: 17.2651 - val_ca4-[12,17]: 100.9046 - val_ca4-[18,23]: 294.5460\n",
      "Epoch 38/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 8.6716 - ca1-[6,11]: 31.7848 - ca1-[12,17]: 145.9703 - ca1-[18,23]: 391.7714 - ca2-[0,5]: 32.2071 - ca2-[6,11]: 17.8599 - ca2-[12,17]: 133.5633 - ca2-[18,23]: 259.1721 - ca3-[0,5]: 7.7017 - ca3-[6,11]: 12.4844 - ca3-[12,17]: 40.4581 - ca3-[18,23]: 182.3610 - ca4-[0,5]: 8.8532 - ca4-[6,11]: 20.2563 - ca4-[12,17]: 90.7673 - ca4-[18,23]: 247.5547 - val_ca1-[0,5]: 9.7796 - val_ca1-[6,11]: 34.3391 - val_ca1-[12,17]: 161.3261 - val_ca1-[18,23]: 394.3241 - val_ca2-[0,5]: 32.7807 - val_ca2-[6,11]: 16.2366 - val_ca2-[12,17]: 94.3684 - val_ca2-[18,23]: 281.8441 - val_ca3-[0,5]: 23.7858 - val_ca3-[6,11]: 19.4603 - val_ca3-[12,17]: 112.1150 - val_ca3-[18,23]: 313.1230 - val_ca4-[0,5]: 30.6260 - val_ca4-[6,11]: 16.7947 - val_ca4-[12,17]: 98.1508 - val_ca4-[18,23]: 288.6309\n",
      "Epoch 39/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 9.0599 - ca1-[6,11]: 31.9345 - ca1-[12,17]: 138.2297 - ca1-[18,23]: 384.7822 - ca2-[0,5]: 33.8171 - ca2-[6,11]: 17.3180 - ca2-[12,17]: 124.4655 - ca2-[18,23]: 253.1496 - ca3-[0,5]: 7.8953 - ca3-[6,11]: 10.8899 - ca3-[12,17]: 43.0943 - ca3-[18,23]: 183.0314 - ca4-[0,5]: 8.7492 - ca4-[6,11]: 19.1270 - ca4-[12,17]: 87.9652 - ca4-[18,23]: 240.3228 - val_ca1-[0,5]: 10.3104 - val_ca1-[6,11]: 33.0827 - val_ca1-[12,17]: 158.2092 - val_ca1-[18,23]: 389.3614 - val_ca2-[0,5]: 34.7100 - val_ca2-[6,11]: 15.7539 - val_ca2-[12,17]: 91.1805 - val_ca2-[18,23]: 276.0667 - val_ca3-[0,5]: 25.1365 - val_ca3-[6,11]: 18.7182 - val_ca3-[12,17]: 109.0779 - val_ca3-[18,23]: 307.8655 - val_ca4-[0,5]: 32.4742 - val_ca4-[6,11]: 16.2323 - val_ca4-[12,17]: 94.8916 - val_ca4-[18,23]: 282.7872\n",
      "Epoch 40/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 9.6202 - ca1-[6,11]: 29.9833 - ca1-[12,17]: 136.5046 - ca1-[18,23]: 381.5480 - ca2-[0,5]: 36.6026 - ca2-[6,11]: 16.3115 - ca2-[12,17]: 121.3347 - ca2-[18,23]: 250.6002 - ca3-[0,5]: 9.1306 - ca3-[6,11]: 10.4466 - ca3-[12,17]: 41.2843 - ca3-[18,23]: 173.9404 - ca4-[0,5]: 7.5281 - ca4-[6,11]: 18.7425 - ca4-[12,17]: 83.1331 - ca4-[18,23]: 223.3382 - val_ca1-[0,5]: 10.8691 - val_ca1-[6,11]: 31.9942 - val_ca1-[12,17]: 155.1587 - val_ca1-[18,23]: 384.4845 - val_ca2-[0,5]: 36.6991 - val_ca2-[6,11]: 15.4156 - val_ca2-[12,17]: 88.0702 - val_ca2-[18,23]: 270.3758 - val_ca3-[0,5]: 26.5371 - val_ca3-[6,11]: 18.1152 - val_ca3-[12,17]: 106.0884 - val_ca3-[18,23]: 302.6545 - val_ca4-[0,5]: 34.3875 - val_ca4-[6,11]: 15.8162 - val_ca4-[12,17]: 91.7012 - val_ca4-[18,23]: 277.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 10.2124 - ca1-[6,11]: 28.4917 - ca1-[12,17]: 132.3698 - ca1-[18,23]: 379.6476 - ca2-[0,5]: 38.0269 - ca2-[6,11]: 16.0037 - ca2-[12,17]: 121.4829 - ca2-[18,23]: 242.4073 - ca3-[0,5]: 9.9155 - ca3-[6,11]: 9.4125 - ca3-[12,17]: 39.7157 - ca3-[18,23]: 166.9150 - ca4-[0,5]: 8.4040 - ca4-[6,11]: 22.1624 - ca4-[12,17]: 79.3633 - ca4-[18,23]: 230.6504 - val_ca1-[0,5]: 11.4565 - val_ca1-[6,11]: 31.0345 - val_ca1-[12,17]: 152.1636 - val_ca1-[18,23]: 379.6764 - val_ca2-[0,5]: 38.7551 - val_ca2-[6,11]: 15.2156 - val_ca2-[12,17]: 85.0256 - val_ca2-[18,23]: 264.7502 - val_ca3-[0,5]: 27.9855 - val_ca3-[6,11]: 17.6387 - val_ca3-[12,17]: 103.1509 - val_ca3-[18,23]: 297.4976 - val_ca4-[0,5]: 36.3669 - val_ca4-[6,11]: 15.5398 - val_ca4-[12,17]: 88.5780 - val_ca4-[18,23]: 271.3088\n",
      "Epoch 42/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 10.7351 - ca1-[6,11]: 26.4376 - ca1-[12,17]: 130.8191 - ca1-[18,23]: 374.1945 - ca2-[0,5]: 40.1415 - ca2-[6,11]: 14.8305 - ca2-[12,17]: 115.0553 - ca2-[18,23]: 235.8384 - ca3-[0,5]: 10.7473 - ca3-[6,11]: 8.4991 - ca3-[12,17]: 40.3981 - ca3-[18,23]: 168.7848 - ca4-[0,5]: 8.4290 - ca4-[6,11]: 19.3176 - ca4-[12,17]: 79.0920 - ca4-[18,23]: 204.1425 - val_ca1-[0,5]: 12.0722 - val_ca1-[6,11]: 30.0261 - val_ca1-[12,17]: 149.2222 - val_ca1-[18,23]: 375.6555 - val_ca2-[0,5]: 40.8762 - val_ca2-[6,11]: 15.0093 - val_ca2-[12,17]: 82.0490 - val_ca2-[18,23]: 259.8328 - val_ca3-[0,5]: 29.4814 - val_ca3-[6,11]: 17.1343 - val_ca3-[12,17]: 100.2656 - val_ca3-[18,23]: 293.0591 - val_ca4-[0,5]: 38.4112 - val_ca4-[6,11]: 15.2561 - val_ca4-[12,17]: 85.5235 - val_ca4-[18,23]: 266.3179\n",
      "Epoch 43/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 11.3360 - ca1-[6,11]: 27.3364 - ca1-[12,17]: 128.7267 - ca1-[18,23]: 365.4478 - ca2-[0,5]: 42.5721 - ca2-[6,11]: 15.2292 - ca2-[12,17]: 112.3231 - ca2-[18,23]: 231.5576 - ca3-[0,5]: 11.6263 - ca3-[6,11]: 7.2012 - ca3-[12,17]: 35.7718 - ca3-[18,23]: 161.1363 - ca4-[0,5]: 8.6548 - ca4-[6,11]: 20.1171 - ca4-[12,17]: 74.3702 - ca4-[18,23]: 206.2182 - val_ca1-[0,5]: 12.7147 - val_ca1-[6,11]: 28.9710 - val_ca1-[12,17]: 146.1149 - val_ca1-[18,23]: 370.2642 - val_ca2-[0,5]: 43.0582 - val_ca2-[6,11]: 14.7993 - val_ca2-[12,17]: 79.0272 - val_ca2-[18,23]: 253.7176 - val_ca3-[0,5]: 31.0270 - val_ca3-[6,11]: 16.6032 - val_ca3-[12,17]: 97.2772 - val_ca3-[18,23]: 287.3394 - val_ca4-[0,5]: 40.5167 - val_ca4-[6,11]: 14.9680 - val_ca4-[12,17]: 82.4175 - val_ca4-[18,23]: 260.1191\n",
      "Epoch 44/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 11.9793 - ca1-[6,11]: 26.9747 - ca1-[12,17]: 126.6963 - ca1-[18,23]: 359.6737 - ca2-[0,5]: 45.0704 - ca2-[6,11]: 15.0483 - ca2-[12,17]: 109.0590 - ca2-[18,23]: 227.2021 - ca3-[0,5]: 12.4006 - ca3-[6,11]: 6.8099 - ca3-[12,17]: 36.3063 - ca3-[18,23]: 163.8441 - ca4-[0,5]: 9.8567 - ca4-[6,11]: 18.2758 - ca4-[12,17]: 68.9920 - ca4-[18,23]: 221.4061 - val_ca1-[0,5]: 13.3856 - val_ca1-[6,11]: 28.0396 - val_ca1-[12,17]: 143.4969 - val_ca1-[18,23]: 365.6481 - val_ca2-[0,5]: 45.2998 - val_ca2-[6,11]: 14.7266 - val_ca2-[12,17]: 76.3167 - val_ca2-[18,23]: 248.3224 - val_ca3-[0,5]: 32.6161 - val_ca3-[6,11]: 16.1986 - val_ca3-[12,17]: 94.6488 - val_ca3-[18,23]: 282.3496 - val_ca4-[0,5]: 42.6896 - val_ca4-[6,11]: 14.8179 - val_ca4-[12,17]: 79.6257 - val_ca4-[18,23]: 254.6268\n",
      "Epoch 45/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 12.6604 - ca1-[6,11]: 24.4059 - ca1-[12,17]: 121.3351 - ca1-[18,23]: 359.5602 - ca2-[0,5]: 46.8379 - ca2-[6,11]: 14.8560 - ca2-[12,17]: 105.4090 - ca2-[18,23]: 220.4847 - ca3-[0,5]: 12.9903 - ca3-[6,11]: 6.3234 - ca3-[12,17]: 35.2270 - ca3-[18,23]: 161.6044 - ca4-[0,5]: 8.7991 - ca4-[6,11]: 20.4134 - ca4-[12,17]: 65.4792 - ca4-[18,23]: 208.8700 - val_ca1-[0,5]: 14.0850 - val_ca1-[6,11]: 27.1434 - val_ca1-[12,17]: 140.7005 - val_ca1-[18,23]: 361.0826 - val_ca2-[0,5]: 47.6063 - val_ca2-[6,11]: 14.7195 - val_ca2-[12,17]: 73.5540 - val_ca2-[18,23]: 242.9946 - val_ca3-[0,5]: 34.2533 - val_ca3-[6,11]: 15.8428 - val_ca3-[12,17]: 91.9194 - val_ca3-[18,23]: 277.4106 - val_ca4-[0,5]: 44.9267 - val_ca4-[6,11]: 14.7340 - val_ca4-[12,17]: 76.7775 - val_ca4-[18,23]: 249.2051\n",
      "Epoch 46/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 13.2805 - ca1-[6,11]: 24.4865 - ca1-[12,17]: 119.8149 - ca1-[18,23]: 353.7976 - ca2-[0,5]: 49.3613 - ca2-[6,11]: 14.4929 - ca2-[12,17]: 93.9327 - ca2-[18,23]: 215.2488 - ca3-[0,5]: 14.3358 - ca3-[6,11]: 5.0545 - ca3-[12,17]: 31.4907 - ca3-[18,23]: 155.2392 - ca4-[0,5]: 8.8234 - ca4-[6,11]: 21.2555 - ca4-[12,17]: 67.1916 - ca4-[18,23]: 206.4388 - val_ca1-[0,5]: 14.8057 - val_ca1-[6,11]: 26.2896 - val_ca1-[12,17]: 137.9713 - val_ca1-[18,23]: 356.6076 - val_ca2-[0,5]: 49.9788 - val_ca2-[6,11]: 14.7779 - val_ca2-[12,17]: 70.8564 - val_ca2-[18,23]: 237.7313 - val_ca3-[0,5]: 35.9380 - val_ca3-[6,11]: 15.5359 - val_ca3-[12,17]: 89.2404 - val_ca3-[18,23]: 272.5234 - val_ca4-[0,5]: 47.2297 - val_ca4-[6,11]: 14.7162 - val_ca4-[12,17]: 73.9953 - val_ca4-[18,23]: 243.8497\n",
      "Epoch 47/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 14.0167 - ca1-[6,11]: 22.7467 - ca1-[12,17]: 116.7569 - ca1-[18,23]: 347.7075 - ca2-[0,5]: 51.5364 - ca2-[6,11]: 14.1248 - ca2-[12,17]: 102.0309 - ca2-[18,23]: 209.3147 - ca3-[0,5]: 14.6885 - ca3-[6,11]: 4.6095 - ca3-[12,17]: 30.1077 - ca3-[18,23]: 149.7026 - ca4-[0,5]: 9.0701 - ca4-[6,11]: 21.7930 - ca4-[12,17]: 63.4958 - ca4-[18,23]: 196.1770 - val_ca1-[0,5]: 15.5570 - val_ca1-[6,11]: 25.4659 - val_ca1-[12,17]: 135.2716 - val_ca1-[18,23]: 352.1617 - val_ca2-[0,5]: 52.4160 - val_ca2-[6,11]: 14.9020 - val_ca2-[12,17]: 68.2254 - val_ca2-[18,23]: 232.5355 - val_ca3-[0,5]: 37.6689 - val_ca3-[6,11]: 15.2780 - val_ca3-[12,17]: 86.6137 - val_ca3-[18,23]: 267.6916 - val_ca4-[0,5]: 49.5950 - val_ca4-[6,11]: 14.7642 - val_ca4-[12,17]: 71.2834 - val_ca4-[18,23]: 238.5686\n",
      "Epoch 48/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 14.6440 - ca1-[6,11]: 22.2730 - ca1-[12,17]: 115.4381 - ca1-[18,23]: 345.0571 - ca2-[0,5]: 53.8736 - ca2-[6,11]: 14.4537 - ca2-[12,17]: 99.4781 - ca2-[18,23]: 207.8791 - ca3-[0,5]: 16.7065 - ca3-[6,11]: 4.2243 - ca3-[12,17]: 29.0353 - ca3-[18,23]: 148.2265 - ca4-[0,5]: 9.2526 - ca4-[6,11]: 20.6076 - ca4-[12,17]: 57.9428 - ca4-[18,23]: 189.7783 - val_ca1-[0,5]: 16.3282 - val_ca1-[6,11]: 24.7668 - val_ca1-[12,17]: 132.6376 - val_ca1-[18,23]: 343.0688 - val_ca2-[0,5]: 54.9154 - val_ca2-[6,11]: 15.1573 - val_ca2-[12,17]: 65.6633 - val_ca2-[18,23]: 223.4918 - val_ca3-[0,5]: 39.4486 - val_ca3-[6,11]: 15.1401 - val_ca3-[12,17]: 84.0348 - val_ca3-[18,23]: 258.7255 - val_ca4-[0,5]: 52.0215 - val_ca4-[6,11]: 14.9447 - val_ca4-[12,17]: 68.6420 - val_ca4-[18,23]: 229.3970\n",
      "Epoch 49/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 15.4713 - ca1-[6,11]: 21.1136 - ca1-[12,17]: 113.1387 - ca1-[18,23]: 343.3340 - ca2-[0,5]: 56.4079 - ca2-[6,11]: 14.1193 - ca2-[12,17]: 89.2373 - ca2-[18,23]: 193.5525 - ca3-[0,5]: 17.2794 - ca3-[6,11]: 3.3215 - ca3-[12,17]: 24.3787 - ca3-[18,23]: 142.1066 - ca4-[0,5]: 9.4250 - ca4-[6,11]: 22.0269 - ca4-[12,17]: 55.9203 - ca4-[18,23]: 185.8216 - val_ca1-[0,5]: 17.1238 - val_ca1-[6,11]: 23.9343 - val_ca1-[12,17]: 130.0497 - val_ca1-[18,23]: 344.2042 - val_ca2-[0,5]: 57.4805 - val_ca2-[6,11]: 15.3460 - val_ca2-[12,17]: 63.1663 - val_ca2-[18,23]: 222.9623 - val_ca3-[0,5]: 41.2746 - val_ca3-[6,11]: 14.9076 - val_ca3-[12,17]: 81.5075 - val_ca3-[18,23]: 258.8150 - val_ca4-[0,5]: 54.5112 - val_ca4-[6,11]: 15.0566 - val_ca4-[12,17]: 66.0687 - val_ca4-[18,23]: 228.8409\n",
      "Epoch 50/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 16.1747 - ca1-[6,11]: 21.3201 - ca1-[12,17]: 109.1859 - ca1-[18,23]: 337.3575 - ca2-[0,5]: 60.0328 - ca2-[6,11]: 15.1316 - ca2-[12,17]: 89.4470 - ca2-[18,23]: 195.4639 - ca3-[0,5]: 17.5549 - ca3-[6,11]: 3.2856 - ca3-[12,17]: 24.9201 - ca3-[18,23]: 141.1961 - ca4-[0,5]: 9.6833 - ca4-[6,11]: 22.5234 - ca4-[12,17]: 56.6986 - ca4-[18,23]: 176.6936 - val_ca1-[0,5]: 17.9450 - val_ca1-[6,11]: 23.2178 - val_ca1-[12,17]: 127.5018 - val_ca1-[18,23]: 339.9484 - val_ca2-[0,5]: 60.1089 - val_ca2-[6,11]: 15.6659 - val_ca2-[12,17]: 60.7366 - val_ca2-[18,23]: 217.9686 - val_ca3-[0,5]: 43.1527 - val_ca3-[6,11]: 14.7949 - val_ca3-[12,17]: 79.0237 - val_ca3-[18,23]: 254.1201 - val_ca4-[0,5]: 57.0659 - val_ca4-[6,11]: 15.3009 - val_ca4-[12,17]: 63.5612 - val_ca4-[18,23]: 223.7674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 17.1129 - ca1-[6,11]: 20.8171 - ca1-[12,17]: 107.5304 - ca1-[18,23]: 332.6696 - ca2-[0,5]: 62.2655 - ca2-[6,11]: 15.4436 - ca2-[12,17]: 88.8260 - ca2-[18,23]: 190.7778 - ca3-[0,5]: 20.3094 - ca3-[6,11]: 2.7162 - ca3-[12,17]: 25.8735 - ca3-[18,23]: 137.7895 - ca4-[0,5]: 8.3507 - ca4-[6,11]: 23.1083 - ca4-[12,17]: 53.1621 - ca4-[18,23]: 167.1536 - val_ca1-[0,5]: 18.7902 - val_ca1-[6,11]: 22.5343 - val_ca1-[12,17]: 124.9976 - val_ca1-[18,23]: 335.7465 - val_ca2-[0,5]: 62.7948 - val_ca2-[6,11]: 16.0499 - val_ca2-[12,17]: 58.3789 - val_ca2-[18,23]: 213.0543 - val_ca3-[0,5]: 45.0754 - val_ca3-[6,11]: 14.7308 - val_ca3-[12,17]: 76.5934 - val_ca3-[18,23]: 249.4834 - val_ca4-[0,5]: 59.6865 - val_ca4-[6,11]: 15.6107 - val_ca4-[12,17]: 61.1187 - val_ca4-[18,23]: 218.7585\n",
      "Epoch 52/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 17.8123 - ca1-[6,11]: 19.6925 - ca1-[12,17]: 105.0066 - ca1-[18,23]: 329.9335 - ca2-[0,5]: 64.7392 - ca2-[6,11]: 14.9448 - ca2-[12,17]: 85.2717 - ca2-[18,23]: 179.0070 - ca3-[0,5]: 22.0022 - ca3-[6,11]: 2.1852 - ca3-[12,17]: 24.1144 - ca3-[18,23]: 128.6499 - ca4-[0,5]: 10.2770 - ca4-[6,11]: 22.3891 - ca4-[12,17]: 51.4771 - ca4-[18,23]: 167.9586 - val_ca1-[0,5]: 19.6634 - val_ca1-[6,11]: 21.8797 - val_ca1-[12,17]: 122.5233 - val_ca1-[18,23]: 330.8842 - val_ca2-[0,5]: 65.5536 - val_ca2-[6,11]: 16.5002 - val_ca2-[12,17]: 56.0797 - val_ca2-[18,23]: 207.5955 - val_ca3-[0,5]: 47.0471 - val_ca3-[6,11]: 14.7152 - val_ca3-[12,17]: 74.2108 - val_ca3-[18,23]: 244.2666 - val_ca4-[0,5]: 62.3623 - val_ca4-[6,11]: 15.9843 - val_ca4-[12,17]: 58.7504 - val_ca4-[18,23]: 213.2326\n",
      "Epoch 53/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 18.6212 - ca1-[6,11]: 19.3241 - ca1-[12,17]: 105.0542 - ca1-[18,23]: 322.0622 - ca2-[0,5]: 67.6715 - ca2-[6,11]: 16.2225 - ca2-[12,17]: 78.2459 - ca2-[18,23]: 170.4966 - ca3-[0,5]: 22.9427 - ca3-[6,11]: 2.0803 - ca3-[12,17]: 21.9143 - ca3-[18,23]: 127.3695 - ca4-[0,5]: 10.6311 - ca4-[6,11]: 25.2467 - ca4-[12,17]: 47.8301 - ca4-[18,23]: 159.7909 - val_ca1-[0,5]: 20.5599 - val_ca1-[6,11]: 21.2574 - val_ca1-[12,17]: 120.0922 - val_ca1-[18,23]: 326.7693 - val_ca2-[0,5]: 68.3773 - val_ca2-[6,11]: 17.0157 - val_ca2-[12,17]: 53.8461 - val_ca2-[18,23]: 202.8027 - val_ca3-[0,5]: 49.0681 - val_ca3-[6,11]: 14.7480 - val_ca3-[12,17]: 71.8754 - val_ca3-[18,23]: 239.7268 - val_ca4-[0,5]: 65.1060 - val_ca4-[6,11]: 16.4234 - val_ca4-[12,17]: 56.4447 - val_ca4-[18,23]: 208.3717\n",
      "Epoch 54/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 19.5132 - ca1-[6,11]: 19.7093 - ca1-[12,17]: 101.7272 - ca1-[18,23]: 319.3727 - ca2-[0,5]: 70.2324 - ca2-[6,11]: 15.3708 - ca2-[12,17]: 77.7812 - ca2-[18,23]: 176.4138 - ca3-[0,5]: 23.3802 - ca3-[6,11]: 1.7560 - ca3-[12,17]: 20.6098 - ca3-[18,23]: 125.2063 - ca4-[0,5]: 11.0061 - ca4-[6,11]: 22.4924 - ca4-[12,17]: 44.1017 - ca4-[18,23]: 156.4291 - val_ca1-[0,5]: 21.4778 - val_ca1-[6,11]: 20.6676 - val_ca1-[12,17]: 117.7065 - val_ca1-[18,23]: 323.3974 - val_ca2-[0,5]: 71.2596 - val_ca2-[6,11]: 17.5951 - val_ca2-[12,17]: 51.6826 - val_ca2-[18,23]: 198.6732 - val_ca3-[0,5]: 51.1354 - val_ca3-[6,11]: 14.8290 - val_ca3-[12,17]: 69.5909 - val_ca3-[18,23]: 235.8596 - val_ca4-[0,5]: 67.9178 - val_ca4-[6,11]: 16.9282 - val_ca4-[12,17]: 54.2016 - val_ca4-[18,23]: 204.1628\n",
      "Epoch 55/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 20.4550 - ca1-[6,11]: 18.9333 - ca1-[12,17]: 101.0710 - ca1-[18,23]: 315.8537 - ca2-[0,5]: 73.3833 - ca2-[6,11]: 15.9716 - ca2-[12,17]: 77.1093 - ca2-[18,23]: 174.8476 - ca3-[0,5]: 25.7621 - ca3-[6,11]: 1.5374 - ca3-[12,17]: 18.4432 - ca3-[18,23]: 121.3507 - ca4-[0,5]: 11.4078 - ca4-[6,11]: 24.7794 - ca4-[12,17]: 44.5579 - ca4-[18,23]: 161.8969 - val_ca1-[0,5]: 22.4203 - val_ca1-[6,11]: 20.1075 - val_ca1-[12,17]: 115.3567 - val_ca1-[18,23]: 318.6959 - val_ca2-[0,5]: 74.1986 - val_ca2-[6,11]: 18.2376 - val_ca2-[12,17]: 49.5899 - val_ca2-[18,23]: 193.4468 - val_ca3-[0,5]: 53.2495 - val_ca3-[6,11]: 14.9584 - val_ca3-[12,17]: 67.3562 - val_ca3-[18,23]: 230.8047 - val_ca4-[0,5]: 70.7896 - val_ca4-[6,11]: 17.4971 - val_ca4-[12,17]: 52.0277 - val_ca4-[18,23]: 198.8433\n",
      "Epoch 56/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 21.2621 - ca1-[6,11]: 17.6886 - ca1-[12,17]: 96.7420 - ca1-[18,23]: 312.2193 - ca2-[0,5]: 77.0276 - ca2-[6,11]: 16.4970 - ca2-[12,17]: 73.9751 - ca2-[18,23]: 164.0661 - ca3-[0,5]: 25.5509 - ca3-[6,11]: 1.2469 - ca3-[12,17]: 18.4536 - ca3-[18,23]: 120.5788 - ca4-[0,5]: 11.8365 - ca4-[6,11]: 24.0747 - ca4-[12,17]: 41.7139 - ca4-[18,23]: 147.2135 - val_ca1-[0,5]: 23.3815 - val_ca1-[6,11]: 19.5797 - val_ca1-[12,17]: 113.0555 - val_ca1-[18,23]: 314.7439 - val_ca2-[0,5]: 77.2061 - val_ca2-[6,11]: 18.9457 - val_ca2-[12,17]: 47.5592 - val_ca2-[18,23]: 188.8667 - val_ca3-[0,5]: 55.4089 - val_ca3-[6,11]: 15.1357 - val_ca3-[12,17]: 65.1729 - val_ca3-[18,23]: 226.4238 - val_ca4-[0,5]: 73.7203 - val_ca4-[6,11]: 18.1296 - val_ca4-[12,17]: 49.9230 - val_ca4-[18,23]: 194.1907\n",
      "Epoch 57/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 22.3326 - ca1-[6,11]: 16.7249 - ca1-[12,17]: 96.3650 - ca1-[18,23]: 308.2261 - ca2-[0,5]: 79.6256 - ca2-[6,11]: 17.7102 - ca2-[12,17]: 71.4378 - ca2-[18,23]: 162.2704 - ca3-[0,5]: 28.1559 - ca3-[6,11]: 1.1633 - ca3-[12,17]: 17.0710 - ca3-[18,23]: 117.2318 - ca4-[0,5]: 12.2966 - ca4-[6,11]: 26.1197 - ca4-[12,17]: 41.4140 - ca4-[18,23]: 153.7193 - val_ca1-[0,5]: 24.3697 - val_ca1-[6,11]: 19.0793 - val_ca1-[12,17]: 110.1759 - val_ca1-[18,23]: 310.8199 - val_ca2-[0,5]: 80.2690 - val_ca2-[6,11]: 19.7161 - val_ca2-[12,17]: 45.2692 - val_ca2-[18,23]: 184.3649 - val_ca3-[0,5]: 57.6148 - val_ca3-[6,11]: 15.3610 - val_ca3-[12,17]: 62.6177 - val_ca3-[18,23]: 222.0940 - val_ca4-[0,5]: 76.7124 - val_ca4-[6,11]: 18.8261 - val_ca4-[12,17]: 47.5419 - val_ca4-[18,23]: 189.6074\n",
      "Epoch 58/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 23.1878 - ca1-[6,11]: 17.0778 - ca1-[12,17]: 93.4594 - ca1-[18,23]: 301.8716 - ca2-[0,5]: 83.7361 - ca2-[6,11]: 18.0811 - ca2-[12,17]: 71.4241 - ca2-[18,23]: 159.9206 - ca3-[0,5]: 29.3918 - ca3-[6,11]: 0.9853 - ca3-[12,17]: 17.1140 - ca3-[18,23]: 113.7482 - ca4-[0,5]: 12.7960 - ca4-[6,11]: 27.3929 - ca4-[12,17]: 38.9929 - ca4-[18,23]: 144.9471 - val_ca1-[0,5]: 25.3818 - val_ca1-[6,11]: 18.6074 - val_ca1-[12,17]: 108.5427 - val_ca1-[18,23]: 306.9352 - val_ca2-[0,5]: 83.3988 - val_ca2-[6,11]: 20.5516 - val_ca2-[12,17]: 43.7022 - val_ca2-[18,23]: 179.9241 - val_ca3-[0,5]: 59.8650 - val_ca3-[6,11]: 15.6338 - val_ca3-[12,17]: 60.9568 - val_ca3-[18,23]: 217.8194 - val_ca4-[0,5]: 79.7756 - val_ca4-[6,11]: 19.5887 - val_ca4-[12,17]: 45.9079 - val_ca4-[18,23]: 185.0795\n",
      "Epoch 59/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 24.1769 - ca1-[6,11]: 16.6675 - ca1-[12,17]: 91.5948 - ca1-[18,23]: 299.7120 - ca2-[0,5]: 86.5640 - ca2-[6,11]: 17.7320 - ca2-[12,17]: 70.3979 - ca2-[18,23]: 154.1042 - ca3-[0,5]: 30.2786 - ca3-[6,11]: 1.0071 - ca3-[12,17]: 15.5126 - ca3-[18,23]: 109.5943 - ca4-[0,5]: 13.2812 - ca4-[6,11]: 29.7484 - ca4-[12,17]: 37.6606 - ca4-[18,23]: 138.8433 - val_ca1-[0,5]: 26.4145 - val_ca1-[6,11]: 18.1651 - val_ca1-[12,17]: 107.0596 - val_ca1-[18,23]: 303.1009 - val_ca2-[0,5]: 86.5958 - val_ca2-[6,11]: 21.4524 - val_ca2-[12,17]: 42.2112 - val_ca2-[18,23]: 175.5440 - val_ca3-[0,5]: 62.1597 - val_ca3-[6,11]: 15.9541 - val_ca3-[12,17]: 59.3927 - val_ca3-[18,23]: 213.5990 - val_ca4-[0,5]: 82.9077 - val_ca4-[6,11]: 20.4174 - val_ca4-[12,17]: 44.3535 - val_ca4-[18,23]: 180.6106\n",
      "Epoch 60/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 25.1764 - ca1-[6,11]: 16.8106 - ca1-[12,17]: 88.5786 - ca1-[18,23]: 296.8742 - ca2-[0,5]: 89.9208 - ca2-[6,11]: 18.9656 - ca2-[12,17]: 64.5130 - ca2-[18,23]: 148.9250 - ca3-[0,5]: 31.1066 - ca3-[6,11]: 1.0006 - ca3-[12,17]: 12.1679 - ca3-[18,23]: 108.0709 - ca4-[0,5]: 13.8500 - ca4-[6,11]: 30.4058 - ca4-[12,17]: 33.6320 - ca4-[18,23]: 142.4110 - val_ca1-[0,5]: 27.4707 - val_ca1-[6,11]: 17.7507 - val_ca1-[12,17]: 104.1778 - val_ca1-[18,23]: 295.5056 - val_ca2-[0,5]: 89.8556 - val_ca2-[6,11]: 22.4172 - val_ca2-[12,17]: 40.0996 - val_ca2-[18,23]: 168.3106 - val_ca3-[0,5]: 64.5085 - val_ca3-[6,11]: 16.3232 - val_ca3-[12,17]: 56.9367 - val_ca3-[18,23]: 206.2017 - val_ca4-[0,5]: 86.1097 - val_ca4-[6,11]: 21.3124 - val_ca4-[12,17]: 42.1405 - val_ca4-[18,23]: 173.2397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 26.4066 - ca1-[6,11]: 15.9568 - ca1-[12,17]: 86.2800 - ca1-[18,23]: 294.3762 - ca2-[0,5]: 93.0653 - ca2-[6,11]: 20.1884 - ca2-[12,17]: 62.7028 - ca2-[18,23]: 144.7965 - ca3-[0,5]: 35.4936 - ca3-[6,11]: 1.0961 - ca3-[12,17]: 13.1090 - ca3-[18,23]: 104.3172 - ca4-[0,5]: 9.7968 - ca4-[6,11]: 33.2162 - ca4-[12,17]: 32.6955 - ca4-[18,23]: 135.3339 - val_ca1-[0,5]: 28.5543 - val_ca1-[6,11]: 17.3625 - val_ca1-[12,17]: 102.0365 - val_ca1-[18,23]: 296.1974 - val_ca2-[0,5]: 93.1708 - val_ca2-[6,11]: 23.4438 - val_ca2-[12,17]: 38.4001 - val_ca2-[18,23]: 167.5514 - val_ca3-[0,5]: 66.9024 - val_ca3-[6,11]: 16.7398 - val_ca3-[12,17]: 54.9982 - val_ca3-[18,23]: 205.8779 - val_ca4-[0,5]: 89.3646 - val_ca4-[6,11]: 22.2690 - val_ca4-[12,17]: 40.3596 - val_ca4-[18,23]: 172.4334\n",
      "Epoch 62/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 27.3306 - ca1-[6,11]: 16.0321 - ca1-[12,17]: 87.5477 - ca1-[18,23]: 287.2597 - ca2-[0,5]: 96.3796 - ca2-[6,11]: 21.8279 - ca2-[12,17]: 63.0575 - ca2-[18,23]: 139.8606 - ca3-[0,5]: 36.0209 - ca3-[6,11]: 1.1201 - ca3-[12,17]: 13.4611 - ca3-[18,23]: 101.9220 - ca4-[0,5]: 15.0881 - ca4-[6,11]: 34.4378 - ca4-[12,17]: 30.3856 - ca4-[18,23]: 130.6827 - val_ca1-[0,5]: 29.6582 - val_ca1-[6,11]: 17.0788 - val_ca1-[12,17]: 99.9336 - val_ca1-[18,23]: 292.4691 - val_ca2-[0,5]: 96.5529 - val_ca2-[6,11]: 24.5894 - val_ca2-[12,17]: 36.7637 - val_ca2-[18,23]: 163.3710 - val_ca3-[0,5]: 69.3471 - val_ca3-[6,11]: 17.2662 - val_ca3-[12,17]: 53.1054 - val_ca3-[18,23]: 201.7865 - val_ca4-[0,5]: 92.6830 - val_ca4-[6,11]: 23.3449 - val_ca4-[12,17]: 38.6442 - val_ca4-[18,23]: 168.1664\n",
      "Epoch 63/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 28.5107 - ca1-[6,11]: 14.1363 - ca1-[12,17]: 84.2748 - ca1-[18,23]: 284.3550 - ca2-[0,5]: 99.3500 - ca2-[6,11]: 21.9942 - ca2-[12,17]: 57.1385 - ca2-[18,23]: 139.9348 - ca3-[0,5]: 35.8266 - ca3-[6,11]: 1.3169 - ca3-[12,17]: 12.1287 - ca3-[18,23]: 97.7987 - ca4-[0,5]: 15.6583 - ca4-[6,11]: 33.2438 - ca4-[12,17]: 29.8576 - ca4-[18,23]: 123.2424 - val_ca1-[0,5]: 30.7831 - val_ca1-[6,11]: 16.6708 - val_ca1-[12,17]: 98.2782 - val_ca1-[18,23]: 288.1229 - val_ca2-[0,5]: 99.9977 - val_ca2-[6,11]: 25.6907 - val_ca2-[12,17]: 35.4413 - val_ca2-[18,23]: 158.7079 - val_ca3-[0,5]: 71.8360 - val_ca3-[6,11]: 17.7171 - val_ca3-[12,17]: 51.5672 - val_ca3-[18,23]: 197.1629 - val_ca4-[0,5]: 96.0602 - val_ca4-[6,11]: 24.3736 - val_ca4-[12,17]: 37.2524 - val_ca4-[18,23]: 163.4174\n",
      "Epoch 64/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 29.7508 - ca1-[6,11]: 15.5259 - ca1-[12,17]: 81.1949 - ca1-[18,23]: 280.7190 - ca2-[0,5]: 102.3584 - ca2-[6,11]: 22.8605 - ca2-[12,17]: 61.2371 - ca2-[18,23]: 135.9191 - ca3-[0,5]: 39.7109 - ca3-[6,11]: 1.3085 - ca3-[12,17]: 11.0599 - ca3-[18,23]: 95.5116 - ca4-[0,5]: 16.3173 - ca4-[6,11]: 35.4672 - ca4-[12,17]: 28.7113 - ca4-[18,23]: 119.1243 - val_ca1-[0,5]: 31.9287 - val_ca1-[6,11]: 16.3661 - val_ca1-[12,17]: 95.8343 - val_ca1-[18,23]: 284.4828 - val_ca2-[0,5]: 103.4998 - val_ca2-[6,11]: 26.9078 - val_ca2-[12,17]: 33.6877 - val_ca2-[18,23]: 154.6700 - val_ca3-[0,5]: 74.3652 - val_ca3-[6,11]: 18.2755 - val_ca3-[12,17]: 49.4745 - val_ca3-[18,23]: 193.1888 - val_ca4-[0,5]: 99.5001 - val_ca4-[6,11]: 25.5211 - val_ca4-[12,17]: 35.4134 - val_ca4-[18,23]: 159.2930\n",
      "Epoch 65/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 30.6808 - ca1-[6,11]: 15.4007 - ca1-[12,17]: 79.8474 - ca1-[18,23]: 276.6648 - ca2-[0,5]: 106.4358 - ca2-[6,11]: 23.0403 - ca2-[12,17]: 57.8767 - ca2-[18,23]: 132.5430 - ca3-[0,5]: 41.4708 - ca3-[6,11]: 1.6599 - ca3-[12,17]: 10.4368 - ca3-[18,23]: 92.4388 - ca4-[0,5]: 14.4505 - ca4-[6,11]: 37.3749 - ca4-[12,17]: 26.2464 - ca4-[18,23]: 121.6756 - val_ca1-[0,5]: 33.0948 - val_ca1-[6,11]: 16.0884 - val_ca1-[12,17]: 93.8369 - val_ca1-[18,23]: 280.8846 - val_ca2-[0,5]: 107.0676 - val_ca2-[6,11]: 28.1895 - val_ca2-[12,17]: 32.2466 - val_ca2-[18,23]: 150.6942 - val_ca3-[0,5]: 76.9476 - val_ca3-[6,11]: 18.8829 - val_ca3-[12,17]: 47.7296 - val_ca3-[18,23]: 189.2542 - val_ca4-[0,5]: 103.0058 - val_ca4-[6,11]: 26.7336 - val_ca4-[12,17]: 33.8944 - val_ca4-[18,23]: 155.2314\n",
      "Epoch 66/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 32.0203 - ca1-[6,11]: 14.2019 - ca1-[12,17]: 75.8406 - ca1-[18,23]: 275.5078 - ca2-[0,5]: 109.4662 - ca2-[6,11]: 23.7945 - ca2-[12,17]: 51.6317 - ca2-[18,23]: 128.3088 - ca3-[0,5]: 43.3812 - ca3-[6,11]: 1.9355 - ca3-[12,17]: 9.2966 - ca3-[18,23]: 92.1849 - ca4-[0,5]: 20.3349 - ca4-[6,11]: 37.1030 - ca4-[12,17]: 23.0671 - ca4-[18,23]: 119.0930 - val_ca1-[0,5]: 34.2908 - val_ca1-[6,11]: 15.8353 - val_ca1-[12,17]: 91.8581 - val_ca1-[18,23]: 277.2993 - val_ca2-[0,5]: 110.6970 - val_ca2-[6,11]: 29.5343 - val_ca2-[12,17]: 30.8705 - val_ca2-[18,23]: 146.7851 - val_ca3-[0,5]: 79.5814 - val_ca3-[6,11]: 19.5390 - val_ca3-[12,17]: 46.0301 - val_ca3-[18,23]: 185.3618 - val_ca4-[0,5]: 106.5677 - val_ca4-[6,11]: 28.0075 - val_ca4-[12,17]: 32.4432 - val_ca4-[18,23]: 151.2432\n",
      "Epoch 67/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 32.9766 - ca1-[6,11]: 14.8816 - ca1-[12,17]: 78.5650 - ca1-[18,23]: 271.5391 - ca2-[0,5]: 113.0868 - ca2-[6,11]: 24.4625 - ca2-[12,17]: 52.7608 - ca2-[18,23]: 123.2470 - ca3-[0,5]: 46.4789 - ca3-[6,11]: 2.3557 - ca3-[12,17]: 9.9098 - ca3-[18,23]: 87.4842 - ca4-[0,5]: 18.4645 - ca4-[6,11]: 39.3993 - ca4-[12,17]: 22.5518 - ca4-[18,23]: 110.7123 - val_ca1-[0,5]: 35.4942 - val_ca1-[6,11]: 15.6112 - val_ca1-[12,17]: 89.9338 - val_ca1-[18,23]: 273.7922 - val_ca2-[0,5]: 114.3954 - val_ca2-[6,11]: 30.9451 - val_ca2-[12,17]: 29.5565 - val_ca2-[18,23]: 142.9348 - val_ca3-[0,5]: 82.2596 - val_ca3-[6,11]: 20.2420 - val_ca3-[12,17]: 44.3808 - val_ca3-[18,23]: 181.5226 - val_ca4-[0,5]: 110.2015 - val_ca4-[6,11]: 29.3484 - val_ca4-[12,17]: 31.0532 - val_ca4-[18,23]: 147.3111\n",
      "Epoch 68/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 34.0110 - ca1-[6,11]: 13.9658 - ca1-[12,17]: 74.0233 - ca1-[18,23]: 267.2561 - ca2-[0,5]: 117.3202 - ca2-[6,11]: 26.6703 - ca2-[12,17]: 49.6013 - ca2-[18,23]: 121.9321 - ca3-[0,5]: 48.5017 - ca3-[6,11]: 2.5293 - ca3-[12,17]: 8.8469 - ca3-[18,23]: 85.3432 - ca4-[0,5]: 19.2356 - ca4-[6,11]: 35.8847 - ca4-[12,17]: 21.5286 - ca4-[18,23]: 111.0458 - val_ca1-[0,5]: 36.7235 - val_ca1-[6,11]: 15.4119 - val_ca1-[12,17]: 88.0330 - val_ca1-[18,23]: 270.9549 - val_ca2-[0,5]: 118.1490 - val_ca2-[6,11]: 32.4164 - val_ca2-[12,17]: 28.3096 - val_ca2-[18,23]: 139.6850 - val_ca3-[0,5]: 84.9807 - val_ca3-[6,11]: 20.9915 - val_ca3-[12,17]: 42.7820 - val_ca3-[18,23]: 178.3059 - val_ca4-[0,5]: 113.8899 - val_ca4-[6,11]: 30.7499 - val_ca4-[12,17]: 29.7310 - val_ca4-[18,23]: 143.9857\n",
      "Epoch 69/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 35.2251 - ca1-[6,11]: 14.3548 - ca1-[12,17]: 71.7279 - ca1-[18,23]: 262.9161 - ca2-[0,5]: 120.9096 - ca2-[6,11]: 30.6755 - ca2-[12,17]: 48.8370 - ca2-[18,23]: 119.5575 - ca3-[0,5]: 50.5675 - ca3-[6,11]: 3.1552 - ca3-[12,17]: 8.3127 - ca3-[18,23]: 82.2971 - ca4-[0,5]: 20.0378 - ca4-[6,11]: 44.1210 - ca4-[12,17]: 20.5193 - ca4-[18,23]: 99.7781 - val_ca1-[0,5]: 37.9675 - val_ca1-[6,11]: 15.2390 - val_ca1-[12,17]: 86.1724 - val_ca1-[18,23]: 266.8758 - val_ca2-[0,5]: 121.9693 - val_ca2-[6,11]: 33.9528 - val_ca2-[12,17]: 27.1256 - val_ca2-[18,23]: 135.4410 - val_ca3-[0,5]: 87.7464 - val_ca3-[6,11]: 21.7877 - val_ca3-[12,17]: 41.2325 - val_ca3-[18,23]: 174.0046 - val_ca4-[0,5]: 117.6509 - val_ca4-[6,11]: 32.2189 - val_ca4-[12,17]: 28.4702 - val_ca4-[18,23]: 139.6513\n",
      "Epoch 70/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 36.6112 - ca1-[6,11]: 14.5731 - ca1-[12,17]: 72.4921 - ca1-[18,23]: 259.2423 - ca2-[0,5]: 125.6416 - ca2-[6,11]: 31.7401 - ca2-[12,17]: 46.1694 - ca2-[18,23]: 114.8957 - ca3-[0,5]: 52.6802 - ca3-[6,11]: 3.6547 - ca3-[12,17]: 7.5493 - ca3-[18,23]: 79.5528 - ca4-[0,5]: 21.1415 - ca4-[6,11]: 44.5866 - ca4-[12,17]: 19.7328 - ca4-[18,23]: 100.4138 - val_ca1-[0,5]: 39.2313 - val_ca1-[6,11]: 15.0911 - val_ca1-[12,17]: 84.3431 - val_ca1-[18,23]: 263.4814 - val_ca2-[0,5]: 125.8570 - val_ca2-[6,11]: 35.5544 - val_ca2-[12,17]: 26.0046 - val_ca2-[18,23]: 131.7854 - val_ca3-[0,5]: 90.5677 - val_ca3-[6,11]: 22.6340 - val_ca3-[12,17]: 39.7263 - val_ca3-[18,23]: 170.3086 - val_ca4-[0,5]: 121.4731 - val_ca4-[6,11]: 33.7510 - val_ca4-[12,17]: 27.2747 - val_ca4-[18,23]: 135.9166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 38.0267 - ca1-[6,11]: 13.8584 - ca1-[12,17]: 68.4629 - ca1-[18,23]: 256.0425 - ca2-[0,5]: 128.9066 - ca2-[6,11]: 32.6758 - ca2-[12,17]: 45.0047 - ca2-[18,23]: 109.7227 - ca3-[0,5]: 51.9790 - ca3-[6,11]: 4.2334 - ca3-[12,17]: 7.4127 - ca3-[18,23]: 75.1026 - ca4-[0,5]: 21.7241 - ca4-[6,11]: 44.6522 - ca4-[12,17]: 18.2266 - ca4-[18,23]: 100.2595 - val_ca1-[0,5]: 40.5187 - val_ca1-[6,11]: 14.9678 - val_ca1-[12,17]: 83.1421 - val_ca1-[18,23]: 260.1136 - val_ca2-[0,5]: 129.7998 - val_ca2-[6,11]: 37.2164 - val_ca2-[12,17]: 25.1133 - val_ca2-[18,23]: 128.2018 - val_ca3-[0,5]: 93.4284 - val_ca3-[6,11]: 23.5253 - val_ca3-[12,17]: 38.5841 - val_ca3-[18,23]: 166.6709 - val_ca4-[0,5]: 125.3510 - val_ca4-[6,11]: 35.3439 - val_ca4-[12,17]: 26.3261 - val_ca4-[18,23]: 132.2542\n",
      "Epoch 72/300\n",
      "26/26 [==============================] - 3s 124ms/step - ca1-[0,5]: 39.0996 - ca1-[6,11]: 14.3398 - ca1-[12,17]: 65.9130 - ca1-[18,23]: 252.1933 - ca2-[0,5]: 134.0189 - ca2-[6,11]: 34.0069 - ca2-[12,17]: 45.6877 - ca2-[18,23]: 107.2383 - ca3-[0,5]: 57.0411 - ca3-[6,11]: 4.8086 - ca3-[12,17]: 6.2379 - ca3-[18,23]: 73.3941 - ca4-[0,5]: 22.6104 - ca4-[6,11]: 47.6094 - ca4-[12,17]: 16.8304 - ca4-[18,23]: 98.2406 - val_ca1-[0,5]: 41.8331 - val_ca1-[6,11]: 14.8686 - val_ca1-[12,17]: 81.3500 - val_ca1-[18,23]: 256.7635 - val_ca2-[0,5]: 133.8044 - val_ca2-[6,11]: 38.9412 - val_ca2-[12,17]: 24.1079 - val_ca2-[18,23]: 124.6836 - val_ca3-[0,5]: 96.3409 - val_ca3-[6,11]: 24.4656 - val_ca3-[12,17]: 37.1625 - val_ca3-[18,23]: 163.0756 - val_ca4-[0,5]: 129.3015 - val_ca4-[6,11]: 37.0043 - val_ca4-[12,17]: 25.2440 - val_ca4-[18,23]: 128.6480\n",
      "Epoch 73/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 40.2199 - ca1-[6,11]: 14.2653 - ca1-[12,17]: 65.3971 - ca1-[18,23]: 253.7651 - ca2-[0,5]: 137.8592 - ca2-[6,11]: 34.6084 - ca2-[12,17]: 43.2592 - ca2-[18,23]: 103.4160 - ca3-[0,5]: 57.7184 - ca3-[6,11]: 5.1074 - ca3-[12,17]: 6.0200 - ca3-[18,23]: 72.5213 - ca4-[0,5]: 20.8317 - ca4-[6,11]: 51.6866 - ca4-[12,17]: 17.0400 - ca4-[18,23]: 89.4984 - val_ca1-[0,5]: 43.1647 - val_ca1-[6,11]: 14.7943 - val_ca1-[12,17]: 78.5172 - val_ca1-[18,23]: 253.4559 - val_ca2-[0,5]: 137.8766 - val_ca2-[6,11]: 40.7315 - val_ca2-[12,17]: 22.8847 - val_ca2-[18,23]: 121.2258 - val_ca3-[0,5]: 99.2979 - val_ca3-[6,11]: 25.4525 - val_ca3-[12,17]: 35.2403 - val_ca3-[18,23]: 159.5315 - val_ca4-[0,5]: 133.3163 - val_ca4-[6,11]: 38.7290 - val_ca4-[12,17]: 23.9161 - val_ca4-[18,23]: 125.1061\n",
      "Epoch 74/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 41.8584 - ca1-[6,11]: 13.0095 - ca1-[12,17]: 65.1429 - ca1-[18,23]: 247.2074 - ca2-[0,5]: 141.6536 - ca2-[6,11]: 37.1308 - ca2-[12,17]: 36.7805 - ca2-[18,23]: 101.1160 - ca3-[0,5]: 56.6230 - ca3-[6,11]: 5.9250 - ca3-[12,17]: 6.6657 - ca3-[18,23]: 67.6889 - ca4-[0,5]: 18.1550 - ca4-[6,11]: 46.1927 - ca4-[12,17]: 15.9118 - ca4-[18,23]: 88.8960 - val_ca1-[0,5]: 44.5064 - val_ca1-[6,11]: 14.7446 - val_ca1-[12,17]: 77.3010 - val_ca1-[18,23]: 250.2063 - val_ca2-[0,5]: 141.9899 - val_ca2-[6,11]: 42.5753 - val_ca2-[12,17]: 22.1725 - val_ca2-[18,23]: 117.8503 - val_ca3-[0,5]: 102.3020 - val_ca3-[6,11]: 26.4868 - val_ca3-[12,17]: 34.1920 - val_ca3-[18,23]: 156.0357 - val_ca4-[0,5]: 137.3790 - val_ca4-[6,11]: 40.5108 - val_ca4-[12,17]: 23.1410 - val_ca4-[18,23]: 121.6420\n",
      "Epoch 75/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 43.1499 - ca1-[6,11]: 14.2831 - ca1-[12,17]: 63.7322 - ca1-[18,23]: 240.5758 - ca2-[0,5]: 144.7756 - ca2-[6,11]: 38.3848 - ca2-[12,17]: 37.8389 - ca2-[18,23]: 95.1547 - ca3-[0,5]: 63.9244 - ca3-[6,11]: 6.7518 - ca3-[12,17]: 5.9520 - ca3-[18,23]: 64.7615 - ca4-[0,5]: 22.6986 - ca4-[6,11]: 55.6800 - ca4-[12,17]: 13.1944 - ca4-[18,23]: 78.4651 - val_ca1-[0,5]: 45.8722 - val_ca1-[6,11]: 14.7186 - val_ca1-[12,17]: 76.1832 - val_ca1-[18,23]: 246.9796 - val_ca2-[0,5]: 146.1593 - val_ca2-[6,11]: 44.4789 - val_ca2-[12,17]: 21.4814 - val_ca2-[18,23]: 114.5432 - val_ca3-[0,5]: 105.3595 - val_ca3-[6,11]: 27.5707 - val_ca3-[12,17]: 33.1856 - val_ca3-[18,23]: 152.5808 - val_ca4-[0,5]: 141.5039 - val_ca4-[6,11]: 42.3556 - val_ca4-[12,17]: 22.3904 - val_ca4-[18,23]: 118.2432\n",
      "Epoch 76/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 44.3758 - ca1-[6,11]: 14.2760 - ca1-[12,17]: 60.7881 - ca1-[18,23]: 242.4562 - ca2-[0,5]: 150.0791 - ca2-[6,11]: 40.5590 - ca2-[12,17]: 39.4270 - ca2-[18,23]: 91.6997 - ca3-[0,5]: 66.3138 - ca3-[6,11]: 7.4056 - ca3-[12,17]: 5.2925 - ca3-[18,23]: 65.1365 - ca4-[0,5]: 26.4334 - ca4-[6,11]: 57.1869 - ca4-[12,17]: 13.5378 - ca4-[18,23]: 80.2156 - val_ca1-[0,5]: 47.2738 - val_ca1-[6,11]: 14.7165 - val_ca1-[12,17]: 73.9434 - val_ca1-[18,23]: 239.7059 - val_ca2-[0,5]: 150.4008 - val_ca2-[6,11]: 46.4498 - val_ca2-[12,17]: 20.6441 - val_ca2-[18,23]: 108.4573 - val_ca3-[0,5]: 108.4620 - val_ca3-[6,11]: 28.7014 - val_ca3-[12,17]: 31.7075 - val_ca3-[18,23]: 145.9324 - val_ca4-[0,5]: 145.7054 - val_ca4-[6,11]: 44.2700 - val_ca4-[12,17]: 21.4606 - val_ca4-[18,23]: 112.0204\n",
      "Epoch 77/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 45.7508 - ca1-[6,11]: 13.9306 - ca1-[12,17]: 59.3488 - ca1-[18,23]: 235.1513 - ca2-[0,5]: 154.2226 - ca2-[6,11]: 41.7571 - ca2-[12,17]: 40.9908 - ca2-[18,23]: 90.3351 - ca3-[0,5]: 68.7448 - ca3-[6,11]: 8.1947 - ca3-[12,17]: 5.7354 - ca3-[18,23]: 59.5352 - ca4-[0,5]: 26.8727 - ca4-[6,11]: 59.2748 - ca4-[12,17]: 13.0026 - ca4-[18,23]: 82.8324 - val_ca1-[0,5]: 48.6718 - val_ca1-[6,11]: 14.7378 - val_ca1-[12,17]: 72.3250 - val_ca1-[18,23]: 240.6043 - val_ca2-[0,5]: 154.7233 - val_ca2-[6,11]: 48.4924 - val_ca2-[12,17]: 19.9712 - val_ca2-[18,23]: 108.0914 - val_ca3-[0,5]: 111.6043 - val_ca3-[6,11]: 29.8767 - val_ca3-[12,17]: 30.5401 - val_ca3-[18,23]: 145.8284 - val_ca4-[0,5]: 149.9672 - val_ca4-[6,11]: 46.2468 - val_ca4-[12,17]: 20.7157 - val_ca4-[18,23]: 111.6194\n",
      "Epoch 78/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 47.1002 - ca1-[6,11]: 13.9576 - ca1-[12,17]: 56.0844 - ca1-[18,23]: 235.0862 - ca2-[0,5]: 159.4241 - ca2-[6,11]: 43.4288 - ca2-[12,17]: 35.6941 - ca2-[18,23]: 86.4713 - ca3-[0,5]: 69.8243 - ca3-[6,11]: 9.7364 - ca3-[12,17]: 5.1969 - ca3-[18,23]: 59.8469 - ca4-[0,5]: 18.2394 - ca4-[6,11]: 56.6019 - ca4-[12,17]: 12.1069 - ca4-[18,23]: 76.9300 - val_ca1-[0,5]: 50.1032 - val_ca1-[6,11]: 14.7827 - val_ca1-[12,17]: 70.7187 - val_ca1-[18,23]: 233.4643 - val_ca2-[0,5]: 159.0843 - val_ca2-[6,11]: 50.5864 - val_ca2-[12,17]: 19.3652 - val_ca2-[18,23]: 102.2140 - val_ca3-[0,5]: 114.7977 - val_ca3-[6,11]: 31.1009 - val_ca3-[12,17]: 29.4188 - val_ca3-[18,23]: 139.3461 - val_ca4-[0,5]: 154.2757 - val_ca4-[6,11]: 48.2793 - val_ca4-[12,17]: 20.0375 - val_ca4-[18,23]: 105.6175\n",
      "Epoch 79/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 48.5950 - ca1-[6,11]: 14.2495 - ca1-[12,17]: 57.4450 - ca1-[18,23]: 230.7116 - ca2-[0,5]: 162.9674 - ca2-[6,11]: 47.6364 - ca2-[12,17]: 38.7210 - ca2-[18,23]: 84.5261 - ca3-[0,5]: 71.6881 - ca3-[6,11]: 9.7997 - ca3-[12,17]: 5.0965 - ca3-[18,23]: 57.5821 - ca4-[0,5]: 29.5957 - ca4-[6,11]: 63.5950 - ca4-[12,17]: 11.2974 - ca4-[18,23]: 76.7688 - val_ca1-[0,5]: 51.5448 - val_ca1-[6,11]: 14.8505 - val_ca1-[12,17]: 69.1502 - val_ca1-[18,23]: 234.3691 - val_ca2-[0,5]: 163.5178 - val_ca2-[6,11]: 52.7481 - val_ca2-[12,17]: 18.8212 - val_ca2-[18,23]: 101.9090 - val_ca3-[0,5]: 118.0358 - val_ca3-[6,11]: 32.3715 - val_ca3-[12,17]: 28.3460 - val_ca3-[18,23]: 139.2695 - val_ca4-[0,5]: 158.6664 - val_ca4-[6,11]: 50.3844 - val_ca4-[12,17]: 19.4202 - val_ca4-[18,23]: 105.2661\n",
      "Epoch 80/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 49.9608 - ca1-[6,11]: 14.7794 - ca1-[12,17]: 54.0942 - ca1-[18,23]: 226.7354 - ca2-[0,5]: 168.2769 - ca2-[6,11]: 48.7820 - ca2-[12,17]: 33.6648 - ca2-[18,23]: 78.2856 - ca3-[0,5]: 74.1640 - ca3-[6,11]: 10.7385 - ca3-[12,17]: 4.9454 - ca3-[18,23]: 56.1266 - ca4-[0,5]: 30.7037 - ca4-[6,11]: 65.9203 - ca4-[12,17]: 11.2510 - ca4-[18,23]: 72.5469 - val_ca1-[0,5]: 53.0020 - val_ca1-[6,11]: 14.9409 - val_ca1-[12,17]: 67.6126 - val_ca1-[18,23]: 231.3159 - val_ca2-[0,5]: 168.0177 - val_ca2-[6,11]: 54.9747 - val_ca2-[12,17]: 18.3400 - val_ca2-[18,23]: 98.9072 - val_ca3-[0,5]: 121.3148 - val_ca3-[6,11]: 33.6868 - val_ca3-[12,17]: 27.3226 - val_ca3-[18,23]: 136.0688 - val_ca4-[0,5]: 163.1014 - val_ca4-[6,11]: 52.5437 - val_ca4-[12,17]: 18.8693 - val_ca4-[18,23]: 102.1921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 51.6643 - ca1-[6,11]: 14.6185 - ca1-[12,17]: 53.1815 - ca1-[18,23]: 224.0679 - ca2-[0,5]: 171.5252 - ca2-[6,11]: 49.5981 - ca2-[12,17]: 30.4826 - ca2-[18,23]: 80.5400 - ca3-[0,5]: 77.4485 - ca3-[6,11]: 12.1689 - ca3-[12,17]: 5.1288 - ca3-[18,23]: 53.5645 - ca4-[0,5]: 28.2242 - ca4-[6,11]: 63.1310 - ca4-[12,17]: 10.0476 - ca4-[18,23]: 68.5643 - val_ca1-[0,5]: 54.4572 - val_ca1-[6,11]: 15.0521 - val_ca1-[12,17]: 66.1231 - val_ca1-[18,23]: 228.9501 - val_ca2-[0,5]: 172.5611 - val_ca2-[6,11]: 57.2545 - val_ca2-[12,17]: 17.9239 - val_ca2-[18,23]: 96.4539 - val_ca3-[0,5]: 124.6527 - val_ca3-[6,11]: 35.0543 - val_ca3-[12,17]: 26.3431 - val_ca3-[18,23]: 133.4250 - val_ca4-[0,5]: 167.6012 - val_ca4-[6,11]: 54.7673 - val_ca4-[12,17]: 18.3816 - val_ca4-[18,23]: 99.6578\n",
      "Epoch 82/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 52.8104 - ca1-[6,11]: 15.0988 - ca1-[12,17]: 53.9389 - ca1-[18,23]: 220.5827 - ca2-[0,5]: 176.7770 - ca2-[6,11]: 52.2764 - ca2-[12,17]: 31.4226 - ca2-[18,23]: 75.0091 - ca3-[0,5]: 83.0512 - ca3-[6,11]: 12.5880 - ca3-[12,17]: 4.5101 - ca3-[18,23]: 50.3936 - ca4-[0,5]: 33.8795 - ca4-[6,11]: 68.9284 - ca4-[12,17]: 9.9210 - ca4-[18,23]: 62.1934 - val_ca1-[0,5]: 55.9524 - val_ca1-[6,11]: 15.1872 - val_ca1-[12,17]: 64.2093 - val_ca1-[18,23]: 225.3433 - val_ca2-[0,5]: 177.1807 - val_ca2-[6,11]: 59.6040 - val_ca2-[12,17]: 17.5245 - val_ca2-[18,23]: 93.1101 - val_ca3-[0,5]: 128.0353 - val_ca3-[6,11]: 36.4680 - val_ca3-[12,17]: 25.2370 - val_ca3-[18,23]: 129.7906 - val_ca4-[0,5]: 172.1651 - val_ca4-[6,11]: 57.0545 - val_ca4-[12,17]: 17.9001 - val_ca4-[18,23]: 96.2323\n",
      "Epoch 83/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 54.1662 - ca1-[6,11]: 14.8312 - ca1-[12,17]: 51.9673 - ca1-[18,23]: 216.1843 - ca2-[0,5]: 180.0660 - ca2-[6,11]: 54.6882 - ca2-[12,17]: 32.8534 - ca2-[18,23]: 73.9554 - ca3-[0,5]: 82.7658 - ca3-[6,11]: 13.9284 - ca3-[12,17]: 4.0075 - ca3-[18,23]: 48.4123 - ca4-[0,5]: 33.2515 - ca4-[6,11]: 73.0541 - ca4-[12,17]: 10.2083 - ca4-[18,23]: 63.9784 - val_ca1-[0,5]: 57.4722 - val_ca1-[6,11]: 15.3451 - val_ca1-[12,17]: 63.1741 - val_ca1-[18,23]: 222.3693 - val_ca2-[0,5]: 181.8604 - val_ca2-[6,11]: 62.0151 - val_ca2-[12,17]: 17.2786 - val_ca2-[18,23]: 90.3036 - val_ca3-[0,5]: 131.4643 - val_ca3-[6,11]: 37.9289 - val_ca3-[12,17]: 24.5286 - val_ca3-[18,23]: 126.7249 - val_ca4-[0,5]: 176.7919 - val_ca4-[6,11]: 59.4051 - val_ca4-[12,17]: 17.5968 - val_ca4-[18,23]: 93.3477\n",
      "Epoch 84/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 55.7958 - ca1-[6,11]: 14.9621 - ca1-[12,17]: 50.9129 - ca1-[18,23]: 218.2522 - ca2-[0,5]: 185.1184 - ca2-[6,11]: 57.8736 - ca2-[12,17]: 34.6162 - ca2-[18,23]: 71.5974 - ca3-[0,5]: 84.5277 - ca3-[6,11]: 15.1430 - ca3-[12,17]: 5.2893 - ca3-[18,23]: 45.3615 - ca4-[0,5]: 35.4159 - ca4-[6,11]: 70.0864 - ca4-[12,17]: 9.7113 - ca4-[18,23]: 60.7854 - val_ca1-[0,5]: 59.0023 - val_ca1-[6,11]: 15.5243 - val_ca1-[12,17]: 61.7442 - val_ca1-[18,23]: 219.4416 - val_ca2-[0,5]: 186.6031 - val_ca2-[6,11]: 64.4891 - val_ca2-[12,17]: 17.0507 - val_ca2-[18,23]: 87.5605 - val_ca3-[0,5]: 134.9454 - val_ca3-[6,11]: 39.4392 - val_ca3-[12,17]: 23.6916 - val_ca3-[18,23]: 123.7028 - val_ca4-[0,5]: 181.4716 - val_ca4-[6,11]: 61.8136 - val_ca4-[12,17]: 17.3002 - val_ca4-[18,23]: 90.5330\n",
      "Epoch 85/300\n",
      "26/26 [==============================] - 3s 131ms/step - ca1-[0,5]: 57.0739 - ca1-[6,11]: 14.8755 - ca1-[12,17]: 49.2489 - ca1-[18,23]: 210.9403 - ca2-[0,5]: 190.8080 - ca2-[6,11]: 58.0316 - ca2-[12,17]: 30.5744 - ca2-[18,23]: 68.6787 - ca3-[0,5]: 88.2660 - ca3-[6,11]: 16.3268 - ca3-[12,17]: 5.3781 - ca3-[18,23]: 45.9796 - ca4-[0,5]: 35.5800 - ca4-[6,11]: 74.1043 - ca4-[12,17]: 8.8047 - ca4-[18,23]: 59.6728 - val_ca1-[0,5]: 60.5543 - val_ca1-[6,11]: 15.7257 - val_ca1-[12,17]: 60.3370 - val_ca1-[18,23]: 217.1407 - val_ca2-[0,5]: 191.3981 - val_ca2-[6,11]: 67.0206 - val_ca2-[12,17]: 16.8861 - val_ca2-[18,23]: 85.3419 - val_ca3-[0,5]: 138.4697 - val_ca3-[6,11]: 40.9951 - val_ca3-[12,17]: 22.9032 - val_ca3-[18,23]: 121.2378 - val_ca4-[0,5]: 186.2257 - val_ca4-[6,11]: 64.2912 - val_ca4-[12,17]: 17.0664 - val_ca4-[18,23]: 88.2354\n",
      "Epoch 86/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 58.7682 - ca1-[6,11]: 15.7493 - ca1-[12,17]: 48.1770 - ca1-[18,23]: 209.9151 - ca2-[0,5]: 194.7053 - ca2-[6,11]: 61.6010 - ca2-[12,17]: 32.7663 - ca2-[18,23]: 64.5208 - ca3-[0,5]: 88.3997 - ca3-[6,11]: 18.6053 - ca3-[12,17]: 5.4084 - ca3-[18,23]: 43.8707 - ca4-[0,5]: 35.1462 - ca4-[6,11]: 80.0654 - ca4-[12,17]: 9.6897 - ca4-[18,23]: 50.8310 - val_ca1-[0,5]: 62.1145 - val_ca1-[6,11]: 15.9474 - val_ca1-[12,17]: 58.9645 - val_ca1-[18,23]: 213.6803 - val_ca2-[0,5]: 196.2656 - val_ca2-[6,11]: 69.6201 - val_ca2-[12,17]: 16.7842 - val_ca2-[18,23]: 82.2696 - val_ca3-[0,5]: 142.0461 - val_ca3-[6,11]: 42.6007 - val_ca3-[12,17]: 22.1613 - val_ca3-[18,23]: 117.8049 - val_ca4-[0,5]: 191.0455 - val_ca4-[6,11]: 66.8335 - val_ca4-[12,17]: 16.8960 - val_ca4-[18,23]: 85.0795\n",
      "Epoch 87/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 60.1548 - ca1-[6,11]: 15.7944 - ca1-[12,17]: 45.6485 - ca1-[18,23]: 207.1084 - ca2-[0,5]: 200.9180 - ca2-[6,11]: 60.4673 - ca2-[12,17]: 31.9168 - ca2-[18,23]: 62.3868 - ca3-[0,5]: 95.5509 - ca3-[6,11]: 18.8071 - ca3-[12,17]: 4.6649 - ca3-[18,23]: 41.3843 - ca4-[0,5]: 32.4401 - ca4-[6,11]: 84.8688 - ca4-[12,17]: 9.3879 - ca4-[18,23]: 57.0932 - val_ca1-[0,5]: 63.6998 - val_ca1-[6,11]: 16.1916 - val_ca1-[12,17]: 58.0699 - val_ca1-[18,23]: 207.0499 - val_ca2-[0,5]: 201.1987 - val_ca2-[6,11]: 72.2839 - val_ca2-[12,17]: 16.6707 - val_ca2-[18,23]: 77.3024 - val_ca3-[0,5]: 145.6604 - val_ca3-[6,11]: 44.2493 - val_ca3-[12,17]: 21.5744 - val_ca3-[18,23]: 112.0553 - val_ca4-[0,5]: 195.9296 - val_ca4-[6,11]: 69.4397 - val_ca4-[12,17]: 16.7304 - val_ca4-[18,23]: 79.9938\n",
      "Epoch 88/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 61.8467 - ca1-[6,11]: 15.9217 - ca1-[12,17]: 45.8565 - ca1-[18,23]: 204.5915 - ca2-[0,5]: 205.9186 - ca2-[6,11]: 67.3747 - ca2-[12,17]: 27.4126 - ca2-[18,23]: 57.9452 - ca3-[0,5]: 98.4791 - ca3-[6,11]: 20.3542 - ca3-[12,17]: 5.9254 - ca3-[18,23]: 38.8780 - ca4-[0,5]: 40.5811 - ca4-[6,11]: 87.2077 - ca4-[12,17]: 9.4694 - ca4-[18,23]: 50.7046 - val_ca1-[0,5]: 65.3072 - val_ca1-[6,11]: 16.4578 - val_ca1-[12,17]: 56.5981 - val_ca1-[18,23]: 208.0219 - val_ca2-[0,5]: 206.1983 - val_ca2-[6,11]: 75.0128 - val_ca2-[12,17]: 16.8651 - val_ca2-[18,23]: 77.2212 - val_ca3-[0,5]: 149.3246 - val_ca3-[6,11]: 45.9465 - val_ca3-[12,17]: 20.9939 - val_ca3-[18,23]: 112.1065 - val_ca4-[0,5]: 200.8648 - val_ca4-[6,11]: 72.1027 - val_ca4-[12,17]: 16.8480 - val_ca4-[18,23]: 79.8846\n",
      "Epoch 89/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 63.3350 - ca1-[6,11]: 15.9382 - ca1-[12,17]: 43.8196 - ca1-[18,23]: 201.8422 - ca2-[0,5]: 211.0428 - ca2-[6,11]: 66.3931 - ca2-[12,17]: 30.9007 - ca2-[18,23]: 60.7210 - ca3-[0,5]: 101.4541 - ca3-[6,11]: 21.7317 - ca3-[12,17]: 6.2993 - ca3-[18,23]: 37.5793 - ca4-[0,5]: 40.5500 - ca4-[6,11]: 89.7203 - ca4-[12,17]: 9.4227 - ca4-[18,23]: 48.2625 - val_ca1-[0,5]: 66.9333 - val_ca1-[6,11]: 16.7454 - val_ca1-[12,17]: 54.9736 - val_ca1-[18,23]: 205.2313 - val_ca2-[0,5]: 211.2418 - val_ca2-[6,11]: 77.7941 - val_ca2-[12,17]: 16.8566 - val_ca2-[18,23]: 74.8001 - val_ca3-[0,5]: 153.0311 - val_ca3-[6,11]: 47.6887 - val_ca3-[12,17]: 20.2259 - val_ca3-[18,23]: 109.3313 - val_ca4-[0,5]: 205.8634 - val_ca4-[6,11]: 74.8291 - val_ca4-[12,17]: 16.7660 - val_ca4-[18,23]: 77.3853\n",
      "Epoch 90/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 65.1020 - ca1-[6,11]: 16.3954 - ca1-[12,17]: 42.4219 - ca1-[18,23]: 199.6794 - ca2-[0,5]: 216.6394 - ca2-[6,11]: 73.9382 - ca2-[12,17]: 29.1206 - ca2-[18,23]: 54.0765 - ca3-[0,5]: 96.3604 - ca3-[6,11]: 22.5885 - ca3-[12,17]: 6.6236 - ca3-[18,23]: 37.4517 - ca4-[0,5]: 41.8559 - ca4-[6,11]: 89.8425 - ca4-[12,17]: 9.5895 - ca4-[18,23]: 46.4910 - val_ca1-[0,5]: 68.5809 - val_ca1-[6,11]: 17.0549 - val_ca1-[12,17]: 53.6893 - val_ca1-[18,23]: 202.4634 - val_ca2-[0,5]: 216.3658 - val_ca2-[6,11]: 80.6481 - val_ca2-[12,17]: 17.0070 - val_ca2-[18,23]: 72.4336 - val_ca3-[0,5]: 156.7874 - val_ca3-[6,11]: 49.4794 - val_ca3-[12,17]: 19.6754 - val_ca3-[18,23]: 106.6014 - val_ca4-[0,5]: 210.9236 - val_ca4-[6,11]: 77.6178 - val_ca4-[12,17]: 16.8493 - val_ca4-[18,23]: 74.9501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 66.8133 - ca1-[6,11]: 17.0856 - ca1-[12,17]: 41.4246 - ca1-[18,23]: 195.3131 - ca2-[0,5]: 221.2477 - ca2-[6,11]: 74.6081 - ca2-[12,17]: 29.1002 - ca2-[18,23]: 54.9661 - ca3-[0,5]: 107.5351 - ca3-[6,11]: 24.1998 - ca3-[12,17]: 6.8916 - ca3-[18,23]: 32.1213 - ca4-[0,5]: 43.1880 - ca4-[6,11]: 94.4988 - ca4-[12,17]: 9.1352 - ca4-[18,23]: 45.4627 - val_ca1-[0,5]: 70.2389 - val_ca1-[6,11]: 17.3840 - val_ca1-[12,17]: 52.4357 - val_ca1-[18,23]: 199.7364 - val_ca2-[0,5]: 221.5497 - val_ca2-[6,11]: 83.5634 - val_ca2-[12,17]: 17.2203 - val_ca2-[18,23]: 70.1316 - val_ca3-[0,5]: 160.5872 - val_ca3-[6,11]: 51.3155 - val_ca3-[12,17]: 19.1728 - val_ca3-[18,23]: 103.9217 - val_ca4-[0,5]: 216.0518 - val_ca4-[6,11]: 80.4724 - val_ca4-[12,17]: 16.9960 - val_ca4-[18,23]: 72.5759\n",
      "Epoch 92/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 68.5020 - ca1-[6,11]: 16.9622 - ca1-[12,17]: 40.3245 - ca1-[18,23]: 189.6798 - ca2-[0,5]: 224.9751 - ca2-[6,11]: 80.2246 - ca2-[12,17]: 31.1235 - ca2-[18,23]: 52.2363 - ca3-[0,5]: 110.6433 - ca3-[6,11]: 25.9251 - ca3-[12,17]: 7.2916 - ca3-[18,23]: 32.9703 - ca4-[0,5]: 39.1258 - ca4-[6,11]: 99.0126 - ca4-[12,17]: 9.2748 - ca4-[18,23]: 45.2995 - val_ca1-[0,5]: 71.9073 - val_ca1-[6,11]: 17.7930 - val_ca1-[12,17]: 51.2117 - val_ca1-[18,23]: 197.6351 - val_ca2-[0,5]: 226.7852 - val_ca2-[6,11]: 86.5639 - val_ca2-[12,17]: 17.4960 - val_ca2-[18,23]: 68.3237 - val_ca3-[0,5]: 164.4388 - val_ca3-[6,11]: 53.2407 - val_ca3-[12,17]: 18.7170 - val_ca3-[18,23]: 101.7662 - val_ca4-[0,5]: 221.2328 - val_ca4-[6,11]: 83.4140 - val_ca4-[12,17]: 17.2055 - val_ca4-[18,23]: 70.7004\n",
      "Epoch 93/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 70.2008 - ca1-[6,11]: 18.0222 - ca1-[12,17]: 38.6192 - ca1-[18,23]: 189.6037 - ca2-[0,5]: 231.2043 - ca2-[6,11]: 81.3454 - ca2-[12,17]: 30.4932 - ca2-[18,23]: 48.9407 - ca3-[0,5]: 110.3183 - ca3-[6,11]: 25.3270 - ca3-[12,17]: 7.7828 - ca3-[18,23]: 31.6774 - ca4-[0,5]: 49.3741 - ca4-[6,11]: 93.6787 - ca4-[12,17]: 9.2805 - ca4-[18,23]: 42.4520 - val_ca1-[0,5]: 73.5987 - val_ca1-[6,11]: 18.1024 - val_ca1-[12,17]: 50.0080 - val_ca1-[18,23]: 194.9638 - val_ca2-[0,5]: 232.0784 - val_ca2-[6,11]: 89.5670 - val_ca2-[12,17]: 17.8342 - val_ca2-[18,23]: 66.1502 - val_ca3-[0,5]: 168.3407 - val_ca3-[6,11]: 55.1357 - val_ca3-[12,17]: 18.3081 - val_ca3-[18,23]: 99.1723 - val_ca4-[0,5]: 226.4643 - val_ca4-[6,11]: 86.3523 - val_ca4-[12,17]: 17.4774 - val_ca4-[18,23]: 68.4583\n",
      "Epoch 94/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 71.7836 - ca1-[6,11]: 18.2806 - ca1-[12,17]: 41.6295 - ca1-[18,23]: 187.7632 - ca2-[0,5]: 238.1600 - ca2-[6,11]: 80.0240 - ca2-[12,17]: 30.3929 - ca2-[18,23]: 45.2433 - ca3-[0,5]: 113.4803 - ca3-[6,11]: 29.3012 - ca3-[12,17]: 8.1290 - ca3-[18,23]: 30.2434 - ca4-[0,5]: 53.6111 - ca4-[6,11]: 108.1284 - ca4-[12,17]: 10.0192 - ca4-[18,23]: 41.5473 - val_ca1-[0,5]: 75.3102 - val_ca1-[6,11]: 18.4935 - val_ca1-[12,17]: 48.4779 - val_ca1-[18,23]: 191.7347 - val_ca2-[0,5]: 237.4387 - val_ca2-[6,11]: 92.6639 - val_ca2-[12,17]: 18.3263 - val_ca2-[18,23]: 63.6199 - val_ca3-[0,5]: 172.2832 - val_ca3-[6,11]: 57.1142 - val_ca3-[12,17]: 17.8903 - val_ca3-[18,23]: 96.1574 - val_ca4-[0,5]: 231.7649 - val_ca4-[6,11]: 89.3866 - val_ca4-[12,17]: 17.8914 - val_ca4-[18,23]: 65.8542\n",
      "Epoch 95/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 73.6285 - ca1-[6,11]: 18.7278 - ca1-[12,17]: 39.1817 - ca1-[18,23]: 186.1828 - ca2-[0,5]: 243.6611 - ca2-[6,11]: 86.5897 - ca2-[12,17]: 30.8060 - ca2-[18,23]: 48.0593 - ca3-[0,5]: 118.4624 - ca3-[6,11]: 30.9948 - ca3-[12,17]: 9.0806 - ca3-[18,23]: 28.9223 - ca4-[0,5]: 48.0398 - ca4-[6,11]: 108.5356 - ca4-[12,17]: 10.2666 - ca4-[18,23]: 37.2918 - val_ca1-[0,5]: 77.0266 - val_ca1-[6,11]: 18.9020 - val_ca1-[12,17]: 47.6773 - val_ca1-[18,23]: 189.1353 - val_ca2-[0,5]: 242.8337 - val_ca2-[6,11]: 95.8072 - val_ca2-[12,17]: 18.6968 - val_ca2-[18,23]: 61.5847 - val_ca3-[0,5]: 176.2630 - val_ca3-[6,11]: 59.1348 - val_ca3-[12,17]: 17.6345 - val_ca3-[18,23]: 93.6723 - val_ca4-[0,5]: 237.1433 - val_ca4-[6,11]: 92.4925 - val_ca4-[12,17]: 18.2118 - val_ca4-[18,23]: 63.7338\n",
      "Epoch 96/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 75.1654 - ca1-[6,11]: 18.6577 - ca1-[12,17]: 38.0661 - ca1-[18,23]: 181.4554 - ca2-[0,5]: 247.4546 - ca2-[6,11]: 89.6676 - ca2-[12,17]: 29.3611 - ca2-[18,23]: 45.0504 - ca3-[0,5]: 125.3242 - ca3-[6,11]: 31.5280 - ca3-[12,17]: 9.6311 - ca3-[18,23]: 26.3579 - ca4-[0,5]: 54.2302 - ca4-[6,11]: 110.9479 - ca4-[12,17]: 11.2317 - ca4-[18,23]: 34.9992 - val_ca1-[0,5]: 78.7655 - val_ca1-[6,11]: 19.3319 - val_ca1-[12,17]: 46.5480 - val_ca1-[18,23]: 186.5546 - val_ca2-[0,5]: 248.3036 - val_ca2-[6,11]: 99.0201 - val_ca2-[12,17]: 19.2216 - val_ca2-[18,23]: 59.6071 - val_ca3-[0,5]: 180.2853 - val_ca3-[6,11]: 61.2002 - val_ca3-[12,17]: 17.3690 - val_ca3-[18,23]: 91.2370 - val_ca4-[0,5]: 242.5715 - val_ca4-[6,11]: 95.6538 - val_ca4-[12,17]: 18.6731 - val_ca4-[18,23]: 61.6816\n",
      "Epoch 97/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 77.0769 - ca1-[6,11]: 20.0651 - ca1-[12,17]: 34.9882 - ca1-[18,23]: 179.2862 - ca2-[0,5]: 253.1221 - ca2-[6,11]: 91.8100 - ca2-[12,17]: 29.1484 - ca2-[18,23]: 43.5647 - ca3-[0,5]: 126.8478 - ca3-[6,11]: 34.0529 - ca3-[12,17]: 10.1387 - ca3-[18,23]: 25.1840 - ca4-[0,5]: 49.1383 - ca4-[6,11]: 118.8019 - ca4-[12,17]: 11.0397 - ca4-[18,23]: 33.3939 - val_ca1-[0,5]: 80.5145 - val_ca1-[6,11]: 19.7799 - val_ca1-[12,17]: 45.4466 - val_ca1-[18,23]: 184.0107 - val_ca2-[0,5]: 253.8300 - val_ca2-[6,11]: 102.2919 - val_ca2-[12,17]: 19.8082 - val_ca2-[18,23]: 57.6940 - val_ca3-[0,5]: 184.3509 - val_ca3-[6,11]: 63.3105 - val_ca3-[12,17]: 17.1507 - val_ca3-[18,23]: 88.8508 - val_ca4-[0,5]: 248.0693 - val_ca4-[6,11]: 98.8820 - val_ca4-[12,17]: 19.1980 - val_ca4-[18,23]: 59.6901\n",
      "Epoch 98/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 78.8468 - ca1-[6,11]: 20.0086 - ca1-[12,17]: 34.0656 - ca1-[18,23]: 179.2784 - ca2-[0,5]: 259.4215 - ca2-[6,11]: 95.3362 - ca2-[12,17]: 27.9210 - ca2-[18,23]: 39.4344 - ca3-[0,5]: 130.2156 - ca3-[6,11]: 35.3868 - ca3-[12,17]: 10.9152 - ca3-[18,23]: 23.5550 - ca4-[0,5]: 53.2105 - ca4-[6,11]: 111.0226 - ca4-[12,17]: 12.2028 - ca4-[18,23]: 32.0174 - val_ca1-[0,5]: 82.2686 - val_ca1-[6,11]: 20.2703 - val_ca1-[12,17]: 44.3752 - val_ca1-[18,23]: 181.5094 - val_ca2-[0,5]: 259.4234 - val_ca2-[6,11]: 105.5523 - val_ca2-[12,17]: 20.4577 - val_ca2-[18,23]: 55.8416 - val_ca3-[0,5]: 188.4778 - val_ca3-[6,11]: 65.4331 - val_ca3-[12,17]: 16.9786 - val_ca3-[18,23]: 86.5033 - val_ca4-[0,5]: 253.6266 - val_ca4-[6,11]: 102.0971 - val_ca4-[12,17]: 19.7856 - val_ca4-[18,23]: 57.7629\n",
      "Epoch 99/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 80.2058 - ca1-[6,11]: 20.8630 - ca1-[12,17]: 34.0100 - ca1-[18,23]: 174.7248 - ca2-[0,5]: 264.2285 - ca2-[6,11]: 96.4759 - ca2-[12,17]: 29.5283 - ca2-[18,23]: 37.5082 - ca3-[0,5]: 129.5410 - ca3-[6,11]: 37.8732 - ca3-[12,17]: 11.8759 - ca3-[18,23]: 22.7692 - ca4-[0,5]: 54.7458 - ca4-[6,11]: 107.2712 - ca4-[12,17]: 13.1049 - ca4-[18,23]: 30.4973 - val_ca1-[0,5]: 84.0399 - val_ca1-[6,11]: 20.7285 - val_ca1-[12,17]: 43.3261 - val_ca1-[18,23]: 179.0331 - val_ca2-[0,5]: 265.0873 - val_ca2-[6,11]: 109.0332 - val_ca2-[12,17]: 21.1706 - val_ca2-[18,23]: 54.0491 - val_ca3-[0,5]: 192.6523 - val_ca3-[6,11]: 67.6875 - val_ca3-[12,17]: 16.8537 - val_ca3-[18,23]: 84.2027 - val_ca4-[0,5]: 259.2456 - val_ca4-[6,11]: 105.5225 - val_ca4-[12,17]: 20.4362 - val_ca4-[18,23]: 55.8992\n",
      "Epoch 100/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 82.0532 - ca1-[6,11]: 21.0892 - ca1-[12,17]: 33.1082 - ca1-[18,23]: 170.8909 - ca2-[0,5]: 270.4032 - ca2-[6,11]: 104.8108 - ca2-[12,17]: 31.4816 - ca2-[18,23]: 38.4098 - ca3-[0,5]: 137.1065 - ca3-[6,11]: 40.5581 - ca3-[12,17]: 12.2686 - ca3-[18,23]: 21.6671 - ca4-[0,5]: 53.8522 - ca4-[6,11]: 123.2781 - ca4-[12,17]: 13.7928 - ca4-[18,23]: 30.3850 - val_ca1-[0,5]: 85.8301 - val_ca1-[6,11]: 21.2325 - val_ca1-[12,17]: 42.2980 - val_ca1-[18,23]: 176.5789 - val_ca2-[0,5]: 270.8007 - val_ca2-[6,11]: 112.4921 - val_ca2-[12,17]: 21.9442 - val_ca2-[18,23]: 52.3231 - val_ca3-[0,5]: 196.8721 - val_ca3-[6,11]: 69.9460 - val_ca3-[12,17]: 16.7760 - val_ca3-[18,23]: 81.9503 - val_ca4-[0,5]: 264.9239 - val_ca4-[6,11]: 108.9346 - val_ca4-[12,17]: 21.1492 - val_ca4-[18,23]: 54.0997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 83.5524 - ca1-[6,11]: 21.6203 - ca1-[12,17]: 31.1533 - ca1-[18,23]: 170.4629 - ca2-[0,5]: 276.2915 - ca2-[6,11]: 106.3053 - ca2-[12,17]: 32.0565 - ca2-[18,23]: 36.0981 - ca3-[0,5]: 142.5307 - ca3-[6,11]: 41.9779 - ca3-[12,17]: 13.3121 - ca3-[18,23]: 20.5993 - ca4-[0,5]: 65.3355 - ca4-[6,11]: 127.7580 - ca4-[12,17]: 14.5319 - ca4-[18,23]: 25.1752 - val_ca1-[0,5]: 87.6348 - val_ca1-[6,11]: 21.7550 - val_ca1-[12,17]: 40.9901 - val_ca1-[18,23]: 174.1528 - val_ca2-[0,5]: 276.5652 - val_ca2-[6,11]: 116.0064 - val_ca2-[12,17]: 22.9482 - val_ca2-[18,23]: 50.6624 - val_ca3-[0,5]: 201.1367 - val_ca3-[6,11]: 72.2502 - val_ca3-[12,17]: 16.7569 - val_ca3-[18,23]: 79.7463 - val_ca4-[0,5]: 270.6666 - val_ca4-[6,11]: 112.4106 - val_ca4-[12,17]: 22.0837 - val_ca4-[18,23]: 52.3626\n",
      "Epoch 102/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 85.4298 - ca1-[6,11]: 21.7686 - ca1-[12,17]: 32.1392 - ca1-[18,23]: 167.9337 - ca2-[0,5]: 282.5726 - ca2-[6,11]: 108.6056 - ca2-[12,17]: 30.6750 - ca2-[18,23]: 34.7710 - ca3-[0,5]: 144.1725 - ca3-[6,11]: 43.6128 - ca3-[12,17]: 14.1286 - ca3-[18,23]: 19.0206 - ca4-[0,5]: 62.1328 - ca4-[6,11]: 129.3084 - ca4-[12,17]: 15.4970 - ca4-[18,23]: 27.9280 - val_ca1-[0,5]: 89.4571 - val_ca1-[6,11]: 22.2969 - val_ca1-[12,17]: 40.3104 - val_ca1-[18,23]: 171.7501 - val_ca2-[0,5]: 282.4001 - val_ca2-[6,11]: 119.5879 - val_ca2-[12,17]: 23.6761 - val_ca2-[18,23]: 49.0616 - val_ca3-[0,5]: 205.4482 - val_ca3-[6,11]: 74.6015 - val_ca3-[12,17]: 16.7620 - val_ca3-[18,23]: 77.5893 - val_ca4-[0,5]: 276.4743 - val_ca4-[6,11]: 115.9508 - val_ca4-[12,17]: 22.7649 - val_ca4-[18,23]: 50.6880\n",
      "Epoch 103/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 87.2796 - ca1-[6,11]: 22.8664 - ca1-[12,17]: 31.6507 - ca1-[18,23]: 164.7531 - ca2-[0,5]: 287.4514 - ca2-[6,11]: 116.8476 - ca2-[12,17]: 33.1350 - ca2-[18,23]: 31.8054 - ca3-[0,5]: 147.7732 - ca3-[6,11]: 45.4220 - ca3-[12,17]: 14.3737 - ca3-[18,23]: 17.9937 - ca4-[0,5]: 63.8783 - ca4-[6,11]: 121.1592 - ca4-[12,17]: 16.1048 - ca4-[18,23]: 26.7900 - val_ca1-[0,5]: 91.2839 - val_ca1-[6,11]: 22.8541 - val_ca1-[12,17]: 39.3554 - val_ca1-[18,23]: 169.3873 - val_ca2-[0,5]: 288.3018 - val_ca2-[6,11]: 123.2344 - val_ca2-[12,17]: 24.6367 - val_ca2-[18,23]: 47.5218 - val_ca3-[0,5]: 209.8020 - val_ca3-[6,11]: 76.9972 - val_ca3-[12,17]: 16.8255 - val_ca3-[18,23]: 75.4818 - val_ca4-[0,5]: 282.3320 - val_ca4-[6,11]: 119.5460 - val_ca4-[12,17]: 23.6653 - val_ca4-[18,23]: 49.0798\n",
      "Epoch 104/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 89.4380 - ca1-[6,11]: 23.6543 - ca1-[12,17]: 28.7570 - ca1-[18,23]: 162.9193 - ca2-[0,5]: 292.9983 - ca2-[6,11]: 116.2861 - ca2-[12,17]: 32.3323 - ca2-[18,23]: 32.9000 - ca3-[0,5]: 151.4151 - ca3-[6,11]: 47.7110 - ca3-[12,17]: 15.9914 - ca3-[18,23]: 17.0161 - ca4-[0,5]: 63.3720 - ca4-[6,11]: 121.1718 - ca4-[12,17]: 17.2777 - ca4-[18,23]: 25.5249 - val_ca1-[0,5]: 93.1318 - val_ca1-[6,11]: 23.4314 - val_ca1-[12,17]: 38.4195 - val_ca1-[18,23]: 167.0428 - val_ca2-[0,5]: 294.2686 - val_ca2-[6,11]: 126.9451 - val_ca2-[12,17]: 25.6601 - val_ca2-[18,23]: 46.0437 - val_ca3-[0,5]: 214.2027 - val_ca3-[6,11]: 79.4398 - val_ca3-[12,17]: 16.9360 - val_ca3-[18,23]: 73.4214 - val_ca4-[0,5]: 288.2682 - val_ca4-[6,11]: 123.2136 - val_ca4-[12,17]: 24.6311 - val_ca4-[18,23]: 47.5304\n",
      "Epoch 105/300\n",
      "26/26 [==============================] - 3s 129ms/step - ca1-[0,5]: 90.7726 - ca1-[6,11]: 24.1704 - ca1-[12,17]: 28.9248 - ca1-[18,23]: 163.1390 - ca2-[0,5]: 301.0547 - ca2-[6,11]: 119.6984 - ca2-[12,17]: 32.7094 - ca2-[18,23]: 31.5448 - ca3-[0,5]: 150.2552 - ca3-[6,11]: 51.5968 - ca3-[12,17]: 16.4642 - ca3-[18,23]: 15.1132 - ca4-[0,5]: 70.4198 - ca4-[6,11]: 142.9147 - ca4-[12,17]: 17.7394 - ca4-[18,23]: 20.2819 - val_ca1-[0,5]: 94.9866 - val_ca1-[6,11]: 24.0951 - val_ca1-[12,17]: 37.5096 - val_ca1-[18,23]: 165.2889 - val_ca2-[0,5]: 300.2972 - val_ca2-[6,11]: 130.6410 - val_ca2-[12,17]: 26.7458 - val_ca2-[18,23]: 44.9997 - val_ca3-[0,5]: 218.6547 - val_ca3-[6,11]: 81.9043 - val_ca3-[12,17]: 17.0937 - val_ca3-[18,23]: 71.8387 - val_ca4-[0,5]: 294.2413 - val_ca4-[6,11]: 126.8547 - val_ca4-[12,17]: 25.6553 - val_ca4-[18,23]: 46.4262\n",
      "Epoch 106/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 93.1328 - ca1-[6,11]: 24.8296 - ca1-[12,17]: 27.0611 - ca1-[18,23]: 158.5744 - ca2-[0,5]: 303.8658 - ca2-[6,11]: 124.0713 - ca2-[12,17]: 35.1716 - ca2-[18,23]: 27.8703 - ca3-[0,5]: 158.8380 - ca3-[6,11]: 51.3793 - ca3-[12,17]: 18.7551 - ca3-[18,23]: 14.6950 - ca4-[0,5]: 60.9287 - ca4-[6,11]: 145.1546 - ca4-[12,17]: 19.5103 - ca4-[18,23]: 23.3865 - val_ca1-[0,5]: 96.8826 - val_ca1-[6,11]: 24.6441 - val_ca1-[12,17]: 36.6090 - val_ca1-[18,23]: 159.0465 - val_ca2-[0,5]: 306.3878 - val_ca2-[6,11]: 134.5525 - val_ca2-[12,17]: 27.8938 - val_ca2-[18,23]: 41.5891 - val_ca3-[0,5]: 223.1493 - val_ca3-[6,11]: 84.4685 - val_ca3-[12,17]: 17.2982 - val_ca3-[18,23]: 67.1925 - val_ca4-[0,5]: 300.2935 - val_ca4-[6,11]: 130.7154 - val_ca4-[12,17]: 26.7452 - val_ca4-[18,23]: 42.9049\n",
      "Epoch 107/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 94.8570 - ca1-[6,11]: 25.3264 - ca1-[12,17]: 26.8133 - ca1-[18,23]: 155.2083 - ca2-[0,5]: 311.2239 - ca2-[6,11]: 129.4113 - ca2-[12,17]: 34.4738 - ca2-[18,23]: 28.6191 - ca3-[0,5]: 162.6164 - ca3-[6,11]: 54.2099 - ca3-[12,17]: 18.4666 - ca3-[18,23]: 13.9121 - ca4-[0,5]: 71.1447 - ca4-[6,11]: 149.1792 - ca4-[12,17]: 19.5140 - ca4-[18,23]: 21.8147 - val_ca1-[0,5]: 98.7720 - val_ca1-[6,11]: 25.2747 - val_ca1-[12,17]: 35.7405 - val_ca1-[18,23]: 160.1539 - val_ca2-[0,5]: 312.5504 - val_ca2-[6,11]: 138.4557 - val_ca2-[12,17]: 29.1061 - val_ca2-[18,23]: 41.9821 - val_ca3-[0,5]: 227.6954 - val_ca3-[6,11]: 87.0546 - val_ca3-[12,17]: 17.5500 - val_ca3-[18,23]: 67.5181 - val_ca4-[0,5]: 306.4199 - val_ca4-[6,11]: 134.5727 - val_ca4-[12,17]: 27.9000 - val_ca4-[18,23]: 43.2680\n",
      "Epoch 108/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 96.5133 - ca1-[6,11]: 25.7810 - ca1-[12,17]: 26.2219 - ca1-[18,23]: 154.9440 - ca2-[0,5]: 320.7753 - ca2-[6,11]: 130.2312 - ca2-[12,17]: 35.2585 - ca2-[18,23]: 25.5749 - ca3-[0,5]: 166.4434 - ca3-[6,11]: 56.4716 - ca3-[12,17]: 20.1086 - ca3-[18,23]: 11.4756 - ca4-[0,5]: 69.6891 - ca4-[6,11]: 143.5363 - ca4-[12,17]: 21.9952 - ca4-[18,23]: 20.6514 - val_ca1-[0,5]: 100.6746 - val_ca1-[6,11]: 25.9227 - val_ca1-[12,17]: 34.8941 - val_ca1-[18,23]: 157.9164 - val_ca2-[0,5]: 318.7741 - val_ca2-[6,11]: 142.4206 - val_ca2-[12,17]: 30.3806 - val_ca2-[18,23]: 40.7522 - val_ca3-[0,5]: 232.2855 - val_ca3-[6,11]: 89.6861 - val_ca3-[12,17]: 17.8486 - val_ca3-[18,23]: 65.6451 - val_ca4-[0,5]: 312.5854 - val_ca4-[6,11]: 138.4780 - val_ca4-[12,17]: 29.1131 - val_ca4-[18,23]: 41.9750\n",
      "Epoch 109/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 98.7388 - ca1-[6,11]: 26.7926 - ca1-[12,17]: 25.9997 - ca1-[18,23]: 151.2627 - ca2-[0,5]: 324.2995 - ca2-[6,11]: 135.5949 - ca2-[12,17]: 35.2145 - ca2-[18,23]: 26.3751 - ca3-[0,5]: 159.5435 - ca3-[6,11]: 58.8486 - ca3-[12,17]: 20.7334 - ca3-[18,23]: 10.7620 - ca4-[0,5]: 74.9390 - ca4-[6,11]: 145.7419 - ca4-[12,17]: 22.8221 - ca4-[18,23]: 19.2244 - val_ca1-[0,5]: 102.5761 - val_ca1-[6,11]: 26.5827 - val_ca1-[12,17]: 34.0756 - val_ca1-[18,23]: 155.7215 - val_ca2-[0,5]: 325.0412 - val_ca2-[6,11]: 146.4357 - val_ca2-[12,17]: 31.7135 - val_ca2-[18,23]: 39.5882 - val_ca3-[0,5]: 236.9269 - val_ca3-[6,11]: 92.3670 - val_ca3-[12,17]: 18.1946 - val_ca3-[18,23]: 63.8174 - val_ca4-[0,5]: 318.8106 - val_ca4-[6,11]: 142.4439 - val_ca4-[12,17]: 30.3882 - val_ca4-[18,23]: 40.7452\n",
      "Epoch 110/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 99.9770 - ca1-[6,11]: 27.8003 - ca1-[12,17]: 25.7171 - ca1-[18,23]: 148.0351 - ca2-[0,5]: 331.4384 - ca2-[6,11]: 139.7730 - ca2-[12,17]: 38.6421 - ca2-[18,23]: 24.0789 - ca3-[0,5]: 163.1795 - ca3-[6,11]: 61.1345 - ca3-[12,17]: 23.2664 - ca3-[18,23]: 11.3967 - ca4-[0,5]: 76.8740 - ca4-[6,11]: 168.9782 - ca4-[12,17]: 24.6898 - ca4-[18,23]: 18.1741 - val_ca1-[0,5]: 104.4911 - val_ca1-[6,11]: 27.2598 - val_ca1-[12,17]: 33.2782 - val_ca1-[18,23]: 153.5515 - val_ca2-[0,5]: 331.3513 - val_ca2-[6,11]: 150.5006 - val_ca2-[12,17]: 33.1043 - val_ca2-[18,23]: 38.4896 - val_ca3-[0,5]: 241.6033 - val_ca3-[6,11]: 95.0881 - val_ca3-[12,17]: 18.5866 - val_ca3-[18,23]: 62.0413 - val_ca4-[0,5]: 325.0970 - val_ca4-[6,11]: 146.4716 - val_ca4-[12,17]: 31.7256 - val_ca4-[18,23]: 39.5782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 102.1958 - ca1-[6,11]: 27.6218 - ca1-[12,17]: 24.2679 - ca1-[18,23]: 146.6652 - ca2-[0,5]: 338.5552 - ca2-[6,11]: 142.7981 - ca2-[12,17]: 38.1757 - ca2-[18,23]: 24.6908 - ca3-[0,5]: 170.3827 - ca3-[6,11]: 63.8608 - ca3-[12,17]: 24.1888 - ca3-[18,23]: 9.7879 - ca4-[0,5]: 78.8469 - ca4-[6,11]: 164.4462 - ca4-[12,17]: 24.3042 - ca4-[18,23]: 18.1866 - val_ca1-[0,5]: 106.4333 - val_ca1-[6,11]: 27.9587 - val_ca1-[12,17]: 32.4962 - val_ca1-[18,23]: 151.9321 - val_ca2-[0,5]: 337.7289 - val_ca2-[6,11]: 154.6310 - val_ca2-[12,17]: 34.5582 - val_ca2-[18,23]: 37.7984 - val_ca3-[0,5]: 246.3358 - val_ca3-[6,11]: 97.8613 - val_ca3-[12,17]: 19.0263 - val_ca3-[18,23]: 60.7197 - val_ca4-[0,5]: 331.4678 - val_ca4-[6,11]: 150.5759 - val_ca4-[12,17]: 33.1304 - val_ca4-[18,23]: 38.8206\n",
      "Epoch 112/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 104.5095 - ca1-[6,11]: 28.8651 - ca1-[12,17]: 23.7705 - ca1-[18,23]: 143.9049 - ca2-[0,5]: 330.0407 - ca2-[6,11]: 146.2916 - ca2-[12,17]: 39.3375 - ca2-[18,23]: 24.5100 - ca3-[0,5]: 182.1885 - ca3-[6,11]: 65.9810 - ca3-[12,17]: 24.5944 - ca3-[18,23]: 9.4843 - ca4-[0,5]: 84.6863 - ca4-[6,11]: 170.4266 - ca4-[12,17]: 26.7601 - ca4-[18,23]: 17.0666 - val_ca1-[0,5]: 108.3910 - val_ca1-[6,11]: 28.6752 - val_ca1-[12,17]: 31.7345 - val_ca1-[18,23]: 149.2531 - val_ca2-[0,5]: 344.1857 - val_ca2-[6,11]: 158.8346 - val_ca2-[12,17]: 36.0780 - val_ca2-[18,23]: 36.4735 - val_ca3-[0,5]: 251.1060 - val_ca3-[6,11]: 100.6761 - val_ca3-[12,17]: 19.5121 - val_ca3-[18,23]: 58.6265 - val_ca4-[0,5]: 337.8885 - val_ca4-[6,11]: 154.7346 - val_ca4-[12,17]: 34.5952 - val_ca4-[18,23]: 37.4268\n",
      "Epoch 113/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 106.0959 - ca1-[6,11]: 29.5350 - ca1-[12,17]: 22.3998 - ca1-[18,23]: 143.1612 - ca2-[0,5]: 349.8902 - ca2-[6,11]: 154.2423 - ca2-[12,17]: 41.6524 - ca2-[18,23]: 23.3417 - ca3-[0,5]: 186.2349 - ca3-[6,11]: 68.8131 - ca3-[12,17]: 27.0672 - ca3-[18,23]: 8.3655 - ca4-[0,5]: 78.8716 - ca4-[6,11]: 172.7784 - ca4-[12,17]: 29.2860 - ca4-[18,23]: 17.0297 - val_ca1-[0,5]: 110.3629 - val_ca1-[6,11]: 29.4089 - val_ca1-[12,17]: 30.9934 - val_ca1-[18,23]: 147.6756 - val_ca2-[0,5]: 350.6926 - val_ca2-[6,11]: 163.0924 - val_ca2-[12,17]: 37.6572 - val_ca2-[18,23]: 35.8971 - val_ca3-[0,5]: 255.9295 - val_ca3-[6,11]: 103.5415 - val_ca3-[12,17]: 20.0455 - val_ca3-[18,23]: 57.3926 - val_ca4-[0,5]: 344.3634 - val_ca4-[6,11]: 158.9506 - val_ca4-[12,17]: 36.1205 - val_ca4-[18,23]: 36.7897\n",
      "Epoch 114/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 108.0142 - ca1-[6,11]: 30.7455 - ca1-[12,17]: 22.9438 - ca1-[18,23]: 140.1479 - ca2-[0,5]: 355.2546 - ca2-[6,11]: 156.1671 - ca2-[12,17]: 41.8499 - ca2-[18,23]: 22.6530 - ca3-[0,5]: 190.3278 - ca3-[6,11]: 71.3599 - ca3-[12,17]: 27.9160 - ca3-[18,23]: 8.2126 - ca4-[0,5]: 80.7846 - ca4-[6,11]: 180.1752 - ca4-[12,17]: 30.7224 - ca4-[18,23]: 16.6482 - val_ca1-[0,5]: 112.3413 - val_ca1-[6,11]: 30.1567 - val_ca1-[12,17]: 30.0536 - val_ca1-[18,23]: 145.0568 - val_ca2-[0,5]: 357.2822 - val_ca2-[6,11]: 167.4259 - val_ca2-[12,17]: 39.6197 - val_ca2-[18,23]: 34.7038 - val_ca3-[0,5]: 260.7991 - val_ca3-[6,11]: 106.4535 - val_ca3-[12,17]: 20.7645 - val_ca3-[18,23]: 55.3987 - val_ca4-[0,5]: 350.9046 - val_ca4-[6,11]: 163.2314 - val_ca4-[12,17]: 38.0146 - val_ca4-[18,23]: 35.5303\n",
      "Epoch 115/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 109.9341 - ca1-[6,11]: 31.4711 - ca1-[12,17]: 23.4382 - ca1-[18,23]: 137.8832 - ca2-[0,5]: 362.3372 - ca2-[6,11]: 160.7478 - ca2-[12,17]: 42.9405 - ca2-[18,23]: 21.1448 - ca3-[0,5]: 194.4683 - ca3-[6,11]: 71.6472 - ca3-[12,17]: 27.7653 - ca3-[18,23]: 7.4228 - ca4-[0,5]: 86.9887 - ca4-[6,11]: 186.8873 - ca4-[12,17]: 31.0295 - ca4-[18,23]: 15.1945 - val_ca1-[0,5]: 114.3551 - val_ca1-[6,11]: 30.9295 - val_ca1-[12,17]: 29.5703 - val_ca1-[18,23]: 142.9757 - val_ca2-[0,5]: 363.9277 - val_ca2-[6,11]: 171.8174 - val_ca2-[12,17]: 41.0105 - val_ca2-[18,23]: 33.9118 - val_ca3-[0,5]: 265.7216 - val_ca3-[6,11]: 109.4160 - val_ca3-[12,17]: 21.2538 - val_ca3-[18,23]: 53.8535 - val_ca4-[0,5]: 357.5045 - val_ca4-[6,11]: 167.5725 - val_ca4-[12,17]: 39.3599 - val_ca4-[18,23]: 34.6761\n",
      "Epoch 116/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 112.3498 - ca1-[6,11]: 32.1420 - ca1-[12,17]: 22.2304 - ca1-[18,23]: 136.2704 - ca2-[0,5]: 370.2644 - ca2-[6,11]: 161.5864 - ca2-[12,17]: 46.4191 - ca2-[18,23]: 21.4507 - ca3-[0,5]: 196.3954 - ca3-[6,11]: 76.6761 - ca3-[12,17]: 31.7458 - ca3-[18,23]: 6.0615 - ca4-[0,5]: 84.6818 - ca4-[6,11]: 186.4924 - ca4-[12,17]: 33.3153 - ca4-[18,23]: 14.7979 - val_ca1-[0,5]: 116.3451 - val_ca1-[6,11]: 31.7045 - val_ca1-[12,17]: 28.6885 - val_ca1-[18,23]: 140.9564 - val_ca2-[0,5]: 370.6400 - val_ca2-[6,11]: 176.2743 - val_ca2-[12,17]: 43.1198 - val_ca2-[18,23]: 33.1815 - val_ca3-[0,5]: 270.6872 - val_ca3-[6,11]: 112.4231 - val_ca3-[12,17]: 22.0866 - val_ca3-[18,23]: 52.3566 - val_ca4-[0,5]: 364.1566 - val_ca4-[6,11]: 171.9692 - val_ca4-[12,17]: 41.3980 - val_ca4-[18,23]: 33.8857\n",
      "Epoch 117/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 114.0026 - ca1-[6,11]: 32.9462 - ca1-[12,17]: 21.1304 - ca1-[18,23]: 133.5137 - ca2-[0,5]: 377.7469 - ca2-[6,11]: 167.6519 - ca2-[12,17]: 46.1561 - ca2-[18,23]: 19.9170 - ca3-[0,5]: 202.8878 - ca3-[6,11]: 78.9989 - ca3-[12,17]: 33.3385 - ca3-[18,23]: 6.7355 - ca4-[0,5]: 82.1030 - ca4-[6,11]: 191.0392 - ca4-[12,17]: 36.3999 - ca4-[18,23]: 14.5150 - val_ca1-[0,5]: 118.3677 - val_ca1-[6,11]: 32.5034 - val_ca1-[12,17]: 28.2395 - val_ca1-[18,23]: 135.8000 - val_ca2-[0,5]: 377.3857 - val_ca2-[6,11]: 180.7741 - val_ca2-[12,17]: 44.6059 - val_ca2-[18,23]: 31.2499 - val_ca3-[0,5]: 275.6978 - val_ca3-[6,11]: 115.4761 - val_ca3-[12,17]: 22.6496 - val_ca3-[18,23]: 49.0248 - val_ca4-[0,5]: 370.8740 - val_ca4-[6,11]: 176.4300 - val_ca4-[12,17]: 42.8436 - val_ca4-[18,23]: 31.8541\n",
      "Epoch 118/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 116.3337 - ca1-[6,11]: 34.0396 - ca1-[12,17]: 20.8634 - ca1-[18,23]: 131.7871 - ca2-[0,5]: 381.2905 - ca2-[6,11]: 173.5224 - ca2-[12,17]: 48.9437 - ca2-[18,23]: 19.8451 - ca3-[0,5]: 198.1751 - ca3-[6,11]: 80.0856 - ca3-[12,17]: 34.2826 - ca3-[18,23]: 5.8029 - ca4-[0,5]: 98.0620 - ca4-[6,11]: 185.5205 - ca4-[12,17]: 37.2337 - ca4-[18,23]: 15.1429 - val_ca1-[0,5]: 120.3929 - val_ca1-[6,11]: 33.3142 - val_ca1-[12,17]: 27.6040 - val_ca1-[18,23]: 136.9590 - val_ca2-[0,5]: 384.2145 - val_ca2-[6,11]: 185.3501 - val_ca2-[12,17]: 46.4987 - val_ca2-[18,23]: 31.9111 - val_ca3-[0,5]: 280.7516 - val_ca3-[6,11]: 118.5736 - val_ca3-[12,17]: 23.4172 - val_ca3-[18,23]: 49.5058 - val_ca4-[0,5]: 377.6482 - val_ca4-[6,11]: 180.9496 - val_ca4-[12,17]: 44.6779 - val_ca4-[18,23]: 32.4918\n",
      "Epoch 119/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 118.4700 - ca1-[6,11]: 34.4195 - ca1-[12,17]: 21.0048 - ca1-[18,23]: 130.6794 - ca2-[0,5]: 391.2685 - ca2-[6,11]: 179.9438 - ca2-[12,17]: 48.2604 - ca2-[18,23]: 18.7586 - ca3-[0,5]: 211.4793 - ca3-[6,11]: 84.4263 - ca3-[12,17]: 35.6387 - ca3-[18,23]: 5.2224 - ca4-[0,5]: 95.5600 - ca4-[6,11]: 188.1585 - ca4-[12,17]: 39.8801 - ca4-[18,23]: 15.2316 - val_ca1-[0,5]: 122.4290 - val_ca1-[6,11]: 34.1402 - val_ca1-[12,17]: 26.9887 - val_ca1-[18,23]: 135.0020 - val_ca2-[0,5]: 391.0983 - val_ca2-[6,11]: 189.9834 - val_ca2-[12,17]: 48.4515 - val_ca2-[18,23]: 31.3687 - val_ca3-[0,5]: 285.8600 - val_ca3-[6,11]: 121.7228 - val_ca3-[12,17]: 24.2330 - val_ca3-[18,23]: 48.1494 - val_ca4-[0,5]: 384.4993 - val_ca4-[6,11]: 185.5414 - val_ca4-[12,17]: 46.5785 - val_ca4-[18,23]: 31.8874\n",
      "Epoch 120/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 120.0873 - ca1-[6,11]: 35.5660 - ca1-[12,17]: 19.4626 - ca1-[18,23]: 128.4166 - ca2-[0,5]: 398.6881 - ca2-[6,11]: 183.4413 - ca2-[12,17]: 50.7107 - ca2-[18,23]: 19.1628 - ca3-[0,5]: 206.5093 - ca3-[6,11]: 86.9494 - ca3-[12,17]: 34.8721 - ca3-[18,23]: 4.9411 - ca4-[0,5]: 97.7734 - ca4-[6,11]: 206.2548 - ca4-[12,17]: 41.5989 - ca4-[18,23]: 14.9110 - val_ca1-[0,5]: 124.4700 - val_ca1-[6,11]: 34.9787 - val_ca1-[12,17]: 26.3950 - val_ca1-[18,23]: 133.0751 - val_ca2-[0,5]: 398.0508 - val_ca2-[6,11]: 194.6832 - val_ca2-[12,17]: 50.4683 - val_ca2-[18,23]: 30.8879 - val_ca3-[0,5]: 291.0161 - val_ca3-[6,11]: 124.9194 - val_ca3-[12,17]: 25.0958 - val_ca3-[18,23]: 46.8398 - val_ca4-[0,5]: 391.4002 - val_ca4-[6,11]: 190.1871 - val_ca4-[12,17]: 48.5382 - val_ca4-[18,23]: 31.3464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 122.2670 - ca1-[6,11]: 36.4996 - ca1-[12,17]: 19.3418 - ca1-[18,23]: 126.4064 - ca2-[0,5]: 404.2301 - ca2-[6,11]: 185.3821 - ca2-[12,17]: 53.3154 - ca2-[18,23]: 19.1408 - ca3-[0,5]: 220.2631 - ca3-[6,11]: 90.5103 - ca3-[12,17]: 38.4227 - ca3-[18,23]: 4.1088 - ca4-[0,5]: 98.9011 - ca4-[6,11]: 206.9458 - ca4-[12,17]: 42.7354 - ca4-[18,23]: 13.8652 - val_ca1-[0,5]: 126.5341 - val_ca1-[6,11]: 35.8372 - val_ca1-[12,17]: 25.8176 - val_ca1-[18,23]: 131.6794 - val_ca2-[0,5]: 405.0454 - val_ca2-[6,11]: 199.4316 - val_ca2-[12,17]: 52.5413 - val_ca2-[18,23]: 30.7750 - val_ca3-[0,5]: 296.2142 - val_ca3-[6,11]: 128.1600 - val_ca3-[12,17]: 26.0049 - val_ca3-[18,23]: 45.9529 - val_ca4-[0,5]: 398.3578 - val_ca4-[6,11]: 194.8912 - val_ca4-[12,17]: 50.5584 - val_ca4-[18,23]: 31.1768\n",
      "Epoch 122/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 124.3471 - ca1-[6,11]: 37.6891 - ca1-[12,17]: 19.6260 - ca1-[18,23]: 123.5938 - ca2-[0,5]: 411.3310 - ca2-[6,11]: 192.0816 - ca2-[12,17]: 55.6887 - ca2-[18,23]: 18.3431 - ca3-[0,5]: 222.3199 - ca3-[6,11]: 93.0400 - ca3-[12,17]: 38.5448 - ca3-[18,23]: 4.2279 - ca4-[0,5]: 107.5760 - ca4-[6,11]: 205.5780 - ca4-[12,17]: 45.1101 - ca4-[18,23]: 13.6229 - val_ca1-[0,5]: 128.6071 - val_ca1-[6,11]: 36.7098 - val_ca1-[12,17]: 25.2672 - val_ca1-[18,23]: 126.7246 - val_ca2-[0,5]: 412.0983 - val_ca2-[6,11]: 204.2393 - val_ca2-[12,17]: 55.1003 - val_ca2-[18,23]: 29.3314 - val_ca3-[0,5]: 301.4607 - val_ca3-[6,11]: 131.4485 - val_ca3-[12,17]: 27.2499 - val_ca3-[18,23]: 43.0043 - val_ca4-[0,5]: 405.3986 - val_ca4-[6,11]: 199.6718 - val_ca4-[12,17]: 53.0646 - val_ca4-[18,23]: 29.6351\n",
      "Epoch 123/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 125.9927 - ca1-[6,11]: 38.2080 - ca1-[12,17]: 19.0766 - ca1-[18,23]: 123.6405 - ca2-[0,5]: 418.5716 - ca2-[6,11]: 194.0771 - ca2-[12,17]: 55.8136 - ca2-[18,23]: 18.5276 - ca3-[0,5]: 229.2163 - ca3-[6,11]: 96.8968 - ca3-[12,17]: 42.2555 - ca3-[18,23]: 3.6447 - ca4-[0,5]: 104.5821 - ca4-[6,11]: 220.4311 - ca4-[12,17]: 47.7566 - ca4-[18,23]: 14.4422 - val_ca1-[0,5]: 130.6796 - val_ca1-[6,11]: 37.5922 - val_ca1-[12,17]: 24.7254 - val_ca1-[18,23]: 127.4183 - val_ca2-[0,5]: 419.1952 - val_ca2-[6,11]: 209.0967 - val_ca2-[12,17]: 56.8650 - val_ca2-[18,23]: 29.8217 - val_ca3-[0,5]: 306.7444 - val_ca3-[6,11]: 134.7778 - val_ca3-[12,17]: 27.9626 - val_ca3-[18,23]: 43.1980 - val_ca4-[0,5]: 412.5116 - val_ca4-[6,11]: 204.5217 - val_ca4-[12,17]: 54.8014 - val_ca4-[18,23]: 30.0960\n",
      "Epoch 124/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 128.1496 - ca1-[6,11]: 39.3906 - ca1-[12,17]: 18.6988 - ca1-[18,23]: 121.0574 - ca2-[0,5]: 427.4362 - ca2-[6,11]: 197.6821 - ca2-[12,17]: 58.4225 - ca2-[18,23]: 17.7193 - ca3-[0,5]: 233.7563 - ca3-[6,11]: 98.5782 - ca3-[12,17]: 44.8948 - ca3-[18,23]: 3.5404 - ca4-[0,5]: 87.5507 - ca4-[6,11]: 226.3643 - ca4-[12,17]: 49.4308 - ca4-[18,23]: 14.0611 - val_ca1-[0,5]: 132.7693 - val_ca1-[6,11]: 38.4920 - val_ca1-[12,17]: 24.2078 - val_ca1-[18,23]: 125.5813 - val_ca2-[0,5]: 426.3571 - val_ca2-[6,11]: 214.0179 - val_ca2-[12,17]: 59.1176 - val_ca2-[18,23]: 29.5900 - val_ca3-[0,5]: 312.0828 - val_ca3-[6,11]: 138.1588 - val_ca3-[12,17]: 29.0124 - val_ca3-[18,23]: 42.0776 - val_ca4-[0,5]: 419.6712 - val_ca4-[6,11]: 209.4232 - val_ca4-[12,17]: 57.0135 - val_ca4-[18,23]: 29.8043\n",
      "Epoch 125/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 130.4391 - ca1-[6,11]: 40.3642 - ca1-[12,17]: 18.3079 - ca1-[18,23]: 119.8309 - ca2-[0,5]: 432.7702 - ca2-[6,11]: 204.2098 - ca2-[12,17]: 58.2511 - ca2-[18,23]: 18.4117 - ca3-[0,5]: 238.3446 - ca3-[6,11]: 101.6525 - ca3-[12,17]: 44.5477 - ca3-[18,23]: 3.4510 - ca4-[0,5]: 102.7538 - ca4-[6,11]: 215.9525 - ca4-[12,17]: 51.1885 - ca4-[18,23]: 14.2045 - val_ca1-[0,5]: 134.9009 - val_ca1-[6,11]: 39.4198 - val_ca1-[12,17]: 23.7019 - val_ca1-[18,23]: 123.7407 - val_ca2-[0,5]: 433.5608 - val_ca2-[6,11]: 218.9870 - val_ca2-[12,17]: 61.4253 - val_ca2-[18,23]: 29.4201 - val_ca3-[0,5]: 317.4585 - val_ca3-[6,11]: 141.5806 - val_ca3-[12,17]: 30.1071 - val_ca3-[18,23]: 41.0060 - val_ca4-[0,5]: 426.8896 - val_ca4-[6,11]: 214.3847 - val_ca4-[12,17]: 59.2868 - val_ca4-[18,23]: 29.5753\n",
      "Epoch 126/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 132.6351 - ca1-[6,11]: 41.3550 - ca1-[12,17]: 17.9580 - ca1-[18,23]: 118.3598 - ca2-[0,5]: 440.0090 - ca2-[6,11]: 207.4411 - ca2-[12,17]: 60.2395 - ca2-[18,23]: 18.4794 - ca3-[0,5]: 235.0199 - ca3-[6,11]: 105.1665 - ca3-[12,17]: 47.0388 - ca3-[18,23]: 3.2207 - ca4-[0,5]: 124.1452 - ca4-[6,11]: 223.0168 - ca4-[12,17]: 53.7297 - ca4-[18,23]: 14.2748 - val_ca1-[0,5]: 137.0153 - val_ca1-[6,11]: 40.3499 - val_ca1-[12,17]: 23.2215 - val_ca1-[18,23]: 121.9472 - val_ca2-[0,5]: 440.8819 - val_ca2-[6,11]: 224.0564 - val_ca2-[12,17]: 63.8127 - val_ca2-[18,23]: 29.3108 - val_ca3-[0,5]: 322.9046 - val_ca3-[6,11]: 145.0644 - val_ca3-[12,17]: 31.2536 - val_ca3-[18,23]: 39.9768 - val_ca4-[0,5]: 434.1736 - val_ca4-[6,11]: 219.4107 - val_ca4-[12,17]: 61.6235 - val_ca4-[18,23]: 29.4085\n",
      "Epoch 127/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 134.5846 - ca1-[6,11]: 41.9098 - ca1-[12,17]: 16.6911 - ca1-[18,23]: 116.1586 - ca2-[0,5]: 446.6553 - ca2-[6,11]: 215.6139 - ca2-[12,17]: 63.7624 - ca2-[18,23]: 18.4384 - ca3-[0,5]: 239.5420 - ca3-[6,11]: 108.8539 - ca3-[12,17]: 49.0593 - ca3-[18,23]: 3.1238 - ca4-[0,5]: 94.6516 - ca4-[6,11]: 245.4389 - ca4-[12,17]: 54.0523 - ca4-[18,23]: 14.3192 - val_ca1-[0,5]: 139.1405 - val_ca1-[6,11]: 41.2944 - val_ca1-[12,17]: 22.7596 - val_ca1-[18,23]: 120.1761 - val_ca2-[0,5]: 448.2451 - val_ca2-[6,11]: 229.1740 - val_ca2-[12,17]: 66.2555 - val_ca2-[18,23]: 29.2638 - val_ca3-[0,5]: 328.3830 - val_ca3-[6,11]: 148.5857 - val_ca3-[12,17]: 32.4441 - val_ca3-[18,23]: 38.9974 - val_ca4-[0,5]: 441.5241 - val_ca4-[6,11]: 224.5021 - val_ca4-[12,17]: 64.0241 - val_ca4-[18,23]: 29.3043\n",
      "Epoch 128/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 136.8869 - ca1-[6,11]: 43.2762 - ca1-[12,17]: 17.3876 - ca1-[18,23]: 111.2286 - ca2-[0,5]: 454.8979 - ca2-[6,11]: 218.5957 - ca2-[12,17]: 66.4491 - ca2-[18,23]: 18.3471 - ca3-[0,5]: 252.3894 - ca3-[6,11]: 111.5266 - ca3-[12,17]: 52.0429 - ca3-[18,23]: 2.9714 - ca4-[0,5]: 116.4821 - ca4-[6,11]: 245.7376 - ca4-[12,17]: 57.9014 - ca4-[18,23]: 14.5977 - val_ca1-[0,5]: 141.2787 - val_ca1-[6,11]: 42.2541 - val_ca1-[12,17]: 22.3156 - val_ca1-[18,23]: 118.4254 - val_ca2-[0,5]: 455.6742 - val_ca2-[6,11]: 234.3561 - val_ca2-[12,17]: 68.7615 - val_ca2-[18,23]: 29.2785 - val_ca3-[0,5]: 333.8976 - val_ca3-[6,11]: 152.1470 - val_ca3-[12,17]: 33.6790 - val_ca3-[18,23]: 38.0667 - val_ca4-[0,5]: 448.9212 - val_ca4-[6,11]: 229.6448 - val_ca4-[12,17]: 66.4819 - val_ca4-[18,23]: 29.2625\n",
      "Epoch 129/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 138.6168 - ca1-[6,11]: 44.4817 - ca1-[12,17]: 17.2984 - ca1-[18,23]: 111.8096 - ca2-[0,5]: 461.9369 - ca2-[6,11]: 221.5652 - ca2-[12,17]: 69.1785 - ca2-[18,23]: 18.6789 - ca3-[0,5]: 251.2279 - ca3-[6,11]: 115.2009 - ca3-[12,17]: 53.8268 - ca3-[18,23]: 3.0414 - ca4-[0,5]: 125.3955 - ca4-[6,11]: 248.5663 - ca4-[12,17]: 61.7903 - ca4-[18,23]: 14.9499 - val_ca1-[0,5]: 143.4070 - val_ca1-[6,11]: 43.2185 - val_ca1-[12,17]: 21.8939 - val_ca1-[18,23]: 116.7133 - val_ca2-[0,5]: 463.1570 - val_ca2-[6,11]: 239.5944 - val_ca2-[12,17]: 71.3266 - val_ca2-[18,23]: 29.3550 - val_ca3-[0,5]: 339.4538 - val_ca3-[6,11]: 155.7519 - val_ca3-[12,17]: 34.9595 - val_ca3-[18,23]: 37.1834 - val_ca4-[0,5]: 456.3991 - val_ca4-[6,11]: 234.8628 - val_ca4-[12,17]: 69.0082 - val_ca4-[18,23]: 29.2832\n",
      "Epoch 130/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 141.2795 - ca1-[6,11]: 45.3782 - ca1-[12,17]: 16.6944 - ca1-[18,23]: 110.7286 - ca2-[0,5]: 468.3021 - ca2-[6,11]: 228.8597 - ca2-[12,17]: 70.9320 - ca2-[18,23]: 18.8789 - ca3-[0,5]: 259.3715 - ca3-[6,11]: 118.1256 - ca3-[12,17]: 54.8606 - ca3-[18,23]: 3.0350 - ca4-[0,5]: 128.0662 - ca4-[6,11]: 258.3234 - ca4-[12,17]: 64.8559 - ca4-[18,23]: 16.4312 - val_ca1-[0,5]: 145.5580 - val_ca1-[6,11]: 44.2455 - val_ca1-[12,17]: 21.4876 - val_ca1-[18,23]: 112.1342 - val_ca2-[0,5]: 470.6968 - val_ca2-[6,11]: 244.8882 - val_ca2-[12,17]: 73.9517 - val_ca2-[18,23]: 28.7208 - val_ca3-[0,5]: 345.0572 - val_ca3-[6,11]: 159.4154 - val_ca3-[12,17]: 36.2868 - val_ca3-[18,23]: 34.8949 - val_ca4-[0,5]: 463.9445 - val_ca4-[6,11]: 240.1446 - val_ca4-[12,17]: 71.5989 - val_ca4-[18,23]: 28.5603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 143.3414 - ca1-[6,11]: 46.2357 - ca1-[12,17]: 16.2933 - ca1-[18,23]: 108.9742 - ca2-[0,5]: 478.2826 - ca2-[6,11]: 233.3786 - ca2-[12,17]: 71.5805 - ca2-[18,23]: 19.5806 - ca3-[0,5]: 257.9909 - ca3-[6,11]: 121.4850 - ca3-[12,17]: 56.9791 - ca3-[18,23]: 3.0208 - ca4-[0,5]: 123.9594 - ca4-[6,11]: 244.5625 - ca4-[12,17]: 64.2507 - ca4-[18,23]: 16.1916 - val_ca1-[0,5]: 147.7258 - val_ca1-[6,11]: 45.2030 - val_ca1-[12,17]: 21.0980 - val_ca1-[18,23]: 113.3292 - val_ca2-[0,5]: 478.3019 - val_ca2-[6,11]: 250.2522 - val_ca2-[12,17]: 76.6398 - val_ca2-[18,23]: 29.6930 - val_ca3-[0,5]: 350.7183 - val_ca3-[6,11]: 163.1093 - val_ca3-[12,17]: 37.6635 - val_ca3-[18,23]: 35.5554 - val_ca4-[0,5]: 471.5279 - val_ca4-[6,11]: 245.4762 - val_ca4-[12,17]: 74.2435 - val_ca4-[18,23]: 29.5120\n",
      "Epoch 132/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 145.2058 - ca1-[6,11]: 47.6979 - ca1-[12,17]: 15.8470 - ca1-[18,23]: 108.5226 - ca2-[0,5]: 488.6211 - ca2-[6,11]: 234.1184 - ca2-[12,17]: 75.2810 - ca2-[18,23]: 19.2538 - ca3-[0,5]: 262.7137 - ca3-[6,11]: 119.4777 - ca3-[12,17]: 56.1948 - ca3-[18,23]: 3.0529 - ca4-[0,5]: 133.4782 - ca4-[6,11]: 253.9398 - ca4-[12,17]: 66.4863 - ca4-[18,23]: 16.3699 - val_ca1-[0,5]: 149.8656 - val_ca1-[6,11]: 46.1993 - val_ca1-[12,17]: 20.7326 - val_ca1-[18,23]: 112.1903 - val_ca2-[0,5]: 485.9910 - val_ca2-[6,11]: 255.6905 - val_ca2-[12,17]: 79.3976 - val_ca2-[18,23]: 30.2141 - val_ca3-[0,5]: 356.4193 - val_ca3-[6,11]: 166.8572 - val_ca3-[12,17]: 39.0852 - val_ca3-[18,23]: 35.1463 - val_ca4-[0,5]: 479.1730 - val_ca4-[6,11]: 250.8673 - val_ca4-[12,17]: 76.9502 - val_ca4-[18,23]: 29.9821\n",
      "Epoch 133/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 147.7203 - ca1-[6,11]: 48.6830 - ca1-[12,17]: 16.3265 - ca1-[18,23]: 106.4460 - ca2-[0,5]: 490.2511 - ca2-[6,11]: 247.5200 - ca2-[12,17]: 75.7910 - ca2-[18,23]: 20.3350 - ca3-[0,5]: 267.4793 - ca3-[6,11]: 128.7559 - ca3-[12,17]: 62.9884 - ca3-[18,23]: 3.2822 - ca4-[0,5]: 129.0765 - ca4-[6,11]: 268.0015 - ca4-[12,17]: 70.6961 - ca4-[18,23]: 16.9928 - val_ca1-[0,5]: 152.0442 - val_ca1-[6,11]: 47.2225 - val_ca1-[12,17]: 20.3795 - val_ca1-[18,23]: 110.0619 - val_ca2-[0,5]: 493.7250 - val_ca2-[6,11]: 261.1789 - val_ca2-[12,17]: 82.2112 - val_ca2-[18,23]: 30.2791 - val_ca3-[0,5]: 362.1695 - val_ca3-[6,11]: 170.6535 - val_ca3-[12,17]: 40.5544 - val_ca3-[18,23]: 34.1145 - val_ca4-[0,5]: 486.8894 - val_ca4-[6,11]: 256.3272 - val_ca4-[12,17]: 79.7225 - val_ca4-[18,23]: 29.9900\n",
      "Epoch 134/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 149.4285 - ca1-[6,11]: 49.5620 - ca1-[12,17]: 15.2897 - ca1-[18,23]: 103.6352 - ca2-[0,5]: 501.7963 - ca2-[6,11]: 245.7345 - ca2-[12,17]: 80.4387 - ca2-[18,23]: 20.2310 - ca3-[0,5]: 273.5976 - ca3-[6,11]: 131.6502 - ca3-[12,17]: 65.3546 - ca3-[18,23]: 3.6332 - ca4-[0,5]: 139.0043 - ca4-[6,11]: 277.5851 - ca4-[12,17]: 76.0608 - ca4-[18,23]: 18.9179 - val_ca1-[0,5]: 154.2150 - val_ca1-[6,11]: 48.2505 - val_ca1-[12,17]: 20.0189 - val_ca1-[18,23]: 108.4618 - val_ca2-[0,5]: 501.5086 - val_ca2-[6,11]: 266.7204 - val_ca2-[12,17]: 84.8526 - val_ca2-[18,23]: 30.6640 - val_ca3-[0,5]: 367.9771 - val_ca3-[6,11]: 174.5036 - val_ca3-[12,17]: 41.9084 - val_ca3-[18,23]: 33.4630 - val_ca4-[0,5]: 494.6238 - val_ca4-[6,11]: 261.8178 - val_ca4-[12,17]: 82.3143 - val_ca4-[18,23]: 30.3206\n",
      "Epoch 135/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 151.4776 - ca1-[6,11]: 50.5175 - ca1-[12,17]: 15.5220 - ca1-[18,23]: 102.8037 - ca2-[0,5]: 508.5689 - ca2-[6,11]: 258.0102 - ca2-[12,17]: 83.4070 - ca2-[18,23]: 21.4374 - ca3-[0,5]: 267.6076 - ca3-[6,11]: 134.4931 - ca3-[12,17]: 68.6626 - ca3-[18,23]: 3.8304 - ca4-[0,5]: 141.4300 - ca4-[6,11]: 281.1284 - ca4-[12,17]: 79.2290 - ca4-[18,23]: 18.1337 - val_ca1-[0,5]: 156.3970 - val_ca1-[6,11]: 49.2923 - val_ca1-[12,17]: 19.7301 - val_ca1-[18,23]: 107.3689 - val_ca2-[0,5]: 509.3543 - val_ca2-[6,11]: 272.3238 - val_ca2-[12,17]: 88.0148 - val_ca2-[18,23]: 31.3567 - val_ca3-[0,5]: 373.8116 - val_ca3-[6,11]: 178.3873 - val_ca3-[12,17]: 43.6334 - val_ca3-[18,23]: 33.1839 - val_ca4-[0,5]: 502.4325 - val_ca4-[6,11]: 267.3792 - val_ca4-[12,17]: 85.4254 - val_ca4-[18,23]: 30.9634\n",
      "Epoch 136/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 153.8050 - ca1-[6,11]: 51.5350 - ca1-[12,17]: 16.0734 - ca1-[18,23]: 100.5141 - ca2-[0,5]: 514.6449 - ca2-[6,11]: 255.1808 - ca2-[12,17]: 84.9091 - ca2-[18,23]: 21.6218 - ca3-[0,5]: 245.7561 - ca3-[6,11]: 138.3524 - ca3-[12,17]: 68.5078 - ca3-[18,23]: 3.9831 - ca4-[0,5]: 137.4068 - ca4-[6,11]: 269.5567 - ca4-[12,17]: 80.1733 - ca4-[18,23]: 19.6648 - val_ca1-[0,5]: 158.5838 - val_ca1-[6,11]: 50.3851 - val_ca1-[12,17]: 19.4311 - val_ca1-[18,23]: 105.3242 - val_ca2-[0,5]: 517.2725 - val_ca2-[6,11]: 277.9884 - val_ca2-[12,17]: 91.0133 - val_ca2-[18,23]: 31.6193 - val_ca3-[0,5]: 379.6881 - val_ca3-[6,11]: 182.3222 - val_ca3-[12,17]: 45.2391 - val_ca3-[18,23]: 32.3047 - val_ca4-[0,5]: 510.3020 - val_ca4-[6,11]: 272.9945 - val_ca4-[12,17]: 88.3717 - val_ca4-[18,23]: 31.1683\n",
      "Epoch 137/300\n",
      "26/26 [==============================] - 3s 131ms/step - ca1-[0,5]: 156.2346 - ca1-[6,11]: 52.6774 - ca1-[12,17]: 14.4829 - ca1-[18,23]: 99.1226 - ca2-[0,5]: 523.7126 - ca2-[6,11]: 267.0795 - ca2-[12,17]: 87.9760 - ca2-[18,23]: 23.1636 - ca3-[0,5]: 285.8445 - ca3-[6,11]: 142.3392 - ca3-[12,17]: 71.5283 - ca3-[18,23]: 4.3235 - ca4-[0,5]: 132.3072 - ca4-[6,11]: 292.9635 - ca4-[12,17]: 84.8686 - ca4-[18,23]: 19.9644 - val_ca1-[0,5]: 160.7997 - val_ca1-[6,11]: 51.4191 - val_ca1-[12,17]: 19.1462 - val_ca1-[18,23]: 103.7738 - val_ca2-[0,5]: 525.2504 - val_ca2-[6,11]: 283.7296 - val_ca2-[12,17]: 94.0727 - val_ca2-[18,23]: 32.1898 - val_ca3-[0,5]: 385.6085 - val_ca3-[6,11]: 186.2867 - val_ca3-[12,17]: 46.8905 - val_ca3-[18,23]: 31.7959 - val_ca4-[0,5]: 518.2381 - val_ca4-[6,11]: 278.6895 - val_ca4-[12,17]: 91.3816 - val_ca4-[18,23]: 31.6853\n",
      "Epoch 138/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 158.1490 - ca1-[6,11]: 53.7546 - ca1-[12,17]: 14.5993 - ca1-[18,23]: 97.6454 - ca2-[0,5]: 532.2890 - ca2-[6,11]: 274.4422 - ca2-[12,17]: 89.3999 - ca2-[18,23]: 22.8972 - ca3-[0,5]: 302.0091 - ca3-[6,11]: 145.5018 - ca3-[12,17]: 70.3351 - ca3-[18,23]: 4.6440 - ca4-[0,5]: 150.4018 - ca4-[6,11]: 302.2007 - ca4-[12,17]: 87.7860 - ca4-[18,23]: 22.2092 - val_ca1-[0,5]: 163.0365 - val_ca1-[6,11]: 52.5120 - val_ca1-[12,17]: 18.8767 - val_ca1-[18,23]: 102.2360 - val_ca2-[0,5]: 533.2856 - val_ca2-[6,11]: 289.5213 - val_ca2-[12,17]: 97.1922 - val_ca2-[18,23]: 32.8217 - val_ca3-[0,5]: 391.6016 - val_ca3-[6,11]: 190.3229 - val_ca3-[12,17]: 48.5960 - val_ca3-[18,23]: 31.3317 - val_ca4-[0,5]: 526.2564 - val_ca4-[6,11]: 284.4538 - val_ca4-[12,17]: 94.4612 - val_ca4-[18,23]: 32.2658\n",
      "Epoch 139/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 160.3285 - ca1-[6,11]: 54.2865 - ca1-[12,17]: 15.1883 - ca1-[18,23]: 98.9775 - ca2-[0,5]: 541.3691 - ca2-[6,11]: 278.3560 - ca2-[12,17]: 93.7693 - ca2-[18,23]: 23.4866 - ca3-[0,5]: 294.1828 - ca3-[6,11]: 149.3051 - ca3-[12,17]: 77.2750 - ca3-[18,23]: 5.1876 - ca4-[0,5]: 136.7355 - ca4-[6,11]: 300.1553 - ca4-[12,17]: 90.6728 - ca4-[18,23]: 22.7485 - val_ca1-[0,5]: 165.2375 - val_ca1-[6,11]: 53.6347 - val_ca1-[12,17]: 18.6289 - val_ca1-[18,23]: 100.7491 - val_ca2-[0,5]: 541.3769 - val_ca2-[6,11]: 295.3600 - val_ca2-[12,17]: 100.3711 - val_ca2-[18,23]: 33.5147 - val_ca3-[0,5]: 397.6260 - val_ca3-[6,11]: 194.4008 - val_ca3-[12,17]: 50.3438 - val_ca3-[18,23]: 30.9154 - val_ca4-[0,5]: 534.3076 - val_ca4-[6,11]: 290.2493 - val_ca4-[12,17]: 97.5916 - val_ca4-[18,23]: 32.9061\n",
      "Epoch 140/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 162.3933 - ca1-[6,11]: 56.4155 - ca1-[12,17]: 14.4489 - ca1-[18,23]: 94.2416 - ca2-[0,5]: 547.7530 - ca2-[6,11]: 284.7332 - ca2-[12,17]: 96.7085 - ca2-[18,23]: 24.7913 - ca3-[0,5]: 312.4763 - ca3-[6,11]: 153.4509 - ca3-[12,17]: 82.0162 - ca3-[18,23]: 5.2063 - ca4-[0,5]: 156.2789 - ca4-[6,11]: 290.2643 - ca4-[12,17]: 93.5648 - ca4-[18,23]: 23.2396 - val_ca1-[0,5]: 167.4423 - val_ca1-[6,11]: 54.7272 - val_ca1-[12,17]: 18.3976 - val_ca1-[18,23]: 99.2849 - val_ca2-[0,5]: 549.5463 - val_ca2-[6,11]: 301.2820 - val_ca2-[12,17]: 103.6181 - val_ca2-[18,23]: 34.2710 - val_ca3-[0,5]: 403.6891 - val_ca3-[6,11]: 198.5139 - val_ca3-[12,17]: 52.1359 - val_ca3-[18,23]: 30.5462 - val_ca4-[0,5]: 542.4395 - val_ca4-[6,11]: 296.1294 - val_ca4-[12,17]: 100.7913 - val_ca4-[18,23]: 33.6099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 164.9650 - ca1-[6,11]: 57.0375 - ca1-[12,17]: 14.3524 - ca1-[18,23]: 92.8745 - ca2-[0,5]: 556.4409 - ca2-[6,11]: 291.9676 - ca2-[12,17]: 97.7891 - ca2-[18,23]: 25.3372 - ca3-[0,5]: 309.9463 - ca3-[6,11]: 158.9255 - ca3-[12,17]: 80.8920 - ca3-[18,23]: 5.9617 - ca4-[0,5]: 150.5782 - ca4-[6,11]: 317.0641 - ca4-[12,17]: 95.7148 - ca4-[18,23]: 22.3276 - val_ca1-[0,5]: 169.6658 - val_ca1-[6,11]: 55.7981 - val_ca1-[12,17]: 18.1811 - val_ca1-[18,23]: 97.8337 - val_ca2-[0,5]: 557.7830 - val_ca2-[6,11]: 307.2820 - val_ca2-[12,17]: 106.9294 - val_ca2-[18,23]: 35.0896 - val_ca3-[0,5]: 409.8140 - val_ca3-[6,11]: 202.6799 - val_ca3-[12,17]: 53.9792 - val_ca3-[18,23]: 30.2229 - val_ca4-[0,5]: 550.6283 - val_ca4-[6,11]: 302.0791 - val_ca4-[12,17]: 104.0510 - val_ca4-[18,23]: 34.3753\n",
      "Epoch 142/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 166.7246 - ca1-[6,11]: 58.3453 - ca1-[12,17]: 14.2093 - ca1-[18,23]: 92.7263 - ca2-[0,5]: 564.6533 - ca2-[6,11]: 297.3298 - ca2-[12,17]: 101.2263 - ca2-[18,23]: 26.4124 - ca3-[0,5]: 320.2694 - ca3-[6,11]: 154.7994 - ca3-[12,17]: 81.9167 - ca3-[18,23]: 7.3361 - ca4-[0,5]: 147.0230 - ca4-[6,11]: 303.1627 - ca4-[12,17]: 101.0846 - ca4-[18,23]: 25.7999 - val_ca1-[0,5]: 171.8994 - val_ca1-[6,11]: 56.9206 - val_ca1-[12,17]: 17.9802 - val_ca1-[18,23]: 96.8740 - val_ca2-[0,5]: 566.0718 - val_ca2-[6,11]: 313.3254 - val_ca2-[12,17]: 110.2984 - val_ca2-[18,23]: 36.1861 - val_ca3-[0,5]: 415.9892 - val_ca3-[6,11]: 206.9000 - val_ca3-[12,17]: 55.8705 - val_ca3-[18,23]: 30.2444 - val_ca4-[0,5]: 558.8898 - val_ca4-[6,11]: 308.0880 - val_ca4-[12,17]: 107.3771 - val_ca4-[18,23]: 35.4244\n",
      "Epoch 143/300\n",
      "26/26 [==============================] - 3s 124ms/step - ca1-[0,5]: 169.0314 - ca1-[6,11]: 59.8840 - ca1-[12,17]: 14.1145 - ca1-[18,23]: 92.1616 - ca2-[0,5]: 573.6824 - ca2-[6,11]: 303.2013 - ca2-[12,17]: 104.7494 - ca2-[18,23]: 27.6274 - ca3-[0,5]: 328.5159 - ca3-[6,11]: 165.6514 - ca3-[12,17]: 87.6286 - ca3-[18,23]: 7.2289 - ca4-[0,5]: 148.5580 - ca4-[6,11]: 322.7746 - ca4-[12,17]: 103.3373 - ca4-[18,23]: 27.2589 - val_ca1-[0,5]: 174.1711 - val_ca1-[6,11]: 58.0699 - val_ca1-[12,17]: 17.7926 - val_ca1-[18,23]: 94.9687 - val_ca2-[0,5]: 574.3793 - val_ca2-[6,11]: 319.3991 - val_ca2-[12,17]: 113.7115 - val_ca2-[18,23]: 36.9054 - val_ca3-[0,5]: 422.2007 - val_ca3-[6,11]: 211.1595 - val_ca3-[12,17]: 57.8052 - val_ca3-[18,23]: 29.7167 - val_ca4-[0,5]: 567.2068 - val_ca4-[6,11]: 314.1542 - val_ca4-[12,17]: 110.7626 - val_ca4-[18,23]: 36.0938\n",
      "Epoch 144/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 171.1758 - ca1-[6,11]: 61.3893 - ca1-[12,17]: 14.0921 - ca1-[18,23]: 89.2098 - ca2-[0,5]: 583.0127 - ca2-[6,11]: 305.4288 - ca2-[12,17]: 108.3021 - ca2-[18,23]: 28.9683 - ca3-[0,5]: 322.7227 - ca3-[6,11]: 169.1756 - ca3-[12,17]: 87.7854 - ca3-[18,23]: 7.1560 - ca4-[0,5]: 168.3962 - ca4-[6,11]: 319.2890 - ca4-[12,17]: 108.4626 - ca4-[18,23]: 27.9703 - val_ca1-[0,5]: 176.4216 - val_ca1-[6,11]: 59.2159 - val_ca1-[12,17]: 17.6231 - val_ca1-[18,23]: 93.5746 - val_ca2-[0,5]: 582.7426 - val_ca2-[6,11]: 325.5299 - val_ca2-[12,17]: 117.1833 - val_ca2-[18,23]: 37.9021 - val_ca3-[0,5]: 428.4670 - val_ca3-[6,11]: 215.4714 - val_ca3-[12,17]: 59.7892 - val_ca3-[18,23]: 29.5337 - val_ca4-[0,5]: 575.5699 - val_ca4-[6,11]: 320.2708 - val_ca4-[12,17]: 114.2035 - val_ca4-[18,23]: 37.0440\n",
      "Epoch 145/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 173.8957 - ca1-[6,11]: 62.0763 - ca1-[12,17]: 13.7092 - ca1-[18,23]: 89.0011 - ca2-[0,5]: 591.5382 - ca2-[6,11]: 312.7404 - ca2-[12,17]: 111.2663 - ca2-[18,23]: 30.0142 - ca3-[0,5]: 336.5134 - ca3-[6,11]: 172.9116 - ca3-[12,17]: 95.7101 - ca3-[18,23]: 8.6662 - ca4-[0,5]: 162.0041 - ca4-[6,11]: 340.5584 - ca4-[12,17]: 109.0746 - ca4-[18,23]: 29.9323 - val_ca1-[0,5]: 178.6694 - val_ca1-[6,11]: 60.3678 - val_ca1-[12,17]: 17.4697 - val_ca1-[18,23]: 90.0597 - val_ca2-[0,5]: 591.2010 - val_ca2-[6,11]: 331.7471 - val_ca2-[12,17]: 120.7308 - val_ca2-[18,23]: 38.9661 - val_ca3-[0,5]: 434.7739 - val_ca3-[6,11]: 219.8257 - val_ca3-[12,17]: 61.8180 - val_ca3-[18,23]: 28.7220 - val_ca4-[0,5]: 584.0151 - val_ca4-[6,11]: 326.4644 - val_ca4-[12,17]: 117.7148 - val_ca4-[18,23]: 38.0312\n",
      "Epoch 146/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 175.3210 - ca1-[6,11]: 63.1881 - ca1-[12,17]: 14.1146 - ca1-[18,23]: 85.3555 - ca2-[0,5]: 597.4507 - ca2-[6,11]: 318.4899 - ca2-[12,17]: 115.0945 - ca2-[18,23]: 32.3429 - ca3-[0,5]: 344.9532 - ca3-[6,11]: 177.6314 - ca3-[12,17]: 96.1029 - ca3-[18,23]: 8.7989 - ca4-[0,5]: 164.9343 - ca4-[6,11]: 349.6312 - ca4-[12,17]: 113.6967 - ca4-[18,23]: 29.6820 - val_ca1-[0,5]: 180.9117 - val_ca1-[6,11]: 61.5239 - val_ca1-[12,17]: 17.3321 - val_ca1-[18,23]: 91.3292 - val_ca2-[0,5]: 599.7250 - val_ca2-[6,11]: 338.0285 - val_ca2-[12,17]: 124.3415 - val_ca2-[18,23]: 40.2890 - val_ca3-[0,5]: 441.1152 - val_ca3-[6,11]: 224.2183 - val_ca3-[12,17]: 63.8895 - val_ca3-[18,23]: 29.5920 - val_ca4-[0,5]: 592.5319 - val_ca4-[6,11]: 332.7266 - val_ca4-[12,17]: 121.2922 - val_ca4-[18,23]: 39.3402\n",
      "Epoch 147/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 178.4014 - ca1-[6,11]: 64.4920 - ca1-[12,17]: 13.5438 - ca1-[18,23]: 85.7627 - ca2-[0,5]: 606.4514 - ca2-[6,11]: 328.5287 - ca2-[12,17]: 116.9276 - ca2-[18,23]: 32.9358 - ca3-[0,5]: 350.5145 - ca3-[6,11]: 182.2481 - ca3-[12,17]: 87.1994 - ca3-[18,23]: 9.9186 - ca4-[0,5]: 167.8956 - ca4-[6,11]: 352.3293 - ca4-[12,17]: 116.6772 - ca4-[18,23]: 30.6012 - val_ca1-[0,5]: 183.1817 - val_ca1-[6,11]: 62.7014 - val_ca1-[12,17]: 17.2084 - val_ca1-[18,23]: 89.5291 - val_ca2-[0,5]: 608.3085 - val_ca2-[6,11]: 344.3701 - val_ca2-[12,17]: 128.0129 - val_ca2-[18,23]: 41.2743 - val_ca3-[0,5]: 447.5150 - val_ca3-[6,11]: 228.6657 - val_ca3-[12,17]: 66.0115 - val_ca3-[18,23]: 29.2657 - val_ca4-[0,5]: 601.1243 - val_ca4-[6,11]: 339.0611 - val_ca4-[12,17]: 124.9375 - val_ca4-[18,23]: 40.2783\n",
      "Epoch 148/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 179.9843 - ca1-[6,11]: 65.3230 - ca1-[12,17]: 13.9579 - ca1-[18,23]: 85.3750 - ca2-[0,5]: 614.6581 - ca2-[6,11]: 316.9836 - ca2-[12,17]: 121.7461 - ca2-[18,23]: 34.5847 - ca3-[0,5]: 344.1005 - ca3-[6,11]: 184.6956 - ca3-[12,17]: 98.5308 - ca3-[18,23]: 10.4878 - ca4-[0,5]: 160.7260 - ca4-[6,11]: 298.5985 - ca4-[12,17]: 119.3216 - ca4-[18,23]: 34.7022 - val_ca1-[0,5]: 185.4290 - val_ca1-[6,11]: 63.8740 - val_ca1-[12,17]: 17.1009 - val_ca1-[18,23]: 85.6932 - val_ca2-[0,5]: 616.9647 - val_ca2-[6,11]: 350.7816 - val_ca2-[12,17]: 131.7507 - val_ca2-[18,23]: 42.4343 - val_ca3-[0,5]: 453.9664 - val_ca3-[6,11]: 233.1633 - val_ca3-[12,17]: 68.1818 - val_ca3-[18,23]: 28.4127 - val_ca4-[0,5]: 609.7474 - val_ca4-[6,11]: 345.4348 - val_ca4-[12,17]: 128.6317 - val_ca4-[18,23]: 41.3577\n",
      "Epoch 149/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 182.1125 - ca1-[6,11]: 66.9632 - ca1-[12,17]: 13.5407 - ca1-[18,23]: 81.1532 - ca2-[0,5]: 623.2207 - ca2-[6,11]: 345.5130 - ca2-[12,17]: 120.6809 - ca2-[18,23]: 34.7640 - ca3-[0,5]: 364.7883 - ca3-[6,11]: 190.0246 - ca3-[12,17]: 96.3451 - ca3-[18,23]: 11.7722 - ca4-[0,5]: 168.0638 - ca4-[6,11]: 358.0177 - ca4-[12,17]: 126.1720 - ca4-[18,23]: 33.4875 - val_ca1-[0,5]: 187.6935 - val_ca1-[6,11]: 65.0623 - val_ca1-[12,17]: 17.0075 - val_ca1-[18,23]: 86.9434 - val_ca2-[0,5]: 625.6774 - val_ca2-[6,11]: 357.2507 - val_ca2-[12,17]: 135.5479 - val_ca2-[18,23]: 43.8330 - val_ca3-[0,5]: 460.4475 - val_ca3-[6,11]: 237.6956 - val_ca3-[12,17]: 70.3931 - val_ca3-[18,23]: 29.3202 - val_ca4-[0,5]: 618.4351 - val_ca4-[6,11]: 351.8720 - val_ca4-[12,17]: 132.3889 - val_ca4-[18,23]: 42.7406\n",
      "Epoch 150/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 184.4929 - ca1-[6,11]: 67.8934 - ca1-[12,17]: 14.5242 - ca1-[18,23]: 80.6103 - ca2-[0,5]: 633.1437 - ca2-[6,11]: 343.9460 - ca2-[12,17]: 126.0685 - ca2-[18,23]: 36.9490 - ca3-[0,5]: 364.4519 - ca3-[6,11]: 194.0956 - ca3-[12,17]: 92.2403 - ca3-[18,23]: 12.6426 - ca4-[0,5]: 176.9211 - ca4-[6,11]: 374.4752 - ca4-[12,17]: 130.5685 - ca4-[18,23]: 38.0570 - val_ca1-[0,5]: 189.9781 - val_ca1-[6,11]: 66.2680 - val_ca1-[12,17]: 17.0437 - val_ca1-[18,23]: 85.6677 - val_ca2-[0,5]: 634.4406 - val_ca2-[6,11]: 363.7733 - val_ca2-[12,17]: 139.1204 - val_ca2-[18,23]: 45.2027 - val_ca3-[0,5]: 466.9857 - val_ca3-[6,11]: 242.2818 - val_ca3-[12,17]: 72.4974 - val_ca3-[18,23]: 29.4175 - val_ca4-[0,5]: 627.2039 - val_ca4-[6,11]: 358.3857 - val_ca4-[12,17]: 135.9402 - val_ca4-[18,23]: 44.0679\n",
      "Epoch 151/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 187.2637 - ca1-[6,11]: 69.0785 - ca1-[12,17]: 13.8344 - ca1-[18,23]: 78.8855 - ca2-[0,5]: 642.3155 - ca2-[6,11]: 351.8886 - ca2-[12,17]: 131.8299 - ca2-[18,23]: 38.4401 - ca3-[0,5]: 357.5324 - ca3-[6,11]: 197.9513 - ca3-[12,17]: 103.8806 - ca3-[18,23]: 13.4646 - ca4-[0,5]: 179.9902 - ca4-[6,11]: 372.2607 - ca4-[12,17]: 131.0991 - ca4-[18,23]: 38.1985 - val_ca1-[0,5]: 192.2434 - val_ca1-[6,11]: 67.4700 - val_ca1-[12,17]: 16.8638 - val_ca1-[18,23]: 84.4245 - val_ca2-[0,5]: 643.2511 - val_ca2-[6,11]: 370.3468 - val_ca2-[12,17]: 143.3109 - val_ca2-[18,23]: 46.6316 - val_ca3-[0,5]: 473.5779 - val_ca3-[6,11]: 246.9200 - val_ca3-[12,17]: 74.9654 - val_ca3-[18,23]: 29.5617 - val_ca4-[0,5]: 636.0149 - val_ca4-[6,11]: 364.9467 - val_ca4-[12,17]: 140.0978 - val_ca4-[18,23]: 45.4543\n",
      "Epoch 152/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 189.6820 - ca1-[6,11]: 70.0567 - ca1-[12,17]: 14.6591 - ca1-[18,23]: 79.7845 - ca2-[0,5]: 649.7310 - ca2-[6,11]: 361.5117 - ca2-[12,17]: 135.5499 - ca2-[18,23]: 41.3803 - ca3-[0,5]: 379.0308 - ca3-[6,11]: 201.7338 - ca3-[12,17]: 113.4447 - ca3-[18,23]: 13.3842 - ca4-[0,5]: 194.0887 - ca4-[6,11]: 387.3435 - ca4-[12,17]: 138.4036 - ca4-[18,23]: 41.2025 - val_ca1-[0,5]: 194.5436 - val_ca1-[6,11]: 68.6972 - val_ca1-[12,17]: 16.8129 - val_ca1-[18,23]: 83.1839 - val_ca2-[0,5]: 652.1274 - val_ca2-[6,11]: 376.9851 - val_ca2-[12,17]: 147.2835 - val_ca2-[18,23]: 48.1226 - val_ca3-[0,5]: 480.2102 - val_ca3-[6,11]: 251.6002 - val_ca3-[12,17]: 77.3205 - val_ca3-[18,23]: 29.7525 - val_ca4-[0,5]: 644.8727 - val_ca4-[6,11]: 371.5585 - val_ca4-[12,17]: 144.0342 - val_ca4-[18,23]: 46.9002\n",
      "Epoch 153/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 191.2961 - ca1-[6,11]: 71.6478 - ca1-[12,17]: 15.1335 - ca1-[18,23]: 76.3393 - ca2-[0,5]: 660.0731 - ca2-[6,11]: 361.2378 - ca2-[12,17]: 137.7744 - ca2-[18,23]: 41.1132 - ca3-[0,5]: 355.6130 - ca3-[6,11]: 206.4545 - ca3-[12,17]: 109.9095 - ca3-[18,23]: 15.3426 - ca4-[0,5]: 186.1877 - ca4-[6,11]: 393.2301 - ca4-[12,17]: 138.8176 - ca4-[18,23]: 40.6123 - val_ca1-[0,5]: 196.8815 - val_ca1-[6,11]: 69.9512 - val_ca1-[12,17]: 16.7758 - val_ca1-[18,23]: 81.9450 - val_ca2-[0,5]: 661.0599 - val_ca2-[6,11]: 383.6807 - val_ca2-[12,17]: 151.3149 - val_ca2-[18,23]: 49.6740 - val_ca3-[0,5]: 486.8753 - val_ca3-[6,11]: 256.3172 - val_ca3-[12,17]: 79.7173 - val_ca3-[18,23]: 29.9894 - val_ca4-[0,5]: 653.8120 - val_ca4-[6,11]: 378.2466 - val_ca4-[12,17]: 148.0412 - val_ca4-[18,23]: 48.4113\n",
      "Epoch 154/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 193.3963 - ca1-[6,11]: 72.8800 - ca1-[12,17]: 14.9204 - ca1-[18,23]: 75.7596 - ca2-[0,5]: 671.2972 - ca2-[6,11]: 374.2612 - ca2-[12,17]: 142.1463 - ca2-[18,23]: 44.1726 - ca3-[0,5]: 390.7387 - ca3-[6,11]: 210.8500 - ca3-[12,17]: 110.6828 - ca3-[18,23]: 16.4212 - ca4-[0,5]: 192.3968 - ca4-[6,11]: 394.2089 - ca4-[12,17]: 145.9612 - ca4-[18,23]: 46.1502 - val_ca1-[0,5]: 199.1784 - val_ca1-[6,11]: 71.1896 - val_ca1-[12,17]: 16.7536 - val_ca1-[18,23]: 80.7491 - val_ca2-[0,5]: 670.0581 - val_ca2-[6,11]: 390.4410 - val_ca2-[12,17]: 155.4099 - val_ca2-[18,23]: 51.2876 - val_ca3-[0,5]: 493.6018 - val_ca3-[6,11]: 261.0913 - val_ca3-[12,17]: 82.1661 - val_ca3-[18,23]: 30.2735 - val_ca4-[0,5]: 662.7909 - val_ca4-[6,11]: 384.9801 - val_ca4-[12,17]: 152.1002 - val_ca4-[18,23]: 49.9805\n",
      "Epoch 155/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 196.1652 - ca1-[6,11]: 74.2749 - ca1-[12,17]: 14.7991 - ca1-[18,23]: 75.7419 - ca2-[0,5]: 681.6339 - ca2-[6,11]: 377.1948 - ca2-[12,17]: 145.4823 - ca2-[18,23]: 44.4613 - ca3-[0,5]: 396.6666 - ca3-[6,11]: 198.9525 - ca3-[12,17]: 116.5559 - ca3-[18,23]: 16.6566 - ca4-[0,5]: 192.5094 - ca4-[6,11]: 402.7072 - ca4-[12,17]: 148.4477 - ca4-[18,23]: 47.4404 - val_ca1-[0,5]: 201.4907 - val_ca1-[6,11]: 72.4427 - val_ca1-[12,17]: 16.7450 - val_ca1-[18,23]: 79.5661 - val_ca2-[0,5]: 679.1121 - val_ca2-[6,11]: 397.2585 - val_ca2-[12,17]: 159.5634 - val_ca2-[18,23]: 52.9614 - val_ca3-[0,5]: 500.3647 - val_ca3-[6,11]: 265.9048 - val_ca3-[12,17]: 84.6578 - val_ca3-[18,23]: 30.6038 - val_ca4-[0,5]: 671.8713 - val_ca4-[6,11]: 391.8051 - val_ca4-[12,17]: 156.2390 - val_ca4-[18,23]: 51.6188\n",
      "Epoch 156/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 198.0599 - ca1-[6,11]: 75.5067 - ca1-[12,17]: 14.8064 - ca1-[18,23]: 74.9677 - ca2-[0,5]: 686.7018 - ca2-[6,11]: 377.2452 - ca2-[12,17]: 150.9215 - ca2-[18,23]: 47.7641 - ca3-[0,5]: 402.6270 - ca3-[6,11]: 219.7901 - ca3-[12,17]: 117.6269 - ca3-[18,23]: 17.9775 - ca4-[0,5]: 207.6301 - ca4-[6,11]: 408.2811 - ca4-[12,17]: 151.3075 - ca4-[18,23]: 47.7088 - val_ca1-[0,5]: 203.7694 - val_ca1-[6,11]: 73.6836 - val_ca1-[12,17]: 16.8759 - val_ca1-[18,23]: 78.4204 - val_ca2-[0,5]: 688.2325 - val_ca2-[6,11]: 404.1411 - val_ca2-[12,17]: 163.6882 - val_ca2-[18,23]: 54.6976 - val_ca3-[0,5]: 507.1665 - val_ca3-[6,11]: 270.7594 - val_ca3-[12,17]: 87.1682 - val_ca3-[18,23]: 30.9801 - val_ca4-[0,5]: 680.9493 - val_ca4-[6,11]: 398.6436 - val_ca4-[12,17]: 160.3204 - val_ca4-[18,23]: 53.3072\n",
      "Epoch 157/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 201.0314 - ca1-[6,11]: 76.5425 - ca1-[12,17]: 15.0644 - ca1-[18,23]: 72.6777 - ca2-[0,5]: 698.3837 - ca2-[6,11]: 395.0903 - ca2-[12,17]: 154.1493 - ca2-[18,23]: 49.5487 - ca3-[0,5]: 408.6327 - ca3-[6,11]: 223.7233 - ca3-[12,17]: 123.5121 - ca3-[18,23]: 19.8622 - ca4-[0,5]: 190.3237 - ca4-[6,11]: 420.3973 - ca4-[12,17]: 157.4838 - ca4-[18,23]: 51.8063 - val_ca1-[0,5]: 206.0475 - val_ca1-[6,11]: 74.9303 - val_ca1-[12,17]: 16.7679 - val_ca1-[18,23]: 77.2946 - val_ca2-[0,5]: 697.4147 - val_ca2-[6,11]: 411.0854 - val_ca2-[12,17]: 168.0597 - val_ca2-[18,23]: 56.4952 - val_ca3-[0,5]: 514.0252 - val_ca3-[6,11]: 275.6679 - val_ca3-[12,17]: 89.7789 - val_ca3-[18,23]: 31.4037 - val_ca4-[0,5]: 690.1279 - val_ca4-[6,11]: 405.5733 - val_ca4-[12,17]: 164.6614 - val_ca4-[18,23]: 55.0646\n",
      "Epoch 158/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 202.8639 - ca1-[6,11]: 78.1084 - ca1-[12,17]: 14.5235 - ca1-[18,23]: 69.1996 - ca2-[0,5]: 707.8239 - ca2-[6,11]: 405.8216 - ca2-[12,17]: 158.1934 - ca2-[18,23]: 50.5340 - ca3-[0,5]: 400.5369 - ca3-[6,11]: 229.5371 - ca3-[12,17]: 134.3090 - ca3-[18,23]: 21.3757 - ca4-[0,5]: 193.5128 - ca4-[6,11]: 428.9933 - ca4-[12,17]: 159.6904 - ca4-[18,23]: 53.1740 - val_ca1-[0,5]: 208.3640 - val_ca1-[6,11]: 76.2042 - val_ca1-[12,17]: 16.8272 - val_ca1-[18,23]: 76.1691 - val_ca2-[0,5]: 706.6437 - val_ca2-[6,11]: 418.0799 - val_ca2-[12,17]: 173.2024 - val_ca2-[18,23]: 58.3512 - val_ca3-[0,5]: 520.9416 - val_ca3-[6,11]: 280.6311 - val_ca3-[12,17]: 92.9839 - val_ca3-[18,23]: 31.8746 - val_ca4-[0,5]: 699.3696 - val_ca4-[6,11]: 412.5658 - val_ca4-[12,17]: 169.7755 - val_ca4-[18,23]: 56.8843\n",
      "Epoch 159/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 205.6568 - ca1-[6,11]: 79.3481 - ca1-[12,17]: 14.8701 - ca1-[18,23]: 70.6384 - ca2-[0,5]: 716.1571 - ca2-[6,11]: 405.8927 - ca2-[12,17]: 160.6996 - ca2-[18,23]: 53.8975 - ca3-[0,5]: 374.3999 - ca3-[6,11]: 235.6097 - ca3-[12,17]: 134.6747 - ca3-[18,23]: 20.1868 - ca4-[0,5]: 209.3688 - ca4-[6,11]: 426.6319 - ca4-[12,17]: 166.8269 - ca4-[18,23]: 54.7304 - val_ca1-[0,5]: 210.6660 - val_ca1-[6,11]: 77.4768 - val_ca1-[12,17]: 16.8763 - val_ca1-[18,23]: 75.0672 - val_ca2-[0,5]: 715.9075 - val_ca2-[6,11]: 425.1157 - val_ca2-[12,17]: 177.5956 - val_ca2-[18,23]: 60.2629 - val_ca3-[0,5]: 527.9008 - val_ca3-[6,11]: 285.6381 - val_ca3-[12,17]: 95.6755 - val_ca3-[18,23]: 32.3920 - val_ca4-[0,5]: 708.6611 - val_ca4-[6,11]: 419.6110 - val_ca4-[12,17]: 174.1565 - val_ca4-[18,23]: 58.7634\n",
      "Epoch 160/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 208.0020 - ca1-[6,11]: 80.8888 - ca1-[12,17]: 15.3132 - ca1-[18,23]: 69.4195 - ca2-[0,5]: 723.0780 - ca2-[6,11]: 412.2123 - ca2-[12,17]: 163.3915 - ca2-[18,23]: 55.9971 - ca3-[0,5]: 426.9527 - ca3-[6,11]: 239.5048 - ca3-[12,17]: 134.6232 - ca3-[18,23]: 23.6592 - ca4-[0,5]: 208.7528 - ca4-[6,11]: 438.0057 - ca4-[12,17]: 172.2235 - ca4-[18,23]: 56.5918 - val_ca1-[0,5]: 212.9731 - val_ca1-[6,11]: 78.7571 - val_ca1-[12,17]: 16.9001 - val_ca1-[18,23]: 73.9835 - val_ca2-[0,5]: 725.2742 - val_ca2-[6,11]: 432.2443 - val_ca2-[12,17]: 181.2380 - val_ca2-[18,23]: 62.2444 - val_ca3-[0,5]: 534.9009 - val_ca3-[6,11]: 290.6875 - val_ca3-[12,17]: 97.8237 - val_ca3-[18,23]: 32.9555 - val_ca4-[0,5]: 717.9948 - val_ca4-[6,11]: 426.7029 - val_ca4-[12,17]: 177.7668 - val_ca4-[18,23]: 60.7002\n",
      "Epoch 161/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 209.3415 - ca1-[6,11]: 81.9650 - ca1-[12,17]: 15.6763 - ca1-[18,23]: 67.3804 - ca2-[0,5]: 735.9634 - ca2-[6,11]: 417.6746 - ca2-[12,17]: 169.5611 - ca2-[18,23]: 57.6331 - ca3-[0,5]: 433.1441 - ca3-[6,11]: 242.9597 - ca3-[12,17]: 144.2113 - ca3-[18,23]: 25.7290 - ca4-[0,5]: 212.0862 - ca4-[6,11]: 447.9549 - ca4-[12,17]: 175.6715 - ca4-[18,23]: 58.8186 - val_ca1-[0,5]: 215.2503 - val_ca1-[6,11]: 80.0266 - val_ca1-[12,17]: 16.9684 - val_ca1-[18,23]: 72.9319 - val_ca2-[0,5]: 734.6907 - val_ca2-[6,11]: 439.4255 - val_ca2-[12,17]: 185.7569 - val_ca2-[18,23]: 64.2847 - val_ca3-[0,5]: 541.9444 - val_ca3-[6,11]: 295.7814 - val_ca3-[12,17]: 100.5954 - val_ca3-[18,23]: 33.5655 - val_ca4-[0,5]: 727.4227 - val_ca4-[6,11]: 433.8816 - val_ca4-[12,17]: 182.2663 - val_ca4-[18,23]: 62.7057\n",
      "Epoch 162/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 212.5720 - ca1-[6,11]: 83.5638 - ca1-[12,17]: 15.8196 - ca1-[18,23]: 67.3312 - ca2-[0,5]: 741.9485 - ca2-[6,11]: 428.1434 - ca2-[12,17]: 174.7505 - ca2-[18,23]: 59.1553 - ca3-[0,5]: 439.3819 - ca3-[6,11]: 248.3570 - ca3-[12,17]: 132.1641 - ca3-[18,23]: 26.6000 - ca4-[0,5]: 219.8922 - ca4-[6,11]: 426.1866 - ca4-[12,17]: 180.4284 - ca4-[18,23]: 59.9072 - val_ca1-[0,5]: 217.5277 - val_ca1-[6,11]: 81.3014 - val_ca1-[12,17]: 16.9257 - val_ca1-[18,23]: 69.6064 - val_ca2-[0,5]: 744.2062 - val_ca2-[6,11]: 446.6969 - val_ca2-[12,17]: 189.1760 - val_ca2-[18,23]: 66.8361 - val_ca3-[0,5]: 549.0381 - val_ca3-[6,11]: 300.9244 - val_ca3-[12,17]: 102.5594 - val_ca3-[18,23]: 33.8276 - val_ca4-[0,5]: 736.8726 - val_ca4-[6,11]: 441.0915 - val_ca4-[12,17]: 185.6405 - val_ca4-[18,23]: 65.1764\n",
      "Epoch 163/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 214.0846 - ca1-[6,11]: 84.7229 - ca1-[12,17]: 16.4150 - ca1-[18,23]: 66.8131 - ca2-[0,5]: 754.2996 - ca2-[6,11]: 429.6780 - ca2-[12,17]: 177.7921 - ca2-[18,23]: 61.3968 - ca3-[0,5]: 430.3835 - ca3-[6,11]: 252.5761 - ca3-[12,17]: 145.6292 - ca3-[18,23]: 27.5423 - ca4-[0,5]: 205.1735 - ca4-[6,11]: 462.5340 - ca4-[12,17]: 183.8994 - ca4-[18,23]: 62.8896 - val_ca1-[0,5]: 219.8563 - val_ca1-[6,11]: 82.6107 - val_ca1-[12,17]: 17.1959 - val_ca1-[18,23]: 70.8561 - val_ca2-[0,5]: 753.7447 - val_ca2-[6,11]: 454.0001 - val_ca2-[12,17]: 195.8616 - val_ca2-[18,23]: 68.5577 - val_ca3-[0,5]: 556.1849 - val_ca3-[6,11]: 306.1186 - val_ca3-[12,17]: 106.9010 - val_ca3-[18,23]: 34.9264 - val_ca4-[0,5]: 746.4022 - val_ca4-[6,11]: 448.3769 - val_ca4-[12,17]: 192.2776 - val_ca4-[18,23]: 66.8885\n",
      "Epoch 164/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 216.5351 - ca1-[6,11]: 86.0334 - ca1-[12,17]: 15.7657 - ca1-[18,23]: 65.2496 - ca2-[0,5]: 762.6746 - ca2-[6,11]: 436.2693 - ca2-[12,17]: 182.5581 - ca2-[18,23]: 63.5003 - ca3-[0,5]: 451.9955 - ca3-[6,11]: 259.3783 - ca3-[12,17]: 155.9939 - ca3-[18,23]: 30.4016 - ca4-[0,5]: 222.2431 - ca4-[6,11]: 464.5469 - ca4-[12,17]: 188.2918 - ca4-[18,23]: 66.2762 - val_ca1-[0,5]: 222.1528 - val_ca1-[6,11]: 83.9097 - val_ca1-[12,17]: 17.2477 - val_ca1-[18,23]: 69.8464 - val_ca2-[0,5]: 763.3478 - val_ca2-[6,11]: 461.3672 - val_ca2-[12,17]: 199.7004 - val_ca2-[18,23]: 70.7826 - val_ca3-[0,5]: 563.3654 - val_ca3-[6,11]: 311.3503 - val_ca3-[12,17]: 109.1943 - val_ca3-[18,23]: 35.6759 - val_ca4-[0,5]: 756.0123 - val_ca4-[6,11]: 455.7384 - val_ca4-[12,17]: 196.1042 - val_ca4-[18,23]: 69.0788\n",
      "Epoch 165/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 219.2594 - ca1-[6,11]: 87.7840 - ca1-[12,17]: 16.2525 - ca1-[18,23]: 65.2829 - ca2-[0,5]: 772.3940 - ca2-[6,11]: 445.0987 - ca2-[12,17]: 185.9713 - ca2-[18,23]: 68.3090 - ca3-[0,5]: 458.3603 - ca3-[6,11]: 263.8228 - ca3-[12,17]: 157.0296 - ca3-[18,23]: 31.5871 - ca4-[0,5]: 225.6862 - ca4-[6,11]: 469.2162 - ca4-[12,17]: 193.5051 - ca4-[18,23]: 69.4972 - val_ca1-[0,5]: 223.9212 - val_ca1-[6,11]: 84.9522 - val_ca1-[12,17]: 17.3296 - val_ca1-[18,23]: 68.9236 - val_ca2-[0,5]: 773.0162 - val_ca2-[6,11]: 468.7989 - val_ca2-[12,17]: 204.4677 - val_ca2-[18,23]: 73.0697 - val_ca3-[0,5]: 570.6003 - val_ca3-[6,11]: 316.6342 - val_ca3-[12,17]: 112.1544 - val_ca3-[18,23]: 36.4727 - val_ca4-[0,5]: 765.6868 - val_ca4-[6,11]: 463.1639 - val_ca4-[12,17]: 200.8508 - val_ca4-[18,23]: 71.3316\n",
      "Epoch 166/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 212.4921 - ca1-[6,11]: 84.2388 - ca1-[12,17]: 16.4348 - ca1-[18,23]: 64.3179 - ca2-[0,5]: 785.0318 - ca2-[6,11]: 454.1608 - ca2-[12,17]: 190.1701 - ca2-[18,23]: 69.0547 - ca3-[0,5]: 442.0097 - ca3-[6,11]: 267.2933 - ca3-[12,17]: 156.8562 - ca3-[18,23]: 31.8986 - ca4-[0,5]: 238.3202 - ca4-[6,11]: 477.0720 - ca4-[12,17]: 200.2752 - ca4-[18,23]: 70.6754 - val_ca1-[0,5]: 40.5439 - val_ca1-[6,11]: 10.5062 - val_ca1-[12,17]: 39.5657 - val_ca1-[18,23]: 122.8906 - val_ca2-[0,5]: 782.7753 - val_ca2-[6,11]: 476.3142 - val_ca2-[12,17]: 209.3109 - val_ca2-[18,23]: 75.4253 - val_ca3-[0,5]: 577.8868 - val_ca3-[6,11]: 321.9684 - val_ca3-[12,17]: 115.1632 - val_ca3-[18,23]: 37.3169 - val_ca4-[0,5]: 775.4004 - val_ca4-[6,11]: 470.6336 - val_ca4-[12,17]: 205.6480 - val_ca4-[18,23]: 73.6409\n",
      "Epoch 167/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 22.3137 - ca1-[6,11]: 9.3766 - ca1-[12,17]: 20.0962 - ca1-[18,23]: 75.2348 - ca2-[0,5]: 790.5610 - ca2-[6,11]: 461.1411 - ca2-[12,17]: 195.7173 - ca2-[18,23]: 71.0801 - ca3-[0,5]: 438.7985 - ca3-[6,11]: 273.1702 - ca3-[12,17]: 166.9994 - ca3-[18,23]: 33.7328 - ca4-[0,5]: 217.9882 - ca4-[6,11]: 484.2939 - ca4-[12,17]: 202.0062 - ca4-[18,23]: 74.1081 - val_ca1-[0,5]: 6.9475 - val_ca1-[6,11]: 11.8519 - val_ca1-[12,17]: 29.0753 - val_ca1-[18,23]: 82.3343 - val_ca2-[0,5]: 792.5727 - val_ca2-[6,11]: 483.8734 - val_ca2-[12,17]: 214.2041 - val_ca2-[18,23]: 77.8368 - val_ca3-[0,5]: 585.2125 - val_ca3-[6,11]: 327.3436 - val_ca3-[12,17]: 118.2156 - val_ca3-[18,23]: 38.2067 - val_ca4-[0,5]: 785.2032 - val_ca4-[6,11]: 478.1862 - val_ca4-[12,17]: 210.5206 - val_ca4-[18,23]: 76.0186\n",
      "Epoch 168/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 6.4675 - ca1-[6,11]: 8.9117 - ca1-[12,17]: 11.9466 - ca1-[18,23]: 61.8525 - ca2-[0,5]: 802.5789 - ca2-[6,11]: 465.6332 - ca2-[12,17]: 201.4437 - ca2-[18,23]: 73.1637 - ca3-[0,5]: 461.3037 - ca3-[6,11]: 278.2311 - ca3-[12,17]: 162.0130 - ca3-[18,23]: 33.5951 - ca4-[0,5]: 241.7644 - ca4-[6,11]: 463.9317 - ca4-[12,17]: 210.3116 - ca4-[18,23]: 76.6433 - val_ca1-[0,5]: 5.3324 - val_ca1-[6,11]: 5.5866 - val_ca1-[12,17]: 23.1269 - val_ca1-[18,23]: 74.4754 - val_ca2-[0,5]: 802.4156 - val_ca2-[6,11]: 491.4816 - val_ca2-[12,17]: 219.1507 - val_ca2-[18,23]: 80.3057 - val_ca3-[0,5]: 592.5806 - val_ca3-[6,11]: 332.7625 - val_ca3-[12,17]: 121.3127 - val_ca3-[18,23]: 39.1427 - val_ca4-[0,5]: 795.0475 - val_ca4-[6,11]: 485.7850 - val_ca4-[12,17]: 215.4449 - val_ca4-[18,23]: 78.4532\n",
      "Epoch 169/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 5.1239 - ca1-[6,11]: 3.9444 - ca1-[12,17]: 9.0312 - ca1-[18,23]: 61.3208 - ca2-[0,5]: 810.8205 - ca2-[6,11]: 475.1673 - ca2-[12,17]: 203.4427 - ca2-[18,23]: 75.4167 - ca3-[0,5]: 467.6052 - ca3-[6,11]: 283.9998 - ca3-[12,17]: 159.3024 - ca3-[18,23]: 37.3679 - ca4-[0,5]: 245.5106 - ca4-[6,11]: 470.8781 - ca4-[12,17]: 212.4078 - ca4-[18,23]: 83.2422 - val_ca1-[0,5]: 3.9628 - val_ca1-[6,11]: 4.0805 - val_ca1-[12,17]: 18.8919 - val_ca1-[18,23]: 69.6512 - val_ca2-[0,5]: 812.3001 - val_ca2-[6,11]: 499.1005 - val_ca2-[12,17]: 224.1486 - val_ca2-[18,23]: 82.9352 - val_ca3-[0,5]: 599.9938 - val_ca3-[6,11]: 338.2105 - val_ca3-[12,17]: 124.4559 - val_ca3-[18,23]: 40.3252 - val_ca4-[0,5]: 804.9421 - val_ca4-[6,11]: 493.4019 - val_ca4-[12,17]: 220.4252 - val_ca4-[18,23]: 81.0544\n",
      "Epoch 170/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 3.7126 - ca1-[6,11]: 2.8826 - ca1-[12,17]: 8.4915 - ca1-[18,23]: 57.8961 - ca2-[0,5]: 820.9841 - ca2-[6,11]: 479.5116 - ca2-[12,17]: 210.7827 - ca2-[18,23]: 79.2724 - ca3-[0,5]: 473.9621 - ca3-[6,11]: 287.2620 - ca3-[12,17]: 178.7651 - ca3-[18,23]: 36.2038 - ca4-[0,5]: 233.8645 - ca4-[6,11]: 513.3174 - ca4-[12,17]: 223.0861 - ca4-[18,23]: 86.2102 - val_ca1-[0,5]: 3.0728 - val_ca1-[6,11]: 3.3158 - val_ca1-[12,17]: 15.2738 - val_ca1-[18,23]: 66.5178 - val_ca2-[0,5]: 822.2431 - val_ca2-[6,11]: 506.8492 - val_ca2-[12,17]: 229.2061 - val_ca2-[18,23]: 85.5164 - val_ca3-[0,5]: 607.4688 - val_ca3-[6,11]: 343.7490 - val_ca3-[12,17]: 127.6521 - val_ca3-[18,23]: 41.3525 - val_ca4-[0,5]: 814.9318 - val_ca4-[6,11]: 501.1760 - val_ca4-[12,17]: 225.4842 - val_ca4-[18,23]: 83.6140\n",
      "Epoch 171/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 2.8414 - ca1-[6,11]: 2.2870 - ca1-[12,17]: 6.7781 - ca1-[18,23]: 55.2822 - ca2-[0,5]: 830.6212 - ca2-[6,11]: 493.6425 - ca2-[12,17]: 217.6038 - ca2-[18,23]: 82.1000 - ca3-[0,5]: 501.0330 - ca3-[6,11]: 292.1091 - ca3-[12,17]: 175.5803 - ca3-[18,23]: 38.0528 - ca4-[0,5]: 237.3957 - ca4-[6,11]: 516.3484 - ca4-[12,17]: 220.4343 - ca4-[18,23]: 84.4794 - val_ca1-[0,5]: 2.4488 - val_ca1-[6,11]: 2.9367 - val_ca1-[12,17]: 13.2436 - val_ca1-[18,23]: 63.7884 - val_ca2-[0,5]: 832.2598 - val_ca2-[6,11]: 514.6331 - val_ca2-[12,17]: 234.3310 - val_ca2-[18,23]: 88.0656 - val_ca3-[0,5]: 614.9756 - val_ca3-[6,11]: 349.3069 - val_ca3-[12,17]: 130.8887 - val_ca3-[18,23]: 42.2316 - val_ca4-[0,5]: 824.9267 - val_ca4-[6,11]: 508.9332 - val_ca4-[12,17]: 230.5762 - val_ca4-[18,23]: 86.1214\n",
      "Epoch 172/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 2.2731 - ca1-[6,11]: 1.7805 - ca1-[12,17]: 6.1910 - ca1-[18,23]: 54.5007 - ca2-[0,5]: 840.6286 - ca2-[6,11]: 495.6479 - ca2-[12,17]: 220.1099 - ca2-[18,23]: 86.6294 - ca3-[0,5]: 469.3681 - ca3-[6,11]: 288.0137 - ca3-[12,17]: 174.5305 - ca3-[18,23]: 40.9095 - ca4-[0,5]: 266.5138 - ca4-[6,11]: 528.4956 - ca4-[12,17]: 230.6951 - ca4-[18,23]: 87.0035 - val_ca1-[0,5]: 2.0073 - val_ca1-[6,11]: 2.6983 - val_ca1-[12,17]: 12.1807 - val_ca1-[18,23]: 61.7820 - val_ca2-[0,5]: 842.3529 - val_ca2-[6,11]: 522.4904 - val_ca2-[12,17]: 239.5251 - val_ca2-[18,23]: 90.7805 - val_ca3-[0,5]: 622.5489 - val_ca3-[6,11]: 354.9260 - val_ca3-[12,17]: 134.1804 - val_ca3-[18,23]: 43.3567 - val_ca4-[0,5]: 835.0353 - val_ca4-[6,11]: 516.7923 - val_ca4-[12,17]: 235.7563 - val_ca4-[18,23]: 88.8076\n",
      "Epoch 173/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 1.9177 - ca1-[6,11]: 1.4794 - ca1-[12,17]: 6.1132 - ca1-[18,23]: 52.4310 - ca2-[0,5]: 850.4887 - ca2-[6,11]: 508.6072 - ca2-[12,17]: 221.5492 - ca2-[18,23]: 88.9103 - ca3-[0,5]: 500.2674 - ca3-[6,11]: 304.0110 - ca3-[12,17]: 187.4385 - ca3-[18,23]: 42.1416 - ca4-[0,5]: 270.4471 - ca4-[6,11]: 540.9785 - ca4-[12,17]: 228.8690 - ca4-[18,23]: 89.0832 - val_ca1-[0,5]: 1.6797 - val_ca1-[6,11]: 2.5052 - val_ca1-[12,17]: 11.4917 - val_ca1-[18,23]: 60.3110 - val_ca2-[0,5]: 852.4800 - val_ca2-[6,11]: 530.3873 - val_ca2-[12,17]: 244.7662 - val_ca2-[18,23]: 93.6370 - val_ca3-[0,5]: 630.1369 - val_ca3-[6,11]: 360.5682 - val_ca3-[12,17]: 137.5048 - val_ca3-[18,23]: 44.7093 - val_ca4-[0,5]: 845.1939 - val_ca4-[6,11]: 524.7044 - val_ca4-[12,17]: 240.9924 - val_ca4-[18,23]: 91.6436\n",
      "Epoch 174/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 1.5803 - ca1-[6,11]: 1.4428 - ca1-[12,17]: 5.6300 - ca1-[18,23]: 51.5774 - ca2-[0,5]: 863.5210 - ca2-[6,11]: 513.3773 - ca2-[12,17]: 230.7391 - ca2-[18,23]: 91.1943 - ca3-[0,5]: 517.7201 - ca3-[6,11]: 308.6419 - ca3-[12,17]: 179.0578 - ca3-[18,23]: 46.7004 - ca4-[0,5]: 257.8958 - ca4-[6,11]: 532.7448 - ca4-[12,17]: 238.9483 - ca4-[18,23]: 96.4247 - val_ca1-[0,5]: 1.4317 - val_ca1-[6,11]: 2.3218 - val_ca1-[12,17]: 10.6483 - val_ca1-[18,23]: 58.3691 - val_ca2-[0,5]: 862.6852 - val_ca2-[6,11]: 538.3589 - val_ca2-[12,17]: 249.9276 - val_ca2-[18,23]: 96.4673 - val_ca3-[0,5]: 637.7713 - val_ca3-[6,11]: 366.2565 - val_ca3-[12,17]: 140.8009 - val_ca3-[18,23]: 45.9189 - val_ca4-[0,5]: 855.4176 - val_ca4-[6,11]: 532.6806 - val_ca4-[12,17]: 246.1446 - val_ca4-[18,23]: 94.4472\n",
      "Epoch 175/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 1.3510 - ca1-[6,11]: 1.3922 - ca1-[12,17]: 4.9952 - ca1-[18,23]: 48.8892 - ca2-[0,5]: 871.5832 - ca2-[6,11]: 521.7041 - ca2-[12,17]: 234.6439 - ca2-[18,23]: 93.5107 - ca3-[0,5]: 520.9283 - ca3-[6,11]: 314.0089 - ca3-[12,17]: 187.2787 - ca3-[18,23]: 46.6692 - ca4-[0,5]: 278.4066 - ca4-[6,11]: 543.9529 - ca4-[12,17]: 244.3998 - ca4-[18,23]: 101.6794 - val_ca1-[0,5]: 1.2367 - val_ca1-[6,11]: 2.1643 - val_ca1-[12,17]: 10.4281 - val_ca1-[18,23]: 56.6767 - val_ca2-[0,5]: 872.9260 - val_ca2-[6,11]: 546.3716 - val_ca2-[12,17]: 255.4360 - val_ca2-[18,23]: 99.2717 - val_ca3-[0,5]: 645.4646 - val_ca3-[6,11]: 372.0007 - val_ca3-[12,17]: 144.2984 - val_ca3-[18,23]: 46.9986 - val_ca4-[0,5]: 865.7133 - val_ca4-[6,11]: 540.7267 - val_ca4-[12,17]: 251.6586 - val_ca4-[18,23]: 97.2329\n",
      "Epoch 176/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 1.1832 - ca1-[6,11]: 1.1859 - ca1-[12,17]: 4.7014 - ca1-[18,23]: 47.0403 - ca2-[0,5]: 879.9376 - ca2-[6,11]: 531.0988 - ca2-[12,17]: 237.8403 - ca2-[18,23]: 95.8864 - ca3-[0,5]: 512.9791 - ca3-[6,11]: 320.1383 - ca3-[12,17]: 189.8365 - ca3-[18,23]: 49.6156 - ca4-[0,5]: 265.3662 - ca4-[6,11]: 556.0433 - ca4-[12,17]: 251.7956 - ca4-[18,23]: 98.0535 - val_ca1-[0,5]: 1.0785 - val_ca1-[6,11]: 2.0238 - val_ca1-[12,17]: 9.9958 - val_ca1-[18,23]: 55.2202 - val_ca2-[0,5]: 883.2252 - val_ca2-[6,11]: 554.4430 - val_ca2-[12,17]: 260.8542 - val_ca2-[18,23]: 102.2201 - val_ca3-[0,5]: 653.2151 - val_ca3-[6,11]: 377.7995 - val_ca3-[12,17]: 147.7726 - val_ca3-[18,23]: 48.3088 - val_ca4-[0,5]: 876.0633 - val_ca4-[6,11]: 548.8288 - val_ca4-[12,17]: 257.0834 - val_ca4-[18,23]: 100.1652\n",
      "Epoch 177/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 1.0465 - ca1-[6,11]: 1.1235 - ca1-[12,17]: 4.7770 - ca1-[18,23]: 46.4559 - ca2-[0,5]: 893.4632 - ca2-[6,11]: 534.3340 - ca2-[12,17]: 242.3277 - ca2-[18,23]: 98.6063 - ca3-[0,5]: 538.2990 - ca3-[6,11]: 324.9049 - ca3-[12,17]: 201.0616 - ca3-[18,23]: 52.7005 - ca4-[0,5]: 269.1270 - ca4-[6,11]: 503.0721 - ca4-[12,17]: 257.0283 - ca4-[18,23]: 104.2360 - val_ca1-[0,5]: 0.9544 - val_ca1-[6,11]: 1.7786 - val_ca1-[12,17]: 9.4055 - val_ca1-[18,23]: 53.6217 - val_ca2-[0,5]: 893.6241 - val_ca2-[6,11]: 562.3314 - val_ca2-[12,17]: 266.1949 - val_ca2-[18,23]: 105.2406 - val_ca3-[0,5]: 660.9876 - val_ca3-[6,11]: 383.4119 - val_ca3-[12,17]: 151.1992 - val_ca3-[18,23]: 49.6613 - val_ca4-[0,5]: 886.4287 - val_ca4-[6,11]: 556.6835 - val_ca4-[12,17]: 262.3885 - val_ca4-[18,23]: 103.1460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.9159 - ca1-[6,11]: 0.9104 - ca1-[12,17]: 4.2132 - ca1-[18,23]: 44.7617 - ca2-[0,5]: 903.5144 - ca2-[6,11]: 535.0540 - ca2-[12,17]: 250.5070 - ca2-[18,23]: 101.4137 - ca3-[0,5]: 526.3157 - ca3-[6,11]: 332.0868 - ca3-[12,17]: 188.8981 - ca3-[18,23]: 51.1962 - ca4-[0,5]: 272.9140 - ca4-[6,11]: 565.9664 - ca4-[12,17]: 258.4544 - ca4-[18,23]: 107.0850 - val_ca1-[0,5]: 0.8511 - val_ca1-[6,11]: 1.7771 - val_ca1-[12,17]: 9.0719 - val_ca1-[18,23]: 52.2553 - val_ca2-[0,5]: 904.0784 - val_ca2-[6,11]: 570.8254 - val_ca2-[12,17]: 271.4613 - val_ca2-[18,23]: 108.3207 - val_ca3-[0,5]: 668.8068 - val_ca3-[6,11]: 389.4999 - val_ca3-[12,17]: 154.5336 - val_ca3-[18,23]: 51.0602 - val_ca4-[0,5]: 896.8745 - val_ca4-[6,11]: 565.1603 - val_ca4-[12,17]: 267.6327 - val_ca4-[18,23]: 106.1937\n",
      "Epoch 179/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 0.8314 - ca1-[6,11]: 1.0756 - ca1-[12,17]: 4.1455 - ca1-[18,23]: 43.3363 - ca2-[0,5]: 915.4276 - ca2-[6,11]: 555.4134 - ca2-[12,17]: 252.9212 - ca2-[18,23]: 105.8169 - ca3-[0,5]: 552.2196 - ca3-[6,11]: 338.2164 - ca3-[12,17]: 212.5330 - ca3-[18,23]: 54.2422 - ca4-[0,5]: 258.7965 - ca4-[6,11]: 581.4653 - ca4-[12,17]: 269.8292 - ca4-[18,23]: 112.8781 - val_ca1-[0,5]: 0.7603 - val_ca1-[6,11]: 1.6775 - val_ca1-[12,17]: 8.8773 - val_ca1-[18,23]: 50.8904 - val_ca2-[0,5]: 914.5834 - val_ca2-[6,11]: 579.0980 - val_ca2-[12,17]: 277.5254 - val_ca2-[18,23]: 111.4589 - val_ca3-[0,5]: 676.6734 - val_ca3-[6,11]: 395.4208 - val_ca3-[12,17]: 158.4414 - val_ca3-[18,23]: 52.5057 - val_ca4-[0,5]: 907.3783 - val_ca4-[6,11]: 573.4227 - val_ca4-[12,17]: 273.6721 - val_ca4-[18,23]: 109.3019\n",
      "Epoch 180/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.7385 - ca1-[6,11]: 0.9307 - ca1-[12,17]: 3.7221 - ca1-[18,23]: 41.4044 - ca2-[0,5]: 925.0773 - ca2-[6,11]: 569.4913 - ca2-[12,17]: 262.5650 - ca2-[18,23]: 110.5658 - ca3-[0,5]: 559.2523 - ca3-[6,11]: 339.2080 - ca3-[12,17]: 217.7976 - ca3-[18,23]: 56.0693 - ca4-[0,5]: 252.2693 - ca4-[6,11]: 525.5472 - ca4-[12,17]: 271.5809 - ca4-[18,23]: 110.3399 - val_ca1-[0,5]: 0.6866 - val_ca1-[6,11]: 1.5964 - val_ca1-[12,17]: 8.5177 - val_ca1-[18,23]: 49.5745 - val_ca2-[0,5]: 925.1401 - val_ca2-[6,11]: 587.4241 - val_ca2-[12,17]: 283.1949 - val_ca2-[18,23]: 114.6552 - val_ca3-[0,5]: 684.5977 - val_ca3-[6,11]: 401.3963 - val_ca3-[12,17]: 162.0961 - val_ca3-[18,23]: 53.9997 - val_ca4-[0,5]: 917.9429 - val_ca4-[6,11]: 581.7462 - val_ca4-[12,17]: 279.3265 - val_ca4-[18,23]: 112.4714\n",
      "Epoch 181/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.6793 - ca1-[6,11]: 0.9599 - ca1-[12,17]: 3.9560 - ca1-[18,23]: 39.8281 - ca2-[0,5]: 937.2476 - ca2-[6,11]: 567.8513 - ca2-[12,17]: 262.3574 - ca2-[18,23]: 112.3718 - ca3-[0,5]: 566.3330 - ca3-[6,11]: 345.9935 - ca3-[12,17]: 222.1908 - ca3-[18,23]: 60.7811 - ca4-[0,5]: 274.2754 - ca4-[6,11]: 593.8588 - ca4-[12,17]: 259.9818 - ca4-[18,23]: 117.2063 - val_ca1-[0,5]: 0.6326 - val_ca1-[6,11]: 1.5048 - val_ca1-[12,17]: 8.1638 - val_ca1-[18,23]: 48.1723 - val_ca2-[0,5]: 935.7535 - val_ca2-[6,11]: 595.8079 - val_ca2-[12,17]: 288.9229 - val_ca2-[18,23]: 117.9113 - val_ca3-[0,5]: 692.5682 - val_ca3-[6,11]: 407.4182 - val_ca3-[12,17]: 165.7972 - val_ca3-[18,23]: 55.5403 - val_ca4-[0,5]: 928.5117 - val_ca4-[6,11]: 590.0861 - val_ca4-[12,17]: 285.0115 - val_ca4-[18,23]: 115.6850\n",
      "Epoch 182/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.6182 - ca1-[6,11]: 0.8021 - ca1-[12,17]: 3.2131 - ca1-[18,23]: 39.4468 - ca2-[0,5]: 946.4554 - ca2-[6,11]: 575.2210 - ca2-[12,17]: 267.6630 - ca2-[18,23]: 115.5717 - ca3-[0,5]: 553.5076 - ca3-[6,11]: 341.7585 - ca3-[12,17]: 208.0137 - ca3-[18,23]: 63.8677 - ca4-[0,5]: 288.3352 - ca4-[6,11]: 571.7984 - ca4-[12,17]: 272.3961 - ca4-[18,23]: 126.9743 - val_ca1-[0,5]: 0.5796 - val_ca1-[6,11]: 1.4443 - val_ca1-[12,17]: 7.8708 - val_ca1-[18,23]: 46.8820 - val_ca2-[0,5]: 946.4061 - val_ca2-[6,11]: 604.2352 - val_ca2-[12,17]: 294.7002 - val_ca2-[18,23]: 121.2213 - val_ca3-[0,5]: 700.5987 - val_ca3-[6,11]: 413.4968 - val_ca3-[12,17]: 169.5510 - val_ca3-[18,23]: 57.1300 - val_ca4-[0,5]: 939.2228 - val_ca4-[6,11]: 598.5511 - val_ca4-[12,17]: 290.8015 - val_ca4-[18,23]: 118.9847\n",
      "Epoch 183/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.5560 - ca1-[6,11]: 0.8266 - ca1-[12,17]: 3.0092 - ca1-[18,23]: 38.7676 - ca2-[0,5]: 957.2971 - ca2-[6,11]: 582.7936 - ca2-[12,17]: 278.7045 - ca2-[18,23]: 120.2774 - ca3-[0,5]: 564.1858 - ca3-[6,11]: 357.9166 - ca3-[12,17]: 231.9587 - ca3-[18,23]: 64.3978 - ca4-[0,5]: 311.3529 - ca4-[6,11]: 622.3498 - ca4-[12,17]: 292.8202 - ca4-[18,23]: 123.9651 - val_ca1-[0,5]: 0.5342 - val_ca1-[6,11]: 1.3971 - val_ca1-[12,17]: 7.6012 - val_ca1-[18,23]: 45.8172 - val_ca2-[0,5]: 957.1133 - val_ca2-[6,11]: 612.7187 - val_ca2-[12,17]: 300.5348 - val_ca2-[18,23]: 124.5902 - val_ca3-[0,5]: 708.6582 - val_ca3-[6,11]: 419.6086 - val_ca3-[12,17]: 173.3432 - val_ca3-[18,23]: 58.7628 - val_ca4-[0,5]: 949.9894 - val_ca4-[6,11]: 607.0729 - val_ca4-[12,17]: 296.6498 - val_ca4-[18,23]: 122.3442\n",
      "Epoch 184/300\n",
      "26/26 [==============================] - 3s 124ms/step - ca1-[0,5]: 0.5252 - ca1-[6,11]: 0.8431 - ca1-[12,17]: 3.3466 - ca1-[18,23]: 37.4172 - ca2-[0,5]: 967.2237 - ca2-[6,11]: 593.4619 - ca2-[12,17]: 284.0289 - ca2-[18,23]: 121.4137 - ca3-[0,5]: 580.2423 - ca3-[6,11]: 365.2120 - ca3-[12,17]: 223.6874 - ca3-[18,23]: 68.4768 - ca4-[0,5]: 296.2212 - ca4-[6,11]: 618.1067 - ca4-[12,17]: 295.4451 - ca4-[18,23]: 132.9099 - val_ca1-[0,5]: 0.4986 - val_ca1-[6,11]: 1.3604 - val_ca1-[12,17]: 7.3095 - val_ca1-[18,23]: 44.7362 - val_ca2-[0,5]: 967.9094 - val_ca2-[6,11]: 621.2849 - val_ca2-[12,17]: 306.4455 - val_ca2-[18,23]: 128.0287 - val_ca3-[0,5]: 716.7890 - val_ca3-[6,11]: 425.7859 - val_ca3-[12,17]: 177.1937 - val_ca3-[18,23]: 60.4473 - val_ca4-[0,5]: 960.7740 - val_ca4-[6,11]: 615.6220 - val_ca4-[12,17]: 302.5360 - val_ca4-[18,23]: 125.7515\n",
      "Epoch 185/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.4747 - ca1-[6,11]: 0.7738 - ca1-[12,17]: 2.8350 - ca1-[18,23]: 35.8484 - ca2-[0,5]: 976.3596 - ca2-[6,11]: 604.3759 - ca2-[12,17]: 286.8460 - ca2-[18,23]: 127.8100 - ca3-[0,5]: 574.4031 - ca3-[6,11]: 369.5585 - ca3-[12,17]: 228.7493 - ca3-[18,23]: 71.3532 - ca4-[0,5]: 280.5019 - ca4-[6,11]: 622.0356 - ca4-[12,17]: 303.9533 - ca4-[18,23]: 131.2927 - val_ca1-[0,5]: 0.4675 - val_ca1-[6,11]: 1.2936 - val_ca1-[12,17]: 6.7750 - val_ca1-[18,23]: 43.4978 - val_ca2-[0,5]: 978.7343 - val_ca2-[6,11]: 629.8868 - val_ca2-[12,17]: 313.5101 - val_ca2-[18,23]: 131.5178 - val_ca3-[0,5]: 725.1515 - val_ca3-[6,11]: 432.1508 - val_ca3-[12,17]: 182.0109 - val_ca3-[18,23]: 62.2181 - val_ca4-[0,5]: 971.6314 - val_ca4-[6,11]: 624.2413 - val_ca4-[12,17]: 309.5931 - val_ca4-[18,23]: 129.2239\n",
      "Epoch 186/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.4520 - ca1-[6,11]: 0.6743 - ca1-[12,17]: 2.6842 - ca1-[18,23]: 34.8172 - ca2-[0,5]: 989.6432 - ca2-[6,11]: 613.4382 - ca2-[12,17]: 293.1156 - ca2-[18,23]: 131.1743 - ca3-[0,5]: 603.0579 - ca3-[6,11]: 376.7008 - ca3-[12,17]: 246.5866 - ca3-[18,23]: 68.7444 - ca4-[0,5]: 304.1964 - ca4-[6,11]: 629.4633 - ca4-[12,17]: 308.9793 - ca4-[18,23]: 135.3604 - val_ca1-[0,5]: 0.4384 - val_ca1-[6,11]: 1.2606 - val_ca1-[12,17]: 6.8056 - val_ca1-[18,23]: 42.4729 - val_ca2-[0,5]: 989.6414 - val_ca2-[6,11]: 638.5664 - val_ca2-[12,17]: 318.4260 - val_ca2-[18,23]: 135.0746 - val_ca3-[0,5]: 742.6873 - val_ca3-[6,11]: 445.5351 - val_ca3-[12,17]: 189.6189 - val_ca3-[18,23]: 66.0547 - val_ca4-[0,5]: 982.5437 - val_ca4-[6,11]: 632.9169 - val_ca4-[12,17]: 314.5012 - val_ca4-[18,23]: 132.7554\n",
      "Epoch 187/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.4262 - ca1-[6,11]: 0.6542 - ca1-[12,17]: 2.5819 - ca1-[18,23]: 33.1150 - ca2-[0,5]: 1000.2028 - ca2-[6,11]: 619.8758 - ca2-[12,17]: 296.0096 - ca2-[18,23]: 134.5285 - ca3-[0,5]: 622.1604 - ca3-[6,11]: 391.1457 - ca3-[12,17]: 245.6675 - ca3-[18,23]: 81.5631 - ca4-[0,5]: 287.9307 - ca4-[6,11]: 638.6041 - ca4-[12,17]: 314.4622 - ca4-[18,23]: 144.0202 - val_ca1-[0,5]: 0.4143 - val_ca1-[6,11]: 1.2031 - val_ca1-[12,17]: 6.4563 - val_ca1-[18,23]: 41.4603 - val_ca2-[0,5]: 1000.6445 - val_ca2-[6,11]: 647.3350 - val_ca2-[12,17]: 324.3421 - val_ca2-[18,23]: 138.7337 - val_ca3-[0,5]: 769.8835 - val_ca3-[6,11]: 466.3887 - val_ca3-[12,17]: 202.7988 - val_ca3-[18,23]: 72.4457 - val_ca4-[0,5]: 993.5089 - val_ca4-[6,11]: 641.6470 - val_ca4-[12,17]: 320.3807 - val_ca4-[18,23]: 136.3781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/300\n",
      "26/26 [==============================] - 3s 124ms/step - ca1-[0,5]: 0.4024 - ca1-[6,11]: 0.5494 - ca1-[12,17]: 2.3250 - ca1-[18,23]: 32.8580 - ca2-[0,5]: 1010.4840 - ca2-[6,11]: 632.0607 - ca2-[12,17]: 299.7485 - ca2-[18,23]: 137.3862 - ca3-[0,5]: 644.2682 - ca3-[6,11]: 410.7360 - ca3-[12,17]: 256.2497 - ca3-[18,23]: 88.7499 - ca4-[0,5]: 332.8624 - ca4-[6,11]: 656.2301 - ca4-[12,17]: 296.6464 - ca4-[18,23]: 145.6223 - val_ca1-[0,5]: 0.3915 - val_ca1-[6,11]: 1.1746 - val_ca1-[12,17]: 6.3736 - val_ca1-[18,23]: 40.4096 - val_ca2-[0,5]: 1011.6565 - val_ca2-[6,11]: 656.1227 - val_ca2-[12,17]: 330.6718 - val_ca2-[18,23]: 142.3766 - val_ca3-[0,5]: 786.9193 - val_ca3-[6,11]: 479.5105 - val_ca3-[12,17]: 211.3779 - val_ca3-[18,23]: 76.4405 - val_ca4-[0,5]: 1004.5651 - val_ca4-[6,11]: 650.4622 - val_ca4-[12,17]: 326.7154 - val_ca4-[18,23]: 140.0068\n",
      "Epoch 189/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.3705 - ca1-[6,11]: 0.5640 - ca1-[12,17]: 2.5772 - ca1-[18,23]: 31.7872 - ca2-[0,5]: 1022.4675 - ca2-[6,11]: 638.0430 - ca2-[12,17]: 305.9829 - ca2-[18,23]: 144.5564 - ca3-[0,5]: 636.2223 - ca3-[6,11]: 422.7412 - ca3-[12,17]: 276.2730 - ca3-[18,23]: 88.1299 - ca4-[0,5]: 316.3758 - ca4-[6,11]: 659.9627 - ca4-[12,17]: 327.6420 - ca4-[18,23]: 144.5531 - val_ca1-[0,5]: 0.3723 - val_ca1-[6,11]: 1.1449 - val_ca1-[12,17]: 6.1505 - val_ca1-[18,23]: 39.4975 - val_ca2-[0,5]: 1022.7177 - val_ca2-[6,11]: 664.9620 - val_ca2-[12,17]: 336.8648 - val_ca2-[18,23]: 146.1062 - val_ca3-[0,5]: 801.7706 - val_ca3-[6,11]: 490.9823 - val_ca3-[12,17]: 218.8252 - val_ca3-[18,23]: 80.1422 - val_ca4-[0,5]: 1015.6812 - val_ca4-[6,11]: 659.3376 - val_ca4-[12,17]: 332.9220 - val_ca4-[18,23]: 143.7290\n",
      "Epoch 190/300\n",
      "26/26 [==============================] - 3s 131ms/step - ca1-[0,5]: 0.3508 - ca1-[6,11]: 0.6438 - ca1-[12,17]: 2.2531 - ca1-[18,23]: 30.5824 - ca2-[0,5]: 1031.8720 - ca2-[6,11]: 643.4518 - ca2-[12,17]: 318.1711 - ca2-[18,23]: 145.2986 - ca3-[0,5]: 617.2801 - ca3-[6,11]: 435.8469 - ca3-[12,17]: 286.5610 - ca3-[18,23]: 93.6014 - ca4-[0,5]: 299.2719 - ca4-[6,11]: 668.5875 - ca4-[12,17]: 333.1643 - ca4-[18,23]: 149.0100 - val_ca1-[0,5]: 0.3544 - val_ca1-[6,11]: 1.1188 - val_ca1-[12,17]: 5.9735 - val_ca1-[18,23]: 38.5912 - val_ca2-[0,5]: 1033.8669 - val_ca2-[6,11]: 673.8841 - val_ca2-[12,17]: 343.1339 - val_ca2-[18,23]: 149.9058 - val_ca3-[0,5]: 815.6677 - val_ca3-[6,11]: 501.7467 - val_ca3-[12,17]: 225.8583 - val_ca3-[18,23]: 83.7014 - val_ca4-[0,5]: 1026.8406 - val_ca4-[6,11]: 668.2601 - val_ca4-[12,17]: 339.1800 - val_ca4-[18,23]: 147.5066\n",
      "Epoch 191/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.3351 - ca1-[6,11]: 0.6028 - ca1-[12,17]: 2.3400 - ca1-[18,23]: 30.0523 - ca2-[0,5]: 1045.1750 - ca2-[6,11]: 659.4103 - ca2-[12,17]: 319.2012 - ca2-[18,23]: 152.8481 - ca3-[0,5]: 684.6758 - ca3-[6,11]: 442.0640 - ca3-[12,17]: 294.1629 - ca3-[18,23]: 98.1253 - ca4-[0,5]: 324.6327 - ca4-[6,11]: 641.4796 - ca4-[12,17]: 336.3531 - ca4-[18,23]: 155.5173 - val_ca1-[0,5]: 0.3384 - val_ca1-[6,11]: 1.0472 - val_ca1-[12,17]: 5.7585 - val_ca1-[18,23]: 37.4348 - val_ca2-[0,5]: 1045.0803 - val_ca2-[6,11]: 682.8694 - val_ca2-[12,17]: 349.4656 - val_ca2-[18,23]: 153.7672 - val_ca3-[0,5]: 829.0133 - val_ca3-[6,11]: 512.1090 - val_ca3-[12,17]: 232.6670 - val_ca3-[18,23]: 87.2021 - val_ca4-[0,5]: 1038.0906 - val_ca4-[6,11]: 677.2672 - val_ca4-[12,17]: 345.5157 - val_ca4-[18,23]: 151.3555\n",
      "Epoch 192/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.3221 - ca1-[6,11]: 0.4749 - ca1-[12,17]: 2.0512 - ca1-[18,23]: 29.7728 - ca2-[0,5]: 1052.9644 - ca2-[6,11]: 668.0770 - ca2-[12,17]: 332.2361 - ca2-[18,23]: 155.7330 - ca3-[0,5]: 688.3234 - ca3-[6,11]: 453.6617 - ca3-[12,17]: 292.3658 - ca3-[18,23]: 101.8457 - ca4-[0,5]: 328.8171 - ca4-[6,11]: 588.0684 - ca4-[12,17]: 348.3228 - ca4-[18,23]: 155.1109 - val_ca1-[0,5]: 0.3235 - val_ca1-[6,11]: 1.0568 - val_ca1-[12,17]: 5.6644 - val_ca1-[18,23]: 36.7661 - val_ca2-[0,5]: 1056.3688 - val_ca2-[6,11]: 691.9271 - val_ca2-[12,17]: 355.8663 - val_ca2-[18,23]: 157.6945 - val_ca3-[0,5]: 841.9601 - val_ca3-[6,11]: 522.1844 - val_ca3-[12,17]: 239.3226 - val_ca3-[18,23]: 90.6741 - val_ca4-[0,5]: 1049.4265 - val_ca4-[6,11]: 686.3555 - val_ca4-[12,17]: 351.9269 - val_ca4-[18,23]: 155.2745\n",
      "Epoch 193/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.3132 - ca1-[6,11]: 0.5116 - ca1-[12,17]: 1.9304 - ca1-[18,23]: 27.7820 - ca2-[0,5]: 1070.5822 - ca2-[6,11]: 672.2180 - ca2-[12,17]: 331.0307 - ca2-[18,23]: 158.3614 - ca3-[0,5]: 683.4084 - ca3-[6,11]: 463.2398 - ca3-[12,17]: 297.6386 - ca3-[18,23]: 110.7376 - ca4-[0,5]: 333.0271 - ca4-[6,11]: 699.6294 - ca4-[12,17]: 340.0709 - ca4-[18,23]: 165.6467 - val_ca1-[0,5]: 0.3077 - val_ca1-[6,11]: 1.0165 - val_ca1-[12,17]: 5.2706 - val_ca1-[18,23]: 35.9009 - val_ca2-[0,5]: 1067.6683 - val_ca2-[6,11]: 701.0055 - val_ca2-[12,17]: 363.4992 - val_ca2-[18,23]: 161.6651 - val_ca3-[0,5]: 854.6732 - val_ca3-[6,11]: 532.0994 - val_ca3-[12,17]: 246.8846 - val_ca3-[18,23]: 94.1546 - val_ca4-[0,5]: 1060.8123 - val_ca4-[6,11]: 695.4956 - val_ca4-[12,17]: 359.5859 - val_ca4-[18,23]: 159.2512\n",
      "Epoch 194/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.2947 - ca1-[6,11]: 0.4536 - ca1-[12,17]: 1.6013 - ca1-[18,23]: 26.6607 - ca2-[0,5]: 1079.0163 - ca2-[6,11]: 680.2746 - ca2-[12,17]: 338.5754 - ca2-[18,23]: 162.0809 - ca3-[0,5]: 694.3951 - ca3-[6,11]: 475.8346 - ca3-[12,17]: 320.0977 - ca3-[18,23]: 113.9805 - ca4-[0,5]: 359.7205 - ca4-[6,11]: 675.6684 - ca4-[12,17]: 358.0229 - ca4-[18,23]: 167.7594 - val_ca1-[0,5]: 0.2939 - val_ca1-[6,11]: 0.9729 - val_ca1-[12,17]: 5.3048 - val_ca1-[18,23]: 34.9787 - val_ca2-[0,5]: 1079.0782 - val_ca2-[6,11]: 710.1850 - val_ca2-[12,17]: 368.8219 - val_ca2-[18,23]: 165.7141 - val_ca3-[0,5]: 867.1953 - val_ca3-[6,11]: 541.8861 - val_ca3-[12,17]: 252.4337 - val_ca3-[18,23]: 97.6501 - val_ca4-[0,5]: 1072.2468 - val_ca4-[6,11]: 704.6873 - val_ca4-[12,17]: 364.9134 - val_ca4-[18,23]: 163.2850\n",
      "Epoch 195/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.2777 - ca1-[6,11]: 0.5292 - ca1-[12,17]: 1.9916 - ca1-[18,23]: 26.1425 - ca2-[0,5]: 1093.2060 - ca2-[6,11]: 691.1018 - ca2-[12,17]: 345.9002 - ca2-[18,23]: 169.0121 - ca3-[0,5]: 705.2333 - ca3-[6,11]: 462.5839 - ca3-[12,17]: 325.4408 - ca3-[18,23]: 120.2025 - ca4-[0,5]: 341.5128 - ca4-[6,11]: 705.9897 - ca4-[12,17]: 364.5757 - ca4-[18,23]: 181.5713 - val_ca1-[0,5]: 0.2808 - val_ca1-[6,11]: 0.9321 - val_ca1-[12,17]: 5.1391 - val_ca1-[18,23]: 34.1334 - val_ca2-[0,5]: 1090.5640 - val_ca2-[6,11]: 719.4368 - val_ca2-[12,17]: 375.4135 - val_ca2-[18,23]: 169.8292 - val_ca3-[0,5]: 879.6168 - val_ca3-[6,11]: 551.6137 - val_ca3-[12,17]: 258.9528 - val_ca3-[18,23]: 101.1823 - val_ca4-[0,5]: 1083.7290 - val_ca4-[6,11]: 713.9297 - val_ca4-[12,17]: 371.4877 - val_ca4-[18,23]: 167.3756\n",
      "Epoch 196/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.2643 - ca1-[6,11]: 0.5033 - ca1-[12,17]: 1.6913 - ca1-[18,23]: 26.4271 - ca2-[0,5]: 1100.7553 - ca2-[6,11]: 702.7969 - ca2-[12,17]: 349.5562 - ca2-[18,23]: 170.6333 - ca3-[0,5]: 742.0674 - ca3-[6,11]: 491.2774 - ca3-[12,17]: 328.9902 - ca3-[18,23]: 122.9429 - ca4-[0,5]: 345.8022 - ca4-[6,11]: 687.3347 - ca4-[12,17]: 370.9957 - ca4-[18,23]: 178.0449 - val_ca1-[0,5]: 0.2685 - val_ca1-[6,11]: 0.9193 - val_ca1-[12,17]: 5.0279 - val_ca1-[18,23]: 33.3204 - val_ca2-[0,5]: 1102.0895 - val_ca2-[6,11]: 728.7325 - val_ca2-[12,17]: 382.0538 - val_ca2-[18,23]: 173.9977 - val_ca3-[0,5]: 891.9551 - val_ca3-[6,11]: 561.2950 - val_ca3-[12,17]: 265.4695 - val_ca3-[18,23]: 104.7530 - val_ca4-[0,5]: 1095.3005 - val_ca4-[6,11]: 723.2559 - val_ca4-[12,17]: 378.1394 - val_ca4-[18,23]: 171.5377\n",
      "Epoch 197/300\n",
      "26/26 [==============================] - 3s 124ms/step - ca1-[0,5]: 0.2530 - ca1-[6,11]: 0.4345 - ca1-[12,17]: 1.5634 - ca1-[18,23]: 24.6684 - ca2-[0,5]: 1116.3053 - ca2-[6,11]: 709.3458 - ca2-[12,17]: 357.0983 - ca2-[18,23]: 177.7911 - ca3-[0,5]: 757.4422 - ca3-[6,11]: 503.3170 - ca3-[12,17]: 344.6082 - ca3-[18,23]: 129.3185 - ca4-[0,5]: 350.1248 - ca4-[6,11]: 687.5609 - ca4-[12,17]: 383.4818 - ca4-[18,23]: 189.5514 - val_ca1-[0,5]: 0.2570 - val_ca1-[6,11]: 0.8813 - val_ca1-[12,17]: 4.6778 - val_ca1-[18,23]: 32.4986 - val_ca2-[0,5]: 1113.6426 - val_ca2-[6,11]: 738.0629 - val_ca2-[12,17]: 389.9806 - val_ca2-[18,23]: 178.2151 - val_ca3-[0,5]: 904.2157 - val_ca3-[6,11]: 570.9335 - val_ca3-[12,17]: 273.0180 - val_ca3-[18,23]: 108.3615 - val_ca4-[0,5]: 1106.9406 - val_ca4-[6,11]: 732.6489 - val_ca4-[12,17]: 386.0945 - val_ca4-[18,23]: 175.7639\n",
      "Epoch 198/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.2450 - ca1-[6,11]: 0.4522 - ca1-[12,17]: 1.5646 - ca1-[18,23]: 25.0843 - ca2-[0,5]: 1122.5562 - ca2-[6,11]: 715.0031 - ca2-[12,17]: 367.7691 - ca2-[18,23]: 180.2075 - ca3-[0,5]: 683.4752 - ca3-[6,11]: 510.0214 - ca3-[12,17]: 341.3658 - ca3-[18,23]: 131.5319 - ca4-[0,5]: 341.9328 - ca4-[6,11]: 743.2889 - ca4-[12,17]: 379.7882 - ca4-[18,23]: 184.2630 - val_ca1-[0,5]: 0.2463 - val_ca1-[6,11]: 0.8765 - val_ca1-[12,17]: 4.8152 - val_ca1-[18,23]: 31.8475 - val_ca2-[0,5]: 1125.3022 - val_ca2-[6,11]: 747.4906 - val_ca2-[12,17]: 395.5058 - val_ca2-[18,23]: 182.5100 - val_ca3-[0,5]: 916.4562 - val_ca3-[6,11]: 580.5742 - val_ca3-[12,17]: 278.5291 - val_ca3-[18,23]: 112.0229 - val_ca4-[0,5]: 1118.6385 - val_ca4-[6,11]: 742.1011 - val_ca4-[12,17]: 391.6337 - val_ca4-[18,23]: 180.0507\n",
      "Epoch 199/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.2292 - ca1-[6,11]: 0.3679 - ca1-[12,17]: 1.4834 - ca1-[18,23]: 22.7549 - ca2-[0,5]: 1131.8259 - ca2-[6,11]: 728.1062 - ca2-[12,17]: 368.2455 - ca2-[18,23]: 182.2872 - ca3-[0,5]: 775.2697 - ca3-[6,11]: 517.0424 - ca3-[12,17]: 323.1960 - ca3-[18,23]: 139.8646 - ca4-[0,5]: 358.8435 - ca4-[6,11]: 669.8437 - ca4-[12,17]: 391.6783 - ca4-[18,23]: 187.5194 - val_ca1-[0,5]: 0.2359 - val_ca1-[6,11]: 0.8449 - val_ca1-[12,17]: 4.6682 - val_ca1-[18,23]: 31.0844 - val_ca2-[0,5]: 1136.9594 - val_ca2-[6,11]: 756.9281 - val_ca2-[12,17]: 402.2991 - val_ca2-[18,23]: 186.8422 - val_ca3-[0,5]: 928.6498 - val_ca3-[6,11]: 590.1951 - val_ca3-[12,17]: 285.0860 - val_ca3-[18,23]: 115.7274 - val_ca4-[0,5]: 1130.3741 - val_ca4-[6,11]: 751.5954 - val_ca4-[12,17]: 398.4584 - val_ca4-[18,23]: 184.3902\n",
      "Epoch 200/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.2229 - ca1-[6,11]: 0.3725 - ca1-[12,17]: 1.2873 - ca1-[18,23]: 22.4680 - ca2-[0,5]: 1151.2371 - ca2-[6,11]: 739.1261 - ca2-[12,17]: 374.4919 - ca2-[18,23]: 186.4933 - ca3-[0,5]: 790.6286 - ca3-[6,11]: 529.4003 - ca3-[12,17]: 355.0085 - ca3-[18,23]: 137.2611 - ca4-[0,5]: 363.2300 - ca4-[6,11]: 763.8161 - ca4-[12,17]: 399.6306 - ca4-[18,23]: 207.4306 - val_ca1-[0,5]: 0.2263 - val_ca1-[6,11]: 0.7809 - val_ca1-[12,17]: 4.5436 - val_ca1-[18,23]: 30.3007 - val_ca2-[0,5]: 1148.7419 - val_ca2-[6,11]: 766.6784 - val_ca2-[12,17]: 409.1911 - val_ca2-[18,23]: 191.2592 - val_ca3-[0,5]: 940.7950 - val_ca3-[6,11]: 599.9793 - val_ca3-[12,17]: 291.6537 - val_ca3-[18,23]: 119.4726 - val_ca4-[0,5]: 1142.1729 - val_ca4-[6,11]: 761.3518 - val_ca4-[12,17]: 405.3455 - val_ca4-[18,23]: 188.7918\n",
      "Epoch 201/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.2067 - ca1-[6,11]: 0.3369 - ca1-[12,17]: 1.5136 - ca1-[18,23]: 22.0275 - ca2-[0,5]: 1159.1888 - ca2-[6,11]: 751.3282 - ca2-[12,17]: 387.0317 - ca2-[18,23]: 195.9348 - ca3-[0,5]: 769.1151 - ca3-[6,11]: 535.5849 - ca3-[12,17]: 369.0078 - ca3-[18,23]: 144.6612 - ca4-[0,5]: 379.0970 - ca4-[6,11]: 657.0830 - ca4-[12,17]: 405.1467 - ca4-[18,23]: 200.1229 - val_ca1-[0,5]: 0.2172 - val_ca1-[6,11]: 0.7899 - val_ca1-[12,17]: 4.2961 - val_ca1-[18,23]: 29.5597 - val_ca2-[0,5]: 1160.5859 - val_ca2-[6,11]: 776.0903 - val_ca2-[12,17]: 414.3951 - val_ca2-[18,23]: 195.7374 - val_ca3-[0,5]: 952.9426 - val_ca3-[6,11]: 609.4128 - val_ca3-[12,17]: 296.7782 - val_ca3-[18,23]: 123.2731 - val_ca4-[0,5]: 1154.0377 - val_ca4-[6,11]: 770.7745 - val_ca4-[12,17]: 410.5558 - val_ca4-[18,23]: 193.2568\n",
      "Epoch 202/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.2018 - ca1-[6,11]: 0.3230 - ca1-[12,17]: 1.0594 - ca1-[18,23]: 21.6117 - ca2-[0,5]: 1173.9717 - ca2-[6,11]: 724.5103 - ca2-[12,17]: 393.4406 - ca2-[18,23]: 197.9766 - ca3-[0,5]: 803.7835 - ca3-[6,11]: 545.6959 - ca3-[12,17]: 378.3027 - ca3-[18,23]: 152.5383 - ca4-[0,5]: 287.2443 - ca4-[6,11]: 775.1698 - ca4-[12,17]: 411.7358 - ca4-[18,23]: 205.5794 - val_ca1-[0,5]: 0.2081 - val_ca1-[6,11]: 0.7613 - val_ca1-[12,17]: 4.2726 - val_ca1-[18,23]: 28.8595 - val_ca2-[0,5]: 1172.4594 - val_ca2-[6,11]: 785.7375 - val_ca2-[12,17]: 423.1399 - val_ca2-[18,23]: 200.2647 - val_ca3-[0,5]: 965.1101 - val_ca3-[6,11]: 619.0628 - val_ca3-[12,17]: 304.9104 - val_ca3-[18,23]: 127.1333 - val_ca4-[0,5]: 1165.9528 - val_ca4-[6,11]: 780.4492 - val_ca4-[12,17]: 419.3031 - val_ca4-[18,23]: 197.7790\n",
      "Epoch 203/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.1950 - ca1-[6,11]: 0.3611 - ca1-[12,17]: 1.3703 - ca1-[18,23]: 20.6264 - ca2-[0,5]: 1186.0007 - ca2-[6,11]: 763.1911 - ca2-[12,17]: 390.8193 - ca2-[18,23]: 199.9320 - ca3-[0,5]: 819.2210 - ca3-[6,11]: 555.7401 - ca3-[12,17]: 349.3347 - ca3-[18,23]: 155.8886 - ca4-[0,5]: 364.9868 - ca4-[6,11]: 712.6141 - ca4-[12,17]: 419.2669 - ca4-[18,23]: 210.8459 - val_ca1-[0,5]: 0.1995 - val_ca1-[6,11]: 0.7635 - val_ca1-[12,17]: 4.0526 - val_ca1-[18,23]: 28.2771 - val_ca2-[0,5]: 1184.3818 - val_ca2-[6,11]: 795.4357 - val_ca2-[12,17]: 431.5002 - val_ca2-[18,23]: 204.8480 - val_ca3-[0,5]: 977.2871 - val_ca3-[6,11]: 628.7361 - val_ca3-[12,17]: 312.7112 - val_ca3-[18,23]: 131.0490 - val_ca4-[0,5]: 1177.9458 - val_ca4-[6,11]: 790.1990 - val_ca4-[12,17]: 427.6858 - val_ca4-[18,23]: 202.3692\n",
      "Epoch 204/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.1832 - ca1-[6,11]: 0.3474 - ca1-[12,17]: 1.0760 - ca1-[18,23]: 19.7357 - ca2-[0,5]: 1197.3659 - ca2-[6,11]: 779.7549 - ca2-[12,17]: 406.4546 - ca2-[18,23]: 208.9777 - ca3-[0,5]: 762.5323 - ca3-[6,11]: 563.9853 - ca3-[12,17]: 390.3378 - ca3-[18,23]: 152.9678 - ca4-[0,5]: 329.4504 - ca4-[6,11]: 754.0084 - ca4-[12,17]: 414.0010 - ca4-[18,23]: 218.8481 - val_ca1-[0,5]: 0.1917 - val_ca1-[6,11]: 0.7164 - val_ca1-[12,17]: 3.9497 - val_ca1-[18,23]: 27.4163 - val_ca2-[0,5]: 1196.3789 - val_ca2-[6,11]: 805.2064 - val_ca2-[12,17]: 435.5147 - val_ca2-[18,23]: 209.4975 - val_ca3-[0,5]: 989.4391 - val_ca3-[6,11]: 638.4055 - val_ca3-[12,17]: 316.7841 - val_ca3-[18,23]: 135.0082 - val_ca4-[0,5]: 1189.9807 - val_ca4-[6,11]: 799.9940 - val_ca4-[12,17]: 431.7230 - val_ca4-[18,23]: 207.0132\n",
      "Epoch 205/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.1755 - ca1-[6,11]: 0.3132 - ca1-[12,17]: 1.0938 - ca1-[18,23]: 18.9962 - ca2-[0,5]: 1205.1150 - ca2-[6,11]: 794.1052 - ca2-[12,17]: 406.9890 - ca2-[18,23]: 217.3957 - ca3-[0,5]: 841.2278 - ca3-[6,11]: 573.2403 - ca3-[12,17]: 348.6688 - ca3-[18,23]: 164.7451 - ca4-[0,5]: 385.6084 - ca4-[6,11]: 767.6198 - ca4-[12,17]: 433.9299 - ca4-[18,23]: 214.3876 - val_ca1-[0,5]: 0.1847 - val_ca1-[6,11]: 0.7238 - val_ca1-[12,17]: 3.8874 - val_ca1-[18,23]: 26.9506 - val_ca2-[0,5]: 1208.4453 - val_ca2-[6,11]: 815.0443 - val_ca2-[12,17]: 444.2440 - val_ca2-[18,23]: 214.2110 - val_ca3-[0,5]: 1001.6180 - val_ca3-[6,11]: 648.1114 - val_ca3-[12,17]: 324.8834 - val_ca3-[18,23]: 139.0269 - val_ca4-[0,5]: 1202.0682 - val_ca4-[6,11]: 809.8433 - val_ca4-[12,17]: 440.4458 - val_ca4-[18,23]: 211.7154\n",
      "Epoch 206/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.1706 - ca1-[6,11]: 0.2975 - ca1-[12,17]: 0.9965 - ca1-[18,23]: 18.9946 - ca2-[0,5]: 1219.6873 - ca2-[6,11]: 793.7479 - ca2-[12,17]: 415.4876 - ca2-[18,23]: 221.5127 - ca3-[0,5]: 856.7892 - ca3-[6,11]: 584.5787 - ca3-[12,17]: 404.8603 - ca3-[18,23]: 160.5721 - ca4-[0,5]: 416.6254 - ca4-[6,11]: 825.8800 - ca4-[12,17]: 442.1525 - ca4-[18,23]: 228.6817 - val_ca1-[0,5]: 0.1769 - val_ca1-[6,11]: 0.6836 - val_ca1-[12,17]: 3.8841 - val_ca1-[18,23]: 26.2142 - val_ca2-[0,5]: 1220.5889 - val_ca2-[6,11]: 824.9564 - val_ca2-[12,17]: 451.7464 - val_ca2-[18,23]: 218.9919 - val_ca3-[0,5]: 1013.8187 - val_ca3-[6,11]: 657.8498 - val_ca3-[12,17]: 331.8804 - val_ca3-[18,23]: 143.1026 - val_ca4-[0,5]: 1214.2483 - val_ca4-[6,11]: 819.7794 - val_ca4-[12,17]: 447.9554 - val_ca4-[18,23]: 216.4910\n",
      "Epoch 207/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.1639 - ca1-[6,11]: 0.3414 - ca1-[12,17]: 0.9794 - ca1-[18,23]: 18.0257 - ca2-[0,5]: 1233.8717 - ca2-[6,11]: 810.0680 - ca2-[12,17]: 422.4652 - ca2-[18,23]: 222.2486 - ca3-[0,5]: 828.1656 - ca3-[6,11]: 590.8974 - ca3-[12,17]: 398.5532 - ca3-[18,23]: 174.0115 - ca4-[0,5]: 421.5661 - ca4-[6,11]: 781.0689 - ca4-[12,17]: 450.0214 - ca4-[18,23]: 223.5707 - val_ca1-[0,5]: 0.1704 - val_ca1-[6,11]: 0.6721 - val_ca1-[12,17]: 3.6369 - val_ca1-[18,23]: 25.6436 - val_ca2-[0,5]: 1232.8019 - val_ca2-[6,11]: 834.9368 - val_ca2-[12,17]: 460.4230 - val_ca2-[18,23]: 223.7842 - val_ca3-[0,5]: 1026.0676 - val_ca3-[6,11]: 667.6416 - val_ca3-[12,17]: 339.9041 - val_ca3-[18,23]: 147.2640 - val_ca4-[0,5]: 1226.4941 - val_ca4-[6,11]: 829.7811 - val_ca4-[12,17]: 456.6332 - val_ca4-[18,23]: 221.2794\n",
      "Epoch 208/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.1582 - ca1-[6,11]: 0.2894 - ca1-[12,17]: 0.9410 - ca1-[18,23]: 17.1763 - ca2-[0,5]: 1244.2699 - ca2-[6,11]: 817.5265 - ca2-[12,17]: 429.8540 - ca2-[18,23]: 226.2563 - ca3-[0,5]: 838.8167 - ca3-[6,11]: 602.5535 - ca3-[12,17]: 398.8588 - ca3-[18,23]: 179.4811 - ca4-[0,5]: 438.4388 - ca4-[6,11]: 834.3203 - ca4-[12,17]: 455.8105 - ca4-[18,23]: 230.9101 - val_ca1-[0,5]: 0.1638 - val_ca1-[6,11]: 0.6525 - val_ca1-[12,17]: 3.7299 - val_ca1-[18,23]: 25.0726 - val_ca2-[0,5]: 1245.0768 - val_ca2-[6,11]: 844.9787 - val_ca2-[12,17]: 466.4498 - val_ca2-[18,23]: 228.7439 - val_ca3-[0,5]: 1038.3173 - val_ca3-[6,11]: 677.4487 - val_ca3-[12,17]: 345.6437 - val_ca3-[18,23]: 151.4335 - val_ca4-[0,5]: 1238.7972 - val_ca4-[6,11]: 839.8403 - val_ca4-[12,17]: 462.6700 - val_ca4-[18,23]: 226.2292\n",
      "Epoch 209/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.1478 - ca1-[6,11]: 0.2797 - ca1-[12,17]: 1.0024 - ca1-[18,23]: 17.1200 - ca2-[0,5]: 1262.1915 - ca2-[6,11]: 827.0606 - ca2-[12,17]: 439.1753 - ca2-[18,23]: 230.6376 - ca3-[0,5]: 885.5106 - ca3-[6,11]: 616.0507 - ca3-[12,17]: 430.1627 - ca3-[18,23]: 184.6609 - ca4-[0,5]: 404.0155 - ca4-[6,11]: 806.8664 - ca4-[12,17]: 469.7505 - ca4-[18,23]: 237.0831 - val_ca1-[0,5]: 0.1579 - val_ca1-[6,11]: 0.6472 - val_ca1-[12,17]: 3.6977 - val_ca1-[18,23]: 24.5549 - val_ca2-[0,5]: 1257.3527 - val_ca2-[6,11]: 855.0326 - val_ca2-[12,17]: 473.8570 - val_ca2-[18,23]: 233.6874 - val_ca3-[0,5]: 1050.6108 - val_ca3-[6,11]: 687.3055 - val_ca3-[12,17]: 352.5982 - val_ca3-[18,23]: 155.6863 - val_ca4-[0,5]: 1251.1582 - val_ca4-[6,11]: 849.9579 - val_ca4-[12,17]: 470.1162 - val_ca4-[18,23]: 231.1883\n",
      "Epoch 210/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.1440 - ca1-[6,11]: 0.2405 - ca1-[12,17]: 0.8416 - ca1-[18,23]: 16.3488 - ca2-[0,5]: 1270.8444 - ca2-[6,11]: 833.3959 - ca2-[12,17]: 445.5660 - ca2-[18,23]: 236.2872 - ca3-[0,5]: 896.6601 - ca3-[6,11]: 620.2926 - ca3-[12,17]: 432.4769 - ca3-[18,23]: 189.8429 - ca4-[0,5]: 408.6865 - ca4-[6,11]: 844.9977 - ca4-[12,17]: 473.9538 - ca4-[18,23]: 244.5573 - val_ca1-[0,5]: 0.1516 - val_ca1-[6,11]: 0.6204 - val_ca1-[12,17]: 3.5687 - val_ca1-[18,23]: 23.8855 - val_ca2-[0,5]: 1269.6953 - val_ca2-[6,11]: 865.1519 - val_ca2-[12,17]: 481.3284 - val_ca2-[18,23]: 238.6938 - val_ca3-[0,5]: 1062.9314 - val_ca3-[6,11]: 697.1982 - val_ca3-[12,17]: 359.5995 - val_ca3-[18,23]: 159.9958 - val_ca4-[0,5]: 1263.6034 - val_ca4-[6,11]: 860.1560 - val_ca4-[12,17]: 477.6378 - val_ca4-[18,23]: 236.2183\n",
      "Epoch 211/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.1387 - ca1-[6,11]: 0.2522 - ca1-[12,17]: 0.8381 - ca1-[18,23]: 15.6593 - ca2-[0,5]: 1280.6885 - ca2-[6,11]: 838.3697 - ca2-[12,17]: 449.3528 - ca2-[18,23]: 237.6049 - ca3-[0,5]: 907.8338 - ca3-[6,11]: 630.5719 - ca3-[12,17]: 422.1735 - ca3-[18,23]: 194.5004 - ca4-[0,5]: 360.8953 - ca4-[6,11]: 858.4829 - ca4-[12,17]: 477.0069 - ca4-[18,23]: 250.7895 - val_ca1-[0,5]: 0.1461 - val_ca1-[6,11]: 0.6039 - val_ca1-[12,17]: 3.4964 - val_ca1-[18,23]: 23.3684 - val_ca2-[0,5]: 1282.1322 - val_ca2-[6,11]: 875.3595 - val_ca2-[12,17]: 488.8811 - val_ca2-[18,23]: 243.7747 - val_ca3-[0,5]: 1075.2748 - val_ca3-[6,11]: 707.1238 - val_ca3-[12,17]: 366.6448 - val_ca3-[18,23]: 164.3601 - val_ca4-[0,5]: 1276.0684 - val_ca4-[6,11]: 870.3812 - val_ca4-[12,17]: 485.1955 - val_ca4-[18,23]: 241.2928\n",
      "Epoch 212/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.1327 - ca1-[6,11]: 0.2455 - ca1-[12,17]: 0.7442 - ca1-[18,23]: 15.7356 - ca2-[0,5]: 1297.3092 - ca2-[6,11]: 857.7192 - ca2-[12,17]: 462.9795 - ca2-[18,23]: 246.1283 - ca3-[0,5]: 881.6836 - ca3-[6,11]: 640.4604 - ca3-[12,17]: 414.2922 - ca3-[18,23]: 190.0799 - ca4-[0,5]: 418.1069 - ca4-[6,11]: 871.0943 - ca4-[12,17]: 486.9873 - ca4-[18,23]: 258.3180 - val_ca1-[0,5]: 0.1413 - val_ca1-[6,11]: 0.6008 - val_ca1-[12,17]: 3.4837 - val_ca1-[18,23]: 22.9517 - val_ca2-[0,5]: 1294.6239 - val_ca2-[6,11]: 885.6233 - val_ca2-[12,17]: 496.4908 - val_ca2-[18,23]: 248.9140 - val_ca3-[0,5]: 1087.6526 - val_ca3-[6,11]: 717.0906 - val_ca3-[12,17]: 373.7402 - val_ca3-[18,23]: 168.7825 - val_ca4-[0,5]: 1288.6025 - val_ca4-[6,11]: 880.6746 - val_ca4-[12,17]: 492.8197 - val_ca4-[18,23]: 246.4322\n",
      "Epoch 213/300\n",
      "26/26 [==============================] - 3s 129ms/step - ca1-[0,5]: 0.1299 - ca1-[6,11]: 0.2366 - ca1-[12,17]: 0.8947 - ca1-[18,23]: 15.1680 - ca2-[0,5]: 1308.4840 - ca2-[6,11]: 866.1685 - ca2-[12,17]: 467.4539 - ca2-[18,23]: 255.5457 - ca3-[0,5]: 797.8756 - ca3-[6,11]: 649.7564 - ca3-[12,17]: 400.4156 - ca3-[18,23]: 204.0047 - ca4-[0,5]: 435.0677 - ca4-[6,11]: 883.0671 - ca4-[12,17]: 496.5507 - ca4-[18,23]: 258.9225 - val_ca1-[0,5]: 0.1357 - val_ca1-[6,11]: 0.5286 - val_ca1-[12,17]: 3.3713 - val_ca1-[18,23]: 22.4047 - val_ca2-[0,5]: 1307.1957 - val_ca2-[6,11]: 895.8917 - val_ca2-[12,17]: 504.1732 - val_ca2-[18,23]: 254.1222 - val_ca3-[0,5]: 1100.0658 - val_ca3-[6,11]: 727.0422 - val_ca3-[12,17]: 380.8863 - val_ca3-[18,23]: 173.2631 - val_ca4-[0,5]: 1301.1708 - val_ca4-[6,11]: 890.9354 - val_ca4-[12,17]: 500.4886 - val_ca4-[18,23]: 251.6218\n",
      "Epoch 214/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.1239 - ca1-[6,11]: 0.2513 - ca1-[12,17]: 0.7233 - ca1-[18,23]: 15.0624 - ca2-[0,5]: 1269.4026 - ca2-[6,11]: 876.9364 - ca2-[12,17]: 473.2701 - ca2-[18,23]: 257.6866 - ca3-[0,5]: 898.5126 - ca3-[6,11]: 659.3729 - ca3-[12,17]: 468.3817 - ca3-[18,23]: 209.8937 - ca4-[0,5]: 427.6085 - ca4-[6,11]: 885.6322 - ca4-[12,17]: 498.4582 - ca4-[18,23]: 269.9821 - val_ca1-[0,5]: 0.1319 - val_ca1-[6,11]: 0.5382 - val_ca1-[12,17]: 3.3836 - val_ca1-[18,23]: 22.0131 - val_ca2-[0,5]: 1319.8348 - val_ca2-[6,11]: 906.5815 - val_ca2-[12,17]: 511.9204 - val_ca2-[18,23]: 259.3119 - val_ca3-[0,5]: 1112.5033 - val_ca3-[6,11]: 737.3397 - val_ca3-[12,17]: 388.0762 - val_ca3-[18,23]: 177.7864 - val_ca4-[0,5]: 1313.7976 - val_ca4-[6,11]: 901.6091 - val_ca4-[12,17]: 508.2170 - val_ca4-[18,23]: 256.7914\n",
      "Epoch 215/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.1202 - ca1-[6,11]: 0.2438 - ca1-[12,17]: 0.6323 - ca1-[18,23]: 14.6780 - ca2-[0,5]: 1335.6942 - ca2-[6,11]: 889.2056 - ca2-[12,17]: 491.1300 - ca2-[18,23]: 264.4207 - ca3-[0,5]: 952.8394 - ca3-[6,11]: 666.6457 - ca3-[12,17]: 452.2354 - ca3-[18,23]: 205.2249 - ca4-[0,5]: 390.3349 - ca4-[6,11]: 896.7852 - ca4-[12,17]: 504.9593 - ca4-[18,23]: 277.8027 - val_ca1-[0,5]: 0.1279 - val_ca1-[6,11]: 0.5590 - val_ca1-[12,17]: 3.2597 - val_ca1-[18,23]: 21.4154 - val_ca2-[0,5]: 1332.4716 - val_ca2-[6,11]: 916.7849 - val_ca2-[12,17]: 519.6896 - val_ca2-[18,23]: 264.7000 - val_ca3-[0,5]: 1124.9744 - val_ca3-[6,11]: 747.2250 - val_ca3-[12,17]: 395.3150 - val_ca3-[18,23]: 182.3887 - val_ca4-[0,5]: 1326.5261 - val_ca4-[6,11]: 911.8835 - val_ca4-[12,17]: 516.0314 - val_ca4-[18,23]: 262.1991\n",
      "Epoch 216/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.1147 - ca1-[6,11]: 0.1928 - ca1-[12,17]: 0.7267 - ca1-[18,23]: 13.7750 - ca2-[0,5]: 1348.5513 - ca2-[6,11]: 895.4445 - ca2-[12,17]: 490.5211 - ca2-[18,23]: 267.4006 - ca3-[0,5]: 964.1871 - ca3-[6,11]: 677.6192 - ca3-[12,17]: 460.1977 - ca3-[18,23]: 221.8853 - ca4-[0,5]: 437.2447 - ca4-[6,11]: 919.4813 - ca4-[12,17]: 520.5645 - ca4-[18,23]: 291.4096 - val_ca1-[0,5]: 0.1230 - val_ca1-[6,11]: 0.5458 - val_ca1-[12,17]: 3.2387 - val_ca1-[18,23]: 21.0540 - val_ca2-[0,5]: 1345.2047 - val_ca2-[6,11]: 927.2902 - val_ca2-[12,17]: 527.5415 - val_ca2-[18,23]: 270.0818 - val_ca3-[0,5]: 1137.5319 - val_ca3-[6,11]: 757.3916 - val_ca3-[12,17]: 402.6334 - val_ca3-[18,23]: 187.0559 - val_ca4-[0,5]: 1339.3112 - val_ca4-[6,11]: 922.4267 - val_ca4-[12,17]: 523.9044 - val_ca4-[18,23]: 267.5865\n",
      "Epoch 217/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.1132 - ca1-[6,11]: 0.2248 - ca1-[12,17]: 0.6159 - ca1-[18,23]: 13.3822 - ca2-[0,5]: 1358.3610 - ca2-[6,11]: 899.5657 - ca2-[12,17]: 499.7958 - ca2-[18,23]: 277.1599 - ca3-[0,5]: 975.6042 - ca3-[6,11]: 692.9612 - ca3-[12,17]: 467.6064 - ca3-[18,23]: 213.8186 - ca4-[0,5]: 447.4826 - ca4-[6,11]: 915.7651 - ca4-[12,17]: 523.3979 - ca4-[18,23]: 291.9108 - val_ca1-[0,5]: 0.1182 - val_ca1-[6,11]: 0.5153 - val_ca1-[12,17]: 2.8804 - val_ca1-[18,23]: 20.4501 - val_ca2-[0,5]: 1357.9901 - val_ca2-[6,11]: 937.8495 - val_ca2-[12,17]: 534.7637 - val_ca2-[18,23]: 275.5209 - val_ca3-[0,5]: 1150.1053 - val_ca3-[6,11]: 767.5840 - val_ca3-[12,17]: 409.4065 - val_ca3-[18,23]: 191.7727 - val_ca4-[0,5]: 1352.1289 - val_ca4-[6,11]: 933.0074 - val_ca4-[12,17]: 531.1386 - val_ca4-[18,23]: 273.0230\n",
      "Epoch 218/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.1063 - ca1-[6,11]: 0.1942 - ca1-[12,17]: 0.5728 - ca1-[18,23]: 13.3524 - ca2-[0,5]: 1371.0248 - ca2-[6,11]: 928.2104 - ca2-[12,17]: 502.0531 - ca2-[18,23]: 278.6763 - ca3-[0,5]: 987.0325 - ca3-[6,11]: 696.3474 - ca3-[12,17]: 493.7986 - ca3-[18,23]: 219.6257 - ca4-[0,5]: 403.5868 - ca4-[6,11]: 943.6717 - ca4-[12,17]: 531.3972 - ca4-[18,23]: 298.4417 - val_ca1-[0,5]: 0.1154 - val_ca1-[6,11]: 0.5175 - val_ca1-[12,17]: 3.0995 - val_ca1-[18,23]: 20.1039 - val_ca2-[0,5]: 1370.9570 - val_ca2-[6,11]: 948.5692 - val_ca2-[12,17]: 543.4921 - val_ca2-[18,23]: 280.9738 - val_ca3-[0,5]: 1162.7084 - val_ca3-[6,11]: 777.8138 - val_ca3-[12,17]: 417.3930 - val_ca3-[18,23]: 196.5151 - val_ca4-[0,5]: 1365.0104 - val_ca4-[6,11]: 943.6516 - val_ca4-[12,17]: 539.8005 - val_ca4-[18,23]: 278.4254\n",
      "Epoch 219/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.1041 - ca1-[6,11]: 0.2133 - ca1-[12,17]: 0.5154 - ca1-[18,23]: 12.3431 - ca2-[0,5]: 1379.0172 - ca2-[6,11]: 934.5142 - ca2-[12,17]: 510.2709 - ca2-[18,23]: 288.0307 - ca3-[0,5]: 932.1786 - ca3-[6,11]: 705.3252 - ca3-[12,17]: 482.8240 - ca3-[18,23]: 236.3391 - ca4-[0,5]: 464.4767 - ca4-[6,11]: 940.5433 - ca4-[12,17]: 545.2035 - ca4-[18,23]: 290.5844 - val_ca1-[0,5]: 0.1115 - val_ca1-[6,11]: 0.4921 - val_ca1-[12,17]: 2.9648 - val_ca1-[18,23]: 19.5833 - val_ca2-[0,5]: 1384.9651 - val_ca2-[6,11]: 960.1614 - val_ca2-[12,17]: 552.2072 - val_ca2-[18,23]: 287.1090 - val_ca3-[0,5]: 1175.3616 - val_ca3-[6,11]: 788.0970 - val_ca3-[12,17]: 424.8537 - val_ca3-[18,23]: 201.3770 - val_ca4-[0,5]: 1377.9072 - val_ca4-[6,11]: 954.3190 - val_ca4-[12,17]: 547.8127 - val_ca4-[18,23]: 284.0625\n",
      "Epoch 220/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0988 - ca1-[6,11]: 0.1776 - ca1-[12,17]: 0.5242 - ca1-[18,23]: 12.2817 - ca2-[0,5]: 1401.9277 - ca2-[6,11]: 940.9077 - ca2-[12,17]: 524.0272 - ca2-[18,23]: 287.6727 - ca3-[0,5]: 974.0062 - ca3-[6,11]: 718.3436 - ca3-[12,17]: 494.3275 - ca3-[18,23]: 226.8050 - ca4-[0,5]: 475.6342 - ca4-[6,11]: 917.6173 - ca4-[12,17]: 547.9629 - ca4-[18,23]: 308.9364 - val_ca1-[0,5]: 0.1090 - val_ca1-[6,11]: 0.4917 - val_ca1-[12,17]: 2.9834 - val_ca1-[18,23]: 19.2932 - val_ca2-[0,5]: 1420.9515 - val_ca2-[6,11]: 989.9962 - val_ca2-[12,17]: 574.7167 - val_ca2-[18,23]: 302.7998 - val_ca3-[0,5]: 1188.0775 - val_ca3-[6,11]: 798.4443 - val_ca3-[12,17]: 432.3794 - val_ca3-[18,23]: 206.2763 - val_ca4-[0,5]: 1390.9235 - val_ca4-[6,11]: 965.0961 - val_ca4-[12,17]: 555.9225 - val_ca4-[18,23]: 289.6893\n",
      "Epoch 221/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0994 - ca1-[6,11]: 0.1685 - ca1-[12,17]: 0.4811 - ca1-[18,23]: 12.0611 - ca2-[0,5]: 1440.8906 - ca2-[6,11]: 974.6657 - ca2-[12,17]: 546.7258 - ca2-[18,23]: 316.0026 - ca3-[0,5]: 1021.5972 - ca3-[6,11]: 728.3082 - ca3-[12,17]: 519.3725 - ca3-[18,23]: 235.2473 - ca4-[0,5]: 461.7601 - ca4-[6,11]: 967.2540 - ca4-[12,17]: 557.5575 - ca4-[18,23]: 317.2920 - val_ca1-[0,5]: 0.1048 - val_ca1-[6,11]: 0.4648 - val_ca1-[12,17]: 2.8631 - val_ca1-[18,23]: 18.8153 - val_ca2-[0,5]: 1457.9347 - val_ca2-[6,11]: 1020.7372 - val_ca2-[12,17]: 598.0249 - val_ca2-[18,23]: 319.1902 - val_ca3-[0,5]: 1200.8354 - val_ca3-[6,11]: 808.8386 - val_ca3-[12,17]: 439.9583 - val_ca3-[18,23]: 211.2343 - val_ca4-[0,5]: 1404.0112 - val_ca4-[6,11]: 975.9427 - val_ca4-[12,17]: 564.1001 - val_ca4-[18,23]: 295.3820\n",
      "Epoch 222/300\n",
      "26/26 [==============================] - 3s 124ms/step - ca1-[0,5]: 0.0954 - ca1-[6,11]: 0.1623 - ca1-[12,17]: 0.4298 - ca1-[18,23]: 11.0742 - ca2-[0,5]: 1479.6505 - ca2-[6,11]: 998.9559 - ca2-[12,17]: 567.2586 - ca2-[18,23]: 322.4152 - ca3-[0,5]: 1001.3108 - ca3-[6,11]: 737.9278 - ca3-[12,17]: 507.7444 - ca3-[18,23]: 252.2057 - ca4-[0,5]: 486.2240 - ca4-[6,11]: 880.5009 - ca4-[12,17]: 567.9553 - ca4-[18,23]: 308.6873 - val_ca1-[0,5]: 0.1022 - val_ca1-[6,11]: 0.4608 - val_ca1-[12,17]: 2.8484 - val_ca1-[18,23]: 18.4903 - val_ca2-[0,5]: 1482.9481 - val_ca2-[6,11]: 1041.5851 - val_ca2-[12,17]: 613.9037 - val_ca2-[18,23]: 330.4384 - val_ca3-[0,5]: 1213.6240 - val_ca3-[6,11]: 819.2701 - val_ca3-[12,17]: 447.5826 - val_ca3-[18,23]: 216.2454 - val_ca4-[0,5]: 1417.1498 - val_ca4-[6,11]: 986.8420 - val_ca4-[12,17]: 572.3322 - val_ca4-[18,23]: 301.1313\n",
      "Epoch 223/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0913 - ca1-[6,11]: 0.1596 - ca1-[12,17]: 0.4628 - ca1-[18,23]: 10.9828 - ca2-[0,5]: 1497.3452 - ca2-[6,11]: 1018.3656 - ca2-[12,17]: 584.2562 - ca2-[18,23]: 340.7742 - ca3-[0,5]: 1044.8662 - ca3-[6,11]: 747.2920 - ca3-[12,17]: 513.7831 - ca3-[18,23]: 264.5469 - ca4-[0,5]: 471.7630 - ca4-[6,11]: 941.6821 - ca4-[12,17]: 570.7333 - ca4-[18,23]: 321.6081 - val_ca1-[0,5]: 0.0999 - val_ca1-[6,11]: 0.4511 - val_ca1-[12,17]: 2.6969 - val_ca1-[18,23]: 18.1081 - val_ca2-[0,5]: 1504.7208 - val_ca2-[6,11]: 1059.7507 - val_ca2-[12,17]: 625.6286 - val_ca2-[18,23]: 340.3112 - val_ca3-[0,5]: 1226.4786 - val_ca3-[6,11]: 829.7682 - val_ca3-[12,17]: 453.4447 - val_ca3-[18,23]: 221.3240 - val_ca4-[0,5]: 1430.3490 - val_ca4-[6,11]: 997.8025 - val_ca4-[12,17]: 578.5617 - val_ca4-[18,23]: 306.9421\n",
      "Epoch 224/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0905 - ca1-[6,11]: 0.1546 - ca1-[12,17]: 0.4855 - ca1-[18,23]: 10.6625 - ca2-[0,5]: 1520.0591 - ca2-[6,11]: 1035.6392 - ca2-[12,17]: 597.7590 - ca2-[18,23]: 356.3131 - ca3-[0,5]: 1056.5823 - ca3-[6,11]: 755.8421 - ca3-[12,17]: 546.5528 - ca3-[18,23]: 251.2549 - ca4-[0,5]: 509.8901 - ca4-[6,11]: 946.1261 - ca4-[12,17]: 584.5141 - ca4-[18,23]: 332.4678 - val_ca1-[0,5]: 0.0965 - val_ca1-[6,11]: 0.4317 - val_ca1-[12,17]: 2.7021 - val_ca1-[18,23]: 17.6507 - val_ca2-[0,5]: 1525.2496 - val_ca2-[6,11]: 1076.9060 - val_ca2-[12,17]: 640.9097 - val_ca2-[18,23]: 349.7037 - val_ca3-[0,5]: 1239.3818 - val_ca3-[6,11]: 840.3185 - val_ca3-[12,17]: 463.0219 - val_ca3-[18,23]: 226.4630 - val_ca4-[0,5]: 1443.6014 - val_ca4-[6,11]: 1008.8167 - val_ca4-[12,17]: 588.9749 - val_ca4-[18,23]: 312.8102\n",
      "Epoch 225/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.0859 - ca1-[6,11]: 0.1051 - ca1-[12,17]: 0.4036 - ca1-[18,23]: 10.0404 - ca2-[0,5]: 1546.3737 - ca2-[6,11]: 1063.0808 - ca2-[12,17]: 607.5602 - ca2-[18,23]: 361.5697 - ca3-[0,5]: 1030.1615 - ca3-[6,11]: 764.5053 - ca3-[12,17]: 524.8806 - ca3-[18,23]: 269.7229 - ca4-[0,5]: 481.8672 - ca4-[6,11]: 998.8734 - ca4-[12,17]: 588.0591 - ca4-[18,23]: 331.4770 - val_ca1-[0,5]: 0.0943 - val_ca1-[6,11]: 0.4275 - val_ca1-[12,17]: 2.7007 - val_ca1-[18,23]: 17.2938 - val_ca2-[0,5]: 1544.9437 - val_ca2-[6,11]: 1093.3864 - val_ca2-[12,17]: 653.5605 - val_ca2-[18,23]: 358.6341 - val_ca3-[0,5]: 1252.3250 - val_ca3-[6,11]: 850.9136 - val_ca3-[12,17]: 470.8204 - val_ca3-[18,23]: 231.5987 - val_ca4-[0,5]: 1456.9067 - val_ca4-[6,11]: 1019.8855 - val_ca4-[12,17]: 597.3801 - val_ca4-[18,23]: 318.6102\n",
      "Epoch 226/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0838 - ca1-[6,11]: 0.1400 - ca1-[12,17]: 0.4663 - ca1-[18,23]: 10.1258 - ca2-[0,5]: 1557.8341 - ca2-[6,11]: 1029.9475 - ca2-[12,17]: 618.6399 - ca2-[18,23]: 367.2300 - ca3-[0,5]: 1075.0341 - ca3-[6,11]: 772.8252 - ca3-[12,17]: 566.4843 - ca3-[18,23]: 274.9037 - ca4-[0,5]: 486.9648 - ca4-[6,11]: 1019.9405 - ca4-[12,17]: 576.1925 - ca4-[18,23]: 341.0684 - val_ca1-[0,5]: 0.0913 - val_ca1-[6,11]: 0.4029 - val_ca1-[12,17]: 2.5996 - val_ca1-[18,23]: 16.8770 - val_ca2-[0,5]: 1564.1459 - val_ca2-[6,11]: 1109.4849 - val_ca2-[12,17]: 665.9552 - val_ca2-[18,23]: 367.5646 - val_ca3-[0,5]: 1265.3176 - val_ca3-[6,11]: 861.5617 - val_ca3-[12,17]: 478.6758 - val_ca3-[18,23]: 236.8502 - val_ca4-[0,5]: 1470.2731 - val_ca4-[6,11]: 1031.0159 - val_ca4-[12,17]: 605.8469 - val_ca4-[18,23]: 324.5932\n",
      "Epoch 227/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0822 - ca1-[6,11]: 0.1571 - ca1-[12,17]: 0.4482 - ca1-[18,23]: 9.9425 - ca2-[0,5]: 1578.1106 - ca2-[6,11]: 1091.6723 - ca2-[12,17]: 628.1420 - ca2-[18,23]: 376.0118 - ca3-[0,5]: 1052.9399 - ca3-[6,11]: 789.1471 - ca3-[12,17]: 548.0044 - ca3-[18,23]: 266.8110 - ca4-[0,5]: 526.3311 - ca4-[6,11]: 1023.6484 - ca4-[12,17]: 606.7653 - ca4-[18,23]: 348.6109 - val_ca1-[0,5]: 0.0892 - val_ca1-[6,11]: 0.3947 - val_ca1-[12,17]: 2.5504 - val_ca1-[18,23]: 16.6001 - val_ca2-[0,5]: 1582.7637 - val_ca2-[6,11]: 1125.1285 - val_ca2-[12,17]: 678.0551 - val_ca2-[18,23]: 376.4939 - val_ca3-[0,5]: 1278.3792 - val_ca3-[6,11]: 872.2779 - val_ca3-[12,17]: 486.5994 - val_ca3-[18,23]: 242.2377 - val_ca4-[0,5]: 1483.6705 - val_ca4-[6,11]: 1042.1820 - val_ca4-[12,17]: 614.3556 - val_ca4-[18,23]: 330.7579\n",
      "Epoch 228/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0806 - ca1-[6,11]: 0.1460 - ca1-[12,17]: 0.3300 - ca1-[18,23]: 9.5614 - ca2-[0,5]: 1595.5940 - ca2-[6,11]: 1064.5165 - ca2-[12,17]: 639.9473 - ca2-[18,23]: 391.6685 - ca3-[0,5]: 1103.9215 - ca3-[6,11]: 799.0791 - ca3-[12,17]: 526.7949 - ca3-[18,23]: 292.0387 - ca4-[0,5]: 462.5178 - ca4-[6,11]: 1040.9783 - ca4-[12,17]: 618.9320 - ca4-[18,23]: 356.5817 - val_ca1-[0,5]: 0.0866 - val_ca1-[6,11]: 0.3763 - val_ca1-[12,17]: 2.2820 - val_ca1-[18,23]: 16.2518 - val_ca2-[0,5]: 1600.0991 - val_ca2-[6,11]: 1139.6978 - val_ca2-[12,17]: 688.5772 - val_ca2-[18,23]: 384.7484 - val_ca3-[0,5]: 1291.5028 - val_ca3-[6,11]: 883.0577 - val_ca3-[12,17]: 493.9337 - val_ca3-[18,23]: 247.6266 - val_ca4-[0,5]: 1497.1106 - val_ca4-[6,11]: 1053.3939 - val_ca4-[12,17]: 622.1644 - val_ca4-[18,23]: 336.8453\n",
      "Epoch 229/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0795 - ca1-[6,11]: 0.1299 - ca1-[12,17]: 0.3429 - ca1-[18,23]: 8.9562 - ca2-[0,5]: 1611.9219 - ca2-[6,11]: 1116.7281 - ca2-[12,17]: 654.0859 - ca2-[18,23]: 388.1409 - ca3-[0,5]: 1115.8929 - ca3-[6,11]: 812.1994 - ca3-[12,17]: 588.6865 - ca3-[18,23]: 294.8264 - ca4-[0,5]: 502.3770 - ca4-[6,11]: 1003.5900 - ca4-[12,17]: 626.5246 - ca4-[18,23]: 360.2063 - val_ca1-[0,5]: 0.0852 - val_ca1-[6,11]: 0.3738 - val_ca1-[12,17]: 2.4517 - val_ca1-[18,23]: 15.7913 - val_ca2-[0,5]: 1606.6249 - val_ca2-[6,11]: 1145.7502 - val_ca2-[12,17]: 694.9877 - val_ca2-[18,23]: 389.1807 - val_ca3-[0,5]: 1304.6605 - val_ca3-[6,11]: 893.8774 - val_ca3-[12,17]: 502.6220 - val_ca3-[18,23]: 252.9921 - val_ca4-[0,5]: 1510.6766 - val_ca4-[6,11]: 1064.7209 - val_ca4-[12,17]: 631.5738 - val_ca4-[18,23]: 342.8807\n",
      "Epoch 230/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0767 - ca1-[6,11]: 0.1194 - ca1-[12,17]: 0.3119 - ca1-[18,23]: 8.5448 - ca2-[0,5]: 1605.1952 - ca2-[6,11]: 1101.0627 - ca2-[12,17]: 655.0330 - ca2-[18,23]: 392.7140 - ca3-[0,5]: 1127.9103 - ca3-[6,11]: 820.0785 - ca3-[12,17]: 552.6026 - ca3-[18,23]: 299.0489 - ca4-[0,5]: 543.0322 - ca4-[6,11]: 1055.3724 - ca4-[12,17]: 630.5880 - ca4-[18,23]: 368.4861 - val_ca1-[0,5]: 0.0824 - val_ca1-[6,11]: 0.3499 - val_ca1-[12,17]: 2.3282 - val_ca1-[18,23]: 15.4807 - val_ca2-[0,5]: 1527.6177 - val_ca2-[6,11]: 1081.2100 - val_ca2-[12,17]: 650.6385 - val_ca2-[18,23]: 361.0615 - val_ca3-[0,5]: 1317.8849 - val_ca3-[6,11]: 904.7639 - val_ca3-[12,17]: 510.7238 - val_ca3-[18,23]: 258.5784 - val_ca4-[0,5]: 1524.2905 - val_ca4-[6,11]: 1076.0985 - val_ca4-[12,17]: 640.2870 - val_ca4-[18,23]: 349.2565\n",
      "Epoch 231/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0770 - ca1-[6,11]: 0.1327 - ca1-[12,17]: 0.2863 - ca1-[18,23]: 8.0356 - ca2-[0,5]: 1473.7134 - ca2-[6,11]: 993.6162 - ca2-[12,17]: 565.0402 - ca2-[18,23]: 338.9265 - ca3-[0,5]: 1134.7389 - ca3-[6,11]: 831.6365 - ca3-[12,17]: 604.5920 - ca3-[18,23]: 307.8567 - ca4-[0,5]: 512.8035 - ca4-[6,11]: 1024.2249 - ca4-[12,17]: 652.8190 - ca4-[18,23]: 380.8668 - val_ca1-[0,5]: 0.0804 - val_ca1-[6,11]: 0.3462 - val_ca1-[12,17]: 2.3113 - val_ca1-[18,23]: 15.1786 - val_ca2-[0,5]: 453.0662 - val_ca2-[6,11]: 238.8364 - val_ca2-[12,17]: 126.7046 - val_ca2-[18,23]: 76.4827 - val_ca3-[0,5]: 1331.1537 - val_ca3-[6,11]: 915.6986 - val_ca3-[12,17]: 518.8785 - val_ca3-[18,23]: 264.1451 - val_ca4-[0,5]: 1537.9548 - val_ca4-[6,11]: 1087.5276 - val_ca4-[12,17]: 649.0543 - val_ca4-[18,23]: 355.5457\n",
      "Epoch 232/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0718 - ca1-[6,11]: 0.1063 - ca1-[12,17]: 0.2526 - ca1-[18,23]: 7.9579 - ca2-[0,5]: 259.5682 - ca2-[6,11]: 86.6729 - ca2-[12,17]: 18.5974 - ca2-[18,23]: 27.6139 - ca3-[0,5]: 1110.8000 - ca3-[6,11]: 845.3844 - ca3-[12,17]: 562.0792 - ca3-[18,23]: 311.8709 - ca4-[0,5]: 445.4635 - ca4-[6,11]: 1023.2224 - ca4-[12,17]: 650.8704 - ca4-[18,23]: 388.9966 - val_ca1-[0,5]: 0.0784 - val_ca1-[6,11]: 0.3300 - val_ca1-[12,17]: 2.2269 - val_ca1-[18,23]: 14.8125 - val_ca2-[0,5]: 97.6723 - val_ca2-[6,11]: 51.9898 - val_ca2-[12,17]: 125.8926 - val_ca2-[18,23]: 130.9987 - val_ca3-[0,5]: 1344.4541 - val_ca3-[6,11]: 926.6707 - val_ca3-[12,17]: 527.0780 - val_ca3-[18,23]: 269.7636 - val_ca4-[0,5]: 1551.7017 - val_ca4-[6,11]: 1099.0360 - val_ca4-[12,17]: 657.8967 - val_ca4-[18,23]: 361.9062\n",
      "Epoch 233/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.0704 - ca1-[6,11]: 0.0842 - ca1-[12,17]: 0.2562 - ca1-[18,23]: 7.7711 - ca2-[0,5]: 84.2357 - ca2-[6,11]: 15.2973 - ca2-[12,17]: 6.2834 - ca2-[18,23]: 18.2424 - ca3-[0,5]: 1148.3037 - ca3-[6,11]: 851.6635 - ca3-[12,17]: 622.1931 - ca3-[18,23]: 304.2078 - ca4-[0,5]: 486.6441 - ca4-[6,11]: 1093.2982 - ca4-[12,17]: 659.6030 - ca4-[18,23]: 377.4055 - val_ca1-[0,5]: 0.0766 - val_ca1-[6,11]: 0.3244 - val_ca1-[12,17]: 2.2229 - val_ca1-[18,23]: 14.5945 - val_ca2-[0,5]: 67.6412 - val_ca2-[6,11]: 46.2108 - val_ca2-[12,17]: 134.0106 - val_ca2-[18,23]: 138.9973 - val_ca3-[0,5]: 1357.8246 - val_ca3-[6,11]: 937.7127 - val_ca3-[12,17]: 535.3465 - val_ca3-[18,23]: 275.4503 - val_ca4-[0,5]: 1565.4458 - val_ca4-[6,11]: 1110.5519 - val_ca4-[12,17]: 666.7589 - val_ca4-[18,23]: 368.2983\n",
      "Epoch 234/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.0699 - ca1-[6,11]: 0.0997 - ca1-[12,17]: 0.2251 - ca1-[18,23]: 7.7282 - ca2-[0,5]: 55.6306 - ca2-[6,11]: 6.7720 - ca2-[12,17]: 4.2721 - ca2-[18,23]: 13.6097 - ca3-[0,5]: 1160.4319 - ca3-[6,11]: 830.0569 - ca3-[12,17]: 602.6778 - ca3-[18,23]: 325.0639 - ca4-[0,5]: 538.4598 - ca4-[6,11]: 1108.8028 - ca4-[12,17]: 671.7045 - ca4-[18,23]: 397.6436 - val_ca1-[0,5]: 0.0752 - val_ca1-[6,11]: 0.3101 - val_ca1-[12,17]: 1.9789 - val_ca1-[18,23]: 14.1603 - val_ca2-[0,5]: 56.6695 - val_ca2-[6,11]: 47.5198 - val_ca2-[12,17]: 146.6675 - val_ca2-[18,23]: 147.1581 - val_ca3-[0,5]: 1371.2252 - val_ca3-[6,11]: 948.7910 - val_ca3-[12,17]: 543.3700 - val_ca3-[18,23]: 281.1877 - val_ca4-[0,5]: 1579.2887 - val_ca4-[6,11]: 1122.1609 - val_ca4-[12,17]: 675.3689 - val_ca4-[18,23]: 374.7691\n",
      "Epoch 235/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0683 - ca1-[6,11]: 0.1109 - ca1-[12,17]: 0.2246 - ca1-[18,23]: 7.5302 - ca2-[0,5]: 45.9054 - ca2-[6,11]: 4.6922 - ca2-[12,17]: 5.7720 - ca2-[18,23]: 11.7429 - ca3-[0,5]: 1183.3760 - ca3-[6,11]: 872.9348 - ca3-[12,17]: 635.4304 - ca3-[18,23]: 315.4502 - ca4-[0,5]: 533.9547 - ca4-[6,11]: 1112.5473 - ca4-[12,17]: 680.7000 - ca4-[18,23]: 405.7119 - val_ca1-[0,5]: 0.0735 - val_ca1-[6,11]: 0.3037 - val_ca1-[12,17]: 2.1002 - val_ca1-[18,23]: 13.9127 - val_ca2-[0,5]: 49.1993 - val_ca2-[6,11]: 41.0348 - val_ca2-[12,17]: 134.0626 - val_ca2-[18,23]: 138.0542 - val_ca3-[0,5]: 1384.7004 - val_ca3-[6,11]: 959.9427 - val_ca3-[12,17]: 552.0425 - val_ca3-[18,23]: 286.9948 - val_ca4-[0,5]: 1593.1642 - val_ca4-[6,11]: 1133.8068 - val_ca4-[12,17]: 684.6972 - val_ca4-[18,23]: 381.2872\n",
      "Epoch 236/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0664 - ca1-[6,11]: 0.0795 - ca1-[12,17]: 0.2116 - ca1-[18,23]: 7.4691 - ca2-[0,5]: 40.5731 - ca2-[6,11]: 4.0104 - ca2-[12,17]: 4.3007 - ca2-[18,23]: 10.5067 - ca3-[0,5]: 1157.9340 - ca3-[6,11]: 883.8018 - ca3-[12,17]: 643.3542 - ca3-[18,23]: 325.1537 - ca4-[0,5]: 525.5892 - ca4-[6,11]: 1124.6039 - ca4-[12,17]: 685.6099 - ca4-[18,23]: 421.6662 - val_ca1-[0,5]: 0.0717 - val_ca1-[6,11]: 0.2936 - val_ca1-[12,17]: 2.0592 - val_ca1-[18,23]: 13.6391 - val_ca2-[0,5]: 43.8670 - val_ca2-[6,11]: 36.1077 - val_ca2-[12,17]: 128.7815 - val_ca2-[18,23]: 135.8725 - val_ca3-[0,5]: 1398.2286 - val_ca3-[6,11]: 971.1490 - val_ca3-[12,17]: 560.4842 - val_ca3-[18,23]: 292.8625 - val_ca4-[0,5]: 1607.1456 - val_ca4-[6,11]: 1145.5510 - val_ca4-[12,17]: 693.7778 - val_ca4-[18,23]: 387.8878\n",
      "Epoch 237/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.0647 - ca1-[6,11]: 0.0838 - ca1-[12,17]: 0.1993 - ca1-[18,23]: 6.9882 - ca2-[0,5]: 36.4687 - ca2-[6,11]: 3.2388 - ca2-[12,17]: 4.1278 - ca2-[18,23]: 9.6285 - ca3-[0,5]: 1213.4337 - ca3-[6,11]: 893.3738 - ca3-[12,17]: 614.0542 - ca3-[18,23]: 342.6352 - ca4-[0,5]: 544.7036 - ca4-[6,11]: 1085.6147 - ca4-[12,17]: 694.9059 - ca4-[18,23]: 409.6077 - val_ca1-[0,5]: 0.0702 - val_ca1-[6,11]: 0.2937 - val_ca1-[12,17]: 2.0677 - val_ca1-[18,23]: 13.3880 - val_ca2-[0,5]: 40.7109 - val_ca2-[6,11]: 34.0577 - val_ca2-[12,17]: 126.7823 - val_ca2-[18,23]: 136.0336 - val_ca3-[0,5]: 1411.8412 - val_ca3-[6,11]: 982.4373 - val_ca3-[12,17]: 569.0035 - val_ca3-[18,23]: 298.8043 - val_ca4-[0,5]: 1621.1547 - val_ca4-[6,11]: 1157.3290 - val_ca4-[12,17]: 702.8978 - val_ca4-[18,23]: 394.5338\n",
      "Epoch 238/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0633 - ca1-[6,11]: 0.0911 - ca1-[12,17]: 0.1803 - ca1-[18,23]: 6.5285 - ca2-[0,5]: 33.5296 - ca2-[6,11]: 2.6411 - ca2-[12,17]: 3.6955 - ca2-[18,23]: 8.5476 - ca3-[0,5]: 1225.8807 - ca3-[6,11]: 904.2731 - ca3-[12,17]: 666.4532 - ca3-[18,23]: 331.9048 - ca4-[0,5]: 602.6727 - ca4-[6,11]: 1149.7404 - ca4-[12,17]: 707.2877 - ca4-[18,23]: 420.4257 - val_ca1-[0,5]: 0.0685 - val_ca1-[6,11]: 0.2858 - val_ca1-[12,17]: 2.0302 - val_ca1-[18,23]: 13.1262 - val_ca2-[0,5]: 38.0652 - val_ca2-[6,11]: 31.0159 - val_ca2-[12,17]: 120.1128 - val_ca2-[18,23]: 132.1023 - val_ca3-[0,5]: 1425.4813 - val_ca3-[6,11]: 993.7591 - val_ca3-[12,17]: 577.5645 - val_ca3-[18,23]: 304.7951 - val_ca4-[0,5]: 1635.1838 - val_ca4-[6,11]: 1169.1332 - val_ca4-[12,17]: 712.0522 - val_ca4-[18,23]: 401.2212\n",
      "Epoch 239/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.0618 - ca1-[6,11]: 0.0882 - ca1-[12,17]: 0.2016 - ca1-[18,23]: 6.5458 - ca2-[0,5]: 31.3701 - ca2-[6,11]: 2.3890 - ca2-[12,17]: 3.3839 - ca2-[18,23]: 7.5880 - ca3-[0,5]: 1243.8036 - ca3-[6,11]: 916.8366 - ca3-[12,17]: 650.0143 - ca3-[18,23]: 353.6689 - ca4-[0,5]: 594.6765 - ca4-[6,11]: 1168.7384 - ca4-[12,17]: 705.4060 - ca4-[18,23]: 431.5438 - val_ca1-[0,5]: 0.0672 - val_ca1-[6,11]: 0.2775 - val_ca1-[12,17]: 1.9882 - val_ca1-[18,23]: 12.8408 - val_ca2-[0,5]: 36.1287 - val_ca2-[6,11]: 28.6906 - val_ca2-[12,17]: 113.2962 - val_ca2-[18,23]: 127.5418 - val_ca3-[0,5]: 1439.1714 - val_ca3-[6,11]: 1005.1333 - val_ca3-[12,17]: 586.1813 - val_ca3-[18,23]: 310.8447 - val_ca4-[0,5]: 1649.3473 - val_ca4-[6,11]: 1181.0603 - val_ca4-[12,17]: 721.3154 - val_ca4-[18,23]: 408.0045\n",
      "Epoch 240/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0622 - ca1-[6,11]: 0.0742 - ca1-[12,17]: 0.1612 - ca1-[18,23]: 6.0648 - ca2-[0,5]: 30.2658 - ca2-[6,11]: 2.3289 - ca2-[12,17]: 3.1342 - ca2-[18,23]: 6.5591 - ca3-[0,5]: 1200.4403 - ca3-[6,11]: 924.0384 - ca3-[12,17]: 681.2126 - ca3-[18,23]: 345.6643 - ca4-[0,5]: 504.9228 - ca4-[6,11]: 1106.1734 - ca4-[12,17]: 723.2827 - ca4-[18,23]: 441.5679 - val_ca1-[0,5]: 0.0664 - val_ca1-[6,11]: 0.2661 - val_ca1-[12,17]: 1.9199 - val_ca1-[18,23]: 12.5113 - val_ca2-[0,5]: 34.0034 - val_ca2-[6,11]: 24.8001 - val_ca2-[12,17]: 102.4063 - val_ca2-[18,23]: 120.2328 - val_ca3-[0,5]: 1452.9021 - val_ca3-[6,11]: 1016.5533 - val_ca3-[12,17]: 594.8481 - val_ca3-[18,23]: 316.9490 - val_ca4-[0,5]: 1663.5867 - val_ca4-[6,11]: 1193.0607 - val_ca4-[12,17]: 730.6494 - val_ca4-[18,23]: 414.8561\n",
      "Epoch 241/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.0599 - ca1-[6,11]: 0.0620 - ca1-[12,17]: 0.1728 - ca1-[18,23]: 6.1018 - ca2-[0,5]: 29.4755 - ca2-[6,11]: 1.9399 - ca2-[12,17]: 2.3793 - ca2-[18,23]: 5.8742 - ca3-[0,5]: 1263.4613 - ca3-[6,11]: 937.2372 - ca3-[12,17]: 692.6270 - ca3-[18,23]: 352.6148 - ca4-[0,5]: 566.5175 - ca4-[6,11]: 1122.1531 - ca4-[12,17]: 740.1613 - ca4-[18,23]: 444.3260 - val_ca1-[0,5]: 0.0645 - val_ca1-[6,11]: 0.2716 - val_ca1-[12,17]: 1.9627 - val_ca1-[18,23]: 12.3827 - val_ca2-[0,5]: 32.8100 - val_ca2-[6,11]: 23.9462 - val_ca2-[12,17]: 99.8521 - val_ca2-[18,23]: 119.0817 - val_ca3-[0,5]: 1466.6796 - val_ca3-[6,11]: 1028.0225 - val_ca3-[12,17]: 603.5684 - val_ca3-[18,23]: 323.1103 - val_ca4-[0,5]: 1677.8838 - val_ca4-[6,11]: 1205.1194 - val_ca4-[12,17]: 740.0422 - val_ca4-[18,23]: 421.7675\n",
      "Epoch 242/300\n",
      "26/26 [==============================] - 3s 129ms/step - ca1-[0,5]: 0.0576 - ca1-[6,11]: 0.0751 - ca1-[12,17]: 0.1560 - ca1-[18,23]: 6.0780 - ca2-[0,5]: 27.9350 - ca2-[6,11]: 1.8781 - ca2-[12,17]: 1.8802 - ca2-[18,23]: 5.0472 - ca3-[0,5]: 1178.6887 - ca3-[6,11]: 949.9806 - ca3-[12,17]: 668.6361 - ca3-[18,23]: 375.9875 - ca4-[0,5]: 477.0040 - ca4-[6,11]: 1206.0181 - ca4-[12,17]: 685.0952 - ca4-[18,23]: 460.8792 - val_ca1-[0,5]: 0.0631 - val_ca1-[6,11]: 0.2592 - val_ca1-[12,17]: 1.8925 - val_ca1-[18,23]: 12.0523 - val_ca2-[0,5]: 31.6469 - val_ca2-[6,11]: 22.4396 - val_ca2-[12,17]: 94.2453 - val_ca2-[18,23]: 115.4744 - val_ca3-[0,5]: 1480.5156 - val_ca3-[6,11]: 1039.5516 - val_ca3-[12,17]: 612.3500 - val_ca3-[18,23]: 329.3339 - val_ca4-[0,5]: 1692.2390 - val_ca4-[6,11]: 1217.2373 - val_ca4-[12,17]: 749.4943 - val_ca4-[18,23]: 428.7386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 243/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0584 - ca1-[6,11]: 0.0619 - ca1-[12,17]: 0.1069 - ca1-[18,23]: 5.7442 - ca2-[0,5]: 27.0574 - ca2-[6,11]: 1.6981 - ca2-[12,17]: 2.3497 - ca2-[18,23]: 4.5231 - ca3-[0,5]: 1236.8087 - ca3-[6,11]: 959.4727 - ca3-[12,17]: 713.0494 - ca3-[18,23]: 383.5155 - ca4-[0,5]: 495.8083 - ca4-[6,11]: 1206.0480 - ca4-[12,17]: 751.3411 - ca4-[18,23]: 472.4510 - val_ca1-[0,5]: 0.0620 - val_ca1-[6,11]: 0.2550 - val_ca1-[12,17]: 1.8755 - val_ca1-[18,23]: 11.8206 - val_ca2-[0,5]: 29.6396 - val_ca2-[6,11]: 17.7280 - val_ca2-[12,17]: 77.2702 - val_ca2-[18,23]: 100.6656 - val_ca3-[0,5]: 1494.4191 - val_ca3-[6,11]: 1051.1481 - val_ca3-[12,17]: 621.1981 - val_ca3-[18,23]: 335.6237 - val_ca4-[0,5]: 1706.6465 - val_ca4-[6,11]: 1229.4081 - val_ca4-[12,17]: 759.0020 - val_ca4-[18,23]: 435.7665\n",
      "Epoch 244/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0545 - ca1-[6,11]: 0.0688 - ca1-[12,17]: 0.1113 - ca1-[18,23]: 5.3898 - ca2-[0,5]: 26.3012 - ca2-[6,11]: 1.5745 - ca2-[12,17]: 1.7574 - ca2-[18,23]: 3.6818 - ca3-[0,5]: 1254.6378 - ca3-[6,11]: 974.9848 - ca3-[12,17]: 718.9161 - ca3-[18,23]: 389.9192 - ca4-[0,5]: 610.2122 - ca4-[6,11]: 1208.3300 - ca4-[12,17]: 765.7694 - ca4-[18,23]: 461.3036 - val_ca1-[0,5]: 0.0614 - val_ca1-[6,11]: 0.2411 - val_ca1-[12,17]: 1.7753 - val_ca1-[18,23]: 11.4405 - val_ca2-[0,5]: 28.3427 - val_ca2-[6,11]: 15.3924 - val_ca2-[12,17]: 69.2929 - val_ca2-[18,23]: 93.9392 - val_ca3-[0,5]: 1508.3939 - val_ca3-[6,11]: 1062.8143 - val_ca3-[12,17]: 630.1148 - val_ca3-[18,23]: 341.9812 - val_ca4-[0,5]: 1721.1152 - val_ca4-[6,11]: 1241.6405 - val_ca4-[12,17]: 768.5709 - val_ca4-[18,23]: 442.8559\n",
      "Epoch 245/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.0552 - ca1-[6,11]: 0.0511 - ca1-[12,17]: 0.1207 - ca1-[18,23]: 5.4884 - ca2-[0,5]: 25.4073 - ca2-[6,11]: 1.5443 - ca2-[12,17]: 1.5180 - ca2-[18,23]: 3.1168 - ca3-[0,5]: 1308.6904 - ca3-[6,11]: 981.9760 - ca3-[12,17]: 699.9261 - ca3-[18,23]: 396.9620 - ca4-[0,5]: 630.5177 - ca4-[6,11]: 1055.3969 - ca4-[12,17]: 770.9533 - ca4-[18,23]: 480.5256 - val_ca1-[0,5]: 0.0595 - val_ca1-[6,11]: 0.2417 - val_ca1-[12,17]: 1.6601 - val_ca1-[18,23]: 11.2726 - val_ca2-[0,5]: 27.2501 - val_ca2-[6,11]: 13.4374 - val_ca2-[12,17]: 60.6890 - val_ca2-[18,23]: 86.0004 - val_ca3-[0,5]: 1522.4387 - val_ca3-[6,11]: 1074.5504 - val_ca3-[12,17]: 638.7756 - val_ca3-[18,23]: 348.4067 - val_ca4-[0,5]: 1735.6564 - val_ca4-[6,11]: 1253.9436 - val_ca4-[12,17]: 777.8352 - val_ca4-[18,23]: 450.0119\n",
      "Epoch 246/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0524 - ca1-[6,11]: 0.0611 - ca1-[12,17]: 0.1169 - ca1-[18,23]: 5.0803 - ca2-[0,5]: 24.4883 - ca2-[6,11]: 1.4421 - ca2-[12,17]: 1.2049 - ca2-[18,23]: 2.7213 - ca3-[0,5]: 1237.1210 - ca3-[6,11]: 993.3291 - ca3-[12,17]: 623.3266 - ca3-[18,23]: 407.3724 - ca4-[0,5]: 594.4473 - ca4-[6,11]: 1244.7598 - ca4-[12,17]: 779.6903 - ca4-[18,23]: 482.8696 - val_ca1-[0,5]: 0.0584 - val_ca1-[6,11]: 0.2309 - val_ca1-[12,17]: 1.5810 - val_ca1-[18,23]: 10.3199 - val_ca2-[0,5]: 26.1260 - val_ca2-[6,11]: 11.1796 - val_ca2-[12,17]: 50.3518 - val_ca2-[18,23]: 75.6606 - val_ca3-[0,5]: 1536.5256 - val_ca3-[6,11]: 1086.3315 - val_ca3-[12,17]: 649.7534 - val_ca3-[18,23]: 357.9120 - val_ca4-[0,5]: 1750.2659 - val_ca4-[6,11]: 1266.3145 - val_ca4-[12,17]: 789.6979 - val_ca4-[18,23]: 460.8301\n",
      "Epoch 247/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0519 - ca1-[6,11]: 0.0585 - ca1-[12,17]: 0.0787 - ca1-[18,23]: 5.1300 - ca2-[0,5]: 23.9784 - ca2-[6,11]: 1.4968 - ca2-[12,17]: 0.9861 - ca2-[18,23]: 2.4873 - ca3-[0,5]: 1328.7312 - ca3-[6,11]: 1003.4805 - ca3-[12,17]: 716.7279 - ca3-[18,23]: 391.9888 - ca4-[0,5]: 600.1203 - ca4-[6,11]: 1139.1581 - ca4-[12,17]: 791.3923 - ca4-[18,23]: 490.3570 - val_ca1-[0,5]: 0.0570 - val_ca1-[6,11]: 0.2051 - val_ca1-[12,17]: 1.7685 - val_ca1-[18,23]: 10.8747 - val_ca2-[0,5]: 25.4151 - val_ca2-[6,11]: 9.9928 - val_ca2-[12,17]: 43.7793 - val_ca2-[18,23]: 67.9018 - val_ca3-[0,5]: 1550.6577 - val_ca3-[6,11]: 1098.0746 - val_ca3-[12,17]: 657.2245 - val_ca3-[18,23]: 361.4222 - val_ca4-[0,5]: 1764.9513 - val_ca4-[6,11]: 1278.6584 - val_ca4-[12,17]: 797.6863 - val_ca4-[18,23]: 464.5224\n",
      "Epoch 248/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0521 - ca1-[6,11]: 0.0469 - ca1-[12,17]: 0.0835 - ca1-[18,23]: 5.0157 - ca2-[0,5]: 23.6743 - ca2-[6,11]: 1.3631 - ca2-[12,17]: 0.8514 - ca2-[18,23]: 2.4533 - ca3-[0,5]: 1304.2699 - ca3-[6,11]: 1023.2200 - ca3-[12,17]: 641.7123 - ca3-[18,23]: 419.7588 - ca4-[0,5]: 648.8501 - ca4-[6,11]: 1254.2030 - ca4-[12,17]: 804.9280 - ca4-[18,23]: 500.8496 - val_ca1-[0,5]: 0.0559 - val_ca1-[6,11]: 0.2258 - val_ca1-[12,17]: 1.7124 - val_ca1-[18,23]: 10.5634 - val_ca2-[0,5]: 24.8234 - val_ca2-[6,11]: 9.1857 - val_ca2-[12,17]: 39.2988 - val_ca2-[18,23]: 63.2762 - val_ca3-[0,5]: 1564.8293 - val_ca3-[6,11]: 1110.0352 - val_ca3-[12,17]: 666.3612 - val_ca3-[18,23]: 368.0110 - val_ca4-[0,5]: 1779.6426 - val_ca4-[6,11]: 1291.2166 - val_ca4-[12,17]: 807.4854 - val_ca4-[18,23]: 471.8456\n",
      "Epoch 249/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0508 - ca1-[6,11]: 0.0500 - ca1-[12,17]: 0.0684 - ca1-[18,23]: 4.8950 - ca2-[0,5]: 22.9484 - ca2-[6,11]: 1.3047 - ca2-[12,17]: 0.8255 - ca2-[18,23]: 2.1284 - ca3-[0,5]: 1366.0525 - ca3-[6,11]: 1026.4036 - ca3-[12,17]: 766.5992 - ca3-[18,23]: 429.1077 - ca4-[0,5]: 567.7283 - ca4-[6,11]: 1279.6061 - ca4-[12,17]: 815.5230 - ca4-[18,23]: 507.2400 - val_ca1-[0,5]: 0.0548 - val_ca1-[6,11]: 0.2180 - val_ca1-[12,17]: 1.6712 - val_ca1-[18,23]: 10.3148 - val_ca2-[0,5]: 24.2162 - val_ca2-[6,11]: 8.2714 - val_ca2-[12,17]: 35.9547 - val_ca2-[18,23]: 59.6998 - val_ca3-[0,5]: 1579.0551 - val_ca3-[6,11]: 1121.9648 - val_ca3-[12,17]: 675.5559 - val_ca3-[18,23]: 374.6595 - val_ca4-[0,5]: 1794.4135 - val_ca4-[6,11]: 1303.7516 - val_ca4-[12,17]: 817.3578 - val_ca4-[18,23]: 479.2393\n",
      "Epoch 250/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0503 - ca1-[6,11]: 0.0347 - ca1-[12,17]: 0.0828 - ca1-[18,23]: 4.5476 - ca2-[0,5]: 22.7619 - ca2-[6,11]: 1.2632 - ca2-[12,17]: 0.6852 - ca2-[18,23]: 1.8489 - ca3-[0,5]: 1379.1228 - ca3-[6,11]: 1036.1073 - ca3-[12,17]: 782.2371 - ca3-[18,23]: 410.9497 - ca4-[0,5]: 602.6222 - ca4-[6,11]: 1305.6913 - ca4-[12,17]: 810.9418 - ca4-[18,23]: 506.5329 - val_ca1-[0,5]: 0.0537 - val_ca1-[6,11]: 0.2175 - val_ca1-[12,17]: 1.5035 - val_ca1-[18,23]: 9.4279 - val_ca2-[0,5]: 23.6297 - val_ca2-[6,11]: 7.2192 - val_ca2-[12,17]: 28.7020 - val_ca2-[18,23]: 49.5708 - val_ca3-[0,5]: 1593.3818 - val_ca3-[6,11]: 1133.9893 - val_ca3-[12,17]: 686.5017 - val_ca3-[18,23]: 384.5712 - val_ca4-[0,5]: 1809.2386 - val_ca4-[6,11]: 1316.3423 - val_ca4-[12,17]: 829.1174 - val_ca4-[18,23]: 490.4391\n",
      "Epoch 251/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0475 - ca1-[6,11]: 0.0460 - ca1-[12,17]: 0.0626 - ca1-[18,23]: 4.3086 - ca2-[0,5]: 22.5805 - ca2-[6,11]: 1.3566 - ca2-[12,17]: 0.9237 - ca2-[18,23]: 2.3548 - ca3-[0,5]: 1341.9995 - ca3-[6,11]: 1052.1244 - ca3-[12,17]: 787.3929 - ca3-[18,23]: 439.1005 - ca4-[0,5]: 578.6268 - ca4-[6,11]: 1297.4139 - ca4-[12,17]: 823.1790 - ca4-[18,23]: 511.8698 - val_ca1-[0,5]: 0.0524 - val_ca1-[6,11]: 0.2098 - val_ca1-[12,17]: 1.6168 - val_ca1-[18,23]: 9.8308 - val_ca2-[0,5]: 23.2671 - val_ca2-[6,11]: 6.8135 - val_ca2-[12,17]: 28.5720 - val_ca2-[18,23]: 50.4137 - val_ca3-[0,5]: 1607.7133 - val_ca3-[6,11]: 1146.0283 - val_ca3-[12,17]: 694.1470 - val_ca3-[18,23]: 388.1566 - val_ca4-[0,5]: 1824.1215 - val_ca4-[6,11]: 1328.9908 - val_ca4-[12,17]: 837.2749 - val_ca4-[18,23]: 494.2016\n",
      "Epoch 252/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0463 - ca1-[6,11]: 0.0324 - ca1-[12,17]: 0.0570 - ca1-[18,23]: 4.1087 - ca2-[0,5]: 22.0486 - ca2-[6,11]: 1.2758 - ca2-[12,17]: 0.6843 - ca2-[18,23]: 2.3882 - ca3-[0,5]: 1399.6155 - ca3-[6,11]: 1069.1505 - ca3-[12,17]: 738.2661 - ca3-[18,23]: 445.7215 - ca4-[0,5]: 628.8426 - ca4-[6,11]: 1256.7463 - ca4-[12,17]: 839.8045 - ca4-[18,23]: 525.6803 - val_ca1-[0,5]: 0.0514 - val_ca1-[6,11]: 0.2080 - val_ca1-[12,17]: 1.6014 - val_ca1-[18,23]: 9.5053 - val_ca2-[0,5]: 22.9675 - val_ca2-[6,11]: 6.4100 - val_ca2-[12,17]: 25.5656 - val_ca2-[18,23]: 46.3944 - val_ca3-[0,5]: 1622.1366 - val_ca3-[6,11]: 1158.1548 - val_ca3-[12,17]: 703.5378 - val_ca3-[18,23]: 394.8247 - val_ca4-[0,5]: 1839.1228 - val_ca4-[6,11]: 1341.7498 - val_ca4-[12,17]: 847.3624 - val_ca4-[18,23]: 501.5645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0468 - ca1-[6,11]: 0.0349 - ca1-[12,17]: 0.0598 - ca1-[18,23]: 4.2649 - ca2-[0,5]: 22.2475 - ca2-[6,11]: 1.2195 - ca2-[12,17]: 0.8339 - ca2-[18,23]: 2.0164 - ca3-[0,5]: 1367.4290 - ca3-[6,11]: 1073.7112 - ca3-[12,17]: 739.7976 - ca3-[18,23]: 435.7438 - ca4-[0,5]: 529.2086 - ca4-[6,11]: 1322.4363 - ca4-[12,17]: 854.7633 - ca4-[18,23]: 541.1955 - val_ca1-[0,5]: 0.0506 - val_ca1-[6,11]: 0.2037 - val_ca1-[12,17]: 1.5700 - val_ca1-[18,23]: 9.3897 - val_ca2-[0,5]: 22.8161 - val_ca2-[6,11]: 6.2843 - val_ca2-[12,17]: 24.2508 - val_ca2-[18,23]: 43.8223 - val_ca3-[0,5]: 1636.6140 - val_ca3-[6,11]: 1170.3373 - val_ca3-[12,17]: 712.9865 - val_ca3-[18,23]: 401.9048 - val_ca4-[0,5]: 1854.1444 - val_ca4-[6,11]: 1354.5348 - val_ca4-[12,17]: 857.4836 - val_ca4-[18,23]: 509.4443\n",
      "Epoch 254/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0462 - ca1-[6,11]: 0.0347 - ca1-[12,17]: 0.0627 - ca1-[18,23]: 4.0468 - ca2-[0,5]: 22.2530 - ca2-[6,11]: 1.2407 - ca2-[12,17]: 0.5865 - ca2-[18,23]: 1.7620 - ca3-[0,5]: 1426.1043 - ca3-[6,11]: 1090.2064 - ca3-[12,17]: 783.8270 - ca3-[18,23]: 460.0980 - ca4-[0,5]: 640.5390 - ca4-[6,11]: 1344.4150 - ca4-[12,17]: 826.2029 - ca4-[18,23]: 539.2108 - val_ca1-[0,5]: 0.0496 - val_ca1-[6,11]: 0.1980 - val_ca1-[12,17]: 1.4032 - val_ca1-[18,23]: 9.1276 - val_ca2-[0,5]: 22.6855 - val_ca2-[6,11]: 6.1791 - val_ca2-[12,17]: 22.2090 - val_ca2-[18,23]: 41.8262 - val_ca3-[0,5]: 1651.1646 - val_ca3-[6,11]: 1182.5911 - val_ca3-[12,17]: 722.1511 - val_ca3-[18,23]: 408.8770 - val_ca4-[0,5]: 1869.2552 - val_ca4-[6,11]: 1367.4050 - val_ca4-[12,17]: 867.2838 - val_ca4-[18,23]: 517.1615\n",
      "Epoch 255/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0460 - ca1-[6,11]: 0.0366 - ca1-[12,17]: 0.0514 - ca1-[18,23]: 3.8580 - ca2-[0,5]: 21.8448 - ca2-[6,11]: 1.2094 - ca2-[12,17]: 0.4692 - ca2-[18,23]: 1.2756 - ca3-[0,5]: 1433.5214 - ca3-[6,11]: 1097.1054 - ca3-[12,17]: 790.4399 - ca3-[18,23]: 471.4779 - ca4-[0,5]: 646.4087 - ca4-[6,11]: 1216.9378 - ca4-[12,17]: 876.5610 - ca4-[18,23]: 553.1959 - val_ca1-[0,5]: 0.0482 - val_ca1-[6,11]: 0.2007 - val_ca1-[12,17]: 1.5607 - val_ca1-[18,23]: 9.0357 - val_ca2-[0,5]: 22.4127 - val_ca2-[6,11]: 5.7265 - val_ca2-[12,17]: 20.4954 - val_ca2-[18,23]: 38.3204 - val_ca3-[0,5]: 1665.7146 - val_ca3-[6,11]: 1194.8550 - val_ca3-[12,17]: 732.0461 - val_ca3-[18,23]: 415.8829 - val_ca4-[0,5]: 1884.3632 - val_ca4-[6,11]: 1380.2820 - val_ca4-[12,17]: 877.9048 - val_ca4-[18,23]: 524.9072\n",
      "Epoch 256/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0439 - ca1-[6,11]: 0.0283 - ca1-[12,17]: 0.0404 - ca1-[18,23]: 3.8218 - ca2-[0,5]: 22.0204 - ca2-[6,11]: 1.1082 - ca2-[12,17]: 0.4884 - ca2-[18,23]: 1.2939 - ca3-[0,5]: 1458.6893 - ca3-[6,11]: 1109.8316 - ca3-[12,17]: 840.3932 - ca3-[18,23]: 455.9555 - ca4-[0,5]: 652.3197 - ca4-[6,11]: 1357.8200 - ca4-[12,17]: 884.1419 - ca4-[18,23]: 543.7164 - val_ca1-[0,5]: 0.0475 - val_ca1-[6,11]: 0.1968 - val_ca1-[12,17]: 1.5222 - val_ca1-[18,23]: 8.7980 - val_ca2-[0,5]: 22.2281 - val_ca2-[6,11]: 5.4985 - val_ca2-[12,17]: 19.3722 - val_ca2-[18,23]: 37.0447 - val_ca3-[0,5]: 1680.3488 - val_ca3-[6,11]: 1207.1996 - val_ca3-[12,17]: 741.6639 - val_ca3-[18,23]: 422.9622 - val_ca4-[0,5]: 1899.5836 - val_ca4-[6,11]: 1393.2637 - val_ca4-[12,17]: 888.2199 - val_ca4-[18,23]: 532.7401\n",
      "Epoch 257/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0428 - ca1-[6,11]: 0.0317 - ca1-[12,17]: 0.0389 - ca1-[18,23]: 3.4736 - ca2-[0,5]: 21.5186 - ca2-[6,11]: 1.1278 - ca2-[12,17]: 0.3791 - ca2-[18,23]: 1.0375 - ca3-[0,5]: 1472.1511 - ca3-[6,11]: 1126.7095 - ca3-[12,17]: 808.3080 - ca3-[18,23]: 461.6102 - ca4-[0,5]: 596.0342 - ca4-[6,11]: 1312.8087 - ca4-[12,17]: 889.2335 - ca4-[18,23]: 576.7780 - val_ca1-[0,5]: 0.0468 - val_ca1-[6,11]: 0.1910 - val_ca1-[12,17]: 1.4558 - val_ca1-[18,23]: 8.4643 - val_ca2-[0,5]: 22.0790 - val_ca2-[6,11]: 5.3546 - val_ca2-[12,17]: 18.4576 - val_ca2-[18,23]: 35.5656 - val_ca3-[0,5]: 1695.0632 - val_ca3-[6,11]: 1219.6221 - val_ca3-[12,17]: 751.3564 - val_ca3-[18,23]: 430.1136 - val_ca4-[0,5]: 1914.8363 - val_ca4-[6,11]: 1406.2820 - val_ca4-[12,17]: 898.5771 - val_ca4-[18,23]: 540.6199\n",
      "Epoch 258/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0445 - ca1-[6,11]: 0.0342 - ca1-[12,17]: 0.0414 - ca1-[18,23]: 3.5194 - ca2-[0,5]: 21.3626 - ca2-[6,11]: 1.0938 - ca2-[12,17]: 0.3933 - ca2-[18,23]: 0.9327 - ca3-[0,5]: 1485.6561 - ca3-[6,11]: 1138.8827 - ca3-[12,17]: 854.2148 - ca3-[18,23]: 490.6492 - ca4-[0,5]: 696.6007 - ca4-[6,11]: 1382.7965 - ca4-[12,17]: 870.2650 - ca4-[18,23]: 593.4855 - val_ca1-[0,5]: 0.0455 - val_ca1-[6,11]: 0.1877 - val_ca1-[12,17]: 1.4467 - val_ca1-[18,23]: 7.7621 - val_ca2-[0,5]: 21.8480 - val_ca2-[6,11]: 4.9917 - val_ca2-[12,17]: 17.2607 - val_ca2-[18,23]: 33.5357 - val_ca3-[0,5]: 1709.7720 - val_ca3-[6,11]: 1232.0498 - val_ca3-[12,17]: 761.0672 - val_ca3-[18,23]: 440.7870 - val_ca4-[0,5]: 1930.1075 - val_ca4-[6,11]: 1419.3251 - val_ca4-[12,17]: 908.9661 - val_ca4-[18,23]: 552.5895\n",
      "Epoch 259/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.0427 - ca1-[6,11]: 0.0269 - ca1-[12,17]: 0.0363 - ca1-[18,23]: 3.2511 - ca2-[0,5]: 21.6362 - ca2-[6,11]: 1.0706 - ca2-[12,17]: 0.3924 - ca2-[18,23]: 0.7832 - ca3-[0,5]: 1505.1594 - ca3-[6,11]: 1143.4871 - ca3-[12,17]: 833.9835 - ca3-[18,23]: 497.2013 - ca4-[0,5]: 670.1677 - ca4-[6,11]: 1404.3735 - ca4-[12,17]: 911.1273 - ca4-[18,23]: 580.1945 - val_ca1-[0,5]: 0.0445 - val_ca1-[6,11]: 0.1866 - val_ca1-[12,17]: 1.2944 - val_ca1-[18,23]: 8.1447 - val_ca2-[0,5]: 21.6933 - val_ca2-[6,11]: 4.7639 - val_ca2-[12,17]: 14.9787 - val_ca2-[18,23]: 31.2564 - val_ca3-[0,5]: 1724.5638 - val_ca3-[6,11]: 1244.5575 - val_ca3-[12,17]: 772.6208 - val_ca3-[18,23]: 444.5503 - val_ca4-[0,5]: 1945.4265 - val_ca4-[6,11]: 1432.4176 - val_ca4-[12,17]: 921.3380 - val_ca4-[18,23]: 556.5109\n",
      "Epoch 260/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 0.0418 - ca1-[6,11]: 0.0265 - ca1-[12,17]: 0.0372 - ca1-[18,23]: 3.1012 - ca2-[0,5]: 21.4239 - ca2-[6,11]: 1.0097 - ca2-[12,17]: 0.4108 - ca2-[18,23]: 0.6413 - ca3-[0,5]: 1348.4340 - ca3-[6,11]: 1154.1194 - ca3-[12,17]: 874.4255 - ca3-[18,23]: 485.5772 - ca4-[0,5]: 709.3741 - ca4-[6,11]: 1335.5063 - ca4-[12,17]: 921.5813 - ca4-[18,23]: 570.7463 - val_ca1-[0,5]: 0.0434 - val_ca1-[6,11]: 0.1850 - val_ca1-[12,17]: 1.4311 - val_ca1-[18,23]: 7.8653 - val_ca2-[0,5]: 21.5101 - val_ca2-[6,11]: 4.5123 - val_ca2-[12,17]: 15.0604 - val_ca2-[18,23]: 30.5266 - val_ca3-[0,5]: 1739.4152 - val_ca3-[6,11]: 1257.1255 - val_ca3-[12,17]: 780.7031 - val_ca3-[18,23]: 451.6568 - val_ca4-[0,5]: 1960.8538 - val_ca4-[6,11]: 1445.6117 - val_ca4-[12,17]: 929.9413 - val_ca4-[18,23]: 564.2979\n",
      "Epoch 261/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0409 - ca1-[6,11]: 0.0254 - ca1-[12,17]: 0.0305 - ca1-[18,23]: 3.1373 - ca2-[0,5]: 21.2921 - ca2-[6,11]: 0.9610 - ca2-[12,17]: 0.3488 - ca2-[18,23]: 0.6794 - ca3-[0,5]: 1520.4005 - ca3-[6,11]: 1171.5457 - ca3-[12,17]: 880.9021 - ca3-[18,23]: 512.3353 - ca4-[0,5]: 685.0197 - ca4-[6,11]: 1296.1679 - ca4-[12,17]: 906.2869 - ca4-[18,23]: 599.6903 - val_ca1-[0,5]: 0.0427 - val_ca1-[6,11]: 0.1758 - val_ca1-[12,17]: 1.2534 - val_ca1-[18,23]: 7.6316 - val_ca2-[0,5]: 21.3688 - val_ca2-[6,11]: 4.2617 - val_ca2-[12,17]: 13.6141 - val_ca2-[18,23]: 29.1515 - val_ca3-[0,5]: 1754.3391 - val_ca3-[6,11]: 1269.7648 - val_ca3-[12,17]: 790.2442 - val_ca3-[18,23]: 459.0375 - val_ca4-[0,5]: 1976.3546 - val_ca4-[6,11]: 1458.8768 - val_ca4-[12,17]: 940.1215 - val_ca4-[18,23]: 572.4195\n",
      "Epoch 262/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0395 - ca1-[6,11]: 0.0245 - ca1-[12,17]: 0.0298 - ca1-[18,23]: 2.9726 - ca2-[0,5]: 21.0809 - ca2-[6,11]: 0.9685 - ca2-[12,17]: 0.4379 - ca2-[18,23]: 0.6984 - ca3-[0,5]: 1478.3514 - ca3-[6,11]: 1184.5778 - ca3-[12,17]: 895.0266 - ca3-[18,23]: 528.7602 - ca4-[0,5]: 672.8520 - ca4-[6,11]: 1451.2074 - ca4-[12,17]: 941.5403 - ca4-[18,23]: 614.7410 - val_ca1-[0,5]: 0.0417 - val_ca1-[6,11]: 0.1760 - val_ca1-[12,17]: 1.3819 - val_ca1-[18,23]: 7.6399 - val_ca2-[0,5]: 21.3906 - val_ca2-[6,11]: 4.4169 - val_ca2-[12,17]: 14.1286 - val_ca2-[18,23]: 29.3228 - val_ca3-[0,5]: 1769.3533 - val_ca3-[6,11]: 1282.4901 - val_ca3-[12,17]: 800.6205 - val_ca3-[18,23]: 466.7134 - val_ca4-[0,5]: 1991.8821 - val_ca4-[6,11]: 1472.1752 - val_ca4-[12,17]: 951.1866 - val_ca4-[18,23]: 580.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 263/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0386 - ca1-[6,11]: 0.0176 - ca1-[12,17]: 0.0285 - ca1-[18,23]: 3.0694 - ca2-[0,5]: 21.1908 - ca2-[6,11]: 0.9879 - ca2-[12,17]: 0.3106 - ca2-[18,23]: 0.5674 - ca3-[0,5]: 1497.7252 - ca3-[6,11]: 1198.5512 - ca3-[12,17]: 906.3029 - ca3-[18,23]: 529.7116 - ca4-[0,5]: 744.2703 - ca4-[6,11]: 1374.1224 - ca4-[12,17]: 956.7968 - ca4-[18,23]: 623.2370 - val_ca1-[0,5]: 0.0408 - val_ca1-[6,11]: 0.1743 - val_ca1-[12,17]: 1.3652 - val_ca1-[18,23]: 7.4675 - val_ca2-[0,5]: 21.2234 - val_ca2-[6,11]: 4.0803 - val_ca2-[12,17]: 12.9969 - val_ca2-[18,23]: 27.4982 - val_ca3-[0,5]: 1784.4567 - val_ca3-[6,11]: 1295.3008 - val_ca3-[12,17]: 810.7006 - val_ca3-[18,23]: 474.2519 - val_ca4-[0,5]: 2007.5002 - val_ca4-[6,11]: 1485.5588 - val_ca4-[12,17]: 961.9094 - val_ca4-[18,23]: 589.1093\n",
      "Epoch 264/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0375 - ca1-[6,11]: 0.0191 - ca1-[12,17]: 0.0286 - ca1-[18,23]: 2.8880 - ca2-[0,5]: 20.6169 - ca2-[6,11]: 0.9931 - ca2-[12,17]: 0.2901 - ca2-[18,23]: 0.5702 - ca3-[0,5]: 1511.0939 - ca3-[6,11]: 1204.3748 - ca3-[12,17]: 889.5281 - ca3-[18,23]: 539.2444 - ca4-[0,5]: 750.8765 - ca4-[6,11]: 1448.4983 - ca4-[12,17]: 961.1618 - ca4-[18,23]: 618.8682 - val_ca1-[0,5]: 0.0401 - val_ca1-[6,11]: 0.1733 - val_ca1-[12,17]: 1.3463 - val_ca1-[18,23]: 7.2844 - val_ca2-[0,5]: 21.2107 - val_ca2-[6,11]: 4.1000 - val_ca2-[12,17]: 12.6020 - val_ca2-[18,23]: 27.1292 - val_ca3-[0,5]: 1799.5762 - val_ca3-[6,11]: 1308.1353 - val_ca3-[12,17]: 820.8132 - val_ca3-[18,23]: 481.8307 - val_ca4-[0,5]: 2023.1697 - val_ca4-[6,11]: 1498.9951 - val_ca4-[12,17]: 972.6866 - val_ca4-[18,23]: 597.4108\n",
      "Epoch 265/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 0.0372 - ca1-[6,11]: 0.0208 - ca1-[12,17]: 0.0281 - ca1-[18,23]: 2.8133 - ca2-[0,5]: 20.8816 - ca2-[6,11]: 1.0032 - ca2-[12,17]: 0.3279 - ca2-[18,23]: 0.6054 - ca3-[0,5]: 1575.6556 - ca3-[6,11]: 1131.1844 - ca3-[12,17]: 893.3613 - ca3-[18,23]: 521.9632 - ca4-[0,5]: 675.3634 - ca4-[6,11]: 1470.0404 - ca4-[12,17]: 979.2324 - ca4-[18,23]: 636.5477 - val_ca1-[0,5]: 0.0390 - val_ca1-[6,11]: 0.1717 - val_ca1-[12,17]: 1.3238 - val_ca1-[18,23]: 7.1023 - val_ca2-[0,5]: 21.0779 - val_ca2-[6,11]: 3.7535 - val_ca2-[12,17]: 11.4798 - val_ca2-[18,23]: 25.1263 - val_ca3-[0,5]: 1814.7255 - val_ca3-[6,11]: 1321.0048 - val_ca3-[12,17]: 830.9669 - val_ca3-[18,23]: 489.4562 - val_ca4-[0,5]: 2038.8486 - val_ca4-[6,11]: 1512.4486 - val_ca4-[12,17]: 983.4891 - val_ca4-[18,23]: 605.7458\n",
      "Epoch 266/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0359 - ca1-[6,11]: 0.0165 - ca1-[12,17]: 0.0172 - ca1-[18,23]: 2.7470 - ca2-[0,5]: 20.9684 - ca2-[6,11]: 0.9817 - ca2-[12,17]: 0.3124 - ca2-[18,23]: 0.5206 - ca3-[0,5]: 1486.1484 - ca3-[6,11]: 1232.1990 - ca3-[12,17]: 935.5562 - ca3-[18,23]: 553.7183 - ca4-[0,5]: 712.7668 - ca4-[6,11]: 1485.1613 - ca4-[12,17]: 992.2399 - ca4-[18,23]: 648.7031 - val_ca1-[0,5]: 0.0393 - val_ca1-[6,11]: 0.1814 - val_ca1-[12,17]: 1.3591 - val_ca1-[18,23]: 7.0393 - val_ca2-[0,5]: 21.1203 - val_ca2-[6,11]: 3.8957 - val_ca2-[12,17]: 11.5288 - val_ca2-[18,23]: 25.3155 - val_ca3-[0,5]: 1829.9078 - val_ca3-[6,11]: 1333.9113 - val_ca3-[12,17]: 841.1632 - val_ca3-[18,23]: 497.1299 - val_ca4-[0,5]: 2054.5864 - val_ca4-[6,11]: 1525.9612 - val_ca4-[12,17]: 994.3512 - val_ca4-[18,23]: 614.1406\n",
      "Epoch 267/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0361 - ca1-[6,11]: 0.0132 - ca1-[12,17]: 0.0179 - ca1-[18,23]: 2.5741 - ca2-[0,5]: 20.9756 - ca2-[6,11]: 0.9329 - ca2-[12,17]: 0.2483 - ca2-[18,23]: 0.3929 - ca3-[0,5]: 1609.7466 - ca3-[6,11]: 1244.7376 - ca3-[12,17]: 957.1973 - ca3-[18,23]: 564.1237 - ca4-[0,5]: 651.3508 - ca4-[6,11]: 1416.5345 - ca4-[12,17]: 961.3246 - ca4-[18,23]: 632.7356 - val_ca1-[0,5]: 0.0394 - val_ca1-[6,11]: 0.1882 - val_ca1-[12,17]: 1.3815 - val_ca1-[18,23]: 6.9764 - val_ca2-[0,5]: 21.0551 - val_ca2-[6,11]: 3.7779 - val_ca2-[12,17]: 11.1379 - val_ca2-[18,23]: 24.6937 - val_ca3-[0,5]: 1845.2141 - val_ca3-[6,11]: 1346.9333 - val_ca3-[12,17]: 851.4644 - val_ca3-[18,23]: 504.8978 - val_ca4-[0,5]: 2070.4275 - val_ca4-[6,11]: 1539.5708 - val_ca4-[12,17]: 1005.3033 - val_ca4-[18,23]: 622.6187\n",
      "Epoch 268/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0346 - ca1-[6,11]: 0.0118 - ca1-[12,17]: 0.0157 - ca1-[18,23]: 2.5125 - ca2-[0,5]: 20.8788 - ca2-[6,11]: 0.9032 - ca2-[12,17]: 0.2705 - ca2-[18,23]: 0.4520 - ca3-[0,5]: 1564.9527 - ca3-[6,11]: 1257.3846 - ca3-[12,17]: 926.1196 - ca3-[18,23]: 572.2426 - ca4-[0,5]: 672.8292 - ca4-[6,11]: 1518.8309 - ca4-[12,17]: 1006.8337 - ca4-[18,23]: 668.0192 - val_ca1-[0,5]: 0.0368 - val_ca1-[6,11]: 0.1599 - val_ca1-[12,17]: 1.2428 - val_ca1-[18,23]: 6.6186 - val_ca2-[0,5]: 21.0601 - val_ca2-[6,11]: 3.8175 - val_ca2-[12,17]: 11.2886 - val_ca2-[18,23]: 25.3505 - val_ca3-[0,5]: 1860.5789 - val_ca3-[6,11]: 1360.0139 - val_ca3-[12,17]: 861.8251 - val_ca3-[18,23]: 512.7267 - val_ca4-[0,5]: 2086.3647 - val_ca4-[6,11]: 1553.2722 - val_ca4-[12,17]: 1016.3412 - val_ca4-[18,23]: 631.1772\n",
      "Epoch 269/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0337 - ca1-[6,11]: 0.0117 - ca1-[12,17]: 0.0175 - ca1-[18,23]: 2.4228 - ca2-[0,5]: 21.0731 - ca2-[6,11]: 0.8923 - ca2-[12,17]: 0.2528 - ca2-[18,23]: 0.4979 - ca3-[0,5]: 1578.5655 - ca3-[6,11]: 1268.6823 - ca3-[12,17]: 973.1685 - ca3-[18,23]: 576.1171 - ca4-[0,5]: 731.4116 - ca4-[6,11]: 1519.7809 - ca4-[12,17]: 1021.1115 - ca4-[18,23]: 679.7535 - val_ca1-[0,5]: 0.0361 - val_ca1-[6,11]: 0.1618 - val_ca1-[12,17]: 1.2426 - val_ca1-[18,23]: 6.4960 - val_ca2-[0,5]: 20.9776 - val_ca2-[6,11]: 3.5939 - val_ca2-[12,17]: 10.6284 - val_ca2-[18,23]: 24.0909 - val_ca3-[0,5]: 1875.9728 - val_ca3-[6,11]: 1373.1293 - val_ca3-[12,17]: 872.2268 - val_ca3-[18,23]: 520.6019 - val_ca4-[0,5]: 2102.2629 - val_ca4-[6,11]: 1566.9479 - val_ca4-[12,17]: 1027.3701 - val_ca4-[18,23]: 639.7421\n",
      "Epoch 270/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0335 - ca1-[6,11]: 0.0112 - ca1-[12,17]: 0.0174 - ca1-[18,23]: 2.4201 - ca2-[0,5]: 20.6680 - ca2-[6,11]: 0.8885 - ca2-[12,17]: 0.2079 - ca2-[18,23]: 0.4064 - ca3-[0,5]: 1652.1768 - ca3-[6,11]: 1230.3050 - ca3-[12,17]: 865.1200 - ca3-[18,23]: 588.9482 - ca4-[0,5]: 721.7464 - ca4-[6,11]: 1465.3743 - ca4-[12,17]: 1032.5970 - ca4-[18,23]: 677.9919 - val_ca1-[0,5]: 0.0356 - val_ca1-[6,11]: 0.1634 - val_ca1-[12,17]: 1.2366 - val_ca1-[18,23]: 6.3662 - val_ca2-[0,5]: 20.9847 - val_ca2-[6,11]: 3.5567 - val_ca2-[12,17]: 10.0669 - val_ca2-[18,23]: 22.9473 - val_ca3-[0,5]: 1891.4272 - val_ca3-[6,11]: 1386.3055 - val_ca3-[12,17]: 882.6897 - val_ca3-[18,23]: 528.5389 - val_ca4-[0,5]: 2118.3025 - val_ca4-[6,11]: 1580.7543 - val_ca4-[12,17]: 1038.5161 - val_ca4-[18,23]: 648.4119\n",
      "Epoch 271/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0325 - ca1-[6,11]: 0.0099 - ca1-[12,17]: 0.0158 - ca1-[18,23]: 2.1611 - ca2-[0,5]: 20.6866 - ca2-[6,11]: 0.8889 - ca2-[12,17]: 0.2271 - ca2-[18,23]: 0.3827 - ca3-[0,5]: 1605.9376 - ca3-[6,11]: 1297.0266 - ca3-[12,17]: 992.7638 - ca3-[18,23]: 592.0412 - ca4-[0,5]: 743.9948 - ca4-[6,11]: 1545.0824 - ca4-[12,17]: 1038.1634 - ca4-[18,23]: 690.3208 - val_ca1-[0,5]: 0.0347 - val_ca1-[6,11]: 0.1649 - val_ca1-[12,17]: 1.2591 - val_ca1-[18,23]: 6.2994 - val_ca2-[0,5]: 20.9168 - val_ca2-[6,11]: 3.4101 - val_ca2-[12,17]: 9.7839 - val_ca2-[18,23]: 22.3920 - val_ca3-[0,5]: 1906.9678 - val_ca3-[6,11]: 1399.5648 - val_ca3-[12,17]: 893.2318 - val_ca3-[18,23]: 536.5514 - val_ca4-[0,5]: 2134.4014 - val_ca4-[6,11]: 1594.6196 - val_ca4-[12,17]: 1049.7222 - val_ca4-[18,23]: 657.1418\n",
      "Epoch 272/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0321 - ca1-[6,11]: 0.0086 - ca1-[12,17]: 0.0145 - ca1-[18,23]: 2.2708 - ca2-[0,5]: 20.9775 - ca2-[6,11]: 0.7776 - ca2-[12,17]: 0.2501 - ca2-[18,23]: 0.4822 - ca3-[0,5]: 1619.7134 - ca3-[6,11]: 1313.7086 - ca3-[12,17]: 963.6480 - ca3-[18,23]: 603.9176 - ca4-[0,5]: 734.2526 - ca4-[6,11]: 1561.6732 - ca4-[12,17]: 1052.7410 - ca4-[18,23]: 694.0524 - val_ca1-[0,5]: 0.0341 - val_ca1-[6,11]: 0.1533 - val_ca1-[12,17]: 1.1784 - val_ca1-[18,23]: 6.0470 - val_ca2-[0,5]: 20.8706 - val_ca2-[6,11]: 3.2959 - val_ca2-[12,17]: 9.6118 - val_ca2-[18,23]: 22.3290 - val_ca3-[0,5]: 1922.5410 - val_ca3-[6,11]: 1412.8611 - val_ca3-[12,17]: 903.8159 - val_ca3-[18,23]: 544.6111 - val_ca4-[0,5]: 2150.5391 - val_ca4-[6,11]: 1608.5278 - val_ca4-[12,17]: 1060.9738 - val_ca4-[18,23]: 665.9207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0315 - ca1-[6,11]: 0.0086 - ca1-[12,17]: 0.0156 - ca1-[18,23]: 2.1169 - ca2-[0,5]: 20.9098 - ca2-[6,11]: 0.8418 - ca2-[12,17]: 0.2037 - ca2-[18,23]: 0.3193 - ca3-[0,5]: 1695.1066 - ca3-[6,11]: 1321.5354 - ca3-[12,17]: 1003.5490 - ca3-[18,23]: 611.1174 - ca4-[0,5]: 740.5624 - ca4-[6,11]: 1505.3402 - ca4-[12,17]: 1059.0764 - ca4-[18,23]: 698.4471 - val_ca1-[0,5]: 0.0332 - val_ca1-[6,11]: 0.1611 - val_ca1-[12,17]: 1.2342 - val_ca1-[18,23]: 6.0552 - val_ca2-[0,5]: 20.8126 - val_ca2-[6,11]: 3.0668 - val_ca2-[12,17]: 8.9942 - val_ca2-[18,23]: 20.9656 - val_ca3-[0,5]: 1938.1792 - val_ca3-[6,11]: 1426.2224 - val_ca3-[12,17]: 914.4654 - val_ca3-[18,23]: 552.7356 - val_ca4-[0,5]: 2166.7766 - val_ca4-[6,11]: 1622.5291 - val_ca4-[12,17]: 1072.3129 - val_ca4-[18,23]: 674.7812\n",
      "Epoch 274/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0307 - ca1-[6,11]: 0.0079 - ca1-[12,17]: 0.0145 - ca1-[18,23]: 2.2095 - ca2-[0,5]: 20.6333 - ca2-[6,11]: 0.7922 - ca2-[12,17]: 0.2045 - ca2-[18,23]: 0.2624 - ca3-[0,5]: 1696.7250 - ca3-[6,11]: 1332.9806 - ca3-[12,17]: 938.4015 - ca3-[18,23]: 621.1262 - ca4-[0,5]: 763.0824 - ca4-[6,11]: 1587.4029 - ca4-[12,17]: 1078.7935 - ca4-[18,23]: 727.3767 - val_ca1-[0,5]: 0.0330 - val_ca1-[6,11]: 0.1501 - val_ca1-[12,17]: 1.1546 - val_ca1-[18,23]: 5.7199 - val_ca2-[0,5]: 20.8446 - val_ca2-[6,11]: 3.1792 - val_ca2-[12,17]: 9.0721 - val_ca2-[18,23]: 21.1299 - val_ca3-[0,5]: 1953.8951 - val_ca3-[6,11]: 1439.6591 - val_ca3-[12,17]: 925.1877 - val_ca3-[18,23]: 560.6614 - val_ca4-[0,5]: 2183.0725 - val_ca4-[6,11]: 1636.5905 - val_ca4-[12,17]: 1083.7120 - val_ca4-[18,23]: 683.3729\n",
      "Epoch 275/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0297 - ca1-[6,11]: 0.0089 - ca1-[12,17]: 0.0172 - ca1-[18,23]: 2.1327 - ca2-[0,5]: 20.9144 - ca2-[6,11]: 0.8616 - ca2-[12,17]: 0.1663 - ca2-[18,23]: 0.2171 - ca3-[0,5]: 1717.5974 - ca3-[6,11]: 1346.3018 - ca3-[12,17]: 1029.0220 - ca3-[18,23]: 629.2199 - ca4-[0,5]: 657.8333 - ca4-[6,11]: 1609.1617 - ca4-[12,17]: 1082.4392 - ca4-[18,23]: 731.2843 - val_ca1-[0,5]: 0.0319 - val_ca1-[6,11]: 0.1480 - val_ca1-[12,17]: 1.1788 - val_ca1-[18,23]: 5.1567 - val_ca2-[0,5]: 20.8180 - val_ca2-[6,11]: 3.0719 - val_ca2-[12,17]: 8.7836 - val_ca2-[18,23]: 20.1725 - val_ca3-[0,5]: 1969.6477 - val_ca3-[6,11]: 1453.1362 - val_ca3-[12,17]: 935.9547 - val_ca3-[18,23]: 573.0891 - val_ca4-[0,5]: 2199.4087 - val_ca4-[6,11]: 1650.6940 - val_ca4-[12,17]: 1095.1571 - val_ca4-[18,23]: 697.0760\n",
      "Epoch 276/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0297 - ca1-[6,11]: 0.0078 - ca1-[12,17]: 0.0178 - ca1-[18,23]: 1.8366 - ca2-[0,5]: 20.3591 - ca2-[6,11]: 0.8558 - ca2-[12,17]: 0.1578 - ca2-[18,23]: 0.2902 - ca3-[0,5]: 1675.3670 - ca3-[6,11]: 1362.0109 - ca3-[12,17]: 1000.7713 - ca3-[18,23]: 638.6225 - ca4-[0,5]: 815.8862 - ca4-[6,11]: 1394.7974 - ca4-[12,17]: 1096.8261 - ca4-[18,23]: 710.1056 - val_ca1-[0,5]: 0.0316 - val_ca1-[6,11]: 0.1675 - val_ca1-[12,17]: 1.1195 - val_ca1-[18,23]: 5.7968 - val_ca2-[0,5]: 20.7538 - val_ca2-[6,11]: 2.8982 - val_ca2-[12,17]: 8.1314 - val_ca2-[18,23]: 19.9033 - val_ca3-[0,5]: 1985.4810 - val_ca3-[6,11]: 1466.6918 - val_ca3-[12,17]: 945.8454 - val_ca3-[18,23]: 577.4926 - val_ca4-[0,5]: 2215.8354 - val_ca4-[6,11]: 1664.8849 - val_ca4-[12,17]: 1105.6455 - val_ca4-[18,23]: 701.7202\n",
      "Epoch 277/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0291 - ca1-[6,11]: 0.0070 - ca1-[12,17]: 0.0123 - ca1-[18,23]: 1.9489 - ca2-[0,5]: 20.7490 - ca2-[6,11]: 0.8431 - ca2-[12,17]: 0.1847 - ca2-[18,23]: 0.2720 - ca3-[0,5]: 1746.6905 - ca3-[6,11]: 1372.2995 - ca3-[12,17]: 1057.7729 - ca3-[18,23]: 618.3123 - ca4-[0,5]: 749.6154 - ca4-[6,11]: 1622.7985 - ca4-[12,17]: 1121.1998 - ca4-[18,23]: 728.7107 - val_ca1-[0,5]: 0.0311 - val_ca1-[6,11]: 0.1144 - val_ca1-[12,17]: 1.1170 - val_ca1-[18,23]: 5.4663 - val_ca2-[0,5]: 20.8065 - val_ca2-[6,11]: 3.0681 - val_ca2-[12,17]: 8.5411 - val_ca2-[18,23]: 20.3115 - val_ca3-[0,5]: 2001.3782 - val_ca3-[6,11]: 1479.7096 - val_ca3-[12,17]: 957.7042 - val_ca3-[18,23]: 585.8738 - val_ca4-[0,5]: 2232.3015 - val_ca4-[6,11]: 1678.4673 - val_ca4-[12,17]: 1118.2567 - val_ca4-[18,23]: 710.8163\n",
      "Epoch 278/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0289 - ca1-[6,11]: 0.0068 - ca1-[12,17]: 0.0150 - ca1-[18,23]: 1.9331 - ca2-[0,5]: 20.5303 - ca2-[6,11]: 0.8063 - ca2-[12,17]: 0.1646 - ca2-[18,23]: 0.2942 - ca3-[0,5]: 1703.5525 - ca3-[6,11]: 1383.9120 - ca3-[12,17]: 1025.4811 - ca3-[18,23]: 655.3119 - ca4-[0,5]: 731.5921 - ca4-[6,11]: 1650.0951 - ca4-[12,17]: 1076.8582 - ca4-[18,23]: 747.3579 - val_ca1-[0,5]: 0.0301 - val_ca1-[6,11]: 0.1479 - val_ca1-[12,17]: 1.1400 - val_ca1-[18,23]: 5.3138 - val_ca2-[0,5]: 20.7043 - val_ca2-[6,11]: 2.6811 - val_ca2-[12,17]: 7.8410 - val_ca2-[18,23]: 18.7339 - val_ca3-[0,5]: 2017.3462 - val_ca3-[6,11]: 1494.0006 - val_ca3-[12,17]: 968.6791 - val_ca3-[18,23]: 594.0357 - val_ca4-[0,5]: 2248.8240 - val_ca4-[6,11]: 1693.4075 - val_ca4-[12,17]: 1129.8876 - val_ca4-[18,23]: 719.6258\n",
      "Epoch 279/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0271 - ca1-[6,11]: 0.0053 - ca1-[12,17]: 0.0123 - ca1-[18,23]: 1.8179 - ca2-[0,5]: 20.2519 - ca2-[6,11]: 0.8164 - ca2-[12,17]: 0.1694 - ca2-[18,23]: 0.2218 - ca3-[0,5]: 1717.7279 - ca3-[6,11]: 1397.2077 - ca3-[12,17]: 1031.7591 - ca3-[18,23]: 659.5553 - ca4-[0,5]: 795.4351 - ca4-[6,11]: 1655.6111 - ca4-[12,17]: 1089.9273 - ca4-[18,23]: 737.8798 - val_ca1-[0,5]: 0.0300 - val_ca1-[6,11]: 0.1417 - val_ca1-[12,17]: 1.0706 - val_ca1-[18,23]: 5.1931 - val_ca2-[0,5]: 20.7303 - val_ca2-[6,11]: 2.7336 - val_ca2-[12,17]: 7.8585 - val_ca2-[18,23]: 18.8857 - val_ca3-[0,5]: 2033.3627 - val_ca3-[6,11]: 1507.7404 - val_ca3-[12,17]: 979.7073 - val_ca3-[18,23]: 602.8262 - val_ca4-[0,5]: 2265.3918 - val_ca4-[6,11]: 1707.7450 - val_ca4-[12,17]: 1141.5685 - val_ca4-[18,23]: 729.1795\n",
      "Epoch 280/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0276 - ca1-[6,11]: 0.0080 - ca1-[12,17]: 0.0183 - ca1-[18,23]: 1.7598 - ca2-[0,5]: 20.3243 - ca2-[6,11]: 0.8187 - ca2-[12,17]: 0.1583 - ca2-[18,23]: 0.2123 - ca3-[0,5]: 1731.9547 - ca3-[6,11]: 1413.7861 - ca3-[12,17]: 1090.0866 - ca3-[18,23]: 634.1499 - ca4-[0,5]: 785.4052 - ca4-[6,11]: 1666.5957 - ca4-[12,17]: 1109.9392 - ca4-[18,23]: 774.7228 - val_ca1-[0,5]: 0.0291 - val_ca1-[6,11]: 0.1497 - val_ca1-[12,17]: 1.1343 - val_ca1-[18,23]: 5.2438 - val_ca2-[0,5]: 20.7686 - val_ca2-[6,11]: 2.8473 - val_ca2-[12,17]: 7.8009 - val_ca2-[18,23]: 19.1570 - val_ca3-[0,5]: 2049.4258 - val_ca3-[6,11]: 1521.5293 - val_ca3-[12,17]: 990.7874 - val_ca3-[18,23]: 611.3847 - val_ca4-[0,5]: 2282.0374 - val_ca4-[6,11]: 1722.1577 - val_ca4-[12,17]: 1153.3219 - val_ca4-[18,23]: 738.4573\n",
      "Epoch 281/300\n",
      "26/26 [==============================] - 3s 128ms/step - ca1-[0,5]: 0.0264 - ca1-[6,11]: 0.0063 - ca1-[12,17]: 0.0141 - ca1-[18,23]: 1.6926 - ca2-[0,5]: 20.4964 - ca2-[6,11]: 0.7699 - ca2-[12,17]: 0.2083 - ca2-[18,23]: 0.3585 - ca3-[0,5]: 1818.7285 - ca3-[6,11]: 1425.5521 - ca3-[12,17]: 970.8498 - ca3-[18,23]: 679.2433 - ca4-[0,5]: 808.5613 - ca4-[6,11]: 1615.5010 - ca4-[12,17]: 1157.4071 - ca4-[18,23]: 779.3414 - val_ca1-[0,5]: 0.0291 - val_ca1-[6,11]: 0.1578 - val_ca1-[12,17]: 1.1128 - val_ca1-[18,23]: 5.2284 - val_ca2-[0,5]: 20.6920 - val_ca2-[6,11]: 2.5470 - val_ca2-[12,17]: 7.3506 - val_ca2-[18,23]: 18.6301 - val_ca3-[0,5]: 2065.5469 - val_ca3-[6,11]: 1535.3768 - val_ca3-[12,17]: 999.2235 - val_ca3-[18,23]: 620.0035 - val_ca4-[0,5]: 2298.7422 - val_ca4-[6,11]: 1736.6300 - val_ca4-[12,17]: 1162.2224 - val_ca4-[18,23]: 747.7954\n",
      "Epoch 282/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0263 - ca1-[6,11]: 0.0064 - ca1-[12,17]: 0.0103 - ca1-[18,23]: 1.6756 - ca2-[0,5]: 20.6363 - ca2-[6,11]: 0.7352 - ca2-[12,17]: 0.1511 - ca2-[18,23]: 0.2390 - ca3-[0,5]: 1680.8204 - ca3-[6,11]: 1446.6843 - ca3-[12,17]: 1068.3272 - ca3-[18,23]: 689.5104 - ca4-[0,5]: 798.4617 - ca4-[6,11]: 1621.5513 - ca4-[12,17]: 1171.4901 - ca4-[18,23]: 761.4636 - val_ca1-[0,5]: 0.0280 - val_ca1-[6,11]: 0.1461 - val_ca1-[12,17]: 1.0917 - val_ca1-[18,23]: 4.9853 - val_ca2-[0,5]: 20.7293 - val_ca2-[6,11]: 2.6399 - val_ca2-[12,17]: 7.4354 - val_ca2-[18,23]: 18.6064 - val_ca3-[0,5]: 2081.7190 - val_ca3-[6,11]: 1549.2773 - val_ca3-[12,17]: 1013.1218 - val_ca3-[18,23]: 628.6794 - val_ca4-[0,5]: 2315.5117 - val_ca4-[6,11]: 1751.1665 - val_ca4-[12,17]: 1177.0123 - val_ca4-[18,23]: 757.1965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0258 - ca1-[6,11]: 0.0071 - ca1-[12,17]: 0.0146 - ca1-[18,23]: 1.6119 - ca2-[0,5]: 20.6377 - ca2-[6,11]: 0.8273 - ca2-[12,17]: 0.1329 - ca2-[18,23]: 0.2134 - ca3-[0,5]: 1828.7070 - ca3-[6,11]: 1460.3243 - ca3-[12,17]: 1079.7975 - ca3-[18,23]: 702.9685 - ca4-[0,5]: 821.8150 - ca4-[6,11]: 1632.0751 - ca4-[12,17]: 1183.9114 - ca4-[18,23]: 801.6168 - val_ca1-[0,5]: 0.0281 - val_ca1-[6,11]: 0.1566 - val_ca1-[12,17]: 1.1717 - val_ca1-[18,23]: 5.0807 - val_ca2-[0,5]: 20.7136 - val_ca2-[6,11]: 2.5256 - val_ca2-[12,17]: 7.2376 - val_ca2-[18,23]: 18.4485 - val_ca3-[0,5]: 2097.9399 - val_ca3-[6,11]: 1563.2285 - val_ca3-[12,17]: 1024.3695 - val_ca3-[18,23]: 637.4105 - val_ca4-[0,5]: 2332.3621 - val_ca4-[6,11]: 1765.7811 - val_ca4-[12,17]: 1188.9642 - val_ca4-[18,23]: 766.6696\n",
      "Epoch 284/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.0258 - ca1-[6,11]: 0.0072 - ca1-[12,17]: 0.0153 - ca1-[18,23]: 1.4472 - ca2-[0,5]: 20.6067 - ca2-[6,11]: 0.7919 - ca2-[12,17]: 0.1255 - ca2-[18,23]: 0.1737 - ca3-[0,5]: 1856.9819 - ca3-[6,11]: 1464.9406 - ca3-[12,17]: 1091.1969 - ca3-[18,23]: 705.3501 - ca4-[0,5]: 828.4488 - ca4-[6,11]: 1728.0700 - ca4-[12,17]: 1200.4767 - ca4-[18,23]: 812.7467 - val_ca1-[0,5]: 0.0279 - val_ca1-[6,11]: 0.1346 - val_ca1-[12,17]: 1.0054 - val_ca1-[18,23]: 4.7109 - val_ca2-[0,5]: 20.7110 - val_ca2-[6,11]: 2.4484 - val_ca2-[12,17]: 7.0678 - val_ca2-[18,23]: 18.2490 - val_ca3-[0,5]: 2114.2463 - val_ca3-[6,11]: 1577.2618 - val_ca3-[12,17]: 1035.6959 - val_ca3-[18,23]: 646.2169 - val_ca4-[0,5]: 2349.1655 - val_ca4-[6,11]: 1780.3632 - val_ca4-[12,17]: 1200.9005 - val_ca4-[18,23]: 776.1431\n",
      "Epoch 285/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0258 - ca1-[6,11]: 0.0053 - ca1-[12,17]: 0.0120 - ca1-[18,23]: 1.4732 - ca2-[0,5]: 20.3941 - ca2-[6,11]: 0.7733 - ca2-[12,17]: 0.1569 - ca2-[18,23]: 0.2476 - ca3-[0,5]: 1872.0431 - ca3-[6,11]: 1483.6115 - ca3-[12,17]: 1055.1412 - ca3-[18,23]: 683.9356 - ca4-[0,5]: 835.1066 - ca4-[6,11]: 1507.4926 - ca4-[12,17]: 1206.6558 - ca4-[18,23]: 798.3121 - val_ca1-[0,5]: 0.0272 - val_ca1-[6,11]: 0.1351 - val_ca1-[12,17]: 0.9268 - val_ca1-[18,23]: 4.7416 - val_ca2-[0,5]: 20.7045 - val_ca2-[6,11]: 2.3887 - val_ca2-[12,17]: 6.5807 - val_ca2-[18,23]: 18.4131 - val_ca3-[0,5]: 2130.6050 - val_ca3-[6,11]: 1591.3495 - val_ca3-[12,17]: 1049.1401 - val_ca3-[18,23]: 655.0806 - val_ca4-[0,5]: 2366.0601 - val_ca4-[6,11]: 1795.0326 - val_ca4-[12,17]: 1215.1403 - val_ca4-[18,23]: 785.6942\n",
      "Epoch 286/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.0249 - ca1-[6,11]: 0.0055 - ca1-[12,17]: 0.0088 - ca1-[18,23]: 1.4279 - ca2-[0,5]: 20.5771 - ca2-[6,11]: 0.7595 - ca2-[12,17]: 0.1270 - ca2-[18,23]: 0.1604 - ca3-[0,5]: 1887.1658 - ca3-[6,11]: 1498.6250 - ca3-[12,17]: 1107.4391 - ca3-[18,23]: 720.7386 - ca4-[0,5]: 841.7889 - ca4-[6,11]: 1764.8835 - ca4-[12,17]: 1215.2729 - ca4-[18,23]: 835.5449 - val_ca1-[0,5]: 0.0263 - val_ca1-[6,11]: 0.1378 - val_ca1-[12,17]: 1.0416 - val_ca1-[18,23]: 4.4926 - val_ca2-[0,5]: 20.7222 - val_ca2-[6,11]: 2.3427 - val_ca2-[12,17]: 6.7999 - val_ca2-[18,23]: 18.3748 - val_ca3-[0,5]: 2147.0564 - val_ca3-[6,11]: 1605.5253 - val_ca3-[12,17]: 1058.5438 - val_ca3-[18,23]: 663.7034 - val_ca4-[0,5]: 2383.0002 - val_ca4-[6,11]: 1809.7488 - val_ca4-[12,17]: 1224.9875 - val_ca4-[18,23]: 794.9185\n",
      "Epoch 287/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0249 - ca1-[6,11]: 0.0052 - ca1-[12,17]: 0.0088 - ca1-[18,23]: 1.4056 - ca2-[0,5]: 20.3663 - ca2-[6,11]: 0.7615 - ca2-[12,17]: 0.1404 - ca2-[18,23]: 0.2156 - ca3-[0,5]: 1902.3578 - ca3-[6,11]: 1510.4653 - ca3-[12,17]: 1166.1433 - ca3-[18,23]: 734.9932 - ca4-[0,5]: 848.5347 - ca4-[6,11]: 1775.4779 - ca4-[12,17]: 1225.6720 - ca4-[18,23]: 843.5911 - val_ca1-[0,5]: 0.0257 - val_ca1-[6,11]: 0.1229 - val_ca1-[12,17]: 1.0350 - val_ca1-[18,23]: 4.5651 - val_ca2-[0,5]: 20.7430 - val_ca2-[6,11]: 2.3381 - val_ca2-[12,17]: 6.7620 - val_ca2-[18,23]: 18.4946 - val_ca3-[0,5]: 2163.5356 - val_ca3-[6,11]: 1619.9941 - val_ca3-[12,17]: 1070.0483 - val_ca3-[18,23]: 673.0105 - val_ca4-[0,5]: 2400.0762 - val_ca4-[6,11]: 1824.8640 - val_ca4-[12,17]: 1237.1704 - val_ca4-[18,23]: 805.0048\n",
      "Epoch 288/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0234 - ca1-[6,11]: 0.0044 - ca1-[12,17]: 0.0082 - ca1-[18,23]: 1.3343 - ca2-[0,5]: 20.3599 - ca2-[6,11]: 0.7441 - ca2-[12,17]: 0.1233 - ca2-[18,23]: 0.1925 - ca3-[0,5]: 1904.0407 - ca3-[6,11]: 1526.4185 - ca3-[12,17]: 1132.3395 - ca3-[18,23]: 749.5249 - ca4-[0,5]: 855.2847 - ca4-[6,11]: 1774.2648 - ca4-[12,17]: 1237.8678 - ca4-[18,23]: 853.3594 - val_ca1-[0,5]: 0.0254 - val_ca1-[6,11]: 0.1350 - val_ca1-[12,17]: 0.9975 - val_ca1-[18,23]: 4.4196 - val_ca2-[0,5]: 20.7815 - val_ca2-[6,11]: 2.3348 - val_ca2-[12,17]: 6.5588 - val_ca2-[18,23]: 18.2146 - val_ca3-[0,5]: 2180.0679 - val_ca3-[6,11]: 1633.9972 - val_ca3-[12,17]: 1081.6086 - val_ca3-[18,23]: 682.0549 - val_ca4-[0,5]: 2417.1675 - val_ca4-[6,11]: 1839.4557 - val_ca4-[12,17]: 1249.3818 - val_ca4-[18,23]: 814.7466\n",
      "Epoch 289/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0234 - ca1-[6,11]: 0.0045 - ca1-[12,17]: 0.0104 - ca1-[18,23]: 1.3052 - ca2-[0,5]: 20.2916 - ca2-[6,11]: 0.7453 - ca2-[12,17]: 0.1481 - ca2-[18,23]: 0.3012 - ca3-[0,5]: 1932.8820 - ca3-[6,11]: 1532.5101 - ca3-[12,17]: 1146.3460 - ca3-[18,23]: 753.4001 - ca4-[0,5]: 907.9082 - ca4-[6,11]: 1793.7707 - ca4-[12,17]: 1251.4026 - ca4-[18,23]: 851.4159 - val_ca1-[0,5]: 0.0255 - val_ca1-[6,11]: 0.1280 - val_ca1-[12,17]: 0.9376 - val_ca1-[18,23]: 4.2448 - val_ca2-[0,5]: 20.8081 - val_ca2-[6,11]: 2.3106 - val_ca2-[12,17]: 6.3491 - val_ca2-[18,23]: 18.1273 - val_ca3-[0,5]: 2196.6804 - val_ca3-[6,11]: 1648.3384 - val_ca3-[12,17]: 1093.2443 - val_ca3-[18,23]: 691.1722 - val_ca4-[0,5]: 2434.3176 - val_ca4-[6,11]: 1854.3790 - val_ca4-[12,17]: 1261.6530 - val_ca4-[18,23]: 824.5479\n",
      "Epoch 290/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0235 - ca1-[6,11]: 0.0072 - ca1-[12,17]: 0.0147 - ca1-[18,23]: 1.2936 - ca2-[0,5]: 20.5534 - ca2-[6,11]: 0.7134 - ca2-[12,17]: 0.1943 - ca2-[18,23]: 0.3380 - ca3-[0,5]: 1877.1886 - ca3-[6,11]: 1552.0436 - ca3-[12,17]: 1218.8070 - ca3-[18,23]: 762.3608 - ca4-[0,5]: 868.8609 - ca4-[6,11]: 1813.5277 - ca4-[12,17]: 1271.9647 - ca4-[18,23]: 862.4304 - val_ca1-[0,5]: 0.0246 - val_ca1-[6,11]: 0.1322 - val_ca1-[12,17]: 0.9802 - val_ca1-[18,23]: 4.2695 - val_ca2-[0,5]: 20.7686 - val_ca2-[6,11]: 2.0810 - val_ca2-[12,17]: 5.8850 - val_ca2-[18,23]: 17.8270 - val_ca3-[0,5]: 2213.3232 - val_ca3-[6,11]: 1662.7144 - val_ca3-[12,17]: 1104.9200 - val_ca3-[18,23]: 700.3346 - val_ca4-[0,5]: 2451.5303 - val_ca4-[6,11]: 1869.3646 - val_ca4-[12,17]: 1273.9854 - val_ca4-[18,23]: 834.4113\n",
      "Epoch 291/300\n",
      "26/26 [==============================] - 3s 127ms/step - ca1-[0,5]: 0.0224 - ca1-[6,11]: 0.0068 - ca1-[12,17]: 0.0129 - ca1-[18,23]: 1.1737 - ca2-[0,5]: 20.6711 - ca2-[6,11]: 0.7298 - ca2-[12,17]: 0.1078 - ca2-[18,23]: 0.1632 - ca3-[0,5]: 1963.6229 - ca3-[6,11]: 1566.6573 - ca3-[12,17]: 1213.9554 - ca3-[18,23]: 774.8108 - ca4-[0,5]: 939.7990 - ca4-[6,11]: 1812.1338 - ca4-[12,17]: 1272.0574 - ca4-[18,23]: 876.8029 - val_ca1-[0,5]: 0.0241 - val_ca1-[6,11]: 0.1320 - val_ca1-[12,17]: 0.9745 - val_ca1-[18,23]: 4.1740 - val_ca2-[0,5]: 20.8602 - val_ca2-[6,11]: 2.2478 - val_ca2-[12,17]: 6.1425 - val_ca2-[18,23]: 18.3804 - val_ca3-[0,5]: 2230.0273 - val_ca3-[6,11]: 1677.1509 - val_ca3-[12,17]: 1116.6573 - val_ca3-[18,23]: 709.5585 - val_ca4-[0,5]: 2468.8562 - val_ca4-[6,11]: 1884.4568 - val_ca4-[12,17]: 1286.4163 - val_ca4-[18,23]: 844.3657\n",
      "Epoch 292/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0223 - ca1-[6,11]: 0.0056 - ca1-[12,17]: 0.0137 - ca1-[18,23]: 1.2063 - ca2-[0,5]: 20.7680 - ca2-[6,11]: 0.7313 - ca2-[12,17]: 0.1182 - ca2-[18,23]: 0.2475 - ca3-[0,5]: 1683.1815 - ca3-[6,11]: 1520.6505 - ca3-[12,17]: 1224.0810 - ca3-[18,23]: 745.3314 - ca4-[0,5]: 882.5824 - ca4-[6,11]: 1839.9128 - ca4-[12,17]: 1281.3536 - ca4-[18,23]: 883.3621 - val_ca1-[0,5]: 0.0242 - val_ca1-[6,11]: 0.1280 - val_ca1-[12,17]: 1.0470 - val_ca1-[18,23]: 4.2407 - val_ca2-[0,5]: 20.8040 - val_ca2-[6,11]: 2.0750 - val_ca2-[12,17]: 5.9205 - val_ca2-[18,23]: 18.4708 - val_ca3-[0,5]: 2246.7695 - val_ca3-[6,11]: 1691.1047 - val_ca3-[12,17]: 1128.4403 - val_ca3-[18,23]: 718.8318 - val_ca4-[0,5]: 2486.2002 - val_ca4-[6,11]: 1899.0122 - val_ca4-[12,17]: 1298.8779 - val_ca4-[18,23]: 854.3561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0228 - ca1-[6,11]: 0.0060 - ca1-[12,17]: 0.0119 - ca1-[18,23]: 1.1798 - ca2-[0,5]: 20.9060 - ca2-[6,11]: 0.7252 - ca2-[12,17]: 0.0935 - ca2-[18,23]: 0.1513 - ca3-[0,5]: 1921.7793 - ca3-[6,11]: 1475.2415 - ca3-[12,17]: 1234.0043 - ca3-[18,23]: 793.8150 - ca4-[0,5]: 872.0527 - ca4-[6,11]: 1863.0902 - ca4-[12,17]: 1302.6790 - ca4-[18,23]: 918.8212 - val_ca1-[0,5]: 0.0237 - val_ca1-[6,11]: 0.1244 - val_ca1-[12,17]: 0.9233 - val_ca1-[18,23]: 3.9772 - val_ca2-[0,5]: 20.8877 - val_ca2-[6,11]: 2.1648 - val_ca2-[12,17]: 5.9376 - val_ca2-[18,23]: 18.4856 - val_ca3-[0,5]: 2263.6108 - val_ca3-[6,11]: 1706.2025 - val_ca3-[12,17]: 1140.3118 - val_ca3-[18,23]: 728.1882 - val_ca4-[0,5]: 2503.6248 - val_ca4-[6,11]: 1914.7653 - val_ca4-[12,17]: 1311.4142 - val_ca4-[18,23]: 864.4188\n",
      "Epoch 294/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0222 - ca1-[6,11]: 0.0058 - ca1-[12,17]: 0.0121 - ca1-[18,23]: 1.0821 - ca2-[0,5]: 20.9817 - ca2-[6,11]: 0.7141 - ca2-[12,17]: 0.1123 - ca2-[18,23]: 0.1862 - ca3-[0,5]: 2017.0314 - ca3-[6,11]: 1615.0573 - ca3-[12,17]: 1147.0400 - ca3-[18,23]: 802.8356 - ca4-[0,5]: 962.1143 - ca4-[6,11]: 1772.3077 - ca4-[12,17]: 1315.4133 - ca4-[18,23]: 919.4205 - val_ca1-[0,5]: 0.0231 - val_ca1-[6,11]: 0.1295 - val_ca1-[12,17]: 0.9500 - val_ca1-[18,23]: 3.9757 - val_ca2-[0,5]: 20.8553 - val_ca2-[6,11]: 1.9675 - val_ca2-[12,17]: 5.5463 - val_ca2-[18,23]: 18.3343 - val_ca3-[0,5]: 2280.4963 - val_ca3-[6,11]: 1720.8231 - val_ca3-[12,17]: 1152.2333 - val_ca3-[18,23]: 737.5975 - val_ca4-[0,5]: 2521.1204 - val_ca4-[6,11]: 1930.0294 - val_ca4-[12,17]: 1324.0190 - val_ca4-[18,23]: 874.5486\n",
      "Epoch 295/300\n",
      "26/26 [==============================] - 3s 129ms/step - ca1-[0,5]: 0.0219 - ca1-[6,11]: 0.0056 - ca1-[12,17]: 0.0100 - ca1-[18,23]: 0.9945 - ca2-[0,5]: 21.1472 - ca2-[6,11]: 0.7455 - ca2-[12,17]: 0.0932 - ca2-[18,23]: 0.1213 - ca3-[0,5]: 2025.7576 - ca3-[6,11]: 1621.1263 - ca3-[12,17]: 1219.6493 - ca3-[18,23]: 812.1715 - ca4-[0,5]: 969.6286 - ca4-[6,11]: 1885.2509 - ca4-[12,17]: 1289.6764 - ca4-[18,23]: 943.2703 - val_ca1-[0,5]: 0.0230 - val_ca1-[6,11]: 0.1226 - val_ca1-[12,17]: 0.8900 - val_ca1-[18,23]: 3.8134 - val_ca2-[0,5]: 20.9479 - val_ca2-[6,11]: 2.1024 - val_ca2-[12,17]: 5.7395 - val_ca2-[18,23]: 18.6564 - val_ca3-[0,5]: 2297.4463 - val_ca3-[6,11]: 1735.5070 - val_ca3-[12,17]: 1164.2183 - val_ca3-[18,23]: 747.0701 - val_ca4-[0,5]: 2538.6970 - val_ca4-[6,11]: 1945.3707 - val_ca4-[12,17]: 1336.6991 - val_ca4-[18,23]: 884.7510\n",
      "Epoch 296/300\n",
      "26/26 [==============================] - 3s 125ms/step - ca1-[0,5]: 0.0215 - ca1-[6,11]: 0.0054 - ca1-[12,17]: 0.0106 - ca1-[18,23]: 1.0328 - ca2-[0,5]: 20.8379 - ca2-[6,11]: 0.6801 - ca2-[12,17]: 0.1068 - ca2-[18,23]: 0.2151 - ca3-[0,5]: 2041.4502 - ca3-[6,11]: 1635.4393 - ca3-[12,17]: 1227.7183 - ca3-[18,23]: 823.5220 - ca4-[0,5]: 843.5067 - ca4-[6,11]: 1893.8015 - ca4-[12,17]: 1350.8691 - ca4-[18,23]: 924.8534 - val_ca1-[0,5]: 0.0224 - val_ca1-[6,11]: 0.1265 - val_ca1-[12,17]: 0.9282 - val_ca1-[18,23]: 3.3891 - val_ca2-[0,5]: 20.9408 - val_ca2-[6,11]: 1.9751 - val_ca2-[12,17]: 5.5637 - val_ca2-[18,23]: 18.3872 - val_ca3-[0,5]: 2314.4580 - val_ca3-[6,11]: 1750.2528 - val_ca3-[12,17]: 1176.2653 - val_ca3-[18,23]: 761.5604 - val_ca4-[0,5]: 2556.3198 - val_ca4-[6,11]: 1960.7609 - val_ca4-[12,17]: 1349.4296 - val_ca4-[18,23]: 900.4916\n",
      "Epoch 297/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0215 - ca1-[6,11]: 0.0048 - ca1-[12,17]: 0.0088 - ca1-[18,23]: 0.9994 - ca2-[0,5]: 20.9281 - ca2-[6,11]: 0.7216 - ca2-[12,17]: 0.1195 - ca2-[18,23]: 0.2348 - ca3-[0,5]: 1982.0725 - ca3-[6,11]: 1591.2014 - ca3-[12,17]: 1284.8351 - ca3-[18,23]: 794.3213 - ca4-[0,5]: 849.9684 - ca4-[6,11]: 1916.8836 - ca4-[12,17]: 1313.9418 - ca4-[18,23]: 945.9247 - val_ca1-[0,5]: 0.0225 - val_ca1-[6,11]: 0.1210 - val_ca1-[12,17]: 0.9033 - val_ca1-[18,23]: 3.3361 - val_ca2-[0,5]: 20.8860 - val_ca2-[6,11]: 1.7788 - val_ca2-[12,17]: 5.4601 - val_ca2-[18,23]: 18.8324 - val_ca3-[0,5]: 2331.5598 - val_ca3-[6,11]: 1765.0848 - val_ca3-[12,17]: 1188.3945 - val_ca3-[18,23]: 771.2119 - val_ca4-[0,5]: 2574.0110 - val_ca4-[6,11]: 1976.2180 - val_ca4-[12,17]: 1362.2264 - val_ca4-[18,23]: 910.8494\n",
      "Epoch 298/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0209 - ca1-[6,11]: 0.0055 - ca1-[12,17]: 0.0103 - ca1-[18,23]: 1.0045 - ca2-[0,5]: 20.7046 - ca2-[6,11]: 0.6577 - ca2-[12,17]: 0.1515 - ca2-[18,23]: 0.1563 - ca3-[0,5]: 2073.0312 - ca3-[6,11]: 1662.6717 - ca3-[12,17]: 1301.1806 - ca3-[18,23]: 840.0833 - ca4-[0,5]: 924.3764 - ca4-[6,11]: 1935.6333 - ca4-[12,17]: 1371.2181 - ca4-[18,23]: 958.6777 - val_ca1-[0,5]: 0.0218 - val_ca1-[6,11]: 0.1254 - val_ca1-[12,17]: 0.9221 - val_ca1-[18,23]: 3.7284 - val_ca2-[0,5]: 21.0188 - val_ca2-[6,11]: 1.9324 - val_ca2-[12,17]: 5.2178 - val_ca2-[18,23]: 18.8342 - val_ca3-[0,5]: 2348.7041 - val_ca3-[6,11]: 1779.9628 - val_ca3-[12,17]: 1200.5725 - val_ca3-[18,23]: 775.8828 - val_ca4-[0,5]: 2591.6685 - val_ca4-[6,11]: 1991.6534 - val_ca4-[12,17]: 1375.0151 - val_ca4-[18,23]: 915.6511\n",
      "Epoch 299/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0203 - ca1-[6,11]: 0.0053 - ca1-[12,17]: 0.0085 - ca1-[18,23]: 0.9916 - ca2-[0,5]: 20.8702 - ca2-[6,11]: 0.6876 - ca2-[12,17]: 0.0926 - ca2-[18,23]: 0.1366 - ca3-[0,5]: 2088.9014 - ca3-[6,11]: 1683.1976 - ca3-[12,17]: 1316.1055 - ca3-[18,23]: 814.9929 - ca4-[0,5]: 999.8984 - ca4-[6,11]: 1949.8481 - ca4-[12,17]: 1384.6779 - ca4-[18,23]: 967.7095 - val_ca1-[0,5]: 0.0216 - val_ca1-[6,11]: 0.1212 - val_ca1-[12,17]: 0.8677 - val_ca1-[18,23]: 3.5619 - val_ca2-[0,5]: 21.0487 - val_ca2-[6,11]: 1.8935 - val_ca2-[12,17]: 5.2685 - val_ca2-[18,23]: 19.0630 - val_ca3-[0,5]: 2365.9058 - val_ca3-[6,11]: 1794.8984 - val_ca3-[12,17]: 1212.8096 - val_ca3-[18,23]: 785.6073 - val_ca4-[0,5]: 2609.4312 - val_ca4-[6,11]: 2007.1887 - val_ca4-[12,17]: 1387.8975 - val_ca4-[18,23]: 926.0637\n",
      "Epoch 300/300\n",
      "26/26 [==============================] - 3s 126ms/step - ca1-[0,5]: 0.0207 - ca1-[6,11]: 0.0054 - ca1-[12,17]: 0.0105 - ca1-[18,23]: 0.7783 - ca2-[0,5]: 20.9745 - ca2-[6,11]: 0.6953 - ca2-[12,17]: 0.1398 - ca2-[18,23]: 0.1776 - ca3-[0,5]: 2027.9129 - ca3-[6,11]: 1697.1574 - ca3-[12,17]: 1327.1264 - ca3-[18,23]: 825.0060 - ca4-[0,5]: 902.7410 - ca4-[6,11]: 1961.7707 - ca4-[12,17]: 1398.7826 - ca4-[18,23]: 990.6152 - val_ca1-[0,5]: 0.0219 - val_ca1-[6,11]: 0.1181 - val_ca1-[12,17]: 0.8628 - val_ca1-[18,23]: 3.5688 - val_ca2-[0,5]: 21.0777 - val_ca2-[6,11]: 1.8619 - val_ca2-[12,17]: 4.9569 - val_ca2-[18,23]: 18.8223 - val_ca3-[0,5]: 2383.1826 - val_ca3-[6,11]: 1809.9078 - val_ca3-[12,17]: 1225.1183 - val_ca3-[18,23]: 795.4016 - val_ca4-[0,5]: 2627.3071 - val_ca4-[6,11]: 2022.8304 - val_ca4-[12,17]: 1400.8785 - val_ca4-[18,23]: 936.5677\n",
      "CPU times: user 16min 38s, sys: 6.96 s, total: 16min 45s\n",
      "Wall time: 16min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=300,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "for k in [k for k in history if 'val_ca4' in k]:\n",
    "    plt.plot(history[k], label=k.split('-')[1])\n",
    "        \n",
    "plt.legend()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len = min([x.shape[0] for x in train_dfs])\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    train_dfs[3].drop('cnt',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[3]['cnt'].to_numpy()[:min_len],\n",
    "    train_dfs[2].drop('cnt',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[2]['cnt'].to_numpy()[:min_len],\n",
    "    train_dfs[1].drop('cnt',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[1]['cnt'].to_numpy()[:min_len],\n",
    "    train_dfs[0].drop('cnt',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[0]['cnt'].to_numpy()[:min_len],\n",
    ")).shuffle(100).batch(128,True)\n",
    "\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    np.concatenate((\n",
    "        test_dfs[3].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[2].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[1].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[0].drop('cnt',axis=1).to_numpy(),\n",
    "    )),\n",
    "    np.concatenate((\n",
    "        test_dfs[3]['cnt'].to_numpy(),\n",
    "        test_dfs[2]['cnt'].to_numpy(),\n",
    "        test_dfs[1]['cnt'].to_numpy(),\n",
    "        test_dfs[0]['cnt'].to_numpy(),\n",
    "    ))\n",
    ")).shuffle(100).batch(128,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.24 s, sys: 0 ns, total: 1.24 s\n",
      "Wall time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('none')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2}]') for ca,(q1,q2) in product(range(4),zip(range(0,25,6)[:-1],range(-1,24,6)[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 43.0989 - ca1-[6,11]: 83.0475 - ca1-[12,17]: 291.6851 - ca1-[18,23]: 544.2434 - ca2-[0,5]: 21.1203 - ca2-[6,11]: 92.0716 - ca2-[12,17]: 166.9738 - ca2-[18,23]: 390.6555 - ca3-[0,5]: 10.6479 - ca3-[6,11]: 98.2006 - ca3-[12,17]: 334.2740 - ca3-[18,23]: 542.6176 - ca4-[0,5]: 13.1864 - ca4-[6,11]: 91.2627 - ca4-[12,17]: 267.8139 - ca4-[18,23]: 586.6292 - val_ca1-[0,5]: 13.4188 - val_ca1-[6,11]: 99.0165 - val_ca1-[12,17]: 297.9132 - val_ca1-[18,23]: 600.3541 - val_ca2-[0,5]: 10.0668 - val_ca2-[6,11]: 86.7342 - val_ca2-[12,17]: 275.0313 - val_ca2-[18,23]: 567.4828 - val_ca3-[0,5]: 9.8775 - val_ca3-[6,11]: 85.9923 - val_ca3-[12,17]: 273.7090 - val_ca3-[18,23]: 565.6170 - val_ca4-[0,5]: 11.1145 - val_ca4-[6,11]: 90.8490 - val_ca4-[12,17]: 282.8064 - val_ca4-[18,23]: 578.7250\n",
      "Epoch 2/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 37.2164 - ca1-[6,11]: 81.0151 - ca1-[12,17]: 286.1590 - ca1-[18,23]: 533.0524 - ca2-[0,5]: 17.9977 - ca2-[6,11]: 91.2536 - ca2-[12,17]: 150.4364 - ca2-[18,23]: 381.7532 - ca3-[0,5]: 8.6932 - ca3-[6,11]: 91.8110 - ca3-[12,17]: 313.3496 - ca3-[18,23]: 531.6300 - ca4-[0,5]: 11.2276 - ca4-[6,11]: 85.1214 - ca4-[12,17]: 254.4456 - ca4-[18,23]: 564.1260 - val_ca1-[0,5]: 12.6972 - val_ca1-[6,11]: 96.3792 - val_ca1-[12,17]: 291.9730 - val_ca1-[18,23]: 590.2021 - val_ca2-[0,5]: 9.0097 - val_ca2-[6,11]: 81.7959 - val_ca2-[12,17]: 264.5685 - val_ca2-[18,23]: 550.7545 - val_ca3-[0,5]: 8.8700 - val_ca3-[6,11]: 81.1489 - val_ca3-[12,17]: 263.3486 - val_ca3-[18,23]: 548.9986 - val_ca4-[0,5]: 9.9300 - val_ca4-[6,11]: 85.8566 - val_ca4-[12,17]: 272.3228 - val_ca4-[18,23]: 561.9886\n",
      "Epoch 3/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 40.1265 - ca1-[6,11]: 78.6470 - ca1-[12,17]: 264.2012 - ca1-[18,23]: 502.7475 - ca2-[0,5]: 15.5672 - ca2-[6,11]: 85.5836 - ca2-[12,17]: 149.5174 - ca2-[18,23]: 358.8368 - ca3-[0,5]: 7.4940 - ca3-[6,11]: 81.0152 - ca3-[12,17]: 293.8185 - ca3-[18,23]: 512.1566 - ca4-[0,5]: 9.8568 - ca4-[6,11]: 78.3595 - ca4-[12,17]: 242.9238 - ca4-[18,23]: 553.4080 - val_ca1-[0,5]: 11.7097 - val_ca1-[6,11]: 92.5949 - val_ca1-[12,17]: 284.7545 - val_ca1-[18,23]: 586.6890 - val_ca2-[0,5]: 7.8818 - val_ca2-[6,11]: 76.0873 - val_ca2-[12,17]: 253.2462 - val_ca2-[18,23]: 540.8789 - val_ca3-[0,5]: 7.8234 - val_ca3-[6,11]: 75.7699 - val_ca3-[12,17]: 252.6300 - val_ca3-[18,23]: 539.9767 - val_ca4-[0,5]: 8.6512 - val_ca4-[6,11]: 80.0029 - val_ca4-[12,17]: 260.8742 - val_ca4-[18,23]: 552.0439\n",
      "Epoch 4/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 35.0685 - ca1-[6,11]: 77.8841 - ca1-[12,17]: 275.5023 - ca1-[18,23]: 515.2417 - ca2-[0,5]: 13.6180 - ca2-[6,11]: 79.5403 - ca2-[12,17]: 137.6400 - ca2-[18,23]: 359.1624 - ca3-[0,5]: 6.6336 - ca3-[6,11]: 82.0048 - ca3-[12,17]: 296.8687 - ca3-[18,23]: 502.8080 - ca4-[0,5]: 8.6318 - ca4-[6,11]: 75.5713 - ca4-[12,17]: 233.1227 - ca4-[18,23]: 531.8147 - val_ca1-[0,5]: 11.1672 - val_ca1-[6,11]: 90.3118 - val_ca1-[12,17]: 272.0856 - val_ca1-[18,23]: 579.5375 - val_ca2-[0,5]: 7.2867 - val_ca2-[6,11]: 72.0591 - val_ca2-[12,17]: 237.2559 - val_ca2-[18,23]: 528.1426 - val_ca3-[0,5]: 7.3146 - val_ca3-[6,11]: 72.2406 - val_ca3-[12,17]: 237.6189 - val_ca3-[18,23]: 528.6851 - val_ca4-[0,5]: 7.9016 - val_ca4-[6,11]: 75.7284 - val_ca4-[12,17]: 244.4368 - val_ca4-[18,23]: 538.8281\n",
      "Epoch 5/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 22.7515 - ca1-[6,11]: 72.8601 - ca1-[12,17]: 259.3243 - ca1-[18,23]: 512.4380 - ca2-[0,5]: 11.3235 - ca2-[6,11]: 74.5066 - ca2-[12,17]: 133.5086 - ca2-[18,23]: 337.3301 - ca3-[0,5]: 5.7859 - ca3-[6,11]: 77.0816 - ca3-[12,17]: 288.7920 - ca3-[18,23]: 490.6380 - ca4-[0,5]: 7.7130 - ca4-[6,11]: 69.5601 - ca4-[12,17]: 225.3091 - ca4-[18,23]: 529.8180 - val_ca1-[0,5]: 10.7853 - val_ca1-[6,11]: 89.3391 - val_ca1-[12,17]: 279.1551 - val_ca1-[18,23]: 570.7307 - val_ca2-[0,5]: 6.8638 - val_ca2-[6,11]: 69.4395 - val_ca2-[12,17]: 240.4498 - val_ca2-[18,23]: 514.4589 - val_ca3-[0,5]: 6.9543 - val_ca3-[6,11]: 70.1256 - val_ca3-[12,17]: 241.8414 - val_ca3-[18,23]: 516.5084 - val_ca4-[0,5]: 7.3719 - val_ca4-[6,11]: 72.9847 - val_ca4-[12,17]: 247.5578 - val_ca4-[18,23]: 524.8908\n",
      "Epoch 6/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 35.2509 - ca1-[6,11]: 73.4023 - ca1-[12,17]: 268.1251 - ca1-[18,23]: 481.1075 - ca2-[0,5]: 10.8808 - ca2-[6,11]: 71.0075 - ca2-[12,17]: 124.7106 - ca2-[18,23]: 343.4821 - ca3-[0,5]: 6.3956 - ca3-[6,11]: 75.0721 - ca3-[12,17]: 286.9603 - ca3-[18,23]: 475.2082 - ca4-[0,5]: 7.0471 - ca4-[6,11]: 66.3235 - ca4-[12,17]: 221.3466 - ca4-[18,23]: 517.0650 - val_ca1-[0,5]: 10.1026 - val_ca1-[6,11]: 86.2430 - val_ca1-[12,17]: 274.6019 - val_ca1-[18,23]: 564.6552 - val_ca2-[0,5]: 6.4064 - val_ca2-[6,11]: 65.1575 - val_ca2-[12,17]: 232.9734 - val_ca2-[18,23]: 503.8461 - val_ca3-[0,5]: 6.5224 - val_ca3-[6,11]: 66.2989 - val_ca3-[12,17]: 235.3296 - val_ca3-[18,23]: 507.3355 - val_ca4-[0,5]: 6.7940 - val_ca4-[6,11]: 68.6277 - val_ca4-[12,17]: 240.0744 - val_ca4-[18,23]: 514.3322\n",
      "Epoch 7/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 30.7982 - ca1-[6,11]: 66.3403 - ca1-[12,17]: 243.4023 - ca1-[18,23]: 469.4923 - ca2-[0,5]: 8.3701 - ca2-[6,11]: 67.4386 - ca2-[12,17]: 126.6893 - ca2-[18,23]: 319.8633 - ca3-[0,5]: 5.7259 - ca3-[6,11]: 70.7384 - ca3-[12,17]: 273.2366 - ca3-[18,23]: 469.5315 - ca4-[0,5]: 6.5532 - ca4-[6,11]: 63.5008 - ca4-[12,17]: 212.5545 - ca4-[18,23]: 505.5166 - val_ca1-[0,5]: 9.7947 - val_ca1-[6,11]: 85.5958 - val_ca1-[12,17]: 270.8434 - val_ca1-[18,23]: 559.6376 - val_ca2-[0,5]: 6.1923 - val_ca2-[6,11]: 63.2043 - val_ca2-[12,17]: 226.4936 - val_ca2-[18,23]: 494.5832 - val_ca3-[0,5]: 6.3202 - val_ca3-[6,11]: 64.7978 - val_ca3-[12,17]: 229.8019 - val_ca3-[18,23]: 499.5075 - val_ca4-[0,5]: 6.4983 - val_ca4-[6,11]: 66.6552 - val_ca4-[12,17]: 233.6108 - val_ca4-[18,23]: 505.1535\n",
      "Epoch 8/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 33.6223 - ca1-[6,11]: 69.4473 - ca1-[12,17]: 260.4172 - ca1-[18,23]: 497.9161 - ca2-[0,5]: 8.3571 - ca2-[6,11]: 64.1272 - ca2-[12,17]: 119.4359 - ca2-[18,23]: 323.5898 - ca3-[0,5]: 5.7682 - ca3-[6,11]: 68.2683 - ca3-[12,17]: 270.4698 - ca3-[18,23]: 461.2043 - ca4-[0,5]: 6.2016 - ca4-[6,11]: 59.5305 - ca4-[12,17]: 206.4222 - ca4-[18,23]: 497.9363 - val_ca1-[0,5]: 8.6707 - val_ca1-[6,11]: 82.7097 - val_ca1-[12,17]: 268.8716 - val_ca1-[18,23]: 558.4562 - val_ca2-[0,5]: 5.5431 - val_ca2-[6,11]: 59.4684 - val_ca2-[12,17]: 221.8418 - val_ca2-[18,23]: 489.1991 - val_ca3-[0,5]: 5.6316 - val_ca3-[6,11]: 61.4724 - val_ca3-[12,17]: 226.1124 - val_ca3-[18,23]: 495.5869 - val_ca4-[0,5]: 5.7179 - val_ca4-[6,11]: 62.8832 - val_ca4-[12,17]: 229.0804 - val_ca4-[18,23]: 500.0077\n",
      "Epoch 9/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 31.1197 - ca1-[6,11]: 67.2157 - ca1-[12,17]: 250.8015 - ca1-[18,23]: 486.7451 - ca2-[0,5]: 7.0233 - ca2-[6,11]: 57.9131 - ca2-[12,17]: 112.4544 - ca2-[18,23]: 305.0422 - ca3-[0,5]: 5.5079 - ca3-[6,11]: 66.2376 - ca3-[12,17]: 260.6490 - ca3-[18,23]: 456.6594 - ca4-[0,5]: 6.0096 - ca4-[6,11]: 58.6200 - ca4-[12,17]: 200.3662 - ca4-[18,23]: 486.0612 - val_ca1-[0,5]: 8.9082 - val_ca1-[6,11]: 80.9757 - val_ca1-[12,17]: 264.4647 - val_ca1-[18,23]: 552.3188 - val_ca2-[0,5]: 5.9743 - val_ca2-[6,11]: 56.8303 - val_ca2-[12,17]: 215.1200 - val_ca2-[18,23]: 479.4007 - val_ca3-[0,5]: 6.0291 - val_ca3-[6,11]: 59.2234 - val_ca3-[12,17]: 220.2921 - val_ca3-[18,23]: 487.1718 - val_ca4-[0,5]: 6.0714 - val_ca4-[6,11]: 60.2539 - val_ca4-[12,17]: 222.4887 - val_ca4-[18,23]: 490.4571\n",
      "Epoch 10/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 33.8163 - ca1-[6,11]: 63.2815 - ca1-[12,17]: 248.5764 - ca1-[18,23]: 484.2891 - ca2-[0,5]: 6.1119 - ca2-[6,11]: 58.0973 - ca2-[12,17]: 110.7910 - ca2-[18,23]: 308.7783 - ca3-[0,5]: 5.2662 - ca3-[6,11]: 61.9508 - ca3-[12,17]: 263.3005 - ca3-[18,23]: 448.9929 - ca4-[0,5]: 5.8004 - ca4-[6,11]: 55.1957 - ca4-[12,17]: 194.7598 - ca4-[18,23]: 475.0880 - val_ca1-[0,5]: 8.4242 - val_ca1-[6,11]: 78.8687 - val_ca1-[12,17]: 256.6272 - val_ca1-[18,23]: 549.8238 - val_ca2-[0,5]: 5.8943 - val_ca2-[6,11]: 53.9284 - val_ca2-[12,17]: 205.3974 - val_ca2-[18,23]: 473.0896 - val_ca3-[0,5]: 5.8756 - val_ca3-[6,11]: 56.6781 - val_ca3-[12,17]: 211.3955 - val_ca3-[18,23]: 482.2387 - val_ca4-[0,5]: 5.8840 - val_ca4-[6,11]: 57.3531 - val_ca4-[12,17]: 212.8457 - val_ca4-[18,23]: 484.4391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 33.0484 - ca1-[6,11]: 60.7237 - ca1-[12,17]: 247.1420 - ca1-[18,23]: 474.4625 - ca2-[0,5]: 5.5740 - ca2-[6,11]: 54.2874 - ca2-[12,17]: 107.7027 - ca2-[18,23]: 304.3681 - ca3-[0,5]: 5.3793 - ca3-[6,11]: 59.9927 - ca3-[12,17]: 260.7265 - ca3-[18,23]: 445.1146 - ca4-[0,5]: 5.5387 - ca4-[6,11]: 52.7969 - ca4-[12,17]: 190.4631 - ca4-[18,23]: 467.5062 - val_ca1-[0,5]: 7.9671 - val_ca1-[6,11]: 77.7126 - val_ca1-[12,17]: 254.2737 - val_ca1-[18,23]: 542.6868 - val_ca2-[0,5]: 5.9205 - val_ca2-[6,11]: 51.8808 - val_ca2-[12,17]: 200.7906 - val_ca2-[18,23]: 462.6629 - val_ca3-[0,5]: 5.8007 - val_ca3-[6,11]: 54.9771 - val_ca3-[12,17]: 207.6265 - val_ca3-[18,23]: 473.0879 - val_ca4-[0,5]: 5.7938 - val_ca4-[6,11]: 55.3389 - val_ca4-[12,17]: 208.4109 - val_ca4-[18,23]: 474.2762\n",
      "Epoch 12/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 33.9039 - ca1-[6,11]: 65.4373 - ca1-[12,17]: 248.7814 - ca1-[18,23]: 471.6983 - ca2-[0,5]: 5.7157 - ca2-[6,11]: 50.9176 - ca2-[12,17]: 105.4711 - ca2-[18,23]: 296.7336 - ca3-[0,5]: 5.6168 - ca3-[6,11]: 59.7381 - ca3-[12,17]: 255.0689 - ca3-[18,23]: 433.5551 - ca4-[0,5]: 5.5012 - ca4-[6,11]: 51.0268 - ca4-[12,17]: 187.4673 - ca4-[18,23]: 463.9624 - val_ca1-[0,5]: 7.1520 - val_ca1-[6,11]: 75.9333 - val_ca1-[12,17]: 253.9075 - val_ca1-[18,23]: 523.9700 - val_ca2-[0,5]: 5.7475 - val_ca2-[6,11]: 49.4714 - val_ca2-[12,17]: 198.1342 - val_ca2-[18,23]: 441.7030 - val_ca3-[0,5]: 5.4876 - val_ca3-[6,11]: 52.8565 - val_ca3-[12,17]: 205.7839 - val_ca3-[18,23]: 453.2069 - val_ca4-[0,5]: 5.4827 - val_ca4-[6,11]: 52.9299 - val_ca4-[12,17]: 205.9435 - val_ca4-[18,23]: 453.4431\n",
      "Epoch 13/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 29.9576 - ca1-[6,11]: 55.8180 - ca1-[12,17]: 238.7441 - ca1-[18,23]: 469.2224 - ca2-[0,5]: 4.6519 - ca2-[6,11]: 47.9149 - ca2-[12,17]: 102.7217 - ca2-[18,23]: 289.0440 - ca3-[0,5]: 5.4133 - ca3-[6,11]: 52.3989 - ca3-[12,17]: 246.5443 - ca3-[18,23]: 431.5402 - ca4-[0,5]: 5.5208 - ca4-[6,11]: 48.1239 - ca4-[12,17]: 180.0586 - ca4-[18,23]: 452.5203 - val_ca1-[0,5]: 7.6914 - val_ca1-[6,11]: 74.1308 - val_ca1-[12,17]: 249.9847 - val_ca1-[18,23]: 528.2302 - val_ca2-[0,5]: 6.5378 - val_ca2-[6,11]: 47.0692 - val_ca2-[12,17]: 192.3321 - val_ca2-[18,23]: 441.9799 - val_ca3-[0,5]: 6.1814 - val_ca3-[6,11]: 50.7208 - val_ca3-[12,17]: 200.7165 - val_ca3-[18,23]: 454.7885 - val_ca4-[0,5]: 6.1927 - val_ca4-[6,11]: 50.5444 - val_ca4-[12,17]: 200.3137 - val_ca4-[18,23]: 454.1727\n",
      "Epoch 14/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 27.7555 - ca1-[6,11]: 60.7278 - ca1-[12,17]: 233.9246 - ca1-[18,23]: 474.0819 - ca2-[0,5]: 4.2579 - ca2-[6,11]: 46.3204 - ca2-[12,17]: 99.8596 - ca2-[18,23]: 283.7241 - ca3-[0,5]: 5.2068 - ca3-[6,11]: 53.5345 - ca3-[12,17]: 240.7178 - ca3-[18,23]: 423.8175 - ca4-[0,5]: 5.6918 - ca4-[6,11]: 46.4367 - ca4-[12,17]: 175.3313 - ca4-[18,23]: 447.2828 - val_ca1-[0,5]: 7.2973 - val_ca1-[6,11]: 72.4872 - val_ca1-[12,17]: 248.8432 - val_ca1-[18,23]: 526.4353 - val_ca2-[0,5]: 6.8148 - val_ca2-[6,11]: 44.8927 - val_ca2-[12,17]: 189.0211 - val_ca2-[18,23]: 436.7615 - val_ca3-[0,5]: 6.2855 - val_ca3-[6,11]: 48.7830 - val_ca3-[12,17]: 198.1655 - val_ca3-[18,23]: 450.7724 - val_ca4-[0,5]: 6.3267 - val_ca4-[6,11]: 48.3822 - val_ca4-[12,17]: 197.2347 - val_ca4-[18,23]: 449.3496\n",
      "Epoch 15/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 22.5692 - ca1-[6,11]: 59.1735 - ca1-[12,17]: 223.9132 - ca1-[18,23]: 462.2983 - ca2-[0,5]: 3.8505 - ca2-[6,11]: 40.0703 - ca2-[12,17]: 87.4156 - ca2-[18,23]: 272.5029 - ca3-[0,5]: 5.6086 - ca3-[6,11]: 47.4655 - ca3-[12,17]: 234.5612 - ca3-[18,23]: 401.6931 - ca4-[0,5]: 5.8165 - ca4-[6,11]: 44.4542 - ca4-[12,17]: 173.3299 - ca4-[18,23]: 443.3504 - val_ca1-[0,5]: 7.1316 - val_ca1-[6,11]: 71.4187 - val_ca1-[12,17]: 243.6499 - val_ca1-[18,23]: 521.2422 - val_ca2-[0,5]: 7.2618 - val_ca2-[6,11]: 43.1297 - val_ca2-[12,17]: 182.2450 - val_ca2-[18,23]: 428.5875 - val_ca3-[0,5]: 6.5565 - val_ca3-[6,11]: 47.2658 - val_ca3-[12,17]: 192.0232 - val_ca3-[18,23]: 443.6895 - val_ca4-[0,5]: 6.6383 - val_ca4-[6,11]: 46.6619 - val_ca4-[12,17]: 190.6161 - val_ca4-[18,23]: 441.5235\n",
      "Epoch 16/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 23.5647 - ca1-[6,11]: 57.7671 - ca1-[12,17]: 230.6326 - ca1-[18,23]: 460.2252 - ca2-[0,5]: 3.3712 - ca2-[6,11]: 41.4780 - ca2-[12,17]: 87.2316 - ca2-[18,23]: 261.7054 - ca3-[0,5]: 6.3934 - ca3-[6,11]: 48.6715 - ca3-[12,17]: 230.1735 - ca3-[18,23]: 416.9617 - ca4-[0,5]: 6.0659 - ca4-[6,11]: 41.5086 - ca4-[12,17]: 168.3801 - ca4-[18,23]: 426.2557 - val_ca1-[0,5]: 6.8120 - val_ca1-[6,11]: 68.4680 - val_ca1-[12,17]: 239.7173 - val_ca1-[18,23]: 518.9337 - val_ca2-[0,5]: 7.7162 - val_ca2-[6,11]: 40.1732 - val_ca2-[12,17]: 176.7285 - val_ca2-[18,23]: 423.0467 - val_ca3-[0,5]: 6.7944 - val_ca3-[6,11]: 44.4281 - val_ca3-[12,17]: 187.1345 - val_ca3-[18,23]: 439.2853 - val_ca4-[0,5]: 6.9315 - val_ca4-[6,11]: 43.6563 - val_ca4-[12,17]: 185.2792 - val_ca4-[18,23]: 436.4013\n",
      "Epoch 17/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 27.3178 - ca1-[6,11]: 58.7686 - ca1-[12,17]: 229.2361 - ca1-[18,23]: 458.4713 - ca2-[0,5]: 3.3051 - ca2-[6,11]: 38.3930 - ca2-[12,17]: 87.8816 - ca2-[18,23]: 264.7798 - ca3-[0,5]: 6.6437 - ca3-[6,11]: 46.5021 - ca3-[12,17]: 226.3320 - ca3-[18,23]: 407.4892 - ca4-[0,5]: 6.3719 - ca4-[6,11]: 39.8040 - ca4-[12,17]: 159.8851 - ca4-[18,23]: 424.6407 - val_ca1-[0,5]: 6.6595 - val_ca1-[6,11]: 68.3960 - val_ca1-[12,17]: 238.0396 - val_ca1-[18,23]: 513.8564 - val_ca2-[0,5]: 8.2262 - val_ca2-[6,11]: 39.3079 - val_ca2-[12,17]: 173.1564 - val_ca2-[18,23]: 415.1208 - val_ca3-[0,5]: 7.0957 - val_ca3-[6,11]: 43.8072 - val_ca3-[12,17]: 184.2299 - val_ca3-[18,23]: 432.4116 - val_ca4-[0,5]: 7.2938 - val_ca4-[6,11]: 42.8610 - val_ca4-[12,17]: 181.9441 - val_ca4-[18,23]: 428.8577\n",
      "Epoch 18/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 26.6885 - ca1-[6,11]: 55.5136 - ca1-[12,17]: 227.5487 - ca1-[18,23]: 448.8669 - ca2-[0,5]: 3.0473 - ca2-[6,11]: 36.0223 - ca2-[12,17]: 87.8608 - ca2-[18,23]: 258.5841 - ca3-[0,5]: 6.8096 - ca3-[6,11]: 45.5678 - ca3-[12,17]: 209.8801 - ca3-[18,23]: 402.3165 - ca4-[0,5]: 6.7293 - ca4-[6,11]: 38.5433 - ca4-[12,17]: 155.9812 - ca4-[18,23]: 417.9141 - val_ca1-[0,5]: 6.2878 - val_ca1-[6,11]: 65.7860 - val_ca1-[12,17]: 234.6388 - val_ca1-[18,23]: 507.4270 - val_ca2-[0,5]: 8.7655 - val_ca2-[6,11]: 36.7330 - val_ca2-[12,17]: 168.1927 - val_ca2-[18,23]: 406.0637 - val_ca3-[0,5]: 7.3692 - val_ca3-[6,11]: 41.3130 - val_ca3-[12,17]: 179.8605 - val_ca3-[18,23]: 424.3500 - val_ca4-[0,5]: 7.6414 - val_ca4-[6,11]: 40.2557 - val_ca4-[12,17]: 177.2233 - val_ca4-[18,23]: 420.2365\n",
      "Epoch 19/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 24.7484 - ca1-[6,11]: 55.2332 - ca1-[12,17]: 220.2456 - ca1-[18,23]: 426.6037 - ca2-[0,5]: 3.0484 - ca2-[6,11]: 32.3323 - ca2-[12,17]: 78.4423 - ca2-[18,23]: 251.2920 - ca3-[0,5]: 7.3233 - ca3-[6,11]: 41.4853 - ca3-[12,17]: 221.6667 - ca3-[18,23]: 389.9855 - ca4-[0,5]: 7.1376 - ca4-[6,11]: 36.5902 - ca4-[12,17]: 156.0567 - ca4-[18,23]: 412.9138 - val_ca1-[0,5]: 6.3263 - val_ca1-[6,11]: 65.3249 - val_ca1-[12,17]: 232.7968 - val_ca1-[18,23]: 501.3167 - val_ca2-[0,5]: 9.5223 - val_ca2-[6,11]: 35.6943 - val_ca2-[12,17]: 164.5533 - val_ca2-[18,23]: 397.4087 - val_ca3-[0,5]: 7.8854 - val_ca3-[6,11]: 40.4581 - val_ca3-[12,17]: 176.8462 - val_ca3-[18,23]: 416.6559 - val_ca4-[0,5]: 8.2289 - val_ca4-[6,11]: 39.2812 - val_ca4-[12,17]: 173.8778 - val_ca4-[18,23]: 412.0319\n",
      "Epoch 20/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 26.8614 - ca1-[6,11]: 50.1613 - ca1-[12,17]: 220.3366 - ca1-[18,23]: 423.9233 - ca2-[0,5]: 3.1345 - ca2-[6,11]: 32.1105 - ca2-[12,17]: 74.2913 - ca2-[18,23]: 246.7990 - ca3-[0,5]: 7.4667 - ca3-[6,11]: 41.7383 - ca3-[12,17]: 213.2536 - ca3-[18,23]: 388.6732 - ca4-[0,5]: 7.6650 - ca4-[6,11]: 34.7222 - ca4-[12,17]: 151.6892 - ca4-[18,23]: 402.9600 - val_ca1-[0,5]: 6.2062 - val_ca1-[6,11]: 63.7570 - val_ca1-[12,17]: 231.8804 - val_ca1-[18,23]: 496.7683 - val_ca2-[0,5]: 10.2067 - val_ca2-[6,11]: 33.9543 - val_ca2-[12,17]: 161.7544 - val_ca2-[18,23]: 390.1711 - val_ca3-[0,5]: 8.3049 - val_ca3-[6,11]: 38.8092 - val_ca3-[12,17]: 174.6693 - val_ca3-[18,23]: 410.3760 - val_ca4-[0,5]: 8.7275 - val_ca4-[6,11]: 37.5440 - val_ca4-[12,17]: 171.3881 - val_ca4-[18,23]: 405.2705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 27.4843 - ca1-[6,11]: 52.3032 - ca1-[12,17]: 214.5078 - ca1-[18,23]: 428.1993 - ca2-[0,5]: 3.0784 - ca2-[6,11]: 29.2834 - ca2-[12,17]: 74.2256 - ca2-[18,23]: 233.8292 - ca3-[0,5]: 8.5607 - ca3-[6,11]: 41.4387 - ca3-[12,17]: 208.0124 - ca3-[18,23]: 378.9024 - ca4-[0,5]: 8.1056 - ca4-[6,11]: 33.2463 - ca4-[12,17]: 144.4906 - ca4-[18,23]: 397.1342 - val_ca1-[0,5]: 6.1075 - val_ca1-[6,11]: 61.4616 - val_ca1-[12,17]: 225.7126 - val_ca1-[18,23]: 485.6451 - val_ca2-[0,5]: 11.1284 - val_ca2-[6,11]: 31.8471 - val_ca2-[12,17]: 154.8112 - val_ca2-[18,23]: 377.1268 - val_ca3-[0,5]: 8.9092 - val_ca3-[6,11]: 36.7083 - val_ca3-[12,17]: 168.1125 - val_ca3-[18,23]: 398.1180 - val_ca4-[0,5]: 9.4298 - val_ca4-[6,11]: 35.3765 - val_ca4-[12,17]: 164.5700 - val_ca4-[18,23]: 392.5605\n",
      "Epoch 22/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 20.5310 - ca1-[6,11]: 52.9130 - ca1-[12,17]: 211.7836 - ca1-[18,23]: 426.0845 - ca2-[0,5]: 2.7804 - ca2-[6,11]: 26.9821 - ca2-[12,17]: 69.6997 - ca2-[18,23]: 227.6430 - ca3-[0,5]: 8.7285 - ca3-[6,11]: 39.7176 - ca3-[12,17]: 202.7958 - ca3-[18,23]: 375.4317 - ca4-[0,5]: 8.7018 - ca4-[6,11]: 31.3953 - ca4-[12,17]: 142.4021 - ca4-[18,23]: 392.4753 - val_ca1-[0,5]: 6.0199 - val_ca1-[6,11]: 60.6108 - val_ca1-[12,17]: 222.2407 - val_ca1-[18,23]: 483.9835 - val_ca2-[0,5]: 12.0787 - val_ca2-[6,11]: 30.6885 - val_ca2-[12,17]: 150.0289 - val_ca2-[18,23]: 372.8162 - val_ca3-[0,5]: 9.5241 - val_ca3-[6,11]: 35.6539 - val_ca3-[12,17]: 163.8331 - val_ca3-[18,23]: 394.7623 - val_ca4-[0,5]: 10.1498 - val_ca4-[6,11]: 34.2371 - val_ca4-[12,17]: 160.0130 - val_ca4-[18,23]: 388.7276\n",
      "Epoch 23/300\n",
      "26/26 [==============================] - 3s 112ms/step - ca1-[0,5]: 23.7082 - ca1-[6,11]: 48.1895 - ca1-[12,17]: 210.6029 - ca1-[18,23]: 428.6257 - ca2-[0,5]: 3.3842 - ca2-[6,11]: 25.7192 - ca2-[12,17]: 71.3717 - ca2-[18,23]: 223.8048 - ca3-[0,5]: 9.3828 - ca3-[6,11]: 37.8016 - ca3-[12,17]: 202.5486 - ca3-[18,23]: 368.1301 - ca4-[0,5]: 9.3747 - ca4-[6,11]: 30.2425 - ca4-[12,17]: 135.9920 - ca4-[18,23]: 387.2957 - val_ca1-[0,5]: 5.9676 - val_ca1-[6,11]: 58.5104 - val_ca1-[12,17]: 218.4416 - val_ca1-[18,23]: 482.7282 - val_ca2-[0,5]: 13.0151 - val_ca2-[6,11]: 28.7690 - val_ca2-[12,17]: 145.0777 - val_ca2-[18,23]: 368.6040 - val_ca3-[0,5]: 10.1262 - val_ca3-[6,11]: 33.7245 - val_ca3-[12,17]: 159.3347 - val_ca3-[18,23]: 391.5522 - val_ca4-[0,5]: 10.8559 - val_ca4-[6,11]: 32.2657 - val_ca4-[12,17]: 155.2786 - val_ca4-[18,23]: 385.0684\n",
      "Epoch 24/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 22.0165 - ca1-[6,11]: 49.0178 - ca1-[12,17]: 202.2647 - ca1-[18,23]: 408.8124 - ca2-[0,5]: 3.6379 - ca2-[6,11]: 23.7281 - ca2-[12,17]: 62.7765 - ca2-[18,23]: 217.7933 - ca3-[0,5]: 10.0733 - ca3-[6,11]: 37.8451 - ca3-[12,17]: 201.0771 - ca3-[18,23]: 363.4523 - ca4-[0,5]: 10.1667 - ca4-[6,11]: 30.0896 - ca4-[12,17]: 134.5058 - ca4-[18,23]: 377.8021 - val_ca1-[0,5]: 5.8940 - val_ca1-[6,11]: 57.1891 - val_ca1-[12,17]: 210.3374 - val_ca1-[18,23]: 478.6785 - val_ca2-[0,5]: 13.9017 - val_ca2-[6,11]: 27.4091 - val_ca2-[12,17]: 136.3819 - val_ca2-[18,23]: 362.1484 - val_ca3-[0,5]: 10.6794 - val_ca3-[6,11]: 32.3855 - val_ca3-[12,17]: 150.9432 - val_ca3-[18,23]: 385.9472 - val_ca4-[0,5]: 11.5155 - val_ca4-[6,11]: 30.8788 - val_ca4-[12,17]: 146.6953 - val_ca4-[18,23]: 379.0567\n",
      "Epoch 25/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 14.4535 - ca1-[6,11]: 50.2377 - ca1-[12,17]: 205.2353 - ca1-[18,23]: 420.8338 - ca2-[0,5]: 3.9598 - ca2-[6,11]: 22.1246 - ca2-[12,17]: 61.8599 - ca2-[18,23]: 217.6133 - ca3-[0,5]: 10.9494 - ca3-[6,11]: 35.4141 - ca3-[12,17]: 193.4395 - ca3-[18,23]: 344.3582 - ca4-[0,5]: 10.8950 - ca4-[6,11]: 27.9301 - ca4-[12,17]: 130.6535 - ca4-[18,23]: 371.5574 - val_ca1-[0,5]: 5.9221 - val_ca1-[6,11]: 55.6181 - val_ca1-[12,17]: 211.9437 - val_ca1-[18,23]: 473.3462 - val_ca2-[0,5]: 15.0350 - val_ca2-[6,11]: 25.9002 - val_ca2-[12,17]: 136.2702 - val_ca2-[18,23]: 354.5457 - val_ca3-[0,5]: 11.4359 - val_ca3-[6,11]: 30.8706 - val_ca3-[12,17]: 151.3827 - val_ca3-[18,23]: 379.1760 - val_ca4-[0,5]: 12.3842 - val_ca4-[6,11]: 29.3391 - val_ca4-[12,17]: 146.9142 - val_ca4-[18,23]: 371.9506\n",
      "Epoch 26/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 20.9974 - ca1-[6,11]: 46.4378 - ca1-[12,17]: 201.6414 - ca1-[18,23]: 421.6257 - ca2-[0,5]: 3.7083 - ca2-[6,11]: 20.1488 - ca2-[12,17]: 59.1597 - ca2-[18,23]: 214.9989 - ca3-[0,5]: 11.6474 - ca3-[6,11]: 33.5659 - ca3-[12,17]: 187.3395 - ca3-[18,23]: 333.0908 - ca4-[0,5]: 11.7455 - ca4-[6,11]: 25.9169 - ca4-[12,17]: 127.4698 - ca4-[18,23]: 361.0325 - val_ca1-[0,5]: 5.9404 - val_ca1-[6,11]: 55.1015 - val_ca1-[12,17]: 210.7082 - val_ca1-[18,23]: 474.7905 - val_ca2-[0,5]: 16.2620 - val_ca2-[6,11]: 25.3500 - val_ca2-[12,17]: 133.6061 - val_ca2-[18,23]: 352.9044 - val_ca3-[0,5]: 12.2542 - val_ca3-[6,11]: 30.3283 - val_ca3-[12,17]: 149.2027 - val_ca3-[18,23]: 378.5436 - val_ca4-[0,5]: 13.3212 - val_ca4-[6,11]: 28.7747 - val_ca4-[12,17]: 144.5504 - val_ca4-[18,23]: 370.9600\n",
      "Epoch 27/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 21.5083 - ca1-[6,11]: 45.6140 - ca1-[12,17]: 196.0896 - ca1-[18,23]: 413.2843 - ca2-[0,5]: 4.8030 - ca2-[6,11]: 18.3663 - ca2-[12,17]: 59.2910 - ca2-[18,23]: 208.7777 - ca3-[0,5]: 12.6566 - ca3-[6,11]: 32.8275 - ca3-[12,17]: 185.5568 - ca3-[18,23]: 345.6002 - ca4-[0,5]: 12.5150 - ca4-[6,11]: 24.7271 - ca4-[12,17]: 124.7650 - ca4-[18,23]: 359.6696 - val_ca1-[0,5]: 5.8164 - val_ca1-[6,11]: 52.9301 - val_ca1-[12,17]: 207.4537 - val_ca1-[18,23]: 464.6313 - val_ca2-[0,5]: 17.4247 - val_ca2-[6,11]: 23.5335 - val_ca2-[12,17]: 129.3798 - val_ca2-[18,23]: 341.4638 - val_ca3-[0,5]: 12.9844 - val_ca3-[6,11]: 28.4270 - val_ca3-[12,17]: 145.3536 - val_ca3-[18,23]: 367.7022 - val_ca4-[0,5]: 14.1794 - val_ca4-[6,11]: 26.8775 - val_ca4-[12,17]: 140.5442 - val_ca4-[18,23]: 359.8721\n",
      "Epoch 28/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 20.9308 - ca1-[6,11]: 43.3279 - ca1-[12,17]: 195.2578 - ca1-[18,23]: 403.6740 - ca2-[0,5]: 5.3197 - ca2-[6,11]: 17.2844 - ca2-[12,17]: 53.7512 - ca2-[18,23]: 204.5505 - ca3-[0,5]: 13.6711 - ca3-[6,11]: 28.4396 - ca3-[12,17]: 176.7211 - ca3-[18,23]: 339.1752 - ca4-[0,5]: 13.3861 - ca4-[6,11]: 24.1903 - ca4-[12,17]: 118.8881 - ca4-[18,23]: 353.2552 - val_ca1-[0,5]: 6.1132 - val_ca1-[6,11]: 51.2788 - val_ca1-[12,17]: 199.5712 - val_ca1-[18,23]: 460.4966 - val_ca2-[0,5]: 18.8683 - val_ca2-[6,11]: 22.7748 - val_ca2-[12,17]: 122.3799 - val_ca2-[18,23]: 336.6435 - val_ca3-[0,5]: 14.0086 - val_ca3-[6,11]: 27.5696 - val_ca3-[12,17]: 138.5674 - val_ca3-[18,23]: 363.7499 - val_ca4-[0,5]: 15.3263 - val_ca4-[6,11]: 26.0313 - val_ca4-[12,17]: 133.6571 - val_ca4-[18,23]: 355.6071\n",
      "Epoch 29/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 19.7181 - ca1-[6,11]: 40.3006 - ca1-[12,17]: 189.0246 - ca1-[18,23]: 379.6908 - ca2-[0,5]: 5.8873 - ca2-[6,11]: 15.9394 - ca2-[12,17]: 53.2523 - ca2-[18,23]: 192.3217 - ca3-[0,5]: 14.2696 - ca3-[6,11]: 29.5426 - ca3-[12,17]: 177.8251 - ca3-[18,23]: 333.0037 - ca4-[0,5]: 14.4640 - ca4-[6,11]: 23.6611 - ca4-[12,17]: 115.9863 - ca4-[18,23]: 341.6260 - val_ca1-[0,5]: 6.1338 - val_ca1-[6,11]: 48.1076 - val_ca1-[12,17]: 191.1032 - val_ca1-[18,23]: 444.0060 - val_ca2-[0,5]: 20.1383 - val_ca2-[6,11]: 21.8455 - val_ca2-[12,17]: 118.2921 - val_ca2-[18,23]: 326.7188 - val_ca3-[0,5]: 14.7810 - val_ca3-[6,11]: 26.6289 - val_ca3-[12,17]: 134.7982 - val_ca3-[18,23]: 354.4255 - val_ca4-[0,5]: 16.2333 - val_ca4-[6,11]: 25.0884 - val_ca4-[12,17]: 129.7961 - val_ca4-[18,23]: 346.1153\n",
      "Epoch 30/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 18.8585 - ca1-[6,11]: 37.6830 - ca1-[12,17]: 178.2893 - ca1-[18,23]: 383.1972 - ca2-[0,5]: 6.1330 - ca2-[6,11]: 14.4223 - ca2-[12,17]: 46.9835 - ca2-[18,23]: 188.9667 - ca3-[0,5]: 15.0614 - ca3-[6,11]: 28.1460 - ca3-[12,17]: 176.7982 - ca3-[18,23]: 321.6963 - ca4-[0,5]: 15.5550 - ca4-[6,11]: 22.0746 - ca4-[12,17]: 112.7154 - ca4-[18,23]: 339.2375 - val_ca1-[0,5]: 6.6935 - val_ca1-[6,11]: 45.4724 - val_ca1-[12,17]: 189.9709 - val_ca1-[18,23]: 432.4752 - val_ca2-[0,5]: 21.5739 - val_ca2-[6,11]: 20.9170 - val_ca2-[12,17]: 118.6411 - val_ca2-[18,23]: 318.4886 - val_ca3-[0,5]: 15.8011 - val_ca3-[6,11]: 25.5757 - val_ca3-[12,17]: 135.6724 - val_ca3-[18,23]: 346.8032 - val_ca4-[0,5]: 17.3595 - val_ca4-[6,11]: 24.0695 - val_ca4-[12,17]: 130.5294 - val_ca4-[18,23]: 338.3430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/300\n",
      "26/26 [==============================] - 3s 106ms/step - ca1-[0,5]: 16.9109 - ca1-[6,11]: 38.9739 - ca1-[12,17]: 174.8686 - ca1-[18,23]: 379.0680 - ca2-[0,5]: 7.2470 - ca2-[6,11]: 12.8644 - ca2-[12,17]: 48.7760 - ca2-[18,23]: 188.8693 - ca3-[0,5]: 16.3224 - ca3-[6,11]: 26.8150 - ca3-[12,17]: 162.2774 - ca3-[18,23]: 323.8142 - ca4-[0,5]: 16.5452 - ca4-[6,11]: 21.0198 - ca4-[12,17]: 107.6127 - ca4-[18,23]: 334.1793 - val_ca1-[0,5]: 7.0922 - val_ca1-[6,11]: 43.5930 - val_ca1-[12,17]: 184.7825 - val_ca1-[18,23]: 428.1198 - val_ca2-[0,5]: 23.1530 - val_ca2-[6,11]: 20.1723 - val_ca2-[12,17]: 114.8135 - val_ca2-[18,23]: 315.1811 - val_ca3-[0,5]: 16.8780 - val_ca3-[6,11]: 24.7278 - val_ca3-[12,17]: 132.1381 - val_ca3-[18,23]: 344.2930 - val_ca4-[0,5]: 18.5639 - val_ca4-[6,11]: 23.2509 - val_ca4-[12,17]: 126.9305 - val_ca4-[18,23]: 335.6412\n",
      "Epoch 32/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 17.9099 - ca1-[6,11]: 34.2800 - ca1-[12,17]: 169.8181 - ca1-[18,23]: 377.9674 - ca2-[0,5]: 8.0617 - ca2-[6,11]: 12.3243 - ca2-[12,17]: 46.2366 - ca2-[18,23]: 184.3181 - ca3-[0,5]: 17.7432 - ca3-[6,11]: 26.1274 - ca3-[12,17]: 158.5456 - ca3-[18,23]: 315.7767 - ca4-[0,5]: 17.5460 - ca4-[6,11]: 21.0757 - ca4-[12,17]: 105.0667 - ca4-[18,23]: 329.2902 - val_ca1-[0,5]: 7.3927 - val_ca1-[6,11]: 41.1466 - val_ca1-[12,17]: 176.2748 - val_ca1-[18,23]: 422.3591 - val_ca2-[0,5]: 24.5505 - val_ca2-[6,11]: 19.0790 - val_ca2-[12,17]: 107.8589 - val_ca2-[18,23]: 310.0721 - val_ca3-[0,5]: 17.7815 - val_ca3-[6,11]: 23.4080 - val_ca3-[12,17]: 125.3012 - val_ca3-[18,23]: 339.9268 - val_ca4-[0,5]: 19.5909 - val_ca4-[6,11]: 21.9948 - val_ca4-[12,17]: 120.0784 - val_ca4-[18,23]: 331.0974\n",
      "Epoch 33/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 15.5853 - ca1-[6,11]: 36.7951 - ca1-[12,17]: 169.1536 - ca1-[18,23]: 356.5801 - ca2-[0,5]: 8.9085 - ca2-[6,11]: 10.2734 - ca2-[12,17]: 43.2303 - ca2-[18,23]: 171.6549 - ca3-[0,5]: 18.4528 - ca3-[6,11]: 25.2127 - ca3-[12,17]: 157.3458 - ca3-[18,23]: 315.1526 - ca4-[0,5]: 18.8182 - ca4-[6,11]: 19.7228 - ca4-[12,17]: 104.3263 - ca4-[18,23]: 320.3073 - val_ca1-[0,5]: 7.7389 - val_ca1-[6,11]: 40.1385 - val_ca1-[12,17]: 175.2110 - val_ca1-[18,23]: 419.4839 - val_ca2-[0,5]: 26.2523 - val_ca2-[6,11]: 18.6074 - val_ca2-[12,17]: 107.0590 - val_ca2-[18,23]: 307.0442 - val_ca3-[0,5]: 18.9082 - val_ca3-[6,11]: 22.8964 - val_ca3-[12,17]: 124.8915 - val_ca3-[18,23]: 337.7424 - val_ca4-[0,5]: 20.8476 - val_ca4-[6,11]: 21.5024 - val_ca4-[12,17]: 119.6150 - val_ca4-[18,23]: 328.7772\n",
      "Epoch 34/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 15.0089 - ca1-[6,11]: 35.4710 - ca1-[12,17]: 162.7735 - ca1-[18,23]: 345.9448 - ca2-[0,5]: 9.8185 - ca2-[6,11]: 9.6328 - ca2-[12,17]: 41.0668 - ca2-[18,23]: 174.2259 - ca3-[0,5]: 19.6860 - ca3-[6,11]: 22.7009 - ca3-[12,17]: 154.8550 - ca3-[18,23]: 305.5313 - ca4-[0,5]: 19.8881 - ca4-[6,11]: 19.0826 - ca4-[12,17]: 98.7256 - ca4-[18,23]: 317.7150 - val_ca1-[0,5]: 8.4722 - val_ca1-[6,11]: 38.0641 - val_ca1-[12,17]: 170.8292 - val_ca1-[18,23]: 409.0462 - val_ca2-[0,5]: 28.0252 - val_ca2-[6,11]: 17.7126 - val_ca2-[12,17]: 103.2699 - val_ca2-[18,23]: 297.4919 - val_ca3-[0,5]: 20.1943 - val_ca3-[6,11]: 21.7398 - val_ca3-[12,17]: 121.3255 - val_ca3-[18,23]: 328.6213 - val_ca4-[0,5]: 22.2415 - val_ca4-[6,11]: 20.4235 - val_ca4-[12,17]: 116.0284 - val_ca4-[18,23]: 319.6138\n",
      "Epoch 35/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 13.0245 - ca1-[6,11]: 33.8965 - ca1-[12,17]: 155.2389 - ca1-[18,23]: 353.6617 - ca2-[0,5]: 10.2261 - ca2-[6,11]: 8.1246 - ca2-[12,17]: 39.6735 - ca2-[18,23]: 166.9168 - ca3-[0,5]: 20.9471 - ca3-[6,11]: 23.4836 - ca3-[12,17]: 153.3373 - ca3-[18,23]: 292.1546 - ca4-[0,5]: 21.3577 - ca4-[6,11]: 18.6751 - ca4-[12,17]: 98.3032 - ca4-[18,23]: 311.6377 - val_ca1-[0,5]: 8.9351 - val_ca1-[6,11]: 36.8637 - val_ca1-[12,17]: 166.7777 - val_ca1-[18,23]: 404.6655 - val_ca2-[0,5]: 29.8936 - val_ca2-[6,11]: 17.3325 - val_ca2-[12,17]: 99.8109 - val_ca2-[18,23]: 293.0067 - val_ca3-[0,5]: 21.4480 - val_ca3-[6,11]: 21.1826 - val_ca3-[12,17]: 118.0660 - val_ca3-[18,23]: 324.8337 - val_ca4-[0,5]: 23.6352 - val_ca4-[6,11]: 19.9181 - val_ca4-[12,17]: 112.7561 - val_ca4-[18,23]: 315.7117\n",
      "Epoch 36/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 13.9733 - ca1-[6,11]: 29.5133 - ca1-[12,17]: 151.8255 - ca1-[18,23]: 343.0361 - ca2-[0,5]: 11.7043 - ca2-[6,11]: 7.2381 - ca2-[12,17]: 36.1978 - ca2-[18,23]: 165.3027 - ca3-[0,5]: 22.3260 - ca3-[6,11]: 22.6114 - ca3-[12,17]: 153.3692 - ca3-[18,23]: 297.1340 - ca4-[0,5]: 22.6044 - ca4-[6,11]: 17.4993 - ca4-[12,17]: 95.2549 - ca4-[18,23]: 306.3245 - val_ca1-[0,5]: 9.4999 - val_ca1-[6,11]: 35.3907 - val_ca1-[12,17]: 163.7021 - val_ca1-[18,23]: 397.4261 - val_ca2-[0,5]: 31.5658 - val_ca2-[6,11]: 16.7585 - val_ca2-[12,17]: 97.0045 - val_ca2-[18,23]: 285.9555 - val_ca3-[0,5]: 22.5903 - val_ca3-[6,11]: 20.3825 - val_ca3-[12,17]: 115.5087 - val_ca3-[18,23]: 318.3207 - val_ca4-[0,5]: 24.8706 - val_ca4-[6,11]: 19.1919 - val_ca4-[12,17]: 110.2174 - val_ca4-[18,23]: 309.2091\n",
      "Epoch 37/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 10.8894 - ca1-[6,11]: 30.6858 - ca1-[12,17]: 149.1368 - ca1-[18,23]: 308.2782 - ca2-[0,5]: 13.5563 - ca2-[6,11]: 6.5615 - ca2-[12,17]: 34.9578 - ca2-[18,23]: 155.5326 - ca3-[0,5]: 23.6737 - ca3-[6,11]: 21.6147 - ca3-[12,17]: 146.8101 - ca3-[18,23]: 286.7356 - ca4-[0,5]: 24.0765 - ca4-[6,11]: 17.0887 - ca4-[12,17]: 92.0827 - ca4-[18,23]: 300.4213 - val_ca1-[0,5]: 10.1025 - val_ca1-[6,11]: 33.7633 - val_ca1-[12,17]: 159.1232 - val_ca1-[18,23]: 395.2936 - val_ca2-[0,5]: 33.6565 - val_ca2-[6,11]: 16.1809 - val_ca2-[12,17]: 93.0225 - val_ca2-[18,23]: 283.1671 - val_ca3-[0,5]: 24.0247 - val_ca3-[6,11]: 19.5108 - val_ca3-[12,17]: 111.6403 - val_ca3-[18,23]: 316.2873 - val_ca4-[0,5]: 26.4278 - val_ca4-[6,11]: 18.4096 - val_ca4-[12,17]: 106.4043 - val_ca4-[18,23]: 307.1287\n",
      "Epoch 38/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 13.0607 - ca1-[6,11]: 31.2623 - ca1-[12,17]: 145.4813 - ca1-[18,23]: 336.7106 - ca2-[0,5]: 14.1083 - ca2-[6,11]: 5.7291 - ca2-[12,17]: 32.1487 - ca2-[18,23]: 157.4444 - ca3-[0,5]: 24.8895 - ca3-[6,11]: 21.5218 - ca3-[12,17]: 146.2440 - ca3-[18,23]: 284.6363 - ca4-[0,5]: 25.1840 - ca4-[6,11]: 16.3220 - ca4-[12,17]: 89.0416 - ca4-[18,23]: 296.0674 - val_ca1-[0,5]: 10.6287 - val_ca1-[6,11]: 32.7656 - val_ca1-[12,17]: 156.2570 - val_ca1-[18,23]: 388.4623 - val_ca2-[0,5]: 35.1306 - val_ca2-[6,11]: 15.8361 - val_ca2-[12,17]: 90.4019 - val_ca2-[18,23]: 276.3220 - val_ca3-[0,5]: 25.0024 - val_ca3-[6,11]: 18.9816 - val_ca3-[12,17]: 109.2221 - val_ca3-[18,23]: 309.9710 - val_ca4-[0,5]: 27.4716 - val_ca4-[6,11]: 17.9405 - val_ca4-[12,17]: 104.0343 - val_ca4-[18,23]: 300.8597\n",
      "Epoch 39/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 12.6435 - ca1-[6,11]: 26.6701 - ca1-[12,17]: 140.9976 - ca1-[18,23]: 326.8968 - ca2-[0,5]: 15.3411 - ca2-[6,11]: 5.0137 - ca2-[12,17]: 28.8280 - ca2-[18,23]: 152.4943 - ca3-[0,5]: 26.3506 - ca3-[6,11]: 20.2511 - ca3-[12,17]: 136.9563 - ca3-[18,23]: 282.0302 - ca4-[0,5]: 26.7064 - ca4-[6,11]: 16.5118 - ca4-[12,17]: 85.9114 - ca4-[18,23]: 290.8906 - val_ca1-[0,5]: 11.3828 - val_ca1-[6,11]: 31.4062 - val_ca1-[12,17]: 151.2600 - val_ca1-[18,23]: 381.3320 - val_ca2-[0,5]: 37.4379 - val_ca2-[6,11]: 15.4301 - val_ca2-[12,17]: 85.7919 - val_ca2-[18,23]: 269.3379 - val_ca3-[0,5]: 26.6130 - val_ca3-[6,11]: 18.2786 - val_ca3-[12,17]: 104.7409 - val_ca3-[18,23]: 303.4225 - val_ca4-[0,5]: 29.1961 - val_ca4-[6,11]: 17.3241 - val_ca4-[12,17]: 99.6195 - val_ca4-[18,23]: 294.3833\n",
      "Epoch 40/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 11.1300 - ca1-[6,11]: 26.2463 - ca1-[12,17]: 139.3686 - ca1-[18,23]: 306.9655 - ca2-[0,5]: 17.3370 - ca2-[6,11]: 4.0907 - ca2-[12,17]: 28.4121 - ca2-[18,23]: 146.8379 - ca3-[0,5]: 27.7397 - ca3-[6,11]: 18.7196 - ca3-[12,17]: 135.8066 - ca3-[18,23]: 273.0072 - ca4-[0,5]: 28.2432 - ca4-[6,11]: 15.7368 - ca4-[12,17]: 83.6400 - ca4-[18,23]: 285.4573 - val_ca1-[0,5]: 12.0445 - val_ca1-[6,11]: 30.4638 - val_ca1-[12,17]: 149.3613 - val_ca1-[18,23]: 375.9936 - val_ca2-[0,5]: 39.3719 - val_ca2-[6,11]: 15.2750 - val_ca2-[12,17]: 84.1344 - val_ca2-[18,23]: 263.7438 - val_ca3-[0,5]: 27.9380 - val_ca3-[6,11]: 17.8644 - val_ca3-[12,17]: 103.2282 - val_ca3-[18,23]: 298.3474 - val_ca4-[0,5]: 30.6080 - val_ca4-[6,11]: 16.9831 - val_ca4-[12,17]: 98.1658 - val_ca4-[18,23]: 289.3553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 11.8804 - ca1-[6,11]: 27.8259 - ca1-[12,17]: 137.1173 - ca1-[18,23]: 319.7450 - ca2-[0,5]: 17.9962 - ca2-[6,11]: 3.5445 - ca2-[12,17]: 28.6746 - ca2-[18,23]: 143.4741 - ca3-[0,5]: 29.3443 - ca3-[6,11]: 17.8439 - ca3-[12,17]: 129.8164 - ca3-[18,23]: 271.8030 - ca4-[0,5]: 29.7999 - ca4-[6,11]: 14.2894 - ca4-[12,17]: 81.4604 - ca4-[18,23]: 280.8614 - val_ca1-[0,5]: 12.8766 - val_ca1-[6,11]: 29.1843 - val_ca1-[12,17]: 147.5527 - val_ca1-[18,23]: 370.5438 - val_ca2-[0,5]: 41.7649 - val_ca2-[6,11]: 15.0316 - val_ca2-[12,17]: 82.3013 - val_ca2-[18,23]: 258.1293 - val_ca3-[0,5]: 29.6140 - val_ca3-[6,11]: 17.2685 - val_ca3-[12,17]: 101.6197 - val_ca3-[18,23]: 293.2133 - val_ca4-[0,5]: 32.3904 - val_ca4-[6,11]: 16.4807 - val_ca4-[12,17]: 96.5990 - val_ca4-[18,23]: 284.2854\n",
      "Epoch 42/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 11.5318 - ca1-[6,11]: 27.9779 - ca1-[12,17]: 130.0895 - ca1-[18,23]: 315.8325 - ca2-[0,5]: 19.4176 - ca2-[6,11]: 3.0160 - ca2-[12,17]: 26.1395 - ca2-[18,23]: 138.3750 - ca3-[0,5]: 30.6415 - ca3-[6,11]: 15.7613 - ca3-[12,17]: 130.7247 - ca3-[18,23]: 252.5386 - ca4-[0,5]: 31.2783 - ca4-[6,11]: 14.5199 - ca4-[12,17]: 77.6875 - ca4-[18,23]: 277.0084 - val_ca1-[0,5]: 13.6768 - val_ca1-[6,11]: 27.9685 - val_ca1-[12,17]: 142.2881 - val_ca1-[18,23]: 361.0057 - val_ca2-[0,5]: 43.9833 - val_ca2-[6,11]: 14.9644 - val_ca2-[12,17]: 77.9357 - val_ca2-[18,23]: 249.1142 - val_ca3-[0,5]: 31.1558 - val_ca3-[6,11]: 16.7967 - val_ca3-[12,17]: 97.1484 - val_ca3-[18,23]: 284.4180 - val_ca4-[0,5]: 34.0126 - val_ca4-[6,11]: 16.1131 - val_ca4-[12,17]: 92.2661 - val_ca4-[18,23]: 275.6479\n",
      "Epoch 43/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 9.2966 - ca1-[6,11]: 24.8620 - ca1-[12,17]: 132.6043 - ca1-[18,23]: 312.3088 - ca2-[0,5]: 20.9015 - ca2-[6,11]: 2.6350 - ca2-[12,17]: 25.1646 - ca2-[18,23]: 136.1029 - ca3-[0,5]: 32.1095 - ca3-[6,11]: 17.1583 - ca3-[12,17]: 129.0090 - ca3-[18,23]: 256.7411 - ca4-[0,5]: 32.7867 - ca4-[6,11]: 14.0490 - ca4-[12,17]: 75.4856 - ca4-[18,23]: 271.7059 - val_ca1-[0,5]: 14.5198 - val_ca1-[6,11]: 27.4429 - val_ca1-[12,17]: 139.7324 - val_ca1-[18,23]: 355.4208 - val_ca2-[0,5]: 46.4096 - val_ca2-[6,11]: 14.8433 - val_ca2-[12,17]: 75.4446 - val_ca2-[18,23]: 243.3643 - val_ca3-[0,5]: 32.8357 - val_ca3-[6,11]: 16.5133 - val_ca3-[12,17]: 94.8250 - val_ca3-[18,23]: 279.1123 - val_ca4-[0,5]: 35.7818 - val_ca4-[6,11]: 15.8717 - val_ca4-[12,17]: 90.0138 - val_ca4-[18,23]: 270.4473\n",
      "Epoch 44/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 9.9967 - ca1-[6,11]: 26.5767 - ca1-[12,17]: 127.4020 - ca1-[18,23]: 286.7950 - ca2-[0,5]: 20.8214 - ca2-[6,11]: 1.9639 - ca2-[12,17]: 22.6183 - ca2-[18,23]: 126.6558 - ca3-[0,5]: 34.0440 - ca3-[6,11]: 16.3850 - ca3-[12,17]: 124.8981 - ca3-[18,23]: 255.4021 - ca4-[0,5]: 34.4505 - ca4-[6,11]: 14.3983 - ca4-[12,17]: 73.9541 - ca4-[18,23]: 266.6939 - val_ca1-[0,5]: 15.2799 - val_ca1-[6,11]: 25.7551 - val_ca1-[12,17]: 136.8976 - val_ca1-[18,23]: 352.9090 - val_ca2-[0,5]: 48.5177 - val_ca2-[6,11]: 14.7359 - val_ca2-[12,17]: 72.9575 - val_ca2-[18,23]: 240.2769 - val_ca3-[0,5]: 34.2754 - val_ca3-[6,11]: 15.8289 - val_ca3-[12,17]: 92.3880 - val_ca3-[18,23]: 276.5796 - val_ca4-[0,5]: 37.2760 - val_ca4-[6,11]: 15.3240 - val_ca4-[12,17]: 87.6900 - val_ca4-[18,23]: 268.0231\n",
      "Epoch 45/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 9.7587 - ca1-[6,11]: 26.2036 - ca1-[12,17]: 125.3146 - ca1-[18,23]: 299.7682 - ca2-[0,5]: 23.2198 - ca2-[6,11]: 1.8184 - ca2-[12,17]: 22.3571 - ca2-[18,23]: 123.0058 - ca3-[0,5]: 35.1765 - ca3-[6,11]: 16.9186 - ca3-[12,17]: 121.9715 - ca3-[18,23]: 252.4102 - ca4-[0,5]: 36.2030 - ca4-[6,11]: 14.5448 - ca4-[12,17]: 72.4898 - ca4-[18,23]: 260.2209 - val_ca1-[0,5]: 16.2982 - val_ca1-[6,11]: 24.8903 - val_ca1-[12,17]: 131.0672 - val_ca1-[18,23]: 351.9733 - val_ca2-[0,5]: 51.3036 - val_ca2-[6,11]: 14.7680 - val_ca2-[12,17]: 68.0124 - val_ca2-[18,23]: 238.2507 - val_ca3-[0,5]: 36.2375 - val_ca3-[6,11]: 15.5078 - val_ca3-[12,17]: 87.2916 - val_ca3-[18,23]: 275.2761 - val_ca4-[0,5]: 39.3157 - val_ca4-[6,11]: 15.0827 - val_ca4-[12,17]: 82.7562 - val_ca4-[18,23]: 266.8058\n",
      "Epoch 46/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 11.1400 - ca1-[6,11]: 24.3245 - ca1-[12,17]: 120.0876 - ca1-[18,23]: 293.3365 - ca2-[0,5]: 24.8632 - ca2-[6,11]: 1.4881 - ca2-[12,17]: 17.5930 - ca2-[18,23]: 123.6521 - ca3-[0,5]: 37.4796 - ca3-[6,11]: 16.3304 - ca3-[12,17]: 117.4774 - ca3-[18,23]: 238.0654 - ca4-[0,5]: 37.9213 - ca4-[6,11]: 13.9817 - ca4-[12,17]: 70.3999 - ca4-[18,23]: 255.6464 - val_ca1-[0,5]: 17.0730 - val_ca1-[6,11]: 24.5275 - val_ca1-[12,17]: 130.6106 - val_ca1-[18,23]: 343.7212 - val_ca2-[0,5]: 53.4390 - val_ca2-[6,11]: 15.0313 - val_ca2-[12,17]: 67.5795 - val_ca2-[18,23]: 230.3337 - val_ca3-[0,5]: 37.6946 - val_ca3-[6,11]: 15.5038 - val_ca3-[12,17]: 86.9819 - val_ca3-[18,23]: 267.5421 - val_ca4-[0,5]: 40.7980 - val_ca4-[6,11]: 15.1370 - val_ca4-[12,17]: 82.5631 - val_ca4-[18,23]: 259.3115\n",
      "Epoch 47/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 9.8866 - ca1-[6,11]: 24.9404 - ca1-[12,17]: 111.0599 - ca1-[18,23]: 294.3116 - ca2-[0,5]: 26.9037 - ca2-[6,11]: 1.2905 - ca2-[12,17]: 16.5248 - ca2-[18,23]: 120.0906 - ca3-[0,5]: 39.5057 - ca3-[6,11]: 15.0527 - ca3-[12,17]: 116.3021 - ca3-[18,23]: 243.1144 - ca4-[0,5]: 39.4421 - ca4-[6,11]: 13.7684 - ca4-[12,17]: 66.4710 - ca4-[18,23]: 253.2824 - val_ca1-[0,5]: 17.9585 - val_ca1-[6,11]: 23.6833 - val_ca1-[12,17]: 127.3450 - val_ca1-[18,23]: 338.8026 - val_ca2-[0,5]: 56.1294 - val_ca2-[6,11]: 15.2248 - val_ca2-[12,17]: 64.7157 - val_ca2-[18,23]: 225.3015 - val_ca3-[0,5]: 39.5410 - val_ca3-[6,11]: 15.2745 - val_ca3-[12,17]: 84.0945 - val_ca3-[18,23]: 262.8322 - val_ca4-[0,5]: 42.6949 - val_ca4-[6,11]: 14.9944 - val_ca4-[12,17]: 79.8238 - val_ca4-[18,23]: 254.8135\n",
      "Epoch 48/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 9.8540 - ca1-[6,11]: 23.5808 - ca1-[12,17]: 112.7938 - ca1-[18,23]: 282.8803 - ca2-[0,5]: 29.2626 - ca2-[6,11]: 1.1234 - ca2-[12,17]: 18.3922 - ca2-[18,23]: 116.1268 - ca3-[0,5]: 41.1210 - ca3-[6,11]: 14.7486 - ca3-[12,17]: 111.5022 - ca3-[18,23]: 234.3957 - ca4-[0,5]: 41.0841 - ca4-[6,11]: 14.0579 - ca4-[12,17]: 65.1142 - ca4-[18,23]: 246.0913 - val_ca1-[0,5]: 19.0900 - val_ca1-[6,11]: 22.8071 - val_ca1-[12,17]: 121.6186 - val_ca1-[18,23]: 334.4666 - val_ca2-[0,5]: 58.7653 - val_ca2-[6,11]: 15.6403 - val_ca2-[12,17]: 60.1087 - val_ca2-[18,23]: 220.6504 - val_ca3-[0,5]: 41.4281 - val_ca3-[6,11]: 15.1666 - val_ca3-[12,17]: 79.1989 - val_ca3-[18,23]: 258.5712 - val_ca4-[0,5]: 44.5994 - val_ca4-[6,11]: 14.9871 - val_ca4-[12,17]: 75.1308 - val_ca4-[18,23]: 250.7598\n",
      "Epoch 49/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 9.2778 - ca1-[6,11]: 24.3668 - ca1-[12,17]: 113.2714 - ca1-[18,23]: 291.5612 - ca2-[0,5]: 30.4574 - ca2-[6,11]: 0.9321 - ca2-[12,17]: 16.2757 - ca2-[18,23]: 111.5070 - ca3-[0,5]: 42.6463 - ca3-[6,11]: 15.4037 - ca3-[12,17]: 111.7763 - ca3-[18,23]: 233.8499 - ca4-[0,5]: 43.3514 - ca4-[6,11]: 13.4380 - ca4-[12,17]: 63.2829 - ca4-[18,23]: 243.4931 - val_ca1-[0,5]: 20.0201 - val_ca1-[6,11]: 21.8126 - val_ca1-[12,17]: 122.1381 - val_ca1-[18,23]: 329.2000 - val_ca2-[0,5]: 61.5356 - val_ca2-[6,11]: 15.9162 - val_ca2-[12,17]: 60.1423 - val_ca2-[18,23]: 215.2014 - val_ca3-[0,5]: 43.3200 - val_ca3-[6,11]: 14.9170 - val_ca3-[12,17]: 79.5141 - val_ca3-[18,23]: 253.4565 - val_ca4-[0,5]: 46.5419 - val_ca4-[6,11]: 14.8309 - val_ca4-[12,17]: 75.5127 - val_ca4-[18,23]: 245.8253\n",
      "Epoch 50/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 9.0904 - ca1-[6,11]: 23.1227 - ca1-[12,17]: 109.1078 - ca1-[18,23]: 278.4717 - ca2-[0,5]: 33.0521 - ca2-[6,11]: 0.9869 - ca2-[12,17]: 15.7859 - ca2-[18,23]: 108.7630 - ca3-[0,5]: 43.5198 - ca3-[6,11]: 13.6166 - ca3-[12,17]: 99.9263 - ca3-[18,23]: 226.0300 - ca4-[0,5]: 45.0707 - ca4-[6,11]: 13.8350 - ca4-[12,17]: 60.5673 - ca4-[18,23]: 239.0891 - val_ca1-[0,5]: 21.1005 - val_ca1-[6,11]: 21.3930 - val_ca1-[12,17]: 115.8746 - val_ca1-[18,23]: 323.2711 - val_ca2-[0,5]: 64.0959 - val_ca2-[6,11]: 16.2349 - val_ca2-[12,17]: 55.1756 - val_ca2-[18,23]: 209.4240 - val_ca3-[0,5]: 45.1254 - val_ca3-[6,11]: 14.8945 - val_ca3-[12,17]: 74.1700 - val_ca3-[18,23]: 247.8772 - val_ca4-[0,5]: 48.3550 - val_ca4-[6,11]: 14.8612 - val_ca4-[12,17]: 70.3721 - val_ca4-[18,23]: 240.4765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 9.0859 - ca1-[6,11]: 22.4866 - ca1-[12,17]: 108.2611 - ca1-[18,23]: 271.0415 - ca2-[0,5]: 35.0416 - ca2-[6,11]: 0.9248 - ca2-[12,17]: 14.5550 - ca2-[18,23]: 104.2307 - ca3-[0,5]: 46.9110 - ca3-[6,11]: 14.8947 - ca3-[12,17]: 106.5095 - ca3-[18,23]: 224.4255 - ca4-[0,5]: 47.0083 - ca4-[6,11]: 13.9774 - ca4-[12,17]: 59.9793 - ca4-[18,23]: 234.2977 - val_ca1-[0,5]: 22.2451 - val_ca1-[6,11]: 20.6043 - val_ca1-[12,17]: 117.0758 - val_ca1-[18,23]: 317.3850 - val_ca2-[0,5]: 67.1350 - val_ca2-[6,11]: 16.6783 - val_ca2-[12,17]: 55.8338 - val_ca2-[18,23]: 203.5198 - val_ca3-[0,5]: 47.2577 - val_ca3-[6,11]: 14.8084 - val_ca3-[12,17]: 75.1068 - val_ca3-[18,23]: 242.2046 - val_ca4-[0,5]: 50.4915 - val_ca4-[6,11]: 14.8567 - val_ca4-[12,17]: 71.4138 - val_ca4-[18,23]: 235.0762\n",
      "Epoch 52/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 9.1010 - ca1-[6,11]: 19.8656 - ca1-[12,17]: 103.1432 - ca1-[18,23]: 270.3978 - ca2-[0,5]: 37.0899 - ca2-[6,11]: 1.0658 - ca2-[12,17]: 13.0980 - ca2-[18,23]: 101.8828 - ca3-[0,5]: 48.5335 - ca3-[6,11]: 15.0609 - ca3-[12,17]: 103.9877 - ca3-[18,23]: 221.2999 - ca4-[0,5]: 48.8187 - ca4-[6,11]: 13.3704 - ca4-[12,17]: 56.0968 - ca4-[18,23]: 229.0326 - val_ca1-[0,5]: 23.1809 - val_ca1-[6,11]: 19.8121 - val_ca1-[12,17]: 114.2208 - val_ca1-[18,23]: 316.6852 - val_ca2-[0,5]: 69.4721 - val_ca2-[6,11]: 17.2764 - val_ca2-[12,17]: 53.3988 - val_ca2-[18,23]: 201.7919 - val_ca3-[0,5]: 48.8647 - val_ca3-[6,11]: 14.8106 - val_ca3-[12,17]: 72.5894 - val_ca3-[18,23]: 241.0728 - val_ca4-[0,5]: 52.0496 - val_ca4-[6,11]: 14.9435 - val_ca4-[12,17]: 69.0777 - val_ca4-[18,23]: 234.1796\n",
      "Epoch 53/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 8.9558 - ca1-[6,11]: 18.0729 - ca1-[12,17]: 102.9378 - ca1-[18,23]: 268.3754 - ca2-[0,5]: 38.2830 - ca2-[6,11]: 1.2170 - ca2-[12,17]: 12.9083 - ca2-[18,23]: 95.8274 - ca3-[0,5]: 50.5651 - ca3-[6,11]: 13.8008 - ca3-[12,17]: 97.4536 - ca3-[18,23]: 216.9425 - ca4-[0,5]: 50.9936 - ca4-[6,11]: 14.3320 - ca4-[12,17]: 53.9937 - ca4-[18,23]: 227.3668 - val_ca1-[0,5]: 24.3793 - val_ca1-[6,11]: 19.3751 - val_ca1-[12,17]: 110.7832 - val_ca1-[18,23]: 310.2408 - val_ca2-[0,5]: 72.5625 - val_ca2-[6,11]: 18.0895 - val_ca2-[12,17]: 50.8476 - val_ca2-[18,23]: 195.6404 - val_ca3-[0,5]: 51.0283 - val_ca3-[6,11]: 15.0705 - val_ca3-[12,17]: 69.7802 - val_ca3-[18,23]: 235.0329 - val_ca4-[0,5]: 54.1966 - val_ca4-[6,11]: 15.2724 - val_ca4-[12,17]: 66.4641 - val_ca4-[18,23]: 228.4375\n",
      "Epoch 54/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 8.1848 - ca1-[6,11]: 21.2469 - ca1-[12,17]: 100.6535 - ca1-[18,23]: 263.5875 - ca2-[0,5]: 41.3740 - ca2-[6,11]: 1.5062 - ca2-[12,17]: 11.9296 - ca2-[18,23]: 89.9246 - ca3-[0,5]: 53.0899 - ca3-[6,11]: 14.8405 - ca3-[12,17]: 100.2494 - ca3-[18,23]: 208.3979 - ca4-[0,5]: 52.5915 - ca4-[6,11]: 14.9281 - ca4-[12,17]: 50.7454 - ca4-[18,23]: 221.7884 - val_ca1-[0,5]: 25.5494 - val_ca1-[6,11]: 18.3965 - val_ca1-[12,17]: 108.5849 - val_ca1-[18,23]: 306.0652 - val_ca2-[0,5]: 75.4230 - val_ca2-[6,11]: 18.6386 - val_ca2-[12,17]: 49.0543 - val_ca2-[18,23]: 191.2786 - val_ca3-[0,5]: 53.0371 - val_ca3-[6,11]: 14.9547 - val_ca3-[12,17]: 67.8937 - val_ca3-[18,23]: 230.9393 - val_ca4-[0,5]: 56.1688 - val_ca4-[6,11]: 15.2355 - val_ca4-[12,17]: 64.7401 - val_ca4-[18,23]: 224.6105\n",
      "Epoch 55/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 8.1100 - ca1-[6,11]: 19.4979 - ca1-[12,17]: 97.5255 - ca1-[18,23]: 255.5852 - ca2-[0,5]: 44.7141 - ca2-[6,11]: 1.7982 - ca2-[12,17]: 10.8376 - ca2-[18,23]: 89.7308 - ca3-[0,5]: 55.1319 - ca3-[6,11]: 14.7885 - ca3-[12,17]: 98.2388 - ca3-[18,23]: 205.4437 - ca4-[0,5]: 54.8089 - ca4-[6,11]: 15.1414 - ca4-[12,17]: 50.4440 - ca4-[18,23]: 216.0454 - val_ca1-[0,5]: 27.1046 - val_ca1-[6,11]: 18.1657 - val_ca1-[12,17]: 107.1007 - val_ca1-[18,23]: 300.8649 - val_ca2-[0,5]: 79.2091 - val_ca2-[6,11]: 19.3389 - val_ca2-[12,17]: 47.5763 - val_ca2-[18,23]: 186.1283 - val_ca3-[0,5]: 55.7602 - val_ca3-[6,11]: 15.2063 - val_ca3-[12,17]: 66.4640 - val_ca3-[18,23]: 225.9558 - val_ca4-[0,5]: 58.8589 - val_ca4-[6,11]: 15.5236 - val_ca4-[12,17]: 63.4654 - val_ca4-[18,23]: 219.9407\n",
      "Epoch 56/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 7.9651 - ca1-[6,11]: 20.4513 - ca1-[12,17]: 92.3596 - ca1-[18,23]: 244.6394 - ca2-[0,5]: 44.7794 - ca2-[6,11]: 2.1893 - ca2-[12,17]: 9.9403 - ca2-[18,23]: 88.0761 - ca3-[0,5]: 57.3655 - ca3-[6,11]: 12.4453 - ca3-[12,17]: 87.8805 - ca3-[18,23]: 202.4048 - ca4-[0,5]: 56.7628 - ca4-[6,11]: 15.0745 - ca4-[12,17]: 49.1327 - ca4-[18,23]: 214.3129 - val_ca1-[0,5]: 27.9247 - val_ca1-[6,11]: 17.8767 - val_ca1-[12,17]: 103.8157 - val_ca1-[18,23]: 297.1518 - val_ca2-[0,5]: 81.5228 - val_ca2-[6,11]: 20.1135 - val_ca2-[12,17]: 45.1447 - val_ca2-[18,23]: 182.1036 - val_ca3-[0,5]: 57.2841 - val_ca3-[6,11]: 15.4757 - val_ca3-[12,17]: 63.7510 - val_ca3-[18,23]: 222.2250 - val_ca4-[0,5]: 60.2966 - val_ca4-[6,11]: 15.8308 - val_ca4-[12,17]: 60.9536 - val_ca4-[18,23]: 216.5092\n",
      "Epoch 57/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 8.5405 - ca1-[6,11]: 17.8554 - ca1-[12,17]: 93.6708 - ca1-[18,23]: 245.2109 - ca2-[0,5]: 48.2704 - ca2-[6,11]: 2.8052 - ca2-[12,17]: 8.6117 - ca2-[18,23]: 84.4103 - ca3-[0,5]: 59.4817 - ca3-[6,11]: 14.3214 - ca3-[12,17]: 87.5144 - ca3-[18,23]: 201.0816 - ca4-[0,5]: 58.8503 - ca4-[6,11]: 15.6590 - ca4-[12,17]: 46.3370 - ca4-[18,23]: 208.0028 - val_ca1-[0,5]: 29.3495 - val_ca1-[6,11]: 17.2078 - val_ca1-[12,17]: 102.0096 - val_ca1-[18,23]: 298.8416 - val_ca2-[0,5]: 85.0956 - val_ca2-[6,11]: 21.1614 - val_ca2-[12,17]: 43.6501 - val_ca2-[18,23]: 182.3257 - val_ca3-[0,5]: 59.8112 - val_ca3-[6,11]: 15.7614 - val_ca3-[12,17]: 62.1737 - val_ca3-[18,23]: 223.1770 - val_ca4-[0,5]: 62.7492 - val_ca4-[6,11]: 16.1783 - val_ca4-[12,17]: 59.5561 - val_ca4-[18,23]: 217.7271\n",
      "Epoch 58/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 7.3880 - ca1-[6,11]: 20.6050 - ca1-[12,17]: 87.6396 - ca1-[18,23]: 236.3405 - ca2-[0,5]: 50.6946 - ca2-[6,11]: 3.1129 - ca2-[12,17]: 8.8346 - ca2-[18,23]: 80.7368 - ca3-[0,5]: 62.7419 - ca3-[6,11]: 14.7206 - ca3-[12,17]: 89.8945 - ca3-[18,23]: 191.4199 - ca4-[0,5]: 61.0211 - ca4-[6,11]: 15.9455 - ca4-[12,17]: 45.6624 - ca4-[18,23]: 205.2654 - val_ca1-[0,5]: 30.6034 - val_ca1-[6,11]: 16.8831 - val_ca1-[12,17]: 98.7175 - val_ca1-[18,23]: 288.4365 - val_ca2-[0,5]: 88.0954 - val_ca2-[6,11]: 22.0161 - val_ca2-[12,17]: 41.3922 - val_ca2-[18,23]: 173.2780 - val_ca3-[0,5]: 61.9104 - val_ca3-[6,11]: 16.0523 - val_ca3-[12,17]: 59.5500 - val_ca3-[18,23]: 213.7712 - val_ca4-[0,5]: 64.7261 - val_ca4-[6,11]: 16.4931 - val_ca4-[12,17]: 57.1568 - val_ca4-[18,23]: 208.7535\n",
      "Epoch 59/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 7.9354 - ca1-[6,11]: 17.6009 - ca1-[12,17]: 86.3286 - ca1-[18,23]: 239.1434 - ca2-[0,5]: 53.1739 - ca2-[6,11]: 3.7114 - ca2-[12,17]: 7.4143 - ca2-[18,23]: 77.8985 - ca3-[0,5]: 64.0587 - ca3-[6,11]: 15.2516 - ca3-[12,17]: 80.4905 - ca3-[18,23]: 190.6639 - ca4-[0,5]: 63.5260 - ca4-[6,11]: 16.1958 - ca4-[12,17]: 43.7762 - ca4-[18,23]: 200.9046 - val_ca1-[0,5]: 32.1365 - val_ca1-[6,11]: 16.4848 - val_ca1-[12,17]: 93.9722 - val_ca1-[18,23]: 284.1458 - val_ca2-[0,5]: 91.8303 - val_ca2-[6,11]: 22.9580 - val_ca2-[12,17]: 37.8429 - val_ca2-[18,23]: 168.9849 - val_ca3-[0,5]: 64.5788 - val_ca3-[6,11]: 16.3656 - val_ca3-[12,17]: 55.5514 - val_ca3-[18,23]: 209.6082 - val_ca4-[0,5]: 67.2729 - val_ca4-[6,11]: 16.8283 - val_ca4-[12,17]: 53.3883 - val_ca4-[18,23]: 204.9687\n",
      "Epoch 60/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 7.8463 - ca1-[6,11]: 21.3606 - ca1-[12,17]: 82.8862 - ca1-[18,23]: 232.9801 - ca2-[0,5]: 54.4705 - ca2-[6,11]: 4.4494 - ca2-[12,17]: 7.2924 - ca2-[18,23]: 74.2479 - ca3-[0,5]: 66.1829 - ca3-[6,11]: 14.8096 - ca3-[12,17]: 84.7811 - ca3-[18,23]: 185.6502 - ca4-[0,5]: 65.6407 - ca4-[6,11]: 17.0520 - ca4-[12,17]: 42.7027 - ca4-[18,23]: 198.2182 - val_ca1-[0,5]: 33.4658 - val_ca1-[6,11]: 16.2329 - val_ca1-[12,17]: 93.1277 - val_ca1-[18,23]: 278.0133 - val_ca2-[0,5]: 95.0358 - val_ca2-[6,11]: 23.4863 - val_ca2-[12,17]: 37.4792 - val_ca2-[18,23]: 163.3442 - val_ca3-[0,5]: 66.8191 - val_ca3-[6,11]: 16.4730 - val_ca3-[12,17]: 55.0208 - val_ca3-[18,23]: 203.9255 - val_ca4-[0,5]: 69.3624 - val_ca4-[6,11]: 16.9264 - val_ca4-[12,17]: 53.0529 - val_ca4-[18,23]: 199.6853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 8.3854 - ca1-[6,11]: 20.4843 - ca1-[12,17]: 82.8065 - ca1-[18,23]: 228.2716 - ca2-[0,5]: 56.7912 - ca2-[6,11]: 4.9840 - ca2-[12,17]: 5.9327 - ca2-[18,23]: 72.1414 - ca3-[0,5]: 69.0054 - ca3-[6,11]: 15.4774 - ca3-[12,17]: 81.2365 - ca3-[18,23]: 183.9295 - ca4-[0,5]: 67.8583 - ca4-[6,11]: 16.7075 - ca4-[12,17]: 41.2380 - ca4-[18,23]: 194.1379 - val_ca1-[0,5]: 35.0783 - val_ca1-[6,11]: 15.8572 - val_ca1-[12,17]: 91.6204 - val_ca1-[18,23]: 278.5667 - val_ca2-[0,5]: 99.0017 - val_ca2-[6,11]: 25.0610 - val_ca2-[12,17]: 36.1883 - val_ca2-[18,23]: 162.7237 - val_ca3-[0,5]: 69.6291 - val_ca3-[6,11]: 17.1639 - val_ca3-[12,17]: 53.6584 - val_ca3-[18,23]: 203.9028 - val_ca4-[0,5]: 72.0396 - val_ca4-[6,11]: 17.6467 - val_ca4-[12,17]: 51.8631 - val_ca4-[18,23]: 199.9780\n",
      "Epoch 62/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 8.3861 - ca1-[6,11]: 18.7194 - ca1-[12,17]: 79.7547 - ca1-[18,23]: 224.1016 - ca2-[0,5]: 62.2816 - ca2-[6,11]: 5.9415 - ca2-[12,17]: 5.8613 - ca2-[18,23]: 67.0853 - ca3-[0,5]: 71.7505 - ca3-[6,11]: 15.7236 - ca3-[12,17]: 76.7047 - ca3-[18,23]: 179.2532 - ca4-[0,5]: 69.7856 - ca4-[6,11]: 17.7110 - ca4-[12,17]: 40.6663 - ca4-[18,23]: 191.8191 - val_ca1-[0,5]: 36.0140 - val_ca1-[6,11]: 15.6614 - val_ca1-[12,17]: 89.6294 - val_ca1-[18,23]: 271.4386 - val_ca2-[0,5]: 101.4506 - val_ca2-[6,11]: 26.4797 - val_ca2-[12,17]: 34.9054 - val_ca2-[18,23]: 156.5605 - val_ca3-[0,5]: 71.2544 - val_ca3-[6,11]: 17.8244 - val_ca3-[12,17]: 52.0995 - val_ca3-[18,23]: 197.4788 - val_ca4-[0,5]: 73.4860 - val_ca4-[6,11]: 18.3125 - val_ca4-[12,17]: 50.4942 - val_ca4-[18,23]: 193.9520\n",
      "Epoch 63/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 8.6072 - ca1-[6,11]: 20.4553 - ca1-[12,17]: 78.4415 - ca1-[18,23]: 220.5414 - ca2-[0,5]: 63.7228 - ca2-[6,11]: 6.6369 - ca2-[12,17]: 4.4536 - ca2-[18,23]: 64.2095 - ca3-[0,5]: 73.3942 - ca3-[6,11]: 16.8624 - ca3-[12,17]: 76.6421 - ca3-[18,23]: 170.8751 - ca4-[0,5]: 72.1431 - ca4-[6,11]: 18.1846 - ca4-[12,17]: 39.6978 - ca4-[18,23]: 186.3638 - val_ca1-[0,5]: 37.7842 - val_ca1-[6,11]: 15.5529 - val_ca1-[12,17]: 87.0937 - val_ca1-[18,23]: 267.4037 - val_ca2-[0,5]: 105.4696 - val_ca2-[6,11]: 27.7669 - val_ca2-[12,17]: 33.1990 - val_ca2-[18,23]: 152.4137 - val_ca3-[0,5]: 74.1454 - val_ca3-[6,11]: 18.4304 - val_ca3-[12,17]: 50.0666 - val_ca3-[18,23]: 193.4981 - val_ca4-[0,5]: 76.2106 - val_ca4-[6,11]: 18.9072 - val_ca4-[12,17]: 48.6493 - val_ca4-[18,23]: 190.3300\n",
      "Epoch 64/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 8.4353 - ca1-[6,11]: 19.9686 - ca1-[12,17]: 76.8827 - ca1-[18,23]: 212.2482 - ca2-[0,5]: 67.8611 - ca2-[6,11]: 7.1538 - ca2-[12,17]: 5.9369 - ca2-[18,23]: 65.0726 - ca3-[0,5]: 75.8167 - ca3-[6,11]: 15.7811 - ca3-[12,17]: 76.2921 - ca3-[18,23]: 169.4590 - ca4-[0,5]: 74.6449 - ca4-[6,11]: 18.9931 - ca4-[12,17]: 36.2523 - ca4-[18,23]: 181.8636 - val_ca1-[0,5]: 39.7110 - val_ca1-[6,11]: 15.0707 - val_ca1-[12,17]: 82.6029 - val_ca1-[18,23]: 263.3243 - val_ca2-[0,5]: 110.0653 - val_ca2-[6,11]: 28.8983 - val_ca2-[12,17]: 30.1343 - val_ca2-[18,23]: 148.4404 - val_ca3-[0,5]: 77.4491 - val_ca3-[6,11]: 18.7904 - val_ca3-[12,17]: 46.4249 - val_ca3-[18,23]: 189.5841 - val_ca4-[0,5]: 79.3310 - val_ca4-[6,11]: 19.2493 - val_ca4-[12,17]: 45.2137 - val_ca4-[18,23]: 186.8002\n",
      "Epoch 65/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 9.7409 - ca1-[6,11]: 19.9698 - ca1-[12,17]: 72.7459 - ca1-[18,23]: 199.0419 - ca2-[0,5]: 62.4241 - ca2-[6,11]: 8.5246 - ca2-[12,17]: 4.4696 - ca2-[18,23]: 62.8402 - ca3-[0,5]: 78.9165 - ca3-[6,11]: 17.2686 - ca3-[12,17]: 70.8891 - ca3-[18,23]: 161.1795 - ca4-[0,5]: 77.0936 - ca4-[6,11]: 19.5863 - ca4-[12,17]: 34.5549 - ca4-[18,23]: 179.6633 - val_ca1-[0,5]: 40.8133 - val_ca1-[6,11]: 15.1655 - val_ca1-[12,17]: 82.7086 - val_ca1-[18,23]: 259.2865 - val_ca2-[0,5]: 112.7684 - val_ca2-[6,11]: 29.7937 - val_ca2-[12,17]: 30.5381 - val_ca2-[18,23]: 144.5390 - val_ca3-[0,5]: 79.2707 - val_ca3-[6,11]: 19.2313 - val_ca3-[12,17]: 46.7006 - val_ca3-[18,23]: 185.7373 - val_ca4-[0,5]: 80.9305 - val_ca4-[6,11]: 19.6442 - val_ca4-[12,17]: 45.6595 - val_ca4-[18,23]: 183.3338\n",
      "Epoch 66/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 7.3974 - ca1-[6,11]: 19.6047 - ca1-[12,17]: 73.3583 - ca1-[18,23]: 211.1523 - ca2-[0,5]: 70.2940 - ca2-[6,11]: 9.5445 - ca2-[12,17]: 5.0312 - ca2-[18,23]: 59.9483 - ca3-[0,5]: 81.7273 - ca3-[6,11]: 18.0017 - ca3-[12,17]: 72.4067 - ca3-[18,23]: 162.5371 - ca4-[0,5]: 79.3357 - ca4-[6,11]: 20.2677 - ca4-[12,17]: 34.4577 - ca4-[18,23]: 176.7990 - val_ca1-[0,5]: 42.4672 - val_ca1-[6,11]: 15.0958 - val_ca1-[12,17]: 75.9306 - val_ca1-[18,23]: 255.6444 - val_ca2-[0,5]: 116.8339 - val_ca2-[6,11]: 31.7005 - val_ca2-[12,17]: 25.9342 - val_ca2-[18,23]: 141.0279 - val_ca3-[0,5]: 82.1305 - val_ca3-[6,11]: 20.2079 - val_ca3-[12,17]: 41.2042 - val_ca3-[18,23]: 182.2646 - val_ca4-[0,5]: 83.5631 - val_ca4-[6,11]: 20.5888 - val_ca4-[12,17]: 40.3713 - val_ca4-[18,23]: 180.2537\n",
      "Epoch 67/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 5.1457 - ca1-[6,11]: 15.8922 - ca1-[12,17]: 72.6913 - ca1-[18,23]: 201.2305 - ca2-[0,5]: 73.1705 - ca2-[6,11]: 10.7414 - ca2-[12,17]: 4.3318 - ca2-[18,23]: 55.2142 - ca3-[0,5]: 85.0447 - ca3-[6,11]: 18.1351 - ca3-[12,17]: 65.9736 - ca3-[18,23]: 156.0241 - ca4-[0,5]: 81.3526 - ca4-[6,11]: 20.8907 - ca4-[12,17]: 32.8707 - ca4-[18,23]: 171.6529 - val_ca1-[0,5]: 43.9981 - val_ca1-[6,11]: 14.9233 - val_ca1-[12,17]: 78.8501 - val_ca1-[18,23]: 250.3475 - val_ca2-[0,5]: 120.4348 - val_ca2-[6,11]: 32.7849 - val_ca2-[12,17]: 28.0118 - val_ca2-[18,23]: 136.2852 - val_ca3-[0,5]: 84.6633 - val_ca3-[6,11]: 20.6478 - val_ca3-[12,17]: 43.5944 - val_ca3-[18,23]: 177.3781 - val_ca4-[0,5]: 85.8106 - val_ca4-[6,11]: 20.9623 - val_ca4-[12,17]: 42.9311 - val_ca4-[18,23]: 175.8147\n",
      "Epoch 68/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 8.7197 - ca1-[6,11]: 21.2827 - ca1-[12,17]: 67.5507 - ca1-[18,23]: 204.4132 - ca2-[0,5]: 78.2922 - ca2-[6,11]: 12.5929 - ca2-[12,17]: 5.4565 - ca2-[18,23]: 54.0198 - ca3-[0,5]: 87.1524 - ca3-[6,11]: 19.5433 - ca3-[12,17]: 60.5141 - ca3-[18,23]: 153.7177 - ca4-[0,5]: 83.9765 - ca4-[6,11]: 22.1199 - ca4-[12,17]: 30.5133 - ca4-[18,23]: 169.5067 - val_ca1-[0,5]: 45.7990 - val_ca1-[6,11]: 14.8601 - val_ca1-[12,17]: 76.2137 - val_ca1-[18,23]: 246.7861 - val_ca2-[0,5]: 124.7111 - val_ca2-[6,11]: 34.4074 - val_ca2-[12,17]: 26.6500 - val_ca2-[18,23]: 132.8347 - val_ca3-[0,5]: 87.7014 - val_ca3-[6,11]: 21.4469 - val_ca3-[12,17]: 41.6871 - val_ca3-[18,23]: 173.9558 - val_ca4-[0,5]: 88.5638 - val_ca4-[6,11]: 21.6934 - val_ca4-[12,17]: 41.2155 - val_ca4-[18,23]: 172.8149\n",
      "Epoch 69/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 6.2346 - ca1-[6,11]: 17.6693 - ca1-[12,17]: 65.7688 - ca1-[18,23]: 198.0711 - ca2-[0,5]: 77.6128 - ca2-[6,11]: 13.2716 - ca2-[12,17]: 4.8150 - ca2-[18,23]: 50.8267 - ca3-[0,5]: 90.4131 - ca3-[6,11]: 19.2939 - ca3-[12,17]: 64.7446 - ca3-[18,23]: 149.9709 - ca4-[0,5]: 86.5409 - ca4-[6,11]: 22.3567 - ca4-[12,17]: 31.0038 - ca4-[18,23]: 166.4346 - val_ca1-[0,5]: 47.4014 - val_ca1-[6,11]: 14.8962 - val_ca1-[12,17]: 74.6286 - val_ca1-[18,23]: 244.8914 - val_ca2-[0,5]: 128.3188 - val_ca2-[6,11]: 36.3870 - val_ca2-[12,17]: 25.8846 - val_ca2-[18,23]: 130.5390 - val_ca3-[0,5]: 90.2438 - val_ca3-[6,11]: 22.4879 - val_ca3-[12,17]: 40.5583 - val_ca3-[18,23]: 171.9034 - val_ca4-[0,5]: 90.8149 - val_ca4-[6,11]: 22.6600 - val_ca4-[12,17]: 40.2580 - val_ca4-[18,23]: 171.1614\n",
      "Epoch 70/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 8.9543 - ca1-[6,11]: 19.7632 - ca1-[12,17]: 64.0810 - ca1-[18,23]: 197.5205 - ca2-[0,5]: 84.5511 - ca2-[6,11]: 14.3039 - ca2-[12,17]: 4.8585 - ca2-[18,23]: 49.5249 - ca3-[0,5]: 91.6349 - ca3-[6,11]: 20.5214 - ca3-[12,17]: 67.1523 - ca3-[18,23]: 148.8665 - ca4-[0,5]: 88.6534 - ca4-[6,11]: 22.9744 - ca4-[12,17]: 29.4023 - ca4-[18,23]: 163.5278 - val_ca1-[0,5]: 48.9696 - val_ca1-[6,11]: 14.7709 - val_ca1-[12,17]: 72.6482 - val_ca1-[18,23]: 241.5705 - val_ca2-[0,5]: 132.0402 - val_ca2-[6,11]: 38.0329 - val_ca2-[12,17]: 24.8520 - val_ca2-[18,23]: 127.2032 - val_ca3-[0,5]: 92.8538 - val_ca3-[6,11]: 23.2654 - val_ca3-[12,17]: 39.0964 - val_ca3-[18,23]: 168.6274 - val_ca4-[0,5]: 93.0654 - val_ca4-[6,11]: 23.3319 - val_ca4-[12,17]: 38.9895 - val_ca4-[18,23]: 168.3577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 9.0335 - ca1-[6,11]: 20.7902 - ca1-[12,17]: 62.6108 - ca1-[18,23]: 189.0804 - ca2-[0,5]: 85.2598 - ca2-[6,11]: 15.5986 - ca2-[12,17]: 5.1243 - ca2-[18,23]: 46.2643 - ca3-[0,5]: 95.6545 - ca3-[6,11]: 21.1687 - ca3-[12,17]: 63.0858 - ca3-[18,23]: 140.4282 - ca4-[0,5]: 90.8503 - ca4-[6,11]: 23.8576 - ca4-[12,17]: 29.0976 - ca4-[18,23]: 158.7609 - val_ca1-[0,5]: 50.7919 - val_ca1-[6,11]: 14.8969 - val_ca1-[12,17]: 69.9177 - val_ca1-[18,23]: 236.6544 - val_ca2-[0,5]: 136.2311 - val_ca2-[6,11]: 39.8451 - val_ca2-[12,17]: 23.4916 - val_ca2-[18,23]: 123.1103 - val_ca3-[0,5]: 95.8454 - val_ca3-[6,11]: 24.2393 - val_ca3-[12,17]: 37.1238 - val_ca3-[18,23]: 164.2371 - val_ca4-[0,5]: 95.6997 - val_ca4-[6,11]: 24.1923 - val_ca4-[12,17]: 37.1924 - val_ca4-[18,23]: 164.4139\n",
      "Epoch 72/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 9.1521 - ca1-[6,11]: 22.5173 - ca1-[12,17]: 57.8598 - ca1-[18,23]: 184.8344 - ca2-[0,5]: 91.0496 - ca2-[6,11]: 16.8378 - ca2-[12,17]: 5.2986 - ca2-[18,23]: 45.2405 - ca3-[0,5]: 98.2623 - ca3-[6,11]: 23.7458 - ca3-[12,17]: 62.8283 - ca3-[18,23]: 140.6871 - ca4-[0,5]: 94.1358 - ca4-[6,11]: 25.4198 - ca4-[12,17]: 27.3196 - ca4-[18,23]: 158.8220 - val_ca1-[0,5]: 52.9442 - val_ca1-[6,11]: 14.8501 - val_ca1-[12,17]: 68.5655 - val_ca1-[18,23]: 234.3634 - val_ca2-[0,5]: 141.0754 - val_ca2-[6,11]: 41.7692 - val_ca2-[12,17]: 22.6000 - val_ca2-[18,23]: 120.5447 - val_ca3-[0,5]: 99.3415 - val_ca3-[6,11]: 25.1988 - val_ca3-[12,17]: 35.9915 - val_ca3-[18,23]: 161.8297 - val_ca4-[0,5]: 98.8176 - val_ca4-[6,11]: 25.0235 - val_ca4-[12,17]: 36.2302 - val_ca4-[18,23]: 162.4536\n",
      "Epoch 73/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 9.4591 - ca1-[6,11]: 22.4966 - ca1-[12,17]: 58.9789 - ca1-[18,23]: 183.0440 - ca2-[0,5]: 94.3957 - ca2-[6,11]: 18.4785 - ca2-[12,17]: 5.5766 - ca2-[18,23]: 42.8295 - ca3-[0,5]: 101.6603 - ca3-[6,11]: 22.6281 - ca3-[12,17]: 53.2814 - ca3-[18,23]: 139.6073 - ca4-[0,5]: 96.3567 - ca4-[6,11]: 25.7565 - ca4-[12,17]: 26.6541 - ca4-[18,23]: 154.7861 - val_ca1-[0,5]: 54.8265 - val_ca1-[6,11]: 14.9599 - val_ca1-[12,17]: 66.0559 - val_ca1-[18,23]: 228.5428 - val_ca2-[0,5]: 145.3900 - val_ca2-[6,11]: 43.7220 - val_ca2-[12,17]: 21.8200 - val_ca2-[18,23]: 115.9398 - val_ca3-[0,5]: 102.4100 - val_ca3-[6,11]: 26.2349 - val_ca3-[12,17]: 34.4445 - val_ca3-[18,23]: 156.7656 - val_ca4-[0,5]: 101.4877 - val_ca4-[6,11]: 25.9167 - val_ca4-[12,17]: 34.8386 - val_ca4-[18,23]: 157.8267\n",
      "Epoch 74/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 9.5763 - ca1-[6,11]: 22.7935 - ca1-[12,17]: 55.5337 - ca1-[18,23]: 180.7463 - ca2-[0,5]: 94.5591 - ca2-[6,11]: 20.0257 - ca2-[12,17]: 5.9072 - ca2-[18,23]: 40.6438 - ca3-[0,5]: 104.9037 - ca3-[6,11]: 23.9746 - ca3-[12,17]: 59.3423 - ca3-[18,23]: 135.4611 - ca4-[0,5]: 99.2201 - ca4-[6,11]: 26.7777 - ca4-[12,17]: 27.0694 - ca4-[18,23]: 152.4645 - val_ca1-[0,5]: 55.7414 - val_ca1-[6,11]: 15.2035 - val_ca1-[12,17]: 65.1091 - val_ca1-[18,23]: 225.8489 - val_ca2-[0,5]: 148.1245 - val_ca2-[6,11]: 46.1665 - val_ca2-[12,17]: 21.4411 - val_ca2-[18,23]: 113.1491 - val_ca3-[0,5]: 104.1459 - val_ca3-[6,11]: 27.6086 - val_ca3-[12,17]: 33.7717 - val_ca3-[18,23]: 154.0508 - val_ca4-[0,5]: 102.8211 - val_ca4-[6,11]: 27.1304 - val_ca4-[12,17]: 34.3212 - val_ca4-[18,23]: 155.5506\n",
      "Epoch 75/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 8.2185 - ca1-[6,11]: 22.4556 - ca1-[12,17]: 47.6981 - ca1-[18,23]: 180.6677 - ca2-[0,5]: 101.2645 - ca2-[6,11]: 21.4242 - ca2-[12,17]: 6.0228 - ca2-[18,23]: 37.4816 - ca3-[0,5]: 107.4386 - ca3-[6,11]: 24.1373 - ca3-[12,17]: 50.3277 - ca3-[18,23]: 128.2716 - ca4-[0,5]: 101.6308 - ca4-[6,11]: 27.8264 - ca4-[12,17]: 24.8972 - ca4-[18,23]: 149.0760 - val_ca1-[0,5]: 57.8571 - val_ca1-[6,11]: 15.5045 - val_ca1-[12,17]: 64.5060 - val_ca1-[18,23]: 222.3964 - val_ca2-[0,5]: 152.8335 - val_ca2-[6,11]: 47.7595 - val_ca2-[12,17]: 20.9191 - val_ca2-[18,23]: 110.0011 - val_ca3-[0,5]: 107.5258 - val_ca3-[6,11]: 28.5002 - val_ca3-[12,17]: 33.1571 - val_ca3-[18,23]: 150.8154 - val_ca4-[0,5]: 105.7500 - val_ca4-[6,11]: 27.8539 - val_ca4-[12,17]: 33.8755 - val_ca4-[18,23]: 152.7716\n",
      "Epoch 76/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 8.3857 - ca1-[6,11]: 21.9289 - ca1-[12,17]: 52.2665 - ca1-[18,23]: 175.2446 - ca2-[0,5]: 104.7881 - ca2-[6,11]: 22.6595 - ca2-[12,17]: 5.7570 - ca2-[18,23]: 35.1120 - ca3-[0,5]: 110.8549 - ca3-[6,11]: 27.3807 - ca3-[12,17]: 51.3838 - ca3-[18,23]: 127.5230 - ca4-[0,5]: 103.7563 - ca4-[6,11]: 29.0191 - ca4-[12,17]: 25.5863 - ca4-[18,23]: 145.3741 - val_ca1-[0,5]: 60.2084 - val_ca1-[6,11]: 15.8958 - val_ca1-[12,17]: 61.1399 - val_ca1-[18,23]: 216.8923 - val_ca2-[0,5]: 158.1078 - val_ca2-[6,11]: 50.2001 - val_ca2-[12,17]: 19.7106 - val_ca2-[18,23]: 105.6855 - val_ca3-[0,5]: 111.3396 - val_ca3-[6,11]: 29.9239 - val_ca3-[12,17]: 30.9832 - val_ca3-[18,23]: 146.0257 - val_ca4-[0,5]: 109.0637 - val_ca4-[6,11]: 29.0749 - val_ca4-[12,17]: 31.8322 - val_ca4-[18,23]: 148.4389\n",
      "Epoch 77/300\n",
      "26/26 [==============================] - 3s 106ms/step - ca1-[0,5]: 10.2618 - ca1-[6,11]: 22.7476 - ca1-[12,17]: 51.0070 - ca1-[18,23]: 168.9280 - ca2-[0,5]: 108.3726 - ca2-[6,11]: 25.5350 - ca2-[12,17]: 7.3880 - ca2-[18,23]: 34.5099 - ca3-[0,5]: 114.5086 - ca3-[6,11]: 26.7454 - ca3-[12,17]: 53.9673 - ca3-[18,23]: 118.7225 - ca4-[0,5]: 106.6155 - ca4-[6,11]: 30.3731 - ca4-[12,17]: 21.8407 - ca4-[18,23]: 142.4364 - val_ca1-[0,5]: 61.9982 - val_ca1-[6,11]: 15.9375 - val_ca1-[12,17]: 55.0893 - val_ca1-[18,23]: 218.0758 - val_ca2-[0,5]: 162.3400 - val_ca2-[6,11]: 52.1134 - val_ca2-[12,17]: 16.3652 - val_ca2-[18,23]: 105.4793 - val_ca3-[0,5]: 114.3085 - val_ca3-[6,11]: 30.8894 - val_ca3-[12,17]: 26.4332 - val_ca3-[18,23]: 146.4100 - val_ca4-[0,5]: 111.5039 - val_ca4-[6,11]: 29.8188 - val_ca4-[12,17]: 27.3858 - val_ca4-[18,23]: 149.3576\n",
      "Epoch 78/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 10.4977 - ca1-[6,11]: 23.1156 - ca1-[12,17]: 49.3222 - ca1-[18,23]: 169.6506 - ca2-[0,5]: 112.0262 - ca2-[6,11]: 27.7599 - ca2-[12,17]: 7.6893 - ca2-[18,23]: 32.2372 - ca3-[0,5]: 117.7332 - ca3-[6,11]: 25.9049 - ca3-[12,17]: 50.9135 - ca3-[18,23]: 123.6574 - ca4-[0,5]: 109.0158 - ca4-[6,11]: 30.9638 - ca4-[12,17]: 24.1626 - ca4-[18,23]: 140.0319 - val_ca1-[0,5]: 63.9751 - val_ca1-[6,11]: 16.1424 - val_ca1-[12,17]: 58.2315 - val_ca1-[18,23]: 209.8570 - val_ca2-[0,5]: 166.7020 - val_ca2-[6,11]: 53.9974 - val_ca2-[12,17]: 18.6908 - val_ca2-[18,23]: 99.4939 - val_ca3-[0,5]: 117.4285 - val_ca3-[6,11]: 31.9020 - val_ca3-[12,17]: 29.0202 - val_ca3-[18,23]: 139.4943 - val_ca4-[0,5]: 114.1270 - val_ca4-[6,11]: 30.6196 - val_ca4-[12,17]: 30.1459 - val_ca4-[18,23]: 142.8231\n",
      "Epoch 79/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 8.9731 - ca1-[6,11]: 25.6538 - ca1-[12,17]: 47.1843 - ca1-[18,23]: 147.4603 - ca2-[0,5]: 108.8099 - ca2-[6,11]: 28.9107 - ca2-[12,17]: 8.2544 - ca2-[18,23]: 30.3750 - ca3-[0,5]: 120.9995 - ca3-[6,11]: 27.6957 - ca3-[12,17]: 51.1281 - ca3-[18,23]: 119.3646 - ca4-[0,5]: 111.9928 - ca4-[6,11]: 32.5833 - ca4-[12,17]: 20.7699 - ca4-[18,23]: 136.1392 - val_ca1-[0,5]: 66.2415 - val_ca1-[6,11]: 16.5731 - val_ca1-[12,17]: 56.0064 - val_ca1-[18,23]: 205.6619 - val_ca2-[0,5]: 171.8112 - val_ca2-[6,11]: 56.0380 - val_ca2-[12,17]: 18.1831 - val_ca2-[18,23]: 96.1191 - val_ca3-[0,5]: 121.0956 - val_ca3-[6,11]: 33.0946 - val_ca3-[12,17]: 27.7103 - val_ca3-[18,23]: 135.7774 - val_ca4-[0,5]: 117.2514 - val_ca4-[6,11]: 31.5859 - val_ca4-[12,17]: 28.9312 - val_ca4-[18,23]: 139.5309\n",
      "Epoch 80/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 9.2051 - ca1-[6,11]: 25.7330 - ca1-[12,17]: 45.2365 - ca1-[18,23]: 159.5264 - ca2-[0,5]: 114.0926 - ca2-[6,11]: 30.5882 - ca2-[12,17]: 8.5476 - ca2-[18,23]: 29.1357 - ca3-[0,5]: 123.1892 - ca3-[6,11]: 29.5935 - ca3-[12,17]: 48.5713 - ca3-[18,23]: 108.7250 - ca4-[0,5]: 114.7624 - ca4-[6,11]: 33.4566 - ca4-[12,17]: 21.2545 - ca4-[18,23]: 134.9442 - val_ca1-[0,5]: 67.9650 - val_ca1-[6,11]: 16.8923 - val_ca1-[12,17]: 54.1528 - val_ca1-[18,23]: 207.3821 - val_ca2-[0,5]: 175.8539 - val_ca2-[6,11]: 58.4186 - val_ca2-[12,17]: 17.6588 - val_ca2-[18,23]: 96.3661 - val_ca3-[0,5]: 123.9025 - val_ca3-[6,11]: 34.4292 - val_ca3-[12,17]: 26.5434 - val_ca3-[18,23]: 136.6506 - val_ca4-[0,5]: 119.4810 - val_ca4-[6,11]: 32.6510 - val_ca4-[12,17]: 27.8718 - val_ca4-[18,23]: 140.9460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 7.5645 - ca1-[6,11]: 26.1476 - ca1-[12,17]: 45.8899 - ca1-[18,23]: 153.9778 - ca2-[0,5]: 121.5590 - ca2-[6,11]: 32.8376 - ca2-[12,17]: 9.9341 - ca2-[18,23]: 27.1364 - ca3-[0,5]: 126.4108 - ca3-[6,11]: 29.6565 - ca3-[12,17]: 48.7344 - ca3-[18,23]: 115.0429 - ca4-[0,5]: 117.7397 - ca4-[6,11]: 34.1424 - ca4-[12,17]: 21.3897 - ca4-[18,23]: 131.8558 - val_ca1-[0,5]: 69.7267 - val_ca1-[6,11]: 17.6650 - val_ca1-[12,17]: 53.5534 - val_ca1-[18,23]: 204.3850 - val_ca2-[0,5]: 180.1147 - val_ca2-[6,11]: 61.7316 - val_ca2-[12,17]: 17.8461 - val_ca2-[18,23]: 93.5950 - val_ca3-[0,5]: 126.8647 - val_ca3-[6,11]: 36.4958 - val_ca3-[12,17]: 26.3067 - val_ca3-[18,23]: 133.7706 - val_ca4-[0,5]: 121.8549 - val_ca4-[6,11]: 34.4162 - val_ca4-[12,17]: 27.7506 - val_ca4-[18,23]: 138.5305\n",
      "Epoch 82/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 9.7032 - ca1-[6,11]: 27.3768 - ca1-[12,17]: 40.9121 - ca1-[18,23]: 154.5482 - ca2-[0,5]: 127.2620 - ca2-[6,11]: 34.6475 - ca2-[12,17]: 10.2827 - ca2-[18,23]: 25.2300 - ca3-[0,5]: 130.8158 - ca3-[6,11]: 33.1797 - ca3-[12,17]: 44.6534 - ca3-[18,23]: 111.1605 - ca4-[0,5]: 120.2797 - ca4-[6,11]: 35.7673 - ca4-[12,17]: 19.2591 - ca4-[18,23]: 129.0144 - val_ca1-[0,5]: 71.9298 - val_ca1-[6,11]: 17.7417 - val_ca1-[12,17]: 51.7589 - val_ca1-[18,23]: 196.3560 - val_ca2-[0,5]: 185.0349 - val_ca2-[6,11]: 63.4670 - val_ca2-[12,17]: 17.1970 - val_ca2-[18,23]: 87.8458 - val_ca3-[0,5]: 130.3708 - val_ca3-[6,11]: 37.3449 - val_ca3-[12,17]: 25.0844 - val_ca3-[18,23]: 127.0576 - val_ca4-[0,5]: 124.7502 - val_ca4-[6,11]: 34.9896 - val_ca4-[12,17]: 26.6190 - val_ca4-[18,23]: 132.1745\n",
      "Epoch 83/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 8.0000 - ca1-[6,11]: 28.8498 - ca1-[12,17]: 40.5680 - ca1-[18,23]: 157.5254 - ca2-[0,5]: 129.3612 - ca2-[6,11]: 37.0222 - ca2-[12,17]: 10.3913 - ca2-[18,23]: 24.2636 - ca3-[0,5]: 132.9756 - ca3-[6,11]: 34.4992 - ca3-[12,17]: 43.3202 - ca3-[18,23]: 106.1246 - ca4-[0,5]: 122.7031 - ca4-[6,11]: 36.9408 - ca4-[12,17]: 19.1686 - ca4-[18,23]: 126.7955 - val_ca1-[0,5]: 74.2176 - val_ca1-[6,11]: 18.2856 - val_ca1-[12,17]: 50.0178 - val_ca1-[18,23]: 194.3203 - val_ca2-[0,5]: 190.2500 - val_ca2-[6,11]: 66.2404 - val_ca2-[12,17]: 17.1139 - val_ca2-[18,23]: 86.1834 - val_ca3-[0,5]: 134.1053 - val_ca3-[6,11]: 38.9978 - val_ca3-[12,17]: 24.1997 - val_ca3-[18,23]: 125.2091 - val_ca4-[0,5]: 127.8160 - val_ca4-[6,11]: 36.3131 - val_ca4-[12,17]: 25.7952 - val_ca4-[18,23]: 130.7868\n",
      "Epoch 84/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 10.2557 - ca1-[6,11]: 27.9157 - ca1-[12,17]: 39.8815 - ca1-[18,23]: 150.4350 - ca2-[0,5]: 133.3426 - ca2-[6,11]: 38.3851 - ca2-[12,17]: 11.4370 - ca2-[18,23]: 21.9125 - ca3-[0,5]: 136.9190 - ca3-[6,11]: 36.7200 - ca3-[12,17]: 40.6007 - ca3-[18,23]: 106.8920 - ca4-[0,5]: 125.2308 - ca4-[6,11]: 38.2834 - ca4-[12,17]: 18.2275 - ca4-[18,23]: 121.9717 - val_ca1-[0,5]: 76.5506 - val_ca1-[6,11]: 18.7312 - val_ca1-[12,17]: 48.1899 - val_ca1-[18,23]: 190.9989 - val_ca2-[0,5]: 195.2654 - val_ca2-[6,11]: 68.6052 - val_ca2-[12,17]: 16.9856 - val_ca2-[18,23]: 83.5167 - val_ca3-[0,5]: 137.7223 - val_ca3-[6,11]: 40.3619 - val_ca3-[12,17]: 23.2505 - val_ca3-[18,23]: 122.2466 - val_ca4-[0,5]: 130.7466 - val_ca4-[6,11]: 37.3442 - val_ca4-[12,17]: 24.8935 - val_ca4-[18,23]: 128.2740\n",
      "Epoch 85/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 14.7115 - ca1-[6,11]: 27.5477 - ca1-[12,17]: 37.5446 - ca1-[18,23]: 150.9262 - ca2-[0,5]: 139.3011 - ca2-[6,11]: 40.8812 - ca2-[12,17]: 12.9143 - ca2-[18,23]: 19.2857 - ca3-[0,5]: 141.1076 - ca3-[6,11]: 34.9474 - ca3-[12,17]: 39.2518 - ca3-[18,23]: 95.8776 - ca4-[0,5]: 128.6524 - ca4-[6,11]: 39.6086 - ca4-[12,17]: 17.3504 - ca4-[18,23]: 120.4720 - val_ca1-[0,5]: 79.0018 - val_ca1-[6,11]: 19.4872 - val_ca1-[12,17]: 45.2506 - val_ca1-[18,23]: 187.7199 - val_ca2-[0,5]: 200.6969 - val_ca2-[6,11]: 71.9619 - val_ca2-[12,17]: 16.1515 - val_ca2-[18,23]: 80.9139 - val_ca3-[0,5]: 141.6081 - val_ca3-[6,11]: 42.4151 - val_ca3-[12,17]: 21.4190 - val_ca3-[18,23]: 119.3453 - val_ca4-[0,5]: 133.9124 - val_ca4-[6,11]: 39.0100 - val_ca4-[12,17]: 23.0692 - val_ca4-[18,23]: 125.8107\n",
      "Epoch 86/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 12.9962 - ca1-[6,11]: 29.1313 - ca1-[12,17]: 35.7853 - ca1-[18,23]: 135.3696 - ca2-[0,5]: 143.4382 - ca2-[6,11]: 43.8068 - ca2-[12,17]: 13.5943 - ca2-[18,23]: 20.1937 - ca3-[0,5]: 144.0513 - ca3-[6,11]: 37.8027 - ca3-[12,17]: 35.7717 - ca3-[18,23]: 98.9296 - ca4-[0,5]: 131.0706 - ca4-[6,11]: 40.7501 - ca4-[12,17]: 18.6744 - ca4-[18,23]: 117.5898 - val_ca1-[0,5]: 80.9151 - val_ca1-[6,11]: 20.1013 - val_ca1-[12,17]: 45.4516 - val_ca1-[18,23]: 180.2129 - val_ca2-[0,5]: 205.2097 - val_ca2-[6,11]: 74.6097 - val_ca2-[12,17]: 16.8843 - val_ca2-[18,23]: 75.4923 - val_ca3-[0,5]: 144.7454 - val_ca3-[6,11]: 44.0013 - val_ca3-[12,17]: 21.8174 - val_ca3-[18,23]: 113.0052 - val_ca4-[0,5]: 136.3345 - val_ca4-[6,11]: 40.2266 - val_ca4-[12,17]: 23.5605 - val_ca4-[18,23]: 119.8062\n",
      "Epoch 87/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 13.3986 - ca1-[6,11]: 27.7147 - ca1-[12,17]: 36.3935 - ca1-[18,23]: 143.8500 - ca2-[0,5]: 147.6334 - ca2-[6,11]: 46.0949 - ca2-[12,17]: 15.2982 - ca2-[18,23]: 17.8525 - ca3-[0,5]: 147.6342 - ca3-[6,11]: 39.8200 - ca3-[12,17]: 39.7486 - ca3-[18,23]: 95.4136 - ca4-[0,5]: 134.1715 - ca4-[6,11]: 41.9417 - ca4-[12,17]: 16.7474 - ca4-[18,23]: 116.4015 - val_ca1-[0,5]: 83.6075 - val_ca1-[6,11]: 20.3913 - val_ca1-[12,17]: 44.8828 - val_ca1-[18,23]: 181.0567 - val_ca2-[0,5]: 211.0107 - val_ca2-[6,11]: 77.1431 - val_ca2-[12,17]: 17.1704 - val_ca2-[18,23]: 75.6669 - val_ca3-[0,5]: 148.9585 - val_ca3-[6,11]: 45.3845 - val_ca3-[12,17]: 21.6282 - val_ca3-[18,23]: 113.4309 - val_ca4-[0,5]: 139.7641 - val_ca4-[6,11]: 41.2040 - val_ca4-[12,17]: 23.4405 - val_ca4-[18,23]: 120.7543\n",
      "Epoch 88/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 13.7694 - ca1-[6,11]: 30.8446 - ca1-[12,17]: 34.1776 - ca1-[18,23]: 136.6425 - ca2-[0,5]: 151.8870 - ca2-[6,11]: 48.6249 - ca2-[12,17]: 15.0015 - ca2-[18,23]: 16.7100 - ca3-[0,5]: 152.0368 - ca3-[6,11]: 39.7461 - ca3-[12,17]: 38.8422 - ca3-[18,23]: 92.2105 - ca4-[0,5]: 136.4103 - ca4-[6,11]: 43.2086 - ca4-[12,17]: 16.5120 - ca4-[18,23]: 114.7758 - val_ca1-[0,5]: 85.4082 - val_ca1-[6,11]: 21.1740 - val_ca1-[12,17]: 43.2290 - val_ca1-[18,23]: 171.5878 - val_ca2-[0,5]: 215.2878 - val_ca2-[6,11]: 79.7699 - val_ca2-[12,17]: 16.7383 - val_ca2-[18,23]: 70.0159 - val_ca3-[0,5]: 151.9052 - val_ca3-[6,11]: 47.0238 - val_ca3-[12,17]: 20.5608 - val_ca3-[18,23]: 106.1070 - val_ca4-[0,5]: 141.9597 - val_ca4-[6,11]: 42.4541 - val_ca4-[12,17]: 22.4068 - val_ca4-[18,23]: 113.6139\n",
      "Epoch 89/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 9.6891 - ca1-[6,11]: 31.4609 - ca1-[12,17]: 31.1806 - ca1-[18,23]: 133.2669 - ca2-[0,5]: 158.2164 - ca2-[6,11]: 51.8152 - ca2-[12,17]: 17.0207 - ca2-[18,23]: 15.1398 - ca3-[0,5]: 156.6291 - ca3-[6,11]: 43.6747 - ca3-[12,17]: 39.1986 - ca3-[18,23]: 92.3006 - ca4-[0,5]: 139.7249 - ca4-[6,11]: 44.7024 - ca4-[12,17]: 17.3377 - ca4-[18,23]: 112.7164 - val_ca1-[0,5]: 88.2036 - val_ca1-[6,11]: 21.6282 - val_ca1-[12,17]: 41.7588 - val_ca1-[18,23]: 173.6163 - val_ca2-[0,5]: 221.2612 - val_ca2-[6,11]: 82.4033 - val_ca2-[12,17]: 17.3176 - val_ca2-[18,23]: 70.5838 - val_ca3-[0,5]: 156.2458 - val_ca3-[6,11]: 48.5225 - val_ca3-[12,17]: 20.1425 - val_ca3-[18,23]: 107.2607 - val_ca4-[0,5]: 145.4304 - val_ca4-[6,11]: 43.5030 - val_ca4-[12,17]: 21.9548 - val_ca4-[18,23]: 115.3734\n",
      "Epoch 90/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 7.7079 - ca1-[6,11]: 30.4899 - ca1-[12,17]: 32.7071 - ca1-[18,23]: 138.1312 - ca2-[0,5]: 155.5676 - ca2-[6,11]: 52.5710 - ca2-[12,17]: 18.9788 - ca2-[18,23]: 14.5764 - ca3-[0,5]: 159.1493 - ca3-[6,11]: 44.8891 - ca3-[12,17]: 39.5493 - ca3-[18,23]: 86.2248 - ca4-[0,5]: 142.8714 - ca4-[6,11]: 45.8185 - ca4-[12,17]: 16.1435 - ca4-[18,23]: 109.0288 - val_ca1-[0,5]: 90.8859 - val_ca1-[6,11]: 22.2033 - val_ca1-[12,17]: 40.5239 - val_ca1-[18,23]: 171.8023 - val_ca2-[0,5]: 227.3286 - val_ca2-[6,11]: 85.0088 - val_ca2-[12,17]: 17.5836 - val_ca2-[18,23]: 69.0338 - val_ca3-[0,5]: 160.5960 - val_ca3-[6,11]: 50.0585 - val_ca3-[12,17]: 19.6418 - val_ca3-[18,23]: 105.5464 - val_ca4-[0,5]: 148.8696 - val_ca4-[6,11]: 44.5852 - val_ca4-[12,17]: 21.4486 - val_ca4-[18,23]: 114.1305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 15.0375 - ca1-[6,11]: 34.8732 - ca1-[12,17]: 29.9116 - ca1-[18,23]: 135.2452 - ca2-[0,5]: 154.6597 - ca2-[6,11]: 53.2931 - ca2-[12,17]: 19.3426 - ca2-[18,23]: 13.0595 - ca3-[0,5]: 164.0607 - ca3-[6,11]: 46.5208 - ca3-[12,17]: 34.3386 - ca3-[18,23]: 81.3262 - ca4-[0,5]: 145.3305 - ca4-[6,11]: 47.6723 - ca4-[12,17]: 14.7912 - ca4-[18,23]: 104.7527 - val_ca1-[0,5]: 92.6302 - val_ca1-[6,11]: 22.9306 - val_ca1-[12,17]: 39.1643 - val_ca1-[18,23]: 168.5887 - val_ca2-[0,5]: 231.4063 - val_ca2-[6,11]: 87.9584 - val_ca2-[12,17]: 17.9936 - val_ca2-[18,23]: 66.7418 - val_ca3-[0,5]: 163.4047 - val_ca3-[6,11]: 51.8505 - val_ca3-[12,17]: 19.1638 - val_ca3-[18,23]: 102.8018 - val_ca4-[0,5]: 150.8556 - val_ca4-[6,11]: 45.9001 - val_ca4-[12,17]: 20.9249 - val_ca4-[18,23]: 111.7801\n",
      "Epoch 92/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 15.4106 - ca1-[6,11]: 35.4298 - ca1-[12,17]: 28.3667 - ca1-[18,23]: 131.1564 - ca2-[0,5]: 171.6100 - ca2-[6,11]: 58.2779 - ca2-[12,17]: 20.6350 - ca2-[18,23]: 12.4799 - ca3-[0,5]: 166.1234 - ca3-[6,11]: 48.4292 - ca3-[12,17]: 34.5878 - ca3-[18,23]: 83.0818 - ca4-[0,5]: 148.3237 - ca4-[6,11]: 48.7255 - ca4-[12,17]: 15.7583 - ca4-[18,23]: 104.3604 - val_ca1-[0,5]: 94.6007 - val_ca1-[6,11]: 23.9704 - val_ca1-[12,17]: 37.5413 - val_ca1-[18,23]: 163.4214 - val_ca2-[0,5]: 236.0356 - val_ca2-[6,11]: 91.7006 - val_ca2-[12,17]: 18.1688 - val_ca2-[18,23]: 63.3063 - val_ca3-[0,5]: 166.6199 - val_ca3-[6,11]: 54.2228 - val_ca3-[12,17]: 18.4346 - val_ca3-[18,23]: 98.5598 - val_ca4-[0,5]: 153.1792 - val_ca4-[6,11]: 47.7231 - val_ca4-[12,17]: 20.1365 - val_ca4-[18,23]: 107.8640\n",
      "Epoch 93/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 18.4045 - ca1-[6,11]: 34.5500 - ca1-[12,17]: 28.2619 - ca1-[18,23]: 128.7499 - ca2-[0,5]: 174.0831 - ca2-[6,11]: 61.1567 - ca2-[12,17]: 21.7588 - ca2-[18,23]: 11.2187 - ca3-[0,5]: 170.4235 - ca3-[6,11]: 48.4320 - ca3-[12,17]: 28.3398 - ca3-[18,23]: 75.8794 - ca4-[0,5]: 151.2240 - ca4-[6,11]: 50.3146 - ca4-[12,17]: 14.8790 - ca4-[18,23]: 102.7728 - val_ca1-[0,5]: 97.8386 - val_ca1-[6,11]: 24.6478 - val_ca1-[12,17]: 36.6538 - val_ca1-[18,23]: 164.3663 - val_ca2-[0,5]: 242.8178 - val_ca2-[6,11]: 94.5538 - val_ca2-[12,17]: 18.7726 - val_ca2-[18,23]: 63.0728 - val_ca3-[0,5]: 171.5855 - val_ca3-[6,11]: 55.9223 - val_ca3-[12,17]: 18.2629 - val_ca3-[18,23]: 98.7852 - val_ca4-[0,5]: 157.1206 - val_ca4-[6,11]: 48.8920 - val_ca4-[12,17]: 19.9251 - val_ca4-[18,23]: 108.7062\n",
      "Epoch 94/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 18.8246 - ca1-[6,11]: 36.9886 - ca1-[12,17]: 27.3532 - ca1-[18,23]: 120.0082 - ca2-[0,5]: 178.7026 - ca2-[6,11]: 64.4846 - ca2-[12,17]: 24.4294 - ca2-[18,23]: 9.6348 - ca3-[0,5]: 175.9421 - ca3-[6,11]: 51.6581 - ca3-[12,17]: 33.4268 - ca3-[18,23]: 80.0254 - ca4-[0,5]: 153.9910 - ca4-[6,11]: 51.9357 - ca4-[12,17]: 15.7448 - ca4-[18,23]: 98.9497 - val_ca1-[0,5]: 100.0583 - val_ca1-[6,11]: 25.3984 - val_ca1-[12,17]: 35.7929 - val_ca1-[18,23]: 159.2290 - val_ca2-[0,5]: 247.8844 - val_ca2-[6,11]: 97.6449 - val_ca2-[12,17]: 18.9896 - val_ca2-[18,23]: 60.1704 - val_ca3-[0,5]: 175.1414 - val_ca3-[6,11]: 57.7882 - val_ca3-[12,17]: 17.8805 - val_ca3-[18,23]: 94.8525 - val_ca4-[0,5]: 159.7004 - val_ca4-[6,11]: 50.1951 - val_ca4-[12,17]: 19.5327 - val_ca4-[18,23]: 105.0443\n",
      "Epoch 95/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 17.0559 - ca1-[6,11]: 34.8039 - ca1-[12,17]: 26.5096 - ca1-[18,23]: 123.3905 - ca2-[0,5]: 185.5458 - ca2-[6,11]: 66.3422 - ca2-[12,17]: 25.1119 - ca2-[18,23]: 9.2270 - ca3-[0,5]: 179.0585 - ca3-[6,11]: 53.0778 - ca3-[12,17]: 35.1292 - ca3-[18,23]: 74.3812 - ca4-[0,5]: 157.2532 - ca4-[6,11]: 53.0156 - ca4-[12,17]: 14.8434 - ca4-[18,23]: 98.4208 - val_ca1-[0,5]: 102.8856 - val_ca1-[6,11]: 26.1391 - val_ca1-[12,17]: 32.5552 - val_ca1-[18,23]: 156.9360 - val_ca2-[0,5]: 254.2277 - val_ca2-[6,11]: 100.6966 - val_ca2-[12,17]: 19.0862 - val_ca2-[18,23]: 58.8138 - val_ca3-[0,5]: 179.6875 - val_ca3-[6,11]: 59.6286 - val_ca3-[12,17]: 16.3911 - val_ca3-[18,23]: 93.0211 - val_ca4-[0,5]: 163.1559 - val_ca4-[6,11]: 51.4476 - val_ca4-[12,17]: 17.7821 - val_ca4-[18,23]: 103.6169\n",
      "Epoch 96/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 17.2998 - ca1-[6,11]: 39.6710 - ca1-[12,17]: 26.2014 - ca1-[18,23]: 119.2096 - ca2-[0,5]: 179.9344 - ca2-[6,11]: 66.7695 - ca2-[12,17]: 28.0723 - ca2-[18,23]: 7.9885 - ca3-[0,5]: 182.5098 - ca3-[6,11]: 56.2143 - ca3-[12,17]: 31.9805 - ca3-[18,23]: 72.4549 - ca4-[0,5]: 159.4727 - ca4-[6,11]: 54.5824 - ca4-[12,17]: 15.1633 - ca4-[18,23]: 97.4010 - val_ca1-[0,5]: 104.9440 - val_ca1-[6,11]: 27.6587 - val_ca1-[12,17]: 33.9431 - val_ca1-[18,23]: 152.9139 - val_ca2-[0,5]: 258.8335 - val_ca2-[6,11]: 105.5194 - val_ca2-[12,17]: 20.9768 - val_ca2-[18,23]: 56.1044 - val_ca3-[0,5]: 182.9055 - val_ca3-[6,11]: 62.7975 - val_ca3-[12,17]: 17.9240 - val_ca3-[18,23]: 89.6706 - val_ca4-[0,5]: 165.3739 - val_ca4-[6,11]: 53.9021 - val_ca4-[12,17]: 19.3447 - val_ca4-[18,23]: 100.6137\n",
      "Epoch 97/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 17.8044 - ca1-[6,11]: 39.2870 - ca1-[12,17]: 24.6962 - ca1-[18,23]: 113.8305 - ca2-[0,5]: 186.7730 - ca2-[6,11]: 72.2546 - ca2-[12,17]: 29.0326 - ca2-[18,23]: 7.6778 - ca3-[0,5]: 187.3683 - ca3-[6,11]: 60.7899 - ca3-[12,17]: 29.8345 - ca3-[18,23]: 71.0821 - ca4-[0,5]: 162.7692 - ca4-[6,11]: 56.1045 - ca4-[12,17]: 14.3071 - ca4-[18,23]: 96.0362 - val_ca1-[0,5]: 107.6959 - val_ca1-[6,11]: 28.2084 - val_ca1-[12,17]: 32.9855 - val_ca1-[18,23]: 149.9197 - val_ca2-[0,5]: 264.8078 - val_ca2-[6,11]: 108.1387 - val_ca2-[12,17]: 21.2655 - val_ca2-[18,23]: 54.1216 - val_ca3-[0,5]: 187.1857 - val_ca3-[6,11]: 64.2927 - val_ca3-[12,17]: 17.5272 - val_ca3-[18,23]: 87.1774 - val_ca4-[0,5]: 168.5632 - val_ca4-[6,11]: 54.8055 - val_ca4-[12,17]: 18.8868 - val_ca4-[18,23]: 98.4872\n",
      "Epoch 98/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 18.5081 - ca1-[6,11]: 40.4119 - ca1-[12,17]: 23.1538 - ca1-[18,23]: 111.7763 - ca2-[0,5]: 195.5438 - ca2-[6,11]: 76.0334 - ca2-[12,17]: 30.0649 - ca2-[18,23]: 6.5688 - ca3-[0,5]: 190.1439 - ca3-[6,11]: 57.6204 - ca3-[12,17]: 32.6357 - ca3-[18,23]: 69.3257 - ca4-[0,5]: 166.0372 - ca4-[6,11]: 57.9326 - ca4-[12,17]: 14.0264 - ca4-[18,23]: 92.6458 - val_ca1-[0,5]: 110.2827 - val_ca1-[6,11]: 28.7634 - val_ca1-[12,17]: 31.0355 - val_ca1-[18,23]: 147.3848 - val_ca2-[0,5]: 270.6356 - val_ca2-[6,11]: 110.5901 - val_ca2-[12,17]: 22.3086 - val_ca2-[18,23]: 52.4598 - val_ca3-[0,5]: 191.3134 - val_ca3-[6,11]: 65.6965 - val_ca3-[12,17]: 17.1169 - val_ca3-[18,23]: 85.0604 - val_ca4-[0,5]: 171.5077 - val_ca4-[6,11]: 55.5912 - val_ca4-[12,17]: 18.1965 - val_ca4-[18,23]: 96.7865\n",
      "Epoch 99/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 8.2735 - ca1-[6,11]: 42.7346 - ca1-[12,17]: 21.8984 - ca1-[18,23]: 109.9620 - ca2-[0,5]: 202.7242 - ca2-[6,11]: 69.9017 - ca2-[12,17]: 31.7431 - ca2-[18,23]: 6.2374 - ca3-[0,5]: 196.1909 - ca3-[6,11]: 58.5732 - ca3-[12,17]: 33.1726 - ca3-[18,23]: 67.6663 - ca4-[0,5]: 168.6786 - ca4-[6,11]: 59.2532 - ca4-[12,17]: 14.8907 - ca4-[18,23]: 92.1478 - val_ca1-[0,5]: 112.5951 - val_ca1-[6,11]: 30.2660 - val_ca1-[12,17]: 30.5250 - val_ca1-[18,23]: 145.7380 - val_ca2-[0,5]: 275.8372 - val_ca2-[6,11]: 115.4516 - val_ca2-[12,17]: 22.8786 - val_ca2-[18,23]: 51.2744 - val_ca3-[0,5]: 194.9675 - val_ca3-[6,11]: 68.8658 - val_ca3-[12,17]: 17.0663 - val_ca3-[18,23]: 83.5938 - val_ca4-[0,5]: 174.0207 - val_ca4-[6,11]: 57.9514 - val_ca4-[12,17]: 18.0821 - val_ca4-[18,23]: 95.7666\n",
      "Epoch 100/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 19.8582 - ca1-[6,11]: 43.4168 - ca1-[12,17]: 21.0148 - ca1-[18,23]: 106.7917 - ca2-[0,5]: 201.0330 - ca2-[6,11]: 82.0592 - ca2-[12,17]: 33.1604 - ca2-[18,23]: 5.9086 - ca3-[0,5]: 199.1735 - ca3-[6,11]: 61.0906 - ca3-[12,17]: 29.7767 - ca3-[18,23]: 64.8502 - ca4-[0,5]: 171.3505 - ca4-[6,11]: 61.0041 - ca4-[12,17]: 13.6919 - ca4-[18,23]: 90.5873 - val_ca1-[0,5]: 115.9511 - val_ca1-[6,11]: 31.3376 - val_ca1-[12,17]: 29.5627 - val_ca1-[18,23]: 141.5734 - val_ca2-[0,5]: 282.9787 - val_ca2-[6,11]: 119.0502 - val_ca2-[12,17]: 23.7719 - val_ca2-[18,23]: 49.0701 - val_ca3-[0,5]: 200.1642 - val_ca3-[6,11]: 71.1331 - val_ca3-[12,17]: 16.9949 - val_ca3-[18,23]: 80.4454 - val_ca4-[0,5]: 177.8994 - val_ca4-[6,11]: 59.4744 - val_ca4-[12,17]: 17.8383 - val_ca4-[18,23]: 92.8824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 17.6284 - ca1-[6,11]: 41.9612 - ca1-[12,17]: 19.5884 - ca1-[18,23]: 110.8394 - ca2-[0,5]: 196.2194 - ca2-[6,11]: 85.9918 - ca2-[12,17]: 35.2173 - ca2-[18,23]: 5.1909 - ca3-[0,5]: 202.6992 - ca3-[6,11]: 67.5218 - ca3-[12,17]: 31.6777 - ca3-[18,23]: 62.6576 - ca4-[0,5]: 174.4758 - ca4-[6,11]: 62.3465 - ca4-[12,17]: 15.1379 - ca4-[18,23]: 86.9466 - val_ca1-[0,5]: 117.9963 - val_ca1-[6,11]: 32.3667 - val_ca1-[12,17]: 28.5913 - val_ca1-[18,23]: 139.9917 - val_ca2-[0,5]: 287.7469 - val_ca2-[6,11]: 122.8701 - val_ca2-[12,17]: 24.9547 - val_ca2-[18,23]: 48.0503 - val_ca3-[0,5]: 203.4572 - val_ca3-[6,11]: 73.5056 - val_ca3-[12,17]: 17.0789 - val_ca3-[18,23]: 79.0915 - val_ca4-[0,5]: 179.9782 - val_ca4-[6,11]: 61.0390 - val_ca4-[12,17]: 17.6929 - val_ca4-[18,23]: 91.9750\n",
      "Epoch 102/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 21.0893 - ca1-[6,11]: 44.1539 - ca1-[12,17]: 20.4168 - ca1-[18,23]: 100.3220 - ca2-[0,5]: 217.8538 - ca2-[6,11]: 88.9090 - ca2-[12,17]: 36.5700 - ca2-[18,23]: 4.8713 - ca3-[0,5]: 207.9495 - ca3-[6,11]: 66.4751 - ca3-[12,17]: 29.3846 - ca3-[18,23]: 60.0533 - ca4-[0,5]: 177.9047 - ca4-[6,11]: 63.8747 - ca4-[12,17]: 14.9058 - ca4-[18,23]: 86.1121 - val_ca1-[0,5]: 121.2130 - val_ca1-[6,11]: 33.7444 - val_ca1-[12,17]: 27.6560 - val_ca1-[18,23]: 138.2035 - val_ca2-[0,5]: 294.5501 - val_ca2-[6,11]: 127.1878 - val_ca2-[12,17]: 25.6230 - val_ca2-[18,23]: 47.1375 - val_ca3-[0,5]: 208.4071 - val_ca3-[6,11]: 76.3092 - val_ca3-[12,17]: 16.8870 - val_ca3-[18,23]: 77.7000 - val_ca4-[0,5]: 183.5380 - val_ca4-[6,11]: 62.9738 - val_ca4-[12,17]: 17.3334 - val_ca4-[18,23]: 90.9977\n",
      "Epoch 103/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 24.6552 - ca1-[6,11]: 46.2595 - ca1-[12,17]: 18.8719 - ca1-[18,23]: 102.7099 - ca2-[0,5]: 223.0168 - ca2-[6,11]: 88.1855 - ca2-[12,17]: 40.1398 - ca2-[18,23]: 4.4019 - ca3-[0,5]: 211.2005 - ca3-[6,11]: 69.4931 - ca3-[12,17]: 31.0854 - ca3-[18,23]: 58.6653 - ca4-[0,5]: 179.9161 - ca4-[6,11]: 65.5277 - ca4-[12,17]: 13.9284 - ca4-[18,23]: 82.5387 - val_ca1-[0,5]: 124.0172 - val_ca1-[6,11]: 34.7862 - val_ca1-[12,17]: 26.7279 - val_ca1-[18,23]: 133.6947 - val_ca2-[0,5]: 300.6427 - val_ca2-[6,11]: 130.4536 - val_ca2-[12,17]: 26.9017 - val_ca2-[18,23]: 44.7769 - val_ca3-[0,5]: 212.7679 - val_ca3-[6,11]: 78.3691 - val_ca3-[12,17]: 17.0334 - val_ca3-[18,23]: 74.2946 - val_ca4-[0,5]: 186.5540 - val_ca4-[6,11]: 64.2630 - val_ca4-[12,17]: 17.2075 - val_ca4-[18,23]: 87.7910\n",
      "Epoch 104/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 19.0712 - ca1-[6,11]: 48.6564 - ca1-[12,17]: 18.2890 - ca1-[18,23]: 95.0943 - ca2-[0,5]: 230.6472 - ca2-[6,11]: 94.4964 - ca2-[12,17]: 39.3461 - ca2-[18,23]: 3.9454 - ca3-[0,5]: 217.5256 - ca3-[6,11]: 70.2245 - ca3-[12,17]: 30.3367 - ca3-[18,23]: 55.8271 - ca4-[0,5]: 183.6276 - ca4-[6,11]: 67.2167 - ca4-[12,17]: 14.1229 - ca4-[18,23]: 82.2019 - val_ca1-[0,5]: 125.9898 - val_ca1-[6,11]: 35.5295 - val_ca1-[12,17]: 24.3692 - val_ca1-[18,23]: 132.0609 - val_ca2-[0,5]: 305.4997 - val_ca2-[6,11]: 133.7874 - val_ca2-[12,17]: 27.5506 - val_ca2-[18,23]: 44.0858 - val_ca3-[0,5]: 216.0651 - val_ca3-[6,11]: 80.3300 - val_ca3-[12,17]: 16.1916 - val_ca3-[18,23]: 73.0895 - val_ca4-[0,5]: 188.5466 - val_ca4-[6,11]: 65.3815 - val_ca4-[12,17]: 15.9506 - val_ca4-[18,23]: 86.9491\n",
      "Epoch 105/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 19.6646 - ca1-[6,11]: 53.6322 - ca1-[12,17]: 17.0174 - ca1-[18,23]: 95.5148 - ca2-[0,5]: 225.9310 - ca2-[6,11]: 98.4161 - ca2-[12,17]: 43.9718 - ca2-[18,23]: 3.6709 - ca3-[0,5]: 221.0403 - ca3-[6,11]: 74.4086 - ca3-[12,17]: 27.3975 - ca3-[18,23]: 54.5846 - ca4-[0,5]: 186.0137 - ca4-[6,11]: 68.6014 - ca4-[12,17]: 14.0362 - ca4-[18,23]: 78.1443 - val_ca1-[0,5]: 129.2984 - val_ca1-[6,11]: 37.1843 - val_ca1-[12,17]: 25.2301 - val_ca1-[18,23]: 129.8183 - val_ca2-[0,5]: 312.4248 - val_ca2-[6,11]: 138.8579 - val_ca2-[12,17]: 29.4543 - val_ca2-[18,23]: 42.8281 - val_ca3-[0,5]: 221.1084 - val_ca3-[6,11]: 83.6611 - val_ca3-[12,17]: 17.4706 - val_ca3-[18,23]: 71.2926 - val_ca4-[0,5]: 192.0943 - val_ca4-[6,11]: 67.6899 - val_ca4-[12,17]: 17.1024 - val_ca4-[18,23]: 85.5287\n",
      "Epoch 106/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 23.7373 - ca1-[6,11]: 50.3643 - ca1-[12,17]: 16.4152 - ca1-[18,23]: 94.6721 - ca2-[0,5]: 241.3415 - ca2-[6,11]: 103.4148 - ca2-[12,17]: 47.6853 - ca2-[18,23]: 3.3578 - ca3-[0,5]: 226.4663 - ca3-[6,11]: 77.4015 - ca3-[12,17]: 31.1965 - ca3-[18,23]: 53.6987 - ca4-[0,5]: 189.4143 - ca4-[6,11]: 70.5095 - ca4-[12,17]: 14.4756 - ca4-[18,23]: 79.1929 - val_ca1-[0,5]: 132.0401 - val_ca1-[6,11]: 38.1609 - val_ca1-[12,17]: 24.8569 - val_ca1-[18,23]: 125.8217 - val_ca2-[0,5]: 318.5621 - val_ca2-[6,11]: 141.8993 - val_ca2-[12,17]: 30.9675 - val_ca2-[18,23]: 40.9443 - val_ca3-[0,5]: 225.4480 - val_ca3-[6,11]: 85.5519 - val_ca3-[12,17]: 17.9796 - val_ca3-[18,23]: 68.3670 - val_ca4-[0,5]: 194.9390 - val_ca4-[6,11]: 68.7489 - val_ca4-[12,17]: 17.3386 - val_ca4-[18,23]: 82.7884\n",
      "Epoch 107/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 24.0161 - ca1-[6,11]: 53.0473 - ca1-[12,17]: 13.0964 - ca1-[18,23]: 89.8986 - ca2-[0,5]: 244.3051 - ca2-[6,11]: 105.6011 - ca2-[12,17]: 47.5853 - ca2-[18,23]: 3.1353 - ca3-[0,5]: 228.8556 - ca3-[6,11]: 76.6133 - ca3-[12,17]: 28.4661 - ca3-[18,23]: 51.8061 - ca4-[0,5]: 192.1063 - ca4-[6,11]: 72.0155 - ca4-[12,17]: 14.6916 - ca4-[18,23]: 78.0570 - val_ca1-[0,5]: 135.7486 - val_ca1-[6,11]: 39.4785 - val_ca1-[12,17]: 23.8288 - val_ca1-[18,23]: 122.6025 - val_ca2-[0,5]: 326.3884 - val_ca2-[6,11]: 146.3739 - val_ca2-[12,17]: 31.4850 - val_ca2-[18,23]: 39.5752 - val_ca3-[0,5]: 231.1381 - val_ca3-[6,11]: 88.3796 - val_ca3-[12,17]: 17.6400 - val_ca3-[18,23]: 66.0732 - val_ca4-[0,5]: 199.0167 - val_ca4-[6,11]: 70.5612 - val_ca4-[12,17]: 16.7694 - val_ca4-[18,23]: 80.6889\n",
      "Epoch 108/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 23.7847 - ca1-[6,11]: 54.0558 - ca1-[12,17]: 14.4588 - ca1-[18,23]: 91.7000 - ca2-[0,5]: 249.7874 - ca2-[6,11]: 111.1204 - ca2-[12,17]: 51.3933 - ca2-[18,23]: 3.0333 - ca3-[0,5]: 237.0579 - ca3-[6,11]: 82.0367 - ca3-[12,17]: 29.3436 - ca3-[18,23]: 50.3952 - ca4-[0,5]: 195.3961 - ca4-[6,11]: 73.7994 - ca4-[12,17]: 14.5666 - ca4-[18,23]: 74.3941 - val_ca1-[0,5]: 137.8770 - val_ca1-[6,11]: 40.6813 - val_ca1-[12,17]: 23.3697 - val_ca1-[18,23]: 123.9794 - val_ca2-[0,5]: 331.3021 - val_ca2-[6,11]: 150.2548 - val_ca2-[12,17]: 32.9729 - val_ca2-[18,23]: 39.9884 - val_ca3-[0,5]: 234.5154 - val_ca3-[6,11]: 90.8294 - val_ca3-[12,17]: 18.0906 - val_ca3-[18,23]: 66.8082 - val_ca4-[0,5]: 200.9493 - val_ca4-[6,11]: 72.0358 - val_ca4-[12,17]: 16.9076 - val_ca4-[18,23]: 82.1122\n",
      "Epoch 109/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 24.9081 - ca1-[6,11]: 51.1794 - ca1-[12,17]: 14.8781 - ca1-[18,23]: 88.1638 - ca2-[0,5]: 244.4027 - ca2-[6,11]: 113.0407 - ca2-[12,17]: 52.2200 - ca2-[18,23]: 3.1264 - ca3-[0,5]: 242.0794 - ca3-[6,11]: 82.0847 - ca3-[12,17]: 30.0543 - ca3-[18,23]: 49.2879 - ca4-[0,5]: 198.3841 - ca4-[6,11]: 75.9104 - ca4-[12,17]: 14.2811 - ca4-[18,23]: 75.0222 - val_ca1-[0,5]: 140.8702 - val_ca1-[6,11]: 41.9805 - val_ca1-[12,17]: 22.7011 - val_ca1-[18,23]: 120.4568 - val_ca2-[0,5]: 337.8217 - val_ca2-[6,11]: 154.3559 - val_ca2-[12,17]: 34.4025 - val_ca2-[18,23]: 38.0960 - val_ca3-[0,5]: 239.1638 - val_ca3-[6,11]: 93.4393 - val_ca3-[12,17]: 18.4108 - val_ca3-[18,23]: 64.0788 - val_ca4-[0,5]: 204.0477 - val_ca4-[6,11]: 73.6539 - val_ca4-[12,17]: 16.8724 - val_ca4-[18,23]: 79.5884\n",
      "Epoch 110/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 22.8463 - ca1-[6,11]: 55.7441 - ca1-[12,17]: 14.2099 - ca1-[18,23]: 84.3335 - ca2-[0,5]: 260.9119 - ca2-[6,11]: 117.2938 - ca2-[12,17]: 54.5784 - ca2-[18,23]: 3.0506 - ca3-[0,5]: 244.5667 - ca3-[6,11]: 84.4442 - ca3-[12,17]: 31.4708 - ca3-[18,23]: 47.1945 - ca4-[0,5]: 201.6115 - ca4-[6,11]: 77.7285 - ca4-[12,17]: 14.8169 - ca4-[18,23]: 72.2389 - val_ca1-[0,5]: 143.9352 - val_ca1-[6,11]: 43.8585 - val_ca1-[12,17]: 22.0860 - val_ca1-[18,23]: 113.6247 - val_ca2-[0,5]: 344.4539 - val_ca2-[6,11]: 159.8257 - val_ca2-[12,17]: 36.3381 - val_ca2-[18,23]: 34.7964 - val_ca3-[0,5]: 243.9222 - val_ca3-[6,11]: 97.0732 - val_ca3-[12,17]: 19.0338 - val_ca3-[18,23]: 59.0822 - val_ca4-[0,5]: 207.1454 - val_ca4-[6,11]: 76.0845 - val_ca4-[12,17]: 17.0365 - val_ca4-[18,23]: 74.4636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 26.8380 - ca1-[6,11]: 60.0995 - ca1-[12,17]: 13.5383 - ca1-[18,23]: 86.5098 - ca2-[0,5]: 266.5479 - ca2-[6,11]: 121.1621 - ca2-[12,17]: 57.8532 - ca2-[18,23]: 3.0329 - ca3-[0,5]: 248.4817 - ca3-[6,11]: 88.6059 - ca3-[12,17]: 28.1806 - ca3-[18,23]: 45.2165 - ca4-[0,5]: 204.6065 - ca4-[6,11]: 79.2660 - ca4-[12,17]: 15.8582 - ca4-[18,23]: 72.0945 - val_ca1-[0,5]: 146.7658 - val_ca1-[6,11]: 44.7024 - val_ca1-[12,17]: 21.9575 - val_ca1-[18,23]: 114.6840 - val_ca2-[0,5]: 350.7414 - val_ca2-[6,11]: 162.9088 - val_ca2-[12,17]: 37.6592 - val_ca2-[18,23]: 35.9942 - val_ca3-[0,5]: 248.3718 - val_ca3-[6,11]: 98.9155 - val_ca3-[12,17]: 19.5304 - val_ca3-[18,23]: 60.0997 - val_ca4-[0,5]: 209.9609 - val_ca4-[6,11]: 76.9717 - val_ca4-[12,17]: 17.2648 - val_ca4-[18,23]: 75.9543\n",
      "Epoch 112/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 27.5806 - ca1-[6,11]: 61.4480 - ca1-[12,17]: 11.9572 - ca1-[18,23]: 74.4608 - ca2-[0,5]: 272.2530 - ca2-[6,11]: 126.3502 - ca2-[12,17]: 57.5310 - ca2-[18,23]: 3.1805 - ca3-[0,5]: 254.0225 - ca3-[6,11]: 89.6012 - ca3-[12,17]: 31.3582 - ca3-[18,23]: 44.5417 - ca4-[0,5]: 207.3487 - ca4-[6,11]: 80.8653 - ca4-[12,17]: 14.8897 - ca4-[18,23]: 69.5942 - val_ca1-[0,5]: 150.2280 - val_ca1-[6,11]: 46.0625 - val_ca1-[12,17]: 21.0157 - val_ca1-[18,23]: 113.5295 - val_ca2-[0,5]: 358.0243 - val_ca2-[6,11]: 167.1224 - val_ca2-[12,17]: 39.8436 - val_ca2-[18,23]: 35.6055 - val_ca3-[0,5]: 253.6476 - val_ca3-[6,11]: 101.6085 - val_ca3-[12,17]: 20.1353 - val_ca3-[18,23]: 59.2473 - val_ca4-[0,5]: 213.4711 - val_ca4-[6,11]: 78.5540 - val_ca4-[12,17]: 17.2600 - val_ca4-[18,23]: 75.4691\n",
      "Epoch 113/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 28.9736 - ca1-[6,11]: 58.1780 - ca1-[12,17]: 12.3590 - ca1-[18,23]: 76.3517 - ca2-[0,5]: 280.6682 - ca2-[6,11]: 128.7411 - ca2-[12,17]: 62.9009 - ca2-[18,23]: 3.2887 - ca3-[0,5]: 259.2953 - ca3-[6,11]: 95.3950 - ca3-[12,17]: 30.4878 - ca3-[18,23]: 40.6200 - ca4-[0,5]: 210.5815 - ca4-[6,11]: 82.2772 - ca4-[12,17]: 15.7185 - ca4-[18,23]: 68.6349 - val_ca1-[0,5]: 153.1534 - val_ca1-[6,11]: 46.6449 - val_ca1-[12,17]: 20.5571 - val_ca1-[18,23]: 109.5417 - val_ca2-[0,5]: 364.4302 - val_ca2-[6,11]: 169.7133 - val_ca2-[12,17]: 41.4816 - val_ca2-[18,23]: 34.1246 - val_ca3-[0,5]: 258.1923 - val_ca3-[6,11]: 103.0527 - val_ca3-[12,17]: 20.6509 - val_ca3-[18,23]: 56.5204 - val_ca4-[0,5]: 216.2763 - val_ca4-[6,11]: 79.0301 - val_ca4-[12,17]: 17.3467 - val_ca4-[18,23]: 72.7570\n",
      "Epoch 114/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 26.3278 - ca1-[6,11]: 63.4307 - ca1-[12,17]: 12.1542 - ca1-[18,23]: 74.4270 - ca2-[0,5]: 283.8522 - ca2-[6,11]: 133.7710 - ca2-[12,17]: 67.9869 - ca2-[18,23]: 3.8873 - ca3-[0,5]: 263.0281 - ca3-[6,11]: 98.0592 - ca3-[12,17]: 29.6055 - ca3-[18,23]: 39.8962 - ca4-[0,5]: 213.3220 - ca4-[6,11]: 84.2556 - ca4-[12,17]: 15.4466 - ca4-[18,23]: 67.4497 - val_ca1-[0,5]: 157.3723 - val_ca1-[6,11]: 49.3604 - val_ca1-[12,17]: 19.7402 - val_ca1-[18,23]: 107.7364 - val_ca2-[0,5]: 373.0661 - val_ca2-[6,11]: 176.6719 - val_ca2-[12,17]: 42.9662 - val_ca2-[18,23]: 33.5851 - val_ca3-[0,5]: 264.5514 - val_ca3-[6,11]: 107.8629 - val_ca3-[12,17]: 20.9176 - val_ca3-[18,23]: 55.2832 - val_ca4-[0,5]: 220.6203 - val_ca4-[6,11]: 82.3632 - val_ca4-[12,17]: 17.1219 - val_ca4-[18,23]: 71.7922\n",
      "Epoch 115/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 33.3904 - ca1-[6,11]: 68.0316 - ca1-[12,17]: 11.1810 - ca1-[18,23]: 71.8193 - ca2-[0,5]: 289.7421 - ca2-[6,11]: 137.3938 - ca2-[12,17]: 66.7196 - ca2-[18,23]: 3.8424 - ca3-[0,5]: 269.1197 - ca3-[6,11]: 97.3447 - ca3-[12,17]: 31.6237 - ca3-[18,23]: 38.8498 - ca4-[0,5]: 216.0037 - ca4-[6,11]: 85.5018 - ca4-[12,17]: 15.9204 - ca4-[18,23]: 65.3928 - val_ca1-[0,5]: 159.7985 - val_ca1-[6,11]: 50.9651 - val_ca1-[12,17]: 19.4526 - val_ca1-[18,23]: 104.3758 - val_ca2-[0,5]: 378.8133 - val_ca2-[6,11]: 181.4192 - val_ca2-[12,17]: 44.6108 - val_ca2-[18,23]: 32.4957 - val_ca3-[0,5]: 268.4774 - val_ca3-[6,11]: 110.9322 - val_ca3-[12,17]: 21.5029 - val_ca3-[18,23]: 53.0514 - val_ca4-[0,5]: 222.7889 - val_ca4-[6,11]: 84.1883 - val_ca4-[12,17]: 17.2812 - val_ca4-[18,23]: 69.5849\n",
      "Epoch 116/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 30.6926 - ca1-[6,11]: 65.2809 - ca1-[12,17]: 11.0488 - ca1-[18,23]: 71.1743 - ca2-[0,5]: 283.1426 - ca2-[6,11]: 140.9991 - ca2-[12,17]: 70.7363 - ca2-[18,23]: 4.3416 - ca3-[0,5]: 272.5543 - ca3-[6,11]: 104.8481 - ca3-[12,17]: 28.8430 - ca3-[18,23]: 38.4392 - ca4-[0,5]: 219.7886 - ca4-[6,11]: 88.3640 - ca4-[12,17]: 16.3965 - ca4-[18,23]: 64.0069 - val_ca1-[0,5]: 163.1810 - val_ca1-[6,11]: 51.8299 - val_ca1-[12,17]: 18.1757 - val_ca1-[18,23]: 106.6183 - val_ca2-[0,5]: 385.8705 - val_ca2-[6,11]: 184.7903 - val_ca2-[12,17]: 46.4065 - val_ca2-[18,23]: 32.9421 - val_ca3-[0,5]: 273.5912 - val_ca3-[6,11]: 112.9323 - val_ca3-[12,17]: 21.7272 - val_ca3-[18,23]: 54.1698 - val_ca4-[0,5]: 225.9854 - val_ca4-[6,11]: 85.0245 - val_ca4-[12,17]: 16.8081 - val_ca4-[18,23]: 71.6191\n",
      "Epoch 117/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 31.5056 - ca1-[6,11]: 67.9238 - ca1-[12,17]: 10.8264 - ca1-[18,23]: 70.9934 - ca2-[0,5]: 301.7007 - ca2-[6,11]: 146.8435 - ca2-[12,17]: 73.0844 - ca2-[18,23]: 5.0248 - ca3-[0,5]: 280.3907 - ca3-[6,11]: 103.8541 - ca3-[12,17]: 30.9826 - ca3-[18,23]: 35.2489 - ca4-[0,5]: 222.0794 - ca4-[6,11]: 89.0619 - ca4-[12,17]: 17.2791 - ca4-[18,23]: 63.5562 - val_ca1-[0,5]: 165.9111 - val_ca1-[6,11]: 53.7643 - val_ca1-[12,17]: 18.8342 - val_ca1-[18,23]: 101.1308 - val_ca2-[0,5]: 392.0349 - val_ca2-[6,11]: 190.1581 - val_ca2-[12,17]: 48.3953 - val_ca2-[18,23]: 31.5365 - val_ca3-[0,5]: 277.9190 - val_ca3-[6,11]: 116.5094 - val_ca3-[12,17]: 22.9269 - val_ca3-[18,23]: 50.7860 - val_ca4-[0,5]: 228.3801 - val_ca4-[6,11]: 87.1875 - val_ca4-[12,17]: 17.6726 - val_ca4-[18,23]: 67.8689\n",
      "Epoch 118/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 28.6894 - ca1-[6,11]: 59.7647 - ca1-[12,17]: 10.2856 - ca1-[18,23]: 70.0503 - ca2-[0,5]: 307.7703 - ca2-[6,11]: 150.5449 - ca2-[12,17]: 73.3498 - ca2-[18,23]: 4.7305 - ca3-[0,5]: 283.6081 - ca3-[6,11]: 110.8152 - ca3-[12,17]: 31.4671 - ca3-[18,23]: 35.0017 - ca4-[0,5]: 225.2845 - ca4-[6,11]: 91.1962 - ca4-[12,17]: 17.1078 - ca4-[18,23]: 61.4098 - val_ca1-[0,5]: 169.3727 - val_ca1-[6,11]: 55.7690 - val_ca1-[12,17]: 18.4945 - val_ca1-[18,23]: 99.2320 - val_ca2-[0,5]: 399.3766 - val_ca2-[6,11]: 195.5380 - val_ca2-[12,17]: 50.4285 - val_ca2-[18,23]: 31.3780 - val_ca3-[0,5]: 283.2065 - val_ca3-[6,11]: 120.1127 - val_ca3-[12,17]: 23.6951 - val_ca3-[18,23]: 49.7030 - val_ca4-[0,5]: 231.6128 - val_ca4-[6,11]: 89.3659 - val_ca4-[12,17]: 17.8583 - val_ca4-[18,23]: 66.9165\n",
      "Epoch 119/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 35.0655 - ca1-[6,11]: 71.4650 - ca1-[12,17]: 10.3322 - ca1-[18,23]: 67.0392 - ca2-[0,5]: 303.4306 - ca2-[6,11]: 154.7826 - ca2-[12,17]: 79.8975 - ca2-[18,23]: 5.5287 - ca3-[0,5]: 288.4212 - ca3-[6,11]: 112.5378 - ca3-[12,17]: 33.3200 - ca3-[18,23]: 33.1136 - ca4-[0,5]: 228.5022 - ca4-[6,11]: 92.5118 - ca4-[12,17]: 17.5334 - ca4-[18,23]: 60.8031 - val_ca1-[0,5]: 172.4768 - val_ca1-[6,11]: 56.2120 - val_ca1-[12,17]: 18.3850 - val_ca1-[18,23]: 96.9212 - val_ca2-[0,5]: 406.2757 - val_ca2-[6,11]: 198.1484 - val_ca2-[12,17]: 53.0447 - val_ca2-[18,23]: 30.5433 - val_ca3-[0,5]: 288.0817 - val_ca3-[6,11]: 121.4861 - val_ca3-[12,17]: 24.8831 - val_ca3-[18,23]: 48.0616 - val_ca4-[0,5]: 234.3825 - val_ca4-[6,11]: 89.5500 - val_ca4-[12,17]: 18.3584 - val_ca4-[18,23]: 65.4695\n",
      "Epoch 120/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 30.2946 - ca1-[6,11]: 65.8879 - ca1-[12,17]: 9.7485 - ca1-[18,23]: 66.5900 - ca2-[0,5]: 298.6888 - ca2-[6,11]: 157.8187 - ca2-[12,17]: 67.7088 - ca2-[18,23]: 5.7688 - ca3-[0,5]: 292.6396 - ca3-[6,11]: 114.6437 - ca3-[12,17]: 31.9321 - ca3-[18,23]: 31.8381 - ca4-[0,5]: 230.8665 - ca4-[6,11]: 94.1207 - ca4-[12,17]: 18.2154 - ca4-[18,23]: 59.0535 - val_ca1-[0,5]: 176.2162 - val_ca1-[6,11]: 58.8549 - val_ca1-[12,17]: 17.6752 - val_ca1-[18,23]: 96.4575 - val_ca2-[0,5]: 414.0310 - val_ca2-[6,11]: 204.8189 - val_ca2-[12,17]: 54.4607 - val_ca2-[18,23]: 30.4101 - val_ca3-[0,5]: 293.7119 - val_ca3-[6,11]: 126.0759 - val_ca3-[12,17]: 25.1371 - val_ca3-[18,23]: 47.6336 - val_ca4-[0,5]: 237.8295 - val_ca4-[6,11]: 92.4885 - val_ca4-[12,17]: 18.0466 - val_ca4-[18,23]: 65.4987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 33.9136 - ca1-[6,11]: 65.9489 - ca1-[12,17]: 8.9073 - ca1-[18,23]: 60.7747 - ca2-[0,5]: 320.6262 - ca2-[6,11]: 162.5779 - ca2-[12,17]: 84.5636 - ca2-[18,23]: 7.3280 - ca3-[0,5]: 297.3896 - ca3-[6,11]: 117.6891 - ca3-[12,17]: 33.8779 - ca3-[18,23]: 30.5559 - ca4-[0,5]: 233.8768 - ca4-[6,11]: 96.4211 - ca4-[12,17]: 18.1045 - ca4-[18,23]: 58.4472 - val_ca1-[0,5]: 180.0576 - val_ca1-[6,11]: 60.6291 - val_ca1-[12,17]: 17.7931 - val_ca1-[18,23]: 92.5458 - val_ca2-[0,5]: 422.1938 - val_ca2-[6,11]: 210.2159 - val_ca2-[12,17]: 56.9923 - val_ca2-[18,23]: 30.1229 - val_ca3-[0,5]: 299.5837 - val_ca3-[6,11]: 129.5565 - val_ca3-[12,17]: 26.3694 - val_ca3-[18,23]: 45.5632 - val_ca4-[0,5]: 241.4176 - val_ca4-[6,11]: 94.3895 - val_ca4-[12,17]: 18.6281 - val_ca4-[18,23]: 63.0682\n",
      "Epoch 122/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 35.7919 - ca1-[6,11]: 75.9168 - ca1-[12,17]: 8.8977 - ca1-[18,23]: 60.8663 - ca2-[0,5]: 332.6875 - ca2-[6,11]: 167.9708 - ca2-[12,17]: 89.4285 - ca2-[18,23]: 7.9424 - ca3-[0,5]: 303.4769 - ca3-[6,11]: 117.4608 - ca3-[12,17]: 31.6984 - ca3-[18,23]: 29.4507 - ca4-[0,5]: 237.3748 - ca4-[6,11]: 98.3300 - ca4-[12,17]: 18.9260 - ca4-[18,23]: 56.3009 - val_ca1-[0,5]: 182.7141 - val_ca1-[6,11]: 62.0802 - val_ca1-[12,17]: 17.6953 - val_ca1-[18,23]: 90.4428 - val_ca2-[0,5]: 428.1304 - val_ca2-[6,11]: 214.6322 - val_ca2-[12,17]: 59.8678 - val_ca2-[18,23]: 29.8354 - val_ca3-[0,5]: 303.7259 - val_ca3-[6,11]: 132.3693 - val_ca3-[12,17]: 27.6949 - val_ca3-[18,23]: 44.3037 - val_ca4-[0,5]: 243.4894 - val_ca4-[6,11]: 95.7530 - val_ca4-[12,17]: 19.1378 - val_ca4-[18,23]: 61.8691\n",
      "Epoch 123/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 37.7817 - ca1-[6,11]: 77.3819 - ca1-[12,17]: 9.6244 - ca1-[18,23]: 57.3439 - ca2-[0,5]: 339.0482 - ca2-[6,11]: 173.9502 - ca2-[12,17]: 86.8081 - ca2-[18,23]: 8.3263 - ca3-[0,5]: 309.5562 - ca3-[6,11]: 121.6920 - ca3-[12,17]: 32.8462 - ca3-[18,23]: 29.0730 - ca4-[0,5]: 239.5183 - ca4-[6,11]: 99.6222 - ca4-[12,17]: 19.0730 - ca4-[18,23]: 55.9959 - val_ca1-[0,5]: 186.8337 - val_ca1-[6,11]: 63.4674 - val_ca1-[12,17]: 17.2921 - val_ca1-[18,23]: 88.1596 - val_ca2-[0,5]: 436.7196 - val_ca2-[6,11]: 218.5140 - val_ca2-[12,17]: 62.1341 - val_ca2-[18,23]: 29.8131 - val_ca3-[0,5]: 309.9908 - val_ca3-[6,11]: 134.8663 - val_ca3-[12,17]: 28.5472 - val_ca3-[18,23]: 43.1000 - val_ca4-[0,5]: 247.2743 - val_ca4-[6,11]: 96.8525 - val_ca4-[12,17]: 19.2185 - val_ca4-[18,23]: 60.6178\n",
      "Epoch 124/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 33.6781 - ca1-[6,11]: 84.6606 - ca1-[12,17]: 8.7927 - ca1-[18,23]: 55.2919 - ca2-[0,5]: 333.8596 - ca2-[6,11]: 176.8873 - ca2-[12,17]: 91.1638 - ca2-[18,23]: 9.1645 - ca3-[0,5]: 313.1017 - ca3-[6,11]: 129.9349 - ca3-[12,17]: 36.0540 - ca3-[18,23]: 28.6010 - ca4-[0,5]: 243.0405 - ca4-[6,11]: 101.6251 - ca4-[12,17]: 19.2977 - ca4-[18,23]: 55.1799 - val_ca1-[0,5]: 189.8925 - val_ca1-[6,11]: 65.1149 - val_ca1-[12,17]: 17.4327 - val_ca1-[18,23]: 87.0853 - val_ca2-[0,5]: 443.5668 - val_ca2-[6,11]: 223.4872 - val_ca2-[12,17]: 64.4205 - val_ca2-[18,23]: 29.7240 - val_ca3-[0,5]: 314.7955 - val_ca3-[6,11]: 138.0585 - val_ca3-[12,17]: 29.6486 - val_ca3-[18,23]: 42.4093 - val_ca4-[0,5]: 249.7172 - val_ca4-[6,11]: 98.4055 - val_ca4-[12,17]: 19.6666 - val_ca4-[18,23]: 60.1938\n",
      "Epoch 125/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 35.7535 - ca1-[6,11]: 82.3432 - ca1-[12,17]: 9.5466 - ca1-[18,23]: 52.5586 - ca2-[0,5]: 351.9794 - ca2-[6,11]: 181.1834 - ca2-[12,17]: 98.3943 - ca2-[18,23]: 9.2789 - ca3-[0,5]: 319.5544 - ca3-[6,11]: 133.1260 - ca3-[12,17]: 35.6027 - ca3-[18,23]: 27.7725 - ca4-[0,5]: 246.2067 - ca4-[6,11]: 103.3430 - ca4-[12,17]: 20.2112 - ca4-[18,23]: 53.0403 - val_ca1-[0,5]: 193.7667 - val_ca1-[6,11]: 66.9833 - val_ca1-[12,17]: 17.3707 - val_ca1-[18,23]: 83.8945 - val_ca2-[0,5]: 451.5697 - val_ca2-[6,11]: 228.8210 - val_ca2-[12,17]: 67.0883 - val_ca2-[18,23]: 29.4750 - val_ca3-[0,5]: 320.5888 - val_ca3-[6,11]: 141.5380 - val_ca3-[12,17]: 30.8594 - val_ca3-[18,23]: 40.6652 - val_ca4-[0,5]: 252.6113 - val_ca4-[6,11]: 99.9639 - val_ca4-[12,17]: 20.0121 - val_ca4-[18,23]: 58.2402\n",
      "Epoch 126/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 39.4792 - ca1-[6,11]: 77.8711 - ca1-[12,17]: 8.8606 - ca1-[18,23]: 52.7386 - ca2-[0,5]: 358.5470 - ca2-[6,11]: 188.1608 - ca2-[12,17]: 95.7210 - ca2-[18,23]: 11.0922 - ca3-[0,5]: 325.2243 - ca3-[6,11]: 134.8731 - ca3-[12,17]: 34.1388 - ca3-[18,23]: 26.6324 - ca4-[0,5]: 246.8686 - ca4-[6,11]: 104.4702 - ca4-[12,17]: 20.4499 - ca4-[18,23]: 52.0315 - val_ca1-[0,5]: 198.0180 - val_ca1-[6,11]: 69.4020 - val_ca1-[12,17]: 17.0159 - val_ca1-[18,23]: 82.7557 - val_ca2-[0,5]: 460.2477 - val_ca2-[6,11]: 235.0573 - val_ca2-[12,17]: 69.8686 - val_ca2-[18,23]: 29.6218 - val_ca3-[0,5]: 326.9212 - val_ca3-[6,11]: 145.7581 - val_ca3-[12,17]: 31.9950 - val_ca3-[18,23]: 40.0663 - val_ca4-[0,5]: 191.3098 - val_ca4-[6,11]: 69.7975 - val_ca4-[12,17]: 15.5957 - val_ca4-[18,23]: 67.2011\n",
      "Epoch 127/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 40.4389 - ca1-[6,11]: 88.2960 - ca1-[12,17]: 9.1320 - ca1-[18,23]: 52.1302 - ca2-[0,5]: 352.8476 - ca2-[6,11]: 186.6606 - ca2-[12,17]: 102.4726 - ca2-[18,23]: 11.1633 - ca3-[0,5]: 331.5250 - ca3-[6,11]: 137.7560 - ca3-[12,17]: 36.0147 - ca3-[18,23]: 25.7889 - ca4-[0,5]: 90.2440 - ca4-[6,11]: 33.2049 - ca4-[12,17]: 16.0694 - ca4-[18,23]: 66.9429 - val_ca1-[0,5]: 200.3361 - val_ca1-[6,11]: 71.3794 - val_ca1-[12,17]: 17.2309 - val_ca1-[18,23]: 80.2111 - val_ca2-[0,5]: 465.9904 - val_ca2-[6,11]: 240.4313 - val_ca2-[12,17]: 72.9711 - val_ca2-[18,23]: 29.4710 - val_ca3-[0,5]: 330.7775 - val_ca3-[6,11]: 149.3086 - val_ca3-[12,17]: 33.5649 - val_ca3-[18,23]: 38.6634 - val_ca4-[0,5]: 3.2332 - val_ca4-[6,11]: 12.9756 - val_ca4-[12,17]: 30.5530 - val_ca4-[18,23]: 71.5780\n",
      "Epoch 128/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 41.4099 - ca1-[6,11]: 88.1275 - ca1-[12,17]: 8.3575 - ca1-[18,23]: 49.5103 - ca2-[0,5]: 368.7935 - ca2-[6,11]: 198.1675 - ca2-[12,17]: 109.3070 - ca2-[18,23]: 12.8317 - ca3-[0,5]: 336.5426 - ca3-[6,11]: 142.6572 - ca3-[12,17]: 39.3335 - ca3-[18,23]: 23.9197 - ca4-[0,5]: 3.6127 - ca4-[6,11]: 8.5839 - ca4-[12,17]: 9.9303 - ca4-[18,23]: 51.8081 - val_ca1-[0,5]: 203.2032 - val_ca1-[6,11]: 72.9948 - val_ca1-[12,17]: 17.2415 - val_ca1-[18,23]: 79.2940 - val_ca2-[0,5]: 472.4393 - val_ca2-[6,11]: 245.2625 - val_ca2-[12,17]: 73.7020 - val_ca2-[18,23]: 29.7250 - val_ca3-[0,5]: 335.2807 - val_ca3-[6,11]: 152.4051 - val_ca3-[12,17]: 33.7527 - val_ca3-[18,23]: 38.2168 - val_ca4-[0,5]: 1.6974 - val_ca4-[6,11]: 5.5772 - val_ca4-[12,17]: 23.0811 - val_ca4-[18,23]: 66.9815\n",
      "Epoch 129/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 42.3942 - ca1-[6,11]: 89.6111 - ca1-[12,17]: 9.2145 - ca1-[18,23]: 49.5203 - ca2-[0,5]: 378.5697 - ca2-[6,11]: 202.0021 - ca2-[12,17]: 110.8467 - ca2-[18,23]: 14.2623 - ca3-[0,5]: 341.4557 - ca3-[6,11]: 148.6282 - ca3-[12,17]: 40.1381 - ca3-[18,23]: 24.8853 - ca4-[0,5]: 1.8428 - ca4-[6,11]: 3.9166 - ca4-[12,17]: 8.6803 - ca4-[18,23]: 48.3038 - val_ca1-[0,5]: 207.3201 - val_ca1-[6,11]: 76.0306 - val_ca1-[12,17]: 17.0398 - val_ca1-[18,23]: 77.6939 - val_ca2-[0,5]: 481.0580 - val_ca2-[6,11]: 253.0480 - val_ca2-[12,17]: 77.6849 - val_ca2-[18,23]: 29.8854 - val_ca3-[0,5]: 341.5250 - val_ca3-[6,11]: 157.7474 - val_ca3-[12,17]: 35.6039 - val_ca3-[18,23]: 37.4026 - val_ca4-[0,5]: 1.3431 - val_ca4-[6,11]: 4.1572 - val_ca4-[12,17]: 18.1444 - val_ca4-[18,23]: 60.7626\n",
      "Epoch 130/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 40.4182 - ca1-[6,11]: 86.4330 - ca1-[12,17]: 8.9525 - ca1-[18,23]: 49.3629 - ca2-[0,5]: 369.2137 - ca2-[6,11]: 208.7157 - ca2-[12,17]: 116.8520 - ca2-[18,23]: 14.0734 - ca3-[0,5]: 347.8660 - ca3-[6,11]: 146.7072 - ca3-[12,17]: 41.4417 - ca3-[18,23]: 23.7900 - ca4-[0,5]: 1.4156 - ca4-[6,11]: 2.5590 - ca4-[12,17]: 7.6266 - ca4-[18,23]: 46.3244 - val_ca1-[0,5]: 210.4147 - val_ca1-[6,11]: 77.4792 - val_ca1-[12,17]: 17.2251 - val_ca1-[18,23]: 76.4777 - val_ca2-[0,5]: 487.9286 - val_ca2-[6,11]: 257.1391 - val_ca2-[12,17]: 80.0708 - val_ca2-[18,23]: 30.0227 - val_ca3-[0,5]: 346.3586 - val_ca3-[6,11]: 160.3604 - val_ca3-[12,17]: 36.7622 - val_ca3-[18,23]: 36.7450 - val_ca4-[0,5]: 1.1056 - val_ca4-[6,11]: 3.4469 - val_ca4-[12,17]: 15.2548 - val_ca4-[18,23]: 56.2255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 45.9436 - ca1-[6,11]: 72.9572 - ca1-[12,17]: 8.7634 - ca1-[18,23]: 46.6750 - ca2-[0,5]: 385.9607 - ca2-[6,11]: 204.1992 - ca2-[12,17]: 114.5905 - ca2-[18,23]: 16.0757 - ca3-[0,5]: 352.1937 - ca3-[6,11]: 147.9476 - ca3-[12,17]: 41.1062 - ca3-[18,23]: 22.7818 - ca4-[0,5]: 1.1476 - ca4-[6,11]: 2.1126 - ca4-[12,17]: 5.9176 - ca4-[18,23]: 43.7697 - val_ca1-[0,5]: 214.0845 - val_ca1-[6,11]: 79.1369 - val_ca1-[12,17]: 16.9413 - val_ca1-[18,23]: 73.6592 - val_ca2-[0,5]: 495.7045 - val_ca2-[6,11]: 261.9895 - val_ca2-[12,17]: 83.1249 - val_ca2-[18,23]: 30.6840 - val_ca3-[0,5]: 351.9324 - val_ca3-[6,11]: 163.4722 - val_ca3-[12,17]: 38.0647 - val_ca3-[18,23]: 35.6399 - val_ca4-[0,5]: 0.9479 - val_ca4-[6,11]: 2.9401 - val_ca4-[12,17]: 13.5127 - val_ca4-[18,23]: 52.9033\n",
      "Epoch 132/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 34.6784 - ca1-[6,11]: 93.1243 - ca1-[12,17]: 9.3498 - ca1-[18,23]: 48.8558 - ca2-[0,5]: 399.1498 - ca2-[6,11]: 209.2330 - ca2-[12,17]: 121.1897 - ca2-[18,23]: 17.6631 - ca3-[0,5]: 357.2620 - ca3-[6,11]: 153.1102 - ca3-[12,17]: 40.6518 - ca3-[18,23]: 21.8108 - ca4-[0,5]: 0.9760 - ca4-[6,11]: 1.7040 - ca4-[12,17]: 6.0459 - ca4-[18,23]: 42.3408 - val_ca1-[0,5]: 218.5426 - val_ca1-[6,11]: 81.4171 - val_ca1-[12,17]: 17.4017 - val_ca1-[18,23]: 72.7101 - val_ca2-[0,5]: 504.9696 - val_ca2-[6,11]: 268.0984 - val_ca2-[12,17]: 85.9412 - val_ca2-[18,23]: 30.6559 - val_ca3-[0,5]: 358.6582 - val_ca3-[6,11]: 167.5392 - val_ca3-[12,17]: 39.5722 - val_ca3-[18,23]: 35.0148 - val_ca4-[0,5]: 0.8306 - val_ca4-[6,11]: 2.7511 - val_ca4-[12,17]: 12.6365 - val_ca4-[18,23]: 51.1642\n",
      "Epoch 133/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 42.1207 - ca1-[6,11]: 97.0427 - ca1-[12,17]: 9.6462 - ca1-[18,23]: 47.7715 - ca2-[0,5]: 375.3112 - ca2-[6,11]: 221.9139 - ca2-[12,17]: 128.5588 - ca2-[18,23]: 17.0441 - ca3-[0,5]: 363.0827 - ca3-[6,11]: 158.6798 - ca3-[12,17]: 42.8845 - ca3-[18,23]: 20.9498 - ca4-[0,5]: 0.8607 - ca4-[6,11]: 1.5113 - ca4-[12,17]: 5.3009 - ca4-[18,23]: 40.9218 - val_ca1-[0,5]: 221.9584 - val_ca1-[6,11]: 83.1698 - val_ca1-[12,17]: 17.2902 - val_ca1-[18,23]: 70.0163 - val_ca2-[0,5]: 512.3281 - val_ca2-[6,11]: 272.9433 - val_ca2-[12,17]: 88.0258 - val_ca2-[18,23]: 31.2804 - val_ca3-[0,5]: 363.8712 - val_ca3-[6,11]: 170.6774 - val_ca3-[12,17]: 40.4189 - val_ca3-[18,23]: 33.9398 - val_ca4-[0,5]: 0.7425 - val_ca4-[6,11]: 2.5258 - val_ca4-[12,17]: 11.7426 - val_ca4-[18,23]: 48.1208\n",
      "Epoch 134/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 47.5370 - ca1-[6,11]: 83.4670 - ca1-[12,17]: 9.5302 - ca1-[18,23]: 41.2266 - ca2-[0,5]: 413.1749 - ca2-[6,11]: 229.1403 - ca2-[12,17]: 124.8627 - ca2-[18,23]: 20.9926 - ca3-[0,5]: 371.8054 - ca3-[6,11]: 165.3849 - ca3-[12,17]: 43.7089 - ca3-[18,23]: 21.3804 - ca4-[0,5]: 0.7629 - ca4-[6,11]: 1.3501 - ca4-[12,17]: 4.3474 - ca4-[18,23]: 38.2082 - val_ca1-[0,5]: 225.2617 - val_ca1-[6,11]: 86.3708 - val_ca1-[12,17]: 17.4281 - val_ca1-[18,23]: 68.9163 - val_ca2-[0,5]: 519.6010 - val_ca2-[6,11]: 280.9598 - val_ca2-[12,17]: 92.1120 - val_ca2-[18,23]: 31.9932 - val_ca3-[0,5]: 368.9659 - val_ca3-[6,11]: 176.1808 - val_ca3-[12,17]: 42.4545 - val_ca3-[18,23]: 33.6424 - val_ca4-[0,5]: 0.6859 - val_ca4-[6,11]: 2.3330 - val_ca4-[12,17]: 10.7207 - val_ca4-[18,23]: 46.5522\n",
      "Epoch 135/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 44.1575 - ca1-[6,11]: 103.8724 - ca1-[12,17]: 10.8283 - ca1-[18,23]: 40.9106 - ca2-[0,5]: 420.2821 - ca2-[6,11]: 231.8278 - ca2-[12,17]: 138.1380 - ca2-[18,23]: 20.8868 - ca3-[0,5]: 375.4251 - ca3-[6,11]: 162.3344 - ca3-[12,17]: 45.0101 - ca3-[18,23]: 20.8699 - ca4-[0,5]: 0.6771 - ca4-[6,11]: 1.1099 - ca4-[12,17]: 4.1635 - ca4-[18,23]: 36.2061 - val_ca1-[0,5]: 229.7688 - val_ca1-[6,11]: 88.0595 - val_ca1-[12,17]: 17.9021 - val_ca1-[18,23]: 67.0864 - val_ca2-[0,5]: 528.8444 - val_ca2-[6,11]: 286.0782 - val_ca2-[12,17]: 95.3194 - val_ca2-[18,23]: 32.7826 - val_ca3-[0,5]: 375.6974 - val_ca3-[6,11]: 179.4335 - val_ca3-[12,17]: 44.1705 - val_ca3-[18,23]: 33.0431 - val_ca4-[0,5]: 0.6283 - val_ca4-[6,11]: 2.1443 - val_ca4-[12,17]: 10.2002 - val_ca4-[18,23]: 44.8044\n",
      "Epoch 136/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 49.6911 - ca1-[6,11]: 104.0197 - ca1-[12,17]: 10.0695 - ca1-[18,23]: 38.5273 - ca2-[0,5]: 420.9034 - ca2-[6,11]: 238.5591 - ca2-[12,17]: 133.4436 - ca2-[18,23]: 22.3250 - ca3-[0,5]: 379.5469 - ca3-[6,11]: 170.8664 - ca3-[12,17]: 46.3410 - ca3-[18,23]: 20.0296 - ca4-[0,5]: 0.6376 - ca4-[6,11]: 1.0131 - ca4-[12,17]: 3.4604 - ca4-[18,23]: 35.2149 - val_ca1-[0,5]: 233.3584 - val_ca1-[6,11]: 89.2450 - val_ca1-[12,17]: 18.1826 - val_ca1-[18,23]: 66.8907 - val_ca2-[0,5]: 536.6932 - val_ca2-[6,11]: 289.7542 - val_ca2-[12,17]: 98.9013 - val_ca2-[18,23]: 33.1416 - val_ca3-[0,5]: 381.2692 - val_ca3-[6,11]: 181.6859 - val_ca3-[12,17]: 46.0018 - val_ca3-[18,23]: 32.9597 - val_ca4-[0,5]: 0.5885 - val_ca4-[6,11]: 2.0081 - val_ca4-[12,17]: 9.5235 - val_ca4-[18,23]: 43.7592\n",
      "Epoch 137/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 52.7190 - ca1-[6,11]: 105.9560 - ca1-[12,17]: 11.1429 - ca1-[18,23]: 34.8053 - ca2-[0,5]: 431.3623 - ca2-[6,11]: 235.1545 - ca2-[12,17]: 138.2204 - ca2-[18,23]: 25.2864 - ca3-[0,5]: 386.1515 - ca3-[6,11]: 169.4013 - ca3-[12,17]: 48.3510 - ca3-[18,23]: 19.4084 - ca4-[0,5]: 0.5956 - ca4-[6,11]: 0.9051 - ca4-[12,17]: 3.3406 - ca4-[18,23]: 33.7792 - val_ca1-[0,5]: 237.5531 - val_ca1-[6,11]: 92.1072 - val_ca1-[12,17]: 18.3494 - val_ca1-[18,23]: 65.4547 - val_ca2-[0,5]: 545.4221 - val_ca2-[6,11]: 296.8975 - val_ca2-[12,17]: 101.6333 - val_ca2-[18,23]: 33.7751 - val_ca3-[0,5]: 387.5720 - val_ca3-[6,11]: 186.5659 - val_ca3-[12,17]: 47.3152 - val_ca3-[18,23]: 32.4544 - val_ca4-[0,5]: 0.5422 - val_ca4-[6,11]: 1.8912 - val_ca4-[12,17]: 8.9129 - val_ca4-[18,23]: 42.2007\n",
      "Epoch 138/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 53.9037 - ca1-[6,11]: 111.6042 - ca1-[12,17]: 11.0691 - ca1-[18,23]: 37.2543 - ca2-[0,5]: 430.1081 - ca2-[6,11]: 249.7631 - ca2-[12,17]: 151.8591 - ca2-[18,23]: 25.5496 - ca3-[0,5]: 392.9636 - ca3-[6,11]: 180.7258 - ca3-[12,17]: 49.8228 - ca3-[18,23]: 19.3160 - ca4-[0,5]: 0.5406 - ca4-[6,11]: 0.9066 - ca4-[12,17]: 2.9994 - ca4-[18,23]: 32.1814 - val_ca1-[0,5]: 240.8570 - val_ca1-[6,11]: 94.3847 - val_ca1-[12,17]: 18.6950 - val_ca1-[18,23]: 64.0942 - val_ca2-[0,5]: 552.6991 - val_ca2-[6,11]: 302.8455 - val_ca2-[12,17]: 104.6792 - val_ca2-[18,23]: 33.8536 - val_ca3-[0,5]: 392.6795 - val_ca3-[6,11]: 190.5286 - val_ca3-[12,17]: 48.8760 - val_ca3-[18,23]: 31.6794 - val_ca4-[0,5]: 0.5349 - val_ca4-[6,11]: 1.7605 - val_ca4-[12,17]: 8.4649 - val_ca4-[18,23]: 40.7079\n",
      "Epoch 139/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 50.4596 - ca1-[6,11]: 112.5809 - ca1-[12,17]: 11.6165 - ca1-[18,23]: 34.7991 - ca2-[0,5]: 449.2659 - ca2-[6,11]: 256.5834 - ca2-[12,17]: 147.7380 - ca2-[18,23]: 28.4597 - ca3-[0,5]: 399.0175 - ca3-[6,11]: 182.8805 - ca3-[12,17]: 51.7408 - ca3-[18,23]: 19.2759 - ca4-[0,5]: 0.5122 - ca4-[6,11]: 0.7681 - ca4-[12,17]: 2.7598 - ca4-[18,23]: 30.4126 - val_ca1-[0,5]: 245.0159 - val_ca1-[6,11]: 95.8350 - val_ca1-[12,17]: 18.8708 - val_ca1-[18,23]: 60.7453 - val_ca2-[0,5]: 561.3857 - val_ca2-[6,11]: 307.3077 - val_ca2-[12,17]: 107.8967 - val_ca2-[18,23]: 36.1187 - val_ca3-[0,5]: 398.9540 - val_ca3-[6,11]: 193.3177 - val_ca3-[12,17]: 50.4529 - val_ca3-[18,23]: 31.1598 - val_ca4-[0,5]: 0.5095 - val_ca4-[6,11]: 1.6994 - val_ca4-[12,17]: 7.8086 - val_ca4-[18,23]: 38.4329\n",
      "Epoch 140/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 58.8561 - ca1-[6,11]: 109.8791 - ca1-[12,17]: 11.9963 - ca1-[18,23]: 36.1161 - ca2-[0,5]: 453.2907 - ca2-[6,11]: 261.1679 - ca2-[12,17]: 156.8602 - ca2-[18,23]: 31.3439 - ca3-[0,5]: 407.4006 - ca3-[6,11]: 185.3191 - ca3-[12,17]: 52.8976 - ca3-[18,23]: 18.1908 - ca4-[0,5]: 0.5000 - ca4-[6,11]: 0.7128 - ca4-[12,17]: 2.5637 - ca4-[18,23]: 28.9514 - val_ca1-[0,5]: 249.2768 - val_ca1-[6,11]: 98.8016 - val_ca1-[12,17]: 19.4105 - val_ca1-[18,23]: 60.5718 - val_ca2-[0,5]: 570.2878 - val_ca2-[6,11]: 314.6353 - val_ca2-[12,17]: 111.8784 - val_ca2-[18,23]: 35.6437 - val_ca3-[0,5]: 405.3783 - val_ca3-[6,11]: 198.3391 - val_ca3-[12,17]: 52.6024 - val_ca3-[18,23]: 30.6285 - val_ca4-[0,5]: 0.4962 - val_ca4-[6,11]: 1.6049 - val_ca4-[12,17]: 7.4017 - val_ca4-[18,23]: 37.5202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 55.3342 - ca1-[6,11]: 119.0081 - ca1-[12,17]: 12.1784 - ca1-[18,23]: 33.6404 - ca2-[0,5]: 464.1176 - ca2-[6,11]: 266.7315 - ca2-[12,17]: 155.5361 - ca2-[18,23]: 31.9443 - ca3-[0,5]: 411.8184 - ca3-[6,11]: 188.5628 - ca3-[12,17]: 54.6406 - ca3-[18,23]: 17.7581 - ca4-[0,5]: 0.4781 - ca4-[6,11]: 0.5872 - ca4-[12,17]: 2.4255 - ca4-[18,23]: 28.0421 - val_ca1-[0,5]: 254.6473 - val_ca1-[6,11]: 101.1414 - val_ca1-[12,17]: 19.6985 - val_ca1-[18,23]: 55.4760 - val_ca2-[0,5]: 581.1134 - val_ca2-[6,11]: 320.9859 - val_ca2-[12,17]: 115.2584 - val_ca2-[18,23]: 37.2054 - val_ca3-[0,5]: 413.3551 - val_ca3-[6,11]: 202.5480 - val_ca3-[12,17]: 54.3113 - val_ca3-[18,23]: 28.9133 - val_ca4-[0,5]: 0.4802 - val_ca4-[6,11]: 1.5083 - val_ca4-[12,17]: 6.9478 - val_ca4-[18,23]: 33.9711\n",
      "Epoch 142/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 58.9915 - ca1-[6,11]: 117.0534 - ca1-[12,17]: 11.9645 - ca1-[18,23]: 30.6784 - ca2-[0,5]: 468.2314 - ca2-[6,11]: 274.2959 - ca2-[12,17]: 158.2740 - ca2-[18,23]: 34.3382 - ca3-[0,5]: 419.4579 - ca3-[6,11]: 192.2130 - ca3-[12,17]: 55.1124 - ca3-[18,23]: 17.6315 - ca4-[0,5]: 0.4630 - ca4-[6,11]: 0.5476 - ca4-[12,17]: 2.3388 - ca4-[18,23]: 26.6288 - val_ca1-[0,5]: 257.6409 - val_ca1-[6,11]: 103.4567 - val_ca1-[12,17]: 19.5550 - val_ca1-[18,23]: 55.2321 - val_ca2-[0,5]: 587.9185 - val_ca2-[6,11]: 327.0596 - val_ca2-[12,17]: 119.2858 - val_ca2-[18,23]: 39.1951 - val_ca3-[0,5]: 418.0316 - val_ca3-[6,11]: 206.5680 - val_ca3-[12,17]: 56.1526 - val_ca3-[18,23]: 29.6676 - val_ca4-[0,5]: 0.4695 - val_ca4-[6,11]: 1.4455 - val_ca4-[12,17]: 6.4151 - val_ca4-[18,23]: 33.8074\n",
      "Epoch 143/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 57.6917 - ca1-[6,11]: 120.9232 - ca1-[12,17]: 13.5068 - ca1-[18,23]: 30.7588 - ca2-[0,5]: 475.7976 - ca2-[6,11]: 278.1458 - ca2-[12,17]: 165.3982 - ca2-[18,23]: 35.0127 - ca3-[0,5]: 426.9089 - ca3-[6,11]: 197.7771 - ca3-[12,17]: 56.4088 - ca3-[18,23]: 18.5451 - ca4-[0,5]: 0.4671 - ca4-[6,11]: 0.6527 - ca4-[12,17]: 2.4600 - ca4-[18,23]: 25.5334 - val_ca1-[0,5]: 260.6811 - val_ca1-[6,11]: 106.0383 - val_ca1-[12,17]: 20.8013 - val_ca1-[18,23]: 56.0094 - val_ca2-[0,5]: 594.8976 - val_ca2-[6,11]: 333.8280 - val_ca2-[12,17]: 123.0083 - val_ca2-[18,23]: 40.0114 - val_ca3-[0,5]: 422.8351 - val_ca3-[6,11]: 211.0910 - val_ca3-[12,17]: 58.4749 - val_ca3-[18,23]: 30.2623 - val_ca4-[0,5]: 0.4559 - val_ca4-[6,11]: 1.3913 - val_ca4-[12,17]: 6.3809 - val_ca4-[18,23]: 34.0373\n",
      "Epoch 144/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 58.8919 - ca1-[6,11]: 118.3675 - ca1-[12,17]: 14.3281 - ca1-[18,23]: 29.6596 - ca2-[0,5]: 419.7635 - ca2-[6,11]: 285.8051 - ca2-[12,17]: 161.9629 - ca2-[18,23]: 36.8016 - ca3-[0,5]: 428.2962 - ca3-[6,11]: 198.0336 - ca3-[12,17]: 58.4776 - ca3-[18,23]: 18.2622 - ca4-[0,5]: 0.4481 - ca4-[6,11]: 0.5622 - ca4-[12,17]: 2.0134 - ca4-[18,23]: 24.7282 - val_ca1-[0,5]: 265.4267 - val_ca1-[6,11]: 108.8089 - val_ca1-[12,17]: 21.1951 - val_ca1-[18,23]: 54.5864 - val_ca2-[0,5]: 604.7170 - val_ca2-[6,11]: 340.7445 - val_ca2-[12,17]: 125.3035 - val_ca2-[18,23]: 40.6422 - val_ca3-[0,5]: 429.9461 - val_ca3-[6,11]: 215.7749 - val_ca3-[12,17]: 59.6323 - val_ca3-[18,23]: 29.7350 - val_ca4-[0,5]: 0.4499 - val_ca4-[6,11]: 1.3197 - val_ca4-[12,17]: 6.1599 - val_ca4-[18,23]: 32.6756\n",
      "Epoch 145/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 62.6170 - ca1-[6,11]: 120.4331 - ca1-[12,17]: 13.4361 - ca1-[18,23]: 30.4937 - ca2-[0,5]: 494.6152 - ca2-[6,11]: 291.3502 - ca2-[12,17]: 176.6839 - ca2-[18,23]: 40.1026 - ca3-[0,5]: 435.6481 - ca3-[6,11]: 206.6736 - ca3-[12,17]: 61.8081 - ca3-[18,23]: 17.2416 - ca4-[0,5]: 0.4355 - ca4-[6,11]: 0.4612 - ca4-[12,17]: 2.0140 - ca4-[18,23]: 23.5955 - val_ca1-[0,5]: 269.3431 - val_ca1-[6,11]: 111.0497 - val_ca1-[12,17]: 21.8782 - val_ca1-[18,23]: 53.3258 - val_ca2-[0,5]: 613.0208 - val_ca2-[6,11]: 346.7531 - val_ca2-[12,17]: 129.5853 - val_ca2-[18,23]: 41.8642 - val_ca3-[0,5]: 435.8793 - val_ca3-[6,11]: 219.7388 - val_ca3-[12,17]: 61.9935 - val_ca3-[18,23]: 29.5967 - val_ca4-[0,5]: 0.4408 - val_ca4-[6,11]: 1.2820 - val_ca4-[12,17]: 5.9029 - val_ca4-[18,23]: 31.6376\n",
      "Epoch 146/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 56.3640 - ca1-[6,11]: 128.0285 - ca1-[12,17]: 15.1336 - ca1-[18,23]: 26.9029 - ca2-[0,5]: 485.0637 - ca2-[6,11]: 296.5376 - ca2-[12,17]: 175.6791 - ca2-[18,23]: 39.7398 - ca3-[0,5]: 441.9141 - ca3-[6,11]: 212.1237 - ca3-[12,17]: 62.9122 - ca3-[18,23]: 18.2564 - ca4-[0,5]: 0.4262 - ca4-[6,11]: 0.5265 - ca4-[12,17]: 1.5736 - ca4-[18,23]: 22.1875 - val_ca1-[0,5]: 274.0879 - val_ca1-[6,11]: 113.5885 - val_ca1-[12,17]: 22.4789 - val_ca1-[18,23]: 51.4117 - val_ca2-[0,5]: 622.7649 - val_ca2-[6,11]: 353.3209 - val_ca2-[12,17]: 133.7242 - val_ca2-[18,23]: 43.2456 - val_ca3-[0,5]: 442.9701 - val_ca3-[6,11]: 224.1412 - val_ca3-[12,17]: 64.2389 - val_ca3-[18,23]: 29.2381 - val_ca4-[0,5]: 0.4425 - val_ca4-[6,11]: 1.2276 - val_ca4-[12,17]: 5.5945 - val_ca4-[18,23]: 30.6175\n",
      "Epoch 147/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 65.2405 - ca1-[6,11]: 134.5522 - ca1-[12,17]: 14.7345 - ca1-[18,23]: 25.8975 - ca2-[0,5]: 510.1961 - ca2-[6,11]: 304.1512 - ca2-[12,17]: 186.7115 - ca2-[18,23]: 43.3138 - ca3-[0,5]: 446.4280 - ca3-[6,11]: 213.9376 - ca3-[12,17]: 63.5407 - ca3-[18,23]: 18.6606 - ca4-[0,5]: 0.4303 - ca4-[6,11]: 0.4209 - ca4-[12,17]: 1.6035 - ca4-[18,23]: 20.7059 - val_ca1-[0,5]: 278.6995 - val_ca1-[6,11]: 116.5352 - val_ca1-[12,17]: 23.0920 - val_ca1-[18,23]: 51.4374 - val_ca2-[0,5]: 632.3620 - val_ca2-[6,11]: 360.6175 - val_ca2-[12,17]: 138.0287 - val_ca2-[18,23]: 44.1253 - val_ca3-[0,5]: 449.8851 - val_ca3-[6,11]: 229.0976 - val_ca3-[12,17]: 66.5640 - val_ca3-[18,23]: 29.5087 - val_ca4-[0,5]: 0.4363 - val_ca4-[6,11]: 1.1781 - val_ca4-[12,17]: 5.2817 - val_ca4-[18,23]: 29.9472\n",
      "Epoch 148/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 58.7677 - ca1-[6,11]: 127.5750 - ca1-[12,17]: 16.1885 - ca1-[18,23]: 28.1322 - ca2-[0,5]: 464.3374 - ca2-[6,11]: 308.8723 - ca2-[12,17]: 183.0921 - ca2-[18,23]: 47.5227 - ca3-[0,5]: 452.5240 - ca3-[6,11]: 218.6334 - ca3-[12,17]: 65.6944 - ca3-[18,23]: 17.8422 - ca4-[0,5]: 0.4229 - ca4-[6,11]: 0.3874 - ca4-[12,17]: 1.3526 - ca4-[18,23]: 20.7618 - val_ca1-[0,5]: 281.5128 - val_ca1-[6,11]: 119.3870 - val_ca1-[12,17]: 23.5694 - val_ca1-[18,23]: 50.4113 - val_ca2-[0,5]: 639.0109 - val_ca2-[6,11]: 367.5663 - val_ca2-[12,17]: 141.2211 - val_ca2-[18,23]: 45.2742 - val_ca3-[0,5]: 454.3853 - val_ca3-[6,11]: 233.8217 - val_ca3-[12,17]: 68.2291 - val_ca3-[18,23]: 29.4329 - val_ca4-[0,5]: 0.4284 - val_ca4-[6,11]: 1.1456 - val_ca4-[12,17]: 5.1448 - val_ca4-[18,23]: 29.3261\n",
      "Epoch 149/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 52.0420 - ca1-[6,11]: 135.7739 - ca1-[12,17]: 16.5105 - ca1-[18,23]: 24.9490 - ca2-[0,5]: 507.8448 - ca2-[6,11]: 292.4349 - ca2-[12,17]: 180.3267 - ca2-[18,23]: 48.7553 - ca3-[0,5]: 461.1420 - ca3-[6,11]: 222.2730 - ca3-[12,17]: 68.2487 - ca3-[18,23]: 18.5286 - ca4-[0,5]: 0.4182 - ca4-[6,11]: 0.4013 - ca4-[12,17]: 1.3486 - ca4-[18,23]: 19.8534 - val_ca1-[0,5]: 286.7262 - val_ca1-[6,11]: 121.4741 - val_ca1-[12,17]: 24.2432 - val_ca1-[18,23]: 50.1518 - val_ca2-[0,5]: 649.4556 - val_ca2-[6,11]: 373.5349 - val_ca2-[12,17]: 145.2302 - val_ca2-[18,23]: 47.8610 - val_ca3-[0,5]: 462.0550 - val_ca3-[6,11]: 237.6810 - val_ca3-[12,17]: 70.4275 - val_ca3-[18,23]: 30.4783 - val_ca4-[0,5]: 0.4293 - val_ca4-[6,11]: 1.0835 - val_ca4-[12,17]: 4.8861 - val_ca4-[18,23]: 28.9536\n",
      "Epoch 150/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 66.3876 - ca1-[6,11]: 141.5294 - ca1-[12,17]: 17.9905 - ca1-[18,23]: 25.5920 - ca2-[0,5]: 534.0275 - ca2-[6,11]: 323.3578 - ca2-[12,17]: 198.7774 - ca2-[18,23]: 51.4906 - ca3-[0,5]: 466.1850 - ca3-[6,11]: 226.1695 - ca3-[12,17]: 69.6444 - ca3-[18,23]: 18.5241 - ca4-[0,5]: 0.4164 - ca4-[6,11]: 0.4027 - ca4-[12,17]: 1.2746 - ca4-[18,23]: 18.9952 - val_ca1-[0,5]: 289.7729 - val_ca1-[6,11]: 124.0828 - val_ca1-[12,17]: 25.1630 - val_ca1-[18,23]: 47.9928 - val_ca2-[0,5]: 656.6062 - val_ca2-[6,11]: 379.9922 - val_ca2-[12,17]: 149.3136 - val_ca2-[18,23]: 48.6507 - val_ca3-[0,5]: 466.9467 - val_ca3-[6,11]: 242.0378 - val_ca3-[12,17]: 72.7762 - val_ca3-[18,23]: 29.6772 - val_ca4-[0,5]: 0.4226 - val_ca4-[6,11]: 1.0725 - val_ca4-[12,17]: 4.7945 - val_ca4-[18,23]: 27.3656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 67.6870 - ca1-[6,11]: 139.8632 - ca1-[12,17]: 18.5587 - ca1-[18,23]: 22.7672 - ca2-[0,5]: 523.3109 - ca2-[6,11]: 327.2783 - ca2-[12,17]: 207.5481 - ca2-[18,23]: 53.3467 - ca3-[0,5]: 474.3253 - ca3-[6,11]: 227.0186 - ca3-[12,17]: 71.3345 - ca3-[18,23]: 19.5454 - ca4-[0,5]: 0.4124 - ca4-[6,11]: 0.3224 - ca4-[12,17]: 1.3216 - ca4-[18,23]: 17.8478 - val_ca1-[0,5]: 294.1002 - val_ca1-[6,11]: 126.3742 - val_ca1-[12,17]: 26.0311 - val_ca1-[18,23]: 46.4760 - val_ca2-[0,5]: 665.7158 - val_ca2-[6,11]: 386.3422 - val_ca2-[12,17]: 153.9884 - val_ca2-[18,23]: 50.1430 - val_ca3-[0,5]: 473.4908 - val_ca3-[6,11]: 246.1951 - val_ca3-[12,17]: 75.4177 - val_ca3-[18,23]: 29.5475 - val_ca4-[0,5]: 0.4219 - val_ca4-[6,11]: 0.9906 - val_ca4-[12,17]: 4.5421 - val_ca4-[18,23]: 26.2661\n",
      "Epoch 152/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 47.0472 - ca1-[6,11]: 136.9808 - ca1-[12,17]: 19.2982 - ca1-[18,23]: 22.6447 - ca2-[0,5]: 553.8662 - ca2-[6,11]: 334.2998 - ca2-[12,17]: 199.6198 - ca2-[18,23]: 55.6499 - ca3-[0,5]: 481.9210 - ca3-[6,11]: 237.7423 - ca3-[12,17]: 72.1313 - ca3-[18,23]: 19.6896 - ca4-[0,5]: 0.4128 - ca4-[6,11]: 0.3511 - ca4-[12,17]: 1.1936 - ca4-[18,23]: 17.9003 - val_ca1-[0,5]: 297.8871 - val_ca1-[6,11]: 129.2007 - val_ca1-[12,17]: 26.7611 - val_ca1-[18,23]: 44.9724 - val_ca2-[0,5]: 674.0747 - val_ca2-[6,11]: 393.2555 - val_ca2-[12,17]: 158.4385 - val_ca2-[18,23]: 52.2826 - val_ca3-[0,5]: 479.3622 - val_ca3-[6,11]: 250.8869 - val_ca3-[12,17]: 77.8640 - val_ca3-[18,23]: 29.7630 - val_ca4-[0,5]: 0.4159 - val_ca4-[6,11]: 0.9961 - val_ca4-[12,17]: 4.4458 - val_ca4-[18,23]: 25.1783\n",
      "Epoch 153/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 75.6181 - ca1-[6,11]: 134.9214 - ca1-[12,17]: 20.5288 - ca1-[18,23]: 21.3119 - ca2-[0,5]: 562.0838 - ca2-[6,11]: 342.5746 - ca2-[12,17]: 205.7067 - ca2-[18,23]: 58.9085 - ca3-[0,5]: 488.0790 - ca3-[6,11]: 239.3651 - ca3-[12,17]: 74.9548 - ca3-[18,23]: 20.0499 - ca4-[0,5]: 0.4074 - ca4-[6,11]: 0.3045 - ca4-[12,17]: 1.0268 - ca4-[18,23]: 16.7273 - val_ca1-[0,5]: 303.4337 - val_ca1-[6,11]: 131.8531 - val_ca1-[12,17]: 27.6881 - val_ca1-[18,23]: 44.4163 - val_ca2-[0,5]: 685.0673 - val_ca2-[6,11]: 400.1638 - val_ca2-[12,17]: 162.3369 - val_ca2-[18,23]: 53.8916 - val_ca3-[0,5]: 487.4522 - val_ca3-[6,11]: 255.4890 - val_ca3-[12,17]: 80.1042 - val_ca3-[18,23]: 30.1355 - val_ca4-[0,5]: 0.4174 - val_ca4-[6,11]: 0.9493 - val_ca4-[12,17]: 4.3821 - val_ca4-[18,23]: 24.7117\n",
      "Epoch 154/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 71.6679 - ca1-[6,11]: 153.0810 - ca1-[12,17]: 20.8154 - ca1-[18,23]: 21.2668 - ca2-[0,5]: 523.5435 - ca2-[6,11]: 349.3619 - ca2-[12,17]: 219.5214 - ca2-[18,23]: 57.8713 - ca3-[0,5]: 473.6634 - ca3-[6,11]: 245.9690 - ca3-[12,17]: 78.7197 - ca3-[18,23]: 20.5193 - ca4-[0,5]: 0.4032 - ca4-[6,11]: 0.2902 - ca4-[12,17]: 1.0288 - ca4-[18,23]: 15.5206 - val_ca1-[0,5]: 307.4312 - val_ca1-[6,11]: 135.9394 - val_ca1-[12,17]: 28.5345 - val_ca1-[18,23]: 43.5582 - val_ca2-[0,5]: 693.7434 - val_ca2-[6,11]: 409.5107 - val_ca2-[12,17]: 167.5641 - val_ca2-[18,23]: 56.4642 - val_ca3-[0,5]: 493.5881 - val_ca3-[6,11]: 262.0624 - val_ca3-[12,17]: 83.0147 - val_ca3-[18,23]: 30.8782 - val_ca4-[0,5]: 0.4121 - val_ca4-[6,11]: 0.9106 - val_ca4-[12,17]: 4.0847 - val_ca4-[18,23]: 24.0988\n",
      "Epoch 155/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 73.0246 - ca1-[6,11]: 142.3686 - ca1-[12,17]: 20.8702 - ca1-[18,23]: 19.5606 - ca2-[0,5]: 514.9387 - ca2-[6,11]: 354.0348 - ca2-[12,17]: 224.5990 - ca2-[18,23]: 60.6028 - ca3-[0,5]: 499.5490 - ca3-[6,11]: 249.2126 - ca3-[12,17]: 80.7139 - ca3-[18,23]: 21.0404 - ca4-[0,5]: 0.4017 - ca4-[6,11]: 0.2833 - ca4-[12,17]: 1.2882 - ca4-[18,23]: 15.6770 - val_ca1-[0,5]: 311.7126 - val_ca1-[6,11]: 138.4422 - val_ca1-[12,17]: 27.5855 - val_ca1-[18,23]: 42.5984 - val_ca2-[0,5]: 702.8784 - val_ca2-[6,11]: 416.2369 - val_ca2-[12,17]: 173.6997 - val_ca2-[18,23]: 58.5951 - val_ca3-[0,5]: 500.0910 - val_ca3-[6,11]: 266.4910 - val_ca3-[12,17]: 85.5614 - val_ca3-[18,23]: 31.3331 - val_ca4-[0,5]: 0.4027 - val_ca4-[6,11]: 0.8705 - val_ca4-[12,17]: 3.1394 - val_ca4-[18,23]: 23.6261\n",
      "Epoch 156/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 72.3902 - ca1-[6,11]: 155.8276 - ca1-[12,17]: 22.6810 - ca1-[18,23]: 19.6192 - ca2-[0,5]: 579.5069 - ca2-[6,11]: 364.1228 - ca2-[12,17]: 216.3655 - ca2-[18,23]: 66.0664 - ca3-[0,5]: 508.2493 - ca3-[6,11]: 240.4507 - ca3-[12,17]: 81.7030 - ca3-[18,23]: 20.6419 - ca4-[0,5]: 0.3970 - ca4-[6,11]: 0.3034 - ca4-[12,17]: 0.9204 - ca4-[18,23]: 14.8465 - val_ca1-[0,5]: 317.3608 - val_ca1-[6,11]: 140.7085 - val_ca1-[12,17]: 29.9040 - val_ca1-[18,23]: 41.1618 - val_ca2-[0,5]: 714.0400 - val_ca2-[6,11]: 422.1584 - val_ca2-[12,17]: 177.1654 - val_ca2-[18,23]: 60.0421 - val_ca3-[0,5]: 508.3253 - val_ca3-[6,11]: 270.3900 - val_ca3-[12,17]: 88.2196 - val_ca3-[18,23]: 31.1999 - val_ca4-[0,5]: 0.4098 - val_ca4-[6,11]: 0.8314 - val_ca4-[12,17]: 3.7005 - val_ca4-[18,23]: 22.4013\n",
      "Epoch 157/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 66.7610 - ca1-[6,11]: 164.9371 - ca1-[12,17]: 23.1628 - ca1-[18,23]: 21.2740 - ca2-[0,5]: 591.7179 - ca2-[6,11]: 367.1510 - ca2-[12,17]: 215.2098 - ca2-[18,23]: 67.9070 - ca3-[0,5]: 513.1788 - ca3-[6,11]: 263.2711 - ca3-[12,17]: 84.4953 - ca3-[18,23]: 21.7584 - ca4-[0,5]: 0.3950 - ca4-[6,11]: 0.2746 - ca4-[12,17]: 0.8454 - ca4-[18,23]: 13.8812 - val_ca1-[0,5]: 320.7090 - val_ca1-[6,11]: 143.4264 - val_ca1-[12,17]: 30.5071 - val_ca1-[18,23]: 39.6166 - val_ca2-[0,5]: 721.7783 - val_ca2-[6,11]: 428.9738 - val_ca2-[12,17]: 178.5060 - val_ca2-[18,23]: 63.8864 - val_ca3-[0,5]: 513.6524 - val_ca3-[6,11]: 274.9686 - val_ca3-[12,17]: 88.9405 - val_ca3-[18,23]: 32.2865 - val_ca4-[0,5]: 0.4031 - val_ca4-[6,11]: 0.8152 - val_ca4-[12,17]: 3.7566 - val_ca4-[18,23]: 21.9503\n",
      "Epoch 158/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 62.4776 - ca1-[6,11]: 161.1014 - ca1-[12,17]: 24.1016 - ca1-[18,23]: 19.3125 - ca2-[0,5]: 600.1911 - ca2-[6,11]: 374.5806 - ca2-[12,17]: 239.4354 - ca2-[18,23]: 69.1933 - ca3-[0,5]: 521.0991 - ca3-[6,11]: 266.5805 - ca3-[12,17]: 87.1949 - ca3-[18,23]: 21.6090 - ca4-[0,5]: 0.3931 - ca4-[6,11]: 0.2383 - ca4-[12,17]: 0.7900 - ca4-[18,23]: 13.2766 - val_ca1-[0,5]: 327.1522 - val_ca1-[6,11]: 147.3571 - val_ca1-[12,17]: 31.5139 - val_ca1-[18,23]: 40.3072 - val_ca2-[0,5]: 734.4297 - val_ca2-[6,11]: 438.1447 - val_ca2-[12,17]: 183.0975 - val_ca2-[18,23]: 63.4058 - val_ca3-[0,5]: 523.0449 - val_ca3-[6,11]: 281.3690 - val_ca3-[12,17]: 91.5791 - val_ca3-[18,23]: 32.1198 - val_ca4-[0,5]: 0.4017 - val_ca4-[6,11]: 0.7943 - val_ca4-[12,17]: 3.6315 - val_ca4-[18,23]: 21.5809\n",
      "Epoch 159/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 82.3052 - ca1-[6,11]: 166.3430 - ca1-[12,17]: 25.7195 - ca1-[18,23]: 18.9037 - ca2-[0,5]: 608.7291 - ca2-[6,11]: 381.2138 - ca2-[12,17]: 235.6667 - ca2-[18,23]: 74.9809 - ca3-[0,5]: 525.7213 - ca3-[6,11]: 264.1780 - ca3-[12,17]: 88.9543 - ca3-[18,23]: 23.1441 - ca4-[0,5]: 0.3770 - ca4-[6,11]: 0.2306 - ca4-[12,17]: 0.7442 - ca4-[18,23]: 12.4844 - val_ca1-[0,5]: 330.2094 - val_ca1-[6,11]: 148.5022 - val_ca1-[12,17]: 33.5087 - val_ca1-[18,23]: 38.2735 - val_ca2-[0,5]: 741.4862 - val_ca2-[6,11]: 442.2984 - val_ca2-[12,17]: 190.5077 - val_ca2-[18,23]: 67.0683 - val_ca3-[0,5]: 527.8737 - val_ca3-[6,11]: 283.7950 - val_ca3-[12,17]: 96.1748 - val_ca3-[18,23]: 32.8749 - val_ca4-[0,5]: 0.4032 - val_ca4-[6,11]: 0.7413 - val_ca4-[12,17]: 3.4812 - val_ca4-[18,23]: 20.3953\n",
      "Epoch 160/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 78.2018 - ca1-[6,11]: 157.3544 - ca1-[12,17]: 26.9330 - ca1-[18,23]: 17.9009 - ca2-[0,5]: 617.3380 - ca2-[6,11]: 374.7763 - ca2-[12,17]: 251.3408 - ca2-[18,23]: 77.3446 - ca3-[0,5]: 533.3271 - ca3-[6,11]: 276.7000 - ca3-[12,17]: 92.8185 - ca3-[18,23]: 24.2571 - ca4-[0,5]: 0.3860 - ca4-[6,11]: 0.2158 - ca4-[12,17]: 0.7914 - ca4-[18,23]: 11.8713 - val_ca1-[0,5]: 335.0677 - val_ca1-[6,11]: 152.5343 - val_ca1-[12,17]: 33.8724 - val_ca1-[18,23]: 38.9459 - val_ca2-[0,5]: 751.5519 - val_ca2-[6,11]: 451.5994 - val_ca2-[12,17]: 192.8340 - val_ca2-[18,23]: 68.2670 - val_ca3-[0,5]: 535.0981 - val_ca3-[6,11]: 290.2730 - val_ca3-[12,17]: 97.2853 - val_ca3-[18,23]: 33.5836 - val_ca4-[0,5]: 0.3988 - val_ca4-[6,11]: 0.7213 - val_ca4-[12,17]: 3.4772 - val_ca4-[18,23]: 20.3747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 85.3710 - ca1-[6,11]: 161.3522 - ca1-[12,17]: 27.8280 - ca1-[18,23]: 16.0594 - ca2-[0,5]: 626.0161 - ca2-[6,11]: 380.0817 - ca2-[12,17]: 257.9420 - ca2-[18,23]: 80.7111 - ca3-[0,5]: 541.0464 - ca3-[6,11]: 279.5416 - ca3-[12,17]: 93.9103 - ca3-[18,23]: 24.8832 - ca4-[0,5]: 0.3891 - ca4-[6,11]: 0.2291 - ca4-[12,17]: 0.7062 - ca4-[18,23]: 11.8031 - val_ca1-[0,5]: 339.2466 - val_ca1-[6,11]: 154.8688 - val_ca1-[12,17]: 34.8464 - val_ca1-[18,23]: 37.9743 - val_ca2-[0,5]: 760.6685 - val_ca2-[6,11]: 457.9388 - val_ca2-[12,17]: 197.1492 - val_ca2-[18,23]: 70.6373 - val_ca3-[0,5]: 541.5287 - val_ca3-[6,11]: 294.4026 - val_ca3-[12,17]: 99.7476 - val_ca3-[18,23]: 34.1425 - val_ca4-[0,5]: 0.3934 - val_ca4-[6,11]: 0.6890 - val_ca4-[12,17]: 3.3853 - val_ca4-[18,23]: 19.8095\n",
      "Epoch 162/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 82.9219 - ca1-[6,11]: 174.4473 - ca1-[12,17]: 28.9403 - ca1-[18,23]: 16.5427 - ca2-[0,5]: 626.8230 - ca2-[6,11]: 390.2218 - ca2-[12,17]: 260.8029 - ca2-[18,23]: 79.4378 - ca3-[0,5]: 551.1153 - ca3-[6,11]: 287.0534 - ca3-[12,17]: 96.2703 - ca3-[18,23]: 25.1232 - ca4-[0,5]: 0.3830 - ca4-[6,11]: 0.2141 - ca4-[12,17]: 0.6890 - ca4-[18,23]: 11.0387 - val_ca1-[0,5]: 345.5899 - val_ca1-[6,11]: 159.4126 - val_ca1-[12,17]: 35.9025 - val_ca1-[18,23]: 36.5077 - val_ca2-[0,5]: 773.0546 - val_ca2-[6,11]: 467.9895 - val_ca2-[12,17]: 204.7497 - val_ca2-[18,23]: 72.4667 - val_ca3-[0,5]: 550.7059 - val_ca3-[6,11]: 301.5340 - val_ca3-[12,17]: 103.9859 - val_ca3-[18,23]: 34.1781 - val_ca4-[0,5]: 0.3928 - val_ca4-[6,11]: 0.6720 - val_ca4-[12,17]: 3.1063 - val_ca4-[18,23]: 18.6314\n",
      "Epoch 163/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 84.3886 - ca1-[6,11]: 176.8555 - ca1-[12,17]: 30.3280 - ca1-[18,23]: 15.9311 - ca2-[0,5]: 643.5163 - ca2-[6,11]: 410.4867 - ca2-[12,17]: 249.3230 - ca2-[18,23]: 88.2252 - ca3-[0,5]: 554.1338 - ca3-[6,11]: 291.4014 - ca3-[12,17]: 98.1578 - ca3-[18,23]: 24.8662 - ca4-[0,5]: 0.3818 - ca4-[6,11]: 0.2032 - ca4-[12,17]: 0.5214 - ca4-[18,23]: 10.5831 - val_ca1-[0,5]: 349.2921 - val_ca1-[6,11]: 160.2860 - val_ca1-[12,17]: 37.1514 - val_ca1-[18,23]: 35.4979 - val_ca2-[0,5]: 781.3802 - val_ca2-[6,11]: 471.7928 - val_ca2-[12,17]: 208.0926 - val_ca2-[18,23]: 75.5693 - val_ca3-[0,5]: 556.5089 - val_ca3-[6,11]: 303.6426 - val_ca3-[12,17]: 106.0639 - val_ca3-[18,23]: 35.1013 - val_ca4-[0,5]: 0.3888 - val_ca4-[6,11]: 0.6610 - val_ca4-[12,17]: 3.0974 - val_ca4-[18,23]: 18.1036\n",
      "Epoch 164/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 85.8732 - ca1-[6,11]: 179.4151 - ca1-[12,17]: 31.2773 - ca1-[18,23]: 16.6787 - ca2-[0,5]: 633.5238 - ca2-[6,11]: 415.8022 - ca2-[12,17]: 272.7308 - ca2-[18,23]: 90.9327 - ca3-[0,5]: 564.7495 - ca3-[6,11]: 293.1111 - ca3-[12,17]: 101.2599 - ca3-[18,23]: 26.3171 - ca4-[0,5]: 0.3707 - ca4-[6,11]: 0.1519 - ca4-[12,17]: 0.5936 - ca4-[18,23]: 10.0250 - val_ca1-[0,5]: 353.1771 - val_ca1-[6,11]: 165.6032 - val_ca1-[12,17]: 38.1983 - val_ca1-[18,23]: 35.2058 - val_ca2-[0,5]: 789.9547 - val_ca2-[6,11]: 484.0822 - val_ca2-[12,17]: 214.7471 - val_ca2-[18,23]: 77.2591 - val_ca3-[0,5]: 562.5081 - val_ca3-[6,11]: 312.3188 - val_ca3-[12,17]: 109.7901 - val_ca3-[18,23]: 35.6091 - val_ca4-[0,5]: 0.3792 - val_ca4-[6,11]: 0.6296 - val_ca4-[12,17]: 2.8991 - val_ca4-[18,23]: 17.5317\n",
      "Epoch 165/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 87.3651 - ca1-[6,11]: 184.9810 - ca1-[12,17]: 33.3649 - ca1-[18,23]: 16.0125 - ca2-[0,5]: 630.0729 - ca2-[6,11]: 424.9808 - ca2-[12,17]: 270.6314 - ca2-[18,23]: 92.6484 - ca3-[0,5]: 570.4653 - ca3-[6,11]: 298.7619 - ca3-[12,17]: 103.1508 - ca3-[18,23]: 27.7038 - ca4-[0,5]: 0.3692 - ca4-[6,11]: 0.1565 - ca4-[12,17]: 0.4939 - ca4-[18,23]: 9.4498 - val_ca1-[0,5]: 357.4554 - val_ca1-[6,11]: 167.2247 - val_ca1-[12,17]: 39.5733 - val_ca1-[18,23]: 34.8687 - val_ca2-[0,5]: 799.2593 - val_ca2-[6,11]: 488.4524 - val_ca2-[12,17]: 217.7656 - val_ca2-[18,23]: 81.2283 - val_ca3-[0,5]: 569.0590 - val_ca3-[6,11]: 315.0476 - val_ca3-[12,17]: 111.7354 - val_ca3-[18,23]: 37.2959 - val_ca4-[0,5]: 0.3654 - val_ca4-[6,11]: 0.6080 - val_ca4-[12,17]: 2.9188 - val_ca4-[18,23]: 17.5828\n",
      "Epoch 166/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 93.2795 - ca1-[6,11]: 174.5017 - ca1-[12,17]: 34.7050 - ca1-[18,23]: 14.9352 - ca2-[0,5]: 670.2416 - ca2-[6,11]: 432.4806 - ca2-[12,17]: 277.0337 - ca2-[18,23]: 90.3283 - ca3-[0,5]: 576.6843 - ca3-[6,11]: 305.8154 - ca3-[12,17]: 105.8056 - ca3-[18,23]: 27.6050 - ca4-[0,5]: 0.3713 - ca4-[6,11]: 0.1453 - ca4-[12,17]: 0.4452 - ca4-[18,23]: 9.2379 - val_ca1-[0,5]: 363.7612 - val_ca1-[6,11]: 170.4053 - val_ca1-[12,17]: 40.4736 - val_ca1-[18,23]: 34.3775 - val_ca2-[0,5]: 811.7297 - val_ca2-[6,11]: 496.2019 - val_ca2-[12,17]: 222.0352 - val_ca2-[18,23]: 81.4291 - val_ca3-[0,5]: 578.2555 - val_ca3-[6,11]: 320.3106 - val_ca3-[12,17]: 114.1256 - val_ca3-[18,23]: 36.9176 - val_ca4-[0,5]: 0.3729 - val_ca4-[6,11]: 0.6001 - val_ca4-[12,17]: 2.9395 - val_ca4-[18,23]: 17.0543\n",
      "Epoch 167/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 90.4019 - ca1-[6,11]: 193.2036 - ca1-[12,17]: 33.9971 - ca1-[18,23]: 15.0948 - ca2-[0,5]: 679.2662 - ca2-[6,11]: 437.9484 - ca2-[12,17]: 291.2096 - ca2-[18,23]: 100.6179 - ca3-[0,5]: 583.5807 - ca3-[6,11]: 307.7695 - ca3-[12,17]: 108.6118 - ca3-[18,23]: 29.4446 - ca4-[0,5]: 0.3611 - ca4-[6,11]: 0.1580 - ca4-[12,17]: 0.4462 - ca4-[18,23]: 8.6442 - val_ca1-[0,5]: 367.0393 - val_ca1-[6,11]: 172.6174 - val_ca1-[12,17]: 41.9933 - val_ca1-[18,23]: 34.0865 - val_ca2-[0,5]: 819.3581 - val_ca2-[6,11]: 502.2375 - val_ca2-[12,17]: 228.2333 - val_ca2-[18,23]: 83.8438 - val_ca3-[0,5]: 583.4696 - val_ca3-[6,11]: 324.2139 - val_ca3-[12,17]: 117.8280 - val_ca3-[18,23]: 37.8039 - val_ca4-[0,5]: 0.3688 - val_ca4-[6,11]: 0.5723 - val_ca4-[12,17]: 2.7319 - val_ca4-[18,23]: 16.5919\n",
      "Epoch 168/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 90.5415 - ca1-[6,11]: 193.9848 - ca1-[12,17]: 37.0959 - ca1-[18,23]: 15.1298 - ca2-[0,5]: 688.3332 - ca2-[6,11]: 445.3831 - ca2-[12,17]: 295.9592 - ca2-[18,23]: 103.7622 - ca3-[0,5]: 594.1480 - ca3-[6,11]: 315.7712 - ca3-[12,17]: 112.1981 - ca3-[18,23]: 30.3722 - ca4-[0,5]: 0.3614 - ca4-[6,11]: 0.1406 - ca4-[12,17]: 0.4415 - ca4-[18,23]: 8.1969 - val_ca1-[0,5]: 372.9011 - val_ca1-[6,11]: 175.4115 - val_ca1-[12,17]: 43.2844 - val_ca1-[18,23]: 33.1062 - val_ca2-[0,5]: 831.0355 - val_ca2-[6,11]: 509.2828 - val_ca2-[12,17]: 233.4129 - val_ca2-[18,23]: 88.5715 - val_ca3-[0,5]: 592.0460 - val_ca3-[6,11]: 328.9281 - val_ca3-[12,17]: 120.8847 - val_ca3-[18,23]: 39.5855 - val_ca4-[0,5]: 0.3751 - val_ca4-[6,11]: 0.5675 - val_ca4-[12,17]: 2.7286 - val_ca4-[18,23]: 16.1128\n",
      "Epoch 169/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 88.7734 - ca1-[6,11]: 197.1341 - ca1-[12,17]: 37.2329 - ca1-[18,23]: 14.5712 - ca2-[0,5]: 697.4609 - ca2-[6,11]: 453.5572 - ca2-[12,17]: 303.4108 - ca2-[18,23]: 107.9721 - ca3-[0,5]: 604.3205 - ca3-[6,11]: 318.4345 - ca3-[12,17]: 114.8486 - ca3-[18,23]: 30.6603 - ca4-[0,5]: 0.3571 - ca4-[6,11]: 0.1475 - ca4-[12,17]: 0.3750 - ca4-[18,23]: 8.0734 - val_ca1-[0,5]: 377.2627 - val_ca1-[6,11]: 179.7557 - val_ca1-[12,17]: 44.3450 - val_ca1-[18,23]: 32.6683 - val_ca2-[0,5]: 840.4524 - val_ca2-[6,11]: 519.4567 - val_ca2-[12,17]: 237.3866 - val_ca2-[18,23]: 90.9597 - val_ca3-[0,5]: 598.6854 - val_ca3-[6,11]: 335.9991 - val_ca3-[12,17]: 123.1793 - val_ca3-[18,23]: 40.3793 - val_ca4-[0,5]: 0.3744 - val_ca4-[6,11]: 0.5714 - val_ca4-[12,17]: 2.8186 - val_ca4-[18,23]: 15.8283\n",
      "Epoch 170/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 88.9638 - ca1-[6,11]: 200.5587 - ca1-[12,17]: 37.4318 - ca1-[18,23]: 14.4366 - ca2-[0,5]: 706.6620 - ca2-[6,11]: 461.1319 - ca2-[12,17]: 304.6004 - ca2-[18,23]: 109.6441 - ca3-[0,5]: 605.7725 - ca3-[6,11]: 305.8020 - ca3-[12,17]: 117.1175 - ca3-[18,23]: 33.1242 - ca4-[0,5]: 0.3439 - ca4-[6,11]: 0.1305 - ca4-[12,17]: 0.3542 - ca4-[18,23]: 7.6145 - val_ca1-[0,5]: 382.3065 - val_ca1-[6,11]: 183.9255 - val_ca1-[12,17]: 45.9949 - val_ca1-[18,23]: 32.5753 - val_ca2-[0,5]: 850.9074 - val_ca2-[6,11]: 528.7744 - val_ca2-[12,17]: 243.8298 - val_ca2-[18,23]: 93.3629 - val_ca3-[0,5]: 606.2370 - val_ca3-[6,11]: 342.5654 - val_ca3-[12,17]: 127.0716 - val_ca3-[18,23]: 41.3471 - val_ca4-[0,5]: 0.3706 - val_ca4-[6,11]: 0.5086 - val_ca4-[12,17]: 2.5151 - val_ca4-[18,23]: 15.0212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 96.6465 - ca1-[6,11]: 192.3903 - ca1-[12,17]: 40.4959 - ca1-[18,23]: 14.5898 - ca2-[0,5]: 711.7372 - ca2-[6,11]: 467.9070 - ca2-[12,17]: 278.6390 - ca2-[18,23]: 113.5955 - ca3-[0,5]: 616.0871 - ca3-[6,11]: 318.5750 - ca3-[12,17]: 117.8127 - ca3-[18,23]: 34.9703 - ca4-[0,5]: 0.3488 - ca4-[6,11]: 0.1189 - ca4-[12,17]: 0.3002 - ca4-[18,23]: 7.5730 - val_ca1-[0,5]: 386.4829 - val_ca1-[6,11]: 187.9936 - val_ca1-[12,17]: 47.3907 - val_ca1-[18,23]: 31.9111 - val_ca2-[0,5]: 860.1403 - val_ca2-[6,11]: 538.3936 - val_ca2-[12,17]: 249.0349 - val_ca2-[18,23]: 95.4279 - val_ca3-[0,5]: 612.7141 - val_ca3-[6,11]: 349.2270 - val_ca3-[12,17]: 130.1802 - val_ca3-[18,23]: 41.8614 - val_ca4-[0,5]: 0.3565 - val_ca4-[6,11]: 0.4909 - val_ca4-[12,17]: 2.4762 - val_ca4-[18,23]: 14.5087\n",
      "Epoch 172/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 93.1964 - ca1-[6,11]: 206.1981 - ca1-[12,17]: 41.0125 - ca1-[18,23]: 14.9597 - ca2-[0,5]: 729.4337 - ca2-[6,11]: 475.6008 - ca2-[12,17]: 310.6267 - ca2-[18,23]: 116.7782 - ca3-[0,5]: 622.5513 - ca3-[6,11]: 340.9577 - ca3-[12,17]: 122.5953 - ca3-[18,23]: 35.9194 - ca4-[0,5]: 0.3579 - ca4-[6,11]: 0.1085 - ca4-[12,17]: 0.2872 - ca4-[18,23]: 6.7795 - val_ca1-[0,5]: 392.3717 - val_ca1-[6,11]: 190.6912 - val_ca1-[12,17]: 48.9579 - val_ca1-[18,23]: 31.6825 - val_ca2-[0,5]: 871.8945 - val_ca2-[6,11]: 545.2240 - val_ca2-[12,17]: 254.7637 - val_ca2-[18,23]: 96.0177 - val_ca3-[0,5]: 621.3013 - val_ca3-[6,11]: 353.7480 - val_ca3-[12,17]: 133.6319 - val_ca3-[18,23]: 41.7980 - val_ca4-[0,5]: 0.3643 - val_ca4-[6,11]: 0.4750 - val_ca4-[12,17]: 2.4197 - val_ca4-[18,23]: 14.3395\n",
      "Epoch 173/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 99.8554 - ca1-[6,11]: 211.0426 - ca1-[12,17]: 43.4689 - ca1-[18,23]: 14.3064 - ca2-[0,5]: 734.6282 - ca2-[6,11]: 484.2902 - ca2-[12,17]: 298.1698 - ca2-[18,23]: 122.1125 - ca3-[0,5]: 626.1201 - ca3-[6,11]: 339.7276 - ca3-[12,17]: 126.1093 - ca3-[18,23]: 36.7484 - ca4-[0,5]: 0.3449 - ca4-[6,11]: 0.0898 - ca4-[12,17]: 0.2993 - ca4-[18,23]: 6.6680 - val_ca1-[0,5]: 398.2247 - val_ca1-[6,11]: 194.5432 - val_ca1-[12,17]: 49.1729 - val_ca1-[18,23]: 30.9415 - val_ca2-[0,5]: 883.7332 - val_ca2-[6,11]: 554.3833 - val_ca2-[12,17]: 257.2032 - val_ca2-[18,23]: 101.9210 - val_ca3-[0,5]: 629.8996 - val_ca3-[6,11]: 360.0291 - val_ca3-[12,17]: 134.7014 - val_ca3-[18,23]: 44.2860 - val_ca4-[0,5]: 0.3621 - val_ca4-[6,11]: 0.4721 - val_ca4-[12,17]: 2.4111 - val_ca4-[18,23]: 13.5763\n",
      "Epoch 174/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 101.4814 - ca1-[6,11]: 214.8682 - ca1-[12,17]: 44.3590 - ca1-[18,23]: 14.2130 - ca2-[0,5]: 744.0844 - ca2-[6,11]: 492.1297 - ca2-[12,17]: 326.3551 - ca2-[18,23]: 117.7580 - ca3-[0,5]: 635.6266 - ca3-[6,11]: 349.6940 - ca3-[12,17]: 128.9564 - ca3-[18,23]: 37.4112 - ca4-[0,5]: 0.3489 - ca4-[6,11]: 0.0903 - ca4-[12,17]: 0.2464 - ca4-[18,23]: 6.2682 - val_ca1-[0,5]: 401.9532 - val_ca1-[6,11]: 196.5849 - val_ca1-[12,17]: 52.1189 - val_ca1-[18,23]: 30.8955 - val_ca2-[0,5]: 892.2231 - val_ca2-[6,11]: 560.1209 - val_ca2-[12,17]: 268.1991 - val_ca2-[18,23]: 105.4021 - val_ca3-[0,5]: 635.7625 - val_ca3-[6,11]: 363.6764 - val_ca3-[12,17]: 141.5838 - val_ca3-[18,23]: 45.8304 - val_ca4-[0,5]: 0.3585 - val_ca4-[6,11]: 0.4523 - val_ca4-[12,17]: 2.2787 - val_ca4-[18,23]: 13.2621\n",
      "Epoch 175/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 108.4939 - ca1-[6,11]: 204.6867 - ca1-[12,17]: 42.6165 - ca1-[18,23]: 13.8598 - ca2-[0,5]: 722.7550 - ca2-[6,11]: 501.1520 - ca2-[12,17]: 343.2723 - ca2-[18,23]: 128.6443 - ca3-[0,5]: 645.7849 - ca3-[6,11]: 353.7215 - ca3-[12,17]: 131.9368 - ca3-[18,23]: 38.9332 - ca4-[0,5]: 0.3389 - ca4-[6,11]: 0.0938 - ca4-[12,17]: 0.2258 - ca4-[18,23]: 5.9051 - val_ca1-[0,5]: 408.5456 - val_ca1-[6,11]: 200.7980 - val_ca1-[12,17]: 53.2261 - val_ca1-[18,23]: 30.6876 - val_ca2-[0,5]: 905.1887 - val_ca2-[6,11]: 569.8098 - val_ca2-[12,17]: 271.0955 - val_ca2-[18,23]: 106.5410 - val_ca3-[0,5]: 645.3652 - val_ca3-[6,11]: 370.4525 - val_ca3-[12,17]: 143.3430 - val_ca3-[18,23]: 46.0695 - val_ca4-[0,5]: 0.3579 - val_ca4-[6,11]: 0.4334 - val_ca4-[12,17]: 2.2370 - val_ca4-[18,23]: 13.1011\n",
      "Epoch 176/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 104.7735 - ca1-[6,11]: 216.8310 - ca1-[12,17]: 46.0037 - ca1-[18,23]: 14.4896 - ca2-[0,5]: 736.2186 - ca2-[6,11]: 512.1736 - ca2-[12,17]: 321.1631 - ca2-[18,23]: 135.5315 - ca3-[0,5]: 652.2487 - ca3-[6,11]: 356.4563 - ca3-[12,17]: 134.9982 - ca3-[18,23]: 40.0640 - ca4-[0,5]: 0.3452 - ca4-[6,11]: 0.0919 - ca4-[12,17]: 0.2089 - ca4-[18,23]: 5.7627 - val_ca1-[0,5]: 414.0404 - val_ca1-[6,11]: 205.0190 - val_ca1-[12,17]: 54.4982 - val_ca1-[18,23]: 30.2935 - val_ca2-[0,5]: 916.4664 - val_ca2-[6,11]: 579.5149 - val_ca2-[12,17]: 276.0086 - val_ca2-[18,23]: 110.6186 - val_ca3-[0,5]: 653.5363 - val_ca3-[6,11]: 377.2221 - val_ca3-[12,17]: 146.2290 - val_ca3-[18,23]: 47.7590 - val_ca4-[0,5]: 0.3554 - val_ca4-[6,11]: 0.4347 - val_ca4-[12,17]: 2.2397 - val_ca4-[18,23]: 12.6738\n",
      "Epoch 177/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 106.4463 - ca1-[6,11]: 189.7269 - ca1-[12,17]: 48.5043 - ca1-[18,23]: 13.3195 - ca2-[0,5]: 736.8149 - ca2-[6,11]: 515.8642 - ca2-[12,17]: 333.3275 - ca2-[18,23]: 129.8177 - ca3-[0,5]: 660.8880 - ca3-[6,11]: 362.7468 - ca3-[12,17]: 137.1123 - ca3-[18,23]: 42.7803 - ca4-[0,5]: 0.3419 - ca4-[6,11]: 0.0774 - ca4-[12,17]: 0.2120 - ca4-[18,23]: 5.6227 - val_ca1-[0,5]: 418.5319 - val_ca1-[6,11]: 206.4523 - val_ca1-[12,17]: 55.4886 - val_ca1-[18,23]: 29.7723 - val_ca2-[0,5]: 926.0800 - val_ca2-[6,11]: 584.3346 - val_ca2-[12,17]: 280.7002 - val_ca2-[18,23]: 112.9556 - val_ca3-[0,5]: 660.3040 - val_ca3-[6,11]: 380.0607 - val_ca3-[12,17]: 148.8400 - val_ca3-[18,23]: 48.4612 - val_ca4-[0,5]: 0.3570 - val_ca4-[6,11]: 0.4191 - val_ca4-[12,17]: 2.0785 - val_ca4-[18,23]: 12.1559\n",
      "Epoch 178/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 108.1299 - ca1-[6,11]: 223.2568 - ca1-[12,17]: 52.7321 - ca1-[18,23]: 14.3817 - ca2-[0,5]: 782.4366 - ca2-[6,11]: 522.5228 - ca2-[12,17]: 358.7572 - ca2-[18,23]: 132.5163 - ca3-[0,5]: 668.1871 - ca3-[6,11]: 365.1443 - ca3-[12,17]: 141.0305 - ca3-[18,23]: 42.5774 - ca4-[0,5]: 0.3409 - ca4-[6,11]: 0.0652 - ca4-[12,17]: 0.1906 - ca4-[18,23]: 4.8546 - val_ca1-[0,5]: 423.0064 - val_ca1-[6,11]: 209.5218 - val_ca1-[12,17]: 57.9757 - val_ca1-[18,23]: 29.8716 - val_ca2-[0,5]: 935.9389 - val_ca2-[6,11]: 592.0281 - val_ca2-[12,17]: 288.7486 - val_ca2-[18,23]: 117.1407 - val_ca3-[0,5]: 667.1882 - val_ca3-[6,11]: 385.1826 - val_ca3-[12,17]: 153.9217 - val_ca3-[18,23]: 50.4263 - val_ca4-[0,5]: 0.3449 - val_ca4-[6,11]: 0.4145 - val_ca4-[12,17]: 2.0479 - val_ca4-[18,23]: 11.9247\n",
      "Epoch 179/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 103.9806 - ca1-[6,11]: 228.8233 - ca1-[12,17]: 51.9573 - ca1-[18,23]: 14.4530 - ca2-[0,5]: 764.2127 - ca2-[6,11]: 533.1030 - ca2-[12,17]: 363.5196 - ca2-[18,23]: 146.7840 - ca3-[0,5]: 673.5445 - ca3-[6,11]: 369.7387 - ca3-[12,17]: 144.6779 - ca3-[18,23]: 44.3469 - ca4-[0,5]: 0.3235 - ca4-[6,11]: 0.0675 - ca4-[12,17]: 0.1694 - ca4-[18,23]: 5.1403 - val_ca1-[0,5]: 427.6276 - val_ca1-[6,11]: 214.5505 - val_ca1-[12,17]: 59.9326 - val_ca1-[18,23]: 29.7877 - val_ca2-[0,5]: 945.8012 - val_ca2-[6,11]: 603.0312 - val_ca2-[12,17]: 295.2526 - val_ca2-[18,23]: 121.7865 - val_ca3-[0,5]: 674.1635 - val_ca3-[6,11]: 392.9868 - val_ca3-[12,17]: 157.9469 - val_ca3-[18,23]: 52.5465 - val_ca4-[0,5]: 0.3452 - val_ca4-[6,11]: 0.3969 - val_ca4-[12,17]: 1.9760 - val_ca4-[18,23]: 11.5639\n",
      "Epoch 180/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 105.5721 - ca1-[6,11]: 218.8348 - ca1-[12,17]: 52.5164 - ca1-[18,23]: 15.2549 - ca2-[0,5]: 773.6518 - ca2-[6,11]: 542.2229 - ca2-[12,17]: 350.7796 - ca2-[18,23]: 141.7450 - ca3-[0,5]: 681.1200 - ca3-[6,11]: 378.1459 - ca3-[12,17]: 149.4535 - ca3-[18,23]: 45.8643 - ca4-[0,5]: 0.3334 - ca4-[6,11]: 0.0593 - ca4-[12,17]: 0.1646 - ca4-[18,23]: 4.6152 - val_ca1-[0,5]: 432.7345 - val_ca1-[6,11]: 217.2975 - val_ca1-[12,17]: 60.9440 - val_ca1-[18,23]: 29.3353 - val_ca2-[0,5]: 956.5291 - val_ca2-[6,11]: 610.2070 - val_ca2-[12,17]: 299.1103 - val_ca2-[18,23]: 125.6958 - val_ca3-[0,5]: 681.8601 - val_ca3-[6,11]: 397.7240 - val_ca3-[12,17]: 160.1489 - val_ca3-[18,23]: 54.1092 - val_ca4-[0,5]: 0.3328 - val_ca4-[6,11]: 0.3883 - val_ca4-[12,17]: 1.9624 - val_ca4-[18,23]: 11.1701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 119.3407 - ca1-[6,11]: 237.9450 - ca1-[12,17]: 57.4053 - ca1-[18,23]: 14.4141 - ca2-[0,5]: 789.4419 - ca2-[6,11]: 550.7578 - ca2-[12,17]: 320.7457 - ca2-[18,23]: 143.9478 - ca3-[0,5]: 694.9597 - ca3-[6,11]: 387.9772 - ca3-[12,17]: 152.0993 - ca3-[18,23]: 47.8840 - ca4-[0,5]: 0.3397 - ca4-[6,11]: 0.0631 - ca4-[12,17]: 0.1495 - ca4-[18,23]: 4.7760 - val_ca1-[0,5]: 438.4140 - val_ca1-[6,11]: 221.2593 - val_ca1-[12,17]: 63.0132 - val_ca1-[18,23]: 29.5330 - val_ca2-[0,5]: 968.0448 - val_ca2-[6,11]: 619.4618 - val_ca2-[12,17]: 306.5643 - val_ca2-[18,23]: 129.4248 - val_ca3-[0,5]: 690.1857 - val_ca3-[6,11]: 404.0870 - val_ca3-[12,17]: 164.7147 - val_ca3-[18,23]: 55.8745 - val_ca4-[0,5]: 0.3470 - val_ca4-[6,11]: 0.3704 - val_ca4-[12,17]: 1.8302 - val_ca4-[18,23]: 11.0651\n",
      "Epoch 182/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 115.0111 - ca1-[6,11]: 242.5003 - ca1-[12,17]: 56.8652 - ca1-[18,23]: 13.4983 - ca2-[0,5]: 817.2858 - ca2-[6,11]: 558.8904 - ca2-[12,17]: 367.2672 - ca2-[18,23]: 155.6644 - ca3-[0,5]: 702.6605 - ca3-[6,11]: 391.6822 - ca3-[12,17]: 151.9203 - ca3-[18,23]: 48.8657 - ca4-[0,5]: 0.3303 - ca4-[6,11]: 0.0500 - ca4-[12,17]: 0.1535 - ca4-[18,23]: 4.5421 - val_ca1-[0,5]: 444.0493 - val_ca1-[6,11]: 224.1036 - val_ca1-[12,17]: 64.7599 - val_ca1-[18,23]: 29.2851 - val_ca2-[0,5]: 979.5362 - val_ca2-[6,11]: 626.7078 - val_ca2-[12,17]: 312.6252 - val_ca2-[18,23]: 131.6506 - val_ca3-[0,5]: 698.4819 - val_ca3-[6,11]: 408.8676 - val_ca3-[12,17]: 168.3965 - val_ca3-[18,23]: 56.6382 - val_ca4-[0,5]: 0.3474 - val_ca4-[6,11]: 0.3795 - val_ca4-[12,17]: 1.8718 - val_ca4-[18,23]: 10.6229\n",
      "Epoch 183/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 116.7674 - ca1-[6,11]: 230.0429 - ca1-[12,17]: 59.7707 - ca1-[18,23]: 14.5513 - ca2-[0,5]: 831.7345 - ca2-[6,11]: 568.5589 - ca2-[12,17]: 374.5394 - ca2-[18,23]: 153.2533 - ca3-[0,5]: 704.9147 - ca3-[6,11]: 397.3613 - ca3-[12,17]: 157.6062 - ca3-[18,23]: 51.2580 - ca4-[0,5]: 0.3297 - ca4-[6,11]: 0.0444 - ca4-[12,17]: 0.1217 - ca4-[18,23]: 4.1647 - val_ca1-[0,5]: 447.8867 - val_ca1-[6,11]: 227.9568 - val_ca1-[12,17]: 66.9426 - val_ca1-[18,23]: 29.3351 - val_ca2-[0,5]: 988.4375 - val_ca2-[6,11]: 635.8230 - val_ca2-[12,17]: 319.4617 - val_ca2-[18,23]: 133.8014 - val_ca3-[0,5]: 704.5717 - val_ca3-[6,11]: 415.1124 - val_ca3-[12,17]: 172.6933 - val_ca3-[18,23]: 57.5031 - val_ca4-[0,5]: 0.3261 - val_ca4-[6,11]: 0.3584 - val_ca4-[12,17]: 1.7865 - val_ca4-[18,23]: 10.3612\n",
      "Epoch 184/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 124.9768 - ca1-[6,11]: 240.5626 - ca1-[12,17]: 62.8244 - ca1-[18,23]: 15.5343 - ca2-[0,5]: 841.7696 - ca2-[6,11]: 574.8008 - ca2-[12,17]: 367.1567 - ca2-[18,23]: 167.6212 - ca3-[0,5]: 715.0205 - ca3-[6,11]: 406.6064 - ca3-[12,17]: 160.2726 - ca3-[18,23]: 52.4562 - ca4-[0,5]: 0.3263 - ca4-[6,11]: 0.0473 - ca4-[12,17]: 0.1200 - ca4-[18,23]: 3.9200 - val_ca1-[0,5]: 455.2221 - val_ca1-[6,11]: 233.9339 - val_ca1-[12,17]: 67.9136 - val_ca1-[18,23]: 29.2718 - val_ca2-[0,5]: 1002.5908 - val_ca2-[6,11]: 648.6141 - val_ca2-[12,17]: 323.5678 - val_ca2-[18,23]: 138.9478 - val_ca3-[0,5]: 715.0978 - val_ca3-[6,11]: 424.3075 - val_ca3-[12,17]: 174.9894 - val_ca3-[18,23]: 59.8843 - val_ca4-[0,5]: 0.3429 - val_ca4-[6,11]: 0.3580 - val_ca4-[12,17]: 1.8308 - val_ca4-[18,23]: 10.0034\n",
      "Epoch 185/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 99.8807 - ca1-[6,11]: 252.4453 - ca1-[12,17]: 62.4893 - ca1-[18,23]: 16.3661 - ca2-[0,5]: 851.8812 - ca2-[6,11]: 583.5483 - ca2-[12,17]: 408.6040 - ca2-[18,23]: 170.3940 - ca3-[0,5]: 719.1754 - ca3-[6,11]: 403.7960 - ca3-[12,17]: 165.5275 - ca3-[18,23]: 55.1412 - ca4-[0,5]: 0.3213 - ca4-[6,11]: 0.0417 - ca4-[12,17]: 0.1029 - ca4-[18,23]: 3.7990 - val_ca1-[0,5]: 459.3454 - val_ca1-[6,11]: 235.3939 - val_ca1-[12,17]: 69.7148 - val_ca1-[18,23]: 29.5816 - val_ca2-[0,5]: 1011.8444 - val_ca2-[6,11]: 653.5822 - val_ca2-[12,17]: 329.8342 - val_ca2-[18,23]: 143.3403 - val_ca3-[0,5]: 721.4982 - val_ca3-[6,11]: 427.2307 - val_ca3-[12,17]: 178.7976 - val_ca3-[18,23]: 62.0398 - val_ca4-[0,5]: 0.3387 - val_ca4-[6,11]: 0.3475 - val_ca4-[12,17]: 1.7182 - val_ca4-[18,23]: 9.7143\n",
      "Epoch 186/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 122.1158 - ca1-[6,11]: 240.4781 - ca1-[12,17]: 66.7143 - ca1-[18,23]: 16.0430 - ca2-[0,5]: 796.3560 - ca2-[6,11]: 591.0197 - ca2-[12,17]: 412.5724 - ca2-[18,23]: 172.3479 - ca3-[0,5]: 731.3977 - ca3-[6,11]: 415.0394 - ca3-[12,17]: 167.0117 - ca3-[18,23]: 55.0563 - ca4-[0,5]: 0.3237 - ca4-[6,11]: 0.0418 - ca4-[12,17]: 0.0978 - ca4-[18,23]: 3.4754 - val_ca1-[0,5]: 465.8079 - val_ca1-[6,11]: 241.0216 - val_ca1-[12,17]: 72.5190 - val_ca1-[18,23]: 29.8628 - val_ca2-[0,5]: 1024.7915 - val_ca2-[6,11]: 665.7439 - val_ca2-[12,17]: 338.2902 - val_ca2-[18,23]: 145.1433 - val_ca3-[0,5]: 730.9373 - val_ca3-[6,11]: 435.8979 - val_ca3-[12,17]: 184.2231 - val_ca3-[18,23]: 62.8217 - val_ca4-[0,5]: 0.3372 - val_ca4-[6,11]: 0.3353 - val_ca4-[12,17]: 1.6957 - val_ca4-[18,23]: 9.6932\n",
      "Epoch 187/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 123.9235 - ca1-[6,11]: 257.0295 - ca1-[12,17]: 65.0855 - ca1-[18,23]: 15.9957 - ca2-[0,5]: 779.3969 - ca2-[6,11]: 597.9043 - ca2-[12,17]: 406.2740 - ca2-[18,23]: 178.3487 - ca3-[0,5]: 738.7523 - ca3-[6,11]: 413.6010 - ca3-[12,17]: 172.1026 - ca3-[18,23]: 59.6552 - ca4-[0,5]: 0.3230 - ca4-[6,11]: 0.0346 - ca4-[12,17]: 0.0882 - ca4-[18,23]: 3.5087 - val_ca1-[0,5]: 473.0686 - val_ca1-[6,11]: 243.7171 - val_ca1-[12,17]: 73.9523 - val_ca1-[18,23]: 29.1999 - val_ca2-[0,5]: 1038.7738 - val_ca2-[6,11]: 672.9768 - val_ca2-[12,17]: 343.8892 - val_ca2-[18,23]: 148.5590 - val_ca3-[0,5]: 741.3163 - val_ca3-[6,11]: 440.6010 - val_ca3-[12,17]: 187.5071 - val_ca3-[18,23]: 63.9994 - val_ca4-[0,5]: 0.3445 - val_ca4-[6,11]: 0.3331 - val_ca4-[12,17]: 1.6645 - val_ca4-[18,23]: 9.3384\n",
      "Epoch 188/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 118.7902 - ca1-[6,11]: 261.6190 - ca1-[12,17]: 68.8690 - ca1-[18,23]: 16.1143 - ca2-[0,5]: 851.2320 - ca2-[6,11]: 608.1708 - ca2-[12,17]: 401.2299 - ca2-[18,23]: 172.3128 - ca3-[0,5]: 747.2192 - ca3-[6,11]: 421.4608 - ca3-[12,17]: 173.2981 - ca3-[18,23]: 59.6181 - ca4-[0,5]: 0.3257 - ca4-[6,11]: 0.0335 - ca4-[12,17]: 0.0801 - ca4-[18,23]: 3.1730 - val_ca1-[0,5]: 476.4893 - val_ca1-[6,11]: 247.4038 - val_ca1-[12,17]: 75.1972 - val_ca1-[18,23]: 29.6581 - val_ca2-[0,5]: 1047.0121 - val_ca2-[6,11]: 681.7629 - val_ca2-[12,17]: 348.5451 - val_ca2-[18,23]: 152.3138 - val_ca3-[0,5]: 746.8856 - val_ca3-[6,11]: 446.6091 - val_ca3-[12,17]: 190.2203 - val_ca3-[18,23]: 65.8942 - val_ca4-[0,5]: 0.3366 - val_ca4-[6,11]: 0.3188 - val_ca4-[12,17]: 1.6051 - val_ca4-[18,23]: 9.0605\n",
      "Epoch 189/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 127.5845 - ca1-[6,11]: 269.7635 - ca1-[12,17]: 71.7373 - ca1-[18,23]: 17.6729 - ca2-[0,5]: 861.1687 - ca2-[6,11]: 617.0968 - ca2-[12,17]: 412.2674 - ca2-[18,23]: 179.3193 - ca3-[0,5]: 757.6226 - ca3-[6,11]: 427.2613 - ca3-[12,17]: 178.2933 - ca3-[18,23]: 63.4656 - ca4-[0,5]: 0.3228 - ca4-[6,11]: 0.0302 - ca4-[12,17]: 0.0726 - ca4-[18,23]: 3.3169 - val_ca1-[0,5]: 482.1432 - val_ca1-[6,11]: 251.7946 - val_ca1-[12,17]: 77.4655 - val_ca1-[18,23]: 29.8011 - val_ca2-[0,5]: 1058.6761 - val_ca2-[6,11]: 691.6840 - val_ca2-[12,17]: 355.8560 - val_ca2-[18,23]: 158.2713 - val_ca3-[0,5]: 755.2836 - val_ca3-[6,11]: 453.5244 - val_ca3-[12,17]: 194.7952 - val_ca3-[18,23]: 68.7817 - val_ca4-[0,5]: 0.3344 - val_ca4-[6,11]: 0.3119 - val_ca4-[12,17]: 1.5351 - val_ca4-[18,23]: 8.5303\n",
      "Epoch 190/300\n",
      "26/26 [==============================] - 3s 106ms/step - ca1-[0,5]: 122.3961 - ca1-[6,11]: 274.7256 - ca1-[12,17]: 73.1785 - ca1-[18,23]: 17.7740 - ca2-[0,5]: 806.9411 - ca2-[6,11]: 627.0607 - ca2-[12,17]: 435.1813 - ca2-[18,23]: 183.2867 - ca3-[0,5]: 762.4932 - ca3-[6,11]: 442.5398 - ca3-[12,17]: 183.7525 - ca3-[18,23]: 61.6127 - ca4-[0,5]: 0.3221 - ca4-[6,11]: 0.0310 - ca4-[12,17]: 0.0871 - ca4-[18,23]: 3.1122 - val_ca1-[0,5]: 487.6522 - val_ca1-[6,11]: 256.1862 - val_ca1-[12,17]: 80.3187 - val_ca1-[18,23]: 30.6095 - val_ca2-[0,5]: 1070.1626 - val_ca2-[6,11]: 701.8834 - val_ca2-[12,17]: 365.3877 - val_ca2-[18,23]: 163.2890 - val_ca3-[0,5]: 763.5840 - val_ca3-[6,11]: 460.6335 - val_ca3-[12,17]: 200.8384 - val_ca3-[18,23]: 71.5061 - val_ca4-[0,5]: 0.3364 - val_ca4-[6,11]: 0.3075 - val_ca4-[12,17]: 1.5097 - val_ca4-[18,23]: 8.4255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/300\n",
      "26/26 [==============================] - 3s 106ms/step - ca1-[0,5]: 131.3048 - ca1-[6,11]: 274.8716 - ca1-[12,17]: 73.6497 - ca1-[18,23]: 18.1792 - ca2-[0,5]: 904.2879 - ca2-[6,11]: 633.8202 - ca2-[12,17]: 445.7903 - ca2-[18,23]: 187.2426 - ca3-[0,5]: 772.0835 - ca3-[6,11]: 446.5472 - ca3-[12,17]: 184.9551 - ca3-[18,23]: 67.4694 - ca4-[0,5]: 0.3189 - ca4-[6,11]: 0.0346 - ca4-[12,17]: 0.0809 - ca4-[18,23]: 2.8986 - val_ca1-[0,5]: 493.4614 - val_ca1-[6,11]: 259.3190 - val_ca1-[12,17]: 81.4646 - val_ca1-[18,23]: 30.6784 - val_ca2-[0,5]: 1082.0776 - val_ca2-[6,11]: 709.8170 - val_ca2-[12,17]: 368.6436 - val_ca2-[18,23]: 166.2846 - val_ca3-[0,5]: 774.5028 - val_ca3-[6,11]: 467.6853 - val_ca3-[12,17]: 203.8958 - val_ca3-[18,23]: 73.3552 - val_ca4-[0,5]: 0.3318 - val_ca4-[6,11]: 0.3018 - val_ca4-[12,17]: 1.5607 - val_ca4-[18,23]: 8.5966\n",
      "Epoch 192/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 104.5955 - ca1-[6,11]: 248.1783 - ca1-[12,17]: 78.1459 - ca1-[18,23]: 17.1887 - ca2-[0,5]: 891.3970 - ca2-[6,11]: 643.5746 - ca2-[12,17]: 454.0827 - ca2-[18,23]: 200.3529 - ca3-[0,5]: 781.8552 - ca3-[6,11]: 459.0184 - ca3-[12,17]: 192.7754 - ca3-[18,23]: 71.5388 - ca4-[0,5]: 0.3192 - ca4-[6,11]: 0.0270 - ca4-[12,17]: 0.0658 - ca4-[18,23]: 2.8237 - val_ca1-[0,5]: 499.6631 - val_ca1-[6,11]: 264.5736 - val_ca1-[12,17]: 83.8976 - val_ca1-[18,23]: 31.0742 - val_ca2-[0,5]: 1094.6656 - val_ca2-[6,11]: 721.1462 - val_ca2-[12,17]: 376.0450 - val_ca2-[18,23]: 171.7795 - val_ca3-[0,5]: 805.1497 - val_ca3-[6,11]: 492.3352 - val_ca3-[12,17]: 219.3394 - val_ca3-[18,23]: 81.4864 - val_ca4-[0,5]: 0.3289 - val_ca4-[6,11]: 0.3053 - val_ca4-[12,17]: 1.5621 - val_ca4-[18,23]: 8.2170\n",
      "Epoch 193/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 135.0796 - ca1-[6,11]: 240.9611 - ca1-[12,17]: 75.3529 - ca1-[18,23]: 18.3553 - ca2-[0,5]: 930.0777 - ca2-[6,11]: 655.3216 - ca2-[12,17]: 440.4811 - ca2-[18,23]: 192.9496 - ca3-[0,5]: 813.1141 - ca3-[6,11]: 481.1649 - ca3-[12,17]: 205.5212 - ca3-[18,23]: 78.3481 - ca4-[0,5]: 0.3154 - ca4-[6,11]: 0.0193 - ca4-[12,17]: 0.0488 - ca4-[18,23]: 2.6727 - val_ca1-[0,5]: 503.7065 - val_ca1-[6,11]: 268.7581 - val_ca1-[12,17]: 86.3809 - val_ca1-[18,23]: 30.5097 - val_ca2-[0,5]: 1103.9474 - val_ca2-[6,11]: 731.0018 - val_ca2-[12,17]: 383.9370 - val_ca2-[18,23]: 172.3142 - val_ca3-[0,5]: 822.7422 - val_ca3-[6,11]: 507.8868 - val_ca3-[12,17]: 230.1410 - val_ca3-[18,23]: 84.0705 - val_ca4-[0,5]: 0.3252 - val_ca4-[6,11]: 0.2959 - val_ca4-[12,17]: 1.4637 - val_ca4-[18,23]: 7.8940\n",
      "Epoch 194/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 114.2635 - ca1-[6,11]: 279.8208 - ca1-[12,17]: 82.0830 - ca1-[18,23]: 19.9581 - ca2-[0,5]: 945.4760 - ca2-[6,11]: 660.9961 - ca2-[12,17]: 444.2695 - ca2-[18,23]: 210.9874 - ca3-[0,5]: 833.4957 - ca3-[6,11]: 497.4224 - ca3-[12,17]: 213.2316 - ca3-[18,23]: 81.3968 - ca4-[0,5]: 0.3159 - ca4-[6,11]: 0.0189 - ca4-[12,17]: 0.0556 - ca4-[18,23]: 2.4093 - val_ca1-[0,5]: 510.7522 - val_ca1-[6,11]: 270.7897 - val_ca1-[12,17]: 87.5676 - val_ca1-[18,23]: 31.3869 - val_ca2-[0,5]: 1117.7367 - val_ca2-[6,11]: 737.0104 - val_ca2-[12,17]: 388.7418 - val_ca2-[18,23]: 180.2729 - val_ca3-[0,5]: 840.1873 - val_ca3-[6,11]: 517.1927 - val_ca3-[12,17]: 236.6125 - val_ca3-[18,23]: 90.5985 - val_ca4-[0,5]: 0.3270 - val_ca4-[6,11]: 0.2886 - val_ca4-[12,17]: 1.4177 - val_ca4-[18,23]: 7.5171\n",
      "Epoch 195/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 138.9160 - ca1-[6,11]: 293.2660 - ca1-[12,17]: 82.2367 - ca1-[18,23]: 20.5536 - ca2-[0,5]: 956.1925 - ca2-[6,11]: 671.8301 - ca2-[12,17]: 460.5232 - ca2-[18,23]: 206.9231 - ca3-[0,5]: 848.1217 - ca3-[6,11]: 503.2742 - ca3-[12,17]: 227.3668 - ca3-[18,23]: 87.3712 - ca4-[0,5]: 0.3061 - ca4-[6,11]: 0.0190 - ca4-[12,17]: 0.0583 - ca4-[18,23]: 2.5378 - val_ca1-[0,5]: 514.5454 - val_ca1-[6,11]: 275.6248 - val_ca1-[12,17]: 89.9423 - val_ca1-[18,23]: 32.1261 - val_ca2-[0,5]: 1126.7610 - val_ca2-[6,11]: 747.8788 - val_ca2-[12,17]: 396.2237 - val_ca2-[18,23]: 183.8419 - val_ca3-[0,5]: 852.1772 - val_ca3-[6,11]: 529.5138 - val_ca3-[12,17]: 244.5213 - val_ca3-[18,23]: 94.2176 - val_ca4-[0,5]: 0.3199 - val_ca4-[6,11]: 0.2840 - val_ca4-[12,17]: 1.3329 - val_ca4-[18,23]: 7.3940\n",
      "Epoch 196/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 140.8520 - ca1-[6,11]: 276.8334 - ca1-[12,17]: 85.8502 - ca1-[18,23]: 20.6479 - ca2-[0,5]: 962.1245 - ca2-[6,11]: 682.5160 - ca2-[12,17]: 478.5825 - ca2-[18,23]: 222.6093 - ca3-[0,5]: 863.2939 - ca3-[6,11]: 521.1657 - ca3-[12,17]: 229.2778 - ca3-[18,23]: 91.1100 - ca4-[0,5]: 0.3149 - ca4-[6,11]: 0.0204 - ca4-[12,17]: 0.0542 - ca4-[18,23]: 2.4242 - val_ca1-[0,5]: 520.4774 - val_ca1-[6,11]: 279.9344 - val_ca1-[12,17]: 91.7190 - val_ca1-[18,23]: 31.8925 - val_ca2-[0,5]: 1138.9551 - val_ca2-[6,11]: 757.8811 - val_ca2-[12,17]: 402.1928 - val_ca2-[18,23]: 188.0023 - val_ca3-[0,5]: 866.1916 - val_ca3-[6,11]: 540.5598 - val_ca3-[12,17]: 250.9379 - val_ca3-[18,23]: 97.6395 - val_ca4-[0,5]: 0.3221 - val_ca4-[6,11]: 0.2771 - val_ca4-[12,17]: 1.3663 - val_ca4-[18,23]: 7.0523\n",
      "Epoch 197/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 141.9955 - ca1-[6,11]: 299.3742 - ca1-[12,17]: 87.5104 - ca1-[18,23]: 21.5536 - ca2-[0,5]: 942.9708 - ca2-[6,11]: 690.4050 - ca2-[12,17]: 488.9448 - ca2-[18,23]: 227.8585 - ca3-[0,5]: 879.4090 - ca3-[6,11]: 522.2426 - ca3-[12,17]: 235.1288 - ca3-[18,23]: 94.8294 - ca4-[0,5]: 0.3053 - ca4-[6,11]: 0.0174 - ca4-[12,17]: 0.0476 - ca4-[18,23]: 2.3441 - val_ca1-[0,5]: 527.9089 - val_ca1-[6,11]: 284.5963 - val_ca1-[12,17]: 95.7680 - val_ca1-[18,23]: 32.5394 - val_ca2-[0,5]: 1153.4102 - val_ca2-[6,11]: 768.4741 - val_ca2-[12,17]: 413.0183 - val_ca2-[18,23]: 189.9748 - val_ca3-[0,5]: 881.6552 - val_ca3-[6,11]: 551.7170 - val_ca3-[12,17]: 260.9604 - val_ca3-[18,23]: 99.9658 - val_ca4-[0,5]: 0.3229 - val_ca4-[6,11]: 0.2707 - val_ca4-[12,17]: 1.3571 - val_ca4-[18,23]: 7.1957\n",
      "Epoch 198/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 144.7648 - ca1-[6,11]: 291.9641 - ca1-[12,17]: 91.0796 - ca1-[18,23]: 22.8092 - ca2-[0,5]: 948.5728 - ca2-[6,11]: 698.6268 - ca2-[12,17]: 501.1495 - ca2-[18,23]: 222.3213 - ca3-[0,5]: 890.4134 - ca3-[6,11]: 536.5036 - ca3-[12,17]: 241.1417 - ca3-[18,23]: 97.2790 - ca4-[0,5]: 0.3078 - ca4-[6,11]: 0.0168 - ca4-[12,17]: 0.0513 - ca4-[18,23]: 2.2336 - val_ca1-[0,5]: 532.8340 - val_ca1-[6,11]: 287.6049 - val_ca1-[12,17]: 96.9805 - val_ca1-[18,23]: 32.7773 - val_ca2-[0,5]: 1164.1974 - val_ca2-[6,11]: 776.1426 - val_ca2-[12,17]: 418.1995 - val_ca2-[18,23]: 197.0652 - val_ca3-[0,5]: 893.4669 - val_ca3-[6,11]: 560.1152 - val_ca3-[12,17]: 266.2380 - val_ca3-[18,23]: 105.1792 - val_ca4-[0,5]: 0.3157 - val_ca4-[6,11]: 0.2722 - val_ca4-[12,17]: 1.2941 - val_ca4-[18,23]: 6.6576\n",
      "Epoch 199/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 146.7466 - ca1-[6,11]: 307.1294 - ca1-[12,17]: 93.1271 - ca1-[18,23]: 21.3621 - ca2-[0,5]: 999.6547 - ca2-[6,11]: 707.1834 - ca2-[12,17]: 502.4682 - ca2-[18,23]: 227.8929 - ca3-[0,5]: 905.7749 - ca3-[6,11]: 548.4514 - ca3-[12,17]: 247.8020 - ca3-[18,23]: 103.3837 - ca4-[0,5]: 0.3035 - ca4-[6,11]: 0.0148 - ca4-[12,17]: 0.0413 - ca4-[18,23]: 2.0580 - val_ca1-[0,5]: 539.2771 - val_ca1-[6,11]: 292.9573 - val_ca1-[12,17]: 100.1409 - val_ca1-[18,23]: 33.3323 - val_ca2-[0,5]: 1177.2079 - val_ca2-[6,11]: 787.9744 - val_ca2-[12,17]: 428.3573 - val_ca2-[18,23]: 201.0333 - val_ca3-[0,5]: 906.9711 - val_ca3-[6,11]: 571.7732 - val_ca3-[12,17]: 275.2172 - val_ca3-[18,23]: 108.5546 - val_ca4-[0,5]: 0.3163 - val_ca4-[6,11]: 0.2577 - val_ca4-[12,17]: 1.3091 - val_ca4-[18,23]: 6.5463\n",
      "Epoch 200/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 141.2296 - ca1-[6,11]: 269.6711 - ca1-[12,17]: 91.7634 - ca1-[18,23]: 21.2897 - ca2-[0,5]: 969.6563 - ca2-[6,11]: 717.4941 - ca2-[12,17]: 501.0588 - ca2-[18,23]: 232.0760 - ca3-[0,5]: 915.1095 - ca3-[6,11]: 552.0760 - ca3-[12,17]: 255.3124 - ca3-[18,23]: 106.2863 - ca4-[0,5]: 0.2942 - ca4-[6,11]: 0.0122 - ca4-[12,17]: 0.0414 - ca4-[18,23]: 1.9680 - val_ca1-[0,5]: 545.4916 - val_ca1-[6,11]: 296.6796 - val_ca1-[12,17]: 103.0095 - val_ca1-[18,23]: 34.1290 - val_ca2-[0,5]: 1189.9612 - val_ca2-[6,11]: 797.0705 - val_ca2-[12,17]: 436.6701 - val_ca2-[18,23]: 207.1040 - val_ca3-[0,5]: 920.0440 - val_ca3-[6,11]: 580.9702 - val_ca3-[12,17]: 282.8540 - val_ca3-[18,23]: 113.2897 - val_ca4-[0,5]: 0.3029 - val_ca4-[6,11]: 0.2531 - val_ca4-[12,17]: 1.2764 - val_ca4-[18,23]: 6.3952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 150.7452 - ca1-[6,11]: 319.8121 - ca1-[12,17]: 98.7113 - ca1-[18,23]: 24.3341 - ca2-[0,5]: 1021.7068 - ca2-[6,11]: 729.8658 - ca2-[12,17]: 517.5973 - ca2-[18,23]: 236.9383 - ca3-[0,5]: 928.9808 - ca3-[6,11]: 565.6154 - ca3-[12,17]: 259.6524 - ca3-[18,23]: 111.3167 - ca4-[0,5]: 0.3008 - ca4-[6,11]: 0.0140 - ca4-[12,17]: 0.0460 - ca4-[18,23]: 1.8651 - val_ca1-[0,5]: 549.6082 - val_ca1-[6,11]: 299.3322 - val_ca1-[12,17]: 104.4438 - val_ca1-[18,23]: 35.0135 - val_ca2-[0,5]: 1199.3992 - val_ca2-[6,11]: 804.2766 - val_ca2-[12,17]: 440.7987 - val_ca2-[18,23]: 211.1797 - val_ca3-[0,5]: 930.1478 - val_ca3-[6,11]: 588.5046 - val_ca3-[12,17]: 287.2843 - val_ca3-[18,23]: 116.7986 - val_ca4-[0,5]: 0.3070 - val_ca4-[6,11]: 0.2525 - val_ca4-[12,17]: 1.2290 - val_ca4-[18,23]: 6.3329\n",
      "Epoch 202/300\n",
      "26/26 [==============================] - 3s 106ms/step - ca1-[0,5]: 152.7651 - ca1-[6,11]: 320.4025 - ca1-[12,17]: 102.0093 - ca1-[18,23]: 26.2088 - ca2-[0,5]: 1027.8142 - ca2-[6,11]: 736.9259 - ca2-[12,17]: 507.5795 - ca2-[18,23]: 241.4525 - ca3-[0,5]: 944.1465 - ca3-[6,11]: 572.1896 - ca3-[12,17]: 270.2443 - ca3-[18,23]: 115.7316 - ca4-[0,5]: 0.3020 - ca4-[6,11]: 0.0134 - ca4-[12,17]: 0.0369 - ca4-[18,23]: 1.7180 - val_ca1-[0,5]: 555.6909 - val_ca1-[6,11]: 305.0288 - val_ca1-[12,17]: 107.4530 - val_ca1-[18,23]: 34.9808 - val_ca2-[0,5]: 1211.8983 - val_ca2-[6,11]: 816.5447 - val_ca2-[12,17]: 449.4659 - val_ca2-[18,23]: 215.3564 - val_ca3-[0,5]: 942.7824 - val_ca3-[6,11]: 600.2701 - val_ca3-[12,17]: 295.1068 - val_ca3-[18,23]: 120.0182 - val_ca4-[0,5]: 0.2986 - val_ca4-[6,11]: 0.2505 - val_ca4-[12,17]: 1.2761 - val_ca4-[18,23]: 6.2835\n",
      "Epoch 203/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 163.8065 - ca1-[6,11]: 322.4356 - ca1-[12,17]: 101.6337 - ca1-[18,23]: 26.6388 - ca2-[0,5]: 1006.6945 - ca2-[6,11]: 720.2003 - ca2-[12,17]: 536.1654 - ca2-[18,23]: 257.6104 - ca3-[0,5]: 955.2989 - ca3-[6,11]: 577.4152 - ca3-[12,17]: 274.5160 - ca3-[18,23]: 116.0264 - ca4-[0,5]: 0.2904 - ca4-[6,11]: 0.0090 - ca4-[12,17]: 0.0282 - ca4-[18,23]: 1.7564 - val_ca1-[0,5]: 563.9594 - val_ca1-[6,11]: 310.6731 - val_ca1-[12,17]: 108.2439 - val_ca1-[18,23]: 35.6143 - val_ca2-[0,5]: 1227.7909 - val_ca2-[6,11]: 829.0113 - val_ca2-[12,17]: 453.1144 - val_ca2-[18,23]: 219.3712 - val_ca3-[0,5]: 958.2695 - val_ca3-[6,11]: 612.0732 - val_ca3-[12,17]: 298.8817 - val_ca3-[18,23]: 123.3598 - val_ca4-[0,5]: 0.3067 - val_ca4-[6,11]: 0.2423 - val_ca4-[12,17]: 1.2550 - val_ca4-[18,23]: 6.0169\n",
      "Epoch 204/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 158.3051 - ca1-[6,11]: 310.9544 - ca1-[12,17]: 106.6386 - ca1-[18,23]: 27.3934 - ca2-[0,5]: 942.0068 - ca2-[6,11]: 758.0958 - ca2-[12,17]: 481.0221 - ca2-[18,23]: 251.6621 - ca3-[0,5]: 967.5280 - ca3-[6,11]: 597.9201 - ca3-[12,17]: 283.4545 - ca3-[18,23]: 122.7000 - ca4-[0,5]: 0.2906 - ca4-[6,11]: 0.0092 - ca4-[12,17]: 0.0295 - ca4-[18,23]: 1.5730 - val_ca1-[0,5]: 569.3448 - val_ca1-[6,11]: 314.1521 - val_ca1-[12,17]: 111.1572 - val_ca1-[18,23]: 36.2033 - val_ca2-[0,5]: 1239.1722 - val_ca2-[6,11]: 837.3694 - val_ca2-[12,17]: 461.4253 - val_ca2-[18,23]: 225.7010 - val_ca3-[0,5]: 969.7255 - val_ca3-[6,11]: 620.3925 - val_ca3-[12,17]: 306.3566 - val_ca3-[18,23]: 128.1570 - val_ca4-[0,5]: 0.3035 - val_ca4-[6,11]: 0.2376 - val_ca4-[12,17]: 1.1803 - val_ca4-[18,23]: 5.6785\n",
      "Epoch 205/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 158.9125 - ca1-[6,11]: 331.2863 - ca1-[12,17]: 108.3229 - ca1-[18,23]: 29.0756 - ca2-[0,5]: 1071.5869 - ca2-[6,11]: 737.8740 - ca2-[12,17]: 445.4579 - ca2-[18,23]: 268.5444 - ca3-[0,5]: 980.5016 - ca3-[6,11]: 610.7691 - ca3-[12,17]: 290.1070 - ca3-[18,23]: 126.4067 - ca4-[0,5]: 0.2864 - ca4-[6,11]: 0.0108 - ca4-[12,17]: 0.0324 - ca4-[18,23]: 1.4559 - val_ca1-[0,5]: 574.5432 - val_ca1-[6,11]: 318.5787 - val_ca1-[12,17]: 113.5387 - val_ca1-[18,23]: 37.1341 - val_ca2-[0,5]: 1250.3993 - val_ca2-[6,11]: 847.7147 - val_ca2-[12,17]: 468.8621 - val_ca2-[18,23]: 230.3986 - val_ca3-[0,5]: 980.7403 - val_ca3-[6,11]: 630.1228 - val_ca3-[12,17]: 312.9652 - val_ca3-[18,23]: 131.9789 - val_ca4-[0,5]: 0.3010 - val_ca4-[6,11]: 0.2328 - val_ca4-[12,17]: 1.1657 - val_ca4-[18,23]: 5.6755\n",
      "Epoch 206/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 159.3077 - ca1-[6,11]: 337.3055 - ca1-[12,17]: 109.7038 - ca1-[18,23]: 28.0954 - ca2-[0,5]: 1000.7762 - ca2-[6,11]: 775.4604 - ca2-[12,17]: 538.7998 - ca2-[18,23]: 273.4778 - ca3-[0,5]: 988.6857 - ca3-[6,11]: 605.4539 - ca3-[12,17]: 293.8464 - ca3-[18,23]: 131.4100 - ca4-[0,5]: 0.2843 - ca4-[6,11]: 0.0185 - ca4-[12,17]: 0.0392 - ca4-[18,23]: 1.4985 - val_ca1-[0,5]: 580.7800 - val_ca1-[6,11]: 322.0304 - val_ca1-[12,17]: 116.0986 - val_ca1-[18,23]: 37.6068 - val_ca2-[0,5]: 1263.2223 - val_ca2-[6,11]: 856.1924 - val_ca2-[12,17]: 476.7029 - val_ca2-[18,23]: 234.5253 - val_ca3-[0,5]: 993.1522 - val_ca3-[6,11]: 638.2938 - val_ca3-[12,17]: 319.8876 - val_ca3-[18,23]: 135.2694 - val_ca4-[0,5]: 0.2989 - val_ca4-[6,11]: 0.2329 - val_ca4-[12,17]: 1.1467 - val_ca4-[18,23]: 5.5695\n",
      "Epoch 207/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 163.0878 - ca1-[6,11]: 336.6969 - ca1-[12,17]: 111.6779 - ca1-[18,23]: 30.4483 - ca2-[0,5]: 1089.3383 - ca2-[6,11]: 785.3595 - ca2-[12,17]: 565.9449 - ca2-[18,23]: 266.5678 - ca3-[0,5]: 1000.4369 - ca3-[6,11]: 622.7964 - ca3-[12,17]: 299.7190 - ca3-[18,23]: 136.0568 - ca4-[0,5]: 0.2871 - ca4-[6,11]: 0.0106 - ca4-[12,17]: 0.0312 - ca4-[18,23]: 1.4676 - val_ca1-[0,5]: 585.9857 - val_ca1-[6,11]: 328.4578 - val_ca1-[12,17]: 118.1359 - val_ca1-[18,23]: 38.5089 - val_ca2-[0,5]: 1274.4801 - val_ca2-[6,11]: 869.9887 - val_ca2-[12,17]: 482.9971 - val_ca2-[18,23]: 241.2920 - val_ca3-[0,5]: 1003.1568 - val_ca3-[6,11]: 650.2562 - val_ca3-[12,17]: 325.2407 - val_ca3-[18,23]: 140.2303 - val_ca4-[0,5]: 0.2948 - val_ca4-[6,11]: 0.2212 - val_ca4-[12,17]: 1.1409 - val_ca4-[18,23]: 5.5806\n",
      "Epoch 208/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 165.1924 - ca1-[6,11]: 345.2866 - ca1-[12,17]: 113.0653 - ca1-[18,23]: 31.7227 - ca2-[0,5]: 1100.8187 - ca2-[6,11]: 795.2997 - ca2-[12,17]: 537.8189 - ca2-[18,23]: 270.1193 - ca3-[0,5]: 1014.8632 - ca3-[6,11]: 603.9372 - ca3-[12,17]: 303.3074 - ca3-[18,23]: 142.7975 - ca4-[0,5]: 0.2841 - ca4-[6,11]: 0.0108 - ca4-[12,17]: 0.0276 - ca4-[18,23]: 1.4449 - val_ca1-[0,5]: 594.0585 - val_ca1-[6,11]: 331.8620 - val_ca1-[12,17]: 122.2375 - val_ca1-[18,23]: 39.9102 - val_ca2-[0,5]: 1290.1437 - val_ca2-[6,11]: 878.5389 - val_ca2-[12,17]: 495.5273 - val_ca2-[18,23]: 246.9206 - val_ca3-[0,5]: 1009.3340 - val_ca3-[6,11]: 652.2919 - val_ca3-[12,17]: 332.2324 - val_ca3-[18,23]: 142.9704 - val_ca4-[0,5]: 0.2964 - val_ca4-[6,11]: 0.2172 - val_ca4-[12,17]: 1.0954 - val_ca4-[18,23]: 5.3963\n",
      "Epoch 209/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 175.2398 - ca1-[6,11]: 353.5605 - ca1-[12,17]: 117.5027 - ca1-[18,23]: 31.4628 - ca2-[0,5]: 1107.2204 - ca2-[6,11]: 808.3852 - ca2-[12,17]: 536.0997 - ca2-[18,23]: 289.1574 - ca3-[0,5]: 988.8568 - ca3-[6,11]: 588.8557 - ca3-[12,17]: 291.0249 - ca3-[18,23]: 133.4378 - ca4-[0,5]: 0.2830 - ca4-[6,11]: 0.0118 - ca4-[12,17]: 0.0342 - ca4-[18,23]: 1.2291 - val_ca1-[0,5]: 598.7635 - val_ca1-[6,11]: 335.7075 - val_ca1-[12,17]: 124.3038 - val_ca1-[18,23]: 40.4819 - val_ca2-[0,5]: 1300.7404 - val_ca2-[6,11]: 887.8148 - val_ca2-[12,17]: 500.8727 - val_ca2-[18,23]: 252.9740 - val_ca3-[0,5]: 449.1675 - val_ca3-[6,11]: 239.8725 - val_ca3-[12,17]: 111.2859 - val_ca3-[18,23]: 43.4562 - val_ca4-[0,5]: 0.2944 - val_ca4-[6,11]: 0.2164 - val_ca4-[12,17]: 1.0801 - val_ca4-[18,23]: 5.1705\n",
      "Epoch 210/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 145.4873 - ca1-[6,11]: 360.9752 - ca1-[12,17]: 120.1438 - ca1-[18,23]: 32.1277 - ca2-[0,5]: 962.8308 - ca2-[6,11]: 817.0074 - ca2-[12,17]: 569.1861 - ca2-[18,23]: 298.6254 - ca3-[0,5]: 292.6261 - ca3-[6,11]: 110.3317 - ca3-[12,17]: 20.0995 - ca3-[18,23]: 13.7267 - ca4-[0,5]: 0.2756 - ca4-[6,11]: 0.0109 - ca4-[12,17]: 0.0282 - ca4-[18,23]: 1.2385 - val_ca1-[0,5]: 604.2145 - val_ca1-[6,11]: 341.4106 - val_ca1-[12,17]: 124.7920 - val_ca1-[18,23]: 41.0633 - val_ca2-[0,5]: 1312.6500 - val_ca2-[6,11]: 900.4198 - val_ca2-[12,17]: 504.3303 - val_ca2-[18,23]: 256.9984 - val_ca3-[0,5]: 107.1719 - val_ca3-[6,11]: 64.6053 - val_ca3-[12,17]: 113.0191 - val_ca3-[18,23]: 85.1078 - val_ca4-[0,5]: 0.2892 - val_ca4-[6,11]: 0.2112 - val_ca4-[12,17]: 1.0716 - val_ca4-[18,23]: 4.9666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 159.1407 - ca1-[6,11]: 362.0911 - ca1-[12,17]: 116.8132 - ca1-[18,23]: 32.4520 - ca2-[0,5]: 1054.7757 - ca2-[6,11]: 826.0082 - ca2-[12,17]: 530.3791 - ca2-[18,23]: 304.4557 - ca3-[0,5]: 88.5465 - ca3-[6,11]: 14.9063 - ca3-[12,17]: 12.3099 - ca3-[18,23]: 27.3667 - ca4-[0,5]: 0.2830 - ca4-[6,11]: 0.0093 - ca4-[12,17]: 0.0266 - ca4-[18,23]: 1.3264 - val_ca1-[0,5]: 612.1013 - val_ca1-[6,11]: 346.5435 - val_ca1-[12,17]: 129.1318 - val_ca1-[18,23]: 41.0944 - val_ca2-[0,5]: 1333.6583 - val_ca2-[6,11]: 917.3094 - val_ca2-[12,17]: 519.1129 - val_ca2-[18,23]: 260.9036 - val_ca3-[0,5]: 64.7043 - val_ca3-[6,11]: 46.0305 - val_ca3-[12,17]: 105.6141 - val_ca3-[18,23]: 81.1372 - val_ca4-[0,5]: 0.2892 - val_ca4-[6,11]: 0.2074 - val_ca4-[12,17]: 1.0597 - val_ca4-[18,23]: 4.9589\n",
      "Epoch 212/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 173.7628 - ca1-[6,11]: 348.7619 - ca1-[12,17]: 124.6030 - ca1-[18,23]: 35.9526 - ca2-[0,5]: 1157.7932 - ca2-[6,11]: 843.8103 - ca2-[12,17]: 613.7531 - ca2-[18,23]: 316.5475 - ca3-[0,5]: 57.5012 - ca3-[6,11]: 6.9127 - ca3-[12,17]: 9.0570 - ca3-[18,23]: 18.4334 - ca4-[0,5]: 0.2783 - ca4-[6,11]: 0.0114 - ca4-[12,17]: 0.0264 - ca4-[18,23]: 1.1969 - val_ca1-[0,5]: 616.4993 - val_ca1-[6,11]: 349.5557 - val_ca1-[12,17]: 132.9053 - val_ca1-[18,23]: 42.5665 - val_ca2-[0,5]: 1376.0461 - val_ca2-[6,11]: 951.1320 - val_ca2-[12,17]: 549.3610 - val_ca2-[18,23]: 283.7477 - val_ca3-[0,5]: 52.8032 - val_ca3-[6,11]: 53.3440 - val_ca3-[12,17]: 110.8561 - val_ca3-[18,23]: 79.6935 - val_ca4-[0,5]: 0.2832 - val_ca4-[6,11]: 0.2082 - val_ca4-[12,17]: 1.0662 - val_ca4-[18,23]: 4.7773\n",
      "Epoch 213/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 146.7365 - ca1-[6,11]: 374.7798 - ca1-[12,17]: 129.4904 - ca1-[18,23]: 39.4091 - ca2-[0,5]: 1154.6553 - ca2-[6,11]: 876.9691 - ca2-[12,17]: 645.1957 - ca2-[18,23]: 321.1793 - ca3-[0,5]: 44.9615 - ca3-[6,11]: 4.2183 - ca3-[12,17]: 5.7825 - ca3-[18,23]: 13.4038 - ca4-[0,5]: 0.2767 - ca4-[6,11]: 0.0071 - ca4-[12,17]: 0.0169 - ca4-[18,23]: 1.1078 - val_ca1-[0,5]: 622.3877 - val_ca1-[6,11]: 356.1483 - val_ca1-[12,17]: 134.8423 - val_ca1-[18,23]: 43.7385 - val_ca2-[0,5]: 1404.1147 - val_ca2-[6,11]: 978.2015 - val_ca2-[12,17]: 565.4413 - val_ca2-[18,23]: 296.0737 - val_ca3-[0,5]: 43.1761 - val_ca3-[6,11]: 48.8666 - val_ca3-[12,17]: 113.2528 - val_ca3-[18,23]: 79.8605 - val_ca4-[0,5]: 0.2686 - val_ca4-[6,11]: 0.2058 - val_ca4-[12,17]: 1.0545 - val_ca4-[18,23]: 4.7619\n",
      "Epoch 214/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 169.9718 - ca1-[6,11]: 354.7768 - ca1-[12,17]: 129.7248 - ca1-[18,23]: 36.6108 - ca2-[0,5]: 1221.9580 - ca2-[6,11]: 902.7995 - ca2-[12,17]: 635.2870 - ca2-[18,23]: 349.8671 - ca3-[0,5]: 35.9868 - ca3-[6,11]: 2.7788 - ca3-[12,17]: 6.0211 - ca3-[18,23]: 11.2855 - ca4-[0,5]: 0.2707 - ca4-[6,11]: 0.0070 - ca4-[12,17]: 0.0166 - ca4-[18,23]: 1.0023 - val_ca1-[0,5]: 629.7443 - val_ca1-[6,11]: 360.9714 - val_ca1-[12,17]: 137.1036 - val_ca1-[18,23]: 43.4754 - val_ca2-[0,5]: 1428.3866 - val_ca2-[6,11]: 997.1053 - val_ca2-[12,17]: 578.7292 - val_ca2-[18,23]: 302.1833 - val_ca3-[0,5]: 37.7685 - val_ca3-[6,11]: 46.0247 - val_ca3-[12,17]: 111.0488 - val_ca3-[18,23]: 79.7500 - val_ca4-[0,5]: 0.2768 - val_ca4-[6,11]: 0.1945 - val_ca4-[12,17]: 0.9970 - val_ca4-[18,23]: 4.6181\n",
      "Epoch 215/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 191.1919 - ca1-[6,11]: 373.2312 - ca1-[12,17]: 133.0840 - ca1-[18,23]: 38.1827 - ca2-[0,5]: 1242.2987 - ca2-[6,11]: 917.5183 - ca2-[12,17]: 648.8485 - ca2-[18,23]: 337.7014 - ca3-[0,5]: 31.9022 - ca3-[6,11]: 2.3868 - ca3-[12,17]: 5.1720 - ca3-[18,23]: 9.9097 - ca4-[0,5]: 0.2748 - ca4-[6,11]: 0.0084 - ca4-[12,17]: 0.0192 - ca4-[18,23]: 1.0706 - val_ca1-[0,5]: 635.2057 - val_ca1-[6,11]: 362.9236 - val_ca1-[12,17]: 140.1047 - val_ca1-[18,23]: 45.3507 - val_ca2-[0,5]: 1447.8092 - val_ca2-[6,11]: 1009.9857 - val_ca2-[12,17]: 592.2945 - val_ca2-[18,23]: 313.5724 - val_ca3-[0,5]: 33.7406 - val_ca3-[6,11]: 42.0200 - val_ca3-[12,17]: 108.2796 - val_ca3-[18,23]: 79.5221 - val_ca4-[0,5]: 0.2754 - val_ca4-[6,11]: 0.1948 - val_ca4-[12,17]: 0.9798 - val_ca4-[18,23]: 4.5172\n",
      "Epoch 216/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 174.3039 - ca1-[6,11]: 380.5250 - ca1-[12,17]: 133.4122 - ca1-[18,23]: 42.4254 - ca2-[0,5]: 1255.7059 - ca2-[6,11]: 901.9892 - ca2-[12,17]: 687.0131 - ca2-[18,23]: 368.7178 - ca3-[0,5]: 28.5006 - ca3-[6,11]: 2.2164 - ca3-[12,17]: 4.4219 - ca3-[18,23]: 8.3732 - ca4-[0,5]: 0.2739 - ca4-[6,11]: 0.0097 - ca4-[12,17]: 0.0237 - ca4-[18,23]: 1.0185 - val_ca1-[0,5]: 643.6319 - val_ca1-[6,11]: 369.1195 - val_ca1-[12,17]: 142.4950 - val_ca1-[18,23]: 46.6996 - val_ca2-[0,5]: 1470.8718 - val_ca2-[6,11]: 1028.7770 - val_ca2-[12,17]: 604.0427 - val_ca2-[18,23]: 324.1493 - val_ca3-[0,5]: 31.1213 - val_ca3-[6,11]: 36.7761 - val_ca3-[12,17]: 101.7660 - val_ca3-[18,23]: 76.2613 - val_ca4-[0,5]: 0.2810 - val_ca4-[6,11]: 0.1943 - val_ca4-[12,17]: 0.9890 - val_ca4-[18,23]: 4.3905\n",
      "Epoch 217/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 195.9705 - ca1-[6,11]: 367.7596 - ca1-[12,17]: 139.7395 - ca1-[18,23]: 40.7564 - ca2-[0,5]: 1279.3580 - ca2-[6,11]: 917.8031 - ca2-[12,17]: 678.0938 - ca2-[18,23]: 359.9806 - ca3-[0,5]: 26.6147 - ca3-[6,11]: 1.7758 - ca3-[12,17]: 3.9019 - ca3-[18,23]: 7.3640 - ca4-[0,5]: 0.2619 - ca4-[6,11]: 0.0067 - ca4-[12,17]: 0.0157 - ca4-[18,23]: 0.9670 - val_ca1-[0,5]: 648.9747 - val_ca1-[6,11]: 373.0762 - val_ca1-[12,17]: 145.7912 - val_ca1-[18,23]: 47.8212 - val_ca2-[0,5]: 1488.5806 - val_ca2-[6,11]: 1043.4833 - val_ca2-[12,17]: 617.1919 - val_ca2-[18,23]: 332.2152 - val_ca3-[0,5]: 29.1080 - val_ca3-[6,11]: 36.4452 - val_ca3-[12,17]: 104.5356 - val_ca3-[18,23]: 75.0598 - val_ca4-[0,5]: 0.2775 - val_ca4-[6,11]: 0.1927 - val_ca4-[12,17]: 1.0077 - val_ca4-[18,23]: 4.5306\n",
      "Epoch 218/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 206.7327 - ca1-[6,11]: 411.7627 - ca1-[12,17]: 140.9157 - ca1-[18,23]: 41.2824 - ca2-[0,5]: 1297.0084 - ca2-[6,11]: 969.2516 - ca2-[12,17]: 687.1065 - ca2-[18,23]: 369.4762 - ca3-[0,5]: 24.6186 - ca3-[6,11]: 1.6435 - ca3-[12,17]: 3.9079 - ca3-[18,23]: 6.4381 - ca4-[0,5]: 0.2660 - ca4-[6,11]: 0.0074 - ca4-[12,17]: 0.0153 - ca4-[18,23]: 0.8006 - val_ca1-[0,5]: 655.8281 - val_ca1-[6,11]: 377.4745 - val_ca1-[12,17]: 148.4675 - val_ca1-[18,23]: 49.6477 - val_ca2-[0,5]: 1508.3892 - val_ca2-[6,11]: 1058.7115 - val_ca2-[12,17]: 628.8641 - val_ca2-[18,23]: 345.1656 - val_ca3-[0,5]: 26.7347 - val_ca3-[6,11]: 30.8970 - val_ca3-[12,17]: 97.1766 - val_ca3-[18,23]: 73.1164 - val_ca4-[0,5]: 0.2663 - val_ca4-[6,11]: 0.1868 - val_ca4-[12,17]: 1.0061 - val_ca4-[18,23]: 4.4165\n",
      "Epoch 219/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 180.9113 - ca1-[6,11]: 401.7992 - ca1-[12,17]: 146.2710 - ca1-[18,23]: 49.0427 - ca2-[0,5]: 1303.0776 - ca2-[6,11]: 981.8218 - ca2-[12,17]: 729.7344 - ca2-[18,23]: 399.2194 - ca3-[0,5]: 23.0532 - ca3-[6,11]: 1.5930 - ca3-[12,17]: 3.4339 - ca3-[18,23]: 5.7042 - ca4-[0,5]: 0.2665 - ca4-[6,11]: 0.0069 - ca4-[12,17]: 0.0131 - ca4-[18,23]: 0.8883 - val_ca1-[0,5]: 662.6464 - val_ca1-[6,11]: 382.6655 - val_ca1-[12,17]: 151.3883 - val_ca1-[18,23]: 49.0906 - val_ca2-[0,5]: 1527.5320 - val_ca2-[6,11]: 1074.9257 - val_ca2-[12,17]: 640.8230 - val_ca2-[18,23]: 346.8457 - val_ca3-[0,5]: 24.9469 - val_ca3-[6,11]: 28.0440 - val_ca3-[12,17]: 96.2989 - val_ca3-[18,23]: 71.9506 - val_ca4-[0,5]: 0.2727 - val_ca4-[6,11]: 0.1820 - val_ca4-[12,17]: 0.9578 - val_ca4-[18,23]: 4.2853\n",
      "Epoch 220/300\n",
      "26/26 [==============================] - 3s 106ms/step - ca1-[0,5]: 191.5870 - ca1-[6,11]: 403.7330 - ca1-[12,17]: 139.5563 - ca1-[18,23]: 44.3698 - ca2-[0,5]: 1331.4408 - ca2-[6,11]: 996.9084 - ca2-[12,17]: 740.2106 - ca2-[18,23]: 405.6889 - ca3-[0,5]: 21.9929 - ca3-[6,11]: 1.4052 - ca3-[12,17]: 3.0939 - ca3-[18,23]: 5.1334 - ca4-[0,5]: 0.2595 - ca4-[6,11]: 0.0050 - ca4-[12,17]: 0.0122 - ca4-[18,23]: 0.8133 - val_ca1-[0,5]: 667.9113 - val_ca1-[6,11]: 387.2462 - val_ca1-[12,17]: 155.0627 - val_ca1-[18,23]: 51.4838 - val_ca2-[0,5]: 1544.0492 - val_ca2-[6,11]: 1089.9817 - val_ca2-[12,17]: 654.0632 - val_ca2-[18,23]: 360.2468 - val_ca3-[0,5]: 24.5739 - val_ca3-[6,11]: 25.9541 - val_ca3-[12,17]: 89.2977 - val_ca3-[18,23]: 68.4674 - val_ca4-[0,5]: 0.2683 - val_ca4-[6,11]: 0.1824 - val_ca4-[12,17]: 0.9757 - val_ca4-[18,23]: 4.1573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 193.8759 - ca1-[6,11]: 409.1581 - ca1-[12,17]: 152.5915 - ca1-[18,23]: 47.2685 - ca2-[0,5]: 1342.6962 - ca2-[6,11]: 1012.0040 - ca2-[12,17]: 692.8050 - ca2-[18,23]: 396.4312 - ca3-[0,5]: 21.4039 - ca3-[6,11]: 1.2883 - ca3-[12,17]: 2.5050 - ca3-[18,23]: 4.1878 - ca4-[0,5]: 0.2577 - ca4-[6,11]: 0.0055 - ca4-[12,17]: 0.0127 - ca4-[18,23]: 0.8004 - val_ca1-[0,5]: 675.7811 - val_ca1-[6,11]: 393.5567 - val_ca1-[12,17]: 157.2079 - val_ca1-[18,23]: 52.1768 - val_ca2-[0,5]: 1564.5532 - val_ca2-[6,11]: 1107.6346 - val_ca2-[12,17]: 664.1221 - val_ca2-[18,23]: 367.2621 - val_ca3-[0,5]: 23.2996 - val_ca3-[6,11]: 21.4701 - val_ca3-[12,17]: 80.8284 - val_ca3-[18,23]: 64.7648 - val_ca4-[0,5]: 0.2703 - val_ca4-[6,11]: 0.1736 - val_ca4-[12,17]: 0.9393 - val_ca4-[18,23]: 3.9877\n",
      "Epoch 222/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 196.1896 - ca1-[6,11]: 403.3184 - ca1-[12,17]: 155.6587 - ca1-[18,23]: 49.0760 - ca2-[0,5]: 1359.4993 - ca2-[6,11]: 1026.0686 - ca2-[12,17]: 768.9445 - ca2-[18,23]: 427.7326 - ca3-[0,5]: 20.2461 - ca3-[6,11]: 1.1785 - ca3-[12,17]: 2.2218 - ca3-[18,23]: 3.5995 - ca4-[0,5]: 0.2553 - ca4-[6,11]: 0.0072 - ca4-[12,17]: 0.0171 - ca4-[18,23]: 0.7723 - val_ca1-[0,5]: 681.0927 - val_ca1-[6,11]: 397.9149 - val_ca1-[12,17]: 160.9874 - val_ca1-[18,23]: 53.6553 - val_ca2-[0,5]: 1580.8760 - val_ca2-[6,11]: 1121.9342 - val_ca2-[12,17]: 677.6357 - val_ca2-[18,23]: 375.3877 - val_ca3-[0,5]: 22.1852 - val_ca3-[6,11]: 20.2735 - val_ca3-[12,17]: 83.1388 - val_ca3-[18,23]: 63.2369 - val_ca4-[0,5]: 0.2642 - val_ca4-[6,11]: 0.1699 - val_ca4-[12,17]: 0.8765 - val_ca4-[18,23]: 3.8817\n",
      "Epoch 223/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 198.5125 - ca1-[6,11]: 425.2451 - ca1-[12,17]: 156.8232 - ca1-[18,23]: 50.3042 - ca2-[0,5]: 1376.1964 - ca2-[6,11]: 1039.6075 - ca2-[12,17]: 752.0383 - ca2-[18,23]: 411.5022 - ca3-[0,5]: 19.1563 - ca3-[6,11]: 1.2013 - ca3-[12,17]: 2.1416 - ca3-[18,23]: 3.3466 - ca4-[0,5]: 0.2509 - ca4-[6,11]: 0.0078 - ca4-[12,17]: 0.0176 - ca4-[18,23]: 0.7530 - val_ca1-[0,5]: 690.2581 - val_ca1-[6,11]: 404.2903 - val_ca1-[12,17]: 164.3961 - val_ca1-[18,23]: 53.9417 - val_ca2-[0,5]: 1603.1172 - val_ca2-[6,11]: 1139.7817 - val_ca2-[12,17]: 692.7407 - val_ca2-[18,23]: 380.4726 - val_ca3-[0,5]: 21.6885 - val_ca3-[6,11]: 17.8714 - val_ca3-[12,17]: 79.0371 - val_ca3-[18,23]: 60.3953 - val_ca4-[0,5]: 0.2666 - val_ca4-[6,11]: 0.2049 - val_ca4-[12,17]: 1.1016 - val_ca4-[18,23]: 4.3711\n",
      "Epoch 224/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 213.1863 - ca1-[6,11]: 418.3603 - ca1-[12,17]: 160.9158 - ca1-[18,23]: 49.6592 - ca2-[0,5]: 1381.1473 - ca2-[6,11]: 1055.0525 - ca2-[12,17]: 795.2575 - ca2-[18,23]: 443.2234 - ca3-[0,5]: 19.0085 - ca3-[6,11]: 1.0797 - ca3-[12,17]: 1.7466 - ca3-[18,23]: 2.9734 - ca4-[0,5]: 0.2510 - ca4-[6,11]: 0.0087 - ca4-[12,17]: 0.0161 - ca4-[18,23]: 0.7232 - val_ca1-[0,5]: 694.8115 - val_ca1-[6,11]: 407.9113 - val_ca1-[12,17]: 166.6061 - val_ca1-[18,23]: 55.4937 - val_ca2-[0,5]: 1617.9828 - val_ca2-[6,11]: 1152.4026 - val_ca2-[12,17]: 699.9840 - val_ca2-[18,23]: 391.2220 - val_ca3-[0,5]: 20.4858 - val_ca3-[6,11]: 15.7315 - val_ca3-[12,17]: 73.6626 - val_ca3-[18,23]: 58.0059 - val_ca4-[0,5]: 0.2512 - val_ca4-[6,11]: 0.1584 - val_ca4-[12,17]: 0.8562 - val_ca4-[18,23]: 3.7462\n",
      "Epoch 225/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 203.1938 - ca1-[6,11]: 401.1433 - ca1-[12,17]: 166.2879 - ca1-[18,23]: 53.0089 - ca2-[0,5]: 1409.3743 - ca2-[6,11]: 1068.3299 - ca2-[12,17]: 817.4641 - ca2-[18,23]: 450.3731 - ca3-[0,5]: 18.3101 - ca3-[6,11]: 1.0684 - ca3-[12,17]: 1.5194 - ca3-[18,23]: 2.4592 - ca4-[0,5]: 0.2493 - ca4-[6,11]: 0.0062 - ca4-[12,17]: 0.0138 - ca4-[18,23]: 0.6683 - val_ca1-[0,5]: 700.7130 - val_ca1-[6,11]: 414.2497 - val_ca1-[12,17]: 170.1478 - val_ca1-[18,23]: 56.7596 - val_ca2-[0,5]: 1634.7029 - val_ca2-[6,11]: 1169.7966 - val_ca2-[12,17]: 712.8531 - val_ca2-[18,23]: 399.5247 - val_ca3-[0,5]: 20.1668 - val_ca3-[6,11]: 13.2227 - val_ca3-[12,17]: 65.7597 - val_ca3-[18,23]: 54.9327 - val_ca4-[0,5]: 0.2573 - val_ca4-[6,11]: 0.1671 - val_ca4-[12,17]: 0.9027 - val_ca4-[18,23]: 3.7759\n",
      "Epoch 226/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 192.8536 - ca1-[6,11]: 431.2294 - ca1-[12,17]: 168.1683 - ca1-[18,23]: 52.8979 - ca2-[0,5]: 1380.1229 - ca2-[6,11]: 1084.4363 - ca2-[12,17]: 722.9654 - ca2-[18,23]: 439.7838 - ca3-[0,5]: 18.0332 - ca3-[6,11]: 0.9876 - ca3-[12,17]: 1.4379 - ca3-[18,23]: 2.2629 - ca4-[0,5]: 0.2449 - ca4-[6,11]: 0.0057 - ca4-[12,17]: 0.0135 - ca4-[18,23]: 0.6488 - val_ca1-[0,5]: 709.8954 - val_ca1-[6,11]: 418.7979 - val_ca1-[12,17]: 172.6368 - val_ca1-[18,23]: 58.4838 - val_ca2-[0,5]: 1656.7505 - val_ca2-[6,11]: 1184.0795 - val_ca2-[12,17]: 723.0519 - val_ca2-[18,23]: 409.1044 - val_ca3-[0,5]: 19.9127 - val_ca3-[6,11]: 12.4551 - val_ca3-[12,17]: 62.9734 - val_ca3-[18,23]: 52.6950 - val_ca4-[0,5]: 0.2619 - val_ca4-[6,11]: 0.1728 - val_ca4-[12,17]: 0.9596 - val_ca4-[18,23]: 3.8424\n",
      "Epoch 227/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 220.7864 - ca1-[6,11]: 432.2442 - ca1-[12,17]: 172.5954 - ca1-[18,23]: 56.0275 - ca2-[0,5]: 1396.0920 - ca2-[6,11]: 1099.6163 - ca2-[12,17]: 797.6471 - ca2-[18,23]: 449.3164 - ca3-[0,5]: 17.2975 - ca3-[6,11]: 0.9573 - ca3-[12,17]: 1.2651 - ca3-[18,23]: 2.0816 - ca4-[0,5]: 0.2471 - ca4-[6,11]: 0.0052 - ca4-[12,17]: 0.0122 - ca4-[18,23]: 0.5542 - val_ca1-[0,5]: 717.7267 - val_ca1-[6,11]: 422.3211 - val_ca1-[12,17]: 176.2358 - val_ca1-[18,23]: 60.6798 - val_ca2-[0,5]: 1676.5721 - val_ca2-[6,11]: 1196.6068 - val_ca2-[12,17]: 736.0984 - val_ca2-[18,23]: 419.6966 - val_ca3-[0,5]: 19.6184 - val_ca3-[6,11]: 11.7393 - val_ca3-[12,17]: 63.2169 - val_ca3-[18,23]: 52.0756 - val_ca4-[0,5]: 0.2602 - val_ca4-[6,11]: 0.1565 - val_ca4-[12,17]: 0.8336 - val_ca4-[18,23]: 3.6418\n",
      "Epoch 228/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 210.3202 - ca1-[6,11]: 447.4956 - ca1-[12,17]: 174.9880 - ca1-[18,23]: 55.8630 - ca2-[0,5]: 1406.1382 - ca2-[6,11]: 1117.0248 - ca2-[12,17]: 840.7526 - ca2-[18,23]: 459.7152 - ca3-[0,5]: 17.0913 - ca3-[6,11]: 0.7942 - ca3-[12,17]: 1.2212 - ca3-[18,23]: 1.7294 - ca4-[0,5]: 0.2429 - ca4-[6,11]: 0.0059 - ca4-[12,17]: 0.0132 - ca4-[18,23]: 0.5884 - val_ca1-[0,5]: 720.6727 - val_ca1-[6,11]: 428.1023 - val_ca1-[12,17]: 178.1540 - val_ca1-[18,23]: 60.7351 - val_ca2-[0,5]: 1688.6067 - val_ca2-[6,11]: 1212.9006 - val_ca2-[12,17]: 744.9090 - val_ca2-[18,23]: 423.8363 - val_ca3-[0,5]: 18.8785 - val_ca3-[6,11]: 9.8345 - val_ca3-[12,17]: 57.9212 - val_ca3-[18,23]: 51.3065 - val_ca4-[0,5]: 0.2487 - val_ca4-[6,11]: 0.1690 - val_ca4-[12,17]: 0.9471 - val_ca4-[18,23]: 3.8025\n",
      "Epoch 229/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 234.8034 - ca1-[6,11]: 410.9774 - ca1-[12,17]: 177.4218 - ca1-[18,23]: 61.0004 - ca2-[0,5]: 1481.5071 - ca2-[6,11]: 1128.9755 - ca2-[12,17]: 789.3842 - ca2-[18,23]: 488.4826 - ca3-[0,5]: 16.4480 - ca3-[6,11]: 0.8136 - ca3-[12,17]: 1.0859 - ca3-[18,23]: 1.9154 - ca4-[0,5]: 0.2370 - ca4-[6,11]: 0.0059 - ca4-[12,17]: 0.0144 - ca4-[18,23]: 0.5574 - val_ca1-[0,5]: 729.3162 - val_ca1-[6,11]: 434.0934 - val_ca1-[12,17]: 181.7932 - val_ca1-[18,23]: 62.5323 - val_ca2-[0,5]: 1709.5686 - val_ca2-[6,11]: 1229.5914 - val_ca2-[12,17]: 757.7189 - val_ca2-[18,23]: 434.8584 - val_ca3-[0,5]: 18.5526 - val_ca3-[6,11]: 8.4136 - val_ca3-[12,17]: 55.3821 - val_ca3-[18,23]: 48.2332 - val_ca4-[0,5]: 0.2548 - val_ca4-[6,11]: 0.1487 - val_ca4-[12,17]: 0.7971 - val_ca4-[18,23]: 3.3955\n",
      "Epoch 230/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 210.6891 - ca1-[6,11]: 450.4073 - ca1-[12,17]: 180.7102 - ca1-[18,23]: 62.5996 - ca2-[0,5]: 1498.0871 - ca2-[6,11]: 1146.6016 - ca2-[12,17]: 836.9614 - ca2-[18,23]: 474.8318 - ca3-[0,5]: 16.4853 - ca3-[6,11]: 0.7996 - ca3-[12,17]: 0.9415 - ca3-[18,23]: 1.8724 - ca4-[0,5]: 0.2432 - ca4-[6,11]: 0.0083 - ca4-[12,17]: 0.0155 - ca4-[18,23]: 0.5462 - val_ca1-[0,5]: 734.9349 - val_ca1-[6,11]: 440.3560 - val_ca1-[12,17]: 186.9528 - val_ca1-[18,23]: 63.1689 - val_ca2-[0,5]: 1725.7174 - val_ca2-[6,11]: 1246.8937 - val_ca2-[12,17]: 774.6660 - val_ca2-[18,23]: 440.9521 - val_ca3-[0,5]: 18.3185 - val_ca3-[6,11]: 7.8034 - val_ca3-[12,17]: 53.0202 - val_ca3-[18,23]: 48.0954 - val_ca4-[0,5]: 0.2482 - val_ca4-[6,11]: 0.1524 - val_ca4-[12,17]: 0.8703 - val_ca4-[18,23]: 3.5878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/300\n",
      "26/26 [==============================] - 3s 106ms/step - ca1-[0,5]: 204.0012 - ca1-[6,11]: 457.8041 - ca1-[12,17]: 184.0070 - ca1-[18,23]: 61.9922 - ca2-[0,5]: 1514.6860 - ca2-[6,11]: 1157.1943 - ca2-[12,17]: 881.2230 - ca2-[18,23]: 484.1238 - ca3-[0,5]: 16.6041 - ca3-[6,11]: 0.7638 - ca3-[12,17]: 0.8878 - ca3-[18,23]: 1.9571 - ca4-[0,5]: 0.2372 - ca4-[6,11]: 0.0094 - ca4-[12,17]: 0.0233 - ca4-[18,23]: 0.5290 - val_ca1-[0,5]: 742.1128 - val_ca1-[6,11]: 443.8648 - val_ca1-[12,17]: 189.2883 - val_ca1-[18,23]: 66.0369 - val_ca2-[0,5]: 1744.2930 - val_ca2-[6,11]: 1259.1913 - val_ca2-[12,17]: 783.8378 - val_ca2-[18,23]: 453.9879 - val_ca3-[0,5]: 17.9563 - val_ca3-[6,11]: 6.6688 - val_ca3-[12,17]: 47.2263 - val_ca3-[18,23]: 44.0028 - val_ca4-[0,5]: 0.2481 - val_ca4-[6,11]: 0.1471 - val_ca4-[12,17]: 0.7843 - val_ca4-[18,23]: 3.3167\n",
      "Epoch 232/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 201.9930 - ca1-[6,11]: 433.3938 - ca1-[12,17]: 186.9633 - ca1-[18,23]: 63.0655 - ca2-[0,5]: 1531.2945 - ca2-[6,11]: 1174.6994 - ca2-[12,17]: 889.5955 - ca2-[18,23]: 518.3479 - ca3-[0,5]: 16.2138 - ca3-[6,11]: 0.8618 - ca3-[12,17]: 1.0772 - ca3-[18,23]: 2.0997 - ca4-[0,5]: 0.2334 - ca4-[6,11]: 0.0093 - ca4-[12,17]: 0.0211 - ca4-[18,23]: 0.5029 - val_ca1-[0,5]: 748.0109 - val_ca1-[6,11]: 448.5237 - val_ca1-[12,17]: 193.4901 - val_ca1-[18,23]: 67.3148 - val_ca2-[0,5]: 1760.8912 - val_ca2-[6,11]: 1273.3518 - val_ca2-[12,17]: 797.1259 - val_ca2-[18,23]: 461.7389 - val_ca3-[0,5]: 17.5689 - val_ca3-[6,11]: 5.9821 - val_ca3-[12,17]: 43.9202 - val_ca3-[18,23]: 43.8209 - val_ca4-[0,5]: 0.2383 - val_ca4-[6,11]: 0.1479 - val_ca4-[12,17]: 0.8453 - val_ca4-[18,23]: 3.4461\n",
      "Epoch 233/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 194.5904 - ca1-[6,11]: 448.5568 - ca1-[12,17]: 190.2448 - ca1-[18,23]: 66.0013 - ca2-[0,5]: 1541.8558 - ca2-[6,11]: 1187.1512 - ca2-[12,17]: 868.0541 - ca2-[18,23]: 528.8473 - ca3-[0,5]: 15.9305 - ca3-[6,11]: 0.9044 - ca3-[12,17]: 1.2043 - ca3-[18,23]: 2.7713 - ca4-[0,5]: 0.2303 - ca4-[6,11]: 0.0071 - ca4-[12,17]: 0.0157 - ca4-[18,23]: 0.4757 - val_ca1-[0,5]: 757.0269 - val_ca1-[6,11]: 454.0155 - val_ca1-[12,17]: 195.9964 - val_ca1-[18,23]: 70.0127 - val_ca2-[0,5]: 1782.3646 - val_ca2-[6,11]: 1289.0142 - val_ca2-[12,17]: 807.9921 - val_ca2-[18,23]: 474.5438 - val_ca3-[0,5]: 17.6064 - val_ca3-[6,11]: 5.7653 - val_ca3-[12,17]: 42.3446 - val_ca3-[18,23]: 42.7039 - val_ca4-[0,5]: 0.2439 - val_ca4-[6,11]: 0.1516 - val_ca4-[12,17]: 0.8437 - val_ca4-[18,23]: 3.4881\n",
      "Epoch 234/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 224.9611 - ca1-[6,11]: 453.9590 - ca1-[12,17]: 194.5606 - ca1-[18,23]: 70.8453 - ca2-[0,5]: 1508.0634 - ca2-[6,11]: 1207.6055 - ca2-[12,17]: 918.6587 - ca2-[18,23]: 535.3750 - ca3-[0,5]: 15.6535 - ca3-[6,11]: 0.7745 - ca3-[12,17]: 0.9993 - ca3-[18,23]: 2.3897 - ca4-[0,5]: 0.2294 - ca4-[6,11]: 0.0079 - ca4-[12,17]: 0.0211 - ca4-[18,23]: 0.4519 - val_ca1-[0,5]: 761.6617 - val_ca1-[6,11]: 459.8437 - val_ca1-[12,17]: 198.3881 - val_ca1-[18,23]: 70.4165 - val_ca2-[0,5]: 1796.9316 - val_ca2-[6,11]: 1305.4607 - val_ca2-[12,17]: 817.8621 - val_ca2-[18,23]: 480.1634 - val_ca3-[0,5]: 17.3838 - val_ca3-[6,11]: 5.5592 - val_ca3-[12,17]: 37.9519 - val_ca3-[18,23]: 40.7331 - val_ca4-[0,5]: 0.2402 - val_ca4-[6,11]: 0.1435 - val_ca4-[12,17]: 0.8169 - val_ca4-[18,23]: 3.3026\n",
      "Epoch 235/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 241.7410 - ca1-[6,11]: 472.0759 - ca1-[12,17]: 194.0529 - ca1-[18,23]: 71.7140 - ca2-[0,5]: 1575.2215 - ca2-[6,11]: 1219.4880 - ca2-[12,17]: 927.0311 - ca2-[18,23]: 521.2743 - ca3-[0,5]: 15.6098 - ca3-[6,11]: 0.7386 - ca3-[12,17]: 0.8655 - ca3-[18,23]: 2.2896 - ca4-[0,5]: 0.2276 - ca4-[6,11]: 0.0073 - ca4-[12,17]: 0.0155 - ca4-[18,23]: 0.4258 - val_ca1-[0,5]: 771.2189 - val_ca1-[6,11]: 463.0353 - val_ca1-[12,17]: 202.0656 - val_ca1-[18,23]: 72.2796 - val_ca2-[0,5]: 1819.2177 - val_ca2-[6,11]: 1317.1083 - val_ca2-[12,17]: 830.5288 - val_ca2-[18,23]: 490.4811 - val_ca3-[0,5]: 17.4849 - val_ca3-[6,11]: 5.4829 - val_ca3-[12,17]: 39.2841 - val_ca3-[18,23]: 40.8418 - val_ca4-[0,5]: 0.2405 - val_ca4-[6,11]: 0.1370 - val_ca4-[12,17]: 0.7806 - val_ca4-[18,23]: 3.2187\n",
      "Epoch 236/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 229.9510 - ca1-[6,11]: 480.9164 - ca1-[12,17]: 202.4735 - ca1-[18,23]: 73.7195 - ca2-[0,5]: 1598.1220 - ca2-[6,11]: 1236.0883 - ca2-[12,17]: 863.3460 - ca2-[18,23]: 552.7801 - ca3-[0,5]: 15.6164 - ca3-[6,11]: 0.6936 - ca3-[12,17]: 0.8226 - ca3-[18,23]: 2.0547 - ca4-[0,5]: 0.2302 - ca4-[6,11]: 0.0071 - ca4-[12,17]: 0.0169 - ca4-[18,23]: 0.4155 - val_ca1-[0,5]: 776.2557 - val_ca1-[6,11]: 468.4747 - val_ca1-[12,17]: 203.9467 - val_ca1-[18,23]: 73.9061 - val_ca2-[0,5]: 1834.3152 - val_ca2-[6,11]: 1332.7480 - val_ca2-[12,17]: 839.3153 - val_ca2-[18,23]: 498.6442 - val_ca3-[0,5]: 17.2207 - val_ca3-[6,11]: 5.2198 - val_ca3-[12,17]: 36.7648 - val_ca3-[18,23]: 38.6525 - val_ca4-[0,5]: 0.2299 - val_ca4-[6,11]: 0.1452 - val_ca4-[12,17]: 0.8551 - val_ca4-[18,23]: 3.3507\n",
      "Epoch 237/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 232.4730 - ca1-[6,11]: 487.1537 - ca1-[12,17]: 200.3968 - ca1-[18,23]: 77.2833 - ca2-[0,5]: 1497.9138 - ca2-[6,11]: 1249.3873 - ca2-[12,17]: 945.9850 - ca2-[18,23]: 541.2217 - ca3-[0,5]: 15.1903 - ca3-[6,11]: 0.6616 - ca3-[12,17]: 0.7450 - ca3-[18,23]: 2.0431 - ca4-[0,5]: 0.2267 - ca4-[6,11]: 0.0066 - ca4-[12,17]: 0.0130 - ca4-[18,23]: 0.3919 - val_ca1-[0,5]: 785.1440 - val_ca1-[6,11]: 477.5937 - val_ca1-[12,17]: 209.4247 - val_ca1-[18,23]: 75.6666 - val_ca2-[0,5]: 1855.3833 - val_ca2-[6,11]: 1354.6859 - val_ca2-[12,17]: 855.9995 - val_ca2-[18,23]: 509.0024 - val_ca3-[0,5]: 17.1884 - val_ca3-[6,11]: 4.7874 - val_ca3-[12,17]: 33.6012 - val_ca3-[18,23]: 37.6469 - val_ca4-[0,5]: 0.2373 - val_ca4-[6,11]: 0.1425 - val_ca4-[12,17]: 0.8043 - val_ca4-[18,23]: 3.1899\n",
      "Epoch 238/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 235.0122 - ca1-[6,11]: 489.9712 - ca1-[12,17]: 206.1968 - ca1-[18,23]: 74.6511 - ca2-[0,5]: 1625.4924 - ca2-[6,11]: 1266.2675 - ca2-[12,17]: 977.1025 - ca2-[18,23]: 574.9127 - ca3-[0,5]: 15.3931 - ca3-[6,11]: 0.7260 - ca3-[12,17]: 0.8815 - ca3-[18,23]: 1.9389 - ca4-[0,5]: 0.2232 - ca4-[6,11]: 0.0068 - ca4-[12,17]: 0.0162 - ca4-[18,23]: 0.3883 - val_ca1-[0,5]: 790.9999 - val_ca1-[6,11]: 478.8537 - val_ca1-[12,17]: 212.8339 - val_ca1-[18,23]: 76.0823 - val_ca2-[0,5]: 1871.8553 - val_ca2-[6,11]: 1363.0652 - val_ca2-[12,17]: 867.9345 - val_ca2-[18,23]: 512.6341 - val_ca3-[0,5]: 16.9429 - val_ca3-[6,11]: 4.7380 - val_ca3-[12,17]: 30.8174 - val_ca3-[18,23]: 36.6787 - val_ca4-[0,5]: 0.2320 - val_ca4-[6,11]: 0.1427 - val_ca4-[12,17]: 0.8368 - val_ca4-[18,23]: 3.4310\n",
      "Epoch 239/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 218.8716 - ca1-[6,11]: 501.7927 - ca1-[12,17]: 204.2953 - ca1-[18,23]: 82.7568 - ca2-[0,5]: 1588.8915 - ca2-[6,11]: 1278.1003 - ca2-[12,17]: 944.7961 - ca2-[18,23]: 584.4220 - ca3-[0,5]: 15.1138 - ca3-[6,11]: 0.6430 - ca3-[12,17]: 0.8064 - ca3-[18,23]: 1.9801 - ca4-[0,5]: 0.2224 - ca4-[6,11]: 0.0066 - ca4-[12,17]: 0.0176 - ca4-[18,23]: 0.3788 - val_ca1-[0,5]: 798.7084 - val_ca1-[6,11]: 486.3138 - val_ca1-[12,17]: 214.5221 - val_ca1-[18,23]: 79.1806 - val_ca2-[0,5]: 1891.1371 - val_ca2-[6,11]: 1382.0367 - val_ca2-[12,17]: 876.7087 - val_ca2-[18,23]: 527.7988 - val_ca3-[0,5]: 16.8772 - val_ca3-[6,11]: 4.3786 - val_ca3-[12,17]: 29.7107 - val_ca3-[18,23]: 34.8358 - val_ca4-[0,5]: 0.2333 - val_ca4-[6,11]: 0.1368 - val_ca4-[12,17]: 0.7975 - val_ca4-[18,23]: 3.1445\n",
      "Epoch 240/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 255.3430 - ca1-[6,11]: 473.8742 - ca1-[12,17]: 217.3597 - ca1-[18,23]: 83.5405 - ca2-[0,5]: 1665.5548 - ca2-[6,11]: 1295.2485 - ca2-[12,17]: 954.4028 - ca2-[18,23]: 593.8853 - ca3-[0,5]: 15.0086 - ca3-[6,11]: 0.7167 - ca3-[12,17]: 0.7943 - ca3-[18,23]: 2.4012 - ca4-[0,5]: 0.2241 - ca4-[6,11]: 0.0054 - ca4-[12,17]: 0.0099 - ca4-[18,23]: 0.3541 - val_ca1-[0,5]: 805.2411 - val_ca1-[6,11]: 491.5797 - val_ca1-[12,17]: 221.6720 - val_ca1-[18,23]: 81.8713 - val_ca2-[0,5]: 1908.6033 - val_ca2-[6,11]: 1397.4117 - val_ca2-[12,17]: 897.5943 - val_ca2-[18,23]: 538.9932 - val_ca3-[0,5]: 16.7170 - val_ca3-[6,11]: 4.2117 - val_ca3-[12,17]: 26.4931 - val_ca3-[18,23]: 34.6088 - val_ca4-[0,5]: 0.2310 - val_ca4-[6,11]: 0.1256 - val_ca4-[12,17]: 0.7342 - val_ca4-[18,23]: 3.0576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 258.1064 - ca1-[6,11]: 498.1916 - ca1-[12,17]: 216.9621 - ca1-[18,23]: 82.1623 - ca2-[0,5]: 1615.1638 - ca2-[6,11]: 1310.8146 - ca2-[12,17]: 998.7088 - ca2-[18,23]: 599.0051 - ca3-[0,5]: 15.0183 - ca3-[6,11]: 0.6473 - ca3-[12,17]: 0.7921 - ca3-[18,23]: 2.2640 - ca4-[0,5]: 0.2160 - ca4-[6,11]: 0.0058 - ca4-[12,17]: 0.0115 - ca4-[18,23]: 0.1903 - val_ca1-[0,5]: 812.8669 - val_ca1-[6,11]: 499.8154 - val_ca1-[12,17]: 222.5800 - val_ca1-[18,23]: 82.4808 - val_ca2-[0,5]: 1927.8594 - val_ca2-[6,11]: 1417.8438 - val_ca2-[12,17]: 903.1790 - val_ca2-[18,23]: 545.1348 - val_ca3-[0,5]: 16.6092 - val_ca3-[6,11]: 4.2376 - val_ca3-[12,17]: 27.4701 - val_ca3-[18,23]: 31.7388 - val_ca4-[0,5]: 0.2269 - val_ca4-[6,11]: 0.1333 - val_ca4-[12,17]: 0.7932 - val_ca4-[18,23]: 3.1081\n",
      "Epoch 242/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 229.6470 - ca1-[6,11]: 486.4708 - ca1-[12,17]: 220.9219 - ca1-[18,23]: 87.0333 - ca2-[0,5]: 1576.1780 - ca2-[6,11]: 1328.8126 - ca2-[12,17]: 974.6721 - ca2-[18,23]: 614.9361 - ca3-[0,5]: 15.0036 - ca3-[6,11]: 0.5968 - ca3-[12,17]: 0.6924 - ca3-[18,23]: 2.0336 - ca4-[0,5]: 0.2130 - ca4-[6,11]: 0.0053 - ca4-[12,17]: 0.0114 - ca4-[18,23]: 0.3121 - val_ca1-[0,5]: 820.9246 - val_ca1-[6,11]: 505.7964 - val_ca1-[12,17]: 222.7875 - val_ca1-[18,23]: 85.2224 - val_ca2-[0,5]: 1947.7229 - val_ca2-[6,11]: 1434.1530 - val_ca2-[12,17]: 908.8956 - val_ca2-[18,23]: 557.8349 - val_ca3-[0,5]: 16.5169 - val_ca3-[6,11]: 4.1641 - val_ca3-[12,17]: 25.5235 - val_ca3-[18,23]: 33.3688 - val_ca4-[0,5]: 0.2248 - val_ca4-[6,11]: 0.1278 - val_ca4-[12,17]: 0.7773 - val_ca4-[18,23]: 3.0521\n",
      "Epoch 243/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 247.8809 - ca1-[6,11]: 487.7647 - ca1-[12,17]: 225.2126 - ca1-[18,23]: 88.0243 - ca2-[0,5]: 1716.5813 - ca2-[6,11]: 1340.6592 - ca2-[12,17]: 996.8675 - ca2-[18,23]: 593.8489 - ca3-[0,5]: 14.7282 - ca3-[6,11]: 0.5662 - ca3-[12,17]: 0.5787 - ca3-[18,23]: 1.8168 - ca4-[0,5]: 0.2130 - ca4-[6,11]: 0.0080 - ca4-[12,17]: 0.0147 - ca4-[18,23]: 0.2912 - val_ca1-[0,5]: 829.3964 - val_ca1-[6,11]: 508.5513 - val_ca1-[12,17]: 231.4723 - val_ca1-[18,23]: 85.8218 - val_ca2-[0,5]: 1968.1799 - val_ca2-[6,11]: 1445.2161 - val_ca2-[12,17]: 932.0365 - val_ca2-[18,23]: 563.7926 - val_ca3-[0,5]: 16.5578 - val_ca3-[6,11]: 4.0431 - val_ca3-[12,17]: 23.3908 - val_ca3-[18,23]: 31.3185 - val_ca4-[0,5]: 0.2259 - val_ca4-[6,11]: 0.1181 - val_ca4-[12,17]: 0.6861 - val_ca4-[18,23]: 2.8929\n",
      "Epoch 244/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 266.4990 - ca1-[6,11]: 467.9789 - ca1-[12,17]: 233.3480 - ca1-[18,23]: 90.7620 - ca2-[0,5]: 1733.7100 - ca2-[6,11]: 1353.0338 - ca2-[12,17]: 1039.0150 - ca2-[18,23]: 636.1371 - ca3-[0,5]: 14.8811 - ca3-[6,11]: 0.5777 - ca3-[12,17]: 0.6656 - ca3-[18,23]: 2.1255 - ca4-[0,5]: 0.2092 - ca4-[6,11]: 0.0084 - ca4-[12,17]: 0.0177 - ca4-[18,23]: 0.2818 - val_ca1-[0,5]: 834.5632 - val_ca1-[6,11]: 515.8210 - val_ca1-[12,17]: 235.9821 - val_ca1-[18,23]: 88.5155 - val_ca2-[0,5]: 1983.4689 - val_ca2-[6,11]: 1463.8358 - val_ca2-[12,17]: 946.0162 - val_ca2-[18,23]: 575.9516 - val_ca3-[0,5]: 16.2793 - val_ca3-[6,11]: 3.8323 - val_ca3-[12,17]: 21.2735 - val_ca3-[18,23]: 28.6966 - val_ca4-[0,5]: 0.2214 - val_ca4-[6,11]: 0.1274 - val_ca4-[12,17]: 0.7553 - val_ca4-[18,23]: 2.9617\n",
      "Epoch 245/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 269.3304 - ca1-[6,11]: 530.1316 - ca1-[12,17]: 233.1089 - ca1-[18,23]: 90.9329 - ca2-[0,5]: 1750.8983 - ca2-[6,11]: 1371.6024 - ca2-[12,17]: 1057.8235 - ca2-[18,23]: 643.8060 - ca3-[0,5]: 14.8940 - ca3-[6,11]: 0.7194 - ca3-[12,17]: 0.9789 - ca3-[18,23]: 2.4572 - ca4-[0,5]: 0.2083 - ca4-[6,11]: 0.0060 - ca4-[12,17]: 0.0114 - ca4-[18,23]: 0.2580 - val_ca1-[0,5]: 842.8683 - val_ca1-[6,11]: 518.5175 - val_ca1-[12,17]: 240.1906 - val_ca1-[18,23]: 88.4785 - val_ca2-[0,5]: 2003.8925 - val_ca2-[6,11]: 1474.7773 - val_ca2-[12,17]: 962.4393 - val_ca2-[18,23]: 578.6782 - val_ca3-[0,5]: 16.1072 - val_ca3-[6,11]: 3.6858 - val_ca3-[12,17]: 21.1865 - val_ca3-[18,23]: 30.8103 - val_ca4-[0,5]: 0.2172 - val_ca4-[6,11]: 0.1329 - val_ca4-[12,17]: 0.7870 - val_ca4-[18,23]: 3.1902\n",
      "Epoch 246/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 255.7785 - ca1-[6,11]: 529.4614 - ca1-[12,17]: 226.4883 - ca1-[18,23]: 95.2494 - ca2-[0,5]: 1768.1429 - ca2-[6,11]: 1390.2279 - ca2-[12,17]: 977.5705 - ca2-[18,23]: 655.6070 - ca3-[0,5]: 14.3849 - ca3-[6,11]: 0.5947 - ca3-[12,17]: 1.0361 - ca3-[18,23]: 2.6764 - ca4-[0,5]: 0.2040 - ca4-[6,11]: 0.0054 - ca4-[12,17]: 0.0106 - ca4-[18,23]: 0.2459 - val_ca1-[0,5]: 849.9357 - val_ca1-[6,11]: 526.0111 - val_ca1-[12,17]: 245.6437 - val_ca1-[18,23]: 92.1603 - val_ca2-[0,5]: 2022.2217 - val_ca2-[6,11]: 1493.9487 - val_ca2-[12,17]: 978.5994 - val_ca2-[18,23]: 594.3973 - val_ca3-[0,5]: 16.2201 - val_ca3-[6,11]: 3.9073 - val_ca3-[12,17]: 20.6126 - val_ca3-[18,23]: 29.8879 - val_ca4-[0,5]: 0.2129 - val_ca4-[6,11]: 0.1269 - val_ca4-[12,17]: 0.7646 - val_ca4-[18,23]: 2.9978\n",
      "Epoch 247/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 232.1241 - ca1-[6,11]: 552.2125 - ca1-[12,17]: 242.6494 - ca1-[18,23]: 97.0281 - ca2-[0,5]: 1655.6832 - ca2-[6,11]: 1404.4214 - ca2-[12,17]: 1079.9178 - ca2-[18,23]: 637.2466 - ca3-[0,5]: 14.5120 - ca3-[6,11]: 0.6650 - ca3-[12,17]: 0.7415 - ca3-[18,23]: 1.9453 - ca4-[0,5]: 0.2036 - ca4-[6,11]: 0.0045 - ca4-[12,17]: 0.0089 - ca4-[18,23]: 0.2633 - val_ca1-[0,5]: 856.5411 - val_ca1-[6,11]: 534.9083 - val_ca1-[12,17]: 246.5617 - val_ca1-[18,23]: 94.7643 - val_ca2-[0,5]: 2039.6918 - val_ca2-[6,11]: 1515.6091 - val_ca2-[12,17]: 983.4611 - val_ca2-[18,23]: 605.1506 - val_ca3-[0,5]: 16.1112 - val_ca3-[6,11]: 3.9080 - val_ca3-[12,17]: 19.1862 - val_ca3-[18,23]: 28.8690 - val_ca4-[0,5]: 0.2162 - val_ca4-[6,11]: 0.1134 - val_ca4-[12,17]: 0.6760 - val_ca4-[18,23]: 2.8988\n",
      "Epoch 248/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 277.8963 - ca1-[6,11]: 487.6392 - ca1-[12,17]: 241.0126 - ca1-[18,23]: 100.8492 - ca2-[0,5]: 1730.7649 - ca2-[6,11]: 1418.5126 - ca2-[12,17]: 969.6076 - ca2-[18,23]: 672.2235 - ca3-[0,5]: 14.2865 - ca3-[6,11]: 0.6464 - ca3-[12,17]: 0.7035 - ca3-[18,23]: 2.1584 - ca4-[0,5]: 0.2009 - ca4-[6,11]: 0.0063 - ca4-[12,17]: 0.0105 - ca4-[18,23]: 0.2285 - val_ca1-[0,5]: 864.7034 - val_ca1-[6,11]: 536.0098 - val_ca1-[12,17]: 250.5484 - val_ca1-[18,23]: 97.3323 - val_ca2-[0,5]: 2059.9946 - val_ca2-[6,11]: 1523.7188 - val_ca2-[12,17]: 997.3334 - val_ca2-[18,23]: 617.8117 - val_ca3-[0,5]: 16.0873 - val_ca3-[6,11]: 4.0661 - val_ca3-[12,17]: 19.4697 - val_ca3-[18,23]: 26.1077 - val_ca4-[0,5]: 0.2090 - val_ca4-[6,11]: 0.1114 - val_ca4-[12,17]: 0.6513 - val_ca4-[18,23]: 2.7007\n",
      "Epoch 249/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 251.3174 - ca1-[6,11]: 549.7372 - ca1-[12,17]: 249.0498 - ca1-[18,23]: 99.0221 - ca2-[0,5]: 1820.2749 - ca2-[6,11]: 1437.9820 - ca2-[12,17]: 1110.9127 - ca2-[18,23]: 654.0561 - ca3-[0,5]: 14.8384 - ca3-[6,11]: 0.6360 - ca3-[12,17]: 0.7405 - ca3-[18,23]: 2.4344 - ca4-[0,5]: 0.1975 - ca4-[6,11]: 0.0095 - ca4-[12,17]: 0.0177 - ca4-[18,23]: 0.2637 - val_ca1-[0,5]: 871.5883 - val_ca1-[6,11]: 545.4074 - val_ca1-[12,17]: 254.2853 - val_ca1-[18,23]: 97.8947 - val_ca2-[0,5]: 2078.0256 - val_ca2-[6,11]: 1546.0577 - val_ca2-[12,17]: 1009.6080 - val_ca2-[18,23]: 623.0436 - val_ca3-[0,5]: 15.9628 - val_ca3-[6,11]: 3.9791 - val_ca3-[12,17]: 18.6336 - val_ca3-[18,23]: 27.4215 - val_ca4-[0,5]: 0.2063 - val_ca4-[6,11]: 0.1121 - val_ca4-[12,17]: 0.6782 - val_ca4-[18,23]: 2.8970\n",
      "Epoch 250/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 256.6466 - ca1-[6,11]: 554.3352 - ca1-[12,17]: 254.1585 - ca1-[18,23]: 98.1178 - ca2-[0,5]: 1770.9279 - ca2-[6,11]: 1451.6135 - ca2-[12,17]: 1129.4790 - ca2-[18,23]: 696.6572 - ca3-[0,5]: 14.5247 - ca3-[6,11]: 0.5972 - ca3-[12,17]: 0.4962 - ca3-[18,23]: 2.1235 - ca4-[0,5]: 0.1986 - ca4-[6,11]: 0.0041 - ca4-[12,17]: 0.0070 - ca4-[18,23]: 0.2108 - val_ca1-[0,5]: 877.4671 - val_ca1-[6,11]: 550.6320 - val_ca1-[12,17]: 258.5807 - val_ca1-[18,23]: 100.8752 - val_ca2-[0,5]: 2094.4912 - val_ca2-[6,11]: 1561.5347 - val_ca2-[12,17]: 1023.3568 - val_ca2-[18,23]: 635.8190 - val_ca3-[0,5]: 15.9025 - val_ca3-[6,11]: 4.1434 - val_ca3-[12,17]: 18.1580 - val_ca3-[18,23]: 27.9940 - val_ca4-[0,5]: 0.2035 - val_ca4-[6,11]: 0.1232 - val_ca4-[12,17]: 0.7609 - val_ca4-[18,23]: 3.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 232.0022 - ca1-[6,11]: 540.6036 - ca1-[12,17]: 261.6210 - ca1-[18,23]: 103.5207 - ca2-[0,5]: 1720.2786 - ca2-[6,11]: 1469.5800 - ca2-[12,17]: 1133.9518 - ca2-[18,23]: 704.8633 - ca3-[0,5]: 14.6411 - ca3-[6,11]: 0.5669 - ca3-[12,17]: 0.3995 - ca3-[18,23]: 1.5963 - ca4-[0,5]: 0.1936 - ca4-[6,11]: 0.0070 - ca4-[12,17]: 0.0144 - ca4-[18,23]: 0.2423 - val_ca1-[0,5]: 886.9062 - val_ca1-[6,11]: 553.5167 - val_ca1-[12,17]: 262.5060 - val_ca1-[18,23]: 102.8986 - val_ca2-[0,5]: 2116.7043 - val_ca2-[6,11]: 1572.7467 - val_ca2-[12,17]: 1036.5150 - val_ca2-[18,23]: 645.6435 - val_ca3-[0,5]: 15.8570 - val_ca3-[6,11]: 3.9671 - val_ca3-[12,17]: 17.3236 - val_ca3-[18,23]: 26.5414 - val_ca4-[0,5]: 0.2060 - val_ca4-[6,11]: 0.1019 - val_ca4-[12,17]: 0.6284 - val_ca4-[18,23]: 2.6283\n",
      "Epoch 252/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 279.5865 - ca1-[6,11]: 534.1354 - ca1-[12,17]: 260.2106 - ca1-[18,23]: 108.7973 - ca2-[0,5]: 1872.8931 - ca2-[6,11]: 1484.3644 - ca2-[12,17]: 1138.2659 - ca2-[18,23]: 721.2928 - ca3-[0,5]: 14.5647 - ca3-[6,11]: 0.5197 - ca3-[12,17]: 0.3003 - ca3-[18,23]: 1.3913 - ca4-[0,5]: 0.1926 - ca4-[6,11]: 0.0081 - ca4-[12,17]: 0.0141 - ca4-[18,23]: 0.2109 - val_ca1-[0,5]: 895.2919 - val_ca1-[6,11]: 562.3483 - val_ca1-[12,17]: 267.3917 - val_ca1-[18,23]: 106.0814 - val_ca2-[0,5]: 2137.2007 - val_ca2-[6,11]: 1594.2146 - val_ca2-[12,17]: 1051.5770 - val_ca2-[18,23]: 659.7009 - val_ca3-[0,5]: 15.8247 - val_ca3-[6,11]: 3.7912 - val_ca3-[12,17]: 15.4291 - val_ca3-[18,23]: 23.6485 - val_ca4-[0,5]: 0.2054 - val_ca4-[6,11]: 0.1145 - val_ca4-[12,17]: 0.7625 - val_ca4-[18,23]: 2.9913\n",
      "Epoch 253/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 264.6956 - ca1-[6,11]: 586.0330 - ca1-[12,17]: 253.9625 - ca1-[18,23]: 106.8876 - ca2-[0,5]: 1684.0264 - ca2-[6,11]: 1443.4743 - ca2-[12,17]: 1109.6095 - ca2-[18,23]: 693.5255 - ca3-[0,5]: 14.2966 - ca3-[6,11]: 0.5502 - ca3-[12,17]: 0.3377 - ca3-[18,23]: 1.1399 - ca4-[0,5]: 0.1872 - ca4-[6,11]: 0.0066 - ca4-[12,17]: 0.0140 - ca4-[18,23]: 0.2269 - val_ca1-[0,5]: 900.2463 - val_ca1-[6,11]: 569.6478 - val_ca1-[12,17]: 270.3792 - val_ca1-[18,23]: 107.3347 - val_ca2-[0,5]: 2152.2300 - val_ca2-[6,11]: 1613.0703 - val_ca2-[12,17]: 1065.0085 - val_ca2-[18,23]: 667.2777 - val_ca3-[0,5]: 15.5303 - val_ca3-[6,11]: 3.5881 - val_ca3-[12,17]: 15.0766 - val_ca3-[18,23]: 23.7213 - val_ca4-[0,5]: 0.2014 - val_ca4-[6,11]: 0.0997 - val_ca4-[12,17]: 0.6559 - val_ca4-[18,23]: 2.6445\n",
      "Epoch 254/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 259.4262 - ca1-[6,11]: 583.8808 - ca1-[12,17]: 268.2066 - ca1-[18,23]: 112.0781 - ca2-[0,5]: 1908.3085 - ca2-[6,11]: 1515.5891 - ca2-[12,17]: 1175.3087 - ca2-[18,23]: 740.8150 - ca3-[0,5]: 14.5343 - ca3-[6,11]: 0.5771 - ca3-[12,17]: 0.4231 - ca3-[18,23]: 1.6425 - ca4-[0,5]: 0.1845 - ca4-[6,11]: 0.0059 - ca4-[12,17]: 0.0113 - ca4-[18,23]: 0.2151 - val_ca1-[0,5]: 907.6312 - val_ca1-[6,11]: 570.5897 - val_ca1-[12,17]: 272.4535 - val_ca1-[18,23]: 108.0840 - val_ca2-[0,5]: 2171.1289 - val_ca2-[6,11]: 1620.9890 - val_ca2-[12,17]: 1072.3893 - val_ca2-[18,23]: 672.6053 - val_ca3-[0,5]: 15.4522 - val_ca3-[6,11]: 3.6184 - val_ca3-[12,17]: 14.2806 - val_ca3-[18,23]: 21.9277 - val_ca4-[0,5]: 0.1989 - val_ca4-[6,11]: 0.1040 - val_ca4-[12,17]: 0.6548 - val_ca4-[18,23]: 2.8260\n",
      "Epoch 255/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 298.4333 - ca1-[6,11]: 591.5809 - ca1-[12,17]: 260.5932 - ca1-[18,23]: 112.1416 - ca2-[0,5]: 1919.2815 - ca2-[6,11]: 1528.7081 - ca2-[12,17]: 1188.0445 - ca2-[18,23]: 722.8729 - ca3-[0,5]: 14.5248 - ca3-[6,11]: 0.5034 - ca3-[12,17]: 0.3695 - ca3-[18,23]: 1.4258 - ca4-[0,5]: 0.1855 - ca4-[6,11]: 0.0051 - ca4-[12,17]: 0.0081 - ca4-[18,23]: 0.1845 - val_ca1-[0,5]: 917.0800 - val_ca1-[6,11]: 578.3843 - val_ca1-[12,17]: 278.4620 - val_ca1-[18,23]: 111.4751 - val_ca2-[0,5]: 2193.3684 - val_ca2-[6,11]: 1640.7421 - val_ca2-[12,17]: 1089.7563 - val_ca2-[18,23]: 686.8909 - val_ca3-[0,5]: 15.4802 - val_ca3-[6,11]: 3.5098 - val_ca3-[12,17]: 13.3666 - val_ca3-[18,23]: 21.5699 - val_ca4-[0,5]: 0.1974 - val_ca4-[6,11]: 0.1025 - val_ca4-[12,17]: 0.6655 - val_ca4-[18,23]: 2.7163\n",
      "Epoch 256/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 262.7250 - ca1-[6,11]: 587.2362 - ca1-[12,17]: 275.6509 - ca1-[18,23]: 116.2277 - ca2-[0,5]: 1873.0774 - ca2-[6,11]: 1545.2348 - ca2-[12,17]: 1110.2805 - ca2-[18,23]: 759.9256 - ca3-[0,5]: 14.4925 - ca3-[6,11]: 0.4351 - ca3-[12,17]: 0.4766 - ca3-[18,23]: 2.0154 - ca4-[0,5]: 0.1802 - ca4-[6,11]: 0.0070 - ca4-[12,17]: 0.0141 - ca4-[18,23]: 0.1587 - val_ca1-[0,5]: 924.1432 - val_ca1-[6,11]: 582.4672 - val_ca1-[12,17]: 281.0118 - val_ca1-[18,23]: 114.8643 - val_ca2-[0,5]: 2211.7031 - val_ca2-[6,11]: 1654.0618 - val_ca2-[12,17]: 1100.4034 - val_ca2-[18,23]: 702.5568 - val_ca3-[0,5]: 15.5390 - val_ca3-[6,11]: 3.5347 - val_ca3-[12,17]: 12.8806 - val_ca3-[18,23]: 20.7993 - val_ca4-[0,5]: 0.1970 - val_ca4-[6,11]: 0.0958 - val_ca4-[12,17]: 0.6214 - val_ca4-[18,23]: 2.6987\n",
      "Epoch 257/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 304.4366 - ca1-[6,11]: 591.9961 - ca1-[12,17]: 280.7398 - ca1-[18,23]: 125.6317 - ca2-[0,5]: 1876.6228 - ca2-[6,11]: 1566.9859 - ca2-[12,17]: 1167.0942 - ca2-[18,23]: 741.9703 - ca3-[0,5]: 14.3811 - ca3-[6,11]: 0.5452 - ca3-[12,17]: 0.4713 - ca3-[18,23]: 1.8729 - ca4-[0,5]: 0.1829 - ca4-[6,11]: 0.0063 - ca4-[12,17]: 0.0132 - ca4-[18,23]: 0.1989 - val_ca1-[0,5]: 931.3905 - val_ca1-[6,11]: 590.4304 - val_ca1-[12,17]: 285.0411 - val_ca1-[18,23]: 117.1706 - val_ca2-[0,5]: 2230.5117 - val_ca2-[6,11]: 1674.2020 - val_ca2-[12,17]: 1114.0116 - val_ca2-[18,23]: 710.1725 - val_ca3-[0,5]: 15.4656 - val_ca3-[6,11]: 3.5968 - val_ca3-[12,17]: 12.4851 - val_ca3-[18,23]: 20.3699 - val_ca4-[0,5]: 0.1943 - val_ca4-[6,11]: 0.0961 - val_ca4-[12,17]: 0.6086 - val_ca4-[18,23]: 2.7248\n",
      "Epoch 258/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 307.4673 - ca1-[6,11]: 609.6809 - ca1-[12,17]: 287.8632 - ca1-[18,23]: 122.1236 - ca2-[0,5]: 1828.5934 - ca2-[6,11]: 1585.5277 - ca2-[12,17]: 1180.8279 - ca2-[18,23]: 779.3237 - ca3-[0,5]: 14.7506 - ca3-[6,11]: 0.4300 - ca3-[12,17]: 0.2620 - ca3-[18,23]: 1.2395 - ca4-[0,5]: 0.1813 - ca4-[6,11]: 0.0082 - ca4-[12,17]: 0.0128 - ca4-[18,23]: 0.1519 - val_ca1-[0,5]: 938.2690 - val_ca1-[6,11]: 596.5295 - val_ca1-[12,17]: 290.6657 - val_ca1-[18,23]: 118.5842 - val_ca2-[0,5]: 2248.7485 - val_ca2-[6,11]: 1690.9843 - val_ca2-[12,17]: 1130.6119 - val_ca2-[18,23]: 719.3390 - val_ca3-[0,5]: 15.4345 - val_ca3-[6,11]: 3.6410 - val_ca3-[12,17]: 12.4665 - val_ca3-[18,23]: 22.0448 - val_ca4-[0,5]: 0.1895 - val_ca4-[6,11]: 0.0959 - val_ca4-[12,17]: 0.6363 - val_ca4-[18,23]: 2.8084\n",
      "Epoch 259/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 291.4521 - ca1-[6,11]: 609.2274 - ca1-[12,17]: 291.6094 - ca1-[18,23]: 130.8053 - ca2-[0,5]: 1997.8542 - ca2-[6,11]: 1602.3093 - ca2-[12,17]: 1244.3210 - ca2-[18,23]: 761.0661 - ca3-[0,5]: 14.3837 - ca3-[6,11]: 0.4619 - ca3-[12,17]: 0.2089 - ca3-[18,23]: 1.1421 - ca4-[0,5]: 0.1792 - ca4-[6,11]: 0.0078 - ca4-[12,17]: 0.0154 - ca4-[18,23]: 0.2038 - val_ca1-[0,5]: 947.4016 - val_ca1-[6,11]: 602.6344 - val_ca1-[12,17]: 294.8675 - val_ca1-[18,23]: 119.7142 - val_ca2-[0,5]: 2270.5981 - val_ca2-[6,11]: 1707.9182 - val_ca2-[12,17]: 1144.4330 - val_ca2-[18,23]: 727.4058 - val_ca3-[0,5]: 15.3601 - val_ca3-[6,11]: 3.4960 - val_ca3-[12,17]: 11.2843 - val_ca3-[18,23]: 19.8475 - val_ca4-[0,5]: 0.1835 - val_ca4-[6,11]: 0.0933 - val_ca4-[12,17]: 0.5829 - val_ca4-[18,23]: 2.5451\n",
      "Epoch 260/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 294.3017 - ca1-[6,11]: 613.2921 - ca1-[12,17]: 293.5334 - ca1-[18,23]: 129.5866 - ca2-[0,5]: 2015.9747 - ca2-[6,11]: 1551.1762 - ca2-[12,17]: 1211.3057 - ca2-[18,23]: 809.2337 - ca3-[0,5]: 14.5066 - ca3-[6,11]: 0.4200 - ca3-[12,17]: 0.2603 - ca3-[18,23]: 1.2159 - ca4-[0,5]: 0.1768 - ca4-[6,11]: 0.0057 - ca4-[12,17]: 0.0102 - ca4-[18,23]: 0.1586 - val_ca1-[0,5]: 954.0178 - val_ca1-[6,11]: 608.2086 - val_ca1-[12,17]: 299.1132 - val_ca1-[18,23]: 122.8971 - val_ca2-[0,5]: 2288.3093 - val_ca2-[6,11]: 1724.1230 - val_ca2-[12,17]: 1157.9460 - val_ca2-[18,23]: 739.3468 - val_ca3-[0,5]: 15.3612 - val_ca3-[6,11]: 3.3908 - val_ca3-[12,17]: 11.0888 - val_ca3-[18,23]: 19.5626 - val_ca4-[0,5]: 0.1872 - val_ca4-[6,11]: 0.0965 - val_ca4-[12,17]: 0.6814 - val_ca4-[18,23]: 2.8425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 286.7869 - ca1-[6,11]: 618.5141 - ca1-[12,17]: 300.5143 - ca1-[18,23]: 129.9560 - ca2-[0,5]: 1818.3185 - ca2-[6,11]: 1630.8511 - ca2-[12,17]: 1158.5231 - ca2-[18,23]: 817.3846 - ca3-[0,5]: 14.6772 - ca3-[6,11]: 0.4005 - ca3-[12,17]: 0.2171 - ca3-[18,23]: 0.9577 - ca4-[0,5]: 0.1760 - ca4-[6,11]: 0.0047 - ca4-[12,17]: 0.0083 - ca4-[18,23]: 0.1752 - val_ca1-[0,5]: 961.0378 - val_ca1-[6,11]: 616.8257 - val_ca1-[12,17]: 302.2428 - val_ca1-[18,23]: 125.8916 - val_ca2-[0,5]: 2306.8171 - val_ca2-[6,11]: 1745.3278 - val_ca2-[12,17]: 1169.8894 - val_ca2-[18,23]: 752.1825 - val_ca3-[0,5]: 15.2383 - val_ca3-[6,11]: 3.3485 - val_ca3-[12,17]: 10.4696 - val_ca3-[18,23]: 18.7190 - val_ca4-[0,5]: 0.1806 - val_ca4-[6,11]: 0.0894 - val_ca4-[12,17]: 0.5981 - val_ca4-[18,23]: 2.6313\n",
      "Epoch 262/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 268.7456 - ca1-[6,11]: 593.9599 - ca1-[12,17]: 301.8222 - ca1-[18,23]: 138.3786 - ca2-[0,5]: 2052.3658 - ca2-[6,11]: 1647.4881 - ca2-[12,17]: 1286.5140 - ca2-[18,23]: 795.6889 - ca3-[0,5]: 14.8276 - ca3-[6,11]: 0.4338 - ca3-[12,17]: 0.2447 - ca3-[18,23]: 1.1115 - ca4-[0,5]: 0.1703 - ca4-[6,11]: 0.0052 - ca4-[12,17]: 0.0116 - ca4-[18,23]: 0.1698 - val_ca1-[0,5]: 973.7357 - val_ca1-[6,11]: 620.4312 - val_ca1-[12,17]: 307.0372 - val_ca1-[18,23]: 130.5290 - val_ca2-[0,5]: 2334.3677 - val_ca2-[6,11]: 1757.9230 - val_ca2-[12,17]: 1184.9873 - val_ca2-[18,23]: 769.9500 - val_ca3-[0,5]: 15.4351 - val_ca3-[6,11]: 3.3252 - val_ca3-[12,17]: 10.1471 - val_ca3-[18,23]: 15.6234 - val_ca4-[0,5]: 0.1831 - val_ca4-[6,11]: 0.0894 - val_ca4-[12,17]: 0.6184 - val_ca4-[18,23]: 2.6738\n",
      "Epoch 263/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 292.4520 - ca1-[6,11]: 603.6458 - ca1-[12,17]: 305.4408 - ca1-[18,23]: 130.2442 - ca2-[0,5]: 1995.1052 - ca2-[6,11]: 1664.1993 - ca2-[12,17]: 1302.4970 - ca2-[18,23]: 840.1868 - ca3-[0,5]: 14.8501 - ca3-[6,11]: 0.4137 - ca3-[12,17]: 0.2507 - ca3-[18,23]: 1.0445 - ca4-[0,5]: 0.1705 - ca4-[6,11]: 0.0040 - ca4-[12,17]: 0.0086 - ca4-[18,23]: 0.1619 - val_ca1-[0,5]: 977.4880 - val_ca1-[6,11]: 628.8467 - val_ca1-[12,17]: 310.1330 - val_ca1-[18,23]: 130.8021 - val_ca2-[0,5]: 2347.5894 - val_ca2-[6,11]: 1778.8354 - val_ca2-[12,17]: 1196.4050 - val_ca2-[18,23]: 773.7198 - val_ca3-[0,5]: 15.3510 - val_ca3-[6,11]: 3.3509 - val_ca3-[12,17]: 10.1596 - val_ca3-[18,23]: 18.6457 - val_ca4-[0,5]: 0.1806 - val_ca4-[6,11]: 0.0849 - val_ca4-[12,17]: 0.6188 - val_ca4-[18,23]: 2.6699\n",
      "Epoch 264/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 284.7821 - ca1-[6,11]: 614.9178 - ca1-[12,17]: 308.9900 - ca1-[18,23]: 139.3250 - ca2-[0,5]: 2082.0230 - ca2-[6,11]: 1678.8223 - ca2-[12,17]: 1305.2785 - ca2-[18,23]: 848.5605 - ca3-[0,5]: 14.6620 - ca3-[6,11]: 0.4155 - ca3-[12,17]: 0.2034 - ca3-[18,23]: 0.9404 - ca4-[0,5]: 0.1687 - ca4-[6,11]: 0.0040 - ca4-[12,17]: 0.0080 - ca4-[18,23]: 0.1572 - val_ca1-[0,5]: 988.3454 - val_ca1-[6,11]: 632.2458 - val_ca1-[12,17]: 316.3524 - val_ca1-[18,23]: 133.1086 - val_ca2-[0,5]: 2372.3198 - val_ca2-[6,11]: 1791.3584 - val_ca2-[12,17]: 1214.5784 - val_ca2-[18,23]: 784.8254 - val_ca3-[0,5]: 15.5139 - val_ca3-[6,11]: 3.3424 - val_ca3-[12,17]: 9.4144 - val_ca3-[18,23]: 17.8972 - val_ca4-[0,5]: 0.1800 - val_ca4-[6,11]: 0.0844 - val_ca4-[12,17]: 0.5806 - val_ca4-[18,23]: 2.5512\n",
      "Epoch 265/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 298.1736 - ca1-[6,11]: 646.5357 - ca1-[12,17]: 314.4175 - ca1-[18,23]: 142.5300 - ca2-[0,5]: 2100.4872 - ca2-[6,11]: 1696.0537 - ca2-[12,17]: 1277.0559 - ca2-[18,23]: 863.4215 - ca3-[0,5]: 14.8187 - ca3-[6,11]: 0.3511 - ca3-[12,17]: 0.1625 - ca3-[18,23]: 0.8004 - ca4-[0,5]: 0.1656 - ca4-[6,11]: 0.0049 - ca4-[12,17]: 0.0099 - ca4-[18,23]: 0.1594 - val_ca1-[0,5]: 995.0276 - val_ca1-[6,11]: 642.9127 - val_ca1-[12,17]: 319.9220 - val_ca1-[18,23]: 136.7096 - val_ca2-[0,5]: 2390.3252 - val_ca2-[6,11]: 1816.1310 - val_ca2-[12,17]: 1227.1276 - val_ca2-[18,23]: 797.9207 - val_ca3-[0,5]: 15.4282 - val_ca3-[6,11]: 3.4213 - val_ca3-[12,17]: 9.3704 - val_ca3-[18,23]: 18.4062 - val_ca4-[0,5]: 0.1762 - val_ca4-[6,11]: 0.0844 - val_ca4-[12,17]: 0.5950 - val_ca4-[18,23]: 2.6885\n",
      "Epoch 266/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 311.6617 - ca1-[6,11]: 551.8956 - ca1-[12,17]: 319.3409 - ca1-[18,23]: 149.1103 - ca2-[0,5]: 2126.0862 - ca2-[6,11]: 1649.9145 - ca2-[12,17]: 1288.8998 - ca2-[18,23]: 833.4877 - ca3-[0,5]: 15.0405 - ca3-[6,11]: 0.3510 - ca3-[12,17]: 0.1687 - ca3-[18,23]: 0.7255 - ca4-[0,5]: 0.1644 - ca4-[6,11]: 0.0079 - ca4-[12,17]: 0.0143 - ca4-[18,23]: 0.1454 - val_ca1-[0,5]: 1001.2904 - val_ca1-[6,11]: 650.5332 - val_ca1-[12,17]: 326.0065 - val_ca1-[18,23]: 138.3264 - val_ca2-[0,5]: 2407.5942 - val_ca2-[6,11]: 1835.8304 - val_ca2-[12,17]: 1244.4509 - val_ca2-[18,23]: 807.5346 - val_ca3-[0,5]: 15.3992 - val_ca3-[6,11]: 3.3021 - val_ca3-[12,17]: 6.9177 - val_ca3-[18,23]: 17.2502 - val_ca4-[0,5]: 0.1742 - val_ca4-[6,11]: 0.0872 - val_ca4-[12,17]: 0.6861 - val_ca4-[18,23]: 2.8438\n",
      "Epoch 267/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 314.5987 - ca1-[6,11]: 620.1746 - ca1-[12,17]: 326.1487 - ca1-[18,23]: 142.7621 - ca2-[0,5]: 2108.6107 - ca2-[6,11]: 1731.9017 - ca2-[12,17]: 1240.4302 - ca2-[18,23]: 885.3472 - ca3-[0,5]: 14.7015 - ca3-[6,11]: 0.3716 - ca3-[12,17]: 0.1658 - ca3-[18,23]: 0.7136 - ca4-[0,5]: 0.1596 - ca4-[6,11]: 0.0072 - ca4-[12,17]: 0.0127 - ca4-[18,23]: 0.1525 - val_ca1-[0,5]: 1011.2133 - val_ca1-[6,11]: 652.7311 - val_ca1-[12,17]: 333.1635 - val_ca1-[18,23]: 141.9366 - val_ca2-[0,5]: 2430.8413 - val_ca2-[6,11]: 1846.0239 - val_ca2-[12,17]: 1265.3634 - val_ca2-[18,23]: 821.3076 - val_ca3-[0,5]: 15.4800 - val_ca3-[6,11]: 3.2811 - val_ca3-[12,17]: 8.2639 - val_ca3-[18,23]: 15.1271 - val_ca4-[0,5]: 0.1727 - val_ca4-[6,11]: 0.0806 - val_ca4-[12,17]: 0.6164 - val_ca4-[18,23]: 2.5969\n",
      "Epoch 268/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 317.5558 - ca1-[6,11]: 634.5016 - ca1-[12,17]: 328.9680 - ca1-[18,23]: 156.0462 - ca2-[0,5]: 2163.3057 - ca2-[6,11]: 1750.1652 - ca2-[12,17]: 1371.1060 - ca2-[18,23]: 894.7064 - ca3-[0,5]: 14.8299 - ca3-[6,11]: 0.3466 - ca3-[12,17]: 0.1402 - ca3-[18,23]: 0.6024 - ca4-[0,5]: 0.1627 - ca4-[6,11]: 0.0094 - ca4-[12,17]: 0.0201 - ca4-[18,23]: 0.1362 - val_ca1-[0,5]: 1017.4672 - val_ca1-[6,11]: 659.7599 - val_ca1-[12,17]: 333.2649 - val_ca1-[18,23]: 144.8713 - val_ca2-[0,5]: 2448.2163 - val_ca2-[6,11]: 1864.6696 - val_ca2-[12,17]: 1270.2667 - val_ca2-[18,23]: 833.8353 - val_ca3-[0,5]: 15.4193 - val_ca3-[6,11]: 3.2438 - val_ca3-[12,17]: 8.5921 - val_ca3-[18,23]: 17.5683 - val_ca4-[0,5]: 0.1670 - val_ca4-[6,11]: 0.0873 - val_ca4-[12,17]: 0.6929 - val_ca4-[18,23]: 2.8689\n",
      "Epoch 269/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 341.7583 - ca1-[6,11]: 672.4454 - ca1-[12,17]: 326.8473 - ca1-[18,23]: 156.5702 - ca2-[0,5]: 2182.0296 - ca2-[6,11]: 1766.1777 - ca2-[12,17]: 1335.3859 - ca2-[18,23]: 871.7616 - ca3-[0,5]: 15.0888 - ca3-[6,11]: 0.3222 - ca3-[12,17]: 0.1402 - ca3-[18,23]: 0.5550 - ca4-[0,5]: 0.1592 - ca4-[6,11]: 0.0052 - ca4-[12,17]: 0.0102 - ca4-[18,23]: 0.1408 - val_ca1-[0,5]: 1026.9962 - val_ca1-[6,11]: 667.0198 - val_ca1-[12,17]: 340.7108 - val_ca1-[18,23]: 145.3862 - val_ca2-[0,5]: 2470.7358 - val_ca2-[6,11]: 1883.7231 - val_ca2-[12,17]: 1292.6534 - val_ca2-[18,23]: 840.1309 - val_ca3-[0,5]: 15.5926 - val_ca3-[6,11]: 3.1988 - val_ca3-[12,17]: 7.3248 - val_ca3-[18,23]: 16.9388 - val_ca4-[0,5]: 0.1698 - val_ca4-[6,11]: 0.0783 - val_ca4-[12,17]: 0.6364 - val_ca4-[18,23]: 2.6664\n",
      "Epoch 270/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 344.9669 - ca1-[6,11]: 682.5047 - ca1-[12,17]: 338.0008 - ca1-[18,23]: 155.9847 - ca2-[0,5]: 2120.3459 - ca2-[6,11]: 1782.7482 - ca2-[12,17]: 1344.7165 - ca2-[18,23]: 918.6151 - ca3-[0,5]: 14.8407 - ca3-[6,11]: 0.3599 - ca3-[12,17]: 0.1706 - ca3-[18,23]: 0.6106 - ca4-[0,5]: 0.1554 - ca4-[6,11]: 0.0052 - ca4-[12,17]: 0.0099 - ca4-[18,23]: 0.1358 - val_ca1-[0,5]: 1035.3831 - val_ca1-[6,11]: 668.1244 - val_ca1-[12,17]: 343.1737 - val_ca1-[18,23]: 149.4205 - val_ca2-[0,5]: 2491.6597 - val_ca2-[6,11]: 1892.4081 - val_ca2-[12,17]: 1301.1412 - val_ca2-[18,23]: 854.5294 - val_ca3-[0,5]: 15.5523 - val_ca3-[6,11]: 3.3131 - val_ca3-[12,17]: 8.0960 - val_ca3-[18,23]: 16.5916 - val_ca4-[0,5]: 0.1664 - val_ca4-[6,11]: 0.0745 - val_ca4-[12,17]: 0.5968 - val_ca4-[18,23]: 2.6217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 293.9511 - ca1-[6,11]: 645.5334 - ca1-[12,17]: 342.0983 - ca1-[18,23]: 168.4606 - ca2-[0,5]: 2205.0748 - ca2-[6,11]: 1800.6898 - ca2-[12,17]: 1401.2705 - ca2-[18,23]: 934.7323 - ca3-[0,5]: 15.0714 - ca3-[6,11]: 0.3460 - ca3-[12,17]: 0.1493 - ca3-[18,23]: 0.5974 - ca4-[0,5]: 0.1524 - ca4-[6,11]: 0.0047 - ca4-[12,17]: 0.0086 - ca4-[18,23]: 0.1322 - val_ca1-[0,5]: 1043.0159 - val_ca1-[6,11]: 679.0026 - val_ca1-[12,17]: 348.2604 - val_ca1-[18,23]: 151.8400 - val_ca2-[0,5]: 2511.3528 - val_ca2-[6,11]: 1917.5745 - val_ca2-[12,17]: 1316.5895 - val_ca2-[18,23]: 864.6165 - val_ca3-[0,5]: 15.5012 - val_ca3-[6,11]: 3.1615 - val_ca3-[12,17]: 7.7252 - val_ca3-[18,23]: 14.7015 - val_ca4-[0,5]: 0.1619 - val_ca4-[6,11]: 0.0973 - val_ca4-[12,17]: 0.7264 - val_ca4-[18,23]: 2.9389\n",
      "Epoch 272/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 329.5134 - ca1-[6,11]: 653.0751 - ca1-[12,17]: 346.7069 - ca1-[18,23]: 160.9708 - ca2-[0,5]: 2074.8176 - ca2-[6,11]: 1818.0911 - ca2-[12,17]: 1371.4999 - ca2-[18,23]: 903.6267 - ca3-[0,5]: 15.0534 - ca3-[6,11]: 0.3349 - ca3-[12,17]: 0.1358 - ca3-[18,23]: 0.4697 - ca4-[0,5]: 0.1512 - ca4-[6,11]: 0.0125 - ca4-[12,17]: 0.0213 - ca4-[18,23]: 0.1477 - val_ca1-[0,5]: 1050.4440 - val_ca1-[6,11]: 684.9082 - val_ca1-[12,17]: 354.3405 - val_ca1-[18,23]: 157.2953 - val_ca2-[0,5]: 2530.6978 - val_ca2-[6,11]: 1934.3816 - val_ca2-[12,17]: 1335.1720 - val_ca2-[18,23]: 884.0044 - val_ca3-[0,5]: 15.5027 - val_ca3-[6,11]: 3.2243 - val_ca3-[12,17]: 7.4529 - val_ca3-[18,23]: 16.1800 - val_ca4-[0,5]: 0.1592 - val_ca4-[6,11]: 0.0739 - val_ca4-[12,17]: 0.6183 - val_ca4-[18,23]: 2.6000\n",
      "Epoch 273/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 332.5464 - ca1-[6,11]: 688.5475 - ca1-[12,17]: 350.9819 - ca1-[18,23]: 170.5635 - ca2-[0,5]: 2264.8862 - ca2-[6,11]: 1767.3835 - ca2-[12,17]: 1382.6646 - ca2-[18,23]: 951.6187 - ca3-[0,5]: 15.3390 - ca3-[6,11]: 0.3208 - ca3-[12,17]: 0.1331 - ca3-[18,23]: 0.4870 - ca4-[0,5]: 0.1503 - ca4-[6,11]: 0.0075 - ca4-[12,17]: 0.0146 - ca4-[18,23]: 0.1281 - val_ca1-[0,5]: 1059.9004 - val_ca1-[6,11]: 692.3350 - val_ca1-[12,17]: 356.2799 - val_ca1-[18,23]: 160.1624 - val_ca2-[0,5]: 2553.2451 - val_ca2-[6,11]: 1953.8245 - val_ca2-[12,17]: 1343.7939 - val_ca2-[18,23]: 896.3221 - val_ca3-[0,5]: 15.6640 - val_ca3-[6,11]: 3.2060 - val_ca3-[12,17]: 7.6439 - val_ca3-[18,23]: 16.3896 - val_ca4-[0,5]: 0.1614 - val_ca4-[6,11]: 0.0729 - val_ca4-[12,17]: 0.5989 - val_ca4-[18,23]: 2.6126\n",
      "Epoch 274/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 291.2397 - ca1-[6,11]: 696.0081 - ca1-[12,17]: 355.4200 - ca1-[18,23]: 163.7611 - ca2-[0,5]: 2019.3604 - ca2-[6,11]: 1852.4729 - ca2-[12,17]: 1412.7345 - ca2-[18,23]: 966.5939 - ca3-[0,5]: 15.3062 - ca3-[6,11]: 0.3347 - ca3-[12,17]: 0.1359 - ca3-[18,23]: 0.4713 - ca4-[0,5]: 0.1462 - ca4-[6,11]: 0.0078 - ca4-[12,17]: 0.0140 - ca4-[18,23]: 0.1031 - val_ca1-[0,5]: 1068.2377 - val_ca1-[6,11]: 697.5974 - val_ca1-[12,17]: 362.4567 - val_ca1-[18,23]: 160.4551 - val_ca2-[0,5]: 2574.0327 - val_ca2-[6,11]: 1969.5399 - val_ca2-[12,17]: 1361.7166 - val_ca2-[18,23]: 901.5206 - val_ca3-[0,5]: 15.7490 - val_ca3-[6,11]: 3.1568 - val_ca3-[12,17]: 7.1397 - val_ca3-[18,23]: 15.3651 - val_ca4-[0,5]: 0.1589 - val_ca4-[6,11]: 0.0781 - val_ca4-[12,17]: 0.6282 - val_ca4-[18,23]: 2.6241\n",
      "Epoch 275/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 305.0025 - ca1-[6,11]: 666.0884 - ca1-[12,17]: 359.9174 - ca1-[18,23]: 169.6179 - ca2-[0,5]: 2211.8334 - ca2-[6,11]: 1870.2649 - ca2-[12,17]: 1473.9907 - ca2-[18,23]: 944.1307 - ca3-[0,5]: 15.2264 - ca3-[6,11]: 0.3005 - ca3-[12,17]: 0.1450 - ca3-[18,23]: 0.4040 - ca4-[0,5]: 0.1446 - ca4-[6,11]: 0.0097 - ca4-[12,17]: 0.0189 - ca4-[18,23]: 0.1184 - val_ca1-[0,5]: 1074.0471 - val_ca1-[6,11]: 705.3278 - val_ca1-[12,17]: 363.3839 - val_ca1-[18,23]: 164.6726 - val_ca2-[0,5]: 2590.9189 - val_ca2-[6,11]: 1989.6418 - val_ca2-[12,17]: 1369.2203 - val_ca2-[18,23]: 917.0398 - val_ca3-[0,5]: 15.6059 - val_ca3-[6,11]: 3.1142 - val_ca3-[12,17]: 7.1454 - val_ca3-[18,23]: 15.5019 - val_ca4-[0,5]: 0.1541 - val_ca4-[6,11]: 0.0725 - val_ca4-[12,17]: 0.6035 - val_ca4-[18,23]: 2.5264\n",
      "Epoch 276/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 341.7048 - ca1-[6,11]: 703.0242 - ca1-[12,17]: 363.3374 - ca1-[18,23]: 176.5335 - ca2-[0,5]: 2315.0649 - ca2-[6,11]: 1894.3299 - ca2-[12,17]: 1496.4741 - ca2-[18,23]: 994.5742 - ca3-[0,5]: 15.1835 - ca3-[6,11]: 0.2947 - ca3-[12,17]: 0.1820 - ca3-[18,23]: 0.4711 - ca4-[0,5]: 0.1450 - ca4-[6,11]: 0.0227 - ca4-[12,17]: 0.0397 - ca4-[18,23]: 0.1295 - val_ca1-[0,5]: 1084.4602 - val_ca1-[6,11]: 712.9207 - val_ca1-[12,17]: 369.5313 - val_ca1-[18,23]: 167.3418 - val_ca2-[0,5]: 2615.1230 - val_ca2-[6,11]: 2009.3029 - val_ca2-[12,17]: 1387.2970 - val_ca2-[18,23]: 928.2323 - val_ca3-[0,5]: 15.7940 - val_ca3-[6,11]: 3.1483 - val_ca3-[12,17]: 7.0356 - val_ca3-[18,23]: 14.0840 - val_ca4-[0,5]: 0.1509 - val_ca4-[6,11]: 0.0631 - val_ca4-[12,17]: 0.5635 - val_ca4-[18,23]: 2.4833\n",
      "Epoch 277/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 378.9772 - ca1-[6,11]: 716.8464 - ca1-[12,17]: 370.2515 - ca1-[18,23]: 173.8861 - ca2-[0,5]: 2334.3776 - ca2-[6,11]: 1904.8718 - ca2-[12,17]: 1502.0499 - ca2-[18,23]: 927.1117 - ca3-[0,5]: 15.2246 - ca3-[6,11]: 0.3002 - ca3-[12,17]: 0.1260 - ca3-[18,23]: 0.4583 - ca4-[0,5]: 0.1434 - ca4-[6,11]: 0.0043 - ca4-[12,17]: 0.0081 - ca4-[18,23]: 0.1081 - val_ca1-[0,5]: 1092.3983 - val_ca1-[6,11]: 719.7506 - val_ca1-[12,17]: 375.7198 - val_ca1-[18,23]: 169.3881 - val_ca2-[0,5]: 2635.3438 - val_ca2-[6,11]: 2027.6785 - val_ca2-[12,17]: 1405.1465 - val_ca2-[18,23]: 937.6193 - val_ca3-[0,5]: 15.8683 - val_ca3-[6,11]: 3.2041 - val_ca3-[12,17]: 6.8284 - val_ca3-[18,23]: 15.5150 - val_ca4-[0,5]: 0.1531 - val_ca4-[6,11]: 0.0691 - val_ca4-[12,17]: 0.5762 - val_ca4-[18,23]: 2.5523\n",
      "Epoch 278/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 371.1949 - ca1-[6,11]: 732.4934 - ca1-[12,17]: 378.6739 - ca1-[18,23]: 183.6320 - ca2-[0,5]: 2260.1009 - ca2-[6,11]: 1927.2767 - ca2-[12,17]: 1534.9726 - ca2-[18,23]: 1021.5333 - ca3-[0,5]: 15.3633 - ca3-[6,11]: 0.3026 - ca3-[12,17]: 0.1183 - ca3-[18,23]: 0.3238 - ca4-[0,5]: 0.1443 - ca4-[6,11]: 0.0072 - ca4-[12,17]: 0.0110 - ca4-[18,23]: 0.0959 - val_ca1-[0,5]: 1103.4261 - val_ca1-[6,11]: 724.5659 - val_ca1-[12,17]: 383.6205 - val_ca1-[18,23]: 172.0077 - val_ca2-[0,5]: 2660.6343 - val_ca2-[6,11]: 2042.9775 - val_ca2-[12,17]: 1428.6379 - val_ca2-[18,23]: 949.3035 - val_ca3-[0,5]: 16.0223 - val_ca3-[6,11]: 3.1697 - val_ca3-[12,17]: 5.0880 - val_ca3-[18,23]: 14.8377 - val_ca4-[0,5]: 0.1546 - val_ca4-[6,11]: 0.0813 - val_ca4-[12,17]: 0.6323 - val_ca4-[18,23]: 2.5985\n",
      "Epoch 279/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 339.7918 - ca1-[6,11]: 746.6701 - ca1-[12,17]: 375.6712 - ca1-[18,23]: 182.6518 - ca2-[0,5]: 2373.2069 - ca2-[6,11]: 1941.5230 - ca2-[12,17]: 1539.4516 - ca2-[18,23]: 1034.8467 - ca3-[0,5]: 15.6901 - ca3-[6,11]: 0.3328 - ca3-[12,17]: 0.1481 - ca3-[18,23]: 0.3940 - ca4-[0,5]: 0.1455 - ca4-[6,11]: 0.0110 - ca4-[12,17]: 0.0146 - ca4-[18,23]: 0.0985 - val_ca1-[0,5]: 1109.0675 - val_ca1-[6,11]: 734.9075 - val_ca1-[12,17]: 385.9943 - val_ca1-[18,23]: 174.0929 - val_ca2-[0,5]: 2677.4824 - val_ca2-[6,11]: 2067.5898 - val_ca2-[12,17]: 1436.9517 - val_ca2-[18,23]: 959.4428 - val_ca3-[0,5]: 15.8165 - val_ca3-[6,11]: 3.1470 - val_ca3-[12,17]: 6.4234 - val_ca3-[18,23]: 13.6650 - val_ca4-[0,5]: 0.1497 - val_ca4-[6,11]: 0.0699 - val_ca4-[12,17]: 0.5657 - val_ca4-[18,23]: 2.4891\n",
      "Epoch 280/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 365.3781 - ca1-[6,11]: 745.0954 - ca1-[12,17]: 385.6581 - ca1-[18,23]: 190.6665 - ca2-[0,5]: 2305.0964 - ca2-[6,11]: 1961.2595 - ca2-[12,17]: 1489.2216 - ca2-[18,23]: 998.3465 - ca3-[0,5]: 15.7199 - ca3-[6,11]: 0.3016 - ca3-[12,17]: 0.1136 - ca3-[18,23]: 0.3693 - ca4-[0,5]: 0.1417 - ca4-[6,11]: 0.0056 - ca4-[12,17]: 0.0070 - ca4-[18,23]: 0.0961 - val_ca1-[0,5]: 1118.0831 - val_ca1-[6,11]: 738.9391 - val_ca1-[12,17]: 388.5077 - val_ca1-[18,23]: 177.1166 - val_ca2-[0,5]: 2699.4202 - val_ca2-[6,11]: 2081.1658 - val_ca2-[12,17]: 1447.8452 - val_ca2-[18,23]: 972.0959 - val_ca3-[0,5]: 15.9920 - val_ca3-[6,11]: 3.0529 - val_ca3-[12,17]: 6.0985 - val_ca3-[18,23]: 14.0287 - val_ca4-[0,5]: 0.1510 - val_ca4-[6,11]: 0.0745 - val_ca4-[12,17]: 0.5741 - val_ca4-[18,23]: 2.4351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 381.2851 - ca1-[6,11]: 746.4530 - ca1-[12,17]: 390.7741 - ca1-[18,23]: 187.5175 - ca2-[0,5]: 2412.3340 - ca2-[6,11]: 1980.5154 - ca2-[12,17]: 1561.2036 - ca2-[18,23]: 1056.6953 - ca3-[0,5]: 15.8650 - ca3-[6,11]: 0.2886 - ca3-[12,17]: 0.1263 - ca3-[18,23]: 0.2895 - ca4-[0,5]: 0.1357 - ca4-[6,11]: 0.0085 - ca4-[12,17]: 0.0131 - ca4-[18,23]: 0.0997 - val_ca1-[0,5]: 1124.2120 - val_ca1-[6,11]: 745.6791 - val_ca1-[12,17]: 393.6391 - val_ca1-[18,23]: 181.4878 - val_ca2-[0,5]: 2716.9297 - val_ca2-[6,11]: 2099.7620 - val_ca2-[12,17]: 1463.8993 - val_ca2-[18,23]: 987.9018 - val_ca3-[0,5]: 15.9428 - val_ca3-[6,11]: 3.0827 - val_ca3-[12,17]: 6.1964 - val_ca3-[18,23]: 14.2142 - val_ca4-[0,5]: 0.1475 - val_ca4-[6,11]: 0.0673 - val_ca4-[12,17]: 0.5528 - val_ca4-[18,23]: 2.3908\n",
      "Epoch 282/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 360.4211 - ca1-[6,11]: 754.3173 - ca1-[12,17]: 394.8263 - ca1-[18,23]: 194.4756 - ca2-[0,5]: 2432.0067 - ca2-[6,11]: 1995.5995 - ca2-[12,17]: 1580.5832 - ca2-[18,23]: 1068.6083 - ca3-[0,5]: 15.5828 - ca3-[6,11]: 0.2886 - ca3-[12,17]: 0.1282 - ca3-[18,23]: 0.3337 - ca4-[0,5]: 0.1366 - ca4-[6,11]: 0.0091 - ca4-[12,17]: 0.0135 - ca4-[18,23]: 0.0970 - val_ca1-[0,5]: 1133.1312 - val_ca1-[6,11]: 753.4692 - val_ca1-[12,17]: 400.3729 - val_ca1-[18,23]: 186.9536 - val_ca2-[0,5]: 2738.9292 - val_ca2-[6,11]: 2119.9824 - val_ca2-[12,17]: 1482.7919 - val_ca2-[18,23]: 1006.6358 - val_ca3-[0,5]: 16.0194 - val_ca3-[6,11]: 3.1253 - val_ca3-[12,17]: 5.8642 - val_ca3-[18,23]: 13.4793 - val_ca4-[0,5]: 0.1413 - val_ca4-[6,11]: 0.0656 - val_ca4-[12,17]: 0.5503 - val_ca4-[18,23]: 2.3797\n",
      "Epoch 283/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 363.5866 - ca1-[6,11]: 756.7292 - ca1-[12,17]: 401.7310 - ca1-[18,23]: 201.1090 - ca2-[0,5]: 2444.1117 - ca2-[6,11]: 2019.5225 - ca2-[12,17]: 1594.1779 - ca2-[18,23]: 1026.1985 - ca3-[0,5]: 15.9352 - ca3-[6,11]: 0.3017 - ca3-[12,17]: 0.1483 - ca3-[18,23]: 0.2345 - ca4-[0,5]: 0.1353 - ca4-[6,11]: 0.0075 - ca4-[12,17]: 0.0107 - ca4-[18,23]: 0.0914 - val_ca1-[0,5]: 1141.4680 - val_ca1-[6,11]: 758.7432 - val_ca1-[12,17]: 405.9336 - val_ca1-[18,23]: 188.7048 - val_ca2-[0,5]: 2759.9846 - val_ca2-[6,11]: 2135.9956 - val_ca2-[12,17]: 1499.5939 - val_ca2-[18,23]: 1015.2529 - val_ca3-[0,5]: 16.0932 - val_ca3-[6,11]: 3.1691 - val_ca3-[12,17]: 6.1054 - val_ca3-[18,23]: 13.9649 - val_ca4-[0,5]: 0.1432 - val_ca4-[6,11]: 0.0669 - val_ca4-[12,17]: 0.5299 - val_ca4-[18,23]: 2.3105\n",
      "Epoch 284/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 366.7727 - ca1-[6,11]: 785.1879 - ca1-[12,17]: 408.1613 - ca1-[18,23]: 205.1770 - ca2-[0,5]: 2471.5386 - ca2-[6,11]: 2032.8192 - ca2-[12,17]: 1560.9800 - ca2-[18,23]: 1093.7696 - ca3-[0,5]: 16.1198 - ca3-[6,11]: 0.3047 - ca3-[12,17]: 0.1666 - ca3-[18,23]: 0.2752 - ca4-[0,5]: 0.1295 - ca4-[6,11]: 0.0111 - ca4-[12,17]: 0.0150 - ca4-[18,23]: 0.0891 - val_ca1-[0,5]: 1148.0907 - val_ca1-[6,11]: 767.5741 - val_ca1-[12,17]: 410.2391 - val_ca1-[18,23]: 192.4259 - val_ca2-[0,5]: 2778.4177 - val_ca2-[6,11]: 2157.9785 - val_ca2-[12,17]: 1514.0543 - val_ca2-[18,23]: 1029.4209 - val_ca3-[0,5]: 15.9112 - val_ca3-[6,11]: 2.9821 - val_ca3-[12,17]: 5.6587 - val_ca3-[18,23]: 13.4625 - val_ca4-[0,5]: 0.1354 - val_ca4-[6,11]: 0.0662 - val_ca4-[12,17]: 0.5201 - val_ca4-[18,23]: 2.2900\n",
      "Epoch 285/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 344.9779 - ca1-[6,11]: 765.2850 - ca1-[12,17]: 412.1940 - ca1-[18,23]: 211.2216 - ca2-[0,5]: 2400.0686 - ca2-[6,11]: 2046.9788 - ca2-[12,17]: 1630.7368 - ca2-[18,23]: 1107.2653 - ca3-[0,5]: 15.7484 - ca3-[6,11]: 0.2901 - ca3-[12,17]: 0.1710 - ca3-[18,23]: 0.3157 - ca4-[0,5]: 0.1294 - ca4-[6,11]: 0.0076 - ca4-[12,17]: 0.0104 - ca4-[18,23]: 0.0867 - val_ca1-[0,5]: 1157.7767 - val_ca1-[6,11]: 770.2272 - val_ca1-[12,17]: 414.7998 - val_ca1-[18,23]: 194.2919 - val_ca2-[0,5]: 2801.6270 - val_ca2-[6,11]: 2169.7014 - val_ca2-[12,17]: 1528.6746 - val_ca2-[18,23]: 1038.4921 - val_ca3-[0,5]: 16.0018 - val_ca3-[6,11]: 2.7824 - val_ca3-[12,17]: 5.6184 - val_ca3-[18,23]: 13.1403 - val_ca4-[0,5]: 0.1402 - val_ca4-[6,11]: 0.1059 - val_ca4-[12,17]: 0.7044 - val_ca4-[18,23]: 2.7490\n",
      "Epoch 286/300\n",
      "26/26 [==============================] - 3s 110ms/step - ca1-[0,5]: 386.8581 - ca1-[6,11]: 740.8693 - ca1-[12,17]: 419.5012 - ca1-[18,23]: 207.3814 - ca2-[0,5]: 2503.6505 - ca2-[6,11]: 2070.9171 - ca2-[12,17]: 1652.0630 - ca2-[18,23]: 1120.4952 - ca3-[0,5]: 15.9883 - ca3-[6,11]: 0.3310 - ca3-[12,17]: 0.1779 - ca3-[18,23]: 0.2590 - ca4-[0,5]: 0.1285 - ca4-[6,11]: 0.0193 - ca4-[12,17]: 0.0338 - ca4-[18,23]: 0.1172 - val_ca1-[0,5]: 1169.3638 - val_ca1-[6,11]: 778.0631 - val_ca1-[12,17]: 422.9077 - val_ca1-[18,23]: 196.3518 - val_ca2-[0,5]: 2827.8013 - val_ca2-[6,11]: 2190.0122 - val_ca2-[12,17]: 1552.5786 - val_ca2-[18,23]: 1049.6526 - val_ca3-[0,5]: 16.4614 - val_ca3-[6,11]: 3.1239 - val_ca3-[12,17]: 3.9307 - val_ca3-[18,23]: 13.2570 - val_ca4-[0,5]: 0.1393 - val_ca4-[6,11]: 0.0600 - val_ca4-[12,17]: 0.4989 - val_ca4-[18,23]: 2.1958\n",
      "Epoch 287/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 378.6797 - ca1-[6,11]: 782.2572 - ca1-[12,17]: 424.0670 - ca1-[18,23]: 207.0463 - ca2-[0,5]: 2531.3680 - ca2-[6,11]: 2087.6583 - ca2-[12,17]: 1532.4582 - ca2-[18,23]: 1085.8637 - ca3-[0,5]: 15.6184 - ca3-[6,11]: 0.2949 - ca3-[12,17]: 0.1362 - ca3-[18,23]: 0.2210 - ca4-[0,5]: 0.1304 - ca4-[6,11]: 0.0088 - ca4-[12,17]: 0.0103 - ca4-[18,23]: 0.0714 - val_ca1-[0,5]: 1177.6879 - val_ca1-[6,11]: 789.9302 - val_ca1-[12,17]: 424.5871 - val_ca1-[18,23]: 201.9943 - val_ca2-[0,5]: 2849.0320 - val_ca2-[6,11]: 2217.3787 - val_ca2-[12,17]: 1559.7402 - val_ca2-[18,23]: 1067.7010 - val_ca3-[0,5]: 16.3604 - val_ca3-[6,11]: 2.9259 - val_ca3-[12,17]: 5.4642 - val_ca3-[18,23]: 12.5888 - val_ca4-[0,5]: 0.1377 - val_ca4-[6,11]: 0.0743 - val_ca4-[12,17]: 0.5599 - val_ca4-[18,23]: 2.3513\n",
      "Epoch 288/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 368.0200 - ca1-[6,11]: 731.9209 - ca1-[12,17]: 408.6026 - ca1-[18,23]: 210.7031 - ca2-[0,5]: 2465.5966 - ca2-[6,11]: 2026.7671 - ca2-[12,17]: 1672.2282 - ca2-[18,23]: 1149.6059 - ca3-[0,5]: 16.2744 - ca3-[6,11]: 0.2871 - ca3-[12,17]: 0.1283 - ca3-[18,23]: 0.2899 - ca4-[0,5]: 0.1253 - ca4-[6,11]: 0.0156 - ca4-[12,17]: 0.0329 - ca4-[18,23]: 0.1149 - val_ca1-[0,5]: 1185.6367 - val_ca1-[6,11]: 793.0873 - val_ca1-[12,17]: 430.5210 - val_ca1-[18,23]: 205.0871 - val_ca2-[0,5]: 2869.5393 - val_ca2-[6,11]: 2229.7664 - val_ca2-[12,17]: 1577.1476 - val_ca2-[18,23]: 1080.6908 - val_ca3-[0,5]: 16.4507 - val_ca3-[6,11]: 2.8034 - val_ca3-[12,17]: 5.3533 - val_ca3-[18,23]: 12.0797 - val_ca4-[0,5]: 0.1356 - val_ca4-[6,11]: 0.0465 - val_ca4-[12,17]: 0.4203 - val_ca4-[18,23]: 1.9748\n",
      "Epoch 289/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 382.9097 - ca1-[6,11]: 809.3888 - ca1-[12,17]: 429.7521 - ca1-[18,23]: 220.9245 - ca2-[0,5]: 2477.3088 - ca2-[6,11]: 2046.7553 - ca2-[12,17]: 1423.9302 - ca2-[18,23]: 1161.8360 - ca3-[0,5]: 16.3468 - ca3-[6,11]: 0.2918 - ca3-[12,17]: 0.1435 - ca3-[18,23]: 0.2193 - ca4-[0,5]: 0.1227 - ca4-[6,11]: 0.0129 - ca4-[12,17]: 0.0208 - ca4-[18,23]: 0.0824 - val_ca1-[0,5]: 1194.4797 - val_ca1-[6,11]: 801.6246 - val_ca1-[12,17]: 434.8282 - val_ca1-[18,23]: 207.9876 - val_ca2-[0,5]: 2891.6467 - val_ca2-[6,11]: 2251.3367 - val_ca2-[12,17]: 1591.8430 - val_ca2-[18,23]: 1091.6605 - val_ca3-[0,5]: 16.5053 - val_ca3-[6,11]: 3.0022 - val_ca3-[12,17]: 5.3573 - val_ca3-[18,23]: 12.5177 - val_ca4-[0,5]: 0.1323 - val_ca4-[6,11]: 0.0785 - val_ca4-[12,17]: 0.5753 - val_ca4-[18,23]: 2.4087\n",
      "Epoch 290/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 386.1820 - ca1-[6,11]: 770.8973 - ca1-[12,17]: 434.7240 - ca1-[18,23]: 232.1788 - ca2-[0,5]: 2488.9706 - ca2-[6,11]: 2144.2928 - ca2-[12,17]: 1580.8623 - ca2-[18,23]: 1123.9201 - ca3-[0,5]: 16.2464 - ca3-[6,11]: 0.2920 - ca3-[12,17]: 0.1155 - ca3-[18,23]: 0.2248 - ca4-[0,5]: 0.1244 - ca4-[6,11]: 0.0084 - ca4-[12,17]: 0.0115 - ca4-[18,23]: 0.0586 - val_ca1-[0,5]: 1202.6029 - val_ca1-[6,11]: 806.8560 - val_ca1-[12,17]: 438.1011 - val_ca1-[18,23]: 211.8617 - val_ca2-[0,5]: 2912.4919 - val_ca2-[6,11]: 2267.3647 - val_ca2-[12,17]: 1604.4935 - val_ca2-[18,23]: 1107.2206 - val_ca3-[0,5]: 16.5282 - val_ca3-[6,11]: 2.7039 - val_ca3-[12,17]: 4.9373 - val_ca3-[18,23]: 11.5176 - val_ca4-[0,5]: 0.1328 - val_ca4-[6,11]: 0.0649 - val_ca4-[12,17]: 0.5067 - val_ca4-[18,23]: 2.2020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 389.4588 - ca1-[6,11]: 807.9392 - ca1-[12,17]: 442.6203 - ca1-[18,23]: 229.7293 - ca2-[0,5]: 2612.2592 - ca2-[6,11]: 2160.9797 - ca2-[12,17]: 1726.9312 - ca2-[18,23]: 1135.1487 - ca3-[0,5]: 16.1763 - ca3-[6,11]: 0.2951 - ca3-[12,17]: 0.0974 - ca3-[18,23]: 0.1965 - ca4-[0,5]: 0.1226 - ca4-[6,11]: 0.0069 - ca4-[12,17]: 0.0084 - ca4-[18,23]: 0.0666 - val_ca1-[0,5]: 1211.3391 - val_ca1-[6,11]: 812.9647 - val_ca1-[12,17]: 447.1026 - val_ca1-[18,23]: 215.2874 - val_ca2-[0,5]: 2934.4189 - val_ca2-[6,11]: 2285.0044 - val_ca2-[12,17]: 1628.9806 - val_ca2-[18,23]: 1120.5858 - val_ca3-[0,5]: 16.6009 - val_ca3-[6,11]: 2.8160 - val_ca3-[12,17]: 5.1034 - val_ca3-[18,23]: 11.5490 - val_ca4-[0,5]: 0.1265 - val_ca4-[6,11]: 0.0608 - val_ca4-[12,17]: 0.4868 - val_ca4-[18,23]: 2.1075\n",
      "Epoch 292/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 392.7513 - ca1-[6,11]: 821.0921 - ca1-[12,17]: 445.7170 - ca1-[18,23]: 234.6220 - ca2-[0,5]: 2535.9744 - ca2-[6,11]: 2183.8674 - ca2-[12,17]: 1680.8610 - ca2-[18,23]: 1149.9281 - ca3-[0,5]: 16.3788 - ca3-[6,11]: 0.2934 - ca3-[12,17]: 0.1178 - ca3-[18,23]: 0.2054 - ca4-[0,5]: 0.1224 - ca4-[6,11]: 0.0093 - ca4-[12,17]: 0.0111 - ca4-[18,23]: 0.0655 - val_ca1-[0,5]: 1219.5819 - val_ca1-[6,11]: 822.4290 - val_ca1-[12,17]: 450.3770 - val_ca1-[18,23]: 216.7795 - val_ca2-[0,5]: 2955.5120 - val_ca2-[6,11]: 2308.2976 - val_ca2-[12,17]: 1640.4772 - val_ca2-[18,23]: 1128.6439 - val_ca3-[0,5]: 16.6331 - val_ca3-[6,11]: 2.6716 - val_ca3-[12,17]: 4.8341 - val_ca3-[18,23]: 11.5004 - val_ca4-[0,5]: 0.1274 - val_ca4-[6,11]: 0.0709 - val_ca4-[12,17]: 0.5314 - val_ca4-[18,23]: 2.3240\n",
      "Epoch 293/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 396.0767 - ca1-[6,11]: 825.0970 - ca1-[12,17]: 451.1098 - ca1-[18,23]: 227.6106 - ca2-[0,5]: 2653.0595 - ca2-[6,11]: 2200.2980 - ca2-[12,17]: 1691.8815 - ca2-[18,23]: 1216.0247 - ca3-[0,5]: 16.7666 - ca3-[6,11]: 0.3092 - ca3-[12,17]: 0.1080 - ca3-[18,23]: 0.2064 - ca4-[0,5]: 0.1153 - ca4-[6,11]: 0.0072 - ca4-[12,17]: 0.0124 - ca4-[18,23]: 0.0711 - val_ca1-[0,5]: 1230.0256 - val_ca1-[6,11]: 832.5758 - val_ca1-[12,17]: 456.6894 - val_ca1-[18,23]: 221.5663 - val_ca2-[0,5]: 2980.1353 - val_ca2-[6,11]: 2332.6294 - val_ca2-[12,17]: 1658.8301 - val_ca2-[18,23]: 1145.5688 - val_ca3-[0,5]: 16.7665 - val_ca3-[6,11]: 2.6579 - val_ca3-[12,17]: 4.7122 - val_ca3-[18,23]: 11.0570 - val_ca4-[0,5]: 0.1285 - val_ca4-[6,11]: 0.0531 - val_ca4-[12,17]: 0.4461 - val_ca4-[18,23]: 2.0815\n",
      "Epoch 294/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 399.4120 - ca1-[6,11]: 835.7162 - ca1-[12,17]: 459.9485 - ca1-[18,23]: 232.7338 - ca2-[0,5]: 2673.5476 - ca2-[6,11]: 2220.4016 - ca2-[12,17]: 1638.7086 - ca2-[18,23]: 1228.9720 - ca3-[0,5]: 16.6619 - ca3-[6,11]: 0.2815 - ca3-[12,17]: 0.1166 - ca3-[18,23]: 0.2245 - ca4-[0,5]: 0.1180 - ca4-[6,11]: 0.0084 - ca4-[12,17]: 0.0150 - ca4-[18,23]: 0.0544 - val_ca1-[0,5]: 1237.7678 - val_ca1-[6,11]: 836.6877 - val_ca1-[12,17]: 460.3314 - val_ca1-[18,23]: 226.5661 - val_ca2-[0,5]: 3000.3096 - val_ca2-[6,11]: 2346.9268 - val_ca2-[12,17]: 1671.8904 - val_ca2-[18,23]: 1162.5636 - val_ca3-[0,5]: 16.8582 - val_ca3-[6,11]: 2.6769 - val_ca3-[12,17]: 4.8216 - val_ca3-[18,23]: 10.9691 - val_ca4-[0,5]: 0.1247 - val_ca4-[6,11]: 0.0473 - val_ca4-[12,17]: 0.4377 - val_ca4-[18,23]: 2.0361\n",
      "Epoch 295/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 430.2158 - ca1-[6,11]: 839.1572 - ca1-[12,17]: 465.8203 - ca1-[18,23]: 234.7387 - ca2-[0,5]: 2595.1414 - ca2-[6,11]: 2159.2923 - ca2-[12,17]: 1717.5203 - ca2-[18,23]: 1242.8734 - ca3-[0,5]: 16.8327 - ca3-[6,11]: 0.3041 - ca3-[12,17]: 0.1213 - ca3-[18,23]: 0.2321 - ca4-[0,5]: 0.1192 - ca4-[6,11]: 0.0116 - ca4-[12,17]: 0.0196 - ca4-[18,23]: 0.0667 - val_ca1-[0,5]: 1245.9573 - val_ca1-[6,11]: 843.0268 - val_ca1-[12,17]: 468.0462 - val_ca1-[18,23]: 231.1501 - val_ca2-[0,5]: 3021.4673 - val_ca2-[6,11]: 2365.0747 - val_ca2-[12,17]: 1692.6700 - val_ca2-[18,23]: 1178.4082 - val_ca3-[0,5]: 16.8593 - val_ca3-[6,11]: 2.3808 - val_ca3-[12,17]: 4.5773 - val_ca3-[18,23]: 10.6386 - val_ca4-[0,5]: 0.1236 - val_ca4-[6,11]: 0.0582 - val_ca4-[12,17]: 0.4845 - val_ca4-[18,23]: 2.1436\n",
      "Epoch 296/300\n",
      "26/26 [==============================] - 3s 107ms/step - ca1-[0,5]: 406.0943 - ca1-[6,11]: 853.4577 - ca1-[12,17]: 462.7175 - ca1-[18,23]: 241.1899 - ca2-[0,5]: 2714.7951 - ca2-[6,11]: 2251.8596 - ca2-[12,17]: 1711.5166 - ca2-[18,23]: 1208.8382 - ca3-[0,5]: 16.6299 - ca3-[6,11]: 0.2985 - ca3-[12,17]: 0.0979 - ca3-[18,23]: 0.1572 - ca4-[0,5]: 0.1125 - ca4-[6,11]: 0.0065 - ca4-[12,17]: 0.0115 - ca4-[18,23]: 0.0619 - val_ca1-[0,5]: 1255.4473 - val_ca1-[6,11]: 851.4286 - val_ca1-[12,17]: 471.0751 - val_ca1-[18,23]: 231.1346 - val_ca2-[0,5]: 3044.6362 - val_ca2-[6,11]: 2386.3901 - val_ca2-[12,17]: 1705.0649 - val_ca2-[18,23]: 1183.7579 - val_ca3-[0,5]: 16.9748 - val_ca3-[6,11]: 2.4127 - val_ca3-[12,17]: 4.4935 - val_ca3-[18,23]: 10.8787 - val_ca4-[0,5]: 0.1208 - val_ca4-[6,11]: 0.0583 - val_ca4-[12,17]: 0.4766 - val_ca4-[18,23]: 2.1566\n",
      "Epoch 297/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 409.7492 - ca1-[6,11]: 816.2927 - ca1-[12,17]: 476.8040 - ca1-[18,23]: 250.2394 - ca2-[0,5]: 2626.9710 - ca2-[6,11]: 2278.7634 - ca2-[12,17]: 1535.9033 - ca2-[18,23]: 1213.0618 - ca3-[0,5]: 17.0798 - ca3-[6,11]: 0.3014 - ca3-[12,17]: 0.1062 - ca3-[18,23]: 0.2022 - ca4-[0,5]: 0.1151 - ca4-[6,11]: 0.0070 - ca4-[12,17]: 0.0108 - ca4-[18,23]: 0.0555 - val_ca1-[0,5]: 1267.5542 - val_ca1-[6,11]: 863.4669 - val_ca1-[12,17]: 480.0480 - val_ca1-[18,23]: 239.6239 - val_ca2-[0,5]: 3065.8254 - val_ca2-[6,11]: 2408.7576 - val_ca2-[12,17]: 1723.9122 - val_ca2-[18,23]: 1205.2179 - val_ca3-[0,5]: 16.9964 - val_ca3-[6,11]: 2.3936 - val_ca3-[12,17]: 4.4267 - val_ca3-[18,23]: 10.7516 - val_ca4-[0,5]: 0.1216 - val_ca4-[6,11]: 0.0399 - val_ca4-[12,17]: 0.4086 - val_ca4-[18,23]: 2.0259\n",
      "Epoch 298/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 438.8859 - ca1-[6,11]: 866.6966 - ca1-[12,17]: 486.3667 - ca1-[18,23]: 254.5840 - ca2-[0,5]: 2452.2325 - ca2-[6,11]: 2300.9677 - ca2-[12,17]: 1836.6490 - ca2-[18,23]: 1286.4704 - ca3-[0,5]: 17.0235 - ca3-[6,11]: 0.2892 - ca3-[12,17]: 0.0979 - ca3-[18,23]: 0.1357 - ca4-[0,5]: 0.1107 - ca4-[6,11]: 0.0052 - ca4-[12,17]: 0.0094 - ca4-[18,23]: 0.0548 - val_ca1-[0,5]: 1306.7755 - val_ca1-[6,11]: 895.2117 - val_ca1-[12,17]: 507.4561 - val_ca1-[18,23]: 253.1244 - val_ca2-[0,5]: 3088.9861 - val_ca2-[6,11]: 2428.4841 - val_ca2-[12,17]: 1748.6720 - val_ca2-[18,23]: 1212.9585 - val_ca3-[0,5]: 17.0209 - val_ca3-[6,11]: 2.2371 - val_ca3-[12,17]: 4.4993 - val_ca3-[18,23]: 10.9918 - val_ca4-[0,5]: 0.1191 - val_ca4-[6,11]: 0.0590 - val_ca4-[12,17]: 0.4771 - val_ca4-[18,23]: 2.1598\n",
      "Epoch 299/300\n",
      "26/26 [==============================] - 3s 109ms/step - ca1-[0,5]: 432.1233 - ca1-[6,11]: 902.1299 - ca1-[12,17]: 508.5789 - ca1-[18,23]: 281.7161 - ca2-[0,5]: 2777.2236 - ca2-[6,11]: 2315.7242 - ca2-[12,17]: 1783.9802 - ca2-[18,23]: 1297.3228 - ca3-[0,5]: 17.0504 - ca3-[6,11]: 0.3101 - ca3-[12,17]: 0.1016 - ca3-[18,23]: 0.1432 - ca4-[0,5]: 0.1099 - ca4-[6,11]: 0.0090 - ca4-[12,17]: 0.0118 - ca4-[18,23]: 0.0488 - val_ca1-[0,5]: 1328.5785 - val_ca1-[6,11]: 916.8900 - val_ca1-[12,17]: 516.7383 - val_ca1-[18,23]: 260.6089 - val_ca2-[0,5]: 3112.6951 - val_ca2-[6,11]: 2455.8735 - val_ca2-[12,17]: 1758.1099 - val_ca2-[18,23]: 1224.0564 - val_ca3-[0,5]: 17.2957 - val_ca3-[6,11]: 2.1640 - val_ca3-[12,17]: 4.2303 - val_ca3-[18,23]: 10.7585 - val_ca4-[0,5]: 0.1213 - val_ca4-[6,11]: 0.0512 - val_ca4-[12,17]: 0.4540 - val_ca4-[18,23]: 2.1726\n",
      "Epoch 300/300\n",
      "26/26 [==============================] - 3s 108ms/step - ca1-[0,5]: 426.6678 - ca1-[6,11]: 921.3319 - ca1-[12,17]: 522.8678 - ca1-[18,23]: 283.1501 - ca2-[0,5]: 2703.3489 - ca2-[6,11]: 2335.9450 - ca2-[12,17]: 1872.2840 - ca2-[18,23]: 1310.3605 - ca3-[0,5]: 17.3926 - ca3-[6,11]: 0.3204 - ca3-[12,17]: 0.1372 - ca3-[18,23]: 0.1467 - ca4-[0,5]: 0.1101 - ca4-[6,11]: 0.0041 - ca4-[12,17]: 0.0062 - ca4-[18,23]: 0.0458 - val_ca1-[0,5]: 1344.6111 - val_ca1-[6,11]: 926.7995 - val_ca1-[12,17]: 527.4464 - val_ca1-[18,23]: 271.1566 - val_ca2-[0,5]: 3132.7942 - val_ca2-[6,11]: 2467.9377 - val_ca2-[12,17]: 1774.4084 - val_ca2-[18,23]: 1245.7930 - val_ca3-[0,5]: 17.2203 - val_ca3-[6,11]: 2.2780 - val_ca3-[12,17]: 4.4918 - val_ca3-[18,23]: 10.4403 - val_ca4-[0,5]: 0.1166 - val_ca4-[6,11]: 0.0549 - val_ca4-[12,17]: 0.4449 - val_ca4-[18,23]: 2.0304\n"
     ]
    }
   ],
   "source": [
    "tmp = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=300,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "for k in [k for k in history if 'val_ca1' in k]:\n",
    "    plt.plot(history[k], label=k.split('-')[1])\n",
    "        \n",
    "plt.legend()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
