{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow import keras\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "fp_local = '/home/jovyan/docker/src/python/temp_test/DJGrad'\n",
    "fp_data = os.path.join(fp_local, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv(os.path.join(fp_data,'winequality-red.csv'),delimiter=';')\n",
    "wine_df = wine_df.append(pd.read_csv(os.path.join(fp_data,'winequality-white.csv'),delimiter=';'))\n",
    "wine_df = wine_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.052</td>\n",
       "      <td>19.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.79</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.082</td>\n",
       "      <td>15.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99655</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.68</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041</td>\n",
       "      <td>39.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.99004</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.37</td>\n",
       "      <td>12.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.27</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.059</td>\n",
       "      <td>23.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.99570</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.74</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.039</td>\n",
       "      <td>51.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.99770</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.43</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.28</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.049</td>\n",
       "      <td>31.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.99677</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>10.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.035</td>\n",
       "      <td>31.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.99096</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.72</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.081</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0.045</td>\n",
       "      <td>53.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.99752</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.77</td>\n",
       "      <td>10.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.036</td>\n",
       "      <td>15.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.99100</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.42</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1198            7.7             0.260         0.26             2.0      0.052   \n",
       "1247            7.4             0.550         0.19             1.8      0.082   \n",
       "4683            6.5             0.330         0.32             1.0      0.041   \n",
       "1713            6.6             0.340         0.27             6.2      0.059   \n",
       "1282            7.4             0.310         0.74            10.7      0.039   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "3814            7.4             0.340         0.28            12.1      0.049   \n",
       "3568            7.8             0.150         0.34             1.1      0.035   \n",
       "602             7.7             0.835         0.00             2.6      0.081   \n",
       "2267            6.6             0.190         0.43            10.9      0.045   \n",
       "336             6.3             0.230         0.33             1.5      0.036   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1198                 19.0                  77.0  0.99510  3.15       0.79   \n",
       "1247                 15.0                  34.0  0.99655  3.49       0.68   \n",
       "4683                 39.0                 120.0  0.99004  3.06       0.37   \n",
       "1713                 23.0                 136.0  0.99570  3.30       0.49   \n",
       "1282                 51.0                 147.0  0.99770  3.02       0.43   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "3814                 31.0                 149.0  0.99677  3.22       0.49   \n",
       "3568                 31.0                  93.0  0.99096  3.07       0.72   \n",
       "602                   6.0                  14.0  0.99750  3.30       0.52   \n",
       "2267                 53.0                 154.0  0.99752  3.52       0.77   \n",
       "336                  15.0                 105.0  0.99100  3.32       0.42   \n",
       "\n",
       "      alcohol  quality  \n",
       "1198     10.9        6  \n",
       "1247     10.5        5  \n",
       "4683     12.2        6  \n",
       "1713     10.1        6  \n",
       "1282      8.7        5  \n",
       "...       ...      ...  \n",
       "3814     10.3        5  \n",
       "3568     11.3        7  \n",
       "602       9.3        5  \n",
       "2267     10.4        6  \n",
       "336      11.2        6  \n",
       "\n",
       "[6497 rows x 12 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda/lib/python3.8/site-packages/pandas/plotting/_matplotlib/tools.py:331: MatplotlibDeprecationWarning: \n",
      "The is_first_col function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use ax.get_subplotspec().is_first_col() instead.\n",
      "  if ax.is_first_col():\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wine_df.hist(figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(wine_df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "quants = wine_df['alcohol'].quantile([0,0.25, 0.5,0.75,1.0]).to_numpy()\n",
    "res = []\n",
    "for q1, q2 in zip(quants[:-1],quants[1:]):\n",
    "    res.append(wine_df.loc[(wine_df['alcohol']>=q1) & (wine_df['alcohol']<q2)])\n",
    "    \n",
    "train_dfs = [q.sample(frac=0.8) for q in res]\n",
    "test_dfs = [q.drop(t.index) for q,t in zip(res,train_dfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_datamodel = Sequential([\n",
    "    layers.Dense(1024, activation='sigmoid', input_shape=(11,)),\n",
    "    layers.Dense(64, activation='sigmoid'),\n",
    "    layers.Dense(32, activation='sigmoid'),\n",
    "    layers.Dense(16, activation='sigmoid'),\n",
    "    layers.Dense(8, activation='sigmoid'),\n",
    "    layers.Dense(1, 'linear')\n",
    "])\n",
    "\n",
    "fp_datamodel.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(\n",
    "    ),\n",
    "#     metrics=[CWAcc1(n,name=f'cl{n}') for n in range(10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['quality'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-308-08a288ef1a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-308-08a288ef1a7e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4161\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4162\u001b[0m         \"\"\"\n\u001b[0;32m-> 4163\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4164\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4165\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3885\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3920\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3921\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5282\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5283\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['quality'] not found in axis\""
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "history = defaultdict(list)\n",
    "\n",
    "x = np.concatenate([train_dfs[i].drop('quality',axis=1).to_numpy() for i in range(4)])\n",
    "y = np.concatenate([train_dfs[i]['quality'].to_numpy() for i in range(4)])\n",
    "p = np.random.permutation(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 24.9543 - val_loss: 17.7191\n",
      "Epoch 2/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 14.8928 - val_loss: 12.1265\n",
      "Epoch 3/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 10.7069 - val_loss: 8.9244\n",
      "Epoch 4/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 7.9511 - val_loss: 6.6091\n",
      "Epoch 5/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 5.9111 - val_loss: 4.8762\n",
      "Epoch 6/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 4.3807 - val_loss: 3.5876\n",
      "Epoch 7/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 3.2443 - val_loss: 2.6407\n",
      "Epoch 8/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 2.4172 - val_loss: 1.9668\n",
      "Epoch 9/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 1.8321 - val_loss: 1.4984\n",
      "Epoch 10/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 1.4299 - val_loss: 1.1876\n",
      "Epoch 11/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 1.1631 - val_loss: 0.9885\n",
      "Epoch 12/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.9936 - val_loss: 0.8659\n",
      "Epoch 13/10000\n",
      "130/130 [==============================] - 0s 701us/step - loss: 0.8905 - val_loss: 0.7965\n",
      "Epoch 14/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.8303 - val_loss: 0.7588\n",
      "Epoch 15/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.7969 - val_loss: 0.7395\n",
      "Epoch 16/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.7793 - val_loss: 0.7311\n",
      "Epoch 17/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.7708 - val_loss: 0.7277\n",
      "Epoch 18/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.7667 - val_loss: 0.7269\n",
      "Epoch 19/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.7649 - val_loss: 0.7270\n",
      "Epoch 20/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.7642 - val_loss: 0.7273\n",
      "Epoch 21/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.7639 - val_loss: 0.7277\n",
      "Epoch 22/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.7638 - val_loss: 0.7280\n",
      "Epoch 23/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.7638 - val_loss: 0.7280\n",
      "Epoch 24/10000\n",
      "130/130 [==============================] - 0s 703us/step - loss: 0.7639 - val_loss: 0.7284\n",
      "Epoch 25/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.7638 - val_loss: 0.7282\n",
      "Epoch 26/10000\n",
      "130/130 [==============================] - 0s 706us/step - loss: 0.7638 - val_loss: 0.7282\n",
      "Epoch 27/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.7638 - val_loss: 0.7283\n",
      "Epoch 28/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.7639 - val_loss: 0.7283\n",
      "Epoch 29/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.7640 - val_loss: 0.7285\n",
      "Epoch 30/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.7639 - val_loss: 0.7284\n",
      "Epoch 31/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.7639 - val_loss: 0.7285\n",
      "Epoch 32/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.7639 - val_loss: 0.7283\n",
      "Epoch 33/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.7639 - val_loss: 0.7282\n",
      "Epoch 34/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.7639 - val_loss: 0.7280\n",
      "Epoch 35/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.7639 - val_loss: 0.7283\n",
      "Epoch 36/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.7639 - val_loss: 0.7281\n",
      "Epoch 37/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.7640 - val_loss: 0.7285\n",
      "Epoch 38/10000\n",
      "130/130 [==============================] - 0s 701us/step - loss: 0.7640 - val_loss: 0.7281\n",
      "Epoch 39/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.7639 - val_loss: 0.7280\n",
      "Epoch 40/10000\n",
      "130/130 [==============================] - 0s 704us/step - loss: 0.7640 - val_loss: 0.7285\n",
      "Epoch 41/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.7640 - val_loss: 0.7274\n",
      "Epoch 42/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.7641 - val_loss: 0.7288\n",
      "Epoch 43/10000\n",
      "130/130 [==============================] - 0s 706us/step - loss: 0.7641 - val_loss: 0.7280\n",
      "Epoch 44/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.7640 - val_loss: 0.7280\n",
      "Epoch 45/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.7639 - val_loss: 0.7284\n",
      "Epoch 46/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.7640 - val_loss: 0.7296\n",
      "Epoch 47/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.7639 - val_loss: 0.7281\n",
      "Epoch 48/10000\n",
      "130/130 [==============================] - 0s 705us/step - loss: 0.7641 - val_loss: 0.7285\n",
      "Epoch 49/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.7640 - val_loss: 0.7285\n",
      "Epoch 50/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.7641 - val_loss: 0.7289\n",
      "Epoch 51/10000\n",
      "130/130 [==============================] - 0s 705us/step - loss: 0.7640 - val_loss: 0.7291\n",
      "Epoch 52/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.7643 - val_loss: 0.7295\n",
      "Epoch 53/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.7641 - val_loss: 0.7287\n",
      "Epoch 54/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.7640 - val_loss: 0.7277\n",
      "Epoch 55/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.7640 - val_loss: 0.7283\n",
      "Epoch 56/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.7643 - val_loss: 0.7285\n",
      "Epoch 57/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.7640 - val_loss: 0.7275\n",
      "Epoch 58/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.7641 - val_loss: 0.7273\n",
      "Epoch 59/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.7641 - val_loss: 0.7290\n",
      "Epoch 60/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.7641 - val_loss: 0.7290\n",
      "Epoch 61/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.7641 - val_loss: 0.7281\n",
      "Epoch 62/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.7640 - val_loss: 0.7285\n",
      "Epoch 63/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.7642 - val_loss: 0.7285\n",
      "Epoch 64/10000\n",
      "130/130 [==============================] - 0s 701us/step - loss: 0.7640 - val_loss: 0.7276\n",
      "Epoch 65/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.7645 - val_loss: 0.7295\n",
      "Epoch 66/10000\n",
      "130/130 [==============================] - 0s 830us/step - loss: 0.7641 - val_loss: 0.7275\n",
      "Epoch 67/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.7644 - val_loss: 0.7281\n",
      "Epoch 68/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.7643 - val_loss: 0.7288\n",
      "Epoch 69/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.7642 - val_loss: 0.7294\n",
      "Epoch 70/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.7640 - val_loss: 0.7295\n",
      "Epoch 71/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.7644 - val_loss: 0.7285\n",
      "Epoch 72/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.7643 - val_loss: 0.7274\n",
      "Epoch 73/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.7641 - val_loss: 0.7300\n",
      "Epoch 74/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.7641 - val_loss: 0.7280\n",
      "Epoch 75/10000\n",
      "130/130 [==============================] - 0s 705us/step - loss: 0.7641 - val_loss: 0.7301\n",
      "Epoch 76/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.7642 - val_loss: 0.7293\n",
      "Epoch 77/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.7642 - val_loss: 0.7274\n",
      "Epoch 78/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.7640 - val_loss: 0.7285\n",
      "Epoch 79/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.7643 - val_loss: 0.7275\n",
      "Epoch 80/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.7644 - val_loss: 0.7295\n",
      "Epoch 81/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.7644 - val_loss: 0.7278\n",
      "Epoch 82/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.7643 - val_loss: 0.7276\n",
      "Epoch 83/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.7642 - val_loss: 0.7290\n",
      "Epoch 84/10000\n",
      "130/130 [==============================] - 0s 696us/step - loss: 0.7641 - val_loss: 0.7287\n",
      "Epoch 85/10000\n",
      "130/130 [==============================] - 0s 684us/step - loss: 0.7640 - val_loss: 0.7286\n",
      "Epoch 86/10000\n",
      "130/130 [==============================] - 0s 700us/step - loss: 0.7640 - val_loss: 0.7302\n",
      "Epoch 87/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.7646 - val_loss: 0.7280\n",
      "Epoch 88/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.7638 - val_loss: 0.7307\n",
      "Epoch 89/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.7643 - val_loss: 0.7295\n",
      "Epoch 90/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.7643 - val_loss: 0.7281\n",
      "Epoch 91/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.7638 - val_loss: 0.7289\n",
      "Epoch 92/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.7642 - val_loss: 0.7296\n",
      "Epoch 93/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.7629 - val_loss: 0.7230\n",
      "Epoch 94/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.7397 - val_loss: 0.7022\n",
      "Epoch 95/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.7319 - val_loss: 0.6634\n",
      "Epoch 96/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.6975 - val_loss: 0.6449\n",
      "Epoch 97/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.6614 - val_loss: 0.6075\n",
      "Epoch 98/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.6319 - val_loss: 0.5324\n",
      "Epoch 99/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.5858 - val_loss: 0.5242\n",
      "Epoch 100/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.5740 - val_loss: 0.5152\n",
      "Epoch 101/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.5821 - val_loss: 0.5020\n",
      "Epoch 102/10000\n",
      "130/130 [==============================] - 0s 851us/step - loss: 0.5778 - val_loss: 0.4960\n",
      "Epoch 103/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.5569 - val_loss: 0.5244\n",
      "Epoch 104/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.5571 - val_loss: 0.5326\n",
      "Epoch 105/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.5670 - val_loss: 0.4938\n",
      "Epoch 106/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.5489 - val_loss: 0.4919\n",
      "Epoch 107/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.5473 - val_loss: 0.4779\n",
      "Epoch 108/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5402 - val_loss: 0.5161\n",
      "Epoch 109/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.5403 - val_loss: 0.4766\n",
      "Epoch 110/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.5421 - val_loss: 0.4766\n",
      "Epoch 111/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.5427 - val_loss: 0.5265\n",
      "Epoch 112/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.5368 - val_loss: 0.4879\n",
      "Epoch 113/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.5408 - val_loss: 0.4690\n",
      "Epoch 114/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.5396 - val_loss: 0.4843\n",
      "Epoch 115/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.5356 - val_loss: 0.4903\n",
      "Epoch 116/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.5383 - val_loss: 0.5337\n",
      "Epoch 117/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.5309 - val_loss: 0.4727\n",
      "Epoch 118/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.5322 - val_loss: 0.4738\n",
      "Epoch 119/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.5319 - val_loss: 0.4823\n",
      "Epoch 120/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.5398 - val_loss: 0.4832\n",
      "Epoch 121/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.5345 - val_loss: 0.4842\n",
      "Epoch 122/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.5308 - val_loss: 0.4945\n",
      "Epoch 123/10000\n",
      "130/130 [==============================] - 0s 897us/step - loss: 0.5331 - val_loss: 0.4804\n",
      "Epoch 124/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.5090\n",
      "Epoch 125/10000\n",
      "130/130 [==============================] - 0s 825us/step - loss: 0.5300 - val_loss: 0.4747\n",
      "Epoch 126/10000\n",
      "130/130 [==============================] - 0s 823us/step - loss: 0.5304 - val_loss: 0.4728\n",
      "Epoch 127/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5304 - val_loss: 0.5138\n",
      "Epoch 128/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 0.4776\n",
      "Epoch 129/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.5220 - val_loss: 0.4694\n",
      "Epoch 130/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.5226 - val_loss: 0.4817\n",
      "Epoch 131/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.5258 - val_loss: 0.4861\n",
      "Epoch 132/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.5198 - val_loss: 0.4695\n",
      "Epoch 133/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.5177 - val_loss: 0.4677\n",
      "Epoch 134/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.5311 - val_loss: 0.4907\n",
      "Epoch 135/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.5184 - val_loss: 0.4749\n",
      "Epoch 136/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.5214 - val_loss: 0.4749\n",
      "Epoch 137/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.5187 - val_loss: 0.4794\n",
      "Epoch 138/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.5283 - val_loss: 0.4830\n",
      "Epoch 139/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.5207 - val_loss: 0.4853\n",
      "Epoch 140/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.5198 - val_loss: 0.4724\n",
      "Epoch 141/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.5153 - val_loss: 0.4677\n",
      "Epoch 142/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.5111 - val_loss: 0.4726\n",
      "Epoch 143/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.5146 - val_loss: 0.4760\n",
      "Epoch 144/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.5088 - val_loss: 0.4821\n",
      "Epoch 145/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.5120 - val_loss: 0.4909\n",
      "Epoch 146/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.5112 - val_loss: 0.4696\n",
      "Epoch 147/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.5123 - val_loss: 0.4761\n",
      "Epoch 148/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.5098 - val_loss: 0.4869\n",
      "Epoch 149/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.5161 - val_loss: 0.4836\n",
      "Epoch 150/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.5092 - val_loss: 0.4765\n",
      "Epoch 151/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.5118 - val_loss: 0.4742\n",
      "Epoch 152/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.5053 - val_loss: 0.4712\n",
      "Epoch 153/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.5089 - val_loss: 0.4761\n",
      "Epoch 154/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.5076 - val_loss: 0.4732\n",
      "Epoch 155/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 740us/step - loss: 0.5025 - val_loss: 0.4691\n",
      "Epoch 156/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.5131 - val_loss: 0.5104\n",
      "Epoch 157/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.5149 - val_loss: 0.4732\n",
      "Epoch 158/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.5084 - val_loss: 0.4707\n",
      "Epoch 159/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.5062 - val_loss: 0.4690\n",
      "Epoch 160/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.5064 - val_loss: 0.4793\n",
      "Epoch 161/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.5114 - val_loss: 0.4667\n",
      "Epoch 162/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.5135 - val_loss: 0.4779\n",
      "Epoch 163/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.5027 - val_loss: 0.4803\n",
      "Epoch 164/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.5104 - val_loss: 0.4749\n",
      "Epoch 165/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.5040 - val_loss: 0.4652\n",
      "Epoch 166/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.5038 - val_loss: 0.4880\n",
      "Epoch 167/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.5060 - val_loss: 0.4699\n",
      "Epoch 168/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.5024 - val_loss: 0.4791\n",
      "Epoch 169/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.5024 - val_loss: 0.4754\n",
      "Epoch 170/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.5016 - val_loss: 0.4725\n",
      "Epoch 171/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.5012 - val_loss: 0.4739\n",
      "Epoch 172/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.4996 - val_loss: 0.5131\n",
      "Epoch 173/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4974 - val_loss: 0.4741\n",
      "Epoch 174/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.4977 - val_loss: 0.4968\n",
      "Epoch 175/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.5024 - val_loss: 0.4788\n",
      "Epoch 176/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4976 - val_loss: 0.4757\n",
      "Epoch 177/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.4960 - val_loss: 0.4779\n",
      "Epoch 178/10000\n",
      "130/130 [==============================] - 0s 946us/step - loss: 0.4990 - val_loss: 0.4998\n",
      "Epoch 179/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.4997 - val_loss: 0.4883\n",
      "Epoch 180/10000\n",
      "130/130 [==============================] - 0s 908us/step - loss: 0.5006 - val_loss: 0.4896\n",
      "Epoch 181/10000\n",
      "130/130 [==============================] - 0s 908us/step - loss: 0.4951 - val_loss: 0.4813\n",
      "Epoch 182/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.5041 - val_loss: 0.4862\n",
      "Epoch 183/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.4967 - val_loss: 0.4818\n",
      "Epoch 184/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.4982 - val_loss: 0.4663\n",
      "Epoch 185/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.4922 - val_loss: 0.4682\n",
      "Epoch 186/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.4943 - val_loss: 0.4910\n",
      "Epoch 187/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.4960 - val_loss: 0.4730\n",
      "Epoch 188/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4922 - val_loss: 0.4760\n",
      "Epoch 189/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.4939 - val_loss: 0.4922\n",
      "Epoch 190/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.4975 - val_loss: 0.4637\n",
      "Epoch 191/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.4912 - val_loss: 0.4663\n",
      "Epoch 192/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.4920 - val_loss: 0.4675\n",
      "Epoch 193/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.4935 - val_loss: 0.4749\n",
      "Epoch 194/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.4908 - val_loss: 0.4700\n",
      "Epoch 195/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4905 - val_loss: 0.4769\n",
      "Epoch 196/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.4916 - val_loss: 0.4774\n",
      "Epoch 197/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.4893 - val_loss: 0.4669\n",
      "Epoch 198/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.4877 - val_loss: 0.4686\n",
      "Epoch 199/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.4911 - val_loss: 0.4659\n",
      "Epoch 200/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.4874 - val_loss: 0.4685\n",
      "Epoch 201/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4856 - val_loss: 0.4777\n",
      "Epoch 202/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.4889 - val_loss: 0.4763\n",
      "Epoch 203/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4870 - val_loss: 0.4636\n",
      "Epoch 204/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.4833 - val_loss: 0.4683\n",
      "Epoch 205/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.4822 - val_loss: 0.4657\n",
      "Epoch 206/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.4912 - val_loss: 0.4717\n",
      "Epoch 207/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4808 - val_loss: 0.4769\n",
      "Epoch 208/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.4919 - val_loss: 0.4611\n",
      "Epoch 209/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.4851 - val_loss: 0.4658\n",
      "Epoch 210/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.4879 - val_loss: 0.4774\n",
      "Epoch 211/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.4832 - val_loss: 0.4647\n",
      "Epoch 212/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.4866 - val_loss: 0.4626\n",
      "Epoch 213/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.4817 - val_loss: 0.4628\n",
      "Epoch 214/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.4796 - val_loss: 0.4625\n",
      "Epoch 215/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.4789 - val_loss: 0.4619\n",
      "Epoch 216/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.4797 - val_loss: 0.4595\n",
      "Epoch 217/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4791 - val_loss: 0.4565\n",
      "Epoch 218/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.4843 - val_loss: 0.4580\n",
      "Epoch 219/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.4885 - val_loss: 0.4617\n",
      "Epoch 220/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.4819 - val_loss: 0.4605\n",
      "Epoch 221/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.4807 - val_loss: 0.4745\n",
      "Epoch 222/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.4806 - val_loss: 0.4624\n",
      "Epoch 223/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.4776 - val_loss: 0.4813\n",
      "Epoch 224/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.4779 - val_loss: 0.4704\n",
      "Epoch 225/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.4823 - val_loss: 0.4659\n",
      "Epoch 226/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.4763 - val_loss: 0.4563\n",
      "Epoch 227/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4730 - val_loss: 0.4738\n",
      "Epoch 228/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.4703 - val_loss: 0.4641\n",
      "Epoch 229/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.4773 - val_loss: 0.4591\n",
      "Epoch 230/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.4761 - val_loss: 0.4649\n",
      "Epoch 231/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4815 - val_loss: 0.5128\n",
      "Epoch 232/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.4813 - val_loss: 0.5009\n",
      "Epoch 233/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.4851 - val_loss: 0.5046\n",
      "Epoch 234/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.4775 - val_loss: 0.4642\n",
      "Epoch 235/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4726 - val_loss: 0.4584\n",
      "Epoch 236/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.4696 - val_loss: 0.4821\n",
      "Epoch 237/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.4788 - val_loss: 0.4624\n",
      "Epoch 238/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4755 - val_loss: 0.4607\n",
      "Epoch 239/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.4752 - val_loss: 0.4909\n",
      "Epoch 240/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4710 - val_loss: 0.4613\n",
      "Epoch 241/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.4767 - val_loss: 0.4546\n",
      "Epoch 242/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.4668 - val_loss: 0.4599\n",
      "Epoch 243/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.4707 - val_loss: 0.4572\n",
      "Epoch 244/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4649 - val_loss: 0.4602\n",
      "Epoch 245/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.4778 - val_loss: 0.4735\n",
      "Epoch 246/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.4745 - val_loss: 0.4586\n",
      "Epoch 247/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.4664 - val_loss: 0.4532\n",
      "Epoch 248/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.4676 - val_loss: 0.4566\n",
      "Epoch 249/10000\n",
      "130/130 [==============================] - 0s 891us/step - loss: 0.4694 - val_loss: 0.4581\n",
      "Epoch 250/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4648 - val_loss: 0.4811\n",
      "Epoch 251/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.4674 - val_loss: 0.4627\n",
      "Epoch 252/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.4620 - val_loss: 0.4735\n",
      "Epoch 253/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.4683 - val_loss: 0.4681\n",
      "Epoch 254/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.4638 - val_loss: 0.4555\n",
      "Epoch 255/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.4687 - val_loss: 0.4659\n",
      "Epoch 256/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.4715 - val_loss: 0.4686\n",
      "Epoch 257/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.4642 - val_loss: 0.4583\n",
      "Epoch 258/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.4737 - val_loss: 0.4632\n",
      "Epoch 259/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.4692 - val_loss: 0.4803\n",
      "Epoch 260/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4816 - val_loss: 0.4658\n",
      "Epoch 261/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.4660 - val_loss: 0.4715\n",
      "Epoch 262/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.4681 - val_loss: 0.4606\n",
      "Epoch 263/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.4618 - val_loss: 0.4514\n",
      "Epoch 264/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.4616 - val_loss: 0.4587\n",
      "Epoch 265/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.4658 - val_loss: 0.4637\n",
      "Epoch 266/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.4655 - val_loss: 0.4612\n",
      "Epoch 267/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.4695 - val_loss: 0.4523\n",
      "Epoch 268/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.4595 - val_loss: 0.4973\n",
      "Epoch 269/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.4637 - val_loss: 0.4834\n",
      "Epoch 270/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.4622 - val_loss: 0.4572\n",
      "Epoch 271/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.4639 - val_loss: 0.4984\n",
      "Epoch 272/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.4634 - val_loss: 0.4616\n",
      "Epoch 273/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.4648 - val_loss: 0.4545\n",
      "Epoch 274/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.4551 - val_loss: 0.4624\n",
      "Epoch 275/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.4651 - val_loss: 0.4542\n",
      "Epoch 276/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.4620 - val_loss: 0.4562\n",
      "Epoch 277/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.4596 - val_loss: 0.4598\n",
      "Epoch 278/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.4728 - val_loss: 0.4521\n",
      "Epoch 279/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.4616 - val_loss: 0.4612\n",
      "Epoch 280/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.4525 - val_loss: 0.4528\n",
      "Epoch 281/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.4590 - val_loss: 0.4621\n",
      "Epoch 282/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.4557 - val_loss: 0.4582\n",
      "Epoch 283/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4673 - val_loss: 0.4701\n",
      "Epoch 284/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.4585 - val_loss: 0.4673\n",
      "Epoch 285/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.4563 - val_loss: 0.4731\n",
      "Epoch 286/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.4611 - val_loss: 0.4604\n",
      "Epoch 287/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.4552 - val_loss: 0.4531\n",
      "Epoch 288/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.4636 - val_loss: 0.4733\n",
      "Epoch 289/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.4723 - val_loss: 0.4578\n",
      "Epoch 290/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4580 - val_loss: 0.4496\n",
      "Epoch 291/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4539 - val_loss: 0.4522\n",
      "Epoch 292/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.4519 - val_loss: 0.4644\n",
      "Epoch 293/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.4563 - val_loss: 0.4756\n",
      "Epoch 294/10000\n",
      "130/130 [==============================] - 0s 832us/step - loss: 0.4525 - val_loss: 0.4579\n",
      "Epoch 295/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.4556 - val_loss: 0.4748\n",
      "Epoch 296/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4522 - val_loss: 0.4506\n",
      "Epoch 297/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4554 - val_loss: 0.4607\n",
      "Epoch 298/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.4562 - val_loss: 0.4767\n",
      "Epoch 299/10000\n",
      "130/130 [==============================] - 0s 927us/step - loss: 0.4506 - val_loss: 0.4492\n",
      "Epoch 300/10000\n",
      "130/130 [==============================] - 0s 929us/step - loss: 0.4513 - val_loss: 0.4729\n",
      "Epoch 301/10000\n",
      "130/130 [==============================] - 0s 970us/step - loss: 0.4685 - val_loss: 0.4522\n",
      "Epoch 302/10000\n",
      "130/130 [==============================] - 0s 830us/step - loss: 0.4514 - val_loss: 0.4730\n",
      "Epoch 303/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4547 - val_loss: 0.4616\n",
      "Epoch 304/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.4519 - val_loss: 0.4595\n",
      "Epoch 305/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.4517 - val_loss: 0.4688\n",
      "Epoch 306/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4477 - val_loss: 0.4714\n",
      "Epoch 307/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 783us/step - loss: 0.4476 - val_loss: 0.4845\n",
      "Epoch 308/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.4474 - val_loss: 0.4588\n",
      "Epoch 309/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.4490 - val_loss: 0.4951\n",
      "Epoch 310/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.4483 - val_loss: 0.4566\n",
      "Epoch 311/10000\n",
      "130/130 [==============================] - 0s 835us/step - loss: 0.4659 - val_loss: 0.4561\n",
      "Epoch 312/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.4485 - val_loss: 0.4619\n",
      "Epoch 313/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4597 - val_loss: 0.4606\n",
      "Epoch 314/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4481 - val_loss: 0.4690\n",
      "Epoch 315/10000\n",
      "130/130 [==============================] - 0s 892us/step - loss: 0.4483 - val_loss: 0.4577\n",
      "Epoch 316/10000\n",
      "130/130 [==============================] - 0s 915us/step - loss: 0.4483 - val_loss: 0.4549\n",
      "Epoch 317/10000\n",
      "130/130 [==============================] - 0s 981us/step - loss: 0.4473 - val_loss: 0.4594\n",
      "Epoch 318/10000\n",
      "130/130 [==============================] - 0s 832us/step - loss: 0.4524 - val_loss: 0.4574\n",
      "Epoch 319/10000\n",
      "130/130 [==============================] - 0s 841us/step - loss: 0.4464 - val_loss: 0.4537\n",
      "Epoch 320/10000\n",
      "130/130 [==============================] - 0s 861us/step - loss: 0.4603 - val_loss: 0.4641\n",
      "Epoch 321/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4433 - val_loss: 0.4838\n",
      "Epoch 322/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4447 - val_loss: 0.4592\n",
      "Epoch 323/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.4469 - val_loss: 0.4579\n",
      "Epoch 324/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.4589 - val_loss: 0.4691\n",
      "Epoch 325/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4536 - val_loss: 0.4538\n",
      "Epoch 326/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.4465 - val_loss: 0.4504\n",
      "Epoch 327/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.4407 - val_loss: 0.4678\n",
      "Epoch 328/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.4412 - val_loss: 0.4488\n",
      "Epoch 329/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.4466 - val_loss: 0.4564\n",
      "Epoch 330/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.4376 - val_loss: 0.4584\n",
      "Epoch 331/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.4445 - val_loss: 0.4536\n",
      "Epoch 332/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.4383 - val_loss: 0.4627\n",
      "Epoch 333/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.4399 - val_loss: 0.4488\n",
      "Epoch 334/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.4369 - val_loss: 0.4602\n",
      "Epoch 335/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.4329 - val_loss: 0.4649\n",
      "Epoch 336/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.4440 - val_loss: 0.4563\n",
      "Epoch 337/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.4400 - val_loss: 0.4535\n",
      "Epoch 338/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.4360 - val_loss: 0.4562\n",
      "Epoch 339/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.4463 - val_loss: 0.4678\n",
      "Epoch 340/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.4383 - val_loss: 0.4562\n",
      "Epoch 341/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4375 - val_loss: 0.4578\n",
      "Epoch 342/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.4353 - val_loss: 0.4946\n",
      "Epoch 343/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4390 - val_loss: 0.4407\n",
      "Epoch 344/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4407 - val_loss: 0.4526\n",
      "Epoch 345/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.4321 - val_loss: 0.4591\n",
      "Epoch 346/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.4344 - val_loss: 0.4584\n",
      "Epoch 347/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.4362 - val_loss: 0.4587\n",
      "Epoch 348/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.4344 - val_loss: 0.4825\n",
      "Epoch 349/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.4465 - val_loss: 0.4506\n",
      "Epoch 350/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.4352 - val_loss: 0.4573\n",
      "Epoch 351/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.4315 - val_loss: 0.4667\n",
      "Epoch 352/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4335 - val_loss: 0.4626\n",
      "Epoch 353/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4352 - val_loss: 0.4510\n",
      "Epoch 354/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.4320 - val_loss: 0.4477\n",
      "Epoch 355/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4293 - val_loss: 0.4534\n",
      "Epoch 356/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4373 - val_loss: 0.4765\n",
      "Epoch 357/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.4272 - val_loss: 0.4563\n",
      "Epoch 358/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.4276 - val_loss: 0.4620\n",
      "Epoch 359/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.4314 - val_loss: 0.4463\n",
      "Epoch 360/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.4292 - val_loss: 0.4573\n",
      "Epoch 361/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.4319 - val_loss: 0.4832\n",
      "Epoch 362/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4337 - val_loss: 0.4533\n",
      "Epoch 363/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.4309 - val_loss: 0.4639\n",
      "Epoch 364/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.4276 - val_loss: 0.4497\n",
      "Epoch 365/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4300 - val_loss: 0.4503\n",
      "Epoch 366/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.4308 - val_loss: 0.4571\n",
      "Epoch 367/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.4238 - val_loss: 0.4537\n",
      "Epoch 368/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4232 - val_loss: 0.4623\n",
      "Epoch 369/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4236 - val_loss: 0.4689\n",
      "Epoch 370/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.4269 - val_loss: 0.4628\n",
      "Epoch 371/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4252 - val_loss: 0.4614\n",
      "Epoch 372/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.4251 - val_loss: 0.4659\n",
      "Epoch 373/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.4263 - val_loss: 0.4575\n",
      "Epoch 374/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.4255 - val_loss: 0.4671\n",
      "Epoch 375/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.4290 - val_loss: 0.4603\n",
      "Epoch 376/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.4327 - val_loss: 0.4526\n",
      "Epoch 377/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.4247 - val_loss: 0.4567\n",
      "Epoch 378/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.4185 - val_loss: 0.4483\n",
      "Epoch 379/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.4193 - val_loss: 0.4594\n",
      "Epoch 380/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.4183 - val_loss: 0.4677\n",
      "Epoch 381/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.4229 - val_loss: 0.4530\n",
      "Epoch 382/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.4181 - val_loss: 0.4556\n",
      "Epoch 383/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.4242 - val_loss: 0.4587\n",
      "Epoch 384/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.4263 - val_loss: 0.4411\n",
      "Epoch 385/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.4252 - val_loss: 0.4623\n",
      "Epoch 386/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.4174 - val_loss: 0.4578\n",
      "Epoch 387/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.4240 - val_loss: 0.4559\n",
      "Epoch 388/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.4213 - val_loss: 0.5165\n",
      "Epoch 389/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4191 - val_loss: 0.4653\n",
      "Epoch 390/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4185 - val_loss: 0.4560\n",
      "Epoch 391/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.4146 - val_loss: 0.4508\n",
      "Epoch 392/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4153 - val_loss: 0.4923\n",
      "Epoch 393/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.4216 - val_loss: 0.4711\n",
      "Epoch 394/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.4193 - val_loss: 0.4736\n",
      "Epoch 395/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.4139 - val_loss: 0.4583\n",
      "Epoch 396/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.4109 - val_loss: 0.4574\n",
      "Epoch 397/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.4119 - val_loss: 0.4578\n",
      "Epoch 398/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.4143 - val_loss: 0.4449\n",
      "Epoch 399/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.4118 - val_loss: 0.4506\n",
      "Epoch 400/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.4121 - val_loss: 0.4509\n",
      "Epoch 401/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.4246 - val_loss: 0.4833\n",
      "Epoch 402/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4140 - val_loss: 0.4850\n",
      "Epoch 403/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.4133 - val_loss: 0.4476\n",
      "Epoch 404/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.4060 - val_loss: 0.4578\n",
      "Epoch 405/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.4068 - val_loss: 0.4536\n",
      "Epoch 406/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4077 - val_loss: 0.4660\n",
      "Epoch 407/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.4154 - val_loss: 0.4603\n",
      "Epoch 408/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.4102 - val_loss: 0.4727\n",
      "Epoch 409/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.4121 - val_loss: 0.4673\n",
      "Epoch 410/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4152 - val_loss: 0.4488\n",
      "Epoch 411/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.4079 - val_loss: 0.4811\n",
      "Epoch 412/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.4058 - val_loss: 0.4507\n",
      "Epoch 413/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.4039 - val_loss: 0.4435\n",
      "Epoch 414/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.4042 - val_loss: 0.4681\n",
      "Epoch 415/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.4024 - val_loss: 0.4471\n",
      "Epoch 416/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.4032 - val_loss: 0.4564\n",
      "Epoch 417/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.4141 - val_loss: 0.4454\n",
      "Epoch 418/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4017 - val_loss: 0.4535\n",
      "Epoch 419/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.4074 - val_loss: 0.4535\n",
      "Epoch 420/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3997 - val_loss: 0.4627\n",
      "Epoch 421/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.3998 - val_loss: 0.4598\n",
      "Epoch 422/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.4048 - val_loss: 0.4840\n",
      "Epoch 423/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.4017 - val_loss: 0.5119\n",
      "Epoch 424/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.4038 - val_loss: 0.4444\n",
      "Epoch 425/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.4012 - val_loss: 0.4557\n",
      "Epoch 426/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.4037 - val_loss: 0.4432\n",
      "Epoch 427/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3953 - val_loss: 0.4507\n",
      "Epoch 428/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.4011 - val_loss: 0.4569\n",
      "Epoch 429/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.4031 - val_loss: 0.4584\n",
      "Epoch 430/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.4082 - val_loss: 0.4497\n",
      "Epoch 431/10000\n",
      "130/130 [==============================] - 0s 796us/step - loss: 0.3985 - val_loss: 0.4458\n",
      "Epoch 432/10000\n",
      "130/130 [==============================] - 0s 935us/step - loss: 0.4008 - val_loss: 0.4463\n",
      "Epoch 433/10000\n",
      "130/130 [==============================] - 0s 847us/step - loss: 0.3997 - val_loss: 0.4957\n",
      "Epoch 434/10000\n",
      "130/130 [==============================] - 0s 864us/step - loss: 0.4000 - val_loss: 0.4673\n",
      "Epoch 435/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.4027 - val_loss: 0.4503\n",
      "Epoch 436/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.3945 - val_loss: 0.4779\n",
      "Epoch 437/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.4043 - val_loss: 0.5266\n",
      "Epoch 438/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.3957 - val_loss: 0.4526\n",
      "Epoch 439/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3971 - val_loss: 0.4598\n",
      "Epoch 440/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.3944 - val_loss: 0.4552\n",
      "Epoch 441/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.3913 - val_loss: 0.4548\n",
      "Epoch 442/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.3915 - val_loss: 0.4577\n",
      "Epoch 443/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3882 - val_loss: 0.4705\n",
      "Epoch 444/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.4083 - val_loss: 0.4661\n",
      "Epoch 445/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.4046 - val_loss: 0.4812\n",
      "Epoch 446/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3888 - val_loss: 0.4582\n",
      "Epoch 447/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.3930 - val_loss: 0.4662\n",
      "Epoch 448/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3922 - val_loss: 0.4598\n",
      "Epoch 449/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.3862 - val_loss: 0.4523\n",
      "Epoch 450/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.3851 - val_loss: 0.5073\n",
      "Epoch 451/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.3974 - val_loss: 0.4695\n",
      "Epoch 452/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3863 - val_loss: 0.4649\n",
      "Epoch 453/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.3940 - val_loss: 0.4752\n",
      "Epoch 454/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.3846 - val_loss: 0.4614\n",
      "Epoch 455/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.3914 - val_loss: 0.4727\n",
      "Epoch 456/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3846 - val_loss: 0.4822\n",
      "Epoch 457/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.3937 - val_loss: 0.4567\n",
      "Epoch 458/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.3867 - val_loss: 0.4550\n",
      "Epoch 459/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 733us/step - loss: 0.3889 - val_loss: 0.4543\n",
      "Epoch 460/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3805 - val_loss: 0.4766\n",
      "Epoch 461/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3978 - val_loss: 0.4573\n",
      "Epoch 462/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3862 - val_loss: 0.4479\n",
      "Epoch 463/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.3852 - val_loss: 0.4654\n",
      "Epoch 464/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3878 - val_loss: 0.5184\n",
      "Epoch 465/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3833 - val_loss: 0.4565\n",
      "Epoch 466/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3970 - val_loss: 0.4924\n",
      "Epoch 467/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.3912 - val_loss: 0.4665\n",
      "Epoch 468/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3852 - val_loss: 0.4573\n",
      "Epoch 469/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3787 - val_loss: 0.4545\n",
      "Epoch 470/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.3872 - val_loss: 0.4646\n",
      "Epoch 471/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3830 - val_loss: 0.4688\n",
      "Epoch 472/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3841 - val_loss: 0.4822\n",
      "Epoch 473/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.3783 - val_loss: 0.4677\n",
      "Epoch 474/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3769 - val_loss: 0.4579\n",
      "Epoch 475/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3716 - val_loss: 0.4741\n",
      "Epoch 476/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3755 - val_loss: 0.5097\n",
      "Epoch 477/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3800 - val_loss: 0.4557\n",
      "Epoch 478/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3768 - val_loss: 0.4684\n",
      "Epoch 479/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.3747 - val_loss: 0.4726\n",
      "Epoch 480/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3741 - val_loss: 0.4787\n",
      "Epoch 481/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.3767 - val_loss: 0.4710\n",
      "Epoch 482/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3742 - val_loss: 0.4697\n",
      "Epoch 483/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.3807 - val_loss: 0.4761\n",
      "Epoch 484/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.3827 - val_loss: 0.4523\n",
      "Epoch 485/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3680 - val_loss: 0.4498\n",
      "Epoch 486/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3797 - val_loss: 0.4646\n",
      "Epoch 487/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.3702 - val_loss: 0.4701\n",
      "Epoch 488/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.3912 - val_loss: 0.4690\n",
      "Epoch 489/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.3696 - val_loss: 0.4607\n",
      "Epoch 490/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3692 - val_loss: 0.4643\n",
      "Epoch 491/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3660 - val_loss: 0.4679\n",
      "Epoch 492/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.3686 - val_loss: 0.4702\n",
      "Epoch 493/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.3725 - val_loss: 0.4856\n",
      "Epoch 494/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3697 - val_loss: 0.4728\n",
      "Epoch 495/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.3687 - val_loss: 0.4860\n",
      "Epoch 496/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3725 - val_loss: 0.4757\n",
      "Epoch 497/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3705 - val_loss: 0.4972\n",
      "Epoch 498/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3613 - val_loss: 0.4687\n",
      "Epoch 499/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3691 - val_loss: 0.4821\n",
      "Epoch 500/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3622 - val_loss: 0.4965\n",
      "Epoch 501/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.3666 - val_loss: 0.4698\n",
      "Epoch 502/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.3705 - val_loss: 0.4806\n",
      "Epoch 503/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.3770 - val_loss: 0.4615\n",
      "Epoch 504/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.3625 - val_loss: 0.4688\n",
      "Epoch 505/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3751 - val_loss: 0.4672\n",
      "Epoch 506/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.3629 - val_loss: 0.4640\n",
      "Epoch 507/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.3651 - val_loss: 0.4713\n",
      "Epoch 508/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3772 - val_loss: 0.4766\n",
      "Epoch 509/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3680 - val_loss: 0.4830\n",
      "Epoch 510/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3575 - val_loss: 0.4892\n",
      "Epoch 511/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3567 - val_loss: 0.4645\n",
      "Epoch 512/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3641 - val_loss: 0.4865\n",
      "Epoch 513/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3565 - val_loss: 0.4664\n",
      "Epoch 514/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3594 - val_loss: 0.4668\n",
      "Epoch 515/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.3683 - val_loss: 0.4685\n",
      "Epoch 516/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3646 - val_loss: 0.4590\n",
      "Epoch 517/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3584 - val_loss: 0.4791\n",
      "Epoch 518/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3640 - val_loss: 0.4842\n",
      "Epoch 519/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3598 - val_loss: 0.4811\n",
      "Epoch 520/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.3582 - val_loss: 0.4755\n",
      "Epoch 521/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.3653 - val_loss: 0.4688\n",
      "Epoch 522/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3614 - val_loss: 0.4968\n",
      "Epoch 523/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3676 - val_loss: 0.4789\n",
      "Epoch 524/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3523 - val_loss: 0.4735\n",
      "Epoch 525/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3540 - val_loss: 0.4730\n",
      "Epoch 526/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.3630 - val_loss: 0.4726\n",
      "Epoch 527/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3600 - val_loss: 0.4721\n",
      "Epoch 528/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.3586 - val_loss: 0.4717\n",
      "Epoch 529/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3503 - val_loss: 0.4752\n",
      "Epoch 530/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3493 - val_loss: 0.4737\n",
      "Epoch 531/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3576 - val_loss: 0.4735\n",
      "Epoch 532/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3501 - val_loss: 0.4739\n",
      "Epoch 533/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3562 - val_loss: 0.4713\n",
      "Epoch 534/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3580 - val_loss: 0.4866\n",
      "Epoch 535/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3580 - val_loss: 0.4627\n",
      "Epoch 536/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3491 - val_loss: 0.4615\n",
      "Epoch 537/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3605 - val_loss: 0.4602\n",
      "Epoch 538/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.3614 - val_loss: 0.4741\n",
      "Epoch 539/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3462 - val_loss: 0.4567\n",
      "Epoch 540/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3451 - val_loss: 0.4847\n",
      "Epoch 541/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3541 - val_loss: 0.4615\n",
      "Epoch 542/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3575 - val_loss: 0.4640\n",
      "Epoch 543/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3493 - val_loss: 0.4792\n",
      "Epoch 544/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3396 - val_loss: 0.4634\n",
      "Epoch 545/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3571 - val_loss: 0.4732\n",
      "Epoch 546/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3415 - val_loss: 0.4652\n",
      "Epoch 547/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3501 - val_loss: 0.4883\n",
      "Epoch 548/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3478 - val_loss: 0.4645\n",
      "Epoch 549/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.3461 - val_loss: 0.4703\n",
      "Epoch 550/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3481 - val_loss: 0.4729\n",
      "Epoch 551/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.3423 - val_loss: 0.4770\n",
      "Epoch 552/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3511 - val_loss: 0.4715\n",
      "Epoch 553/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3553 - val_loss: 0.4652\n",
      "Epoch 554/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3436 - val_loss: 0.5088\n",
      "Epoch 555/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.3465 - val_loss: 0.4634\n",
      "Epoch 556/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3418 - val_loss: 0.5365\n",
      "Epoch 557/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.3562 - val_loss: 0.4734\n",
      "Epoch 558/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3390 - val_loss: 0.4730\n",
      "Epoch 559/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3543 - val_loss: 0.4655\n",
      "Epoch 560/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3483 - val_loss: 0.4660\n",
      "Epoch 561/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3411 - val_loss: 0.4722\n",
      "Epoch 562/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3445 - val_loss: 0.4839\n",
      "Epoch 563/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.3370 - val_loss: 0.4781\n",
      "Epoch 564/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3463 - val_loss: 0.4681\n",
      "Epoch 565/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3365 - val_loss: 0.4806\n",
      "Epoch 566/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3606 - val_loss: 0.4974\n",
      "Epoch 567/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3418 - val_loss: 0.4852\n",
      "Epoch 568/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3373 - val_loss: 0.4592\n",
      "Epoch 569/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3390 - val_loss: 0.4690\n",
      "Epoch 570/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3425 - val_loss: 0.4734\n",
      "Epoch 571/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3431 - val_loss: 0.4837\n",
      "Epoch 572/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3412 - val_loss: 0.4681\n",
      "Epoch 573/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3519 - val_loss: 0.4735\n",
      "Epoch 574/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3334 - val_loss: 0.4852\n",
      "Epoch 575/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3372 - val_loss: 0.4912\n",
      "Epoch 576/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3296 - val_loss: 0.4769\n",
      "Epoch 577/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3341 - val_loss: 0.4939\n",
      "Epoch 578/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3411 - val_loss: 0.4851\n",
      "Epoch 579/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3390 - val_loss: 0.4827\n",
      "Epoch 580/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3322 - val_loss: 0.4699\n",
      "Epoch 581/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3302 - val_loss: 0.4833\n",
      "Epoch 582/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.3431 - val_loss: 0.4836\n",
      "Epoch 583/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3352 - val_loss: 0.4607\n",
      "Epoch 584/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.3359 - val_loss: 0.4973\n",
      "Epoch 585/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.3344 - val_loss: 0.4859\n",
      "Epoch 586/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.3317 - val_loss: 0.4943\n",
      "Epoch 587/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3396 - val_loss: 0.4667\n",
      "Epoch 588/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3349 - val_loss: 0.5171\n",
      "Epoch 589/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.3350 - val_loss: 0.4834\n",
      "Epoch 590/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.3296 - val_loss: 0.4692\n",
      "Epoch 591/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.3333 - val_loss: 0.4721\n",
      "Epoch 592/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.3250 - val_loss: 0.4788\n",
      "Epoch 593/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.3302 - val_loss: 0.4760\n",
      "Epoch 594/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3285 - val_loss: 0.4814\n",
      "Epoch 595/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3328 - val_loss: 0.4824\n",
      "Epoch 596/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3312 - val_loss: 0.4947\n",
      "Epoch 597/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3210 - val_loss: 0.4951\n",
      "Epoch 598/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3275 - val_loss: 0.4946\n",
      "Epoch 599/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3336 - val_loss: 0.4833\n",
      "Epoch 600/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3283 - val_loss: 0.4948\n",
      "Epoch 601/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3386 - val_loss: 0.4815\n",
      "Epoch 602/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3238 - val_loss: 0.4882\n",
      "Epoch 603/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3210 - val_loss: 0.4780\n",
      "Epoch 604/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3167 - val_loss: 0.4984\n",
      "Epoch 605/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3228 - val_loss: 0.5037\n",
      "Epoch 606/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3302 - val_loss: 0.4675\n",
      "Epoch 607/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3220 - val_loss: 0.4747\n",
      "Epoch 608/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3325 - val_loss: 0.4818\n",
      "Epoch 609/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3151 - val_loss: 0.4837\n",
      "Epoch 610/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3232 - val_loss: 0.4895\n",
      "Epoch 611/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 726us/step - loss: 0.3315 - val_loss: 0.4940\n",
      "Epoch 612/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3334 - val_loss: 0.4836\n",
      "Epoch 613/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.3219 - val_loss: 0.4875\n",
      "Epoch 614/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.3189 - val_loss: 0.4963\n",
      "Epoch 615/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3195 - val_loss: 0.4909\n",
      "Epoch 616/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3252 - val_loss: 0.4655\n",
      "Epoch 617/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3215 - val_loss: 0.4813\n",
      "Epoch 618/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3233 - val_loss: 0.4887\n",
      "Epoch 619/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3149 - val_loss: 0.4834\n",
      "Epoch 620/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3228 - val_loss: 0.4972\n",
      "Epoch 621/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3243 - val_loss: 0.4716\n",
      "Epoch 622/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3145 - val_loss: 0.5111\n",
      "Epoch 623/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3111 - val_loss: 0.4800\n",
      "Epoch 624/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3127 - val_loss: 0.4661\n",
      "Epoch 625/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3506 - val_loss: 0.5006\n",
      "Epoch 626/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3145 - val_loss: 0.4666\n",
      "Epoch 627/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3161 - val_loss: 0.4763\n",
      "Epoch 628/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.3281 - val_loss: 0.4872\n",
      "Epoch 629/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3146 - val_loss: 0.4830\n",
      "Epoch 630/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.3145 - val_loss: 0.5107\n",
      "Epoch 631/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.3202 - val_loss: 0.4909\n",
      "Epoch 632/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.3133 - val_loss: 0.4752\n",
      "Epoch 633/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.3194 - val_loss: 0.4945\n",
      "Epoch 634/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.3192 - val_loss: 0.4865\n",
      "Epoch 635/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.3152 - val_loss: 0.4975\n",
      "Epoch 636/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3112 - val_loss: 0.4942\n",
      "Epoch 637/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3161 - val_loss: 0.4825\n",
      "Epoch 638/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3069 - val_loss: 0.4787\n",
      "Epoch 639/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3229 - val_loss: 0.4771\n",
      "Epoch 640/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3034 - val_loss: 0.4839\n",
      "Epoch 641/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3061 - val_loss: 0.5247\n",
      "Epoch 642/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3147 - val_loss: 0.4815\n",
      "Epoch 643/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3147 - val_loss: 0.4980\n",
      "Epoch 644/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3041 - val_loss: 0.4850\n",
      "Epoch 645/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3037 - val_loss: 0.4935\n",
      "Epoch 646/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.3101 - val_loss: 0.5209\n",
      "Epoch 647/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.3140 - val_loss: 0.4838\n",
      "Epoch 648/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.3174 - val_loss: 0.4714\n",
      "Epoch 649/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.3134 - val_loss: 0.5059\n",
      "Epoch 650/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3033 - val_loss: 0.4794\n",
      "Epoch 651/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3102 - val_loss: 0.4783\n",
      "Epoch 652/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.3116 - val_loss: 0.4900\n",
      "Epoch 653/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.2985 - val_loss: 0.4855\n",
      "Epoch 654/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3151 - val_loss: 0.4868\n",
      "Epoch 655/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3040 - val_loss: 0.4926\n",
      "Epoch 656/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.3140 - val_loss: 0.4971\n",
      "Epoch 657/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.3070 - val_loss: 0.4758\n",
      "Epoch 658/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.3067 - val_loss: 0.5338\n",
      "Epoch 659/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3082 - val_loss: 0.4981\n",
      "Epoch 660/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2998 - val_loss: 0.4933\n",
      "Epoch 661/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.3079 - val_loss: 0.4793\n",
      "Epoch 662/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2977 - val_loss: 0.4939\n",
      "Epoch 663/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.3082 - val_loss: 0.5043\n",
      "Epoch 664/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3050 - val_loss: 0.4965\n",
      "Epoch 665/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.3037 - val_loss: 0.4863\n",
      "Epoch 666/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.3047 - val_loss: 0.5174\n",
      "Epoch 667/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.3059 - val_loss: 0.4621\n",
      "Epoch 668/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2999 - val_loss: 0.4803\n",
      "Epoch 669/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.3228 - val_loss: 0.4931\n",
      "Epoch 670/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.3141 - val_loss: 0.4919\n",
      "Epoch 671/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.3081 - val_loss: 0.4946\n",
      "Epoch 672/10000\n",
      "130/130 [==============================] - 0s 975us/step - loss: 0.3038 - val_loss: 0.4932\n",
      "Epoch 673/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.3041 - val_loss: 0.5275\n",
      "Epoch 674/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.3035 - val_loss: 0.5080\n",
      "Epoch 675/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.2967 - val_loss: 0.4870\n",
      "Epoch 676/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2971 - val_loss: 0.4800\n",
      "Epoch 677/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3006 - val_loss: 0.4840\n",
      "Epoch 678/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2954 - val_loss: 0.4915\n",
      "Epoch 679/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.3004 - val_loss: 0.4844\n",
      "Epoch 680/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.2925 - val_loss: 0.4788\n",
      "Epoch 681/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.2997 - val_loss: 0.4984\n",
      "Epoch 682/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.3146 - val_loss: 0.5030\n",
      "Epoch 683/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3053 - val_loss: 0.4956\n",
      "Epoch 684/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2908 - val_loss: 0.5047\n",
      "Epoch 685/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.3024 - val_loss: 0.4915\n",
      "Epoch 686/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2991 - val_loss: 0.5091\n",
      "Epoch 687/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.3131 - val_loss: 0.4969\n",
      "Epoch 688/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3044 - val_loss: 0.4931\n",
      "Epoch 689/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2946 - val_loss: 0.4877\n",
      "Epoch 690/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2984 - val_loss: 0.4729\n",
      "Epoch 691/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2954 - val_loss: 0.4850\n",
      "Epoch 692/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2927 - val_loss: 0.4855\n",
      "Epoch 693/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2905 - val_loss: 0.4891\n",
      "Epoch 694/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2886 - val_loss: 0.4806\n",
      "Epoch 695/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2963 - val_loss: 0.4781\n",
      "Epoch 696/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2866 - val_loss: 0.5121\n",
      "Epoch 697/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2925 - val_loss: 0.5478\n",
      "Epoch 698/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.3063 - val_loss: 0.5078\n",
      "Epoch 699/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.2977 - val_loss: 0.5086\n",
      "Epoch 700/10000\n",
      "130/130 [==============================] - 0s 826us/step - loss: 0.2862 - val_loss: 0.5226\n",
      "Epoch 701/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.2890 - val_loss: 0.4816\n",
      "Epoch 702/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.2965 - val_loss: 0.4880\n",
      "Epoch 703/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.4977\n",
      "Epoch 704/10000\n",
      "130/130 [==============================] - 0s 905us/step - loss: 0.2943 - val_loss: 0.4892\n",
      "Epoch 705/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.2934 - val_loss: 0.4836\n",
      "Epoch 706/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.3016 - val_loss: 0.4874\n",
      "Epoch 707/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.3000 - val_loss: 0.4868\n",
      "Epoch 708/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2968 - val_loss: 0.4805\n",
      "Epoch 709/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.2858 - val_loss: 0.4867\n",
      "Epoch 710/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.2830 - val_loss: 0.4965\n",
      "Epoch 711/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2933 - val_loss: 0.5232\n",
      "Epoch 712/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2899 - val_loss: 0.4921\n",
      "Epoch 713/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.2939 - val_loss: 0.5015\n",
      "Epoch 714/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2870 - val_loss: 0.4870\n",
      "Epoch 715/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2772 - val_loss: 0.4998\n",
      "Epoch 716/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.2900 - val_loss: 0.4911\n",
      "Epoch 717/10000\n",
      "130/130 [==============================] - 0s 864us/step - loss: 0.2879 - val_loss: 0.4781\n",
      "Epoch 718/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.2869 - val_loss: 0.5028\n",
      "Epoch 719/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.2935 - val_loss: 0.4961\n",
      "Epoch 720/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2941 - val_loss: 0.5255\n",
      "Epoch 721/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.2890 - val_loss: 0.4931\n",
      "Epoch 722/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2842 - val_loss: 0.4942\n",
      "Epoch 723/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2901 - val_loss: 0.5261\n",
      "Epoch 724/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2921 - val_loss: 0.5036\n",
      "Epoch 725/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2971 - val_loss: 0.4810\n",
      "Epoch 726/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2887 - val_loss: 0.4911\n",
      "Epoch 727/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2860 - val_loss: 0.4893\n",
      "Epoch 728/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2803 - val_loss: 0.4892\n",
      "Epoch 729/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2859 - val_loss: 0.4932\n",
      "Epoch 730/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2817 - val_loss: 0.5078\n",
      "Epoch 731/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2836 - val_loss: 0.4996\n",
      "Epoch 732/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2811 - val_loss: 0.4903\n",
      "Epoch 733/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2822 - val_loss: 0.4958\n",
      "Epoch 734/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2842 - val_loss: 0.5014\n",
      "Epoch 735/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.2782 - val_loss: 0.5217\n",
      "Epoch 736/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2953 - val_loss: 0.4886\n",
      "Epoch 737/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.2763 - val_loss: 0.5354\n",
      "Epoch 738/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2980 - val_loss: 0.4989\n",
      "Epoch 739/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2869 - val_loss: 0.4892\n",
      "Epoch 740/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2805 - val_loss: 0.5001\n",
      "Epoch 741/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2726 - val_loss: 0.5121\n",
      "Epoch 742/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2795 - val_loss: 0.5023\n",
      "Epoch 743/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2851 - val_loss: 0.5143\n",
      "Epoch 744/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.2758 - val_loss: 0.5031\n",
      "Epoch 745/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2762 - val_loss: 0.4891\n",
      "Epoch 746/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2738 - val_loss: 0.4935\n",
      "Epoch 747/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.2902 - val_loss: 0.5024\n",
      "Epoch 748/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2800 - val_loss: 0.5030\n",
      "Epoch 749/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2833 - val_loss: 0.5109\n",
      "Epoch 750/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2764 - val_loss: 0.4997\n",
      "Epoch 751/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2759 - val_loss: 0.5018\n",
      "Epoch 752/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2831 - val_loss: 0.4918\n",
      "Epoch 753/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2770 - val_loss: 0.4867\n",
      "Epoch 754/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2754 - val_loss: 0.4974\n",
      "Epoch 755/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2742 - val_loss: 0.4875\n",
      "Epoch 756/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2842 - val_loss: 0.5323\n",
      "Epoch 757/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2816 - val_loss: 0.5476\n",
      "Epoch 758/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2810 - val_loss: 0.5121\n",
      "Epoch 759/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.2726 - val_loss: 0.5001\n",
      "Epoch 760/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2851 - val_loss: 0.5248\n",
      "Epoch 761/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2834 - val_loss: 0.5245\n",
      "Epoch 762/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2779 - val_loss: 0.5114\n",
      "Epoch 763/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 725us/step - loss: 0.2781 - val_loss: 0.5116\n",
      "Epoch 764/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2832 - val_loss: 0.4860\n",
      "Epoch 765/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2681 - val_loss: 0.4949\n",
      "Epoch 766/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2784 - val_loss: 0.5230\n",
      "Epoch 767/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.2706 - val_loss: 0.5157\n",
      "Epoch 768/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2837 - val_loss: 0.5255\n",
      "Epoch 769/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2749 - val_loss: 0.5089\n",
      "Epoch 770/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2770 - val_loss: 0.5017\n",
      "Epoch 771/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2916 - val_loss: 0.5199\n",
      "Epoch 772/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2732 - val_loss: 0.5022\n",
      "Epoch 773/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2660 - val_loss: 0.5365\n",
      "Epoch 774/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2785 - val_loss: 0.5138\n",
      "Epoch 775/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2864 - val_loss: 0.5085\n",
      "Epoch 776/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.2722 - val_loss: 0.5278\n",
      "Epoch 777/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2726 - val_loss: 0.5082\n",
      "Epoch 778/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2648 - val_loss: 0.5236\n",
      "Epoch 779/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2699 - val_loss: 0.5153\n",
      "Epoch 780/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.2701 - val_loss: 0.4961\n",
      "Epoch 781/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2677 - val_loss: 0.5139\n",
      "Epoch 782/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2681 - val_loss: 0.5106\n",
      "Epoch 783/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.2724 - val_loss: 0.4865\n",
      "Epoch 784/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2685 - val_loss: 0.5160\n",
      "Epoch 785/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2738 - val_loss: 0.5231\n",
      "Epoch 786/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2732 - val_loss: 0.5033\n",
      "Epoch 787/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2700 - val_loss: 0.5007\n",
      "Epoch 788/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2677 - val_loss: 0.4964\n",
      "Epoch 789/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2758 - val_loss: 0.5568\n",
      "Epoch 790/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2777 - val_loss: 0.5044\n",
      "Epoch 791/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2667 - val_loss: 0.5395\n",
      "Epoch 792/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2589 - val_loss: 0.5018\n",
      "Epoch 793/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2637 - val_loss: 0.5278\n",
      "Epoch 794/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2677 - val_loss: 0.4944\n",
      "Epoch 795/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.2635 - val_loss: 0.4998\n",
      "Epoch 796/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.2624 - val_loss: 0.5044\n",
      "Epoch 797/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2698 - val_loss: 0.4919\n",
      "Epoch 798/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2685 - val_loss: 0.4989\n",
      "Epoch 799/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2596 - val_loss: 0.5095\n",
      "Epoch 800/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2652 - val_loss: 0.5091\n",
      "Epoch 801/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2644 - val_loss: 0.5241\n",
      "Epoch 802/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2638 - val_loss: 0.4998\n",
      "Epoch 803/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.2592 - val_loss: 0.5093\n",
      "Epoch 804/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2656 - val_loss: 0.5160\n",
      "Epoch 805/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2635 - val_loss: 0.5107\n",
      "Epoch 806/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2689 - val_loss: 0.5038\n",
      "Epoch 807/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.2659 - val_loss: 0.5131\n",
      "Epoch 808/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.2634 - val_loss: 0.5053\n",
      "Epoch 809/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.2575 - val_loss: 0.5129\n",
      "Epoch 810/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2631 - val_loss: 0.5439\n",
      "Epoch 811/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.2598 - val_loss: 0.5057\n",
      "Epoch 812/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2626 - val_loss: 0.5093\n",
      "Epoch 813/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.2545 - val_loss: 0.5164\n",
      "Epoch 814/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2687 - val_loss: 0.5170\n",
      "Epoch 815/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.2665 - val_loss: 0.5041\n",
      "Epoch 816/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2709 - val_loss: 0.5059\n",
      "Epoch 817/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2560 - val_loss: 0.5031\n",
      "Epoch 818/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2563 - val_loss: 0.5167\n",
      "Epoch 819/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2628 - val_loss: 0.5211\n",
      "Epoch 820/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.2570 - val_loss: 0.5183\n",
      "Epoch 821/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.2595 - val_loss: 0.5197\n",
      "Epoch 822/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2562 - val_loss: 0.5111\n",
      "Epoch 823/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2555 - val_loss: 0.5296\n",
      "Epoch 824/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2588 - val_loss: 0.5135\n",
      "Epoch 825/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2595 - val_loss: 0.5080\n",
      "Epoch 826/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2577 - val_loss: 0.5033\n",
      "Epoch 827/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2717 - val_loss: 0.5361\n",
      "Epoch 828/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2527 - val_loss: 0.5272\n",
      "Epoch 829/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.2572 - val_loss: 0.5079\n",
      "Epoch 830/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2559 - val_loss: 0.5163\n",
      "Epoch 831/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2595 - val_loss: 0.5133\n",
      "Epoch 832/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2553 - val_loss: 0.5316\n",
      "Epoch 833/10000\n",
      "130/130 [==============================] - 0s 978us/step - loss: 0.2497 - val_loss: 0.5185\n",
      "Epoch 834/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.2565 - val_loss: 0.5073\n",
      "Epoch 835/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.2602 - val_loss: 0.5122\n",
      "Epoch 836/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2474 - val_loss: 0.5034\n",
      "Epoch 837/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2602 - val_loss: 0.5034\n",
      "Epoch 838/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2576 - val_loss: 0.5248\n",
      "Epoch 839/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2542 - val_loss: 0.5204\n",
      "Epoch 840/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2575 - val_loss: 0.5088\n",
      "Epoch 841/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2551 - val_loss: 0.5296\n",
      "Epoch 842/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.2634 - val_loss: 0.5605\n",
      "Epoch 843/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.2600 - val_loss: 0.5090\n",
      "Epoch 844/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2581 - val_loss: 0.5583\n",
      "Epoch 845/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2549 - val_loss: 0.5193\n",
      "Epoch 846/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2545 - val_loss: 0.5199\n",
      "Epoch 847/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2580 - val_loss: 0.5312\n",
      "Epoch 848/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2589 - val_loss: 0.5043\n",
      "Epoch 849/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2516 - val_loss: 0.5322\n",
      "Epoch 850/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2650 - val_loss: 0.4871\n",
      "Epoch 851/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2417 - val_loss: 0.4992\n",
      "Epoch 852/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2515 - val_loss: 0.4969\n",
      "Epoch 853/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2608 - val_loss: 0.5097\n",
      "Epoch 854/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2562 - val_loss: 0.5373\n",
      "Epoch 855/10000\n",
      "130/130 [==============================] - 0s 907us/step - loss: 0.2542 - val_loss: 0.5065\n",
      "Epoch 856/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.2526 - val_loss: 0.5107\n",
      "Epoch 857/10000\n",
      "130/130 [==============================] - 0s 881us/step - loss: 0.2485 - val_loss: 0.5154\n",
      "Epoch 858/10000\n",
      "130/130 [==============================] - 0s 908us/step - loss: 0.2424 - val_loss: 0.5262\n",
      "Epoch 859/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.2506 - val_loss: 0.5174\n",
      "Epoch 860/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.2521 - val_loss: 0.5450\n",
      "Epoch 861/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2523 - val_loss: 0.5414\n",
      "Epoch 862/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2646 - val_loss: 0.5116\n",
      "Epoch 863/10000\n",
      "130/130 [==============================] - 0s 852us/step - loss: 0.2421 - val_loss: 0.5072\n",
      "Epoch 864/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.2409 - val_loss: 0.5506\n",
      "Epoch 865/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.2425 - val_loss: 0.5238\n",
      "Epoch 866/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.2504 - val_loss: 0.5250\n",
      "Epoch 867/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.2464 - val_loss: 0.5101\n",
      "Epoch 868/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2431 - val_loss: 0.5220\n",
      "Epoch 869/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2499 - val_loss: 0.5179\n",
      "Epoch 870/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.2433 - val_loss: 0.5273\n",
      "Epoch 871/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.2568 - val_loss: 0.5045\n",
      "Epoch 872/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2484 - val_loss: 0.5035\n",
      "Epoch 873/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2424 - val_loss: 0.5131\n",
      "Epoch 874/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.2433 - val_loss: 0.5171\n",
      "Epoch 875/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.2393 - val_loss: 0.4928\n",
      "Epoch 876/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2454 - val_loss: 0.5180\n",
      "Epoch 877/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2448 - val_loss: 0.5298\n",
      "Epoch 878/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2424 - val_loss: 0.5341\n",
      "Epoch 879/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2521 - val_loss: 0.5462\n",
      "Epoch 880/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.2515 - val_loss: 0.5346\n",
      "Epoch 881/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2388 - val_loss: 0.4995\n",
      "Epoch 882/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2422 - val_loss: 0.5281\n",
      "Epoch 883/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2446 - val_loss: 0.5208\n",
      "Epoch 884/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2374 - val_loss: 0.5350\n",
      "Epoch 885/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2552 - val_loss: 0.5050\n",
      "Epoch 886/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2469 - val_loss: 0.5249\n",
      "Epoch 887/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.2508 - val_loss: 0.5133\n",
      "Epoch 888/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2418 - val_loss: 0.5044\n",
      "Epoch 889/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2412 - val_loss: 0.5276\n",
      "Epoch 890/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2543 - val_loss: 0.5123\n",
      "Epoch 891/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.2379 - val_loss: 0.5293\n",
      "Epoch 892/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2376 - val_loss: 0.5254\n",
      "Epoch 893/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2383 - val_loss: 0.5167\n",
      "Epoch 894/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2430 - val_loss: 0.5548\n",
      "Epoch 895/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.2414 - val_loss: 0.5207\n",
      "Epoch 896/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2351 - val_loss: 0.5308\n",
      "Epoch 897/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2512 - val_loss: 0.4970\n",
      "Epoch 898/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2387 - val_loss: 0.5165\n",
      "Epoch 899/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2415 - val_loss: 0.5424\n",
      "Epoch 900/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2540 - val_loss: 0.5306\n",
      "Epoch 901/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.2382 - val_loss: 0.5229\n",
      "Epoch 902/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2418 - val_loss: 0.5172\n",
      "Epoch 903/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2367 - val_loss: 0.5808\n",
      "Epoch 904/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2388 - val_loss: 0.5351\n",
      "Epoch 905/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2338 - val_loss: 0.5220\n",
      "Epoch 906/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2402 - val_loss: 0.5607\n",
      "Epoch 907/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2389 - val_loss: 0.5384\n",
      "Epoch 908/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2320 - val_loss: 0.5115\n",
      "Epoch 909/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.2392 - val_loss: 0.5330\n",
      "Epoch 910/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2373 - val_loss: 0.5130\n",
      "Epoch 911/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.2448 - val_loss: 0.5453\n",
      "Epoch 912/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.2287 - val_loss: 0.5248\n",
      "Epoch 913/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2286 - val_loss: 0.5286\n",
      "Epoch 914/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2360 - val_loss: 0.5286\n",
      "Epoch 915/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 737us/step - loss: 0.2336 - val_loss: 0.5345\n",
      "Epoch 916/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.2310 - val_loss: 0.5525\n",
      "Epoch 917/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2434 - val_loss: 0.5779\n",
      "Epoch 918/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2472 - val_loss: 0.5087\n",
      "Epoch 919/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2267 - val_loss: 0.5184\n",
      "Epoch 920/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2334 - val_loss: 0.5459\n",
      "Epoch 921/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2308 - val_loss: 0.5302\n",
      "Epoch 922/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2311 - val_loss: 0.5304\n",
      "Epoch 923/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2372 - val_loss: 0.5073\n",
      "Epoch 924/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2290 - val_loss: 0.5215\n",
      "Epoch 925/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.2301 - val_loss: 0.5531\n",
      "Epoch 926/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2321 - val_loss: 0.5195\n",
      "Epoch 927/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.2283 - val_loss: 0.5367\n",
      "Epoch 928/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2380 - val_loss: 0.5375\n",
      "Epoch 929/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.2278 - val_loss: 0.5166\n",
      "Epoch 930/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2332 - val_loss: 0.5326\n",
      "Epoch 931/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2384 - val_loss: 0.5238\n",
      "Epoch 932/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2336 - val_loss: 0.5193\n",
      "Epoch 933/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2303 - val_loss: 0.5544\n",
      "Epoch 934/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2293 - val_loss: 0.5221\n",
      "Epoch 935/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2365 - val_loss: 0.5423\n",
      "Epoch 936/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2247 - val_loss: 0.5260\n",
      "Epoch 937/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2400 - val_loss: 0.5436\n",
      "Epoch 938/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2323 - val_loss: 0.5395\n",
      "Epoch 939/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2389 - val_loss: 0.5178\n",
      "Epoch 940/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2303 - val_loss: 0.5156\n",
      "Epoch 941/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2236 - val_loss: 0.5318\n",
      "Epoch 942/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2377 - val_loss: 0.5178\n",
      "Epoch 943/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2266 - val_loss: 0.5171\n",
      "Epoch 944/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2241 - val_loss: 0.5235\n",
      "Epoch 945/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2371 - val_loss: 0.5059\n",
      "Epoch 946/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2229 - val_loss: 0.5174\n",
      "Epoch 947/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2255 - val_loss: 0.5196\n",
      "Epoch 948/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2211 - val_loss: 0.5160\n",
      "Epoch 949/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2322 - val_loss: 0.5244\n",
      "Epoch 950/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2215 - val_loss: 0.5347\n",
      "Epoch 951/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2272 - val_loss: 0.5360\n",
      "Epoch 952/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2346 - val_loss: 0.5400\n",
      "Epoch 953/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2183 - val_loss: 0.5624\n",
      "Epoch 954/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.2308 - val_loss: 0.5373\n",
      "Epoch 955/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2328 - val_loss: 0.5350\n",
      "Epoch 956/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2276 - val_loss: 0.5478\n",
      "Epoch 957/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2204 - val_loss: 0.5297\n",
      "Epoch 958/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2256 - val_loss: 0.5353\n",
      "Epoch 959/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2276 - val_loss: 0.5243\n",
      "Epoch 960/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2281 - val_loss: 0.5423\n",
      "Epoch 961/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2279 - val_loss: 0.5269\n",
      "Epoch 962/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2327 - val_loss: 0.5167\n",
      "Epoch 963/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2352 - val_loss: 0.5285\n",
      "Epoch 964/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2233 - val_loss: 0.5393\n",
      "Epoch 965/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2309 - val_loss: 0.5224\n",
      "Epoch 966/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.2192 - val_loss: 0.5486\n",
      "Epoch 967/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.2231 - val_loss: 0.5602\n",
      "Epoch 968/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.2173 - val_loss: 0.5284\n",
      "Epoch 969/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2168 - val_loss: 0.5540\n",
      "Epoch 970/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2253 - val_loss: 0.5278\n",
      "Epoch 971/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2387 - val_loss: 0.5083\n",
      "Epoch 972/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2193 - val_loss: 0.5391\n",
      "Epoch 973/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2185 - val_loss: 0.5232\n",
      "Epoch 974/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2182 - val_loss: 0.5662\n",
      "Epoch 975/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2298 - val_loss: 0.5380\n",
      "Epoch 976/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.2233 - val_loss: 0.5238\n",
      "Epoch 977/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.2184 - val_loss: 0.5470\n",
      "Epoch 978/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.2207 - val_loss: 0.5246\n",
      "Epoch 979/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2151 - val_loss: 0.5333\n",
      "Epoch 980/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2102 - val_loss: 0.5345\n",
      "Epoch 981/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2179 - val_loss: 0.5393\n",
      "Epoch 982/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.2193 - val_loss: 0.5221\n",
      "Epoch 983/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2257 - val_loss: 0.5268\n",
      "Epoch 984/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2161 - val_loss: 0.5146\n",
      "Epoch 985/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2275 - val_loss: 0.5239\n",
      "Epoch 986/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2302 - val_loss: 0.5139\n",
      "Epoch 987/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2118 - val_loss: 0.5354\n",
      "Epoch 988/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2189 - val_loss: 0.5299\n",
      "Epoch 989/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2213 - val_loss: 0.5483\n",
      "Epoch 990/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2187 - val_loss: 0.5252\n",
      "Epoch 991/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2124 - val_loss: 0.5390\n",
      "Epoch 992/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2175 - val_loss: 0.5367\n",
      "Epoch 993/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2258 - val_loss: 0.5272\n",
      "Epoch 994/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2208 - val_loss: 0.5445\n",
      "Epoch 995/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2143 - val_loss: 0.5374\n",
      "Epoch 996/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2073 - val_loss: 0.5762\n",
      "Epoch 997/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2208 - val_loss: 0.5336\n",
      "Epoch 998/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2150 - val_loss: 0.5225\n",
      "Epoch 999/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2094 - val_loss: 0.5311\n",
      "Epoch 1000/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.2127 - val_loss: 0.5944\n",
      "Epoch 1001/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2122 - val_loss: 0.5364\n",
      "Epoch 1002/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2221 - val_loss: 0.5782\n",
      "Epoch 1003/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2230 - val_loss: 0.5308\n",
      "Epoch 1004/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2088 - val_loss: 0.5553\n",
      "Epoch 1005/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.2107 - val_loss: 0.5374\n",
      "Epoch 1006/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.2112 - val_loss: 0.5658\n",
      "Epoch 1007/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2141 - val_loss: 0.5253\n",
      "Epoch 1008/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.2199 - val_loss: 0.5429\n",
      "Epoch 1009/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.2174 - val_loss: 0.5272\n",
      "Epoch 1010/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2183 - val_loss: 0.5193\n",
      "Epoch 1011/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2073 - val_loss: 0.5666\n",
      "Epoch 1012/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.2198 - val_loss: 0.5408\n",
      "Epoch 1013/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.2175 - val_loss: 0.5091\n",
      "Epoch 1014/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.2050 - val_loss: 0.5339\n",
      "Epoch 1015/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2076 - val_loss: 0.5350\n",
      "Epoch 1016/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2200 - val_loss: 0.5490\n",
      "Epoch 1017/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.2064 - val_loss: 0.5218\n",
      "Epoch 1018/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2104 - val_loss: 0.5527\n",
      "Epoch 1019/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2109 - val_loss: 0.5265\n",
      "Epoch 1020/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.2198 - val_loss: 0.5528\n",
      "Epoch 1021/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2175 - val_loss: 0.5326\n",
      "Epoch 1022/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2208 - val_loss: 0.5379\n",
      "Epoch 1023/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2125 - val_loss: 0.5223\n",
      "Epoch 1024/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1999 - val_loss: 0.5641\n",
      "Epoch 1025/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2160 - val_loss: 0.5542\n",
      "Epoch 1026/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2095 - val_loss: 0.5417\n",
      "Epoch 1027/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2069 - val_loss: 0.5495\n",
      "Epoch 1028/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2050 - val_loss: 0.5644\n",
      "Epoch 1029/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2144 - val_loss: 0.5393\n",
      "Epoch 1030/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2070 - val_loss: 0.5528\n",
      "Epoch 1031/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2107 - val_loss: 0.5408\n",
      "Epoch 1032/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2117 - val_loss: 0.5644\n",
      "Epoch 1033/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2126 - val_loss: 0.5231\n",
      "Epoch 1034/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2087 - val_loss: 0.5294\n",
      "Epoch 1035/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.2036 - val_loss: 0.5346\n",
      "Epoch 1036/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2121 - val_loss: 0.5264\n",
      "Epoch 1037/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2106 - val_loss: 0.5407\n",
      "Epoch 1038/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2075 - val_loss: 0.5427\n",
      "Epoch 1039/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2101 - val_loss: 0.5520\n",
      "Epoch 1040/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2061 - val_loss: 0.5357\n",
      "Epoch 1041/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2098 - val_loss: 0.5242\n",
      "Epoch 1042/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2040 - val_loss: 0.5589\n",
      "Epoch 1043/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2105 - val_loss: 0.5646\n",
      "Epoch 1044/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2128 - val_loss: 0.5256\n",
      "Epoch 1045/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2082 - val_loss: 0.5264\n",
      "Epoch 1046/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.2008 - val_loss: 0.5325\n",
      "Epoch 1047/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2034 - val_loss: 0.5585\n",
      "Epoch 1048/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.2143 - val_loss: 0.5399\n",
      "Epoch 1049/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2130 - val_loss: 0.5359\n",
      "Epoch 1050/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.2054 - val_loss: 0.5377\n",
      "Epoch 1051/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.2046 - val_loss: 0.5449\n",
      "Epoch 1052/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2028 - val_loss: 0.5446\n",
      "Epoch 1053/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2116 - val_loss: 0.5233\n",
      "Epoch 1054/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1984 - val_loss: 0.5733\n",
      "Epoch 1055/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1993 - val_loss: 0.5596\n",
      "Epoch 1056/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.2016 - val_loss: 0.5445\n",
      "Epoch 1057/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2128 - val_loss: 0.5648\n",
      "Epoch 1058/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2147 - val_loss: 0.5271\n",
      "Epoch 1059/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.2044 - val_loss: 0.5387\n",
      "Epoch 1060/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.2015 - val_loss: 0.5515\n",
      "Epoch 1061/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.2038 - val_loss: 0.5320\n",
      "Epoch 1062/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1967 - val_loss: 0.5348\n",
      "Epoch 1063/10000\n",
      "130/130 [==============================] - 0s 810us/step - loss: 0.2061 - val_loss: 0.5545\n",
      "Epoch 1064/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1990 - val_loss: 0.5521\n",
      "Epoch 1065/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2121 - val_loss: 0.5685\n",
      "Epoch 1066/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.2094 - val_loss: 0.5610\n",
      "Epoch 1067/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 749us/step - loss: 0.2169 - val_loss: 0.5418\n",
      "Epoch 1068/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1991 - val_loss: 0.5401\n",
      "Epoch 1069/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1938 - val_loss: 0.5329\n",
      "Epoch 1070/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1972 - val_loss: 0.5378\n",
      "Epoch 1071/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2092 - val_loss: 0.5766\n",
      "Epoch 1072/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2070 - val_loss: 0.5528\n",
      "Epoch 1073/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2012 - val_loss: 0.5420\n",
      "Epoch 1074/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2181 - val_loss: 0.5261\n",
      "Epoch 1075/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1945 - val_loss: 0.5567\n",
      "Epoch 1076/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1986 - val_loss: 0.5680\n",
      "Epoch 1077/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2062 - val_loss: 0.5494\n",
      "Epoch 1078/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1997 - val_loss: 0.5555\n",
      "Epoch 1079/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1985 - val_loss: 0.5436\n",
      "Epoch 1080/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.2017 - val_loss: 0.5388\n",
      "Epoch 1081/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1980 - val_loss: 0.5581\n",
      "Epoch 1082/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2054 - val_loss: 0.5226\n",
      "Epoch 1083/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.2093 - val_loss: 0.5468\n",
      "Epoch 1084/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1988 - val_loss: 0.5273\n",
      "Epoch 1085/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1962 - val_loss: 0.5479\n",
      "Epoch 1086/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.2079 - val_loss: 0.5742\n",
      "Epoch 1087/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.2025 - val_loss: 0.5603\n",
      "Epoch 1088/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2025 - val_loss: 0.5646\n",
      "Epoch 1089/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.2061 - val_loss: 0.5703\n",
      "Epoch 1090/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.2019 - val_loss: 0.5374\n",
      "Epoch 1091/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1959 - val_loss: 0.5346\n",
      "Epoch 1092/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1941 - val_loss: 0.5364\n",
      "Epoch 1093/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1930 - val_loss: 0.5486\n",
      "Epoch 1094/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1971 - val_loss: 0.5259\n",
      "Epoch 1095/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1972 - val_loss: 0.5548\n",
      "Epoch 1096/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.2066 - val_loss: 0.5426\n",
      "Epoch 1097/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1946 - val_loss: 0.5375\n",
      "Epoch 1098/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.1944 - val_loss: 0.5410\n",
      "Epoch 1099/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1941 - val_loss: 0.5596\n",
      "Epoch 1100/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.2039 - val_loss: 0.5476\n",
      "Epoch 1101/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.2033 - val_loss: 0.5364\n",
      "Epoch 1102/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1950 - val_loss: 0.5334\n",
      "Epoch 1103/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1968 - val_loss: 0.5495\n",
      "Epoch 1104/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1966 - val_loss: 0.5440\n",
      "Epoch 1105/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2047 - val_loss: 0.5290\n",
      "Epoch 1106/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1951 - val_loss: 0.5452\n",
      "Epoch 1107/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1926 - val_loss: 0.5501\n",
      "Epoch 1108/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1910 - val_loss: 0.5450\n",
      "Epoch 1109/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.2011 - val_loss: 0.5517\n",
      "Epoch 1110/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.2000 - val_loss: 0.5646\n",
      "Epoch 1111/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.1937 - val_loss: 0.5406\n",
      "Epoch 1112/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1970 - val_loss: 0.5483\n",
      "Epoch 1113/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1863 - val_loss: 0.5263\n",
      "Epoch 1114/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.2023 - val_loss: 0.5466\n",
      "Epoch 1115/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1951 - val_loss: 0.5714\n",
      "Epoch 1116/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1904 - val_loss: 0.5577\n",
      "Epoch 1117/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1931 - val_loss: 0.5832\n",
      "Epoch 1118/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1966 - val_loss: 0.6057\n",
      "Epoch 1119/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.2009 - val_loss: 0.5512\n",
      "Epoch 1120/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1972 - val_loss: 0.5294\n",
      "Epoch 1121/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1972 - val_loss: 0.5421\n",
      "Epoch 1122/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1835 - val_loss: 0.5417\n",
      "Epoch 1123/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1975 - val_loss: 0.5900\n",
      "Epoch 1124/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1961 - val_loss: 0.5400\n",
      "Epoch 1125/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.2075 - val_loss: 0.5559\n",
      "Epoch 1126/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1834 - val_loss: 0.5681\n",
      "Epoch 1127/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1846 - val_loss: 0.5403\n",
      "Epoch 1128/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1933 - val_loss: 0.5411\n",
      "Epoch 1129/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1938 - val_loss: 0.5428\n",
      "Epoch 1130/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1927 - val_loss: 0.5556\n",
      "Epoch 1131/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1899 - val_loss: 0.5493\n",
      "Epoch 1132/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1793 - val_loss: 0.5350\n",
      "Epoch 1133/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1926 - val_loss: 0.5500\n",
      "Epoch 1134/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1915 - val_loss: 0.5533\n",
      "Epoch 1135/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1923 - val_loss: 0.5675\n",
      "Epoch 1136/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1821 - val_loss: 0.5891\n",
      "Epoch 1137/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1894 - val_loss: 0.5565\n",
      "Epoch 1138/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1866 - val_loss: 0.5429\n",
      "Epoch 1139/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1928 - val_loss: 0.5374\n",
      "Epoch 1140/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1916 - val_loss: 0.5584\n",
      "Epoch 1141/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1868 - val_loss: 0.5517\n",
      "Epoch 1142/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1936 - val_loss: 0.5328\n",
      "Epoch 1143/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 743us/step - loss: 0.1955 - val_loss: 0.5664\n",
      "Epoch 1144/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.2002 - val_loss: 0.5403\n",
      "Epoch 1145/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.1865 - val_loss: 0.5397\n",
      "Epoch 1146/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1955 - val_loss: 0.5515\n",
      "Epoch 1147/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1863 - val_loss: 0.5346\n",
      "Epoch 1148/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1924 - val_loss: 0.5675\n",
      "Epoch 1149/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1893 - val_loss: 0.5538\n",
      "Epoch 1150/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1906 - val_loss: 0.5481\n",
      "Epoch 1151/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1904 - val_loss: 0.5372\n",
      "Epoch 1152/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1809 - val_loss: 0.5653\n",
      "Epoch 1153/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1810 - val_loss: 0.5667\n",
      "Epoch 1154/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1807 - val_loss: 0.5621\n",
      "Epoch 1155/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1882 - val_loss: 0.5465\n",
      "Epoch 1156/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1828 - val_loss: 0.5508\n",
      "Epoch 1157/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1841 - val_loss: 0.5367\n",
      "Epoch 1158/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1809 - val_loss: 0.5890\n",
      "Epoch 1159/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1895 - val_loss: 0.5970\n",
      "Epoch 1160/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1845 - val_loss: 0.5573\n",
      "Epoch 1161/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1892 - val_loss: 0.5508\n",
      "Epoch 1162/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1882 - val_loss: 0.5231\n",
      "Epoch 1163/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1844 - val_loss: 0.5638\n",
      "Epoch 1164/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1857 - val_loss: 0.5338\n",
      "Epoch 1165/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1856 - val_loss: 0.5541\n",
      "Epoch 1166/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1896 - val_loss: 0.5683\n",
      "Epoch 1167/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.1788 - val_loss: 0.5447\n",
      "Epoch 1168/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1852 - val_loss: 0.5723\n",
      "Epoch 1169/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1886 - val_loss: 0.5421\n",
      "Epoch 1170/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1900 - val_loss: 0.5423\n",
      "Epoch 1171/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1860 - val_loss: 0.5580\n",
      "Epoch 1172/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1804 - val_loss: 0.5334\n",
      "Epoch 1173/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1828 - val_loss: 0.5405\n",
      "Epoch 1174/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1825 - val_loss: 0.5520\n",
      "Epoch 1175/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1858 - val_loss: 0.5444\n",
      "Epoch 1176/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1809 - val_loss: 0.5393\n",
      "Epoch 1177/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1841 - val_loss: 0.5624\n",
      "Epoch 1178/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1834 - val_loss: 0.5665\n",
      "Epoch 1179/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.1930 - val_loss: 0.5659\n",
      "Epoch 1180/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1852 - val_loss: 0.5510\n",
      "Epoch 1181/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1829 - val_loss: 0.5731\n",
      "Epoch 1182/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1817 - val_loss: 0.5363\n",
      "Epoch 1183/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1917 - val_loss: 0.5619\n",
      "Epoch 1184/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.1754 - val_loss: 0.5507\n",
      "Epoch 1185/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1944 - val_loss: 0.5488\n",
      "Epoch 1186/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1799 - val_loss: 0.5457\n",
      "Epoch 1187/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1740 - val_loss: 0.5427\n",
      "Epoch 1188/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.1827 - val_loss: 0.5456\n",
      "Epoch 1189/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1871 - val_loss: 0.5673\n",
      "Epoch 1190/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1927 - val_loss: 0.5277\n",
      "Epoch 1191/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1815 - val_loss: 0.5410\n",
      "Epoch 1192/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1832 - val_loss: 0.5444\n",
      "Epoch 1193/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1781 - val_loss: 0.5312\n",
      "Epoch 1194/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1777 - val_loss: 0.5476\n",
      "Epoch 1195/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1802 - val_loss: 0.5611\n",
      "Epoch 1196/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1822 - val_loss: 0.5425\n",
      "Epoch 1197/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1825 - val_loss: 0.5975\n",
      "Epoch 1198/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.1802 - val_loss: 0.5539\n",
      "Epoch 1199/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1752 - val_loss: 0.5263\n",
      "Epoch 1200/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1795 - val_loss: 0.5566\n",
      "Epoch 1201/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.1743 - val_loss: 0.5652\n",
      "Epoch 1202/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1834 - val_loss: 0.5518\n",
      "Epoch 1203/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1794 - val_loss: 0.5599\n",
      "Epoch 1204/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1776 - val_loss: 0.5649\n",
      "Epoch 1205/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1734 - val_loss: 0.5569\n",
      "Epoch 1206/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1792 - val_loss: 0.5618\n",
      "Epoch 1207/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1740 - val_loss: 0.5416\n",
      "Epoch 1208/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1846 - val_loss: 0.5584\n",
      "Epoch 1209/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1823 - val_loss: 0.5417\n",
      "Epoch 1210/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1821 - val_loss: 0.5652\n",
      "Epoch 1211/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1816 - val_loss: 0.5499\n",
      "Epoch 1212/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1867 - val_loss: 0.5525\n",
      "Epoch 1213/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1732 - val_loss: 0.5651\n",
      "Epoch 1214/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1774 - val_loss: 0.5591\n",
      "Epoch 1215/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1748 - val_loss: 0.5680\n",
      "Epoch 1216/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1800 - val_loss: 0.5719\n",
      "Epoch 1217/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.1876 - val_loss: 0.5558\n",
      "Epoch 1218/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1693 - val_loss: 0.5270\n",
      "Epoch 1219/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 736us/step - loss: 0.1805 - val_loss: 0.5571\n",
      "Epoch 1220/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1808 - val_loss: 0.5617\n",
      "Epoch 1221/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.1715 - val_loss: 0.5365\n",
      "Epoch 1222/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1713 - val_loss: 0.5573\n",
      "Epoch 1223/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1681 - val_loss: 0.5626\n",
      "Epoch 1224/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1776 - val_loss: 0.5627\n",
      "Epoch 1225/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1744 - val_loss: 0.5495\n",
      "Epoch 1226/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1655 - val_loss: 0.5539\n",
      "Epoch 1227/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1736 - val_loss: 0.5459\n",
      "Epoch 1228/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1782 - val_loss: 0.5522\n",
      "Epoch 1229/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1758 - val_loss: 0.5446\n",
      "Epoch 1230/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1760 - val_loss: 0.5713\n",
      "Epoch 1231/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1718 - val_loss: 0.5583\n",
      "Epoch 1232/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1798 - val_loss: 0.5519\n",
      "Epoch 1233/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1736 - val_loss: 0.5340\n",
      "Epoch 1234/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1737 - val_loss: 0.5515\n",
      "Epoch 1235/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1731 - val_loss: 0.5621\n",
      "Epoch 1236/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1787 - val_loss: 0.5450\n",
      "Epoch 1237/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1926 - val_loss: 0.5647\n",
      "Epoch 1238/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1703 - val_loss: 0.5477\n",
      "Epoch 1239/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1769 - val_loss: 0.5666\n",
      "Epoch 1240/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1690 - val_loss: 0.5665\n",
      "Epoch 1241/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1715 - val_loss: 0.5831\n",
      "Epoch 1242/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1713 - val_loss: 0.5593\n",
      "Epoch 1243/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1720 - val_loss: 0.5585\n",
      "Epoch 1244/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1722 - val_loss: 0.5711\n",
      "Epoch 1245/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1755 - val_loss: 0.5472\n",
      "Epoch 1246/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1759 - val_loss: 0.5626\n",
      "Epoch 1247/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1726 - val_loss: 0.5665\n",
      "Epoch 1248/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1700 - val_loss: 0.5872\n",
      "Epoch 1249/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1795 - val_loss: 0.5454\n",
      "Epoch 1250/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1717 - val_loss: 0.5372\n",
      "Epoch 1251/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1697 - val_loss: 0.5532\n",
      "Epoch 1252/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1808 - val_loss: 0.5399\n",
      "Epoch 1253/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1690 - val_loss: 0.5399\n",
      "Epoch 1254/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1715 - val_loss: 0.5703\n",
      "Epoch 1255/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1689 - val_loss: 0.5738\n",
      "Epoch 1256/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1665 - val_loss: 0.5882\n",
      "Epoch 1257/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1764 - val_loss: 0.5360\n",
      "Epoch 1258/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.1720 - val_loss: 0.5724\n",
      "Epoch 1259/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1800 - val_loss: 0.5430\n",
      "Epoch 1260/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1663 - val_loss: 0.5727\n",
      "Epoch 1261/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1724 - val_loss: 0.5813\n",
      "Epoch 1262/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1664 - val_loss: 0.5587\n",
      "Epoch 1263/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1686 - val_loss: 0.5802\n",
      "Epoch 1264/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1780 - val_loss: 0.5652\n",
      "Epoch 1265/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1772 - val_loss: 0.5587\n",
      "Epoch 1266/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1707 - val_loss: 0.5473\n",
      "Epoch 1267/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1681 - val_loss: 0.5612\n",
      "Epoch 1268/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1648 - val_loss: 0.5707\n",
      "Epoch 1269/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.1688 - val_loss: 0.5411\n",
      "Epoch 1270/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1641 - val_loss: 0.5829\n",
      "Epoch 1271/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1647 - val_loss: 0.5676\n",
      "Epoch 1272/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1585 - val_loss: 0.5683\n",
      "Epoch 1273/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1725 - val_loss: 0.5635\n",
      "Epoch 1274/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1782 - val_loss: 0.5528\n",
      "Epoch 1275/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1746 - val_loss: 0.5600\n",
      "Epoch 1276/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1671 - val_loss: 0.5465\n",
      "Epoch 1277/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.1641 - val_loss: 0.5479\n",
      "Epoch 1278/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1711 - val_loss: 0.5590\n",
      "Epoch 1279/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1676 - val_loss: 0.5595\n",
      "Epoch 1280/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1654 - val_loss: 0.5626\n",
      "Epoch 1281/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1644 - val_loss: 0.5813\n",
      "Epoch 1282/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1656 - val_loss: 0.5591\n",
      "Epoch 1283/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1704 - val_loss: 0.5557\n",
      "Epoch 1284/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1687 - val_loss: 0.5630\n",
      "Epoch 1285/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1695 - val_loss: 0.5488\n",
      "Epoch 1286/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1554 - val_loss: 0.5514\n",
      "Epoch 1287/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1665 - val_loss: 0.5563\n",
      "Epoch 1288/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1575 - val_loss: 0.5637\n",
      "Epoch 1289/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1611 - val_loss: 0.5374\n",
      "Epoch 1290/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1625 - val_loss: 0.5745\n",
      "Epoch 1291/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1696 - val_loss: 0.5787\n",
      "Epoch 1292/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1771 - val_loss: 0.5300\n",
      "Epoch 1293/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1627 - val_loss: 0.5522\n",
      "Epoch 1294/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1597 - val_loss: 0.5334\n",
      "Epoch 1295/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 726us/step - loss: 0.1632 - val_loss: 0.5575\n",
      "Epoch 1296/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.1664 - val_loss: 0.5645\n",
      "Epoch 1297/10000\n",
      "130/130 [==============================] - 0s 819us/step - loss: 0.1596 - val_loss: 0.5708\n",
      "Epoch 1298/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.1672 - val_loss: 0.5616\n",
      "Epoch 1299/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1633 - val_loss: 0.5569\n",
      "Epoch 1300/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.1598 - val_loss: 0.5571\n",
      "Epoch 1301/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1571 - val_loss: 0.5575\n",
      "Epoch 1302/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1611 - val_loss: 0.5611\n",
      "Epoch 1303/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.1608 - val_loss: 0.5685\n",
      "Epoch 1304/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.1566 - val_loss: 0.5661\n",
      "Epoch 1305/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1634 - val_loss: 0.6206\n",
      "Epoch 1306/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1691 - val_loss: 0.5498\n",
      "Epoch 1307/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1599 - val_loss: 0.5684\n",
      "Epoch 1308/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1578 - val_loss: 0.5558\n",
      "Epoch 1309/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1739 - val_loss: 0.5447\n",
      "Epoch 1310/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1722 - val_loss: 0.5724\n",
      "Epoch 1311/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1715 - val_loss: 0.5782\n",
      "Epoch 1312/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1575 - val_loss: 0.5649\n",
      "Epoch 1313/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1589 - val_loss: 0.5576\n",
      "Epoch 1314/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1669 - val_loss: 0.5643\n",
      "Epoch 1315/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1669 - val_loss: 0.5447\n",
      "Epoch 1316/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1593 - val_loss: 0.5596\n",
      "Epoch 1317/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1567 - val_loss: 0.5505\n",
      "Epoch 1318/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1596 - val_loss: 0.5652\n",
      "Epoch 1319/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1553 - val_loss: 0.5527\n",
      "Epoch 1320/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.1590 - val_loss: 0.5822\n",
      "Epoch 1321/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1542 - val_loss: 0.5586\n",
      "Epoch 1322/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1568 - val_loss: 0.5449\n",
      "Epoch 1323/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1559 - val_loss: 0.5756\n",
      "Epoch 1324/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1626 - val_loss: 0.5661\n",
      "Epoch 1325/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1729 - val_loss: 0.5682\n",
      "Epoch 1326/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1571 - val_loss: 0.5535\n",
      "Epoch 1327/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1626 - val_loss: 0.5552\n",
      "Epoch 1328/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1535 - val_loss: 0.5361\n",
      "Epoch 1329/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1746 - val_loss: 0.5666\n",
      "Epoch 1330/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1611 - val_loss: 0.5536\n",
      "Epoch 1331/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1557 - val_loss: 0.5719\n",
      "Epoch 1332/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.1502 - val_loss: 0.5635\n",
      "Epoch 1333/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1529 - val_loss: 0.5420\n",
      "Epoch 1334/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1606 - val_loss: 0.5875\n",
      "Epoch 1335/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1543 - val_loss: 0.5693\n",
      "Epoch 1336/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1591 - val_loss: 0.5942\n",
      "Epoch 1337/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1563 - val_loss: 0.5608\n",
      "Epoch 1338/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1597 - val_loss: 0.5548\n",
      "Epoch 1339/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1507 - val_loss: 0.5770\n",
      "Epoch 1340/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1633 - val_loss: 0.5672\n",
      "Epoch 1341/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1501 - val_loss: 0.5532\n",
      "Epoch 1342/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1486 - val_loss: 0.5572\n",
      "Epoch 1343/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1481 - val_loss: 0.5725\n",
      "Epoch 1344/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1565 - val_loss: 0.5700\n",
      "Epoch 1345/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1567 - val_loss: 0.5465\n",
      "Epoch 1346/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1571 - val_loss: 0.5648\n",
      "Epoch 1347/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1587 - val_loss: 0.5609\n",
      "Epoch 1348/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1574 - val_loss: 0.5491\n",
      "Epoch 1349/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1520 - val_loss: 0.5483\n",
      "Epoch 1350/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1539 - val_loss: 0.5718\n",
      "Epoch 1351/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1656 - val_loss: 0.5809\n",
      "Epoch 1352/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1630 - val_loss: 0.5594\n",
      "Epoch 1353/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1587 - val_loss: 0.5681\n",
      "Epoch 1354/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1552 - val_loss: 0.5683\n",
      "Epoch 1355/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1530 - val_loss: 0.5575\n",
      "Epoch 1356/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1539 - val_loss: 0.5440\n",
      "Epoch 1357/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.1532 - val_loss: 0.5611\n",
      "Epoch 1358/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1565 - val_loss: 0.5354\n",
      "Epoch 1359/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1487 - val_loss: 0.5532\n",
      "Epoch 1360/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1523 - val_loss: 0.5967\n",
      "Epoch 1361/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1569 - val_loss: 0.5704\n",
      "Epoch 1362/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1550 - val_loss: 0.5960\n",
      "Epoch 1363/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1662 - val_loss: 0.5484\n",
      "Epoch 1364/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1510 - val_loss: 0.5674\n",
      "Epoch 1365/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.1506 - val_loss: 0.5721\n",
      "Epoch 1366/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1646 - val_loss: 0.5654\n",
      "Epoch 1367/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1474 - val_loss: 0.5715\n",
      "Epoch 1368/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1508 - val_loss: 0.5713\n",
      "Epoch 1369/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.1455 - val_loss: 0.5498\n",
      "Epoch 1370/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.1508 - val_loss: 0.5920\n",
      "Epoch 1371/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 727us/step - loss: 0.1469 - val_loss: 0.5686\n",
      "Epoch 1372/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1544 - val_loss: 0.5711\n",
      "Epoch 1373/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1518 - val_loss: 0.5719\n",
      "Epoch 1374/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1510 - val_loss: 0.5739\n",
      "Epoch 1375/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1471 - val_loss: 0.5646\n",
      "Epoch 1376/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1554 - val_loss: 0.5656\n",
      "Epoch 1377/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1527 - val_loss: 0.5551\n",
      "Epoch 1378/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1524 - val_loss: 0.5554\n",
      "Epoch 1379/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1487 - val_loss: 0.5707\n",
      "Epoch 1380/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1529 - val_loss: 0.5801\n",
      "Epoch 1381/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1516 - val_loss: 0.5621\n",
      "Epoch 1382/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1464 - val_loss: 0.5765\n",
      "Epoch 1383/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1540 - val_loss: 0.5989\n",
      "Epoch 1384/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1598 - val_loss: 0.5492\n",
      "Epoch 1385/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1466 - val_loss: 0.5618\n",
      "Epoch 1386/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1409 - val_loss: 0.5490\n",
      "Epoch 1387/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1530 - val_loss: 0.5647\n",
      "Epoch 1388/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1428 - val_loss: 0.5904\n",
      "Epoch 1389/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.1505 - val_loss: 0.5634\n",
      "Epoch 1390/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.1518 - val_loss: 0.5709\n",
      "Epoch 1391/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.1588 - val_loss: 0.5699\n",
      "Epoch 1392/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.1453 - val_loss: 0.5803\n",
      "Epoch 1393/10000\n",
      "130/130 [==============================] - 0s 867us/step - loss: 0.1537 - val_loss: 0.5439\n",
      "Epoch 1394/10000\n",
      "130/130 [==============================] - 0s 840us/step - loss: 0.1552 - val_loss: 0.5553\n",
      "Epoch 1395/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.1425 - val_loss: 0.5736\n",
      "Epoch 1396/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.1500 - val_loss: 0.5512\n",
      "Epoch 1397/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.1490 - val_loss: 0.5654\n",
      "Epoch 1398/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1464 - val_loss: 0.5756\n",
      "Epoch 1399/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1428 - val_loss: 0.5552\n",
      "Epoch 1400/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1471 - val_loss: 0.5634\n",
      "Epoch 1401/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1453 - val_loss: 0.5642\n",
      "Epoch 1402/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1442 - val_loss: 0.5576\n",
      "Epoch 1403/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1432 - val_loss: 0.5535\n",
      "Epoch 1404/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1463 - val_loss: 0.6021\n",
      "Epoch 1405/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1452 - val_loss: 0.6077\n",
      "Epoch 1406/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1682 - val_loss: 0.5609\n",
      "Epoch 1407/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1442 - val_loss: 0.5612\n",
      "Epoch 1408/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1433 - val_loss: 0.5833\n",
      "Epoch 1409/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1475 - val_loss: 0.5506\n",
      "Epoch 1410/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1396 - val_loss: 0.5691\n",
      "Epoch 1411/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1459 - val_loss: 0.5623\n",
      "Epoch 1412/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1500 - val_loss: 0.5763\n",
      "Epoch 1413/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.1576 - val_loss: 0.5895\n",
      "Epoch 1414/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.1447 - val_loss: 0.5818\n",
      "Epoch 1415/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1357 - val_loss: 0.5625\n",
      "Epoch 1416/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1491 - val_loss: 0.5592\n",
      "Epoch 1417/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.1546 - val_loss: 0.5646\n",
      "Epoch 1418/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1386 - val_loss: 0.5746\n",
      "Epoch 1419/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1489 - val_loss: 0.5706\n",
      "Epoch 1420/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1540 - val_loss: 0.5726\n",
      "Epoch 1421/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1442 - val_loss: 0.5583\n",
      "Epoch 1422/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1453 - val_loss: 0.5577\n",
      "Epoch 1423/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1433 - val_loss: 0.5672\n",
      "Epoch 1424/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1372 - val_loss: 0.5814\n",
      "Epoch 1425/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1485 - val_loss: 0.5568\n",
      "Epoch 1426/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1483 - val_loss: 0.5551\n",
      "Epoch 1427/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1469 - val_loss: 0.5548\n",
      "Epoch 1428/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1449 - val_loss: 0.5863\n",
      "Epoch 1429/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1407 - val_loss: 0.5870\n",
      "Epoch 1430/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.1425 - val_loss: 0.5716\n",
      "Epoch 1431/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1424 - val_loss: 0.5728\n",
      "Epoch 1432/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1380 - val_loss: 0.5653\n",
      "Epoch 1433/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1420 - val_loss: 0.5694\n",
      "Epoch 1434/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1432 - val_loss: 0.5602\n",
      "Epoch 1435/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1427 - val_loss: 0.5714\n",
      "Epoch 1436/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1408 - val_loss: 0.5818\n",
      "Epoch 1437/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1417 - val_loss: 0.5493\n",
      "Epoch 1438/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.1368 - val_loss: 0.5686\n",
      "Epoch 1439/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1397 - val_loss: 0.5883\n",
      "Epoch 1440/10000\n",
      "130/130 [==============================] - 0s 809us/step - loss: 0.1434 - val_loss: 0.5933\n",
      "Epoch 1441/10000\n",
      "130/130 [==============================] - 0s 803us/step - loss: 0.1390 - val_loss: 0.5828\n",
      "Epoch 1442/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.1459 - val_loss: 0.5695\n",
      "Epoch 1443/10000\n",
      "130/130 [==============================] - 0s 950us/step - loss: 0.1399 - val_loss: 0.5564\n",
      "Epoch 1444/10000\n",
      "130/130 [==============================] - 0s 919us/step - loss: 0.1343 - val_loss: 0.5684\n",
      "Epoch 1445/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.1432 - val_loss: 0.5657\n",
      "Epoch 1446/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.1440 - val_loss: 0.5578\n",
      "Epoch 1447/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 756us/step - loss: 0.1457 - val_loss: 0.5707\n",
      "Epoch 1448/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.1388 - val_loss: 0.5883\n",
      "Epoch 1449/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1388 - val_loss: 0.5970\n",
      "Epoch 1450/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1441 - val_loss: 0.5773\n",
      "Epoch 1451/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1367 - val_loss: 0.5704\n",
      "Epoch 1452/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1398 - val_loss: 0.5829\n",
      "Epoch 1453/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1422 - val_loss: 0.5622\n",
      "Epoch 1454/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.1336 - val_loss: 0.5686\n",
      "Epoch 1455/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.1475 - val_loss: 0.5644\n",
      "Epoch 1456/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.1477 - val_loss: 0.5494\n",
      "Epoch 1457/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1429 - val_loss: 0.5484\n",
      "Epoch 1458/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1337 - val_loss: 0.5746\n",
      "Epoch 1459/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1447 - val_loss: 0.5651\n",
      "Epoch 1460/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1376 - val_loss: 0.5710\n",
      "Epoch 1461/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1344 - val_loss: 0.5611\n",
      "Epoch 1462/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1373 - val_loss: 0.5746\n",
      "Epoch 1463/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1347 - val_loss: 0.5556\n",
      "Epoch 1464/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1350 - val_loss: 0.5842\n",
      "Epoch 1465/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1446 - val_loss: 0.6076\n",
      "Epoch 1466/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.1413 - val_loss: 0.5766\n",
      "Epoch 1467/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.1374 - val_loss: 0.5660\n",
      "Epoch 1468/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.1369 - val_loss: 0.5560\n",
      "Epoch 1469/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.1346 - val_loss: 0.5786\n",
      "Epoch 1470/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.1358 - val_loss: 0.6117\n",
      "Epoch 1471/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1361 - val_loss: 0.5789\n",
      "Epoch 1472/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1359 - val_loss: 0.5587\n",
      "Epoch 1473/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.1347 - val_loss: 0.5606\n",
      "Epoch 1474/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1456 - val_loss: 0.5769\n",
      "Epoch 1475/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.1439 - val_loss: 0.5750\n",
      "Epoch 1476/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1334 - val_loss: 0.5729\n",
      "Epoch 1477/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1344 - val_loss: 0.5865\n",
      "Epoch 1478/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1396 - val_loss: 0.5944\n",
      "Epoch 1479/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1381 - val_loss: 0.5690\n",
      "Epoch 1480/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1293 - val_loss: 0.5680\n",
      "Epoch 1481/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1365 - val_loss: 0.5690\n",
      "Epoch 1482/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1321 - val_loss: 0.5677\n",
      "Epoch 1483/10000\n",
      "130/130 [==============================] - 0s 883us/step - loss: 0.1447 - val_loss: 0.5549\n",
      "Epoch 1484/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.1383 - val_loss: 0.5780\n",
      "Epoch 1485/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1305 - val_loss: 0.5575\n",
      "Epoch 1486/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.1304 - val_loss: 0.5643\n",
      "Epoch 1487/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.1413 - val_loss: 0.5716\n",
      "Epoch 1488/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1378 - val_loss: 0.5816\n",
      "Epoch 1489/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1345 - val_loss: 0.5605\n",
      "Epoch 1490/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.1287 - val_loss: 0.5641\n",
      "Epoch 1491/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1313 - val_loss: 0.5629\n",
      "Epoch 1492/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1339 - val_loss: 0.5619\n",
      "Epoch 1493/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.1337 - val_loss: 0.5693\n",
      "Epoch 1494/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1343 - val_loss: 0.5875\n",
      "Epoch 1495/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.1414 - val_loss: 0.6014\n",
      "Epoch 1496/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1415 - val_loss: 0.5732\n",
      "Epoch 1497/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1307 - val_loss: 0.5839\n",
      "Epoch 1498/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.1350 - val_loss: 0.5647\n",
      "Epoch 1499/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1299 - val_loss: 0.5768\n",
      "Epoch 1500/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1302 - val_loss: 0.5593\n",
      "Epoch 1501/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1271 - val_loss: 0.5686\n",
      "Epoch 1502/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.1323 - val_loss: 0.5691\n",
      "Epoch 1503/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1397 - val_loss: 0.5801\n",
      "Epoch 1504/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1385 - val_loss: 0.5729\n",
      "Epoch 1505/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.1313 - val_loss: 0.5844\n",
      "Epoch 1506/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1298 - val_loss: 0.5863\n",
      "Epoch 1507/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.1334 - val_loss: 0.5646\n",
      "Epoch 1508/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1349 - val_loss: 0.5765\n",
      "Epoch 1509/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1317 - val_loss: 0.5896\n",
      "Epoch 1510/10000\n",
      "130/130 [==============================] - 0s 885us/step - loss: 0.1245 - val_loss: 0.5826\n",
      "Epoch 1511/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.1307 - val_loss: 0.5602\n",
      "Epoch 1512/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.1372 - val_loss: 0.5709\n",
      "Epoch 1513/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.1359 - val_loss: 0.5751\n",
      "Epoch 1514/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1403 - val_loss: 0.5846\n",
      "Epoch 1515/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1273 - val_loss: 0.5862\n",
      "Epoch 1516/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1295 - val_loss: 0.5678\n",
      "Epoch 1517/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1368 - val_loss: 0.5618\n",
      "Epoch 1518/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1303 - val_loss: 0.5820\n",
      "Epoch 1519/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1362 - val_loss: 0.5535\n",
      "Epoch 1520/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1289 - val_loss: 0.5741\n",
      "Epoch 1521/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1370 - val_loss: 0.5613\n",
      "Epoch 1522/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1410 - val_loss: 0.5761\n",
      "Epoch 1523/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 744us/step - loss: 0.1372 - val_loss: 0.5653\n",
      "Epoch 1524/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.1229 - val_loss: 0.5811\n",
      "Epoch 1525/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1312 - val_loss: 0.5899\n",
      "Epoch 1526/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1338 - val_loss: 0.5497\n",
      "Epoch 1527/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1323 - val_loss: 0.5780\n",
      "Epoch 1528/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1330 - val_loss: 0.5808\n",
      "Epoch 1529/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1272 - val_loss: 0.6030\n",
      "Epoch 1530/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1249 - val_loss: 0.5621\n",
      "Epoch 1531/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1300 - val_loss: 0.5799\n",
      "Epoch 1532/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1335 - val_loss: 0.5692\n",
      "Epoch 1533/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1263 - val_loss: 0.5721\n",
      "Epoch 1534/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1292 - val_loss: 0.5656\n",
      "Epoch 1535/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1402 - val_loss: 0.5821\n",
      "Epoch 1536/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1256 - val_loss: 0.5760\n",
      "Epoch 1537/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1343 - val_loss: 0.5718\n",
      "Epoch 1538/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1322 - val_loss: 0.5656\n",
      "Epoch 1539/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1266 - val_loss: 0.5686\n",
      "Epoch 1540/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1338 - val_loss: 0.5848\n",
      "Epoch 1541/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1326 - val_loss: 0.5770\n",
      "Epoch 1542/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1344 - val_loss: 0.5829\n",
      "Epoch 1543/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1281 - val_loss: 0.5622\n",
      "Epoch 1544/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1217 - val_loss: 0.5880\n",
      "Epoch 1545/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1265 - val_loss: 0.5857\n",
      "Epoch 1546/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1301 - val_loss: 0.5656\n",
      "Epoch 1547/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1229 - val_loss: 0.5812\n",
      "Epoch 1548/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1357 - val_loss: 0.5592\n",
      "Epoch 1549/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1315 - val_loss: 0.5904\n",
      "Epoch 1550/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1264 - val_loss: 0.6117\n",
      "Epoch 1551/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1308 - val_loss: 0.5716\n",
      "Epoch 1552/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1288 - val_loss: 0.5575\n",
      "Epoch 1553/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1308 - val_loss: 0.5518\n",
      "Epoch 1554/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1195 - val_loss: 0.5779\n",
      "Epoch 1555/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1305 - val_loss: 0.5786\n",
      "Epoch 1556/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.1303 - val_loss: 0.5988\n",
      "Epoch 1557/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1367 - val_loss: 0.5634\n",
      "Epoch 1558/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1241 - val_loss: 0.5843\n",
      "Epoch 1559/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.1274 - val_loss: 0.5777\n",
      "Epoch 1560/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1367 - val_loss: 0.5697\n",
      "Epoch 1561/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1176 - val_loss: 0.5652\n",
      "Epoch 1562/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1183 - val_loss: 0.5781\n",
      "Epoch 1563/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1189 - val_loss: 0.5618\n",
      "Epoch 1564/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1318 - val_loss: 0.5910\n",
      "Epoch 1565/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1355 - val_loss: 0.5569\n",
      "Epoch 1566/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1372 - val_loss: 0.5676\n",
      "Epoch 1567/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1262 - val_loss: 0.5703\n",
      "Epoch 1568/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1318 - val_loss: 0.5711\n",
      "Epoch 1569/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1356 - val_loss: 0.5767\n",
      "Epoch 1570/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1256 - val_loss: 0.5660\n",
      "Epoch 1571/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1243 - val_loss: 0.5681\n",
      "Epoch 1572/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1234 - val_loss: 0.5795\n",
      "Epoch 1573/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1270 - val_loss: 0.5673\n",
      "Epoch 1574/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1258 - val_loss: 0.5650\n",
      "Epoch 1575/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1241 - val_loss: 0.5765\n",
      "Epoch 1576/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1248 - val_loss: 0.5673\n",
      "Epoch 1577/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1346 - val_loss: 0.5811\n",
      "Epoch 1578/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1283 - val_loss: 0.5965\n",
      "Epoch 1579/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1327 - val_loss: 0.5730\n",
      "Epoch 1580/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1300 - val_loss: 0.6233\n",
      "Epoch 1581/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1238 - val_loss: 0.5517\n",
      "Epoch 1582/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1167 - val_loss: 0.5852\n",
      "Epoch 1583/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1221 - val_loss: 0.5797\n",
      "Epoch 1584/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1202 - val_loss: 0.5782\n",
      "Epoch 1585/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1171 - val_loss: 0.5904\n",
      "Epoch 1586/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.1258 - val_loss: 0.5862\n",
      "Epoch 1587/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1408 - val_loss: 0.5835\n",
      "Epoch 1588/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1315 - val_loss: 0.5865\n",
      "Epoch 1589/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1231 - val_loss: 0.5673\n",
      "Epoch 1590/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1205 - val_loss: 0.5816\n",
      "Epoch 1591/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1195 - val_loss: 0.5870\n",
      "Epoch 1592/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1158 - val_loss: 0.5937\n",
      "Epoch 1593/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1265 - val_loss: 0.5872\n",
      "Epoch 1594/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1282 - val_loss: 0.5744\n",
      "Epoch 1595/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1324 - val_loss: 0.5704\n",
      "Epoch 1596/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1163 - val_loss: 0.5653\n",
      "Epoch 1597/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1338 - val_loss: 0.5767\n",
      "Epoch 1598/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1281 - val_loss: 0.5879\n",
      "Epoch 1599/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 760us/step - loss: 0.1201 - val_loss: 0.5566\n",
      "Epoch 1600/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1242 - val_loss: 0.5844\n",
      "Epoch 1601/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1203 - val_loss: 0.5533\n",
      "Epoch 1602/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1127 - val_loss: 0.5832\n",
      "Epoch 1603/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1215 - val_loss: 0.5643\n",
      "Epoch 1604/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1262 - val_loss: 0.5772\n",
      "Epoch 1605/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1213 - val_loss: 0.5982\n",
      "Epoch 1606/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1195 - val_loss: 0.5818\n",
      "Epoch 1607/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1221 - val_loss: 0.5765\n",
      "Epoch 1608/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1144 - val_loss: 0.6074\n",
      "Epoch 1609/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1238 - val_loss: 0.5953\n",
      "Epoch 1610/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1264 - val_loss: 0.5865\n",
      "Epoch 1611/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1235 - val_loss: 0.5680\n",
      "Epoch 1612/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.1358 - val_loss: 0.5760\n",
      "Epoch 1613/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1194 - val_loss: 0.5925\n",
      "Epoch 1614/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1200 - val_loss: 0.5898\n",
      "Epoch 1615/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1227 - val_loss: 0.5801\n",
      "Epoch 1616/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1178 - val_loss: 0.5783\n",
      "Epoch 1617/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.1164 - val_loss: 0.5560\n",
      "Epoch 1618/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1186 - val_loss: 0.5683\n",
      "Epoch 1619/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.1204 - val_loss: 0.5874\n",
      "Epoch 1620/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1185 - val_loss: 0.5775\n",
      "Epoch 1621/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1302 - val_loss: 0.5974\n",
      "Epoch 1622/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1318 - val_loss: 0.5453\n",
      "Epoch 1623/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1210 - val_loss: 0.5808\n",
      "Epoch 1624/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1133 - val_loss: 0.5797\n",
      "Epoch 1625/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1140 - val_loss: 0.5758\n",
      "Epoch 1626/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1184 - val_loss: 0.5667\n",
      "Epoch 1627/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1205 - val_loss: 0.5606\n",
      "Epoch 1628/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1140 - val_loss: 0.5646\n",
      "Epoch 1629/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1135 - val_loss: 0.5872\n",
      "Epoch 1630/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.1238 - val_loss: 0.5682\n",
      "Epoch 1631/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1226 - val_loss: 0.5579\n",
      "Epoch 1632/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1184 - val_loss: 0.5612\n",
      "Epoch 1633/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.1207 - val_loss: 0.6073\n",
      "Epoch 1634/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1255 - val_loss: 0.5653\n",
      "Epoch 1635/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1174 - val_loss: 0.5952\n",
      "Epoch 1636/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1160 - val_loss: 0.5898\n",
      "Epoch 1637/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1127 - val_loss: 0.5821\n",
      "Epoch 1638/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1213 - val_loss: 0.5775\n",
      "Epoch 1639/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.1213 - val_loss: 0.5799\n",
      "Epoch 1640/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1207 - val_loss: 0.5596\n",
      "Epoch 1641/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1149 - val_loss: 0.5969\n",
      "Epoch 1642/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1191 - val_loss: 0.6031\n",
      "Epoch 1643/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.1439 - val_loss: 0.6045\n",
      "Epoch 1644/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1185 - val_loss: 0.5701\n",
      "Epoch 1645/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1143 - val_loss: 0.5917\n",
      "Epoch 1646/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1178 - val_loss: 0.5867\n",
      "Epoch 1647/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.1108 - val_loss: 0.5722\n",
      "Epoch 1648/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.1130 - val_loss: 0.6037\n",
      "Epoch 1649/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1190 - val_loss: 0.5623\n",
      "Epoch 1650/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1109 - val_loss: 0.5890\n",
      "Epoch 1651/10000\n",
      "130/130 [==============================] - 0s 858us/step - loss: 0.1187 - val_loss: 0.5746\n",
      "Epoch 1652/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1183 - val_loss: 0.5670\n",
      "Epoch 1653/10000\n",
      "130/130 [==============================] - 0s 871us/step - loss: 0.1215 - val_loss: 0.5851\n",
      "Epoch 1654/10000\n",
      "130/130 [==============================] - 0s 803us/step - loss: 0.1170 - val_loss: 0.5670\n",
      "Epoch 1655/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.1248 - val_loss: 0.5779\n",
      "Epoch 1656/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1113 - val_loss: 0.5597\n",
      "Epoch 1657/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1157 - val_loss: 0.5970\n",
      "Epoch 1658/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.1171 - val_loss: 0.5740\n",
      "Epoch 1659/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1157 - val_loss: 0.5888\n",
      "Epoch 1660/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1200 - val_loss: 0.5732\n",
      "Epoch 1661/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1106 - val_loss: 0.5786\n",
      "Epoch 1662/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.1116 - val_loss: 0.5963\n",
      "Epoch 1663/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1140 - val_loss: 0.5718\n",
      "Epoch 1664/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1258 - val_loss: 0.5923\n",
      "Epoch 1665/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1207 - val_loss: 0.5936\n",
      "Epoch 1666/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1150 - val_loss: 0.5793\n",
      "Epoch 1667/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1189 - val_loss: 0.5915\n",
      "Epoch 1668/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1147 - val_loss: 0.5836\n",
      "Epoch 1669/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1113 - val_loss: 0.5984\n",
      "Epoch 1670/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1151 - val_loss: 0.6081\n",
      "Epoch 1671/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1190 - val_loss: 0.5618\n",
      "Epoch 1672/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1140 - val_loss: 0.5670\n",
      "Epoch 1673/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1128 - val_loss: 0.6013\n",
      "Epoch 1674/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1105 - val_loss: 0.5745\n",
      "Epoch 1675/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 745us/step - loss: 0.1143 - val_loss: 0.5890\n",
      "Epoch 1676/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1176 - val_loss: 0.5641\n",
      "Epoch 1677/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1129 - val_loss: 0.5947\n",
      "Epoch 1678/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1121 - val_loss: 0.5890\n",
      "Epoch 1679/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1188 - val_loss: 0.5731\n",
      "Epoch 1680/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1138 - val_loss: 0.5815\n",
      "Epoch 1681/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1287 - val_loss: 0.5964\n",
      "Epoch 1682/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1236 - val_loss: 0.5682\n",
      "Epoch 1683/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1073 - val_loss: 0.5719\n",
      "Epoch 1684/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1115 - val_loss: 0.5845\n",
      "Epoch 1685/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1249 - val_loss: 0.5967\n",
      "Epoch 1686/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1201 - val_loss: 0.5902\n",
      "Epoch 1687/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1110 - val_loss: 0.6076\n",
      "Epoch 1688/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1403 - val_loss: 0.5895\n",
      "Epoch 1689/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1077 - val_loss: 0.5837\n",
      "Epoch 1690/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1133 - val_loss: 0.5875\n",
      "Epoch 1691/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1155 - val_loss: 0.5758\n",
      "Epoch 1692/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1151 - val_loss: 0.5648\n",
      "Epoch 1693/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1097 - val_loss: 0.5746\n",
      "Epoch 1694/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1134 - val_loss: 0.5729\n",
      "Epoch 1695/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1100 - val_loss: 0.5714\n",
      "Epoch 1696/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1139 - val_loss: 0.5939\n",
      "Epoch 1697/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1061 - val_loss: 0.5865\n",
      "Epoch 1698/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1083 - val_loss: 0.5830\n",
      "Epoch 1699/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1137 - val_loss: 0.5747\n",
      "Epoch 1700/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1125 - val_loss: 0.6047\n",
      "Epoch 1701/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1149 - val_loss: 0.6072\n",
      "Epoch 1702/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1104 - val_loss: 0.5656\n",
      "Epoch 1703/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1241 - val_loss: 0.5946\n",
      "Epoch 1704/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1126 - val_loss: 0.5864\n",
      "Epoch 1705/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1098 - val_loss: 0.5888\n",
      "Epoch 1706/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1117 - val_loss: 0.5913\n",
      "Epoch 1707/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1051 - val_loss: 0.5922\n",
      "Epoch 1708/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1076 - val_loss: 0.5775\n",
      "Epoch 1709/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1116 - val_loss: 0.5836\n",
      "Epoch 1710/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1055 - val_loss: 0.5963\n",
      "Epoch 1711/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1126 - val_loss: 0.5694\n",
      "Epoch 1712/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1130 - val_loss: 0.5623\n",
      "Epoch 1713/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1086 - val_loss: 0.5960\n",
      "Epoch 1714/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1065 - val_loss: 0.5859\n",
      "Epoch 1715/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1194 - val_loss: 0.5817\n",
      "Epoch 1716/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1088 - val_loss: 0.5756\n",
      "Epoch 1717/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1284 - val_loss: 0.6073\n",
      "Epoch 1718/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1067 - val_loss: 0.5702\n",
      "Epoch 1719/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1084 - val_loss: 0.5913\n",
      "Epoch 1720/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1098 - val_loss: 0.5782\n",
      "Epoch 1721/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1110 - val_loss: 0.5727\n",
      "Epoch 1722/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1131 - val_loss: 0.5829\n",
      "Epoch 1723/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1031 - val_loss: 0.5891\n",
      "Epoch 1724/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1045 - val_loss: 0.5983\n",
      "Epoch 1725/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1120 - val_loss: 0.5945\n",
      "Epoch 1726/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1142 - val_loss: 0.5752\n",
      "Epoch 1727/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1145 - val_loss: 0.5764\n",
      "Epoch 1728/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1098 - val_loss: 0.5730\n",
      "Epoch 1729/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1063 - val_loss: 0.5842\n",
      "Epoch 1730/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1059 - val_loss: 0.5791\n",
      "Epoch 1731/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1031 - val_loss: 0.5813\n",
      "Epoch 1732/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1122 - val_loss: 0.5937\n",
      "Epoch 1733/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1063 - val_loss: 0.5703\n",
      "Epoch 1734/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1103 - val_loss: 0.6004\n",
      "Epoch 1735/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1128 - val_loss: 0.5699\n",
      "Epoch 1736/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1074 - val_loss: 0.6009\n",
      "Epoch 1737/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1226 - val_loss: 0.5793\n",
      "Epoch 1738/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1109 - val_loss: 0.6109\n",
      "Epoch 1739/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.1142 - val_loss: 0.5941\n",
      "Epoch 1740/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1050 - val_loss: 0.5910\n",
      "Epoch 1741/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.1105 - val_loss: 0.5980\n",
      "Epoch 1742/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1074 - val_loss: 0.5849\n",
      "Epoch 1743/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1121 - val_loss: 0.5808\n",
      "Epoch 1744/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1101 - val_loss: 0.5739\n",
      "Epoch 1745/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.1089 - val_loss: 0.5666\n",
      "Epoch 1746/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.1081 - val_loss: 0.5855\n",
      "Epoch 1747/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1048 - val_loss: 0.5913\n",
      "Epoch 1748/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.1061 - val_loss: 0.5799\n",
      "Epoch 1749/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1142 - val_loss: 0.5734\n",
      "Epoch 1750/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0990 - val_loss: 0.5727\n",
      "Epoch 1751/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 762us/step - loss: 0.1070 - val_loss: 0.5941\n",
      "Epoch 1752/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1118 - val_loss: 0.5838\n",
      "Epoch 1753/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1104 - val_loss: 0.6019\n",
      "Epoch 1754/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1049 - val_loss: 0.5822\n",
      "Epoch 1755/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.1081 - val_loss: 0.5995\n",
      "Epoch 1756/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1309 - val_loss: 0.5903\n",
      "Epoch 1757/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1108 - val_loss: 0.6204\n",
      "Epoch 1758/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1038 - val_loss: 0.5998\n",
      "Epoch 1759/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1014 - val_loss: 0.5693\n",
      "Epoch 1760/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1026 - val_loss: 0.5711\n",
      "Epoch 1761/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1039 - val_loss: 0.6068\n",
      "Epoch 1762/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1056 - val_loss: 0.5985\n",
      "Epoch 1763/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1147 - val_loss: 0.5730\n",
      "Epoch 1764/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1093 - val_loss: 0.5910\n",
      "Epoch 1765/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1130 - val_loss: 0.5917\n",
      "Epoch 1766/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1235 - val_loss: 0.5902\n",
      "Epoch 1767/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1072 - val_loss: 0.5942\n",
      "Epoch 1768/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.1044 - val_loss: 0.5819\n",
      "Epoch 1769/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0998 - val_loss: 0.5847\n",
      "Epoch 1770/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1132 - val_loss: 0.5802\n",
      "Epoch 1771/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1098 - val_loss: 0.6055\n",
      "Epoch 1772/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1110 - val_loss: 0.5972\n",
      "Epoch 1773/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1108 - val_loss: 0.5790\n",
      "Epoch 1774/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1042 - val_loss: 0.5839\n",
      "Epoch 1775/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1033 - val_loss: 0.5721\n",
      "Epoch 1776/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1012 - val_loss: 0.5893\n",
      "Epoch 1777/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1095 - val_loss: 0.5797\n",
      "Epoch 1778/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1098 - val_loss: 0.5810\n",
      "Epoch 1779/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1045 - val_loss: 0.5968\n",
      "Epoch 1780/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1167 - val_loss: 0.5968\n",
      "Epoch 1781/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.1079 - val_loss: 0.5738\n",
      "Epoch 1782/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.1011 - val_loss: 0.6006\n",
      "Epoch 1783/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.1056 - val_loss: 0.5900\n",
      "Epoch 1784/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1062 - val_loss: 0.5927\n",
      "Epoch 1785/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1048 - val_loss: 0.5894\n",
      "Epoch 1786/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1091 - val_loss: 0.6325\n",
      "Epoch 1787/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.1160 - val_loss: 0.5829\n",
      "Epoch 1788/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1056 - val_loss: 0.5922\n",
      "Epoch 1789/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1029 - val_loss: 0.5773\n",
      "Epoch 1790/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1085 - val_loss: 0.5846\n",
      "Epoch 1791/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1164 - val_loss: 0.5803\n",
      "Epoch 1792/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.1015 - val_loss: 0.5719\n",
      "Epoch 1793/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1045 - val_loss: 0.5867\n",
      "Epoch 1794/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.1179 - val_loss: 0.5728\n",
      "Epoch 1795/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0968 - val_loss: 0.5936\n",
      "Epoch 1796/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1003 - val_loss: 0.5760\n",
      "Epoch 1797/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0999 - val_loss: 0.5975\n",
      "Epoch 1798/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1025 - val_loss: 0.5905\n",
      "Epoch 1799/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1017 - val_loss: 0.6030\n",
      "Epoch 1800/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.1066 - val_loss: 0.5758\n",
      "Epoch 1801/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.1043 - val_loss: 0.5872\n",
      "Epoch 1802/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1137 - val_loss: 0.5799\n",
      "Epoch 1803/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1077 - val_loss: 0.5802\n",
      "Epoch 1804/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1145 - val_loss: 0.6206\n",
      "Epoch 1805/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1094 - val_loss: 0.5793\n",
      "Epoch 1806/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0970 - val_loss: 0.5773\n",
      "Epoch 1807/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1004 - val_loss: 0.6278\n",
      "Epoch 1808/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1074 - val_loss: 0.5757\n",
      "Epoch 1809/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1040 - val_loss: 0.5885\n",
      "Epoch 1810/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1082 - val_loss: 0.5865\n",
      "Epoch 1811/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.1002 - val_loss: 0.5708\n",
      "Epoch 1812/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0996 - val_loss: 0.6039\n",
      "Epoch 1813/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1059 - val_loss: 0.5860\n",
      "Epoch 1814/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0993 - val_loss: 0.5817\n",
      "Epoch 1815/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0975 - val_loss: 0.5976\n",
      "Epoch 1816/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1009 - val_loss: 0.5993\n",
      "Epoch 1817/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1059 - val_loss: 0.6064\n",
      "Epoch 1818/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0967 - val_loss: 0.5871\n",
      "Epoch 1819/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0985 - val_loss: 0.6112\n",
      "Epoch 1820/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1098 - val_loss: 0.5840\n",
      "Epoch 1821/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0915 - val_loss: 0.5830\n",
      "Epoch 1822/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0990 - val_loss: 0.5722\n",
      "Epoch 1823/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.1092 - val_loss: 0.5964\n",
      "Epoch 1824/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1032 - val_loss: 0.5800\n",
      "Epoch 1825/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.1035 - val_loss: 0.5903\n",
      "Epoch 1826/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0997 - val_loss: 0.5854\n",
      "Epoch 1827/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 748us/step - loss: 0.0991 - val_loss: 0.5978\n",
      "Epoch 1828/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.1046 - val_loss: 0.5884\n",
      "Epoch 1829/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0995 - val_loss: 0.5778\n",
      "Epoch 1830/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0932 - val_loss: 0.5808\n",
      "Epoch 1831/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1063 - val_loss: 0.6084\n",
      "Epoch 1832/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1118 - val_loss: 0.6270\n",
      "Epoch 1833/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1065 - val_loss: 0.5966\n",
      "Epoch 1834/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0982 - val_loss: 0.6169\n",
      "Epoch 1835/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1013 - val_loss: 0.5960\n",
      "Epoch 1836/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.1015 - val_loss: 0.5931\n",
      "Epoch 1837/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0990 - val_loss: 0.5948\n",
      "Epoch 1838/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0963 - val_loss: 0.6147\n",
      "Epoch 1839/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0987 - val_loss: 0.6096\n",
      "Epoch 1840/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0985 - val_loss: 0.5764\n",
      "Epoch 1841/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0966 - val_loss: 0.5931\n",
      "Epoch 1842/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1010 - val_loss: 0.5968\n",
      "Epoch 1843/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.1022 - val_loss: 0.5869\n",
      "Epoch 1844/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0996 - val_loss: 0.5950\n",
      "Epoch 1845/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0952 - val_loss: 0.6039\n",
      "Epoch 1846/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1038 - val_loss: 0.5897\n",
      "Epoch 1847/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1170 - val_loss: 0.5856\n",
      "Epoch 1848/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.1004 - val_loss: 0.5862\n",
      "Epoch 1849/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0974 - val_loss: 0.5847\n",
      "Epoch 1850/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0946 - val_loss: 0.5846\n",
      "Epoch 1851/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0956 - val_loss: 0.5936\n",
      "Epoch 1852/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.1073 - val_loss: 0.5863\n",
      "Epoch 1853/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0998 - val_loss: 0.5900\n",
      "Epoch 1854/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.1029 - val_loss: 0.5920\n",
      "Epoch 1855/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0982 - val_loss: 0.6147\n",
      "Epoch 1856/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0981 - val_loss: 0.5903\n",
      "Epoch 1857/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0965 - val_loss: 0.5807\n",
      "Epoch 1858/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0956 - val_loss: 0.5776\n",
      "Epoch 1859/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0983 - val_loss: 0.5960\n",
      "Epoch 1860/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0972 - val_loss: 0.5976\n",
      "Epoch 1861/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0976 - val_loss: 0.5870\n",
      "Epoch 1862/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0949 - val_loss: 0.5838\n",
      "Epoch 1863/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1070 - val_loss: 0.5991\n",
      "Epoch 1864/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1060 - val_loss: 0.5920\n",
      "Epoch 1865/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1050 - val_loss: 0.5792\n",
      "Epoch 1866/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0912 - val_loss: 0.6020\n",
      "Epoch 1867/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.1010 - val_loss: 0.5707\n",
      "Epoch 1868/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1085 - val_loss: 0.5895\n",
      "Epoch 1869/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.1013 - val_loss: 0.5991\n",
      "Epoch 1870/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0996 - val_loss: 0.5853\n",
      "Epoch 1871/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1011 - val_loss: 0.6018\n",
      "Epoch 1872/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0928 - val_loss: 0.6122\n",
      "Epoch 1873/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0973 - val_loss: 0.6295\n",
      "Epoch 1874/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1148 - val_loss: 0.5838\n",
      "Epoch 1875/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0963 - val_loss: 0.6252\n",
      "Epoch 1876/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0928 - val_loss: 0.5941\n",
      "Epoch 1877/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0982 - val_loss: 0.6022\n",
      "Epoch 1878/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1078 - val_loss: 0.6112\n",
      "Epoch 1879/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0990 - val_loss: 0.5866\n",
      "Epoch 1880/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0996 - val_loss: 0.5855\n",
      "Epoch 1881/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0935 - val_loss: 0.6037\n",
      "Epoch 1882/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0945 - val_loss: 0.5779\n",
      "Epoch 1883/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1031 - val_loss: 0.5960\n",
      "Epoch 1884/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.1073 - val_loss: 0.5816\n",
      "Epoch 1885/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.1009 - val_loss: 0.5844\n",
      "Epoch 1886/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0947 - val_loss: 0.5863\n",
      "Epoch 1887/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0974 - val_loss: 0.5980\n",
      "Epoch 1888/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.1009 - val_loss: 0.5791\n",
      "Epoch 1889/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0904 - val_loss: 0.6052\n",
      "Epoch 1890/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0973 - val_loss: 0.5818\n",
      "Epoch 1891/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1029 - val_loss: 0.5933\n",
      "Epoch 1892/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0974 - val_loss: 0.5832\n",
      "Epoch 1893/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0962 - val_loss: 0.5921\n",
      "Epoch 1894/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0924 - val_loss: 0.5726\n",
      "Epoch 1895/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0947 - val_loss: 0.5676\n",
      "Epoch 1896/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.1011 - val_loss: 0.5815\n",
      "Epoch 1897/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0976 - val_loss: 0.5909\n",
      "Epoch 1898/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0940 - val_loss: 0.5774\n",
      "Epoch 1899/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.1000 - val_loss: 0.5971\n",
      "Epoch 1900/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0947 - val_loss: 0.5821\n",
      "Epoch 1901/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0907 - val_loss: 0.5832\n",
      "Epoch 1902/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0916 - val_loss: 0.6262\n",
      "Epoch 1903/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 754us/step - loss: 0.0924 - val_loss: 0.6036\n",
      "Epoch 1904/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0924 - val_loss: 0.5910\n",
      "Epoch 1905/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0980 - val_loss: 0.6025\n",
      "Epoch 1906/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0976 - val_loss: 0.5911\n",
      "Epoch 1907/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0944 - val_loss: 0.5871\n",
      "Epoch 1908/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0917 - val_loss: 0.5949\n",
      "Epoch 1909/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0937 - val_loss: 0.6020\n",
      "Epoch 1910/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0951 - val_loss: 0.5877\n",
      "Epoch 1911/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0911 - val_loss: 0.6117\n",
      "Epoch 1912/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0990 - val_loss: 0.5874\n",
      "Epoch 1913/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0892 - val_loss: 0.6070\n",
      "Epoch 1914/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0926 - val_loss: 0.5944\n",
      "Epoch 1915/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1012 - val_loss: 0.5803\n",
      "Epoch 1916/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.1035 - val_loss: 0.5868\n",
      "Epoch 1917/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0957 - val_loss: 0.5960\n",
      "Epoch 1918/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0968 - val_loss: 0.6344\n",
      "Epoch 1919/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0965 - val_loss: 0.6010\n",
      "Epoch 1920/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0999 - val_loss: 0.5988\n",
      "Epoch 1921/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0963 - val_loss: 0.6007\n",
      "Epoch 1922/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.1023 - val_loss: 0.5870\n",
      "Epoch 1923/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1033 - val_loss: 0.5984\n",
      "Epoch 1924/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0889 - val_loss: 0.5990\n",
      "Epoch 1925/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0891 - val_loss: 0.6080\n",
      "Epoch 1926/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0990 - val_loss: 0.6005\n",
      "Epoch 1927/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0962 - val_loss: 0.5964\n",
      "Epoch 1928/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.1004 - val_loss: 0.5881\n",
      "Epoch 1929/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0987 - val_loss: 0.5825\n",
      "Epoch 1930/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0929 - val_loss: 0.6076\n",
      "Epoch 1931/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0890 - val_loss: 0.5744\n",
      "Epoch 1932/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0921 - val_loss: 0.6008\n",
      "Epoch 1933/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0895 - val_loss: 0.5873\n",
      "Epoch 1934/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0941 - val_loss: 0.5894\n",
      "Epoch 1935/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0867 - val_loss: 0.5811\n",
      "Epoch 1936/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.1002 - val_loss: 0.5915\n",
      "Epoch 1937/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0976 - val_loss: 0.5996\n",
      "Epoch 1938/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0944 - val_loss: 0.6084\n",
      "Epoch 1939/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0991 - val_loss: 0.5944\n",
      "Epoch 1940/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0949 - val_loss: 0.5972\n",
      "Epoch 1941/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0947 - val_loss: 0.5764\n",
      "Epoch 1942/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0873 - val_loss: 0.5954\n",
      "Epoch 1943/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0969 - val_loss: 0.5940\n",
      "Epoch 1944/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0957 - val_loss: 0.6032\n",
      "Epoch 1945/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0976 - val_loss: 0.6077\n",
      "Epoch 1946/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0921 - val_loss: 0.5814\n",
      "Epoch 1947/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0980 - val_loss: 0.5874\n",
      "Epoch 1948/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0947 - val_loss: 0.6181\n",
      "Epoch 1949/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0969 - val_loss: 0.5718\n",
      "Epoch 1950/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0903 - val_loss: 0.5815\n",
      "Epoch 1951/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0891 - val_loss: 0.5760\n",
      "Epoch 1952/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0945 - val_loss: 0.6072\n",
      "Epoch 1953/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0935 - val_loss: 0.5766\n",
      "Epoch 1954/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0910 - val_loss: 0.6048\n",
      "Epoch 1955/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0924 - val_loss: 0.6050\n",
      "Epoch 1956/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0966 - val_loss: 0.6036\n",
      "Epoch 1957/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0868 - val_loss: 0.6021\n",
      "Epoch 1958/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0998 - val_loss: 0.5866\n",
      "Epoch 1959/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0969 - val_loss: 0.5842\n",
      "Epoch 1960/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0914 - val_loss: 0.5767\n",
      "Epoch 1961/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0854 - val_loss: 0.5992\n",
      "Epoch 1962/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0883 - val_loss: 0.5801\n",
      "Epoch 1963/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0980 - val_loss: 0.5908\n",
      "Epoch 1964/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0876 - val_loss: 0.6031\n",
      "Epoch 1965/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0926 - val_loss: 0.6040\n",
      "Epoch 1966/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.1038 - val_loss: 0.5875\n",
      "Epoch 1967/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1011 - val_loss: 0.5903\n",
      "Epoch 1968/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0939 - val_loss: 0.5889\n",
      "Epoch 1969/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0920 - val_loss: 0.6059\n",
      "Epoch 1970/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0918 - val_loss: 0.6064\n",
      "Epoch 1971/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0902 - val_loss: 0.6132\n",
      "Epoch 1972/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0845 - val_loss: 0.5982\n",
      "Epoch 1973/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0848 - val_loss: 0.6303\n",
      "Epoch 1974/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0857 - val_loss: 0.5958\n",
      "Epoch 1975/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0890 - val_loss: 0.5881\n",
      "Epoch 1976/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0857 - val_loss: 0.6139\n",
      "Epoch 1977/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0865 - val_loss: 0.5788\n",
      "Epoch 1978/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0939 - val_loss: 0.6009\n",
      "Epoch 1979/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 761us/step - loss: 0.0861 - val_loss: 0.6116\n",
      "Epoch 1980/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0908 - val_loss: 0.5783\n",
      "Epoch 1981/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0998 - val_loss: 0.6129\n",
      "Epoch 1982/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0941 - val_loss: 0.5975\n",
      "Epoch 1983/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0865 - val_loss: 0.6014\n",
      "Epoch 1984/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0864 - val_loss: 0.6662\n",
      "Epoch 1985/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0993 - val_loss: 0.6000\n",
      "Epoch 1986/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0904 - val_loss: 0.6391\n",
      "Epoch 1987/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0995 - val_loss: 0.5922\n",
      "Epoch 1988/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0916 - val_loss: 0.6043\n",
      "Epoch 1989/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0913 - val_loss: 0.6137\n",
      "Epoch 1990/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0884 - val_loss: 0.5913\n",
      "Epoch 1991/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0900 - val_loss: 0.6088\n",
      "Epoch 1992/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0893 - val_loss: 0.5893\n",
      "Epoch 1993/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0943 - val_loss: 0.5733\n",
      "Epoch 1994/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0853 - val_loss: 0.6022\n",
      "Epoch 1995/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0846 - val_loss: 0.6144\n",
      "Epoch 1996/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.1004 - val_loss: 0.5789\n",
      "Epoch 1997/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0887 - val_loss: 0.6324\n",
      "Epoch 1998/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.1071 - val_loss: 0.5999\n",
      "Epoch 1999/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0863 - val_loss: 0.5981\n",
      "Epoch 2000/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0892 - val_loss: 0.6017\n",
      "Epoch 2001/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0887 - val_loss: 0.5970\n",
      "Epoch 2002/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0861 - val_loss: 0.5908\n",
      "Epoch 2003/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0912 - val_loss: 0.5985\n",
      "Epoch 2004/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0868 - val_loss: 0.6035\n",
      "Epoch 2005/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0833 - val_loss: 0.5918\n",
      "Epoch 2006/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0800 - val_loss: 0.5827\n",
      "Epoch 2007/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0991 - val_loss: 0.6085\n",
      "Epoch 2008/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0901 - val_loss: 0.5931\n",
      "Epoch 2009/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0882 - val_loss: 0.5904\n",
      "Epoch 2010/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0853 - val_loss: 0.5972\n",
      "Epoch 2011/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0842 - val_loss: 0.6059\n",
      "Epoch 2012/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0840 - val_loss: 0.6116\n",
      "Epoch 2013/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0891 - val_loss: 0.6082\n",
      "Epoch 2014/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0918 - val_loss: 0.6095\n",
      "Epoch 2015/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0861 - val_loss: 0.5967\n",
      "Epoch 2016/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0841 - val_loss: 0.5763\n",
      "Epoch 2017/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0809 - val_loss: 0.6095\n",
      "Epoch 2018/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0952 - val_loss: 0.5864\n",
      "Epoch 2019/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0922 - val_loss: 0.6219\n",
      "Epoch 2020/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0872 - val_loss: 0.6092\n",
      "Epoch 2021/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0890 - val_loss: 0.5886\n",
      "Epoch 2022/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0866 - val_loss: 0.5909\n",
      "Epoch 2023/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0855 - val_loss: 0.6124\n",
      "Epoch 2024/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0942 - val_loss: 0.5791\n",
      "Epoch 2025/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0905 - val_loss: 0.5725\n",
      "Epoch 2026/10000\n",
      "130/130 [==============================] - 0s 832us/step - loss: 0.0900 - val_loss: 0.5798\n",
      "Epoch 2027/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0821 - val_loss: 0.6134\n",
      "Epoch 2028/10000\n",
      "130/130 [==============================] - 0s 792us/step - loss: 0.0884 - val_loss: 0.6259\n",
      "Epoch 2029/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0855 - val_loss: 0.6021\n",
      "Epoch 2030/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0860 - val_loss: 0.5756\n",
      "Epoch 2031/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0931 - val_loss: 0.6000\n",
      "Epoch 2032/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0907 - val_loss: 0.5850\n",
      "Epoch 2033/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0787 - val_loss: 0.5963\n",
      "Epoch 2034/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0862 - val_loss: 0.5983\n",
      "Epoch 2035/10000\n",
      "130/130 [==============================] - 0s 821us/step - loss: 0.0831 - val_loss: 0.6180\n",
      "Epoch 2036/10000\n",
      "130/130 [==============================] - 0s 904us/step - loss: 0.0884 - val_loss: 0.6057\n",
      "Epoch 2037/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0894 - val_loss: 0.6046\n",
      "Epoch 2038/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0849 - val_loss: 0.5932\n",
      "Epoch 2039/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0905 - val_loss: 0.5757\n",
      "Epoch 2040/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0953 - val_loss: 0.6002\n",
      "Epoch 2041/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0875 - val_loss: 0.6222\n",
      "Epoch 2042/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0853 - val_loss: 0.6014\n",
      "Epoch 2043/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0872 - val_loss: 0.5841\n",
      "Epoch 2044/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0853 - val_loss: 0.5918\n",
      "Epoch 2045/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0902 - val_loss: 0.6239\n",
      "Epoch 2046/10000\n",
      "130/130 [==============================] - 0s 933us/step - loss: 0.0916 - val_loss: 0.5897\n",
      "Epoch 2047/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0883 - val_loss: 0.5973\n",
      "Epoch 2048/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0870 - val_loss: 0.6046\n",
      "Epoch 2049/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0870 - val_loss: 0.5846\n",
      "Epoch 2050/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0831 - val_loss: 0.6316\n",
      "Epoch 2051/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0899 - val_loss: 0.6150\n",
      "Epoch 2052/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0852 - val_loss: 0.6005\n",
      "Epoch 2053/10000\n",
      "130/130 [==============================] - 0s 809us/step - loss: 0.0938 - val_loss: 0.5925\n",
      "Epoch 2054/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0828 - val_loss: 0.6036\n",
      "Epoch 2055/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 812us/step - loss: 0.0822 - val_loss: 0.6294\n",
      "Epoch 2056/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0835 - val_loss: 0.5768\n",
      "Epoch 2057/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0794 - val_loss: 0.5907\n",
      "Epoch 2058/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0823 - val_loss: 0.5997\n",
      "Epoch 2059/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0922 - val_loss: 0.5797\n",
      "Epoch 2060/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0863 - val_loss: 0.6099\n",
      "Epoch 2061/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0896 - val_loss: 0.5932\n",
      "Epoch 2062/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0835 - val_loss: 0.6021\n",
      "Epoch 2063/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0822 - val_loss: 0.6086\n",
      "Epoch 2064/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0879 - val_loss: 0.5939\n",
      "Epoch 2065/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0857 - val_loss: 0.6241\n",
      "Epoch 2066/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0850 - val_loss: 0.6071\n",
      "Epoch 2067/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0934 - val_loss: 0.6035\n",
      "Epoch 2068/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0899 - val_loss: 0.5927\n",
      "Epoch 2069/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0822 - val_loss: 0.5927\n",
      "Epoch 2070/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0838 - val_loss: 0.5957\n",
      "Epoch 2071/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0838 - val_loss: 0.5996\n",
      "Epoch 2072/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0875 - val_loss: 0.5982\n",
      "Epoch 2073/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0822 - val_loss: 0.5947\n",
      "Epoch 2074/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0820 - val_loss: 0.6013\n",
      "Epoch 2075/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0959 - val_loss: 0.6095\n",
      "Epoch 2076/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0851 - val_loss: 0.6088\n",
      "Epoch 2077/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0772 - val_loss: 0.5937\n",
      "Epoch 2078/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0840 - val_loss: 0.5954\n",
      "Epoch 2079/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0767 - val_loss: 0.5978\n",
      "Epoch 2080/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0823 - val_loss: 0.5869\n",
      "Epoch 2081/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0818 - val_loss: 0.5961\n",
      "Epoch 2082/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0830 - val_loss: 0.5988\n",
      "Epoch 2083/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0853 - val_loss: 0.6166\n",
      "Epoch 2084/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0927 - val_loss: 0.5966\n",
      "Epoch 2085/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0780 - val_loss: 0.6143\n",
      "Epoch 2086/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0885 - val_loss: 0.5884\n",
      "Epoch 2087/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0746 - val_loss: 0.6052\n",
      "Epoch 2088/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0874 - val_loss: 0.6206\n",
      "Epoch 2089/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0842 - val_loss: 0.5978\n",
      "Epoch 2090/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0726 - val_loss: 0.6086\n",
      "Epoch 2091/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0897 - val_loss: 0.6186\n",
      "Epoch 2092/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0817 - val_loss: 0.5756\n",
      "Epoch 2093/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0788 - val_loss: 0.5915\n",
      "Epoch 2094/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0774 - val_loss: 0.6311\n",
      "Epoch 2095/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0868 - val_loss: 0.5981\n",
      "Epoch 2096/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0871 - val_loss: 0.6055\n",
      "Epoch 2097/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0815 - val_loss: 0.6079\n",
      "Epoch 2098/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0855 - val_loss: 0.5993\n",
      "Epoch 2099/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0859 - val_loss: 0.5964\n",
      "Epoch 2100/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0836 - val_loss: 0.5912\n",
      "Epoch 2101/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0833 - val_loss: 0.6062\n",
      "Epoch 2102/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0812 - val_loss: 0.6074\n",
      "Epoch 2103/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0845 - val_loss: 0.5923\n",
      "Epoch 2104/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0804 - val_loss: 0.6008\n",
      "Epoch 2105/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0786 - val_loss: 0.6086\n",
      "Epoch 2106/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0800 - val_loss: 0.6020\n",
      "Epoch 2107/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0790 - val_loss: 0.6247\n",
      "Epoch 2108/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0835 - val_loss: 0.6033\n",
      "Epoch 2109/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0841 - val_loss: 0.6027\n",
      "Epoch 2110/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0839 - val_loss: 0.5824\n",
      "Epoch 2111/10000\n",
      "130/130 [==============================] - 0s 816us/step - loss: 0.0896 - val_loss: 0.5871\n",
      "Epoch 2112/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0842 - val_loss: 0.5922\n",
      "Epoch 2113/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0809 - val_loss: 0.6062\n",
      "Epoch 2114/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0783 - val_loss: 0.6055\n",
      "Epoch 2115/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0828 - val_loss: 0.5970\n",
      "Epoch 2116/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0787 - val_loss: 0.5920\n",
      "Epoch 2117/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0822 - val_loss: 0.5899\n",
      "Epoch 2118/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0760 - val_loss: 0.5956\n",
      "Epoch 2119/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0917 - val_loss: 0.5741\n",
      "Epoch 2120/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0775 - val_loss: 0.6225\n",
      "Epoch 2121/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0788 - val_loss: 0.5906\n",
      "Epoch 2122/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0755 - val_loss: 0.6117\n",
      "Epoch 2123/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0791 - val_loss: 0.5956\n",
      "Epoch 2124/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0828 - val_loss: 0.6102\n",
      "Epoch 2125/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0887 - val_loss: 0.6070\n",
      "Epoch 2126/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0821 - val_loss: 0.6007\n",
      "Epoch 2127/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0802 - val_loss: 0.5976\n",
      "Epoch 2128/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0896 - val_loss: 0.6043\n",
      "Epoch 2129/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0864 - val_loss: 0.6045\n",
      "Epoch 2130/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0809 - val_loss: 0.5874\n",
      "Epoch 2131/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 737us/step - loss: 0.0814 - val_loss: 0.6125\n",
      "Epoch 2132/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0777 - val_loss: 0.6013\n",
      "Epoch 2133/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0787 - val_loss: 0.5845\n",
      "Epoch 2134/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0813 - val_loss: 0.6057\n",
      "Epoch 2135/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0833 - val_loss: 0.6056\n",
      "Epoch 2136/10000\n",
      "130/130 [==============================] - 0s 848us/step - loss: 0.0863 - val_loss: 0.6051\n",
      "Epoch 2137/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0828 - val_loss: 0.5866\n",
      "Epoch 2138/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0779 - val_loss: 0.5968\n",
      "Epoch 2139/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0771 - val_loss: 0.6080\n",
      "Epoch 2140/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0768 - val_loss: 0.5993\n",
      "Epoch 2141/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0746 - val_loss: 0.6057\n",
      "Epoch 2142/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0880 - val_loss: 0.6098\n",
      "Epoch 2143/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0806 - val_loss: 0.5784\n",
      "Epoch 2144/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0851 - val_loss: 0.6097\n",
      "Epoch 2145/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0816 - val_loss: 0.5954\n",
      "Epoch 2146/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0859 - val_loss: 0.5992\n",
      "Epoch 2147/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0741 - val_loss: 0.5868\n",
      "Epoch 2148/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0752 - val_loss: 0.6107\n",
      "Epoch 2149/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0792 - val_loss: 0.6032\n",
      "Epoch 2150/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0778 - val_loss: 0.6058\n",
      "Epoch 2151/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0768 - val_loss: 0.5863\n",
      "Epoch 2152/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0771 - val_loss: 0.5993\n",
      "Epoch 2153/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0904 - val_loss: 0.6211\n",
      "Epoch 2154/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0819 - val_loss: 0.5996\n",
      "Epoch 2155/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0762 - val_loss: 0.6034\n",
      "Epoch 2156/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0759 - val_loss: 0.5863\n",
      "Epoch 2157/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0771 - val_loss: 0.5924\n",
      "Epoch 2158/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0817 - val_loss: 0.6167\n",
      "Epoch 2159/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0807 - val_loss: 0.5862\n",
      "Epoch 2160/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0818 - val_loss: 0.5820\n",
      "Epoch 2161/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0808 - val_loss: 0.5938\n",
      "Epoch 2162/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0744 - val_loss: 0.6033\n",
      "Epoch 2163/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0863 - val_loss: 0.5960\n",
      "Epoch 2164/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0829 - val_loss: 0.6174\n",
      "Epoch 2165/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0827 - val_loss: 0.5853\n",
      "Epoch 2166/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0806 - val_loss: 0.5908\n",
      "Epoch 2167/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0806 - val_loss: 0.6163\n",
      "Epoch 2168/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0754 - val_loss: 0.6082\n",
      "Epoch 2169/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0729 - val_loss: 0.6070\n",
      "Epoch 2170/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0751 - val_loss: 0.5894\n",
      "Epoch 2171/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0758 - val_loss: 0.5976\n",
      "Epoch 2172/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0746 - val_loss: 0.5884\n",
      "Epoch 2173/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0860 - val_loss: 0.6146\n",
      "Epoch 2174/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0800 - val_loss: 0.6008\n",
      "Epoch 2175/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0777 - val_loss: 0.6117\n",
      "Epoch 2176/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0881 - val_loss: 0.6118\n",
      "Epoch 2177/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0834 - val_loss: 0.5963\n",
      "Epoch 2178/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0765 - val_loss: 0.6076\n",
      "Epoch 2179/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0822 - val_loss: 0.6084\n",
      "Epoch 2180/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0797 - val_loss: 0.6035\n",
      "Epoch 2181/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0798 - val_loss: 0.6081\n",
      "Epoch 2182/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0750 - val_loss: 0.6078\n",
      "Epoch 2183/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0767 - val_loss: 0.6057\n",
      "Epoch 2184/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0739 - val_loss: 0.6084\n",
      "Epoch 2185/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0726 - val_loss: 0.5914\n",
      "Epoch 2186/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0756 - val_loss: 0.6375\n",
      "Epoch 2187/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0805 - val_loss: 0.6128\n",
      "Epoch 2188/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0792 - val_loss: 0.5975\n",
      "Epoch 2189/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0725 - val_loss: 0.5958\n",
      "Epoch 2190/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0762 - val_loss: 0.6065\n",
      "Epoch 2191/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0789 - val_loss: 0.5996\n",
      "Epoch 2192/10000\n",
      "130/130 [==============================] - 0s 809us/step - loss: 0.0759 - val_loss: 0.6077\n",
      "Epoch 2193/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0844 - val_loss: 0.6191\n",
      "Epoch 2194/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0816 - val_loss: 0.6023\n",
      "Epoch 2195/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0685 - val_loss: 0.6110\n",
      "Epoch 2196/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0776 - val_loss: 0.5933\n",
      "Epoch 2197/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0868 - val_loss: 0.6104\n",
      "Epoch 2198/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0756 - val_loss: 0.5974\n",
      "Epoch 2199/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0724 - val_loss: 0.6280\n",
      "Epoch 2200/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0798 - val_loss: 0.6081\n",
      "Epoch 2201/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0778 - val_loss: 0.5982\n",
      "Epoch 2202/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0891 - val_loss: 0.5972\n",
      "Epoch 2203/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0815 - val_loss: 0.5822\n",
      "Epoch 2204/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0734 - val_loss: 0.6038\n",
      "Epoch 2205/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0700 - val_loss: 0.6209\n",
      "Epoch 2206/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0722 - val_loss: 0.5925\n",
      "Epoch 2207/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 726us/step - loss: 0.0743 - val_loss: 0.5873\n",
      "Epoch 2208/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0803 - val_loss: 0.5848\n",
      "Epoch 2209/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0852 - val_loss: 0.6080\n",
      "Epoch 2210/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0727 - val_loss: 0.5996\n",
      "Epoch 2211/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0711 - val_loss: 0.5947\n",
      "Epoch 2212/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0699 - val_loss: 0.6124\n",
      "Epoch 2213/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0707 - val_loss: 0.6088\n",
      "Epoch 2214/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0685 - val_loss: 0.6160\n",
      "Epoch 2215/10000\n",
      "130/130 [==============================] - 0s 814us/step - loss: 0.0684 - val_loss: 0.5989\n",
      "Epoch 2216/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0776 - val_loss: 0.5976\n",
      "Epoch 2217/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0747 - val_loss: 0.6117\n",
      "Epoch 2218/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0939 - val_loss: 0.5840\n",
      "Epoch 2219/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0794 - val_loss: 0.6079\n",
      "Epoch 2220/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0716 - val_loss: 0.5952\n",
      "Epoch 2221/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0739 - val_loss: 0.6101\n",
      "Epoch 2222/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0738 - val_loss: 0.6026\n",
      "Epoch 2223/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0762 - val_loss: 0.6047\n",
      "Epoch 2224/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0784 - val_loss: 0.5916\n",
      "Epoch 2225/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0937 - val_loss: 0.5899\n",
      "Epoch 2226/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0697 - val_loss: 0.5951\n",
      "Epoch 2227/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0718 - val_loss: 0.6222\n",
      "Epoch 2228/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0754 - val_loss: 0.5907\n",
      "Epoch 2229/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0694 - val_loss: 0.6002\n",
      "Epoch 2230/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0706 - val_loss: 0.6249\n",
      "Epoch 2231/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0736 - val_loss: 0.6017\n",
      "Epoch 2232/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0703 - val_loss: 0.5918\n",
      "Epoch 2233/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0732 - val_loss: 0.5992\n",
      "Epoch 2234/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0791 - val_loss: 0.6212\n",
      "Epoch 2235/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0764 - val_loss: 0.5998\n",
      "Epoch 2236/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0717 - val_loss: 0.6042\n",
      "Epoch 2237/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0792 - val_loss: 0.6269\n",
      "Epoch 2238/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0729 - val_loss: 0.6021\n",
      "Epoch 2239/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0756 - val_loss: 0.6057\n",
      "Epoch 2240/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0734 - val_loss: 0.6176\n",
      "Epoch 2241/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0753 - val_loss: 0.5939\n",
      "Epoch 2242/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0709 - val_loss: 0.5811\n",
      "Epoch 2243/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0829 - val_loss: 0.6086\n",
      "Epoch 2244/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0725 - val_loss: 0.5948\n",
      "Epoch 2245/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0729 - val_loss: 0.5910\n",
      "Epoch 2246/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0688 - val_loss: 0.6036\n",
      "Epoch 2247/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0748 - val_loss: 0.5991\n",
      "Epoch 2248/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0714 - val_loss: 0.6003\n",
      "Epoch 2249/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0758 - val_loss: 0.6144\n",
      "Epoch 2250/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0734 - val_loss: 0.5854\n",
      "Epoch 2251/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0712 - val_loss: 0.6031\n",
      "Epoch 2252/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0684 - val_loss: 0.6061\n",
      "Epoch 2253/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0804 - val_loss: 0.5928\n",
      "Epoch 2254/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0859 - val_loss: 0.6033\n",
      "Epoch 2255/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0724 - val_loss: 0.5868\n",
      "Epoch 2256/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0751 - val_loss: 0.6359\n",
      "Epoch 2257/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0794 - val_loss: 0.6137\n",
      "Epoch 2258/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0718 - val_loss: 0.5932\n",
      "Epoch 2259/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0692 - val_loss: 0.6014\n",
      "Epoch 2260/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0698 - val_loss: 0.6202\n",
      "Epoch 2261/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0782 - val_loss: 0.6187\n",
      "Epoch 2262/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.1072 - val_loss: 0.5906\n",
      "Epoch 2263/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0781 - val_loss: 0.5884\n",
      "Epoch 2264/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0670 - val_loss: 0.6094\n",
      "Epoch 2265/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0642 - val_loss: 0.5857\n",
      "Epoch 2266/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0715 - val_loss: 0.5936\n",
      "Epoch 2267/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0688 - val_loss: 0.5881\n",
      "Epoch 2268/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0667 - val_loss: 0.6126\n",
      "Epoch 2269/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0756 - val_loss: 0.5960\n",
      "Epoch 2270/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0667 - val_loss: 0.6096\n",
      "Epoch 2271/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0697 - val_loss: 0.6291\n",
      "Epoch 2272/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0755 - val_loss: 0.6155\n",
      "Epoch 2273/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0737 - val_loss: 0.6163\n",
      "Epoch 2274/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0806 - val_loss: 0.5905\n",
      "Epoch 2275/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0692 - val_loss: 0.6338\n",
      "Epoch 2276/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0691 - val_loss: 0.5963\n",
      "Epoch 2277/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0732 - val_loss: 0.6147\n",
      "Epoch 2278/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0712 - val_loss: 0.6070\n",
      "Epoch 2279/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0730 - val_loss: 0.6062\n",
      "Epoch 2280/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0676 - val_loss: 0.5888\n",
      "Epoch 2281/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0651 - val_loss: 0.6236\n",
      "Epoch 2282/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0688 - val_loss: 0.6286\n",
      "Epoch 2283/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 750us/step - loss: 0.0768 - val_loss: 0.6011\n",
      "Epoch 2284/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0777 - val_loss: 0.6054\n",
      "Epoch 2285/10000\n",
      "130/130 [==============================] - 0s 840us/step - loss: 0.0630 - val_loss: 0.6240\n",
      "Epoch 2286/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0688 - val_loss: 0.5798\n",
      "Epoch 2287/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0704 - val_loss: 0.5893\n",
      "Epoch 2288/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0746 - val_loss: 0.6092\n",
      "Epoch 2289/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0958 - val_loss: 0.6103\n",
      "Epoch 2290/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0739 - val_loss: 0.6384\n",
      "Epoch 2291/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0774 - val_loss: 0.5816\n",
      "Epoch 2292/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0701 - val_loss: 0.6152\n",
      "Epoch 2293/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0694 - val_loss: 0.6045\n",
      "Epoch 2294/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0768 - val_loss: 0.5900\n",
      "Epoch 2295/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0688 - val_loss: 0.6118\n",
      "Epoch 2296/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0743 - val_loss: 0.6022\n",
      "Epoch 2297/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0754 - val_loss: 0.5910\n",
      "Epoch 2298/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0701 - val_loss: 0.5980\n",
      "Epoch 2299/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0700 - val_loss: 0.6136\n",
      "Epoch 2300/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0697 - val_loss: 0.5992\n",
      "Epoch 2301/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0712 - val_loss: 0.6117\n",
      "Epoch 2302/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0710 - val_loss: 0.6174\n",
      "Epoch 2303/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0746 - val_loss: 0.6310\n",
      "Epoch 2304/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0822 - val_loss: 0.6161\n",
      "Epoch 2305/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0670 - val_loss: 0.5927\n",
      "Epoch 2306/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0662 - val_loss: 0.6357\n",
      "Epoch 2307/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0789 - val_loss: 0.5903\n",
      "Epoch 2308/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0718 - val_loss: 0.6053\n",
      "Epoch 2309/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0752 - val_loss: 0.6078\n",
      "Epoch 2310/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0693 - val_loss: 0.5951\n",
      "Epoch 2311/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0729 - val_loss: 0.5984\n",
      "Epoch 2312/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0671 - val_loss: 0.6164\n",
      "Epoch 2313/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0695 - val_loss: 0.6074\n",
      "Epoch 2314/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0739 - val_loss: 0.6028\n",
      "Epoch 2315/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0705 - val_loss: 0.5762\n",
      "Epoch 2316/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0661 - val_loss: 0.5961\n",
      "Epoch 2317/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0647 - val_loss: 0.6132\n",
      "Epoch 2318/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0908 - val_loss: 0.5678\n",
      "Epoch 2319/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0709 - val_loss: 0.5963\n",
      "Epoch 2320/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0651 - val_loss: 0.6013\n",
      "Epoch 2321/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0649 - val_loss: 0.5872\n",
      "Epoch 2322/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0668 - val_loss: 0.5902\n",
      "Epoch 2323/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0646 - val_loss: 0.6126\n",
      "Epoch 2324/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0622 - val_loss: 0.6382\n",
      "Epoch 2325/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0745 - val_loss: 0.6106\n",
      "Epoch 2326/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0740 - val_loss: 0.6021\n",
      "Epoch 2327/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0675 - val_loss: 0.6033\n",
      "Epoch 2328/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0736 - val_loss: 0.6333\n",
      "Epoch 2329/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0710 - val_loss: 0.6159\n",
      "Epoch 2330/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0654 - val_loss: 0.6052\n",
      "Epoch 2331/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0698 - val_loss: 0.5944\n",
      "Epoch 2332/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0689 - val_loss: 0.5974\n",
      "Epoch 2333/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0695 - val_loss: 0.6049\n",
      "Epoch 2334/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0650 - val_loss: 0.6160\n",
      "Epoch 2335/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0658 - val_loss: 0.6243\n",
      "Epoch 2336/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0670 - val_loss: 0.6081\n",
      "Epoch 2337/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0732 - val_loss: 0.6166\n",
      "Epoch 2338/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0686 - val_loss: 0.6033\n",
      "Epoch 2339/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0720 - val_loss: 0.6034\n",
      "Epoch 2340/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0667 - val_loss: 0.5994\n",
      "Epoch 2341/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0728 - val_loss: 0.6040\n",
      "Epoch 2342/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0625 - val_loss: 0.6019\n",
      "Epoch 2343/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0719 - val_loss: 0.5964\n",
      "Epoch 2344/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0704 - val_loss: 0.6035\n",
      "Epoch 2345/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0682 - val_loss: 0.6082\n",
      "Epoch 2346/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0633 - val_loss: 0.6079\n",
      "Epoch 2347/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0713 - val_loss: 0.6292\n",
      "Epoch 2348/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0627 - val_loss: 0.6024\n",
      "Epoch 2349/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0654 - val_loss: 0.6175\n",
      "Epoch 2350/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0750 - val_loss: 0.6087\n",
      "Epoch 2351/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0654 - val_loss: 0.5929\n",
      "Epoch 2352/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0712 - val_loss: 0.6123\n",
      "Epoch 2353/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0745 - val_loss: 0.6308\n",
      "Epoch 2354/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0706 - val_loss: 0.6060\n",
      "Epoch 2355/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0717 - val_loss: 0.5973\n",
      "Epoch 2356/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0775 - val_loss: 0.6096\n",
      "Epoch 2357/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0700 - val_loss: 0.6351\n",
      "Epoch 2358/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0683 - val_loss: 0.6143\n",
      "Epoch 2359/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 775us/step - loss: 0.0644 - val_loss: 0.6423\n",
      "Epoch 2360/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0684 - val_loss: 0.6067\n",
      "Epoch 2361/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0683 - val_loss: 0.6050\n",
      "Epoch 2362/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0787 - val_loss: 0.6190\n",
      "Epoch 2363/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0716 - val_loss: 0.6193\n",
      "Epoch 2364/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0610 - val_loss: 0.6124\n",
      "Epoch 2365/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0673 - val_loss: 0.6052\n",
      "Epoch 2366/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0615 - val_loss: 0.5876\n",
      "Epoch 2367/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0667 - val_loss: 0.6130\n",
      "Epoch 2368/10000\n",
      "130/130 [==============================] - 0s 814us/step - loss: 0.0783 - val_loss: 0.6045\n",
      "Epoch 2369/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0703 - val_loss: 0.6065\n",
      "Epoch 2370/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0658 - val_loss: 0.6086\n",
      "Epoch 2371/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0656 - val_loss: 0.6189\n",
      "Epoch 2372/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0698 - val_loss: 0.6141\n",
      "Epoch 2373/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0649 - val_loss: 0.6168\n",
      "Epoch 2374/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0762 - val_loss: 0.6218\n",
      "Epoch 2375/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0773 - val_loss: 0.6032\n",
      "Epoch 2376/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0674 - val_loss: 0.6151\n",
      "Epoch 2377/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0724 - val_loss: 0.6046\n",
      "Epoch 2378/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0683 - val_loss: 0.6085\n",
      "Epoch 2379/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0640 - val_loss: 0.6097\n",
      "Epoch 2380/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0614 - val_loss: 0.6224\n",
      "Epoch 2381/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0661 - val_loss: 0.6355\n",
      "Epoch 2382/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0685 - val_loss: 0.6075\n",
      "Epoch 2383/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0665 - val_loss: 0.5941\n",
      "Epoch 2384/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0681 - val_loss: 0.6045\n",
      "Epoch 2385/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0685 - val_loss: 0.5997\n",
      "Epoch 2386/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0713 - val_loss: 0.6061\n",
      "Epoch 2387/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0636 - val_loss: 0.6010\n",
      "Epoch 2388/10000\n",
      "130/130 [==============================] - 0s 813us/step - loss: 0.0652 - val_loss: 0.6130\n",
      "Epoch 2389/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0721 - val_loss: 0.6245\n",
      "Epoch 2390/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0713 - val_loss: 0.6023\n",
      "Epoch 2391/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0640 - val_loss: 0.6246\n",
      "Epoch 2392/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0687 - val_loss: 0.5968\n",
      "Epoch 2393/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0627 - val_loss: 0.6363\n",
      "Epoch 2394/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0747 - val_loss: 0.6543\n",
      "Epoch 2395/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0866 - val_loss: 0.6099\n",
      "Epoch 2396/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0687 - val_loss: 0.6102\n",
      "Epoch 2397/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0646 - val_loss: 0.5986\n",
      "Epoch 2398/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0687 - val_loss: 0.6126\n",
      "Epoch 2399/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0651 - val_loss: 0.6020\n",
      "Epoch 2400/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0658 - val_loss: 0.6151\n",
      "Epoch 2401/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0696 - val_loss: 0.6069\n",
      "Epoch 2402/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0598 - val_loss: 0.6199\n",
      "Epoch 2403/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0619 - val_loss: 0.6095\n",
      "Epoch 2404/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0701 - val_loss: 0.6144\n",
      "Epoch 2405/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0657 - val_loss: 0.6045\n",
      "Epoch 2406/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0677 - val_loss: 0.5954\n",
      "Epoch 2407/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0655 - val_loss: 0.6183\n",
      "Epoch 2408/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0623 - val_loss: 0.6093\n",
      "Epoch 2409/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0609 - val_loss: 0.5863\n",
      "Epoch 2410/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0676 - val_loss: 0.6145\n",
      "Epoch 2411/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0702 - val_loss: 0.6346\n",
      "Epoch 2412/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0625 - val_loss: 0.6239\n",
      "Epoch 2413/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0675 - val_loss: 0.5909\n",
      "Epoch 2414/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0629 - val_loss: 0.5863\n",
      "Epoch 2415/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0625 - val_loss: 0.6110\n",
      "Epoch 2416/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0609 - val_loss: 0.6212\n",
      "Epoch 2417/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0656 - val_loss: 0.5894\n",
      "Epoch 2418/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0713 - val_loss: 0.6041\n",
      "Epoch 2419/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0647 - val_loss: 0.6253\n",
      "Epoch 2420/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0643 - val_loss: 0.6243\n",
      "Epoch 2421/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0741 - val_loss: 0.6064\n",
      "Epoch 2422/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0727 - val_loss: 0.5879\n",
      "Epoch 2423/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0639 - val_loss: 0.5968\n",
      "Epoch 2424/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0696 - val_loss: 0.6194\n",
      "Epoch 2425/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0705 - val_loss: 0.6315\n",
      "Epoch 2426/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0660 - val_loss: 0.6177\n",
      "Epoch 2427/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0727 - val_loss: 0.6105\n",
      "Epoch 2428/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0627 - val_loss: 0.5713\n",
      "Epoch 2429/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0664 - val_loss: 0.6188\n",
      "Epoch 2430/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0667 - val_loss: 0.6132\n",
      "Epoch 2431/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0587 - val_loss: 0.6154\n",
      "Epoch 2432/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0636 - val_loss: 0.5993\n",
      "Epoch 2433/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0630 - val_loss: 0.6091\n",
      "Epoch 2434/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0664 - val_loss: 0.5987\n",
      "Epoch 2435/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 744us/step - loss: 0.0703 - val_loss: 0.5872\n",
      "Epoch 2436/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0677 - val_loss: 0.6385\n",
      "Epoch 2437/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0713 - val_loss: 0.6176\n",
      "Epoch 2438/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0612 - val_loss: 0.6041\n",
      "Epoch 2439/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0828 - val_loss: 0.5880\n",
      "Epoch 2440/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0690 - val_loss: 0.6217\n",
      "Epoch 2441/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0602 - val_loss: 0.6029\n",
      "Epoch 2442/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0626 - val_loss: 0.5974\n",
      "Epoch 2443/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0561 - val_loss: 0.6193\n",
      "Epoch 2444/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0579 - val_loss: 0.6126\n",
      "Epoch 2445/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0602 - val_loss: 0.6119\n",
      "Epoch 2446/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0638 - val_loss: 0.6121\n",
      "Epoch 2447/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0591 - val_loss: 0.6187\n",
      "Epoch 2448/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0632 - val_loss: 0.5971\n",
      "Epoch 2449/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0688 - val_loss: 0.6276\n",
      "Epoch 2450/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0717 - val_loss: 0.5990\n",
      "Epoch 2451/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0690 - val_loss: 0.6340\n",
      "Epoch 2452/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0639 - val_loss: 0.5994\n",
      "Epoch 2453/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0680 - val_loss: 0.6046\n",
      "Epoch 2454/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0759 - val_loss: 0.6027\n",
      "Epoch 2455/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0715 - val_loss: 0.6034\n",
      "Epoch 2456/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0618 - val_loss: 0.6230\n",
      "Epoch 2457/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0575 - val_loss: 0.6031\n",
      "Epoch 2458/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0576 - val_loss: 0.5975\n",
      "Epoch 2459/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0619 - val_loss: 0.6119\n",
      "Epoch 2460/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0708 - val_loss: 0.5970\n",
      "Epoch 2461/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0633 - val_loss: 0.6063\n",
      "Epoch 2462/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0603 - val_loss: 0.6221\n",
      "Epoch 2463/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0615 - val_loss: 0.6096\n",
      "Epoch 2464/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0610 - val_loss: 0.6079\n",
      "Epoch 2465/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0650 - val_loss: 0.6102\n",
      "Epoch 2466/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0666 - val_loss: 0.6042\n",
      "Epoch 2467/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0648 - val_loss: 0.6280\n",
      "Epoch 2468/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0604 - val_loss: 0.6196\n",
      "Epoch 2469/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0638 - val_loss: 0.6159\n",
      "Epoch 2470/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0587 - val_loss: 0.6243\n",
      "Epoch 2471/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0616 - val_loss: 0.6153\n",
      "Epoch 2472/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0623 - val_loss: 0.6308\n",
      "Epoch 2473/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0599 - val_loss: 0.6044\n",
      "Epoch 2474/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0675 - val_loss: 0.6102\n",
      "Epoch 2475/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0637 - val_loss: 0.6266\n",
      "Epoch 2476/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0779 - val_loss: 0.6019\n",
      "Epoch 2477/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0634 - val_loss: 0.5852\n",
      "Epoch 2478/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0644 - val_loss: 0.6106\n",
      "Epoch 2479/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0715 - val_loss: 0.6346\n",
      "Epoch 2480/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0652 - val_loss: 0.6158\n",
      "Epoch 2481/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0605 - val_loss: 0.6216\n",
      "Epoch 2482/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0609 - val_loss: 0.6183\n",
      "Epoch 2483/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0654 - val_loss: 0.6162\n",
      "Epoch 2484/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0672 - val_loss: 0.6253\n",
      "Epoch 2485/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0643 - val_loss: 0.6281\n",
      "Epoch 2486/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0594 - val_loss: 0.6169\n",
      "Epoch 2487/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0540 - val_loss: 0.6282\n",
      "Epoch 2488/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0629 - val_loss: 0.6247\n",
      "Epoch 2489/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0638 - val_loss: 0.6052\n",
      "Epoch 2490/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0664 - val_loss: 0.6058\n",
      "Epoch 2491/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0656 - val_loss: 0.6139\n",
      "Epoch 2492/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0598 - val_loss: 0.6187\n",
      "Epoch 2493/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0600 - val_loss: 0.6242\n",
      "Epoch 2494/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0654 - val_loss: 0.6107\n",
      "Epoch 2495/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0556 - val_loss: 0.6252\n",
      "Epoch 2496/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0720 - val_loss: 0.6221\n",
      "Epoch 2497/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0677 - val_loss: 0.6008\n",
      "Epoch 2498/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0586 - val_loss: 0.6166\n",
      "Epoch 2499/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0571 - val_loss: 0.6205\n",
      "Epoch 2500/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0672 - val_loss: 0.5985\n",
      "Epoch 2501/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0604 - val_loss: 0.6175\n",
      "Epoch 2502/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0654 - val_loss: 0.6256\n",
      "Epoch 2503/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0547 - val_loss: 0.6217\n",
      "Epoch 2504/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0610 - val_loss: 0.6196\n",
      "Epoch 2505/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0615 - val_loss: 0.6185\n",
      "Epoch 2506/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0655 - val_loss: 0.6119\n",
      "Epoch 2507/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0619 - val_loss: 0.6045\n",
      "Epoch 2508/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0653 - val_loss: 0.6208\n",
      "Epoch 2509/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0659 - val_loss: 0.6216\n",
      "Epoch 2510/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0589 - val_loss: 0.6204\n",
      "Epoch 2511/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 757us/step - loss: 0.0585 - val_loss: 0.6120\n",
      "Epoch 2512/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0633 - val_loss: 0.6295\n",
      "Epoch 2513/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0648 - val_loss: 0.5933\n",
      "Epoch 2514/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0584 - val_loss: 0.6067\n",
      "Epoch 2515/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0646 - val_loss: 0.6261\n",
      "Epoch 2516/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0596 - val_loss: 0.6337\n",
      "Epoch 2517/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0609 - val_loss: 0.6148\n",
      "Epoch 2518/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0617 - val_loss: 0.6033\n",
      "Epoch 2519/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0603 - val_loss: 0.6122\n",
      "Epoch 2520/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0632 - val_loss: 0.6118\n",
      "Epoch 2521/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0596 - val_loss: 0.6128\n",
      "Epoch 2522/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0728 - val_loss: 0.6190\n",
      "Epoch 2523/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0668 - val_loss: 0.6203\n",
      "Epoch 2524/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0607 - val_loss: 0.6163\n",
      "Epoch 2525/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0570 - val_loss: 0.6088\n",
      "Epoch 2526/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0605 - val_loss: 0.6157\n",
      "Epoch 2527/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0578 - val_loss: 0.6028\n",
      "Epoch 2528/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0651 - val_loss: 0.6276\n",
      "Epoch 2529/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0632 - val_loss: 0.5930\n",
      "Epoch 2530/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0648 - val_loss: 0.6174\n",
      "Epoch 2531/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0623 - val_loss: 0.6174\n",
      "Epoch 2532/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0664 - val_loss: 0.6047\n",
      "Epoch 2533/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0572 - val_loss: 0.6184\n",
      "Epoch 2534/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0606 - val_loss: 0.6106\n",
      "Epoch 2535/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0595 - val_loss: 0.6327\n",
      "Epoch 2536/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0634 - val_loss: 0.6076\n",
      "Epoch 2537/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0554 - val_loss: 0.6319\n",
      "Epoch 2538/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0551 - val_loss: 0.6104\n",
      "Epoch 2539/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0602 - val_loss: 0.6108\n",
      "Epoch 2540/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0622 - val_loss: 0.6147\n",
      "Epoch 2541/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0549 - val_loss: 0.6098\n",
      "Epoch 2542/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0570 - val_loss: 0.6161\n",
      "Epoch 2543/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0660 - val_loss: 0.6173\n",
      "Epoch 2544/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0793 - val_loss: 0.6142\n",
      "Epoch 2545/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0592 - val_loss: 0.6282\n",
      "Epoch 2546/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0614 - val_loss: 0.6210\n",
      "Epoch 2547/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0599 - val_loss: 0.6169\n",
      "Epoch 2548/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0511 - val_loss: 0.6179\n",
      "Epoch 2549/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0561 - val_loss: 0.6149\n",
      "Epoch 2550/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0627 - val_loss: 0.6214\n",
      "Epoch 2551/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0634 - val_loss: 0.6224\n",
      "Epoch 2552/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0605 - val_loss: 0.6233\n",
      "Epoch 2553/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0640 - val_loss: 0.6042\n",
      "Epoch 2554/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0594 - val_loss: 0.6120\n",
      "Epoch 2555/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0676 - val_loss: 0.6287\n",
      "Epoch 2556/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0645 - val_loss: 0.6264\n",
      "Epoch 2557/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0655 - val_loss: 0.6097\n",
      "Epoch 2558/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0601 - val_loss: 0.6216\n",
      "Epoch 2559/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0520 - val_loss: 0.5971\n",
      "Epoch 2560/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0571 - val_loss: 0.6246\n",
      "Epoch 2561/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0569 - val_loss: 0.6303\n",
      "Epoch 2562/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0616 - val_loss: 0.6111\n",
      "Epoch 2563/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0581 - val_loss: 0.6233\n",
      "Epoch 2564/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0714 - val_loss: 0.6058\n",
      "Epoch 2565/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0665 - val_loss: 0.6031\n",
      "Epoch 2566/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0637 - val_loss: 0.6097\n",
      "Epoch 2567/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0637 - val_loss: 0.6225\n",
      "Epoch 2568/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0621 - val_loss: 0.6448\n",
      "Epoch 2569/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0792 - val_loss: 0.6269\n",
      "Epoch 2570/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0629 - val_loss: 0.6146\n",
      "Epoch 2571/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0605 - val_loss: 0.6277\n",
      "Epoch 2572/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0550 - val_loss: 0.6263\n",
      "Epoch 2573/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0625 - val_loss: 0.6033\n",
      "Epoch 2574/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0524 - val_loss: 0.6169\n",
      "Epoch 2575/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0604 - val_loss: 0.6143\n",
      "Epoch 2576/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0539 - val_loss: 0.6240\n",
      "Epoch 2577/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0609 - val_loss: 0.6326\n",
      "Epoch 2578/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0619 - val_loss: 0.6215\n",
      "Epoch 2579/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0550 - val_loss: 0.6162\n",
      "Epoch 2580/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0617 - val_loss: 0.6167\n",
      "Epoch 2581/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0668 - val_loss: 0.6155\n",
      "Epoch 2582/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0591 - val_loss: 0.6359\n",
      "Epoch 2583/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0644 - val_loss: 0.6033\n",
      "Epoch 2584/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0564 - val_loss: 0.6118\n",
      "Epoch 2585/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0577 - val_loss: 0.6093\n",
      "Epoch 2586/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0596 - val_loss: 0.6106\n",
      "Epoch 2587/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 741us/step - loss: 0.0554 - val_loss: 0.6399\n",
      "Epoch 2588/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0873 - val_loss: 0.6117\n",
      "Epoch 2589/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0601 - val_loss: 0.6131\n",
      "Epoch 2590/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0558 - val_loss: 0.6185\n",
      "Epoch 2591/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0583 - val_loss: 0.6349\n",
      "Epoch 2592/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0559 - val_loss: 0.6149\n",
      "Epoch 2593/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0562 - val_loss: 0.6224\n",
      "Epoch 2594/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0574 - val_loss: 0.6238\n",
      "Epoch 2595/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0560 - val_loss: 0.6090\n",
      "Epoch 2596/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0527 - val_loss: 0.6275\n",
      "Epoch 2597/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0627 - val_loss: 0.6239\n",
      "Epoch 2598/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0640 - val_loss: 0.6250\n",
      "Epoch 2599/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0584 - val_loss: 0.6314\n",
      "Epoch 2600/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0702 - val_loss: 0.5996\n",
      "Epoch 2601/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0598 - val_loss: 0.6179\n",
      "Epoch 2602/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0541 - val_loss: 0.6127\n",
      "Epoch 2603/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0559 - val_loss: 0.6152\n",
      "Epoch 2604/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0564 - val_loss: 0.6369\n",
      "Epoch 2605/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0606 - val_loss: 0.6112\n",
      "Epoch 2606/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0677 - val_loss: 0.6197\n",
      "Epoch 2607/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0651 - val_loss: 0.6184\n",
      "Epoch 2608/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0604 - val_loss: 0.6159\n",
      "Epoch 2609/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0640 - val_loss: 0.6139\n",
      "Epoch 2610/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0571 - val_loss: 0.6157\n",
      "Epoch 2611/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0567 - val_loss: 0.6142\n",
      "Epoch 2612/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0535 - val_loss: 0.6288\n",
      "Epoch 2613/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0560 - val_loss: 0.6066\n",
      "Epoch 2614/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0531 - val_loss: 0.6241\n",
      "Epoch 2615/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0576 - val_loss: 0.6170\n",
      "Epoch 2616/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0560 - val_loss: 0.6293\n",
      "Epoch 2617/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0522 - val_loss: 0.6375\n",
      "Epoch 2618/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0602 - val_loss: 0.6200\n",
      "Epoch 2619/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0579 - val_loss: 0.6144\n",
      "Epoch 2620/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0610 - val_loss: 0.6089\n",
      "Epoch 2621/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0660 - val_loss: 0.6086\n",
      "Epoch 2622/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0536 - val_loss: 0.6333\n",
      "Epoch 2623/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0546 - val_loss: 0.6354\n",
      "Epoch 2624/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0580 - val_loss: 0.6093\n",
      "Epoch 2625/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0684 - val_loss: 0.6012\n",
      "Epoch 2626/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0698 - val_loss: 0.6266\n",
      "Epoch 2627/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0567 - val_loss: 0.6519\n",
      "Epoch 2628/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0555 - val_loss: 0.6304\n",
      "Epoch 2629/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0571 - val_loss: 0.6130\n",
      "Epoch 2630/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0583 - val_loss: 0.5977\n",
      "Epoch 2631/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0583 - val_loss: 0.6256\n",
      "Epoch 2632/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0548 - val_loss: 0.6186\n",
      "Epoch 2633/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0567 - val_loss: 0.6002\n",
      "Epoch 2634/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0537 - val_loss: 0.6227\n",
      "Epoch 2635/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0556 - val_loss: 0.6100\n",
      "Epoch 2636/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0542 - val_loss: 0.6266\n",
      "Epoch 2637/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0562 - val_loss: 0.6229\n",
      "Epoch 2638/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0585 - val_loss: 0.6405\n",
      "Epoch 2639/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0613 - val_loss: 0.6214\n",
      "Epoch 2640/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0528 - val_loss: 0.6209\n",
      "Epoch 2641/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0516 - val_loss: 0.6170\n",
      "Epoch 2642/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0590 - val_loss: 0.6297\n",
      "Epoch 2643/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0600 - val_loss: 0.6089\n",
      "Epoch 2644/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0612 - val_loss: 0.6091\n",
      "Epoch 2645/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0615 - val_loss: 0.6206\n",
      "Epoch 2646/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0585 - val_loss: 0.6179\n",
      "Epoch 2647/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0534 - val_loss: 0.6191\n",
      "Epoch 2648/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0531 - val_loss: 0.6133\n",
      "Epoch 2649/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0511 - val_loss: 0.6218\n",
      "Epoch 2650/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0535 - val_loss: 0.6254\n",
      "Epoch 2651/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0543 - val_loss: 0.6146\n",
      "Epoch 2652/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0596 - val_loss: 0.6251\n",
      "Epoch 2653/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0562 - val_loss: 0.6214\n",
      "Epoch 2654/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0560 - val_loss: 0.6328\n",
      "Epoch 2655/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0671 - val_loss: 0.6205\n",
      "Epoch 2656/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0718 - val_loss: 0.6174\n",
      "Epoch 2657/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0579 - val_loss: 0.6084\n",
      "Epoch 2658/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0495 - val_loss: 0.6188\n",
      "Epoch 2659/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0495 - val_loss: 0.6224\n",
      "Epoch 2660/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0511 - val_loss: 0.6218\n",
      "Epoch 2661/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0588 - val_loss: 0.6334\n",
      "Epoch 2662/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0699 - val_loss: 0.6146\n",
      "Epoch 2663/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 731us/step - loss: 0.0605 - val_loss: 0.6177\n",
      "Epoch 2664/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0570 - val_loss: 0.6206\n",
      "Epoch 2665/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0654 - val_loss: 0.6176\n",
      "Epoch 2666/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0588 - val_loss: 0.6193\n",
      "Epoch 2667/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0537 - val_loss: 0.6174\n",
      "Epoch 2668/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0566 - val_loss: 0.6116\n",
      "Epoch 2669/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0605 - val_loss: 0.6181\n",
      "Epoch 2670/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0526 - val_loss: 0.6346\n",
      "Epoch 2671/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0580 - val_loss: 0.6252\n",
      "Epoch 2672/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0604 - val_loss: 0.6534\n",
      "Epoch 2673/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0643 - val_loss: 0.6269\n",
      "Epoch 2674/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0539 - val_loss: 0.6341\n",
      "Epoch 2675/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0521 - val_loss: 0.6310\n",
      "Epoch 2676/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0491 - val_loss: 0.6203\n",
      "Epoch 2677/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0620 - val_loss: 0.6355\n",
      "Epoch 2678/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0569 - val_loss: 0.6207\n",
      "Epoch 2679/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0501 - val_loss: 0.6205\n",
      "Epoch 2680/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0524 - val_loss: 0.6280\n",
      "Epoch 2681/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0540 - val_loss: 0.6287\n",
      "Epoch 2682/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0504 - val_loss: 0.6234\n",
      "Epoch 2683/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0568 - val_loss: 0.6467\n",
      "Epoch 2684/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0592 - val_loss: 0.6212\n",
      "Epoch 2685/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0517 - val_loss: 0.6212\n",
      "Epoch 2686/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0632 - val_loss: 0.6022\n",
      "Epoch 2687/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0552 - val_loss: 0.6299\n",
      "Epoch 2688/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0553 - val_loss: 0.6236\n",
      "Epoch 2689/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0521 - val_loss: 0.6626\n",
      "Epoch 2690/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0574 - val_loss: 0.6175\n",
      "Epoch 2691/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0524 - val_loss: 0.6447\n",
      "Epoch 2692/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0563 - val_loss: 0.6362\n",
      "Epoch 2693/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0619 - val_loss: 0.6248\n",
      "Epoch 2694/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0545 - val_loss: 0.6212\n",
      "Epoch 2695/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0491 - val_loss: 0.6216\n",
      "Epoch 2696/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0722 - val_loss: 0.6015\n",
      "Epoch 2697/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0582 - val_loss: 0.6215\n",
      "Epoch 2698/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0480 - val_loss: 0.6147\n",
      "Epoch 2699/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0566 - val_loss: 0.6226\n",
      "Epoch 2700/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0568 - val_loss: 0.6434\n",
      "Epoch 2701/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0550 - val_loss: 0.6459\n",
      "Epoch 2702/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0513 - val_loss: 0.6336\n",
      "Epoch 2703/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0563 - val_loss: 0.6261\n",
      "Epoch 2704/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0534 - val_loss: 0.6124\n",
      "Epoch 2705/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0621 - val_loss: 0.6129\n",
      "Epoch 2706/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0583 - val_loss: 0.6199\n",
      "Epoch 2707/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0517 - val_loss: 0.6249\n",
      "Epoch 2708/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0510 - val_loss: 0.6213\n",
      "Epoch 2709/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0525 - val_loss: 0.6070\n",
      "Epoch 2710/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0601 - val_loss: 0.6168\n",
      "Epoch 2711/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0556 - val_loss: 0.6155\n",
      "Epoch 2712/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0568 - val_loss: 0.6220\n",
      "Epoch 2713/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0563 - val_loss: 0.6194\n",
      "Epoch 2714/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0555 - val_loss: 0.6148\n",
      "Epoch 2715/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0536 - val_loss: 0.6215\n",
      "Epoch 2716/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0580 - val_loss: 0.6346\n",
      "Epoch 2717/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0548 - val_loss: 0.6245\n",
      "Epoch 2718/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0529 - val_loss: 0.6222\n",
      "Epoch 2719/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0511 - val_loss: 0.6230\n",
      "Epoch 2720/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0580 - val_loss: 0.6146\n",
      "Epoch 2721/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0611 - val_loss: 0.6217\n",
      "Epoch 2722/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0526 - val_loss: 0.6168\n",
      "Epoch 2723/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0512 - val_loss: 0.6375\n",
      "Epoch 2724/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0497 - val_loss: 0.6378\n",
      "Epoch 2725/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0533 - val_loss: 0.6113\n",
      "Epoch 2726/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0508 - val_loss: 0.6327\n",
      "Epoch 2727/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0627 - val_loss: 0.6345\n",
      "Epoch 2728/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0783 - val_loss: 0.6378\n",
      "Epoch 2729/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0509 - val_loss: 0.6243\n",
      "Epoch 2730/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0506 - val_loss: 0.6213\n",
      "Epoch 2731/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0477 - val_loss: 0.6237\n",
      "Epoch 2732/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0517 - val_loss: 0.6328\n",
      "Epoch 2733/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0511 - val_loss: 0.6556\n",
      "Epoch 2734/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0533 - val_loss: 0.6338\n",
      "Epoch 2735/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0516 - val_loss: 0.6346\n",
      "Epoch 2736/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0556 - val_loss: 0.6219\n",
      "Epoch 2737/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0573 - val_loss: 0.6156\n",
      "Epoch 2738/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0565 - val_loss: 0.6357\n",
      "Epoch 2739/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 728us/step - loss: 0.0486 - val_loss: 0.6293\n",
      "Epoch 2740/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0505 - val_loss: 0.6320\n",
      "Epoch 2741/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0532 - val_loss: 0.6448\n",
      "Epoch 2742/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0639 - val_loss: 0.6341\n",
      "Epoch 2743/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0561 - val_loss: 0.6168\n",
      "Epoch 2744/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0512 - val_loss: 0.6170\n",
      "Epoch 2745/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0484 - val_loss: 0.6241\n",
      "Epoch 2746/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0499 - val_loss: 0.6583\n",
      "Epoch 2747/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0544 - val_loss: 0.6246\n",
      "Epoch 2748/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0574 - val_loss: 0.6283\n",
      "Epoch 2749/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0509 - val_loss: 0.6147\n",
      "Epoch 2750/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0518 - val_loss: 0.6337\n",
      "Epoch 2751/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0721 - val_loss: 0.6698\n",
      "Epoch 2752/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0585 - val_loss: 0.6425\n",
      "Epoch 2753/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0503 - val_loss: 0.6156\n",
      "Epoch 2754/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0539 - val_loss: 0.6171\n",
      "Epoch 2755/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0509 - val_loss: 0.6171\n",
      "Epoch 2756/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0485 - val_loss: 0.6242\n",
      "Epoch 2757/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0492 - val_loss: 0.6256\n",
      "Epoch 2758/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0542 - val_loss: 0.6363\n",
      "Epoch 2759/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0516 - val_loss: 0.6361\n",
      "Epoch 2760/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0494 - val_loss: 0.6314\n",
      "Epoch 2761/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0596 - val_loss: 0.6194\n",
      "Epoch 2762/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0562 - val_loss: 0.6230\n",
      "Epoch 2763/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0507 - val_loss: 0.6217\n",
      "Epoch 2764/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0580 - val_loss: 0.6295\n",
      "Epoch 2765/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0548 - val_loss: 0.6302\n",
      "Epoch 2766/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0523 - val_loss: 0.6290\n",
      "Epoch 2767/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0558 - val_loss: 0.6167\n",
      "Epoch 2768/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0590 - val_loss: 0.6139\n",
      "Epoch 2769/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0657 - val_loss: 0.6193\n",
      "Epoch 2770/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0520 - val_loss: 0.6295\n",
      "Epoch 2771/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0505 - val_loss: 0.6183\n",
      "Epoch 2772/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0457 - val_loss: 0.6179\n",
      "Epoch 2773/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0451 - val_loss: 0.6276\n",
      "Epoch 2774/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0546 - val_loss: 0.6357\n",
      "Epoch 2775/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0497 - val_loss: 0.6224\n",
      "Epoch 2776/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0566 - val_loss: 0.6259\n",
      "Epoch 2777/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0490 - val_loss: 0.6437\n",
      "Epoch 2778/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0508 - val_loss: 0.6211\n",
      "Epoch 2779/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0494 - val_loss: 0.6359\n",
      "Epoch 2780/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0637 - val_loss: 0.6243\n",
      "Epoch 2781/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0453 - val_loss: 0.6237\n",
      "Epoch 2782/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0522 - val_loss: 0.6379\n",
      "Epoch 2783/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0482 - val_loss: 0.6424\n",
      "Epoch 2784/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0484 - val_loss: 0.6190\n",
      "Epoch 2785/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0706 - val_loss: 0.6252\n",
      "Epoch 2786/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0548 - val_loss: 0.6145\n",
      "Epoch 2787/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0583 - val_loss: 0.6073\n",
      "Epoch 2788/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0510 - val_loss: 0.6258\n",
      "Epoch 2789/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0510 - val_loss: 0.6147\n",
      "Epoch 2790/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0720 - val_loss: 0.6491\n",
      "Epoch 2791/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0517 - val_loss: 0.6387\n",
      "Epoch 2792/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0476 - val_loss: 0.6194\n",
      "Epoch 2793/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0484 - val_loss: 0.6280\n",
      "Epoch 2794/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0460 - val_loss: 0.6469\n",
      "Epoch 2795/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0447 - val_loss: 0.6261\n",
      "Epoch 2796/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0464 - val_loss: 0.6483\n",
      "Epoch 2797/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0493 - val_loss: 0.6302\n",
      "Epoch 2798/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0548 - val_loss: 0.6655\n",
      "Epoch 2799/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0557 - val_loss: 0.6176\n",
      "Epoch 2800/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0496 - val_loss: 0.6355\n",
      "Epoch 2801/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0548 - val_loss: 0.6315\n",
      "Epoch 2802/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0539 - val_loss: 0.6289\n",
      "Epoch 2803/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0557 - val_loss: 0.6550\n",
      "Epoch 2804/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0595 - val_loss: 0.6063\n",
      "Epoch 2805/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0498 - val_loss: 0.6045\n",
      "Epoch 2806/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0476 - val_loss: 0.6330\n",
      "Epoch 2807/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0555 - val_loss: 0.6253\n",
      "Epoch 2808/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0458 - val_loss: 0.6331\n",
      "Epoch 2809/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0599 - val_loss: 0.6206\n",
      "Epoch 2810/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0717 - val_loss: 0.6303\n",
      "Epoch 2811/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0501 - val_loss: 0.6331\n",
      "Epoch 2812/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0445 - val_loss: 0.6426\n",
      "Epoch 2813/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0479 - val_loss: 0.6351\n",
      "Epoch 2814/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0484 - val_loss: 0.6050\n",
      "Epoch 2815/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 737us/step - loss: 0.0596 - val_loss: 0.6184\n",
      "Epoch 2816/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0564 - val_loss: 0.6334\n",
      "Epoch 2817/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0546 - val_loss: 0.6520\n",
      "Epoch 2818/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0497 - val_loss: 0.6438\n",
      "Epoch 2819/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0576 - val_loss: 0.6417\n",
      "Epoch 2820/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0586 - val_loss: 0.6248\n",
      "Epoch 2821/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0476 - val_loss: 0.6252\n",
      "Epoch 2822/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0459 - val_loss: 0.6261\n",
      "Epoch 2823/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0467 - val_loss: 0.6431\n",
      "Epoch 2824/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0500 - val_loss: 0.6250\n",
      "Epoch 2825/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0516 - val_loss: 0.6354\n",
      "Epoch 2826/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0596 - val_loss: 0.6398\n",
      "Epoch 2827/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0506 - val_loss: 0.6434\n",
      "Epoch 2828/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0522 - val_loss: 0.6309\n",
      "Epoch 2829/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0608 - val_loss: 0.6365\n",
      "Epoch 2830/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0606 - val_loss: 0.6661\n",
      "Epoch 2831/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0536 - val_loss: 0.6275\n",
      "Epoch 2832/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0517 - val_loss: 0.6328\n",
      "Epoch 2833/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0512 - val_loss: 0.6382\n",
      "Epoch 2834/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0492 - val_loss: 0.6298\n",
      "Epoch 2835/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0470 - val_loss: 0.6600\n",
      "Epoch 2836/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0499 - val_loss: 0.6206\n",
      "Epoch 2837/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0617 - val_loss: 0.6196\n",
      "Epoch 2838/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0505 - val_loss: 0.6310\n",
      "Epoch 2839/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0504 - val_loss: 0.6317\n",
      "Epoch 2840/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0485 - val_loss: 0.6288\n",
      "Epoch 2841/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0507 - val_loss: 0.6234\n",
      "Epoch 2842/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0502 - val_loss: 0.6254\n",
      "Epoch 2843/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0544 - val_loss: 0.6314\n",
      "Epoch 2844/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0508 - val_loss: 0.6398\n",
      "Epoch 2845/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0456 - val_loss: 0.6252\n",
      "Epoch 2846/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0490 - val_loss: 0.6353\n",
      "Epoch 2847/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0478 - val_loss: 0.6091\n",
      "Epoch 2848/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0502 - val_loss: 0.6348\n",
      "Epoch 2849/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0485 - val_loss: 0.6295\n",
      "Epoch 2850/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0494 - val_loss: 0.6367\n",
      "Epoch 2851/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0564 - val_loss: 0.6326\n",
      "Epoch 2852/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0602 - val_loss: 0.6465\n",
      "Epoch 2853/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0516 - val_loss: 0.6525\n",
      "Epoch 2854/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0492 - val_loss: 0.6308\n",
      "Epoch 2855/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0501 - val_loss: 0.6512\n",
      "Epoch 2856/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0517 - val_loss: 0.6356\n",
      "Epoch 2857/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0506 - val_loss: 0.6341\n",
      "Epoch 2858/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0485 - val_loss: 0.6205\n",
      "Epoch 2859/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0508 - val_loss: 0.6488\n",
      "Epoch 2860/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0538 - val_loss: 0.6303\n",
      "Epoch 2861/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0505 - val_loss: 0.6188\n",
      "Epoch 2862/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0455 - val_loss: 0.6522\n",
      "Epoch 2863/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0484 - val_loss: 0.6385\n",
      "Epoch 2864/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0485 - val_loss: 0.6206\n",
      "Epoch 2865/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0558 - val_loss: 0.6293\n",
      "Epoch 2866/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0658 - val_loss: 0.6414\n",
      "Epoch 2867/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0529 - val_loss: 0.6336\n",
      "Epoch 2868/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0506 - val_loss: 0.6417\n",
      "Epoch 2869/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0467 - val_loss: 0.6458\n",
      "Epoch 2870/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0506 - val_loss: 0.6261\n",
      "Epoch 2871/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0464 - val_loss: 0.6417\n",
      "Epoch 2872/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0578 - val_loss: 0.6553\n",
      "Epoch 2873/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0562 - val_loss: 0.6682\n",
      "Epoch 2874/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0525 - val_loss: 0.6440\n",
      "Epoch 2875/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0432 - val_loss: 0.6226\n",
      "Epoch 2876/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0451 - val_loss: 0.6300\n",
      "Epoch 2877/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0464 - val_loss: 0.6342\n",
      "Epoch 2878/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0474 - val_loss: 0.6357\n",
      "Epoch 2879/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0503 - val_loss: 0.6490\n",
      "Epoch 2880/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0481 - val_loss: 0.6166\n",
      "Epoch 2881/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0410 - val_loss: 0.6459\n",
      "Epoch 2882/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0405 - val_loss: 0.6134\n",
      "Epoch 2883/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0594 - val_loss: 0.6290\n",
      "Epoch 2884/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0627 - val_loss: 0.6125\n",
      "Epoch 2885/10000\n",
      "130/130 [==============================] - 0s 832us/step - loss: 0.0510 - val_loss: 0.6353\n",
      "Epoch 2886/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0477 - val_loss: 0.6249\n",
      "Epoch 2887/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0478 - val_loss: 0.6236\n",
      "Epoch 2888/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0651 - val_loss: 0.6145\n",
      "Epoch 2889/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0699 - val_loss: 0.6232\n",
      "Epoch 2890/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0478 - val_loss: 0.6346\n",
      "Epoch 2891/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 741us/step - loss: 0.0510 - val_loss: 0.6295\n",
      "Epoch 2892/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0475 - val_loss: 0.6232\n",
      "Epoch 2893/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0507 - val_loss: 0.6385\n",
      "Epoch 2894/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0556 - val_loss: 0.6243\n",
      "Epoch 2895/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0472 - val_loss: 0.6406\n",
      "Epoch 2896/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0460 - val_loss: 0.6194\n",
      "Epoch 2897/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0487 - val_loss: 0.6380\n",
      "Epoch 2898/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0504 - val_loss: 0.6242\n",
      "Epoch 2899/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0442 - val_loss: 0.6268\n",
      "Epoch 2900/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0501 - val_loss: 0.6413\n",
      "Epoch 2901/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0608 - val_loss: 0.6357\n",
      "Epoch 2902/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0544 - val_loss: 0.6369\n",
      "Epoch 2903/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0468 - val_loss: 0.6285\n",
      "Epoch 2904/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0503 - val_loss: 0.6241\n",
      "Epoch 2905/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0479 - val_loss: 0.6017\n",
      "Epoch 2906/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0435 - val_loss: 0.6354\n",
      "Epoch 2907/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0467 - val_loss: 0.6181\n",
      "Epoch 2908/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0788 - val_loss: 0.6205\n",
      "Epoch 2909/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0471 - val_loss: 0.6391\n",
      "Epoch 2910/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0464 - val_loss: 0.6180\n",
      "Epoch 2911/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0605 - val_loss: 0.6120\n",
      "Epoch 2912/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0489 - val_loss: 0.6374\n",
      "Epoch 2913/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0517 - val_loss: 0.6129\n",
      "Epoch 2914/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0427 - val_loss: 0.6345\n",
      "Epoch 2915/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0541 - val_loss: 0.6113\n",
      "Epoch 2916/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0459 - val_loss: 0.6458\n",
      "Epoch 2917/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0464 - val_loss: 0.6254\n",
      "Epoch 2918/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0451 - val_loss: 0.6310\n",
      "Epoch 2919/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0446 - val_loss: 0.6292\n",
      "Epoch 2920/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0438 - val_loss: 0.6328\n",
      "Epoch 2921/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0541 - val_loss: 0.6136\n",
      "Epoch 2922/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0501 - val_loss: 0.6254\n",
      "Epoch 2923/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0450 - val_loss: 0.6384\n",
      "Epoch 2924/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0468 - val_loss: 0.6261\n",
      "Epoch 2925/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0449 - val_loss: 0.6324\n",
      "Epoch 2926/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0451 - val_loss: 0.6388\n",
      "Epoch 2927/10000\n",
      "130/130 [==============================] - 0s 830us/step - loss: 0.0485 - val_loss: 0.6300\n",
      "Epoch 2928/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0514 - val_loss: 0.6310\n",
      "Epoch 2929/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0545 - val_loss: 0.6324\n",
      "Epoch 2930/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0506 - val_loss: 0.6347\n",
      "Epoch 2931/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0455 - val_loss: 0.6149\n",
      "Epoch 2932/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0464 - val_loss: 0.6393\n",
      "Epoch 2933/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0608 - val_loss: 0.6233\n",
      "Epoch 2934/10000\n",
      "130/130 [==============================] - 0s 856us/step - loss: 0.0520 - val_loss: 0.6263\n",
      "Epoch 2935/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0452 - val_loss: 0.6232\n",
      "Epoch 2936/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0456 - val_loss: 0.6302\n",
      "Epoch 2937/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0461 - val_loss: 0.6457\n",
      "Epoch 2938/10000\n",
      "130/130 [==============================] - 0s 914us/step - loss: 0.0571 - val_loss: 0.6293\n",
      "Epoch 2939/10000\n",
      "130/130 [==============================] - 0s 878us/step - loss: 0.0596 - val_loss: 0.6111\n",
      "Epoch 2940/10000\n",
      "130/130 [==============================] - 0s 858us/step - loss: 0.0563 - val_loss: 0.6201\n",
      "Epoch 2941/10000\n",
      "130/130 [==============================] - 0s 974us/step - loss: 0.0489 - val_loss: 0.6268\n",
      "Epoch 2942/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0452 - val_loss: 0.6171\n",
      "Epoch 2943/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0469 - val_loss: 0.6587\n",
      "Epoch 2944/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0456 - val_loss: 0.6377\n",
      "Epoch 2945/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0469 - val_loss: 0.6197\n",
      "Epoch 2946/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0403 - val_loss: 0.6365\n",
      "Epoch 2947/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0401 - val_loss: 0.6445\n",
      "Epoch 2948/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0455 - val_loss: 0.6318\n",
      "Epoch 2949/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0542 - val_loss: 0.6311\n",
      "Epoch 2950/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0484 - val_loss: 0.6446\n",
      "Epoch 2951/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0493 - val_loss: 0.6225\n",
      "Epoch 2952/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0463 - val_loss: 0.6252\n",
      "Epoch 2953/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0529 - val_loss: 0.6367\n",
      "Epoch 2954/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0500 - val_loss: 0.6385\n",
      "Epoch 2955/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0550 - val_loss: 0.6285\n",
      "Epoch 2956/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0504 - val_loss: 0.6297\n",
      "Epoch 2957/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0427 - val_loss: 0.6170\n",
      "Epoch 2958/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0469 - val_loss: 0.6268\n",
      "Epoch 2959/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0503 - val_loss: 0.6306\n",
      "Epoch 2960/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0432 - val_loss: 0.6322\n",
      "Epoch 2961/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0466 - val_loss: 0.6273\n",
      "Epoch 2962/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0469 - val_loss: 0.6305\n",
      "Epoch 2963/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0478 - val_loss: 0.6183\n",
      "Epoch 2964/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0467 - val_loss: 0.6339\n",
      "Epoch 2965/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0562 - val_loss: 0.6042\n",
      "Epoch 2966/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0592 - val_loss: 0.6193\n",
      "Epoch 2967/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 715us/step - loss: 0.0445 - val_loss: 0.6176\n",
      "Epoch 2968/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0404 - val_loss: 0.6561\n",
      "Epoch 2969/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0483 - val_loss: 0.6415\n",
      "Epoch 2970/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0487 - val_loss: 0.6343\n",
      "Epoch 2971/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0440 - val_loss: 0.6423\n",
      "Epoch 2972/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0443 - val_loss: 0.6279\n",
      "Epoch 2973/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0618 - val_loss: 0.6515\n",
      "Epoch 2974/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0619 - val_loss: 0.6468\n",
      "Epoch 2975/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0596 - val_loss: 0.6205\n",
      "Epoch 2976/10000\n",
      "130/130 [==============================] - 0s 956us/step - loss: 0.0537 - val_loss: 0.6412\n",
      "Epoch 2977/10000\n",
      "130/130 [==============================] - 0s 820us/step - loss: 0.0414 - val_loss: 0.6371\n",
      "Epoch 2978/10000\n",
      "130/130 [==============================] - 0s 813us/step - loss: 0.0404 - val_loss: 0.6295\n",
      "Epoch 2979/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0394 - val_loss: 0.6415\n",
      "Epoch 2980/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0437 - val_loss: 0.6322\n",
      "Epoch 2981/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0392 - val_loss: 0.6369\n",
      "Epoch 2982/10000\n",
      "130/130 [==============================] - 0s 844us/step - loss: 0.0493 - val_loss: 0.6253\n",
      "Epoch 2983/10000\n",
      "130/130 [==============================] - 0s 882us/step - loss: 0.0580 - val_loss: 0.6209\n",
      "Epoch 2984/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0501 - val_loss: 0.6299\n",
      "Epoch 2985/10000\n",
      "130/130 [==============================] - 0s 879us/step - loss: 0.0460 - val_loss: 0.6294\n",
      "Epoch 2986/10000\n",
      "130/130 [==============================] - 0s 854us/step - loss: 0.0431 - val_loss: 0.6575\n",
      "Epoch 2987/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0558 - val_loss: 0.6282\n",
      "Epoch 2988/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0484 - val_loss: 0.6210\n",
      "Epoch 2989/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0438 - val_loss: 0.6487\n",
      "Epoch 2990/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0538 - val_loss: 0.6062\n",
      "Epoch 2991/10000\n",
      "130/130 [==============================] - 0s 848us/step - loss: 0.0489 - val_loss: 0.6429\n",
      "Epoch 2992/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0443 - val_loss: 0.6267\n",
      "Epoch 2993/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0423 - val_loss: 0.6401\n",
      "Epoch 2994/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0386 - val_loss: 0.6259\n",
      "Epoch 2995/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0455 - val_loss: 0.6253\n",
      "Epoch 2996/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0445 - val_loss: 0.6505\n",
      "Epoch 2997/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0483 - val_loss: 0.6294\n",
      "Epoch 2998/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0519 - val_loss: 0.6283\n",
      "Epoch 2999/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0468 - val_loss: 0.6443\n",
      "Epoch 3000/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0482 - val_loss: 0.6297\n",
      "Epoch 3001/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0441 - val_loss: 0.6498\n",
      "Epoch 3002/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0495 - val_loss: 0.6718\n",
      "Epoch 3003/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0648 - val_loss: 0.6339\n",
      "Epoch 3004/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0485 - val_loss: 0.6404\n",
      "Epoch 3005/10000\n",
      "130/130 [==============================] - 0s 814us/step - loss: 0.0438 - val_loss: 0.6377\n",
      "Epoch 3006/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.6235\n",
      "Epoch 3007/10000\n",
      "130/130 [==============================] - 0s 972us/step - loss: 0.0426 - val_loss: 0.6194\n",
      "Epoch 3008/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0402 - val_loss: 0.6423\n",
      "Epoch 3009/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0453 - val_loss: 0.6104\n",
      "Epoch 3010/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0417 - val_loss: 0.6296\n",
      "Epoch 3011/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0471 - val_loss: 0.6485\n",
      "Epoch 3012/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0501 - val_loss: 0.6483\n",
      "Epoch 3013/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0494 - val_loss: 0.6633\n",
      "Epoch 3014/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0493 - val_loss: 0.6415\n",
      "Epoch 3015/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0438 - val_loss: 0.6241\n",
      "Epoch 3016/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0379 - val_loss: 0.6314\n",
      "Epoch 3017/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0399 - val_loss: 0.6413\n",
      "Epoch 3018/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0508 - val_loss: 0.6353\n",
      "Epoch 3019/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0444 - val_loss: 0.6515\n",
      "Epoch 3020/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0440 - val_loss: 0.6499\n",
      "Epoch 3021/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0396 - val_loss: 0.6244\n",
      "Epoch 3022/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0463 - val_loss: 0.6349\n",
      "Epoch 3023/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0491 - val_loss: 0.6172\n",
      "Epoch 3024/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0557 - val_loss: 0.6384\n",
      "Epoch 3025/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0466 - val_loss: 0.6241\n",
      "Epoch 3026/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0452 - val_loss: 0.6546\n",
      "Epoch 3027/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0527 - val_loss: 0.6273\n",
      "Epoch 3028/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0502 - val_loss: 0.6225\n",
      "Epoch 3029/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0463 - val_loss: 0.6513\n",
      "Epoch 3030/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0398 - val_loss: 0.6373\n",
      "Epoch 3031/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0429 - val_loss: 0.6631\n",
      "Epoch 3032/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0421 - val_loss: 0.6258\n",
      "Epoch 3033/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0461 - val_loss: 0.6273\n",
      "Epoch 3034/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0436 - val_loss: 0.6463\n",
      "Epoch 3035/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0454 - val_loss: 0.6432\n",
      "Epoch 3036/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0484 - val_loss: 0.6924\n",
      "Epoch 3037/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0500 - val_loss: 0.6696\n",
      "Epoch 3038/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0479 - val_loss: 0.6351\n",
      "Epoch 3039/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0469 - val_loss: 0.6408\n",
      "Epoch 3040/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0406 - val_loss: 0.6360\n",
      "Epoch 3041/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0395 - val_loss: 0.6416\n",
      "Epoch 3042/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0400 - val_loss: 0.6356\n",
      "Epoch 3043/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 737us/step - loss: 0.0431 - val_loss: 0.6326\n",
      "Epoch 3044/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0467 - val_loss: 0.6189\n",
      "Epoch 3045/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0461 - val_loss: 0.6445\n",
      "Epoch 3046/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0492 - val_loss: 0.6072\n",
      "Epoch 3047/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0434 - val_loss: 0.6290\n",
      "Epoch 3048/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0464 - val_loss: 0.6173\n",
      "Epoch 3049/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0495 - val_loss: 0.6341\n",
      "Epoch 3050/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0499 - val_loss: 0.6351\n",
      "Epoch 3051/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0437 - val_loss: 0.6203\n",
      "Epoch 3052/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0449 - val_loss: 0.6268\n",
      "Epoch 3053/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0516 - val_loss: 0.6322\n",
      "Epoch 3054/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0464 - val_loss: 0.6420\n",
      "Epoch 3055/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0418 - val_loss: 0.6401\n",
      "Epoch 3056/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0420 - val_loss: 0.6454\n",
      "Epoch 3057/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0469 - val_loss: 0.6284\n",
      "Epoch 3058/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0422 - val_loss: 0.6363\n",
      "Epoch 3059/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0459 - val_loss: 0.6503\n",
      "Epoch 3060/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0635 - val_loss: 0.6672\n",
      "Epoch 3061/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0614 - val_loss: 0.6268\n",
      "Epoch 3062/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0476 - val_loss: 0.6566\n",
      "Epoch 3063/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0480 - val_loss: 0.6475\n",
      "Epoch 3064/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0437 - val_loss: 0.6337\n",
      "Epoch 3065/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0499 - val_loss: 0.6224\n",
      "Epoch 3066/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0368 - val_loss: 0.6387\n",
      "Epoch 3067/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0384 - val_loss: 0.6448\n",
      "Epoch 3068/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0412 - val_loss: 0.6401\n",
      "Epoch 3069/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0438 - val_loss: 0.6365\n",
      "Epoch 3070/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0458 - val_loss: 0.6233\n",
      "Epoch 3071/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0455 - val_loss: 0.6441\n",
      "Epoch 3072/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0412 - val_loss: 0.6384\n",
      "Epoch 3073/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0479 - val_loss: 0.6406\n",
      "Epoch 3074/10000\n",
      "130/130 [==============================] - 0s 804us/step - loss: 0.0428 - val_loss: 0.6275\n",
      "Epoch 3075/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0439 - val_loss: 0.6526\n",
      "Epoch 3076/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0421 - val_loss: 0.6388\n",
      "Epoch 3077/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0444 - val_loss: 0.6420\n",
      "Epoch 3078/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0438 - val_loss: 0.6408\n",
      "Epoch 3079/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0446 - val_loss: 0.6459\n",
      "Epoch 3080/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0590 - val_loss: 0.6502\n",
      "Epoch 3081/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0493 - val_loss: 0.6457\n",
      "Epoch 3082/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0406 - val_loss: 0.6414\n",
      "Epoch 3083/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0376 - val_loss: 0.6544\n",
      "Epoch 3084/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0439 - val_loss: 0.6604\n",
      "Epoch 3085/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0531 - val_loss: 0.6433\n",
      "Epoch 3086/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0460 - val_loss: 0.6365\n",
      "Epoch 3087/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0441 - val_loss: 0.6264\n",
      "Epoch 3088/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0396 - val_loss: 0.6248\n",
      "Epoch 3089/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0378 - val_loss: 0.6263\n",
      "Epoch 3090/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0456 - val_loss: 0.6394\n",
      "Epoch 3091/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0519 - val_loss: 0.6360\n",
      "Epoch 3092/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0421 - val_loss: 0.6395\n",
      "Epoch 3093/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0514 - val_loss: 0.6244\n",
      "Epoch 3094/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0463 - val_loss: 0.6242\n",
      "Epoch 3095/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0420 - val_loss: 0.6505\n",
      "Epoch 3096/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0491 - val_loss: 0.6288\n",
      "Epoch 3097/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0416 - val_loss: 0.6491\n",
      "Epoch 3098/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0438 - val_loss: 0.6540\n",
      "Epoch 3099/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0478 - val_loss: 0.6308\n",
      "Epoch 3100/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0438 - val_loss: 0.6369\n",
      "Epoch 3101/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0541 - val_loss: 0.6566\n",
      "Epoch 3102/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0537 - val_loss: 0.6394\n",
      "Epoch 3103/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0446 - val_loss: 0.6458\n",
      "Epoch 3104/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0417 - val_loss: 0.6477\n",
      "Epoch 3105/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0427 - val_loss: 0.6355\n",
      "Epoch 3106/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0429 - val_loss: 0.6215\n",
      "Epoch 3107/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0481 - val_loss: 0.6298\n",
      "Epoch 3108/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0595 - val_loss: 0.6330\n",
      "Epoch 3109/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0572 - val_loss: 0.6551\n",
      "Epoch 3110/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0412 - val_loss: 0.6372\n",
      "Epoch 3111/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0395 - val_loss: 0.6334\n",
      "Epoch 3112/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0412 - val_loss: 0.6374\n",
      "Epoch 3113/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0454 - val_loss: 0.6318\n",
      "Epoch 3114/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0420 - val_loss: 0.6365\n",
      "Epoch 3115/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0392 - val_loss: 0.6333\n",
      "Epoch 3116/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0498 - val_loss: 0.6437\n",
      "Epoch 3117/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0437 - val_loss: 0.6283\n",
      "Epoch 3118/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0390 - val_loss: 0.6364\n",
      "Epoch 3119/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 719us/step - loss: 0.0411 - val_loss: 0.6597\n",
      "Epoch 3120/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0467 - val_loss: 0.6429\n",
      "Epoch 3121/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0430 - val_loss: 0.6494\n",
      "Epoch 3122/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0427 - val_loss: 0.6330\n",
      "Epoch 3123/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0434 - val_loss: 0.6533\n",
      "Epoch 3124/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0603 - val_loss: 0.6167\n",
      "Epoch 3125/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0412 - val_loss: 0.6369\n",
      "Epoch 3126/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0419 - val_loss: 0.6516\n",
      "Epoch 3127/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0394 - val_loss: 0.6585\n",
      "Epoch 3128/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0452 - val_loss: 0.6254\n",
      "Epoch 3129/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0467 - val_loss: 0.6473\n",
      "Epoch 3130/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0457 - val_loss: 0.6559\n",
      "Epoch 3131/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0462 - val_loss: 0.6239\n",
      "Epoch 3132/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0420 - val_loss: 0.6321\n",
      "Epoch 3133/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0475 - val_loss: 0.6380\n",
      "Epoch 3134/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0478 - val_loss: 0.6348\n",
      "Epoch 3135/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0421 - val_loss: 0.6552\n",
      "Epoch 3136/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0507 - val_loss: 0.6209\n",
      "Epoch 3137/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0480 - val_loss: 0.6479\n",
      "Epoch 3138/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0427 - val_loss: 0.6334\n",
      "Epoch 3139/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0457 - val_loss: 0.6507\n",
      "Epoch 3140/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0444 - val_loss: 0.6331\n",
      "Epoch 3141/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0432 - val_loss: 0.6509\n",
      "Epoch 3142/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0439 - val_loss: 0.6463\n",
      "Epoch 3143/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0457 - val_loss: 0.6673\n",
      "Epoch 3144/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0446 - val_loss: 0.6382\n",
      "Epoch 3145/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0418 - val_loss: 0.6495\n",
      "Epoch 3146/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0448 - val_loss: 0.6388\n",
      "Epoch 3147/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0397 - val_loss: 0.6175\n",
      "Epoch 3148/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0411 - val_loss: 0.6163\n",
      "Epoch 3149/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0400 - val_loss: 0.6287\n",
      "Epoch 3150/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0459 - val_loss: 0.6586\n",
      "Epoch 3151/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0449 - val_loss: 0.6291\n",
      "Epoch 3152/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0378 - val_loss: 0.6319\n",
      "Epoch 3153/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0420 - val_loss: 0.6447\n",
      "Epoch 3154/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0408 - val_loss: 0.6270\n",
      "Epoch 3155/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0438 - val_loss: 0.6284\n",
      "Epoch 3156/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0632 - val_loss: 0.6373\n",
      "Epoch 3157/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0496 - val_loss: 0.6319\n",
      "Epoch 3158/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0380 - val_loss: 0.6217\n",
      "Epoch 3159/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0393 - val_loss: 0.6380\n",
      "Epoch 3160/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0443 - val_loss: 0.6502\n",
      "Epoch 3161/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0439 - val_loss: 0.6395\n",
      "Epoch 3162/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0397 - val_loss: 0.6430\n",
      "Epoch 3163/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0443 - val_loss: 0.6443\n",
      "Epoch 3164/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0430 - val_loss: 0.6516\n",
      "Epoch 3165/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0527 - val_loss: 0.6511\n",
      "Epoch 3166/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0385 - val_loss: 0.6607\n",
      "Epoch 3167/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0362 - val_loss: 0.6253\n",
      "Epoch 3168/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0436 - val_loss: 0.6573\n",
      "Epoch 3169/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0490 - val_loss: 0.6487\n",
      "Epoch 3170/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0506 - val_loss: 0.6375\n",
      "Epoch 3171/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0405 - val_loss: 0.6297\n",
      "Epoch 3172/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0420 - val_loss: 0.6503\n",
      "Epoch 3173/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0435 - val_loss: 0.6142\n",
      "Epoch 3174/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0419 - val_loss: 0.6243\n",
      "Epoch 3175/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0389 - val_loss: 0.6488\n",
      "Epoch 3176/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0442 - val_loss: 0.6449\n",
      "Epoch 3177/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0412 - val_loss: 0.6430\n",
      "Epoch 3178/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0475 - val_loss: 0.6389\n",
      "Epoch 3179/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0503 - val_loss: 0.6276\n",
      "Epoch 3180/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0453 - val_loss: 0.6401\n",
      "Epoch 3181/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0443 - val_loss: 0.6338\n",
      "Epoch 3182/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0437 - val_loss: 0.6511\n",
      "Epoch 3183/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0557 - val_loss: 0.6509\n",
      "Epoch 3184/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0479 - val_loss: 0.6410\n",
      "Epoch 3185/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0372 - val_loss: 0.6349\n",
      "Epoch 3186/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0351 - val_loss: 0.6376\n",
      "Epoch 3187/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0381 - val_loss: 0.6332\n",
      "Epoch 3188/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0389 - val_loss: 0.6260\n",
      "Epoch 3189/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0392 - val_loss: 0.6324\n",
      "Epoch 3190/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0399 - val_loss: 0.6487\n",
      "Epoch 3191/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0421 - val_loss: 0.6544\n",
      "Epoch 3192/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0442 - val_loss: 0.6369\n",
      "Epoch 3193/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0371 - val_loss: 0.6261\n",
      "Epoch 3194/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0497 - val_loss: 0.6404\n",
      "Epoch 3195/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 712us/step - loss: 0.0427 - val_loss: 0.6278\n",
      "Epoch 3196/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0519 - val_loss: 0.6606\n",
      "Epoch 3197/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0422 - val_loss: 0.6426\n",
      "Epoch 3198/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0399 - val_loss: 0.6602\n",
      "Epoch 3199/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0361 - val_loss: 0.6464\n",
      "Epoch 3200/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0372 - val_loss: 0.6429\n",
      "Epoch 3201/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0525 - val_loss: 0.6009\n",
      "Epoch 3202/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0616 - val_loss: 0.6391\n",
      "Epoch 3203/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0388 - val_loss: 0.6307\n",
      "Epoch 3204/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0433 - val_loss: 0.6300\n",
      "Epoch 3205/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0522 - val_loss: 0.6181\n",
      "Epoch 3206/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0371 - val_loss: 0.6315\n",
      "Epoch 3207/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0337 - val_loss: 0.6451\n",
      "Epoch 3208/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0384 - val_loss: 0.6227\n",
      "Epoch 3209/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0422 - val_loss: 0.6356\n",
      "Epoch 3210/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0384 - val_loss: 0.6306\n",
      "Epoch 3211/10000\n",
      "130/130 [==============================] - 0s 792us/step - loss: 0.0383 - val_loss: 0.6358\n",
      "Epoch 3212/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0387 - val_loss: 0.6529\n",
      "Epoch 3213/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0422 - val_loss: 0.6384\n",
      "Epoch 3214/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0460 - val_loss: 0.6246\n",
      "Epoch 3215/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0476 - val_loss: 0.6393\n",
      "Epoch 3216/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0500 - val_loss: 0.6699\n",
      "Epoch 3217/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0410 - val_loss: 0.6425\n",
      "Epoch 3218/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0411 - val_loss: 0.6410\n",
      "Epoch 3219/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0415 - val_loss: 0.6154\n",
      "Epoch 3220/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0426 - val_loss: 0.6535\n",
      "Epoch 3221/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0403 - val_loss: 0.6439\n",
      "Epoch 3222/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0396 - val_loss: 0.6609\n",
      "Epoch 3223/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0446 - val_loss: 0.6361\n",
      "Epoch 3224/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0399 - val_loss: 0.6422\n",
      "Epoch 3225/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0362 - val_loss: 0.6442\n",
      "Epoch 3226/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0451 - val_loss: 0.6268\n",
      "Epoch 3227/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0559 - val_loss: 0.6252\n",
      "Epoch 3228/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0475 - val_loss: 0.6610\n",
      "Epoch 3229/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0407 - val_loss: 0.6567\n",
      "Epoch 3230/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0386 - val_loss: 0.6409\n",
      "Epoch 3231/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0369 - val_loss: 0.6272\n",
      "Epoch 3232/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0327 - val_loss: 0.6407\n",
      "Epoch 3233/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0427 - val_loss: 0.6221\n",
      "Epoch 3234/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0435 - val_loss: 0.6365\n",
      "Epoch 3235/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0444 - val_loss: 0.6259\n",
      "Epoch 3236/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0610 - val_loss: 0.6442\n",
      "Epoch 3237/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0476 - val_loss: 0.6254\n",
      "Epoch 3238/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0355 - val_loss: 0.6342\n",
      "Epoch 3239/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0389 - val_loss: 0.6563\n",
      "Epoch 3240/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0422 - val_loss: 0.6448\n",
      "Epoch 3241/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0391 - val_loss: 0.6278\n",
      "Epoch 3242/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0349 - val_loss: 0.6511\n",
      "Epoch 3243/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0456 - val_loss: 0.6329\n",
      "Epoch 3244/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0478 - val_loss: 0.6331\n",
      "Epoch 3245/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0449 - val_loss: 0.6461\n",
      "Epoch 3246/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0384 - val_loss: 0.6304\n",
      "Epoch 3247/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0416 - val_loss: 0.6329\n",
      "Epoch 3248/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0404 - val_loss: 0.6385\n",
      "Epoch 3249/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0412 - val_loss: 0.6326\n",
      "Epoch 3250/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0409 - val_loss: 0.6368\n",
      "Epoch 3251/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0424 - val_loss: 0.6636\n",
      "Epoch 3252/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0421 - val_loss: 0.6467\n",
      "Epoch 3253/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0373 - val_loss: 0.6296\n",
      "Epoch 3254/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0413 - val_loss: 0.6372\n",
      "Epoch 3255/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0394 - val_loss: 0.6656\n",
      "Epoch 3256/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0417 - val_loss: 0.6790\n",
      "Epoch 3257/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0424 - val_loss: 0.6525\n",
      "Epoch 3258/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0372 - val_loss: 0.6423\n",
      "Epoch 3259/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0393 - val_loss: 0.6304\n",
      "Epoch 3260/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0392 - val_loss: 0.6154\n",
      "Epoch 3261/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0396 - val_loss: 0.6381\n",
      "Epoch 3262/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0449 - val_loss: 0.6353\n",
      "Epoch 3263/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0411 - val_loss: 0.6425\n",
      "Epoch 3264/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0392 - val_loss: 0.6495\n",
      "Epoch 3265/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0380 - val_loss: 0.6212\n",
      "Epoch 3266/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0400 - val_loss: 0.6185\n",
      "Epoch 3267/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0396 - val_loss: 0.6365\n",
      "Epoch 3268/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0462 - val_loss: 0.6302\n",
      "Epoch 3269/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0628 - val_loss: 0.6289\n",
      "Epoch 3270/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0422 - val_loss: 0.6436\n",
      "Epoch 3271/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 771us/step - loss: 0.0390 - val_loss: 0.6609\n",
      "Epoch 3272/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0381 - val_loss: 0.6291\n",
      "Epoch 3273/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0412 - val_loss: 0.6506\n",
      "Epoch 3274/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0397 - val_loss: 0.6479\n",
      "Epoch 3275/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0358 - val_loss: 0.6410\n",
      "Epoch 3276/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0393 - val_loss: 0.6496\n",
      "Epoch 3277/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0471 - val_loss: 0.6386\n",
      "Epoch 3278/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0396 - val_loss: 0.6421\n",
      "Epoch 3279/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0351 - val_loss: 0.6509\n",
      "Epoch 3280/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0375 - val_loss: 0.6486\n",
      "Epoch 3281/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0340 - val_loss: 0.6320\n",
      "Epoch 3282/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0503 - val_loss: 0.6304\n",
      "Epoch 3283/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0426 - val_loss: 0.6534\n",
      "Epoch 3284/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0359 - val_loss: 0.6331\n",
      "Epoch 3285/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0399 - val_loss: 0.6523\n",
      "Epoch 3286/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0383 - val_loss: 0.6540\n",
      "Epoch 3287/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0792 - val_loss: 0.6565\n",
      "Epoch 3288/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0684 - val_loss: 0.6244\n",
      "Epoch 3289/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0370 - val_loss: 0.6205\n",
      "Epoch 3290/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0355 - val_loss: 0.6505\n",
      "Epoch 3291/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0432 - val_loss: 0.6394\n",
      "Epoch 3292/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0341 - val_loss: 0.6362\n",
      "Epoch 3293/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0317 - val_loss: 0.6525\n",
      "Epoch 3294/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0402 - val_loss: 0.6171\n",
      "Epoch 3295/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0389 - val_loss: 0.6455\n",
      "Epoch 3296/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0360 - val_loss: 0.6412\n",
      "Epoch 3297/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0411 - val_loss: 0.6680\n",
      "Epoch 3298/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0356 - val_loss: 0.6439\n",
      "Epoch 3299/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0410 - val_loss: 0.6446\n",
      "Epoch 3300/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0460 - val_loss: 0.6281\n",
      "Epoch 3301/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0468 - val_loss: 0.6437\n",
      "Epoch 3302/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0359 - val_loss: 0.6348\n",
      "Epoch 3303/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0344 - val_loss: 0.6411\n",
      "Epoch 3304/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0412 - val_loss: 0.6641\n",
      "Epoch 3305/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0343 - val_loss: 0.6640\n",
      "Epoch 3306/10000\n",
      "130/130 [==============================] - 0s 706us/step - loss: 0.0386 - val_loss: 0.6393\n",
      "Epoch 3307/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0370 - val_loss: 0.6508\n",
      "Epoch 3308/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0460 - val_loss: 0.6175\n",
      "Epoch 3309/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0464 - val_loss: 0.6381\n",
      "Epoch 3310/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0341 - val_loss: 0.6442\n",
      "Epoch 3311/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0392 - val_loss: 0.6383\n",
      "Epoch 3312/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0368 - val_loss: 0.6547\n",
      "Epoch 3313/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0377 - val_loss: 0.6612\n",
      "Epoch 3314/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0415 - val_loss: 0.6485\n",
      "Epoch 3315/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0578 - val_loss: 0.6389\n",
      "Epoch 3316/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0434 - val_loss: 0.6337\n",
      "Epoch 3317/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0390 - val_loss: 0.6272\n",
      "Epoch 3318/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0430 - val_loss: 0.6379\n",
      "Epoch 3319/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0573 - val_loss: 0.6505\n",
      "Epoch 3320/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0496 - val_loss: 0.6441\n",
      "Epoch 3321/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0384 - val_loss: 0.6390\n",
      "Epoch 3322/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0437 - val_loss: 0.6411\n",
      "Epoch 3323/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0348 - val_loss: 0.6337\n",
      "Epoch 3324/10000\n",
      "130/130 [==============================] - 0s 792us/step - loss: 0.0332 - val_loss: 0.6624\n",
      "Epoch 3325/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0322 - val_loss: 0.6432\n",
      "Epoch 3326/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0381 - val_loss: 0.6317\n",
      "Epoch 3327/10000\n",
      "130/130 [==============================] - 0s 839us/step - loss: 0.0413 - val_loss: 0.6188\n",
      "Epoch 3328/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0353 - val_loss: 0.6441\n",
      "Epoch 3329/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0426 - val_loss: 0.6475\n",
      "Epoch 3330/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0339 - val_loss: 0.6529\n",
      "Epoch 3331/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0393 - val_loss: 0.6656\n",
      "Epoch 3332/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0440 - val_loss: 0.6351\n",
      "Epoch 3333/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0410 - val_loss: 0.6461\n",
      "Epoch 3334/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0356 - val_loss: 0.6455\n",
      "Epoch 3335/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0382 - val_loss: 0.6394\n",
      "Epoch 3336/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0438 - val_loss: 0.6368\n",
      "Epoch 3337/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0401 - val_loss: 0.6421\n",
      "Epoch 3338/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0425 - val_loss: 0.6349\n",
      "Epoch 3339/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0443 - val_loss: 0.6472\n",
      "Epoch 3340/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0373 - val_loss: 0.6439\n",
      "Epoch 3341/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0374 - val_loss: 0.6402\n",
      "Epoch 3342/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0408 - val_loss: 0.6394\n",
      "Epoch 3343/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0383 - val_loss: 0.6342\n",
      "Epoch 3344/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0350 - val_loss: 0.6342\n",
      "Epoch 3345/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0362 - val_loss: 0.6455\n",
      "Epoch 3346/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0364 - val_loss: 0.6495\n",
      "Epoch 3347/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 715us/step - loss: 0.0451 - val_loss: 0.6361\n",
      "Epoch 3348/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0477 - val_loss: 0.6509\n",
      "Epoch 3349/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0404 - val_loss: 0.6452\n",
      "Epoch 3350/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0400 - val_loss: 0.6352\n",
      "Epoch 3351/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0386 - val_loss: 0.6408\n",
      "Epoch 3352/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0382 - val_loss: 0.6527\n",
      "Epoch 3353/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0356 - val_loss: 0.6322\n",
      "Epoch 3354/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0369 - val_loss: 0.6538\n",
      "Epoch 3355/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0381 - val_loss: 0.6357\n",
      "Epoch 3356/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0528 - val_loss: 0.6282\n",
      "Epoch 3357/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0455 - val_loss: 0.6369\n",
      "Epoch 3358/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0414 - val_loss: 0.6411\n",
      "Epoch 3359/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0385 - val_loss: 0.6340\n",
      "Epoch 3360/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0402 - val_loss: 0.6188\n",
      "Epoch 3361/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0433 - val_loss: 0.6218\n",
      "Epoch 3362/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0501 - val_loss: 0.6641\n",
      "Epoch 3363/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0410 - val_loss: 0.6469\n",
      "Epoch 3364/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0326 - val_loss: 0.6431\n",
      "Epoch 3365/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0357 - val_loss: 0.6170\n",
      "Epoch 3366/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0408 - val_loss: 0.6348\n",
      "Epoch 3367/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0395 - val_loss: 0.6277\n",
      "Epoch 3368/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0393 - val_loss: 0.6652\n",
      "Epoch 3369/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0415 - val_loss: 0.6448\n",
      "Epoch 3370/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0453 - val_loss: 0.6318\n",
      "Epoch 3371/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0388 - val_loss: 0.6401\n",
      "Epoch 3372/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0368 - val_loss: 0.6406\n",
      "Epoch 3373/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0320 - val_loss: 0.6379\n",
      "Epoch 3374/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0387 - val_loss: 0.6370\n",
      "Epoch 3375/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0371 - val_loss: 0.6355\n",
      "Epoch 3376/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0379 - val_loss: 0.6311\n",
      "Epoch 3377/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0374 - val_loss: 0.6262\n",
      "Epoch 3378/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0410 - val_loss: 0.6396\n",
      "Epoch 3379/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0432 - val_loss: 0.6283\n",
      "Epoch 3380/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0382 - val_loss: 0.6286\n",
      "Epoch 3381/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0395 - val_loss: 0.6340\n",
      "Epoch 3382/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0354 - val_loss: 0.6431\n",
      "Epoch 3383/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0407 - val_loss: 0.6251\n",
      "Epoch 3384/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0430 - val_loss: 0.6194\n",
      "Epoch 3385/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0369 - val_loss: 0.6471\n",
      "Epoch 3386/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0361 - val_loss: 0.6505\n",
      "Epoch 3387/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0353 - val_loss: 0.6380\n",
      "Epoch 3388/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0357 - val_loss: 0.6376\n",
      "Epoch 3389/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0475 - val_loss: 0.6359\n",
      "Epoch 3390/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0473 - val_loss: 0.6398\n",
      "Epoch 3391/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0333 - val_loss: 0.6304\n",
      "Epoch 3392/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0346 - val_loss: 0.6357\n",
      "Epoch 3393/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0332 - val_loss: 0.6287\n",
      "Epoch 3394/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0357 - val_loss: 0.6546\n",
      "Epoch 3395/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0457 - val_loss: 0.6430\n",
      "Epoch 3396/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0425 - val_loss: 0.6397\n",
      "Epoch 3397/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0486 - val_loss: 0.6570\n",
      "Epoch 3398/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0404 - val_loss: 0.6318\n",
      "Epoch 3399/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0354 - val_loss: 0.6481\n",
      "Epoch 3400/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0365 - val_loss: 0.6541\n",
      "Epoch 3401/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0464 - val_loss: 0.6098\n",
      "Epoch 3402/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0457 - val_loss: 0.6406\n",
      "Epoch 3403/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0345 - val_loss: 0.6280\n",
      "Epoch 3404/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0400 - val_loss: 0.6336\n",
      "Epoch 3405/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0410 - val_loss: 0.6408\n",
      "Epoch 3406/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0486 - val_loss: 0.6514\n",
      "Epoch 3407/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0420 - val_loss: 0.6498\n",
      "Epoch 3408/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0312 - val_loss: 0.6426\n",
      "Epoch 3409/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0325 - val_loss: 0.6301\n",
      "Epoch 3410/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0349 - val_loss: 0.6269\n",
      "Epoch 3411/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0349 - val_loss: 0.6373\n",
      "Epoch 3412/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0426 - val_loss: 0.6432\n",
      "Epoch 3413/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0578 - val_loss: 0.6598\n",
      "Epoch 3414/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0616 - val_loss: 0.6284\n",
      "Epoch 3415/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0355 - val_loss: 0.6390\n",
      "Epoch 3416/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0349 - val_loss: 0.6271\n",
      "Epoch 3417/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0334 - val_loss: 0.6424\n",
      "Epoch 3418/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0324 - val_loss: 0.6539\n",
      "Epoch 3419/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0317 - val_loss: 0.6367\n",
      "Epoch 3420/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0449 - val_loss: 0.6288\n",
      "Epoch 3421/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0338 - val_loss: 0.6601\n",
      "Epoch 3422/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0343 - val_loss: 0.6356\n",
      "Epoch 3423/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 721us/step - loss: 0.0400 - val_loss: 0.6169\n",
      "Epoch 3424/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0399 - val_loss: 0.6575\n",
      "Epoch 3425/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0351 - val_loss: 0.6325\n",
      "Epoch 3426/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0355 - val_loss: 0.6305\n",
      "Epoch 3427/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0405 - val_loss: 0.6321\n",
      "Epoch 3428/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0328 - val_loss: 0.6326\n",
      "Epoch 3429/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0429 - val_loss: 0.6439\n",
      "Epoch 3430/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0365 - val_loss: 0.6496\n",
      "Epoch 3431/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0532 - val_loss: 0.6522\n",
      "Epoch 3432/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0466 - val_loss: 0.6443\n",
      "Epoch 3433/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0724 - val_loss: 0.6541\n",
      "Epoch 3434/10000\n",
      "130/130 [==============================] - 0s 706us/step - loss: 0.0359 - val_loss: 0.6529\n",
      "Epoch 3435/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0362 - val_loss: 0.6101\n",
      "Epoch 3436/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0303 - val_loss: 0.6300\n",
      "Epoch 3437/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0360 - val_loss: 0.6361\n",
      "Epoch 3438/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0332 - val_loss: 0.6427\n",
      "Epoch 3439/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0349 - val_loss: 0.6241\n",
      "Epoch 3440/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0364 - val_loss: 0.6372\n",
      "Epoch 3441/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0444 - val_loss: 0.6627\n",
      "Epoch 3442/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0401 - val_loss: 0.6248\n",
      "Epoch 3443/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0306 - val_loss: 0.6331\n",
      "Epoch 3444/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0354 - val_loss: 0.6294\n",
      "Epoch 3445/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0352 - val_loss: 0.6165\n",
      "Epoch 3446/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0326 - val_loss: 0.6188\n",
      "Epoch 3447/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0360 - val_loss: 0.6560\n",
      "Epoch 3448/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0460 - val_loss: 0.6237\n",
      "Epoch 3449/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0360 - val_loss: 0.6472\n",
      "Epoch 3450/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0358 - val_loss: 0.6406\n",
      "Epoch 3451/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0355 - val_loss: 0.6519\n",
      "Epoch 3452/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0409 - val_loss: 0.6530\n",
      "Epoch 3453/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0459 - val_loss: 0.6396\n",
      "Epoch 3454/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0362 - val_loss: 0.6293\n",
      "Epoch 3455/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0363 - val_loss: 0.6582\n",
      "Epoch 3456/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0361 - val_loss: 0.6533\n",
      "Epoch 3457/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0327 - val_loss: 0.6458\n",
      "Epoch 3458/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0403 - val_loss: 0.6445\n",
      "Epoch 3459/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0396 - val_loss: 0.6412\n",
      "Epoch 3460/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0369 - val_loss: 0.6302\n",
      "Epoch 3461/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0386 - val_loss: 0.6440\n",
      "Epoch 3462/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0401 - val_loss: 0.6302\n",
      "Epoch 3463/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0348 - val_loss: 0.6388\n",
      "Epoch 3464/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0362 - val_loss: 0.6352\n",
      "Epoch 3465/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0568 - val_loss: 0.6162\n",
      "Epoch 3466/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0463 - val_loss: 0.6329\n",
      "Epoch 3467/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0371 - val_loss: 0.6231\n",
      "Epoch 3468/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0348 - val_loss: 0.6598\n",
      "Epoch 3469/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0393 - val_loss: 0.6489\n",
      "Epoch 3470/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0431 - val_loss: 0.6334\n",
      "Epoch 3471/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0490 - val_loss: 0.6428\n",
      "Epoch 3472/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0371 - val_loss: 0.6382\n",
      "Epoch 3473/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0300 - val_loss: 0.6401\n",
      "Epoch 3474/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0301 - val_loss: 0.6387\n",
      "Epoch 3475/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0381 - val_loss: 0.6383\n",
      "Epoch 3476/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0374 - val_loss: 0.6551\n",
      "Epoch 3477/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0440 - val_loss: 0.6479\n",
      "Epoch 3478/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0505 - val_loss: 0.6301\n",
      "Epoch 3479/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0400 - val_loss: 0.6210\n",
      "Epoch 3480/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0324 - val_loss: 0.6429\n",
      "Epoch 3481/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0322 - val_loss: 0.6473\n",
      "Epoch 3482/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0339 - val_loss: 0.6361\n",
      "Epoch 3483/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0440 - val_loss: 0.6352\n",
      "Epoch 3484/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0426 - val_loss: 0.6259\n",
      "Epoch 3485/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0357 - val_loss: 0.6410\n",
      "Epoch 3486/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0360 - val_loss: 0.6565\n",
      "Epoch 3487/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0341 - val_loss: 0.6444\n",
      "Epoch 3488/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0341 - val_loss: 0.6349\n",
      "Epoch 3489/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0321 - val_loss: 0.6291\n",
      "Epoch 3490/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0305 - val_loss: 0.6355\n",
      "Epoch 3491/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0375 - val_loss: 0.6383\n",
      "Epoch 3492/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0387 - val_loss: 0.6476\n",
      "Epoch 3493/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0386 - val_loss: 0.6378\n",
      "Epoch 3494/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0486 - val_loss: 0.6480\n",
      "Epoch 3495/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0342 - val_loss: 0.6368\n",
      "Epoch 3496/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0307 - val_loss: 0.6336\n",
      "Epoch 3497/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0358 - val_loss: 0.6411\n",
      "Epoch 3498/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0329 - val_loss: 0.6522\n",
      "Epoch 3499/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 713us/step - loss: 0.0386 - val_loss: 0.6481\n",
      "Epoch 3500/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0482 - val_loss: 0.6108\n",
      "Epoch 3501/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0452 - val_loss: 0.6412\n",
      "Epoch 3502/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0424 - val_loss: 0.6548\n",
      "Epoch 3503/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0398 - val_loss: 0.6328\n",
      "Epoch 3504/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0404 - val_loss: 0.6269\n",
      "Epoch 3505/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0363 - val_loss: 0.6316\n",
      "Epoch 3506/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0331 - val_loss: 0.6466\n",
      "Epoch 3507/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0338 - val_loss: 0.6649\n",
      "Epoch 3508/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0349 - val_loss: 0.6354\n",
      "Epoch 3509/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0284 - val_loss: 0.6428\n",
      "Epoch 3510/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0429 - val_loss: 0.6442\n",
      "Epoch 3511/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0405 - val_loss: 0.6280\n",
      "Epoch 3512/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0347 - val_loss: 0.6363\n",
      "Epoch 3513/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0382 - val_loss: 0.6619\n",
      "Epoch 3514/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0443 - val_loss: 0.6417\n",
      "Epoch 3515/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0386 - val_loss: 0.6248\n",
      "Epoch 3516/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0367 - val_loss: 0.6550\n",
      "Epoch 3517/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0315 - val_loss: 0.6383\n",
      "Epoch 3518/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0334 - val_loss: 0.6389\n",
      "Epoch 3519/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0383 - val_loss: 0.6457\n",
      "Epoch 3520/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0420 - val_loss: 0.6354\n",
      "Epoch 3521/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0456 - val_loss: 0.6668\n",
      "Epoch 3522/10000\n",
      "130/130 [==============================] - 0s 706us/step - loss: 0.0406 - val_loss: 0.6194\n",
      "Epoch 3523/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0295 - val_loss: 0.6210\n",
      "Epoch 3524/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0320 - val_loss: 0.6467\n",
      "Epoch 3525/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0406 - val_loss: 0.6341\n",
      "Epoch 3526/10000\n",
      "130/130 [==============================] - 0s 703us/step - loss: 0.0446 - val_loss: 0.6535\n",
      "Epoch 3527/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0466 - val_loss: 0.6357\n",
      "Epoch 3528/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0416 - val_loss: 0.6552\n",
      "Epoch 3529/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0329 - val_loss: 0.6335\n",
      "Epoch 3530/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0395 - val_loss: 0.6237\n",
      "Epoch 3531/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0347 - val_loss: 0.6371\n",
      "Epoch 3532/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0321 - val_loss: 0.6392\n",
      "Epoch 3533/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0312 - val_loss: 0.6451\n",
      "Epoch 3534/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0376 - val_loss: 0.6486\n",
      "Epoch 3535/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0404 - val_loss: 0.6585\n",
      "Epoch 3536/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0352 - val_loss: 0.6459\n",
      "Epoch 3537/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0336 - val_loss: 0.6445\n",
      "Epoch 3538/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0327 - val_loss: 0.6289\n",
      "Epoch 3539/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0379 - val_loss: 0.6538\n",
      "Epoch 3540/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0335 - val_loss: 0.6472\n",
      "Epoch 3541/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0351 - val_loss: 0.6496\n",
      "Epoch 3542/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0390 - val_loss: 0.6329\n",
      "Epoch 3543/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0369 - val_loss: 0.6623\n",
      "Epoch 3544/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0393 - val_loss: 0.6503\n",
      "Epoch 3545/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0448 - val_loss: 0.6620\n",
      "Epoch 3546/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0394 - val_loss: 0.6424\n",
      "Epoch 3547/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0471 - val_loss: 0.6437\n",
      "Epoch 3548/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0440 - val_loss: 0.6339\n",
      "Epoch 3549/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0392 - val_loss: 0.6438\n",
      "Epoch 3550/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0336 - val_loss: 0.6411\n",
      "Epoch 3551/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0291 - val_loss: 0.6328\n",
      "Epoch 3552/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0327 - val_loss: 0.6340\n",
      "Epoch 3553/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0389 - val_loss: 0.6426\n",
      "Epoch 3554/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0368 - val_loss: 0.6164\n",
      "Epoch 3555/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0395 - val_loss: 0.6481\n",
      "Epoch 3556/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0381 - val_loss: 0.6198\n",
      "Epoch 3557/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0309 - val_loss: 0.6495\n",
      "Epoch 3558/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0318 - val_loss: 0.6675\n",
      "Epoch 3559/10000\n",
      "130/130 [==============================] - 0s 703us/step - loss: 0.0337 - val_loss: 0.6314\n",
      "Epoch 3560/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0362 - val_loss: 0.6321\n",
      "Epoch 3561/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0347 - val_loss: 0.6428\n",
      "Epoch 3562/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0370 - val_loss: 0.6419\n",
      "Epoch 3563/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0411 - val_loss: 0.6427\n",
      "Epoch 3564/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0400 - val_loss: 0.6311\n",
      "Epoch 3565/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0405 - val_loss: 0.6561\n",
      "Epoch 3566/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0364 - val_loss: 0.6499\n",
      "Epoch 3567/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0338 - val_loss: 0.6447\n",
      "Epoch 3568/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0329 - val_loss: 0.6612\n",
      "Epoch 3569/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0341 - val_loss: 0.6542\n",
      "Epoch 3570/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0498 - val_loss: 0.6650\n",
      "Epoch 3571/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0392 - val_loss: 0.6265\n",
      "Epoch 3572/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0337 - val_loss: 0.6319\n",
      "Epoch 3573/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0450 - val_loss: 0.6299\n",
      "Epoch 3574/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0358 - val_loss: 0.6553\n",
      "Epoch 3575/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 714us/step - loss: 0.0271 - val_loss: 0.6323\n",
      "Epoch 3576/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0281 - val_loss: 0.6523\n",
      "Epoch 3577/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0349 - val_loss: 0.6564\n",
      "Epoch 3578/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0433 - val_loss: 0.6387\n",
      "Epoch 3579/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0338 - val_loss: 0.6389\n",
      "Epoch 3580/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0396 - val_loss: 0.6451\n",
      "Epoch 3581/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0343 - val_loss: 0.6449\n",
      "Epoch 3582/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0327 - val_loss: 0.6342\n",
      "Epoch 3583/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0352 - val_loss: 0.6366\n",
      "Epoch 3584/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0309 - val_loss: 0.6466\n",
      "Epoch 3585/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0343 - val_loss: 0.6389\n",
      "Epoch 3586/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0318 - val_loss: 0.6357\n",
      "Epoch 3587/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0326 - val_loss: 0.6386\n",
      "Epoch 3588/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0394 - val_loss: 0.6286\n",
      "Epoch 3589/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0443 - val_loss: 0.6379\n",
      "Epoch 3590/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0533 - val_loss: 0.6187\n",
      "Epoch 3591/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0475 - val_loss: 0.6430\n",
      "Epoch 3592/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0397 - val_loss: 0.6413\n",
      "Epoch 3593/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0319 - val_loss: 0.6447\n",
      "Epoch 3594/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0315 - val_loss: 0.6316\n",
      "Epoch 3595/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0345 - val_loss: 0.6262\n",
      "Epoch 3596/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0326 - val_loss: 0.6313\n",
      "Epoch 3597/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0299 - val_loss: 0.6353\n",
      "Epoch 3598/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0328 - val_loss: 0.6566\n",
      "Epoch 3599/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0350 - val_loss: 0.6338\n",
      "Epoch 3600/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0328 - val_loss: 0.6390\n",
      "Epoch 3601/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0312 - val_loss: 0.6432\n",
      "Epoch 3602/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0490 - val_loss: 0.6450\n",
      "Epoch 3603/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0311 - val_loss: 0.6324\n",
      "Epoch 3604/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0315 - val_loss: 0.6271\n",
      "Epoch 3605/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0362 - val_loss: 0.6469\n",
      "Epoch 3606/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0366 - val_loss: 0.6307\n",
      "Epoch 3607/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0332 - val_loss: 0.6569\n",
      "Epoch 3608/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0346 - val_loss: 0.6356\n",
      "Epoch 3609/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0399 - val_loss: 0.6214\n",
      "Epoch 3610/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0429 - val_loss: 0.6381\n",
      "Epoch 3611/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0326 - val_loss: 0.6414\n",
      "Epoch 3612/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0304 - val_loss: 0.6533\n",
      "Epoch 3613/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0313 - val_loss: 0.6389\n",
      "Epoch 3614/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0310 - val_loss: 0.6383\n",
      "Epoch 3615/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0380 - val_loss: 0.6486\n",
      "Epoch 3616/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0482 - val_loss: 0.6482\n",
      "Epoch 3617/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0375 - val_loss: 0.6567\n",
      "Epoch 3618/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0621 - val_loss: 0.6428\n",
      "Epoch 3619/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0424 - val_loss: 0.6380\n",
      "Epoch 3620/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0271 - val_loss: 0.6446\n",
      "Epoch 3621/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0271 - val_loss: 0.6318\n",
      "Epoch 3622/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0291 - val_loss: 0.6364\n",
      "Epoch 3623/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0354 - val_loss: 0.6443\n",
      "Epoch 3624/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0300 - val_loss: 0.6413\n",
      "Epoch 3625/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0292 - val_loss: 0.6474\n",
      "Epoch 3626/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0281 - val_loss: 0.6440\n",
      "Epoch 3627/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0369 - val_loss: 0.6590\n",
      "Epoch 3628/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0683 - val_loss: 0.6608\n",
      "Epoch 3629/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0481 - val_loss: 0.6192\n",
      "Epoch 3630/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0362 - val_loss: 0.6304\n",
      "Epoch 3631/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0360 - val_loss: 0.6274\n",
      "Epoch 3632/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0295 - val_loss: 0.6378\n",
      "Epoch 3633/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0282 - val_loss: 0.6272\n",
      "Epoch 3634/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0299 - val_loss: 0.6477\n",
      "Epoch 3635/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0343 - val_loss: 0.6430\n",
      "Epoch 3636/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0357 - val_loss: 0.6219\n",
      "Epoch 3637/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0352 - val_loss: 0.6278\n",
      "Epoch 3638/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0369 - val_loss: 0.6217\n",
      "Epoch 3639/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0358 - val_loss: 0.6603\n",
      "Epoch 3640/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0598 - val_loss: 0.6146\n",
      "Epoch 3641/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0507 - val_loss: 0.6354\n",
      "Epoch 3642/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0373 - val_loss: 0.6328\n",
      "Epoch 3643/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0272 - val_loss: 0.6363\n",
      "Epoch 3644/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0349 - val_loss: 0.6433\n",
      "Epoch 3645/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0333 - val_loss: 0.6341\n",
      "Epoch 3646/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0329 - val_loss: 0.6469\n",
      "Epoch 3647/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0363 - val_loss: 0.6500\n",
      "Epoch 3648/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0374 - val_loss: 0.6486\n",
      "Epoch 3649/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0330 - val_loss: 0.6435\n",
      "Epoch 3650/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0297 - val_loss: 0.6392\n",
      "Epoch 3651/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 717us/step - loss: 0.0312 - val_loss: 0.6446\n",
      "Epoch 3652/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0363 - val_loss: 0.6356\n",
      "Epoch 3653/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0303 - val_loss: 0.6245\n",
      "Epoch 3654/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0472 - val_loss: 0.6448\n",
      "Epoch 3655/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0393 - val_loss: 0.6123\n",
      "Epoch 3656/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0370 - val_loss: 0.6278\n",
      "Epoch 3657/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0378 - val_loss: 0.6303\n",
      "Epoch 3658/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0313 - val_loss: 0.6298\n",
      "Epoch 3659/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0361 - val_loss: 0.6235\n",
      "Epoch 3660/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0554 - val_loss: 0.6332\n",
      "Epoch 3661/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0366 - val_loss: 0.6395\n",
      "Epoch 3662/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0316 - val_loss: 0.6261\n",
      "Epoch 3663/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0310 - val_loss: 0.6203\n",
      "Epoch 3664/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0330 - val_loss: 0.6403\n",
      "Epoch 3665/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0310 - val_loss: 0.6314\n",
      "Epoch 3666/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0354 - val_loss: 0.6501\n",
      "Epoch 3667/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0338 - val_loss: 0.6461\n",
      "Epoch 3668/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0315 - val_loss: 0.6397\n",
      "Epoch 3669/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0295 - val_loss: 0.6528\n",
      "Epoch 3670/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0295 - val_loss: 0.6552\n",
      "Epoch 3671/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0423 - val_loss: 0.6532\n",
      "Epoch 3672/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0423 - val_loss: 0.6410\n",
      "Epoch 3673/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0368 - val_loss: 0.6367\n",
      "Epoch 3674/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0308 - val_loss: 0.6324\n",
      "Epoch 3675/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0338 - val_loss: 0.6400\n",
      "Epoch 3676/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0296 - val_loss: 0.6530\n",
      "Epoch 3677/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0324 - val_loss: 0.6099\n",
      "Epoch 3678/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0354 - val_loss: 0.6390\n",
      "Epoch 3679/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0680 - val_loss: 0.6617\n",
      "Epoch 3680/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0658 - val_loss: 0.6342\n",
      "Epoch 3681/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0332 - val_loss: 0.6348\n",
      "Epoch 3682/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0275 - val_loss: 0.6322\n",
      "Epoch 3683/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0268 - val_loss: 0.6470\n",
      "Epoch 3684/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0308 - val_loss: 0.6400\n",
      "Epoch 3685/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0346 - val_loss: 0.6426\n",
      "Epoch 3686/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0356 - val_loss: 0.6225\n",
      "Epoch 3687/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0320 - val_loss: 0.6199\n",
      "Epoch 3688/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0327 - val_loss: 0.6520\n",
      "Epoch 3689/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0315 - val_loss: 0.6472\n",
      "Epoch 3690/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0331 - val_loss: 0.6446\n",
      "Epoch 3691/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0482 - val_loss: 0.6386\n",
      "Epoch 3692/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0407 - val_loss: 0.6388\n",
      "Epoch 3693/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0403 - val_loss: 0.6580\n",
      "Epoch 3694/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0287 - val_loss: 0.6412\n",
      "Epoch 3695/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0349 - val_loss: 0.6104\n",
      "Epoch 3696/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0334 - val_loss: 0.6489\n",
      "Epoch 3697/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0291 - val_loss: 0.6287\n",
      "Epoch 3698/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0318 - val_loss: 0.6427\n",
      "Epoch 3699/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0459 - val_loss: 0.6713\n",
      "Epoch 3700/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0393 - val_loss: 0.6222\n",
      "Epoch 3701/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0328 - val_loss: 0.6560\n",
      "Epoch 3702/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0364 - val_loss: 0.6277\n",
      "Epoch 3703/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0327 - val_loss: 0.6341\n",
      "Epoch 3704/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0276 - val_loss: 0.6248\n",
      "Epoch 3705/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0270 - val_loss: 0.6389\n",
      "Epoch 3706/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0323 - val_loss: 0.6297\n",
      "Epoch 3707/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0347 - val_loss: 0.6489\n",
      "Epoch 3708/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0349 - val_loss: 0.6209\n",
      "Epoch 3709/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0395 - val_loss: 0.6342\n",
      "Epoch 3710/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0331 - val_loss: 0.6463\n",
      "Epoch 3711/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0363 - val_loss: 0.6407\n",
      "Epoch 3712/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0367 - val_loss: 0.6368\n",
      "Epoch 3713/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0459 - val_loss: 0.6423\n",
      "Epoch 3714/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0426 - val_loss: 0.6218\n",
      "Epoch 3715/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0352 - val_loss: 0.6335\n",
      "Epoch 3716/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0307 - val_loss: 0.6641\n",
      "Epoch 3717/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0306 - val_loss: 0.6453\n",
      "Epoch 3718/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0306 - val_loss: 0.6394\n",
      "Epoch 3719/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0301 - val_loss: 0.6410\n",
      "Epoch 3720/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0319 - val_loss: 0.6366\n",
      "Epoch 3721/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0431 - val_loss: 0.6210\n",
      "Epoch 3722/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0307 - val_loss: 0.6372\n",
      "Epoch 3723/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0282 - val_loss: 0.6479\n",
      "Epoch 3724/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0347 - val_loss: 0.6525\n",
      "Epoch 3725/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0490 - val_loss: 0.6523\n",
      "Epoch 3726/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0342 - val_loss: 0.6344\n",
      "Epoch 3727/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 720us/step - loss: 0.0323 - val_loss: 0.6614\n",
      "Epoch 3728/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0318 - val_loss: 0.6362\n",
      "Epoch 3729/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0307 - val_loss: 0.6304\n",
      "Epoch 3730/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0352 - val_loss: 0.6425\n",
      "Epoch 3731/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0355 - val_loss: 0.6317\n",
      "Epoch 3732/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0343 - val_loss: 0.6478\n",
      "Epoch 3733/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0314 - val_loss: 0.6465\n",
      "Epoch 3734/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0258 - val_loss: 0.6481\n",
      "Epoch 3735/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0313 - val_loss: 0.6517\n",
      "Epoch 3736/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0388 - val_loss: 0.6185\n",
      "Epoch 3737/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0427 - val_loss: 0.6428\n",
      "Epoch 3738/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0364 - val_loss: 0.6323\n",
      "Epoch 3739/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0397 - val_loss: 0.6353\n",
      "Epoch 3740/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0357 - val_loss: 0.6578\n",
      "Epoch 3741/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0379 - val_loss: 0.6143\n",
      "Epoch 3742/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0404 - val_loss: 0.6271\n",
      "Epoch 3743/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0341 - val_loss: 0.6418\n",
      "Epoch 3744/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0324 - val_loss: 0.6405\n",
      "Epoch 3745/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0368 - val_loss: 0.6413\n",
      "Epoch 3746/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0338 - val_loss: 0.6344\n",
      "Epoch 3747/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0304 - val_loss: 0.6313\n",
      "Epoch 3748/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0301 - val_loss: 0.6450\n",
      "Epoch 3749/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0305 - val_loss: 0.6334\n",
      "Epoch 3750/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0344 - val_loss: 0.6273\n",
      "Epoch 3751/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0317 - val_loss: 0.6352\n",
      "Epoch 3752/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0321 - val_loss: 0.6358\n",
      "Epoch 3753/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0327 - val_loss: 0.6413\n",
      "Epoch 3754/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0310 - val_loss: 0.6324\n",
      "Epoch 3755/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0333 - val_loss: 0.6190\n",
      "Epoch 3756/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0356 - val_loss: 0.6160\n",
      "Epoch 3757/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0455 - val_loss: 0.6608\n",
      "Epoch 3758/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0336 - val_loss: 0.6338\n",
      "Epoch 3759/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0272 - val_loss: 0.6335\n",
      "Epoch 3760/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0262 - val_loss: 0.6387\n",
      "Epoch 3761/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0348 - val_loss: 0.6422\n",
      "Epoch 3762/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0371 - val_loss: 0.6605\n",
      "Epoch 3763/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0368 - val_loss: 0.6336\n",
      "Epoch 3764/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0272 - val_loss: 0.6278\n",
      "Epoch 3765/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0285 - val_loss: 0.6413\n",
      "Epoch 3766/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0315 - val_loss: 0.6229\n",
      "Epoch 3767/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0358 - val_loss: 0.6330\n",
      "Epoch 3768/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0488 - val_loss: 0.6642\n",
      "Epoch 3769/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0334 - val_loss: 0.6299\n",
      "Epoch 3770/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0308 - val_loss: 0.6211\n",
      "Epoch 3771/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0361 - val_loss: 0.6302\n",
      "Epoch 3772/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0472 - val_loss: 0.6457\n",
      "Epoch 3773/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0357 - val_loss: 0.6422\n",
      "Epoch 3774/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0260 - val_loss: 0.6487\n",
      "Epoch 3775/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0316 - val_loss: 0.6394\n",
      "Epoch 3776/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0329 - val_loss: 0.6494\n",
      "Epoch 3777/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0322 - val_loss: 0.6223\n",
      "Epoch 3778/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0299 - val_loss: 0.6331\n",
      "Epoch 3779/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0322 - val_loss: 0.6520\n",
      "Epoch 3780/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0535 - val_loss: 0.6383\n",
      "Epoch 3781/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0556 - val_loss: 0.6362\n",
      "Epoch 3782/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0389 - val_loss: 0.6226\n",
      "Epoch 3783/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0307 - val_loss: 0.6531\n",
      "Epoch 3784/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0290 - val_loss: 0.6459\n",
      "Epoch 3785/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0297 - val_loss: 0.6472\n",
      "Epoch 3786/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0267 - val_loss: 0.6486\n",
      "Epoch 3787/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0247 - val_loss: 0.6444\n",
      "Epoch 3788/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0279 - val_loss: 0.6369\n",
      "Epoch 3789/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0299 - val_loss: 0.6372\n",
      "Epoch 3790/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0404 - val_loss: 0.6636\n",
      "Epoch 3791/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0760 - val_loss: 0.5989\n",
      "Epoch 3792/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0443 - val_loss: 0.6308\n",
      "Epoch 3793/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0284 - val_loss: 0.6350\n",
      "Epoch 3794/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0259 - val_loss: 0.6569\n",
      "Epoch 3795/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0250 - val_loss: 0.6474\n",
      "Epoch 3796/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0273 - val_loss: 0.6467\n",
      "Epoch 3797/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0275 - val_loss: 0.6449\n",
      "Epoch 3798/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0299 - val_loss: 0.6421\n",
      "Epoch 3799/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0292 - val_loss: 0.6331\n",
      "Epoch 3800/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0317 - val_loss: 0.6306\n",
      "Epoch 3801/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0350 - val_loss: 0.6397\n",
      "Epoch 3802/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0446 - val_loss: 0.6271\n",
      "Epoch 3803/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 734us/step - loss: 0.0344 - val_loss: 0.6382\n",
      "Epoch 3804/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0399 - val_loss: 0.6262\n",
      "Epoch 3805/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0360 - val_loss: 0.6534\n",
      "Epoch 3806/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0293 - val_loss: 0.6307\n",
      "Epoch 3807/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0329 - val_loss: 0.6151\n",
      "Epoch 3808/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0313 - val_loss: 0.6227\n",
      "Epoch 3809/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0286 - val_loss: 0.6370\n",
      "Epoch 3810/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0342 - val_loss: 0.6389\n",
      "Epoch 3811/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0306 - val_loss: 0.6422\n",
      "Epoch 3812/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0310 - val_loss: 0.6362\n",
      "Epoch 3813/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0334 - val_loss: 0.6389\n",
      "Epoch 3814/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0370 - val_loss: 0.6267\n",
      "Epoch 3815/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0340 - val_loss: 0.6551\n",
      "Epoch 3816/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0377 - val_loss: 0.6618\n",
      "Epoch 3817/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0330 - val_loss: 0.6356\n",
      "Epoch 3818/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0306 - val_loss: 0.6311\n",
      "Epoch 3819/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0285 - val_loss: 0.6199\n",
      "Epoch 3820/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0312 - val_loss: 0.6477\n",
      "Epoch 3821/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0308 - val_loss: 0.6383\n",
      "Epoch 3822/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0354 - val_loss: 0.6605\n",
      "Epoch 3823/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0320 - val_loss: 0.6709\n",
      "Epoch 3824/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0771 - val_loss: 0.6497\n",
      "Epoch 3825/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0483 - val_loss: 0.6495\n",
      "Epoch 3826/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0351 - val_loss: 0.6192\n",
      "Epoch 3827/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0313 - val_loss: 0.6323\n",
      "Epoch 3828/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0310 - val_loss: 0.6368\n",
      "Epoch 3829/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0264 - val_loss: 0.6558\n",
      "Epoch 3830/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0282 - val_loss: 0.6529\n",
      "Epoch 3831/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0315 - val_loss: 0.6370\n",
      "Epoch 3832/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0405 - val_loss: 0.6337\n",
      "Epoch 3833/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0324 - val_loss: 0.6471\n",
      "Epoch 3834/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0301 - val_loss: 0.6400\n",
      "Epoch 3835/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0262 - val_loss: 0.6312\n",
      "Epoch 3836/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0304 - val_loss: 0.6428\n",
      "Epoch 3837/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0377 - val_loss: 0.6462\n",
      "Epoch 3838/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0362 - val_loss: 0.6457\n",
      "Epoch 3839/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0363 - val_loss: 0.6294\n",
      "Epoch 3840/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0329 - val_loss: 0.6358\n",
      "Epoch 3841/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0289 - val_loss: 0.6288\n",
      "Epoch 3842/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0286 - val_loss: 0.6430\n",
      "Epoch 3843/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0294 - val_loss: 0.6435\n",
      "Epoch 3844/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0282 - val_loss: 0.6391\n",
      "Epoch 3845/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0281 - val_loss: 0.6420\n",
      "Epoch 3846/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0377 - val_loss: 0.6593\n",
      "Epoch 3847/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0573 - val_loss: 0.6584\n",
      "Epoch 3848/10000\n",
      "130/130 [==============================] - 0s 824us/step - loss: 0.0395 - val_loss: 0.6341\n",
      "Epoch 3849/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0333 - val_loss: 0.6242\n",
      "Epoch 3850/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0364 - val_loss: 0.6243\n",
      "Epoch 3851/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0286 - val_loss: 0.6304\n",
      "Epoch 3852/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0265 - val_loss: 0.6325\n",
      "Epoch 3853/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0279 - val_loss: 0.6366\n",
      "Epoch 3854/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0270 - val_loss: 0.6280\n",
      "Epoch 3855/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0303 - val_loss: 0.6425\n",
      "Epoch 3856/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0315 - val_loss: 0.6303\n",
      "Epoch 3857/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0346 - val_loss: 0.6193\n",
      "Epoch 3858/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0402 - val_loss: 0.6396\n",
      "Epoch 3859/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0400 - val_loss: 0.6292\n",
      "Epoch 3860/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0260 - val_loss: 0.6288\n",
      "Epoch 3861/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0279 - val_loss: 0.6290\n",
      "Epoch 3862/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0316 - val_loss: 0.6534\n",
      "Epoch 3863/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0335 - val_loss: 0.6357\n",
      "Epoch 3864/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0399 - val_loss: 0.6329\n",
      "Epoch 3865/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0332 - val_loss: 0.6516\n",
      "Epoch 3866/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0277 - val_loss: 0.6348\n",
      "Epoch 3867/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0254 - val_loss: 0.6553\n",
      "Epoch 3868/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0270 - val_loss: 0.6479\n",
      "Epoch 3869/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0350 - val_loss: 0.6628\n",
      "Epoch 3870/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0507 - val_loss: 0.6468\n",
      "Epoch 3871/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0387 - val_loss: 0.6447\n",
      "Epoch 3872/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0327 - val_loss: 0.6381\n",
      "Epoch 3873/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0319 - val_loss: 0.6413\n",
      "Epoch 3874/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0269 - val_loss: 0.6430\n",
      "Epoch 3875/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0279 - val_loss: 0.6436\n",
      "Epoch 3876/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0324 - val_loss: 0.6361\n",
      "Epoch 3877/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0417 - val_loss: 0.6393\n",
      "Epoch 3878/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0353 - val_loss: 0.6389\n",
      "Epoch 3879/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 725us/step - loss: 0.0339 - val_loss: 0.6661\n",
      "Epoch 3880/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0322 - val_loss: 0.6316\n",
      "Epoch 3881/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0283 - val_loss: 0.6469\n",
      "Epoch 3882/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0271 - val_loss: 0.6365\n",
      "Epoch 3883/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0352 - val_loss: 0.6670\n",
      "Epoch 3884/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0319 - val_loss: 0.6386\n",
      "Epoch 3885/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0315 - val_loss: 0.6386\n",
      "Epoch 3886/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0318 - val_loss: 0.6419\n",
      "Epoch 3887/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0320 - val_loss: 0.6304\n",
      "Epoch 3888/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0346 - val_loss: 0.6490\n",
      "Epoch 3889/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0364 - val_loss: 0.6323\n",
      "Epoch 3890/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0321 - val_loss: 0.6344\n",
      "Epoch 3891/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0326 - val_loss: 0.6151\n",
      "Epoch 3892/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0281 - val_loss: 0.6398\n",
      "Epoch 3893/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0313 - val_loss: 0.6407\n",
      "Epoch 3894/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0249 - val_loss: 0.6553\n",
      "Epoch 3895/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0302 - val_loss: 0.6349\n",
      "Epoch 3896/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0334 - val_loss: 0.6480\n",
      "Epoch 3897/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0308 - val_loss: 0.6380\n",
      "Epoch 3898/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0274 - val_loss: 0.6457\n",
      "Epoch 3899/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0393 - val_loss: 0.6660\n",
      "Epoch 3900/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0473 - val_loss: 0.6510\n",
      "Epoch 3901/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0399 - val_loss: 0.6322\n",
      "Epoch 3902/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0334 - val_loss: 0.6493\n",
      "Epoch 3903/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0282 - val_loss: 0.6330\n",
      "Epoch 3904/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0260 - val_loss: 0.6377\n",
      "Epoch 3905/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0302 - val_loss: 0.6509\n",
      "Epoch 3906/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0344 - val_loss: 0.6258\n",
      "Epoch 3907/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0331 - val_loss: 0.6560\n",
      "Epoch 3908/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0310 - val_loss: 0.6419\n",
      "Epoch 3909/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0344 - val_loss: 0.6457\n",
      "Epoch 3910/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0297 - val_loss: 0.6440\n",
      "Epoch 3911/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0324 - val_loss: 0.6271\n",
      "Epoch 3912/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0373 - val_loss: 0.6450\n",
      "Epoch 3913/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0312 - val_loss: 0.6474\n",
      "Epoch 3914/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0316 - val_loss: 0.6310\n",
      "Epoch 3915/10000\n",
      "130/130 [==============================] - 0s 815us/step - loss: 0.0339 - val_loss: 0.6161\n",
      "Epoch 3916/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0297 - val_loss: 0.6466\n",
      "Epoch 3917/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0369 - val_loss: 0.6629\n",
      "Epoch 3918/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0428 - val_loss: 0.6389\n",
      "Epoch 3919/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0324 - val_loss: 0.6410\n",
      "Epoch 3920/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0293 - val_loss: 0.6361\n",
      "Epoch 3921/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0382 - val_loss: 0.6208\n",
      "Epoch 3922/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0326 - val_loss: 0.6306\n",
      "Epoch 3923/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0303 - val_loss: 0.6511\n",
      "Epoch 3924/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0285 - val_loss: 0.6313\n",
      "Epoch 3925/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0247 - val_loss: 0.6442\n",
      "Epoch 3926/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0312 - val_loss: 0.6395\n",
      "Epoch 3927/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0356 - val_loss: 0.6748\n",
      "Epoch 3928/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0328 - val_loss: 0.6441\n",
      "Epoch 3929/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0297 - val_loss: 0.6512\n",
      "Epoch 3930/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0308 - val_loss: 0.6476\n",
      "Epoch 3931/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0326 - val_loss: 0.6465\n",
      "Epoch 3932/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0306 - val_loss: 0.6162\n",
      "Epoch 3933/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0293 - val_loss: 0.6433\n",
      "Epoch 3934/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0356 - val_loss: 0.6434\n",
      "Epoch 3935/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0297 - val_loss: 0.6480\n",
      "Epoch 3936/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0364 - val_loss: 0.6191\n",
      "Epoch 3937/10000\n",
      "130/130 [==============================] - 0s 813us/step - loss: 0.0266 - val_loss: 0.6290\n",
      "Epoch 3938/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0334 - val_loss: 0.6411\n",
      "Epoch 3939/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0283 - val_loss: 0.6482\n",
      "Epoch 3940/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0291 - val_loss: 0.6452\n",
      "Epoch 3941/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0368 - val_loss: 0.6563\n",
      "Epoch 3942/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0346 - val_loss: 0.6341\n",
      "Epoch 3943/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0375 - val_loss: 0.6226\n",
      "Epoch 3944/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0444 - val_loss: 0.6262\n",
      "Epoch 3945/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0343 - val_loss: 0.6327\n",
      "Epoch 3946/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0285 - val_loss: 0.6254\n",
      "Epoch 3947/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0256 - val_loss: 0.6242\n",
      "Epoch 3948/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0329 - val_loss: 0.6369\n",
      "Epoch 3949/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0313 - val_loss: 0.6508\n",
      "Epoch 3950/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0271 - val_loss: 0.6515\n",
      "Epoch 3951/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0266 - val_loss: 0.6269\n",
      "Epoch 3952/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0314 - val_loss: 0.6342\n",
      "Epoch 3953/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0332 - val_loss: 0.6275\n",
      "Epoch 3954/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0476 - val_loss: 0.6222\n",
      "Epoch 3955/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 715us/step - loss: 0.0407 - val_loss: 0.6314\n",
      "Epoch 3956/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0283 - val_loss: 0.6346\n",
      "Epoch 3957/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0272 - val_loss: 0.6404\n",
      "Epoch 3958/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0292 - val_loss: 0.6242\n",
      "Epoch 3959/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0347 - val_loss: 0.6627\n",
      "Epoch 3960/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0316 - val_loss: 0.6303\n",
      "Epoch 3961/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0304 - val_loss: 0.6239\n",
      "Epoch 3962/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0365 - val_loss: 0.6354\n",
      "Epoch 3963/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0264 - val_loss: 0.6556\n",
      "Epoch 3964/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0306 - val_loss: 0.6401\n",
      "Epoch 3965/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0316 - val_loss: 0.6362\n",
      "Epoch 3966/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0342 - val_loss: 0.6435\n",
      "Epoch 3967/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0360 - val_loss: 0.6602\n",
      "Epoch 3968/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0325 - val_loss: 0.6181\n",
      "Epoch 3969/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0332 - val_loss: 0.6466\n",
      "Epoch 3970/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0311 - val_loss: 0.6418\n",
      "Epoch 3971/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0312 - val_loss: 0.6413\n",
      "Epoch 3972/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0282 - val_loss: 0.6371\n",
      "Epoch 3973/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0272 - val_loss: 0.6503\n",
      "Epoch 3974/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0288 - val_loss: 0.6232\n",
      "Epoch 3975/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0280 - val_loss: 0.6362\n",
      "Epoch 3976/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0258 - val_loss: 0.6228\n",
      "Epoch 3977/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0372 - val_loss: 0.6447\n",
      "Epoch 3978/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0293 - val_loss: 0.6576\n",
      "Epoch 3979/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0270 - val_loss: 0.6274\n",
      "Epoch 3980/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0354 - val_loss: 0.6443\n",
      "Epoch 3981/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0291 - val_loss: 0.6326\n",
      "Epoch 3982/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0317 - val_loss: 0.6429\n",
      "Epoch 3983/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0348 - val_loss: 0.6319\n",
      "Epoch 3984/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0361 - val_loss: 0.6391\n",
      "Epoch 3985/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0318 - val_loss: 0.6269\n",
      "Epoch 3986/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0324 - val_loss: 0.6168\n",
      "Epoch 3987/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0378 - val_loss: 0.6260\n",
      "Epoch 3988/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0306 - val_loss: 0.6110\n",
      "Epoch 3989/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0322 - val_loss: 0.6374\n",
      "Epoch 3990/10000\n",
      "130/130 [==============================] - 0s 921us/step - loss: 0.0294 - val_loss: 0.6368\n",
      "Epoch 3991/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0321 - val_loss: 0.6474\n",
      "Epoch 3992/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0305 - val_loss: 0.6381\n",
      "Epoch 3993/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0255 - val_loss: 0.6452\n",
      "Epoch 3994/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0260 - val_loss: 0.5936\n",
      "Epoch 3995/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0338 - val_loss: 0.6376\n",
      "Epoch 3996/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0308 - val_loss: 0.6452\n",
      "Epoch 3997/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0237 - val_loss: 0.6271\n",
      "Epoch 3998/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0298 - val_loss: 0.6242\n",
      "Epoch 3999/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0265 - val_loss: 0.6260\n",
      "Epoch 4000/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0353 - val_loss: 0.6393\n",
      "Epoch 4001/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0357 - val_loss: 0.6538\n",
      "Epoch 4002/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0385 - val_loss: 0.6273\n",
      "Epoch 4003/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0355 - val_loss: 0.6325\n",
      "Epoch 4004/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0283 - val_loss: 0.6287\n",
      "Epoch 4005/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0295 - val_loss: 0.6067\n",
      "Epoch 4006/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0270 - val_loss: 0.6224\n",
      "Epoch 4007/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0269 - val_loss: 0.6144\n",
      "Epoch 4008/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0258 - val_loss: 0.6338\n",
      "Epoch 4009/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0260 - val_loss: 0.6298\n",
      "Epoch 4010/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0373 - val_loss: 0.6709\n",
      "Epoch 4011/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0459 - val_loss: 0.6416\n",
      "Epoch 4012/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0438 - val_loss: 0.6433\n",
      "Epoch 4013/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0343 - val_loss: 0.6158\n",
      "Epoch 4014/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0316 - val_loss: 0.6275\n",
      "Epoch 4015/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0313 - val_loss: 0.6377\n",
      "Epoch 4016/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0247 - val_loss: 0.6424\n",
      "Epoch 4017/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0281 - val_loss: 0.6264\n",
      "Epoch 4018/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0247 - val_loss: 0.6444\n",
      "Epoch 4019/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0251 - val_loss: 0.6384\n",
      "Epoch 4020/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0285 - val_loss: 0.6330\n",
      "Epoch 4021/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0404 - val_loss: 0.6443\n",
      "Epoch 4022/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0334 - val_loss: 0.6250\n",
      "Epoch 4023/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0299 - val_loss: 0.6383\n",
      "Epoch 4024/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0299 - val_loss: 0.6302\n",
      "Epoch 4025/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0306 - val_loss: 0.6369\n",
      "Epoch 4026/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0348 - val_loss: 0.6263\n",
      "Epoch 4027/10000\n",
      "130/130 [==============================] - 0s 825us/step - loss: 0.0503 - val_loss: 0.6165\n",
      "Epoch 4028/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0289 - val_loss: 0.6415\n",
      "Epoch 4029/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0288 - val_loss: 0.6436\n",
      "Epoch 4030/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0298 - val_loss: 0.6243\n",
      "Epoch 4031/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 717us/step - loss: 0.0262 - val_loss: 0.6198\n",
      "Epoch 4032/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0311 - val_loss: 0.6241\n",
      "Epoch 4033/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0306 - val_loss: 0.6109\n",
      "Epoch 4034/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0246 - val_loss: 0.6475\n",
      "Epoch 4035/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0280 - val_loss: 0.6525\n",
      "Epoch 4036/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0255 - val_loss: 0.6354\n",
      "Epoch 4037/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0304 - val_loss: 0.6347\n",
      "Epoch 4038/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0287 - val_loss: 0.6220\n",
      "Epoch 4039/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0275 - val_loss: 0.6300\n",
      "Epoch 4040/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0323 - val_loss: 0.6588\n",
      "Epoch 4041/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0256 - val_loss: 0.6255\n",
      "Epoch 4042/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0375 - val_loss: 0.6457\n",
      "Epoch 4043/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0598 - val_loss: 0.6451\n",
      "Epoch 4044/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0437 - val_loss: 0.6224\n",
      "Epoch 4045/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0251 - val_loss: 0.6368\n",
      "Epoch 4046/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0250 - val_loss: 0.6327\n",
      "Epoch 4047/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0249 - val_loss: 0.6375\n",
      "Epoch 4048/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0294 - val_loss: 0.6347\n",
      "Epoch 4049/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0264 - val_loss: 0.6185\n",
      "Epoch 4050/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0386 - val_loss: 0.6455\n",
      "Epoch 4051/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0287 - val_loss: 0.6499\n",
      "Epoch 4052/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0302 - val_loss: 0.6426\n",
      "Epoch 4053/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0374 - val_loss: 0.6133\n",
      "Epoch 4054/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0318 - val_loss: 0.6438\n",
      "Epoch 4055/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0270 - val_loss: 0.6137\n",
      "Epoch 4056/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0226 - val_loss: 0.6496\n",
      "Epoch 4057/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0247 - val_loss: 0.6119\n",
      "Epoch 4058/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0300 - val_loss: 0.6409\n",
      "Epoch 4059/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0360 - val_loss: 0.6265\n",
      "Epoch 4060/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0326 - val_loss: 0.6381\n",
      "Epoch 4061/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0368 - val_loss: 0.6413\n",
      "Epoch 4062/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0365 - val_loss: 0.6212\n",
      "Epoch 4063/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0425 - val_loss: 0.6329\n",
      "Epoch 4064/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0304 - val_loss: 0.6431\n",
      "Epoch 4065/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0325 - val_loss: 0.6787\n",
      "Epoch 4066/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0325 - val_loss: 0.6580\n",
      "Epoch 4067/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0287 - val_loss: 0.6437\n",
      "Epoch 4068/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0254 - val_loss: 0.6219\n",
      "Epoch 4069/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0320 - val_loss: 0.6387\n",
      "Epoch 4070/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0323 - val_loss: 0.6331\n",
      "Epoch 4071/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0236 - val_loss: 0.6318\n",
      "Epoch 4072/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0249 - val_loss: 0.6204\n",
      "Epoch 4073/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0223 - val_loss: 0.6275\n",
      "Epoch 4074/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0280 - val_loss: 0.6476\n",
      "Epoch 4075/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0340 - val_loss: 0.6450\n",
      "Epoch 4076/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0469 - val_loss: 0.6483\n",
      "Epoch 4077/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0331 - val_loss: 0.6425\n",
      "Epoch 4078/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0256 - val_loss: 0.6261\n",
      "Epoch 4079/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0321 - val_loss: 0.6468\n",
      "Epoch 4080/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0262 - val_loss: 0.6262\n",
      "Epoch 4081/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0289 - val_loss: 0.6300\n",
      "Epoch 4082/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0285 - val_loss: 0.6245\n",
      "Epoch 4083/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0286 - val_loss: 0.6199\n",
      "Epoch 4084/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0337 - val_loss: 0.6369\n",
      "Epoch 4085/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0294 - val_loss: 0.6288\n",
      "Epoch 4086/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0260 - val_loss: 0.6263\n",
      "Epoch 4087/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0260 - val_loss: 0.6283\n",
      "Epoch 4088/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0290 - val_loss: 0.6407\n",
      "Epoch 4089/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0418 - val_loss: 0.6690\n",
      "Epoch 4090/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0328 - val_loss: 0.6233\n",
      "Epoch 4091/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0263 - val_loss: 0.6481\n",
      "Epoch 4092/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0277 - val_loss: 0.6060\n",
      "Epoch 4093/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0303 - val_loss: 0.6542\n",
      "Epoch 4094/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0332 - val_loss: 0.6531\n",
      "Epoch 4095/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0370 - val_loss: 0.6337\n",
      "Epoch 4096/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0317 - val_loss: 0.6575\n",
      "Epoch 4097/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0242 - val_loss: 0.6562\n",
      "Epoch 4098/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0261 - val_loss: 0.6372\n",
      "Epoch 4099/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0253 - val_loss: 0.6328\n",
      "Epoch 4100/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0373 - val_loss: 0.6482\n",
      "Epoch 4101/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0269 - val_loss: 0.6376\n",
      "Epoch 4102/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0386 - val_loss: 0.6506\n",
      "Epoch 4103/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0284 - val_loss: 0.6276\n",
      "Epoch 4104/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0255 - val_loss: 0.6407\n",
      "Epoch 4105/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0337 - val_loss: 0.6474\n",
      "Epoch 4106/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0283 - val_loss: 0.6219\n",
      "Epoch 4107/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 714us/step - loss: 0.0434 - val_loss: 0.6353\n",
      "Epoch 4108/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0308 - val_loss: 0.6350\n",
      "Epoch 4109/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0295 - val_loss: 0.6353\n",
      "Epoch 4110/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0266 - val_loss: 0.6325\n",
      "Epoch 4111/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0349 - val_loss: 0.6459\n",
      "Epoch 4112/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0324 - val_loss: 0.6263\n",
      "Epoch 4113/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0328 - val_loss: 0.6370\n",
      "Epoch 4114/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0290 - val_loss: 0.6296\n",
      "Epoch 4115/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0235 - val_loss: 0.6311\n",
      "Epoch 4116/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0282 - val_loss: 0.6094\n",
      "Epoch 4117/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0244 - val_loss: 0.6380\n",
      "Epoch 4118/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0302 - val_loss: 0.6281\n",
      "Epoch 4119/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0289 - val_loss: 0.6259\n",
      "Epoch 4120/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0367 - val_loss: 0.6113\n",
      "Epoch 4121/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0376 - val_loss: 0.6389\n",
      "Epoch 4122/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0318 - val_loss: 0.6222\n",
      "Epoch 4123/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0241 - val_loss: 0.6273\n",
      "Epoch 4124/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0262 - val_loss: 0.6225\n",
      "Epoch 4125/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0296 - val_loss: 0.6414\n",
      "Epoch 4126/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0312 - val_loss: 0.6381\n",
      "Epoch 4127/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0291 - val_loss: 0.6340\n",
      "Epoch 4128/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0301 - val_loss: 0.6135\n",
      "Epoch 4129/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0255 - val_loss: 0.6317\n",
      "Epoch 4130/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0387 - val_loss: 0.6251\n",
      "Epoch 4131/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0356 - val_loss: 0.6348\n",
      "Epoch 4132/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0289 - val_loss: 0.6235\n",
      "Epoch 4133/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0255 - val_loss: 0.6364\n",
      "Epoch 4134/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0259 - val_loss: 0.6282\n",
      "Epoch 4135/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0316 - val_loss: 0.6340\n",
      "Epoch 4136/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0535 - val_loss: 0.6533\n",
      "Epoch 4137/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0358 - val_loss: 0.6505\n",
      "Epoch 4138/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0253 - val_loss: 0.6325\n",
      "Epoch 4139/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0265 - val_loss: 0.6328\n",
      "Epoch 4140/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0238 - val_loss: 0.6450\n",
      "Epoch 4141/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0267 - val_loss: 0.6271\n",
      "Epoch 4142/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0271 - val_loss: 0.6280\n",
      "Epoch 4143/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0252 - val_loss: 0.6478\n",
      "Epoch 4144/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0277 - val_loss: 0.6515\n",
      "Epoch 4145/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0245 - val_loss: 0.6373\n",
      "Epoch 4146/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0287 - val_loss: 0.6135\n",
      "Epoch 4147/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0339 - val_loss: 0.6322\n",
      "Epoch 4148/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0279 - val_loss: 0.6468\n",
      "Epoch 4149/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0273 - val_loss: 0.6309\n",
      "Epoch 4150/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0317 - val_loss: 0.6256\n",
      "Epoch 4151/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0267 - val_loss: 0.6265\n",
      "Epoch 4152/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0264 - val_loss: 0.6268\n",
      "Epoch 4153/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0313 - val_loss: 0.6265\n",
      "Epoch 4154/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0295 - val_loss: 0.6467\n",
      "Epoch 4155/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0350 - val_loss: 0.6143\n",
      "Epoch 4156/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0383 - val_loss: 0.6482\n",
      "Epoch 4157/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0275 - val_loss: 0.6270\n",
      "Epoch 4158/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0284 - val_loss: 0.6289\n",
      "Epoch 4159/10000\n",
      "130/130 [==============================] - 0s 709us/step - loss: 0.0280 - val_loss: 0.6454\n",
      "Epoch 4160/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0301 - val_loss: 0.6376\n",
      "Epoch 4161/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0320 - val_loss: 0.6233\n",
      "Epoch 4162/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0243 - val_loss: 0.6076\n",
      "Epoch 4163/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0248 - val_loss: 0.6312\n",
      "Epoch 4164/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0260 - val_loss: 0.6539\n",
      "Epoch 4165/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0369 - val_loss: 0.6403\n",
      "Epoch 4166/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0566 - val_loss: 0.6415\n",
      "Epoch 4167/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0451 - val_loss: 0.6322\n",
      "Epoch 4168/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0308 - val_loss: 0.6213\n",
      "Epoch 4169/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0269 - val_loss: 0.6100\n",
      "Epoch 4170/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0245 - val_loss: 0.6420\n",
      "Epoch 4171/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0238 - val_loss: 0.6280\n",
      "Epoch 4172/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0233 - val_loss: 0.6419\n",
      "Epoch 4173/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0229 - val_loss: 0.6348\n",
      "Epoch 4174/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0250 - val_loss: 0.6395\n",
      "Epoch 4175/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0351 - val_loss: 0.6434\n",
      "Epoch 4176/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0301 - val_loss: 0.6457\n",
      "Epoch 4177/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0297 - val_loss: 0.6312\n",
      "Epoch 4178/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0290 - val_loss: 0.6434\n",
      "Epoch 4179/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0325 - val_loss: 0.6516\n",
      "Epoch 4180/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0283 - val_loss: 0.6137\n",
      "Epoch 4181/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0326 - val_loss: 0.6323\n",
      "Epoch 4182/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0340 - val_loss: 0.6261\n",
      "Epoch 4183/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 715us/step - loss: 0.0260 - val_loss: 0.6543\n",
      "Epoch 4184/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0226 - val_loss: 0.6192\n",
      "Epoch 4185/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0280 - val_loss: 0.6440\n",
      "Epoch 4186/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0301 - val_loss: 0.6286\n",
      "Epoch 4187/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0293 - val_loss: 0.6468\n",
      "Epoch 4188/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0360 - val_loss: 0.6667\n",
      "Epoch 4189/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0296 - val_loss: 0.6371\n",
      "Epoch 4190/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0269 - val_loss: 0.6221\n",
      "Epoch 4191/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0245 - val_loss: 0.6466\n",
      "Epoch 4192/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0256 - val_loss: 0.6250\n",
      "Epoch 4193/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0245 - val_loss: 0.6450\n",
      "Epoch 4194/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0311 - val_loss: 0.6261\n",
      "Epoch 4195/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0547 - val_loss: 0.6353\n",
      "Epoch 4196/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0458 - val_loss: 0.6145\n",
      "Epoch 4197/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0307 - val_loss: 0.6265\n",
      "Epoch 4198/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0307 - val_loss: 0.6142\n",
      "Epoch 4199/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0258 - val_loss: 0.6376\n",
      "Epoch 4200/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0203 - val_loss: 0.6385\n",
      "Epoch 4201/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0235 - val_loss: 0.6380\n",
      "Epoch 4202/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0258 - val_loss: 0.6276\n",
      "Epoch 4203/10000\n",
      "130/130 [==============================] - 0s 705us/step - loss: 0.0274 - val_loss: 0.6355\n",
      "Epoch 4204/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0293 - val_loss: 0.6403\n",
      "Epoch 4205/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0439 - val_loss: 0.6098\n",
      "Epoch 4206/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0405 - val_loss: 0.6382\n",
      "Epoch 4207/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0300 - val_loss: 0.6446\n",
      "Epoch 4208/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0366 - val_loss: 0.6542\n",
      "Epoch 4209/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0278 - val_loss: 0.6191\n",
      "Epoch 4210/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0245 - val_loss: 0.6206\n",
      "Epoch 4211/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0225 - val_loss: 0.6275\n",
      "Epoch 4212/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0243 - val_loss: 0.6731\n",
      "Epoch 4213/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0244 - val_loss: 0.6310\n",
      "Epoch 4214/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0295 - val_loss: 0.6171\n",
      "Epoch 4215/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0253 - val_loss: 0.6421\n",
      "Epoch 4216/10000\n",
      "130/130 [==============================] - 0s 992us/step - loss: 0.0256 - val_loss: 0.6281\n",
      "Epoch 4217/10000\n",
      "130/130 [==============================] - 0s 965us/step - loss: 0.0303 - val_loss: 0.6167\n",
      "Epoch 4218/10000\n",
      "130/130 [==============================] - 0s 822us/step - loss: 0.0251 - val_loss: 0.6358\n",
      "Epoch 4219/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.0293 - val_loss: 0.6323\n",
      "Epoch 4220/10000\n",
      "130/130 [==============================] - 0s 888us/step - loss: 0.0323 - val_loss: 0.6353\n",
      "Epoch 4221/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0279 - val_loss: 0.6422\n",
      "Epoch 4222/10000\n",
      "130/130 [==============================] - 0s 820us/step - loss: 0.0254 - val_loss: 0.6248\n",
      "Epoch 4223/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0353 - val_loss: 0.6503\n",
      "Epoch 4224/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0376 - val_loss: 0.6497\n",
      "Epoch 4225/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0347 - val_loss: 0.6352\n",
      "Epoch 4226/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0370 - val_loss: 0.6203\n",
      "Epoch 4227/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0252 - val_loss: 0.6147\n",
      "Epoch 4228/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0214 - val_loss: 0.6393\n",
      "Epoch 4229/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0227 - val_loss: 0.6312\n",
      "Epoch 4230/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0285 - val_loss: 0.6235\n",
      "Epoch 4231/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0294 - val_loss: 0.6313\n",
      "Epoch 4232/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0394 - val_loss: 0.6416\n",
      "Epoch 4233/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0342 - val_loss: 0.6291\n",
      "Epoch 4234/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0232 - val_loss: 0.6549\n",
      "Epoch 4235/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0223 - val_loss: 0.6322\n",
      "Epoch 4236/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0321 - val_loss: 0.6527\n",
      "Epoch 4237/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0323 - val_loss: 0.6274\n",
      "Epoch 4238/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0310 - val_loss: 0.6264\n",
      "Epoch 4239/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0271 - val_loss: 0.6414\n",
      "Epoch 4240/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0304 - val_loss: 0.6555\n",
      "Epoch 4241/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0273 - val_loss: 0.6301\n",
      "Epoch 4242/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0266 - val_loss: 0.6466\n",
      "Epoch 4243/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0232 - val_loss: 0.6373\n",
      "Epoch 4244/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0227 - val_loss: 0.6554\n",
      "Epoch 4245/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0317 - val_loss: 0.6344\n",
      "Epoch 4246/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0297 - val_loss: 0.6507\n",
      "Epoch 4247/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0246 - val_loss: 0.6214\n",
      "Epoch 4248/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0261 - val_loss: 0.6449\n",
      "Epoch 4249/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0534 - val_loss: 0.6241\n",
      "Epoch 4250/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0339 - val_loss: 0.6458\n",
      "Epoch 4251/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0254 - val_loss: 0.6200\n",
      "Epoch 4252/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0249 - val_loss: 0.6318\n",
      "Epoch 4253/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0216 - val_loss: 0.6426\n",
      "Epoch 4254/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0250 - val_loss: 0.6264\n",
      "Epoch 4255/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0235 - val_loss: 0.6181\n",
      "Epoch 4256/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0292 - val_loss: 0.6503\n",
      "Epoch 4257/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0281 - val_loss: 0.6629\n",
      "Epoch 4258/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0322 - val_loss: 0.6528\n",
      "Epoch 4259/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 729us/step - loss: 0.0284 - val_loss: 0.6196\n",
      "Epoch 4260/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0244 - val_loss: 0.6236\n",
      "Epoch 4261/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0293 - val_loss: 0.6556\n",
      "Epoch 4262/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0296 - val_loss: 0.6276\n",
      "Epoch 4263/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0226 - val_loss: 0.6504\n",
      "Epoch 4264/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0247 - val_loss: 0.6277\n",
      "Epoch 4265/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0271 - val_loss: 0.6216\n",
      "Epoch 4266/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0242 - val_loss: 0.6745\n",
      "Epoch 4267/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0254 - val_loss: 0.6312\n",
      "Epoch 4268/10000\n",
      "130/130 [==============================] - 0s 891us/step - loss: 0.0330 - val_loss: 0.6593\n",
      "Epoch 4269/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0538 - val_loss: 0.6136\n",
      "Epoch 4270/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0391 - val_loss: 0.6220\n",
      "Epoch 4271/10000\n",
      "130/130 [==============================] - 0s 946us/step - loss: 0.0339 - val_loss: 0.6312\n",
      "Epoch 4272/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0292 - val_loss: 0.6370\n",
      "Epoch 4273/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0235 - val_loss: 0.6412\n",
      "Epoch 4274/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0280 - val_loss: 0.6363\n",
      "Epoch 4275/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0303 - val_loss: 0.6219\n",
      "Epoch 4276/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0268 - val_loss: 0.6355\n",
      "Epoch 4277/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0250 - val_loss: 0.6427\n",
      "Epoch 4278/10000\n",
      "130/130 [==============================] - 0s 810us/step - loss: 0.0333 - val_loss: 0.6774\n",
      "Epoch 4279/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0483 - val_loss: 0.6224\n",
      "Epoch 4280/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0252 - val_loss: 0.6246\n",
      "Epoch 4281/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0219 - val_loss: 0.6302\n",
      "Epoch 4282/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0253 - val_loss: 0.6340\n",
      "Epoch 4283/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0226 - val_loss: 0.6246\n",
      "Epoch 4284/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0276 - val_loss: 0.6333\n",
      "Epoch 4285/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0233 - val_loss: 0.6317\n",
      "Epoch 4286/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0294 - val_loss: 0.6472\n",
      "Epoch 4287/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0290 - val_loss: 0.6415\n",
      "Epoch 4288/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0304 - val_loss: 0.6632\n",
      "Epoch 4289/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0368 - val_loss: 0.6196\n",
      "Epoch 4290/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0314 - val_loss: 0.6391\n",
      "Epoch 4291/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0356 - val_loss: 0.6199\n",
      "Epoch 4292/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0251 - val_loss: 0.6229\n",
      "Epoch 4293/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0216 - val_loss: 0.6334\n",
      "Epoch 4294/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0225 - val_loss: 0.6220\n",
      "Epoch 4295/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0262 - val_loss: 0.6327\n",
      "Epoch 4296/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0252 - val_loss: 0.6444\n",
      "Epoch 4297/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0268 - val_loss: 0.6192\n",
      "Epoch 4298/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0329 - val_loss: 0.6122\n",
      "Epoch 4299/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0282 - val_loss: 0.6325\n",
      "Epoch 4300/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0234 - val_loss: 0.6394\n",
      "Epoch 4301/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0244 - val_loss: 0.6402\n",
      "Epoch 4302/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0316 - val_loss: 0.6186\n",
      "Epoch 4303/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0272 - val_loss: 0.6433\n",
      "Epoch 4304/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0276 - val_loss: 0.6561\n",
      "Epoch 4305/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0272 - val_loss: 0.6441\n",
      "Epoch 4306/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0400 - val_loss: 0.6316\n",
      "Epoch 4307/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0361 - val_loss: 0.6492\n",
      "Epoch 4308/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0307 - val_loss: 0.6314\n",
      "Epoch 4309/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0253 - val_loss: 0.6364\n",
      "Epoch 4310/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0248 - val_loss: 0.6273\n",
      "Epoch 4311/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0241 - val_loss: 0.6469\n",
      "Epoch 4312/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0320 - val_loss: 0.6290\n",
      "Epoch 4313/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0380 - val_loss: 0.6100\n",
      "Epoch 4314/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0491 - val_loss: 0.6603\n",
      "Epoch 4315/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0284 - val_loss: 0.6200\n",
      "Epoch 4316/10000\n",
      "130/130 [==============================] - 0s 821us/step - loss: 0.0232 - val_loss: 0.6507\n",
      "Epoch 4317/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0263 - val_loss: 0.6402\n",
      "Epoch 4318/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0188 - val_loss: 0.6440\n",
      "Epoch 4319/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0222 - val_loss: 0.6252\n",
      "Epoch 4320/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0246 - val_loss: 0.6258\n",
      "Epoch 4321/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0288 - val_loss: 0.6396\n",
      "Epoch 4322/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0428 - val_loss: 0.6436\n",
      "Epoch 4323/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0292 - val_loss: 0.6177\n",
      "Epoch 4324/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0247 - val_loss: 0.6286\n",
      "Epoch 4325/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0206 - val_loss: 0.6292\n",
      "Epoch 4326/10000\n",
      "130/130 [==============================] - 0s 804us/step - loss: 0.0222 - val_loss: 0.6419\n",
      "Epoch 4327/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0251 - val_loss: 0.6253\n",
      "Epoch 4328/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0286 - val_loss: 0.6397\n",
      "Epoch 4329/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0330 - val_loss: 0.6458\n",
      "Epoch 4330/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0270 - val_loss: 0.6411\n",
      "Epoch 4331/10000\n",
      "130/130 [==============================] - 0s 792us/step - loss: 0.0323 - val_loss: 0.6537\n",
      "Epoch 4332/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0416 - val_loss: 0.6184\n",
      "Epoch 4333/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0284 - val_loss: 0.6323\n",
      "Epoch 4334/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0236 - val_loss: 0.6324\n",
      "Epoch 4335/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 760us/step - loss: 0.0224 - val_loss: 0.6422\n",
      "Epoch 4336/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0275 - val_loss: 0.6173\n",
      "Epoch 4337/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0290 - val_loss: 0.6432\n",
      "Epoch 4338/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0265 - val_loss: 0.6392\n",
      "Epoch 4339/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0272 - val_loss: 0.6260\n",
      "Epoch 4340/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0312 - val_loss: 0.6518\n",
      "Epoch 4341/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0619 - val_loss: 0.6154\n",
      "Epoch 4342/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0366 - val_loss: 0.6373\n",
      "Epoch 4343/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0207 - val_loss: 0.6132\n",
      "Epoch 4344/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0197 - val_loss: 0.6092\n",
      "Epoch 4345/10000\n",
      "130/130 [==============================] - 0s 985us/step - loss: 0.0238 - val_loss: 0.6413\n",
      "Epoch 4346/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0233 - val_loss: 0.6460\n",
      "Epoch 4347/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0284 - val_loss: 0.6282\n",
      "Epoch 4348/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0228 - val_loss: 0.6353\n",
      "Epoch 4349/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0194 - val_loss: 0.6080\n",
      "Epoch 4350/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0269 - val_loss: 0.6388\n",
      "Epoch 4351/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0384 - val_loss: 0.6977\n",
      "Epoch 4352/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0399 - val_loss: 0.6384\n",
      "Epoch 4353/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0235 - val_loss: 0.6419\n",
      "Epoch 4354/10000\n",
      "130/130 [==============================] - 0s 707us/step - loss: 0.0253 - val_loss: 0.6302\n",
      "Epoch 4355/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0258 - val_loss: 0.6181\n",
      "Epoch 4356/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0243 - val_loss: 0.6343\n",
      "Epoch 4357/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0365 - val_loss: 0.6458\n",
      "Epoch 4358/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0401 - val_loss: 0.6258\n",
      "Epoch 4359/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0271 - val_loss: 0.6252\n",
      "Epoch 4360/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0270 - val_loss: 0.6091\n",
      "Epoch 4361/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0214 - val_loss: 0.6456\n",
      "Epoch 4362/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0226 - val_loss: 0.6303\n",
      "Epoch 4363/10000\n",
      "130/130 [==============================] - 0s 712us/step - loss: 0.0226 - val_loss: 0.6291\n",
      "Epoch 4364/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0337 - val_loss: 0.6513\n",
      "Epoch 4365/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0309 - val_loss: 0.6670\n",
      "Epoch 4366/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0237 - val_loss: 0.6247\n",
      "Epoch 4367/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0237 - val_loss: 0.6346\n",
      "Epoch 4368/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0269 - val_loss: 0.6356\n",
      "Epoch 4369/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0237 - val_loss: 0.6270\n",
      "Epoch 4370/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0249 - val_loss: 0.6273\n",
      "Epoch 4371/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0264 - val_loss: 0.6258\n",
      "Epoch 4372/10000\n",
      "130/130 [==============================] - 0s 816us/step - loss: 0.0304 - val_loss: 0.6476\n",
      "Epoch 4373/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0343 - val_loss: 0.6351\n",
      "Epoch 4374/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0335 - val_loss: 0.6269\n",
      "Epoch 4375/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0238 - val_loss: 0.6386\n",
      "Epoch 4376/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0256 - val_loss: 0.6355\n",
      "Epoch 4377/10000\n",
      "130/130 [==============================] - 0s 957us/step - loss: 0.0304 - val_loss: 0.6351\n",
      "Epoch 4378/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0239 - val_loss: 0.6520\n",
      "Epoch 4379/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0346 - val_loss: 0.6511\n",
      "Epoch 4380/10000\n",
      "130/130 [==============================] - 0s 830us/step - loss: 0.0265 - val_loss: 0.6268\n",
      "Epoch 4381/10000\n",
      "130/130 [==============================] - 0s 883us/step - loss: 0.0239 - val_loss: 0.6486\n",
      "Epoch 4382/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0245 - val_loss: 0.6165\n",
      "Epoch 4383/10000\n",
      "130/130 [==============================] - 0s 914us/step - loss: 0.0325 - val_loss: 0.6301\n",
      "Epoch 4384/10000\n",
      "130/130 [==============================] - 0s 897us/step - loss: 0.0322 - val_loss: 0.6275\n",
      "Epoch 4385/10000\n",
      "130/130 [==============================] - 0s 902us/step - loss: 0.0345 - val_loss: 0.6311\n",
      "Epoch 4386/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0305 - val_loss: 0.6348\n",
      "Epoch 4387/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0259 - val_loss: 0.6502\n",
      "Epoch 4388/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0234 - val_loss: 0.6231\n",
      "Epoch 4389/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0270 - val_loss: 0.6316\n",
      "Epoch 4390/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0347 - val_loss: 0.6266\n",
      "Epoch 4391/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0344 - val_loss: 0.6170\n",
      "Epoch 4392/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0233 - val_loss: 0.6230\n",
      "Epoch 4393/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0242 - val_loss: 0.6359\n",
      "Epoch 4394/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0213 - val_loss: 0.6381\n",
      "Epoch 4395/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0269 - val_loss: 0.6208\n",
      "Epoch 4396/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0271 - val_loss: 0.6235\n",
      "Epoch 4397/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0266 - val_loss: 0.6512\n",
      "Epoch 4398/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0233 - val_loss: 0.6241\n",
      "Epoch 4399/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0249 - val_loss: 0.6138\n",
      "Epoch 4400/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0303 - val_loss: 0.6408\n",
      "Epoch 4401/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0302 - val_loss: 0.6549\n",
      "Epoch 4402/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0227 - val_loss: 0.6351\n",
      "Epoch 4403/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0210 - val_loss: 0.6266\n",
      "Epoch 4404/10000\n",
      "130/130 [==============================] - 0s 805us/step - loss: 0.0215 - val_loss: 0.6473\n",
      "Epoch 4405/10000\n",
      "130/130 [==============================] - 0s 845us/step - loss: 0.0319 - val_loss: 0.6488\n",
      "Epoch 4406/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0329 - val_loss: 0.6198\n",
      "Epoch 4407/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0255 - val_loss: 0.6348\n",
      "Epoch 4408/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0271 - val_loss: 0.6509\n",
      "Epoch 4409/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0429 - val_loss: 0.6273\n",
      "Epoch 4410/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0366 - val_loss: 0.6159\n",
      "Epoch 4411/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 764us/step - loss: 0.0290 - val_loss: 0.6365\n",
      "Epoch 4412/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0280 - val_loss: 0.6341\n",
      "Epoch 4413/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0700 - val_loss: 0.6380\n",
      "Epoch 4414/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0302 - val_loss: 0.6255\n",
      "Epoch 4415/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0206 - val_loss: 0.6318\n",
      "Epoch 4416/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0232 - val_loss: 0.6352\n",
      "Epoch 4417/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0198 - val_loss: 0.6348\n",
      "Epoch 4418/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0178 - val_loss: 0.6515\n",
      "Epoch 4419/10000\n",
      "130/130 [==============================] - 0s 708us/step - loss: 0.0184 - val_loss: 0.6278\n",
      "Epoch 4420/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0291 - val_loss: 0.6395\n",
      "Epoch 4421/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0270 - val_loss: 0.6557\n",
      "Epoch 4422/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0351 - val_loss: 0.6133\n",
      "Epoch 4423/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0390 - val_loss: 0.6265\n",
      "Epoch 4424/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0225 - val_loss: 0.6255\n",
      "Epoch 4425/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0214 - val_loss: 0.6197\n",
      "Epoch 4426/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0219 - val_loss: 0.6134\n",
      "Epoch 4427/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0210 - val_loss: 0.6371\n",
      "Epoch 4428/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0250 - val_loss: 0.6153\n",
      "Epoch 4429/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0253 - val_loss: 0.6641\n",
      "Epoch 4430/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0276 - val_loss: 0.6500\n",
      "Epoch 4431/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0295 - val_loss: 0.6314\n",
      "Epoch 4432/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0300 - val_loss: 0.6277\n",
      "Epoch 4433/10000\n",
      "130/130 [==============================] - 0s 834us/step - loss: 0.0216 - val_loss: 0.6332\n",
      "Epoch 4434/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0224 - val_loss: 0.6344\n",
      "Epoch 4435/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0248 - val_loss: 0.6414\n",
      "Epoch 4436/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0519 - val_loss: 0.6114\n",
      "Epoch 4437/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0395 - val_loss: 0.6263\n",
      "Epoch 4438/10000\n",
      "130/130 [==============================] - 0s 836us/step - loss: 0.0242 - val_loss: 0.6215\n",
      "Epoch 4439/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0202 - val_loss: 0.6482\n",
      "Epoch 4440/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0217 - val_loss: 0.6375\n",
      "Epoch 4441/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0248 - val_loss: 0.6275\n",
      "Epoch 4442/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0240 - val_loss: 0.6302\n",
      "Epoch 4443/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0249 - val_loss: 0.6505\n",
      "Epoch 4444/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0439 - val_loss: 0.6347\n",
      "Epoch 4445/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0400 - val_loss: 0.6327\n",
      "Epoch 4446/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0282 - val_loss: 0.6205\n",
      "Epoch 4447/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0204 - val_loss: 0.6316\n",
      "Epoch 4448/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0217 - val_loss: 0.6338\n",
      "Epoch 4449/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0211 - val_loss: 0.6381\n",
      "Epoch 4450/10000\n",
      "130/130 [==============================] - 0s 909us/step - loss: 0.0271 - val_loss: 0.6380\n",
      "Epoch 4451/10000\n",
      "130/130 [==============================] - 0s 906us/step - loss: 0.0302 - val_loss: 0.6538\n",
      "Epoch 4452/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0271 - val_loss: 0.6424\n",
      "Epoch 4453/10000\n",
      "130/130 [==============================] - 0s 713us/step - loss: 0.0296 - val_loss: 0.6365\n",
      "Epoch 4454/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0312 - val_loss: 0.6208\n",
      "Epoch 4455/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0261 - val_loss: 0.6386\n",
      "Epoch 4456/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0351 - val_loss: 0.6034\n",
      "Epoch 4457/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0246 - val_loss: 0.6368\n",
      "Epoch 4458/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0185 - val_loss: 0.6255\n",
      "Epoch 4459/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0208 - val_loss: 0.6381\n",
      "Epoch 4460/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0210 - val_loss: 0.6598\n",
      "Epoch 4461/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0206 - val_loss: 0.6373\n",
      "Epoch 4462/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0331 - val_loss: 0.6350\n",
      "Epoch 4463/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0940 - val_loss: 0.6267\n",
      "Epoch 4464/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0397 - val_loss: 0.6366\n",
      "Epoch 4465/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0199 - val_loss: 0.6150\n",
      "Epoch 4466/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0189 - val_loss: 0.6334\n",
      "Epoch 4467/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0186 - val_loss: 0.6180\n",
      "Epoch 4468/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0195 - val_loss: 0.6511\n",
      "Epoch 4469/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0185 - val_loss: 0.6494\n",
      "Epoch 4470/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0188 - val_loss: 0.6421\n",
      "Epoch 4471/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.6522\n",
      "Epoch 4472/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0247 - val_loss: 0.6403\n",
      "Epoch 4473/10000\n",
      "130/130 [==============================] - 0s 840us/step - loss: 0.0262 - val_loss: 0.6402\n",
      "Epoch 4474/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0292 - val_loss: 0.6171\n",
      "Epoch 4475/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0287 - val_loss: 0.6310\n",
      "Epoch 4476/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0302 - val_loss: 0.6412\n",
      "Epoch 4477/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0359 - val_loss: 0.6518\n",
      "Epoch 4478/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0247 - val_loss: 0.6175\n",
      "Epoch 4479/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0222 - val_loss: 0.6406\n",
      "Epoch 4480/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0213 - val_loss: 0.6329\n",
      "Epoch 4481/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0217 - val_loss: 0.6493\n",
      "Epoch 4482/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0218 - val_loss: 0.6444\n",
      "Epoch 4483/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0278 - val_loss: 0.6192\n",
      "Epoch 4484/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0251 - val_loss: 0.6146\n",
      "Epoch 4485/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0340 - val_loss: 0.6589\n",
      "Epoch 4486/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0448 - val_loss: 0.6576\n",
      "Epoch 4487/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 853us/step - loss: 0.0426 - val_loss: 0.6600\n",
      "Epoch 4488/10000\n",
      "130/130 [==============================] - 0s 833us/step - loss: 0.0274 - val_loss: 0.6196\n",
      "Epoch 4489/10000\n",
      "130/130 [==============================] - 0s 805us/step - loss: 0.0221 - val_loss: 0.6296\n",
      "Epoch 4490/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0251 - val_loss: 0.6511\n",
      "Epoch 4491/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0294 - val_loss: 0.6163\n",
      "Epoch 4492/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0313 - val_loss: 0.6165\n",
      "Epoch 4493/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0262 - val_loss: 0.6144\n",
      "Epoch 4494/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0227 - val_loss: 0.6266\n",
      "Epoch 4495/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0219 - val_loss: 0.6328\n",
      "Epoch 4496/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0207 - val_loss: 0.6182\n",
      "Epoch 4497/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0212 - val_loss: 0.6192\n",
      "Epoch 4498/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0303 - val_loss: 0.6500\n",
      "Epoch 4499/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0398 - val_loss: 0.6202\n",
      "Epoch 4500/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0309 - val_loss: 0.6199\n",
      "Epoch 4501/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0251 - val_loss: 0.6248\n",
      "Epoch 4502/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0287 - val_loss: 0.6258\n",
      "Epoch 4503/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0237 - val_loss: 0.6322\n",
      "Epoch 4504/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0252 - val_loss: 0.6106\n",
      "Epoch 4505/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0296 - val_loss: 0.6450\n",
      "Epoch 4506/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0277 - val_loss: 0.6273\n",
      "Epoch 4507/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0260 - val_loss: 0.6319\n",
      "Epoch 4508/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0350 - val_loss: 0.6166\n",
      "Epoch 4509/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0352 - val_loss: 0.6204\n",
      "Epoch 4510/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0434 - val_loss: 0.6705\n",
      "Epoch 4511/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0304 - val_loss: 0.6283\n",
      "Epoch 4512/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0201 - val_loss: 0.6357\n",
      "Epoch 4513/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0180 - val_loss: 0.6270\n",
      "Epoch 4514/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0201 - val_loss: 0.6221\n",
      "Epoch 4515/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0227 - val_loss: 0.6189\n",
      "Epoch 4516/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0196 - val_loss: 0.6202\n",
      "Epoch 4517/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0188 - val_loss: 0.6363\n",
      "Epoch 4518/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0225 - val_loss: 0.6324\n",
      "Epoch 4519/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0216 - val_loss: 0.6442\n",
      "Epoch 4520/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0271 - val_loss: 0.6452\n",
      "Epoch 4521/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0306 - val_loss: 0.6215\n",
      "Epoch 4522/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0357 - val_loss: 0.6176\n",
      "Epoch 4523/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0389 - val_loss: 0.6440\n",
      "Epoch 4524/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0312 - val_loss: 0.6415\n",
      "Epoch 4525/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0233 - val_loss: 0.6266\n",
      "Epoch 4526/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0260 - val_loss: 0.6139\n",
      "Epoch 4527/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0204 - val_loss: 0.6192\n",
      "Epoch 4528/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0220 - val_loss: 0.6250\n",
      "Epoch 4529/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0235 - val_loss: 0.6098\n",
      "Epoch 4530/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0239 - val_loss: 0.6446\n",
      "Epoch 4531/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0272 - val_loss: 0.6312\n",
      "Epoch 4532/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0306 - val_loss: 0.6367\n",
      "Epoch 4533/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0292 - val_loss: 0.6511\n",
      "Epoch 4534/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0727 - val_loss: 0.6329\n",
      "Epoch 4535/10000\n",
      "130/130 [==============================] - 0s 711us/step - loss: 0.0294 - val_loss: 0.6329\n",
      "Epoch 4536/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0180 - val_loss: 0.6346\n",
      "Epoch 4537/10000\n",
      "130/130 [==============================] - 0s 871us/step - loss: 0.0228 - val_loss: 0.6302\n",
      "Epoch 4538/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0272 - val_loss: 0.6107\n",
      "Epoch 4539/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0244 - val_loss: 0.6328\n",
      "Epoch 4540/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0235 - val_loss: 0.6348\n",
      "Epoch 4541/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0285 - val_loss: 0.6358\n",
      "Epoch 4542/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0238 - val_loss: 0.6397\n",
      "Epoch 4543/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0268 - val_loss: 0.6078\n",
      "Epoch 4544/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0234 - val_loss: 0.6343\n",
      "Epoch 4545/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0215 - val_loss: 0.6462\n",
      "Epoch 4546/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0209 - val_loss: 0.6473\n",
      "Epoch 4547/10000\n",
      "130/130 [==============================] - 0s 834us/step - loss: 0.0343 - val_loss: 0.6572\n",
      "Epoch 4548/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0597 - val_loss: 0.6221\n",
      "Epoch 4549/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0292 - val_loss: 0.6200\n",
      "Epoch 4550/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0192 - val_loss: 0.6238\n",
      "Epoch 4551/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0222 - val_loss: 0.6306\n",
      "Epoch 4552/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0200 - val_loss: 0.6303\n",
      "Epoch 4553/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0254 - val_loss: 0.6308\n",
      "Epoch 4554/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0301 - val_loss: 0.6427\n",
      "Epoch 4555/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0209 - val_loss: 0.6430\n",
      "Epoch 4556/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0211 - val_loss: 0.6105\n",
      "Epoch 4557/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0239 - val_loss: 0.6252\n",
      "Epoch 4558/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0280 - val_loss: 0.6275\n",
      "Epoch 4559/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0224 - val_loss: 0.6469\n",
      "Epoch 4560/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0231 - val_loss: 0.6258\n",
      "Epoch 4561/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0244 - val_loss: 0.6339\n",
      "Epoch 4562/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0255 - val_loss: 0.6182\n",
      "Epoch 4563/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 742us/step - loss: 0.0261 - val_loss: 0.6529\n",
      "Epoch 4564/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0520 - val_loss: 0.6216\n",
      "Epoch 4565/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0378 - val_loss: 0.6233\n",
      "Epoch 4566/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0251 - val_loss: 0.6364\n",
      "Epoch 4567/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0212 - val_loss: 0.6208\n",
      "Epoch 4568/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0200 - val_loss: 0.6477\n",
      "Epoch 4569/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0232 - val_loss: 0.6247\n",
      "Epoch 4570/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0226 - val_loss: 0.6213\n",
      "Epoch 4571/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0277 - val_loss: 0.6267\n",
      "Epoch 4572/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0256 - val_loss: 0.6248\n",
      "Epoch 4573/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0245 - val_loss: 0.6321\n",
      "Epoch 4574/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0303 - val_loss: 0.6465\n",
      "Epoch 4575/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0330 - val_loss: 0.6251\n",
      "Epoch 4576/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0274 - val_loss: 0.6269\n",
      "Epoch 4577/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0184 - val_loss: 0.6167\n",
      "Epoch 4578/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0197 - val_loss: 0.6143\n",
      "Epoch 4579/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0249 - val_loss: 0.6418\n",
      "Epoch 4580/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0372 - val_loss: 0.6243\n",
      "Epoch 4581/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0343 - val_loss: 0.6279\n",
      "Epoch 4582/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0226 - val_loss: 0.6371\n",
      "Epoch 4583/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0212 - val_loss: 0.6224\n",
      "Epoch 4584/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0240 - val_loss: 0.6231\n",
      "Epoch 4585/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0253 - val_loss: 0.6302\n",
      "Epoch 4586/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0243 - val_loss: 0.6553\n",
      "Epoch 4587/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0329 - val_loss: 0.6243\n",
      "Epoch 4588/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0230 - val_loss: 0.6348\n",
      "Epoch 4589/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0274 - val_loss: 0.6313\n",
      "Epoch 4590/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0270 - val_loss: 0.6271\n",
      "Epoch 4591/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0223 - val_loss: 0.6401\n",
      "Epoch 4592/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0271 - val_loss: 0.6282\n",
      "Epoch 4593/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0363 - val_loss: 0.6224\n",
      "Epoch 4594/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0309 - val_loss: 0.6256\n",
      "Epoch 4595/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0295 - val_loss: 0.6381\n",
      "Epoch 4596/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0498 - val_loss: 0.6355\n",
      "Epoch 4597/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0660 - val_loss: 0.6078\n",
      "Epoch 4598/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0279 - val_loss: 0.6195\n",
      "Epoch 4599/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0171 - val_loss: 0.6130\n",
      "Epoch 4600/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0187 - val_loss: 0.6318\n",
      "Epoch 4601/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0173 - val_loss: 0.6258\n",
      "Epoch 4602/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0176 - val_loss: 0.6351\n",
      "Epoch 4603/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0259 - val_loss: 0.6463\n",
      "Epoch 4604/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0262 - val_loss: 0.6108\n",
      "Epoch 4605/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0212 - val_loss: 0.6226\n",
      "Epoch 4606/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0213 - val_loss: 0.6183\n",
      "Epoch 4607/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0222 - val_loss: 0.6379\n",
      "Epoch 4608/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0215 - val_loss: 0.6438\n",
      "Epoch 4609/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0213 - val_loss: 0.6338\n",
      "Epoch 4610/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0250 - val_loss: 0.6172\n",
      "Epoch 4611/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0278 - val_loss: 0.6401\n",
      "Epoch 4612/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0340 - val_loss: 0.6335\n",
      "Epoch 4613/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0306 - val_loss: 0.6251\n",
      "Epoch 4614/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0304 - val_loss: 0.6336\n",
      "Epoch 4615/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0277 - val_loss: 0.6186\n",
      "Epoch 4616/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0226 - val_loss: 0.6208\n",
      "Epoch 4617/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0218 - val_loss: 0.6374\n",
      "Epoch 4618/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0285 - val_loss: 0.6240\n",
      "Epoch 4619/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0264 - val_loss: 0.6373\n",
      "Epoch 4620/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0212 - val_loss: 0.6166\n",
      "Epoch 4621/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0271 - val_loss: 0.6324\n",
      "Epoch 4622/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0325 - val_loss: 0.6631\n",
      "Epoch 4623/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0389 - val_loss: 0.6381\n",
      "Epoch 4624/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0305 - val_loss: 0.6425\n",
      "Epoch 4625/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0233 - val_loss: 0.6291\n",
      "Epoch 4626/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0246 - val_loss: 0.6326\n",
      "Epoch 4627/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0293 - val_loss: 0.6220\n",
      "Epoch 4628/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0201 - val_loss: 0.6327\n",
      "Epoch 4629/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0273 - val_loss: 0.6717\n",
      "Epoch 4630/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0475 - val_loss: 0.6222\n",
      "Epoch 4631/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0288 - val_loss: 0.6213\n",
      "Epoch 4632/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0210 - val_loss: 0.6244\n",
      "Epoch 4633/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0216 - val_loss: 0.6178\n",
      "Epoch 4634/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0206 - val_loss: 0.6147\n",
      "Epoch 4635/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0174 - val_loss: 0.6151\n",
      "Epoch 4636/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0164 - val_loss: 0.6235\n",
      "Epoch 4637/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0284 - val_loss: 0.6479\n",
      "Epoch 4638/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0276 - val_loss: 0.6398\n",
      "Epoch 4639/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 753us/step - loss: 0.0230 - val_loss: 0.6139\n",
      "Epoch 4640/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0235 - val_loss: 0.6342\n",
      "Epoch 4641/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0321 - val_loss: 0.6440\n",
      "Epoch 4642/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0456 - val_loss: 0.6505\n",
      "Epoch 4643/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0479 - val_loss: 0.6256\n",
      "Epoch 4644/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0233 - val_loss: 0.6380\n",
      "Epoch 4645/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0200 - val_loss: 0.6362\n",
      "Epoch 4646/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0203 - val_loss: 0.6226\n",
      "Epoch 4647/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0219 - val_loss: 0.6314\n",
      "Epoch 4648/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0166 - val_loss: 0.6307\n",
      "Epoch 4649/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0212 - val_loss: 0.6282\n",
      "Epoch 4650/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0290 - val_loss: 0.6301\n",
      "Epoch 4651/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0267 - val_loss: 0.6382\n",
      "Epoch 4652/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0209 - val_loss: 0.6312\n",
      "Epoch 4653/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0205 - val_loss: 0.6383\n",
      "Epoch 4654/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0196 - val_loss: 0.6336\n",
      "Epoch 4655/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0323 - val_loss: 0.6126\n",
      "Epoch 4656/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0388 - val_loss: 0.6287\n",
      "Epoch 4657/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0304 - val_loss: 0.6247\n",
      "Epoch 4658/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0261 - val_loss: 0.6402\n",
      "Epoch 4659/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0260 - val_loss: 0.6391\n",
      "Epoch 4660/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0284 - val_loss: 0.6321\n",
      "Epoch 4661/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0237 - val_loss: 0.6315\n",
      "Epoch 4662/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0291 - val_loss: 0.6271\n",
      "Epoch 4663/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0220 - val_loss: 0.6372\n",
      "Epoch 4664/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0189 - val_loss: 0.6321\n",
      "Epoch 4665/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0196 - val_loss: 0.6268\n",
      "Epoch 4666/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0213 - val_loss: 0.6136\n",
      "Epoch 4667/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0397 - val_loss: 0.6431\n",
      "Epoch 4668/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0339 - val_loss: 0.6666\n",
      "Epoch 4669/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0324 - val_loss: 0.6422\n",
      "Epoch 4670/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0211 - val_loss: 0.6256\n",
      "Epoch 4671/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0202 - val_loss: 0.6295\n",
      "Epoch 4672/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0335 - val_loss: 0.6206\n",
      "Epoch 4673/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0247 - val_loss: 0.6272\n",
      "Epoch 4674/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0221 - val_loss: 0.6247\n",
      "Epoch 4675/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0188 - val_loss: 0.6274\n",
      "Epoch 4676/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0194 - val_loss: 0.6352\n",
      "Epoch 4677/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0200 - val_loss: 0.6326\n",
      "Epoch 4678/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0243 - val_loss: 0.6306\n",
      "Epoch 4679/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0281 - val_loss: 0.6097\n",
      "Epoch 4680/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0254 - val_loss: 0.6253\n",
      "Epoch 4681/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0289 - val_loss: 0.6365\n",
      "Epoch 4682/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0332 - val_loss: 0.6345\n",
      "Epoch 4683/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0400 - val_loss: 0.6396\n",
      "Epoch 4684/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0300 - val_loss: 0.6265\n",
      "Epoch 4685/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0220 - val_loss: 0.6373\n",
      "Epoch 4686/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0197 - val_loss: 0.6225\n",
      "Epoch 4687/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0168 - val_loss: 0.6221\n",
      "Epoch 4688/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0265 - val_loss: 0.6226\n",
      "Epoch 4689/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0213 - val_loss: 0.6512\n",
      "Epoch 4690/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0201 - val_loss: 0.6289\n",
      "Epoch 4691/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0191 - val_loss: 0.6401\n",
      "Epoch 4692/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0289 - val_loss: 0.6389\n",
      "Epoch 4693/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0313 - val_loss: 0.6386\n",
      "Epoch 4694/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0290 - val_loss: 0.6252\n",
      "Epoch 4695/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0215 - val_loss: 0.6168\n",
      "Epoch 4696/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0223 - val_loss: 0.6197\n",
      "Epoch 4697/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0293 - val_loss: 0.6306\n",
      "Epoch 4698/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0288 - val_loss: 0.6510\n",
      "Epoch 4699/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0247 - val_loss: 0.6196\n",
      "Epoch 4700/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0299 - val_loss: 0.6267\n",
      "Epoch 4701/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0286 - val_loss: 0.6293\n",
      "Epoch 4702/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0242 - val_loss: 0.6334\n",
      "Epoch 4703/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0236 - val_loss: 0.6157\n",
      "Epoch 4704/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0229 - val_loss: 0.6434\n",
      "Epoch 4705/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0276 - val_loss: 0.6471\n",
      "Epoch 4706/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0248 - val_loss: 0.6477\n",
      "Epoch 4707/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0217 - val_loss: 0.6367\n",
      "Epoch 4708/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0215 - val_loss: 0.6375\n",
      "Epoch 4709/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0241 - val_loss: 0.6453\n",
      "Epoch 4710/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0199 - val_loss: 0.6346\n",
      "Epoch 4711/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0270 - val_loss: 0.6455\n",
      "Epoch 4712/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0284 - val_loss: 0.6158\n",
      "Epoch 4713/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0278 - val_loss: 0.6396\n",
      "Epoch 4714/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0311 - val_loss: 0.6131\n",
      "Epoch 4715/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 728us/step - loss: 0.0220 - val_loss: 0.6182\n",
      "Epoch 4716/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0276 - val_loss: 0.6229\n",
      "Epoch 4717/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0206 - val_loss: 0.6194\n",
      "Epoch 4718/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0193 - val_loss: 0.6287\n",
      "Epoch 4719/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0214 - val_loss: 0.6399\n",
      "Epoch 4720/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0411 - val_loss: 0.6638\n",
      "Epoch 4721/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0410 - val_loss: 0.6318\n",
      "Epoch 4722/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0303 - val_loss: 0.6216\n",
      "Epoch 4723/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0224 - val_loss: 0.6242\n",
      "Epoch 4724/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0216 - val_loss: 0.6381\n",
      "Epoch 4725/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0187 - val_loss: 0.6200\n",
      "Epoch 4726/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0209 - val_loss: 0.6215\n",
      "Epoch 4727/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0211 - val_loss: 0.6276\n",
      "Epoch 4728/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0274 - val_loss: 0.6449\n",
      "Epoch 4729/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0227 - val_loss: 0.6200\n",
      "Epoch 4730/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0230 - val_loss: 0.6317\n",
      "Epoch 4731/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0251 - val_loss: 0.6395\n",
      "Epoch 4732/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0249 - val_loss: 0.6240\n",
      "Epoch 4733/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0197 - val_loss: 0.6318\n",
      "Epoch 4734/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0194 - val_loss: 0.6537\n",
      "Epoch 4735/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0248 - val_loss: 0.6411\n",
      "Epoch 4736/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0316 - val_loss: 0.6432\n",
      "Epoch 4737/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0405 - val_loss: 0.6304\n",
      "Epoch 4738/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0481 - val_loss: 0.6172\n",
      "Epoch 4739/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0272 - val_loss: 0.6180\n",
      "Epoch 4740/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0235 - val_loss: 0.6074\n",
      "Epoch 4741/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0217 - val_loss: 0.6369\n",
      "Epoch 4742/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0235 - val_loss: 0.6248\n",
      "Epoch 4743/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0196 - val_loss: 0.6395\n",
      "Epoch 4744/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0197 - val_loss: 0.6364\n",
      "Epoch 4745/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0222 - val_loss: 0.6434\n",
      "Epoch 4746/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0315 - val_loss: 0.6451\n",
      "Epoch 4747/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0404 - val_loss: 0.6226\n",
      "Epoch 4748/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0270 - val_loss: 0.6245\n",
      "Epoch 4749/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0219 - val_loss: 0.6248\n",
      "Epoch 4750/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0198 - val_loss: 0.6318\n",
      "Epoch 4751/10000\n",
      "130/130 [==============================] - 0s 822us/step - loss: 0.0193 - val_loss: 0.6186\n",
      "Epoch 4752/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0221 - val_loss: 0.6432\n",
      "Epoch 4753/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0206 - val_loss: 0.6134\n",
      "Epoch 4754/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0239 - val_loss: 0.6352\n",
      "Epoch 4755/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0224 - val_loss: 0.6313\n",
      "Epoch 4756/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0225 - val_loss: 0.6092\n",
      "Epoch 4757/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0199 - val_loss: 0.6286\n",
      "Epoch 4758/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0257 - val_loss: 0.6444\n",
      "Epoch 4759/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0339 - val_loss: 0.6395\n",
      "Epoch 4760/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0348 - val_loss: 0.6185\n",
      "Epoch 4761/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0375 - val_loss: 0.6382\n",
      "Epoch 4762/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0246 - val_loss: 0.6250\n",
      "Epoch 4763/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0180 - val_loss: 0.6197\n",
      "Epoch 4764/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0203 - val_loss: 0.6501\n",
      "Epoch 4765/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0225 - val_loss: 0.6280\n",
      "Epoch 4766/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0208 - val_loss: 0.6532\n",
      "Epoch 4767/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0219 - val_loss: 0.6123\n",
      "Epoch 4768/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0181 - val_loss: 0.6552\n",
      "Epoch 4769/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0240 - val_loss: 0.6667\n",
      "Epoch 4770/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0286 - val_loss: 0.6432\n",
      "Epoch 4771/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0209 - val_loss: 0.6169\n",
      "Epoch 4772/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0236 - val_loss: 0.6451\n",
      "Epoch 4773/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0296 - val_loss: 0.6334\n",
      "Epoch 4774/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0287 - val_loss: 0.6293\n",
      "Epoch 4775/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0228 - val_loss: 0.6170\n",
      "Epoch 4776/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0211 - val_loss: 0.6367\n",
      "Epoch 4777/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0254 - val_loss: 0.6379\n",
      "Epoch 4778/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0269 - val_loss: 0.6306\n",
      "Epoch 4779/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0192 - val_loss: 0.6380\n",
      "Epoch 4780/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0193 - val_loss: 0.6212\n",
      "Epoch 4781/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0214 - val_loss: 0.6471\n",
      "Epoch 4782/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0262 - val_loss: 0.6527\n",
      "Epoch 4783/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0406 - val_loss: 0.6143\n",
      "Epoch 4784/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0390 - val_loss: 0.6233\n",
      "Epoch 4785/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0307 - val_loss: 0.6196\n",
      "Epoch 4786/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0214 - val_loss: 0.6305\n",
      "Epoch 4787/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0209 - val_loss: 0.6210\n",
      "Epoch 4788/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0186 - val_loss: 0.6267\n",
      "Epoch 4789/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0189 - val_loss: 0.6407\n",
      "Epoch 4790/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0191 - val_loss: 0.6318\n",
      "Epoch 4791/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 756us/step - loss: 0.0198 - val_loss: 0.6241\n",
      "Epoch 4792/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0216 - val_loss: 0.6137\n",
      "Epoch 4793/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0277 - val_loss: 0.6292\n",
      "Epoch 4794/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0302 - val_loss: 0.6597\n",
      "Epoch 4795/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0392 - val_loss: 0.6535\n",
      "Epoch 4796/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0346 - val_loss: 0.6531\n",
      "Epoch 4797/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0316 - val_loss: 0.6442\n",
      "Epoch 4798/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0221 - val_loss: 0.6124\n",
      "Epoch 4799/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0191 - val_loss: 0.6270\n",
      "Epoch 4800/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0281 - val_loss: 0.6309\n",
      "Epoch 4801/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0196 - val_loss: 0.6258\n",
      "Epoch 4802/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0231 - val_loss: 0.6259\n",
      "Epoch 4803/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0242 - val_loss: 0.6338\n",
      "Epoch 4804/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0197 - val_loss: 0.6361\n",
      "Epoch 4805/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0221 - val_loss: 0.6316\n",
      "Epoch 4806/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0299 - val_loss: 0.6592\n",
      "Epoch 4807/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0238 - val_loss: 0.6248\n",
      "Epoch 4808/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0201 - val_loss: 0.6382\n",
      "Epoch 4809/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0189 - val_loss: 0.6125\n",
      "Epoch 4810/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0538 - val_loss: 0.6103\n",
      "Epoch 4811/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0434 - val_loss: 0.6320\n",
      "Epoch 4812/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0221 - val_loss: 0.6122\n",
      "Epoch 4813/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0179 - val_loss: 0.6169\n",
      "Epoch 4814/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0200 - val_loss: 0.6222\n",
      "Epoch 4815/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0210 - val_loss: 0.6206\n",
      "Epoch 4816/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0326 - val_loss: 0.6218\n",
      "Epoch 4817/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0402 - val_loss: 0.6318\n",
      "Epoch 4818/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0256 - val_loss: 0.6159\n",
      "Epoch 4819/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0190 - val_loss: 0.6173\n",
      "Epoch 4820/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0194 - val_loss: 0.6184\n",
      "Epoch 4821/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0186 - val_loss: 0.6304\n",
      "Epoch 4822/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0156 - val_loss: 0.6436\n",
      "Epoch 4823/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0175 - val_loss: 0.6304\n",
      "Epoch 4824/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0208 - val_loss: 0.6572\n",
      "Epoch 4825/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0204 - val_loss: 0.6306\n",
      "Epoch 4826/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0225 - val_loss: 0.6320\n",
      "Epoch 4827/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0277 - val_loss: 0.6340\n",
      "Epoch 4828/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0300 - val_loss: 0.6244\n",
      "Epoch 4829/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0265 - val_loss: 0.6327\n",
      "Epoch 4830/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0238 - val_loss: 0.6334\n",
      "Epoch 4831/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0225 - val_loss: 0.6272\n",
      "Epoch 4832/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0183 - val_loss: 0.6299\n",
      "Epoch 4833/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0217 - val_loss: 0.6332\n",
      "Epoch 4834/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0275 - val_loss: 0.6321\n",
      "Epoch 4835/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0282 - val_loss: 0.6154\n",
      "Epoch 4836/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0278 - val_loss: 0.6593\n",
      "Epoch 4837/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0288 - val_loss: 0.6156\n",
      "Epoch 4838/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0244 - val_loss: 0.5907\n",
      "Epoch 4839/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0417 - val_loss: 0.6329\n",
      "Epoch 4840/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0381 - val_loss: 0.6488\n",
      "Epoch 4841/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0455 - val_loss: 0.6238\n",
      "Epoch 4842/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0254 - val_loss: 0.6194\n",
      "Epoch 4843/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0148 - val_loss: 0.6139\n",
      "Epoch 4844/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0151 - val_loss: 0.6171\n",
      "Epoch 4845/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0176 - val_loss: 0.6129\n",
      "Epoch 4846/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0184 - val_loss: 0.6174\n",
      "Epoch 4847/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0190 - val_loss: 0.6314\n",
      "Epoch 4848/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0244 - val_loss: 0.6646\n",
      "Epoch 4849/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0230 - val_loss: 0.6350\n",
      "Epoch 4850/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0207 - val_loss: 0.6330\n",
      "Epoch 4851/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0315 - val_loss: 0.6283\n",
      "Epoch 4852/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0348 - val_loss: 0.6149\n",
      "Epoch 4853/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0237 - val_loss: 0.6249\n",
      "Epoch 4854/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0244 - val_loss: 0.6055\n",
      "Epoch 4855/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0188 - val_loss: 0.6142\n",
      "Epoch 4856/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0252 - val_loss: 0.6164\n",
      "Epoch 4857/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0344 - val_loss: 0.6493\n",
      "Epoch 4858/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0627 - val_loss: 0.6327\n",
      "Epoch 4859/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0202 - val_loss: 0.6174\n",
      "Epoch 4860/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0167 - val_loss: 0.6208\n",
      "Epoch 4861/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0166 - val_loss: 0.6315\n",
      "Epoch 4862/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0184 - val_loss: 0.6276\n",
      "Epoch 4863/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0209 - val_loss: 0.6253\n",
      "Epoch 4864/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0195 - val_loss: 0.6526\n",
      "Epoch 4865/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0270 - val_loss: 0.6701\n",
      "Epoch 4866/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0454 - val_loss: 0.6340\n",
      "Epoch 4867/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 742us/step - loss: 0.0319 - val_loss: 0.6212\n",
      "Epoch 4868/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0256 - val_loss: 0.6176\n",
      "Epoch 4869/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0196 - val_loss: 0.6138\n",
      "Epoch 4870/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0161 - val_loss: 0.6431\n",
      "Epoch 4871/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0160 - val_loss: 0.6349\n",
      "Epoch 4872/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0210 - val_loss: 0.6287\n",
      "Epoch 4873/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0232 - val_loss: 0.6275\n",
      "Epoch 4874/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0270 - val_loss: 0.6182\n",
      "Epoch 4875/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0222 - val_loss: 0.6505\n",
      "Epoch 4876/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0196 - val_loss: 0.6200\n",
      "Epoch 4877/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0180 - val_loss: 0.6345\n",
      "Epoch 4878/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0304 - val_loss: 0.6424\n",
      "Epoch 4879/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0352 - val_loss: 0.6360\n",
      "Epoch 4880/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0234 - val_loss: 0.6376\n",
      "Epoch 4881/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0202 - val_loss: 0.6285\n",
      "Epoch 4882/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0211 - val_loss: 0.6175\n",
      "Epoch 4883/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0234 - val_loss: 0.6097\n",
      "Epoch 4884/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0273 - val_loss: 0.6658\n",
      "Epoch 4885/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0440 - val_loss: 0.6048\n",
      "Epoch 4886/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0237 - val_loss: 0.6279\n",
      "Epoch 4887/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0207 - val_loss: 0.6221\n",
      "Epoch 4888/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0206 - val_loss: 0.6308\n",
      "Epoch 4889/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0267 - val_loss: 0.6635\n",
      "Epoch 4890/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0224 - val_loss: 0.6350\n",
      "Epoch 4891/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0216 - val_loss: 0.6360\n",
      "Epoch 4892/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0241 - val_loss: 0.6318\n",
      "Epoch 4893/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0218 - val_loss: 0.6257\n",
      "Epoch 4894/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0221 - val_loss: 0.6569\n",
      "Epoch 4895/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0272 - val_loss: 0.6204\n",
      "Epoch 4896/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0252 - val_loss: 0.6224\n",
      "Epoch 4897/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0205 - val_loss: 0.6256\n",
      "Epoch 4898/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0202 - val_loss: 0.6373\n",
      "Epoch 4899/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0154 - val_loss: 0.6342\n",
      "Epoch 4900/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0247 - val_loss: 0.6200\n",
      "Epoch 4901/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0227 - val_loss: 0.6373\n",
      "Epoch 4902/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0224 - val_loss: 0.6365\n",
      "Epoch 4903/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0249 - val_loss: 0.6261\n",
      "Epoch 4904/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0302 - val_loss: 0.6388\n",
      "Epoch 4905/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0367 - val_loss: 0.6235\n",
      "Epoch 4906/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0428 - val_loss: 0.6332\n",
      "Epoch 4907/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0323 - val_loss: 0.6054\n",
      "Epoch 4908/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0182 - val_loss: 0.6270\n",
      "Epoch 4909/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0159 - val_loss: 0.6169\n",
      "Epoch 4910/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0171 - val_loss: 0.6239\n",
      "Epoch 4911/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0205 - val_loss: 0.6303\n",
      "Epoch 4912/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0208 - val_loss: 0.6331\n",
      "Epoch 4913/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0241 - val_loss: 0.6595\n",
      "Epoch 4914/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0219 - val_loss: 0.6288\n",
      "Epoch 4915/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0240 - val_loss: 0.6346\n",
      "Epoch 4916/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0221 - val_loss: 0.6214\n",
      "Epoch 4917/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0221 - val_loss: 0.6270\n",
      "Epoch 4918/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0211 - val_loss: 0.6158\n",
      "Epoch 4919/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0180 - val_loss: 0.6440\n",
      "Epoch 4920/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0241 - val_loss: 0.6232\n",
      "Epoch 4921/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0276 - val_loss: 0.6434\n",
      "Epoch 4922/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0360 - val_loss: 0.6351\n",
      "Epoch 4923/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0296 - val_loss: 0.6125\n",
      "Epoch 4924/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0191 - val_loss: 0.6286\n",
      "Epoch 4925/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0184 - val_loss: 0.6200\n",
      "Epoch 4926/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0176 - val_loss: 0.6214\n",
      "Epoch 4927/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0170 - val_loss: 0.6376\n",
      "Epoch 4928/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0198 - val_loss: 0.6309\n",
      "Epoch 4929/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0204 - val_loss: 0.6327\n",
      "Epoch 4930/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0298 - val_loss: 0.6404\n",
      "Epoch 4931/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0436 - val_loss: 0.6452\n",
      "Epoch 4932/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0261 - val_loss: 0.6444\n",
      "Epoch 4933/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0215 - val_loss: 0.5958\n",
      "Epoch 4934/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0248 - val_loss: 0.6363\n",
      "Epoch 4935/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0215 - val_loss: 0.6174\n",
      "Epoch 4936/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0173 - val_loss: 0.6229\n",
      "Epoch 4937/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0197 - val_loss: 0.6207\n",
      "Epoch 4938/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0177 - val_loss: 0.6170\n",
      "Epoch 4939/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0264 - val_loss: 0.6323\n",
      "Epoch 4940/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0266 - val_loss: 0.6307\n",
      "Epoch 4941/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0269 - val_loss: 0.6165\n",
      "Epoch 4942/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0241 - val_loss: 0.6169\n",
      "Epoch 4943/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 731us/step - loss: 0.0259 - val_loss: 0.6346\n",
      "Epoch 4944/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0249 - val_loss: 0.6337\n",
      "Epoch 4945/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0230 - val_loss: 0.6415\n",
      "Epoch 4946/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0225 - val_loss: 0.6115\n",
      "Epoch 4947/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0217 - val_loss: 0.6511\n",
      "Epoch 4948/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0263 - val_loss: 0.6312\n",
      "Epoch 4949/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0290 - val_loss: 0.6343\n",
      "Epoch 4950/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0273 - val_loss: 0.6287\n",
      "Epoch 4951/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0194 - val_loss: 0.6366\n",
      "Epoch 4952/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0178 - val_loss: 0.6265\n",
      "Epoch 4953/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0212 - val_loss: 0.6284\n",
      "Epoch 4954/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0347 - val_loss: 0.6312\n",
      "Epoch 4955/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0348 - val_loss: 0.6312\n",
      "Epoch 4956/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0195 - val_loss: 0.6136\n",
      "Epoch 4957/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0275 - val_loss: 0.6304\n",
      "Epoch 4958/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0267 - val_loss: 0.6307\n",
      "Epoch 4959/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0192 - val_loss: 0.6317\n",
      "Epoch 4960/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0200 - val_loss: 0.6321\n",
      "Epoch 4961/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0189 - val_loss: 0.6351\n",
      "Epoch 4962/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0230 - val_loss: 0.6317\n",
      "Epoch 4963/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0293 - val_loss: 0.6329\n",
      "Epoch 4964/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0221 - val_loss: 0.6248\n",
      "Epoch 4965/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0226 - val_loss: 0.6411\n",
      "Epoch 4966/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0212 - val_loss: 0.6368\n",
      "Epoch 4967/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0282 - val_loss: 0.6270\n",
      "Epoch 4968/10000\n",
      "130/130 [==============================] - 0s 934us/step - loss: 0.0194 - val_loss: 0.6274\n",
      "Epoch 4969/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0195 - val_loss: 0.6231\n",
      "Epoch 4970/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0200 - val_loss: 0.6229\n",
      "Epoch 4971/10000\n",
      "130/130 [==============================] - 0s 947us/step - loss: 0.0216 - val_loss: 0.6423\n",
      "Epoch 4972/10000\n",
      "130/130 [==============================] - 0s 824us/step - loss: 0.0232 - val_loss: 0.6253\n",
      "Epoch 4973/10000\n",
      "130/130 [==============================] - 0s 803us/step - loss: 0.0223 - val_loss: 0.6165\n",
      "Epoch 4974/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0331 - val_loss: 0.6434\n",
      "Epoch 4975/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0347 - val_loss: 0.6291\n",
      "Epoch 4976/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0181 - val_loss: 0.6316\n",
      "Epoch 4977/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0153 - val_loss: 0.6166\n",
      "Epoch 4978/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0156 - val_loss: 0.6113\n",
      "Epoch 4979/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0226 - val_loss: 0.6226\n",
      "Epoch 4980/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0269 - val_loss: 0.6527\n",
      "Epoch 4981/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0189 - val_loss: 0.6171\n",
      "Epoch 4982/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0192 - val_loss: 0.6474\n",
      "Epoch 4983/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0433 - val_loss: 0.6157\n",
      "Epoch 4984/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0389 - val_loss: 0.6309\n",
      "Epoch 4985/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0250 - val_loss: 0.6156\n",
      "Epoch 4986/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0179 - val_loss: 0.6231\n",
      "Epoch 4987/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0206 - val_loss: 0.6315\n",
      "Epoch 4988/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0188 - val_loss: 0.6353\n",
      "Epoch 4989/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0360 - val_loss: 0.6340\n",
      "Epoch 4990/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0215 - val_loss: 0.6110\n",
      "Epoch 4991/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0157 - val_loss: 0.6178\n",
      "Epoch 4992/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0270 - val_loss: 0.6338\n",
      "Epoch 4993/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0193 - val_loss: 0.6368\n",
      "Epoch 4994/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0179 - val_loss: 0.6308\n",
      "Epoch 4995/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0204 - val_loss: 0.6419\n",
      "Epoch 4996/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0247 - val_loss: 0.6208\n",
      "Epoch 4997/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0273 - val_loss: 0.6107\n",
      "Epoch 4998/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0328 - val_loss: 0.6296\n",
      "Epoch 4999/10000\n",
      "130/130 [==============================] - 0s 906us/step - loss: 0.0268 - val_loss: 0.6196\n",
      "Epoch 5000/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0259 - val_loss: 0.6270\n",
      "Epoch 5001/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0213 - val_loss: 0.6342\n",
      "Epoch 5002/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0169 - val_loss: 0.6336\n",
      "Epoch 5003/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0163 - val_loss: 0.6120\n",
      "Epoch 5004/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0196 - val_loss: 0.6305\n",
      "Epoch 5005/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0349 - val_loss: 0.6175\n",
      "Epoch 5006/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0248 - val_loss: 0.6201\n",
      "Epoch 5007/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0222 - val_loss: 0.6135\n",
      "Epoch 5008/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0293 - val_loss: 0.6181\n",
      "Epoch 5009/10000\n",
      "130/130 [==============================] - 0s 717us/step - loss: 0.0319 - val_loss: 0.6059\n",
      "Epoch 5010/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0366 - val_loss: 0.6203\n",
      "Epoch 5011/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0187 - val_loss: 0.6274\n",
      "Epoch 5012/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0210 - val_loss: 0.6238\n",
      "Epoch 5013/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0214 - val_loss: 0.6139\n",
      "Epoch 5014/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0166 - val_loss: 0.6205\n",
      "Epoch 5015/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0196 - val_loss: 0.6321\n",
      "Epoch 5016/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0185 - val_loss: 0.6261\n",
      "Epoch 5017/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0165 - val_loss: 0.6034\n",
      "Epoch 5018/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0256 - val_loss: 0.6310\n",
      "Epoch 5019/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 714us/step - loss: 0.0327 - val_loss: 0.6514\n",
      "Epoch 5020/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0264 - val_loss: 0.6227\n",
      "Epoch 5021/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0185 - val_loss: 0.6591\n",
      "Epoch 5022/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0181 - val_loss: 0.6209\n",
      "Epoch 5023/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0311 - val_loss: 0.6274\n",
      "Epoch 5024/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0645 - val_loss: 0.6451\n",
      "Epoch 5025/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0299 - val_loss: 0.6060\n",
      "Epoch 5026/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0180 - val_loss: 0.5962\n",
      "Epoch 5027/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0152 - val_loss: 0.6079\n",
      "Epoch 5028/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0147 - val_loss: 0.6080\n",
      "Epoch 5029/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0143 - val_loss: 0.6086\n",
      "Epoch 5030/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0269 - val_loss: 0.6191\n",
      "Epoch 5031/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0351 - val_loss: 0.6245\n",
      "Epoch 5032/10000\n",
      "130/130 [==============================] - 0s 899us/step - loss: 0.0360 - val_loss: 0.6405\n",
      "Epoch 5033/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0306 - val_loss: 0.6056\n",
      "Epoch 5034/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0174 - val_loss: 0.6068\n",
      "Epoch 5035/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0177 - val_loss: 0.6240\n",
      "Epoch 5036/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0196 - val_loss: 0.6400\n",
      "Epoch 5037/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0151 - val_loss: 0.6170\n",
      "Epoch 5038/10000\n",
      "130/130 [==============================] - 0s 867us/step - loss: 0.0158 - val_loss: 0.6267\n",
      "Epoch 5039/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0239 - val_loss: 0.6350\n",
      "Epoch 5040/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0217 - val_loss: 0.6413\n",
      "Epoch 5041/10000\n",
      "130/130 [==============================] - 0s 862us/step - loss: 0.0227 - val_loss: 0.6391\n",
      "Epoch 5042/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0248 - val_loss: 0.6234\n",
      "Epoch 5043/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0211 - val_loss: 0.6144\n",
      "Epoch 5044/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0222 - val_loss: 0.6307\n",
      "Epoch 5045/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0228 - val_loss: 0.6245\n",
      "Epoch 5046/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0278 - val_loss: 0.6265\n",
      "Epoch 5047/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0864 - val_loss: 0.6100\n",
      "Epoch 5048/10000\n",
      "130/130 [==============================] - 0s 710us/step - loss: 0.0553 - val_loss: 0.6266\n",
      "Epoch 5049/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0172 - val_loss: 0.6264\n",
      "Epoch 5050/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0140 - val_loss: 0.6175\n",
      "Epoch 5051/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0126 - val_loss: 0.6166\n",
      "Epoch 5052/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0157 - val_loss: 0.6179\n",
      "Epoch 5053/10000\n",
      "130/130 [==============================] - 0s 719us/step - loss: 0.0121 - val_loss: 0.6188\n",
      "Epoch 5054/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0158 - val_loss: 0.6199\n",
      "Epoch 5055/10000\n",
      "130/130 [==============================] - 0s 820us/step - loss: 0.0146 - val_loss: 0.6250\n",
      "Epoch 5056/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0179 - val_loss: 0.6237\n",
      "Epoch 5057/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0211 - val_loss: 0.6295\n",
      "Epoch 5058/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0260 - val_loss: 0.6368\n",
      "Epoch 5059/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0340 - val_loss: 0.6517\n",
      "Epoch 5060/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0395 - val_loss: 0.6220\n",
      "Epoch 5061/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0466 - val_loss: 0.6491\n",
      "Epoch 5062/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0331 - val_loss: 0.6242\n",
      "Epoch 5063/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0182 - val_loss: 0.6255\n",
      "Epoch 5064/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0197 - val_loss: 0.6278\n",
      "Epoch 5065/10000\n",
      "130/130 [==============================] - 0s 868us/step - loss: 0.0173 - val_loss: 0.6319\n",
      "Epoch 5066/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0145 - val_loss: 0.6172\n",
      "Epoch 5067/10000\n",
      "130/130 [==============================] - 0s 839us/step - loss: 0.0162 - val_loss: 0.6207\n",
      "Epoch 5068/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0163 - val_loss: 0.6170\n",
      "Epoch 5069/10000\n",
      "130/130 [==============================] - 0s 981us/step - loss: 0.0154 - val_loss: 0.6107\n",
      "Epoch 5070/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.6303\n",
      "Epoch 5071/10000\n",
      "130/130 [==============================] - 0s 843us/step - loss: 0.0316 - val_loss: 0.6068\n",
      "Epoch 5072/10000\n",
      "130/130 [==============================] - 0s 846us/step - loss: 0.0364 - val_loss: 0.6286\n",
      "Epoch 5073/10000\n",
      "130/130 [==============================] - 0s 853us/step - loss: 0.0249 - val_loss: 0.6350\n",
      "Epoch 5074/10000\n",
      "130/130 [==============================] - 0s 890us/step - loss: 0.0219 - val_loss: 0.6264\n",
      "Epoch 5075/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0240 - val_loss: 0.6148\n",
      "Epoch 5076/10000\n",
      "130/130 [==============================] - 0s 975us/step - loss: 0.0212 - val_loss: 0.6420\n",
      "Epoch 5077/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0248 - val_loss: 0.6318\n",
      "Epoch 5078/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.0186 - val_loss: 0.6214\n",
      "Epoch 5079/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0174 - val_loss: 0.6134\n",
      "Epoch 5080/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0171 - val_loss: 0.6247\n",
      "Epoch 5081/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0226 - val_loss: 0.6441\n",
      "Epoch 5082/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0274 - val_loss: 0.6384\n",
      "Epoch 5083/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0285 - val_loss: 0.6507\n",
      "Epoch 5084/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0369 - val_loss: 0.6444\n",
      "Epoch 5085/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0359 - val_loss: 0.6443\n",
      "Epoch 5086/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0238 - val_loss: 0.6145\n",
      "Epoch 5087/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0226 - val_loss: 0.6158\n",
      "Epoch 5088/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0143 - val_loss: 0.6155\n",
      "Epoch 5089/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0143 - val_loss: 0.6266\n",
      "Epoch 5090/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0167 - val_loss: 0.6211\n",
      "Epoch 5091/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0231 - val_loss: 0.6371\n",
      "Epoch 5092/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0396 - val_loss: 0.6378\n",
      "Epoch 5093/10000\n",
      "130/130 [==============================] - 0s 792us/step - loss: 0.0267 - val_loss: 0.6306\n",
      "Epoch 5094/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0181 - val_loss: 0.6172\n",
      "Epoch 5095/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 860us/step - loss: 0.0162 - val_loss: 0.6398\n",
      "Epoch 5096/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0168 - val_loss: 0.6326\n",
      "Epoch 5097/10000\n",
      "130/130 [==============================] - 0s 885us/step - loss: 0.0162 - val_loss: 0.6229\n",
      "Epoch 5098/10000\n",
      "130/130 [==============================] - 0s 936us/step - loss: 0.0177 - val_loss: 0.6303\n",
      "Epoch 5099/10000\n",
      "130/130 [==============================] - 0s 909us/step - loss: 0.0198 - val_loss: 0.6567\n",
      "Epoch 5100/10000\n",
      "130/130 [==============================] - 0s 819us/step - loss: 0.0364 - val_loss: 0.6096\n",
      "Epoch 5101/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0391 - val_loss: 0.6599\n",
      "Epoch 5102/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0521 - val_loss: 0.6310\n",
      "Epoch 5103/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0258 - val_loss: 0.6342\n",
      "Epoch 5104/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0162 - val_loss: 0.6258\n",
      "Epoch 5105/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0167 - val_loss: 0.6131\n",
      "Epoch 5106/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0191 - val_loss: 0.6221\n",
      "Epoch 5107/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0194 - val_loss: 0.6241\n",
      "Epoch 5108/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0151 - val_loss: 0.6305\n",
      "Epoch 5109/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0185 - val_loss: 0.6240\n",
      "Epoch 5110/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0204 - val_loss: 0.6235\n",
      "Epoch 5111/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0231 - val_loss: 0.6396\n",
      "Epoch 5112/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0190 - val_loss: 0.6084\n",
      "Epoch 5113/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0162 - val_loss: 0.6480\n",
      "Epoch 5114/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0238 - val_loss: 0.6161\n",
      "Epoch 5115/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0331 - val_loss: 0.6336\n",
      "Epoch 5116/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0409 - val_loss: 0.6182\n",
      "Epoch 5117/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0512 - val_loss: 0.6050\n",
      "Epoch 5118/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0247 - val_loss: 0.6154\n",
      "Epoch 5119/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0139 - val_loss: 0.6158\n",
      "Epoch 5120/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0167 - val_loss: 0.6302\n",
      "Epoch 5121/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0128 - val_loss: 0.6223\n",
      "Epoch 5122/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0131 - val_loss: 0.6298\n",
      "Epoch 5123/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0246 - val_loss: 0.6322\n",
      "Epoch 5124/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0373 - val_loss: 0.6207\n",
      "Epoch 5125/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0240 - val_loss: 0.6275\n",
      "Epoch 5126/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0259 - val_loss: 0.6124\n",
      "Epoch 5127/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0249 - val_loss: 0.6260\n",
      "Epoch 5128/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0198 - val_loss: 0.6193\n",
      "Epoch 5129/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0182 - val_loss: 0.5939\n",
      "Epoch 5130/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0149 - val_loss: 0.6245\n",
      "Epoch 5131/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0205 - val_loss: 0.6225\n",
      "Epoch 5132/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0249 - val_loss: 0.6455\n",
      "Epoch 5133/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0218 - val_loss: 0.6169\n",
      "Epoch 5134/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0250 - val_loss: 0.6152\n",
      "Epoch 5135/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0228 - val_loss: 0.6059\n",
      "Epoch 5136/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0172 - val_loss: 0.6266\n",
      "Epoch 5137/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0198 - val_loss: 0.6332\n",
      "Epoch 5138/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0188 - val_loss: 0.6064\n",
      "Epoch 5139/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0188 - val_loss: 0.6087\n",
      "Epoch 5140/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0302 - val_loss: 0.6208\n",
      "Epoch 5141/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0268 - val_loss: 0.6282\n",
      "Epoch 5142/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0202 - val_loss: 0.6220\n",
      "Epoch 5143/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0206 - val_loss: 0.6206\n",
      "Epoch 5144/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0226 - val_loss: 0.6088\n",
      "Epoch 5145/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0291 - val_loss: 0.6362\n",
      "Epoch 5146/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0210 - val_loss: 0.6138\n",
      "Epoch 5147/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0174 - val_loss: 0.6227\n",
      "Epoch 5148/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0162 - val_loss: 0.6119\n",
      "Epoch 5149/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0351 - val_loss: 0.6355\n",
      "Epoch 5150/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0863 - val_loss: 0.6269\n",
      "Epoch 5151/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0312 - val_loss: 0.6275\n",
      "Epoch 5152/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0157 - val_loss: 0.6129\n",
      "Epoch 5153/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0144 - val_loss: 0.6199\n",
      "Epoch 5154/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0178 - val_loss: 0.6263\n",
      "Epoch 5155/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0167 - val_loss: 0.6247\n",
      "Epoch 5156/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0139 - val_loss: 0.6255\n",
      "Epoch 5157/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0153 - val_loss: 0.6284\n",
      "Epoch 5158/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0166 - val_loss: 0.6327\n",
      "Epoch 5159/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0208 - val_loss: 0.6310\n",
      "Epoch 5160/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0226 - val_loss: 0.6077\n",
      "Epoch 5161/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0264 - val_loss: 0.6123\n",
      "Epoch 5162/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0242 - val_loss: 0.6317\n",
      "Epoch 5163/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0313 - val_loss: 0.6291\n",
      "Epoch 5164/10000\n",
      "130/130 [==============================] - 0s 715us/step - loss: 0.0274 - val_loss: 0.6214\n",
      "Epoch 5165/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0222 - val_loss: 0.6343\n",
      "Epoch 5166/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0210 - val_loss: 0.6152\n",
      "Epoch 5167/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0163 - val_loss: 0.6440\n",
      "Epoch 5168/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0151 - val_loss: 0.6240\n",
      "Epoch 5169/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0213 - val_loss: 0.6256\n",
      "Epoch 5170/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0222 - val_loss: 0.6273\n",
      "Epoch 5171/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 721us/step - loss: 0.0174 - val_loss: 0.6265\n",
      "Epoch 5172/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0165 - val_loss: 0.6071\n",
      "Epoch 5173/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0150 - val_loss: 0.6261\n",
      "Epoch 5174/10000\n",
      "130/130 [==============================] - 0s 714us/step - loss: 0.0158 - val_loss: 0.6255\n",
      "Epoch 5175/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0295 - val_loss: 0.6735\n",
      "Epoch 5176/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0495 - val_loss: 0.6446\n",
      "Epoch 5177/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0296 - val_loss: 0.6382\n",
      "Epoch 5178/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0207 - val_loss: 0.6139\n",
      "Epoch 5179/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0204 - val_loss: 0.6254\n",
      "Epoch 5180/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0212 - val_loss: 0.6106\n",
      "Epoch 5181/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0165 - val_loss: 0.6214\n",
      "Epoch 5182/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0257 - val_loss: 0.6418\n",
      "Epoch 5183/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0233 - val_loss: 0.6031\n",
      "Epoch 5184/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0245 - val_loss: 0.6406\n",
      "Epoch 5185/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0295 - val_loss: 0.6206\n",
      "Epoch 5186/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0364 - val_loss: 0.6289\n",
      "Epoch 5187/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0252 - val_loss: 0.6363\n",
      "Epoch 5188/10000\n",
      "130/130 [==============================] - 0s 804us/step - loss: 0.0158 - val_loss: 0.6217\n",
      "Epoch 5189/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0188 - val_loss: 0.6478\n",
      "Epoch 5190/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0166 - val_loss: 0.6310\n",
      "Epoch 5191/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0213 - val_loss: 0.6258\n",
      "Epoch 5192/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0206 - val_loss: 0.6357\n",
      "Epoch 5193/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0184 - val_loss: 0.6338\n",
      "Epoch 5194/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0206 - val_loss: 0.6437\n",
      "Epoch 5195/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0277 - val_loss: 0.6288\n",
      "Epoch 5196/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0228 - val_loss: 0.6095\n",
      "Epoch 5197/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0353 - val_loss: 0.6384\n",
      "Epoch 5198/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0222 - val_loss: 0.6143\n",
      "Epoch 5199/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0151 - val_loss: 0.6167\n",
      "Epoch 5200/10000\n",
      "130/130 [==============================] - 0s 809us/step - loss: 0.0184 - val_loss: 0.6204\n",
      "Epoch 5201/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0259 - val_loss: 0.6246\n",
      "Epoch 5202/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0267 - val_loss: 0.6559\n",
      "Epoch 5203/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0333 - val_loss: 0.6170\n",
      "Epoch 5204/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0560 - val_loss: 0.6439\n",
      "Epoch 5205/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0447 - val_loss: 0.5914\n",
      "Epoch 5206/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0217 - val_loss: 0.6112\n",
      "Epoch 5207/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0160 - val_loss: 0.6321\n",
      "Epoch 5208/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0132 - val_loss: 0.6222\n",
      "Epoch 5209/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0143 - val_loss: 0.6384\n",
      "Epoch 5210/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0195 - val_loss: 0.6425\n",
      "Epoch 5211/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0181 - val_loss: 0.6302\n",
      "Epoch 5212/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0239 - val_loss: 0.6148\n",
      "Epoch 5213/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0240 - val_loss: 0.6213\n",
      "Epoch 5214/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0184 - val_loss: 0.6138\n",
      "Epoch 5215/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0177 - val_loss: 0.6357\n",
      "Epoch 5216/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0286 - val_loss: 0.6480\n",
      "Epoch 5217/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0231 - val_loss: 0.6328\n",
      "Epoch 5218/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0184 - val_loss: 0.6060\n",
      "Epoch 5219/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0230 - val_loss: 0.6152\n",
      "Epoch 5220/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0203 - val_loss: 0.6312\n",
      "Epoch 5221/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0201 - val_loss: 0.6165\n",
      "Epoch 5222/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0210 - val_loss: 0.6238\n",
      "Epoch 5223/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0156 - val_loss: 0.6063\n",
      "Epoch 5224/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0155 - val_loss: 0.6077\n",
      "Epoch 5225/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0161 - val_loss: 0.6231\n",
      "Epoch 5226/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0188 - val_loss: 0.6080\n",
      "Epoch 5227/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0322 - val_loss: 0.6734\n",
      "Epoch 5228/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0375 - val_loss: 0.6267\n",
      "Epoch 5229/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0274 - val_loss: 0.6246\n",
      "Epoch 5230/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0231 - val_loss: 0.6276\n",
      "Epoch 5231/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0346 - val_loss: 0.6382\n",
      "Epoch 5232/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0371 - val_loss: 0.6359\n",
      "Epoch 5233/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0269 - val_loss: 0.6333\n",
      "Epoch 5234/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0233 - val_loss: 0.6151\n",
      "Epoch 5235/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0142 - val_loss: 0.6056\n",
      "Epoch 5236/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0168 - val_loss: 0.6382\n",
      "Epoch 5237/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0232 - val_loss: 0.6185\n",
      "Epoch 5238/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0344 - val_loss: 0.6135\n",
      "Epoch 5239/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0290 - val_loss: 0.6078\n",
      "Epoch 5240/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0190 - val_loss: 0.6262\n",
      "Epoch 5241/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0149 - val_loss: 0.6119\n",
      "Epoch 5242/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0143 - val_loss: 0.6376\n",
      "Epoch 5243/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0149 - val_loss: 0.6225\n",
      "Epoch 5244/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0180 - val_loss: 0.6389\n",
      "Epoch 5245/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0170 - val_loss: 0.6021\n",
      "Epoch 5246/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0241 - val_loss: 0.6280\n",
      "Epoch 5247/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 764us/step - loss: 0.0253 - val_loss: 0.6267\n",
      "Epoch 5248/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0157 - val_loss: 0.6110\n",
      "Epoch 5249/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0210 - val_loss: 0.6183\n",
      "Epoch 5250/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0259 - val_loss: 0.6517\n",
      "Epoch 5251/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0340 - val_loss: 0.5964\n",
      "Epoch 5252/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0429 - val_loss: 0.6048\n",
      "Epoch 5253/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0958 - val_loss: 0.6346\n",
      "Epoch 5254/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0322 - val_loss: 0.6263\n",
      "Epoch 5255/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0144 - val_loss: 0.6074\n",
      "Epoch 5256/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0116 - val_loss: 0.6021\n",
      "Epoch 5257/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0118 - val_loss: 0.6216\n",
      "Epoch 5258/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0112 - val_loss: 0.6043\n",
      "Epoch 5259/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0128 - val_loss: 0.6077\n",
      "Epoch 5260/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0136 - val_loss: 0.6452\n",
      "Epoch 5261/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0157 - val_loss: 0.6128\n",
      "Epoch 5262/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0178 - val_loss: 0.6326\n",
      "Epoch 5263/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0219 - val_loss: 0.6578\n",
      "Epoch 5264/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0359 - val_loss: 0.6112\n",
      "Epoch 5265/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0443 - val_loss: 0.6189\n",
      "Epoch 5266/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0231 - val_loss: 0.6128\n",
      "Epoch 5267/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0173 - val_loss: 0.6148\n",
      "Epoch 5268/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0150 - val_loss: 0.6024\n",
      "Epoch 5269/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0159 - val_loss: 0.6186\n",
      "Epoch 5270/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0154 - val_loss: 0.5979\n",
      "Epoch 5271/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0232 - val_loss: 0.6083\n",
      "Epoch 5272/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0252 - val_loss: 0.6007\n",
      "Epoch 5273/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0410 - val_loss: 0.6245\n",
      "Epoch 5274/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0525 - val_loss: 0.6204\n",
      "Epoch 5275/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0339 - val_loss: 0.6243\n",
      "Epoch 5276/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0195 - val_loss: 0.6114\n",
      "Epoch 5277/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0133 - val_loss: 0.6136\n",
      "Epoch 5278/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0127 - val_loss: 0.6092\n",
      "Epoch 5279/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0118 - val_loss: 0.6126\n",
      "Epoch 5280/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0129 - val_loss: 0.6196\n",
      "Epoch 5281/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0134 - val_loss: 0.6097\n",
      "Epoch 5282/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0161 - val_loss: 0.5971\n",
      "Epoch 5283/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0226 - val_loss: 0.6059\n",
      "Epoch 5284/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0427 - val_loss: 0.6145\n",
      "Epoch 5285/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0286 - val_loss: 0.6116\n",
      "Epoch 5286/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0223 - val_loss: 0.6183\n",
      "Epoch 5287/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0217 - val_loss: 0.6176\n",
      "Epoch 5288/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0203 - val_loss: 0.6108\n",
      "Epoch 5289/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0199 - val_loss: 0.6293\n",
      "Epoch 5290/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0188 - val_loss: 0.6147\n",
      "Epoch 5291/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0288 - val_loss: 0.5905\n",
      "Epoch 5292/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0245 - val_loss: 0.6306\n",
      "Epoch 5293/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0247 - val_loss: 0.6100\n",
      "Epoch 5294/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0281 - val_loss: 0.6332\n",
      "Epoch 5295/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0168 - val_loss: 0.6260\n",
      "Epoch 5296/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0223 - val_loss: 0.6348\n",
      "Epoch 5297/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0212 - val_loss: 0.6363\n",
      "Epoch 5298/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0138 - val_loss: 0.6233\n",
      "Epoch 5299/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0180 - val_loss: 0.5927\n",
      "Epoch 5300/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0162 - val_loss: 0.6189\n",
      "Epoch 5301/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0143 - val_loss: 0.6290\n",
      "Epoch 5302/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0174 - val_loss: 0.6149\n",
      "Epoch 5303/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0295 - val_loss: 0.6334\n",
      "Epoch 5304/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0309 - val_loss: 0.6103\n",
      "Epoch 5305/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0388 - val_loss: 0.6192\n",
      "Epoch 5306/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0412 - val_loss: 0.6248\n",
      "Epoch 5307/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0336 - val_loss: 0.6308\n",
      "Epoch 5308/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0160 - val_loss: 0.6198\n",
      "Epoch 5309/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0128 - val_loss: 0.6323\n",
      "Epoch 5310/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0187 - val_loss: 0.6159\n",
      "Epoch 5311/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0241 - val_loss: 0.6271\n",
      "Epoch 5312/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0245 - val_loss: 0.6209\n",
      "Epoch 5313/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0223 - val_loss: 0.6178\n",
      "Epoch 5314/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0251 - val_loss: 0.6225\n",
      "Epoch 5315/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0157 - val_loss: 0.6068\n",
      "Epoch 5316/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0167 - val_loss: 0.6256\n",
      "Epoch 5317/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0199 - val_loss: 0.6331\n",
      "Epoch 5318/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0156 - val_loss: 0.6524\n",
      "Epoch 5319/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0176 - val_loss: 0.6160\n",
      "Epoch 5320/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0220 - val_loss: 0.6386\n",
      "Epoch 5321/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0244 - val_loss: 0.6279\n",
      "Epoch 5322/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0272 - val_loss: 0.6438\n",
      "Epoch 5323/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 735us/step - loss: 0.1126 - val_loss: 0.6108\n",
      "Epoch 5324/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0473 - val_loss: 0.5948\n",
      "Epoch 5325/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0799 - val_loss: 0.6388\n",
      "Epoch 5326/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0212 - val_loss: 0.6270\n",
      "Epoch 5327/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0145 - val_loss: 0.6154\n",
      "Epoch 5328/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0123 - val_loss: 0.6200\n",
      "Epoch 5329/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0126 - val_loss: 0.6320\n",
      "Epoch 5330/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0157 - val_loss: 0.6209\n",
      "Epoch 5331/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0122 - val_loss: 0.6096\n",
      "Epoch 5332/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0123 - val_loss: 0.6140\n",
      "Epoch 5333/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0116 - val_loss: 0.6172\n",
      "Epoch 5334/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0179 - val_loss: 0.6433\n",
      "Epoch 5335/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0260 - val_loss: 0.6213\n",
      "Epoch 5336/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0255 - val_loss: 0.6101\n",
      "Epoch 5337/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0230 - val_loss: 0.6049\n",
      "Epoch 5338/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0365 - val_loss: 0.6215\n",
      "Epoch 5339/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0351 - val_loss: 0.5984\n",
      "Epoch 5340/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0233 - val_loss: 0.6279\n",
      "Epoch 5341/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0243 - val_loss: 0.6170\n",
      "Epoch 5342/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0125 - val_loss: 0.6198\n",
      "Epoch 5343/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0141 - val_loss: 0.6061\n",
      "Epoch 5344/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0121 - val_loss: 0.6203\n",
      "Epoch 5345/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0304 - val_loss: 0.6301\n",
      "Epoch 5346/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0342 - val_loss: 0.6246\n",
      "Epoch 5347/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0230 - val_loss: 0.6223\n",
      "Epoch 5348/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0308 - val_loss: 0.6173\n",
      "Epoch 5349/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0284 - val_loss: 0.6327\n",
      "Epoch 5350/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0231 - val_loss: 0.6122\n",
      "Epoch 5351/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0150 - val_loss: 0.6165\n",
      "Epoch 5352/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0130 - val_loss: 0.6304\n",
      "Epoch 5353/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0152 - val_loss: 0.6258\n",
      "Epoch 5354/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0155 - val_loss: 0.6106\n",
      "Epoch 5355/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0144 - val_loss: 0.6117\n",
      "Epoch 5356/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0241 - val_loss: 0.6354\n",
      "Epoch 5357/10000\n",
      "130/130 [==============================] - 0s 842us/step - loss: 0.0369 - val_loss: 0.6132\n",
      "Epoch 5358/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0692 - val_loss: 0.5877\n",
      "Epoch 5359/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0786 - val_loss: 0.6114\n",
      "Epoch 5360/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0374 - val_loss: 0.5917\n",
      "Epoch 5361/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0179 - val_loss: 0.6016\n",
      "Epoch 5362/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0112 - val_loss: 0.6026\n",
      "Epoch 5363/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0118 - val_loss: 0.6108\n",
      "Epoch 5364/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0135 - val_loss: 0.6009\n",
      "Epoch 5365/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0159 - val_loss: 0.6199\n",
      "Epoch 5366/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0154 - val_loss: 0.6036\n",
      "Epoch 5367/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0159 - val_loss: 0.6062\n",
      "Epoch 5368/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0182 - val_loss: 0.6025\n",
      "Epoch 5369/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0330 - val_loss: 0.6165\n",
      "Epoch 5370/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0452 - val_loss: 0.6215\n",
      "Epoch 5371/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0336 - val_loss: 0.6145\n",
      "Epoch 5372/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0189 - val_loss: 0.6009\n",
      "Epoch 5373/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0163 - val_loss: 0.6427\n",
      "Epoch 5374/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0155 - val_loss: 0.6016\n",
      "Epoch 5375/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0142 - val_loss: 0.6134\n",
      "Epoch 5376/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0144 - val_loss: 0.6216\n",
      "Epoch 5377/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0277 - val_loss: 0.6216\n",
      "Epoch 5378/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0285 - val_loss: 0.6170\n",
      "Epoch 5379/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0247 - val_loss: 0.6444\n",
      "Epoch 5380/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0268 - val_loss: 0.6218\n",
      "Epoch 5381/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0182 - val_loss: 0.6135\n",
      "Epoch 5382/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0163 - val_loss: 0.6163\n",
      "Epoch 5383/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0382 - val_loss: 0.6455\n",
      "Epoch 5384/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0364 - val_loss: 0.6111\n",
      "Epoch 5385/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0224 - val_loss: 0.6051\n",
      "Epoch 5386/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0153 - val_loss: 0.5955\n",
      "Epoch 5387/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0183 - val_loss: 0.6120\n",
      "Epoch 5388/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0158 - val_loss: 0.6252\n",
      "Epoch 5389/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0125 - val_loss: 0.6243\n",
      "Epoch 5390/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0182 - val_loss: 0.6182\n",
      "Epoch 5391/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0259 - val_loss: 0.6325\n",
      "Epoch 5392/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.6373\n",
      "Epoch 5393/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0274 - val_loss: 0.6204\n",
      "Epoch 5394/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0313 - val_loss: 0.6105\n",
      "Epoch 5395/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0262 - val_loss: 0.6245\n",
      "Epoch 5396/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0235 - val_loss: 0.6313\n",
      "Epoch 5397/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0340 - val_loss: 0.6052\n",
      "Epoch 5398/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0403 - val_loss: 0.6257\n",
      "Epoch 5399/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 742us/step - loss: 0.0206 - val_loss: 0.5993\n",
      "Epoch 5400/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0151 - val_loss: 0.6193\n",
      "Epoch 5401/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0151 - val_loss: 0.6032\n",
      "Epoch 5402/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0210 - val_loss: 0.6205\n",
      "Epoch 5403/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0144 - val_loss: 0.6155\n",
      "Epoch 5404/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0137 - val_loss: 0.6254\n",
      "Epoch 5405/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0189 - val_loss: 0.6056\n",
      "Epoch 5406/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0227 - val_loss: 0.6277\n",
      "Epoch 5407/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0201 - val_loss: 0.6199\n",
      "Epoch 5408/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0323 - val_loss: 0.6478\n",
      "Epoch 5409/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0445 - val_loss: 0.6389\n",
      "Epoch 5410/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0239 - val_loss: 0.6263\n",
      "Epoch 5411/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0146 - val_loss: 0.5960\n",
      "Epoch 5412/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0179 - val_loss: 0.6109\n",
      "Epoch 5413/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0160 - val_loss: 0.6113\n",
      "Epoch 5414/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0179 - val_loss: 0.6524\n",
      "Epoch 5415/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0272 - val_loss: 0.5991\n",
      "Epoch 5416/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0186 - val_loss: 0.6143\n",
      "Epoch 5417/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0276 - val_loss: 0.6114\n",
      "Epoch 5418/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0381 - val_loss: 0.6055\n",
      "Epoch 5419/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0299 - val_loss: 0.6101\n",
      "Epoch 5420/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0164 - val_loss: 0.6153\n",
      "Epoch 5421/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0113 - val_loss: 0.6236\n",
      "Epoch 5422/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0113 - val_loss: 0.6174\n",
      "Epoch 5423/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0201 - val_loss: 0.6075\n",
      "Epoch 5424/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0186 - val_loss: 0.6421\n",
      "Epoch 5425/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0205 - val_loss: 0.6613\n",
      "Epoch 5426/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0277 - val_loss: 0.6157\n",
      "Epoch 5427/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0215 - val_loss: 0.6188\n",
      "Epoch 5428/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0762 - val_loss: 0.6272\n",
      "Epoch 5429/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0383 - val_loss: 0.6139\n",
      "Epoch 5430/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0180 - val_loss: 0.6258\n",
      "Epoch 5431/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0143 - val_loss: 0.6022\n",
      "Epoch 5432/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0124 - val_loss: 0.6224\n",
      "Epoch 5433/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0145 - val_loss: 0.6173\n",
      "Epoch 5434/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0130 - val_loss: 0.6369\n",
      "Epoch 5435/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0413 - val_loss: 0.6729\n",
      "Epoch 5436/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0544 - val_loss: 0.5856\n",
      "Epoch 5437/10000\n",
      "130/130 [==============================] - 0s 718us/step - loss: 0.0291 - val_loss: 0.6222\n",
      "Epoch 5438/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0192 - val_loss: 0.6179\n",
      "Epoch 5439/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0159 - val_loss: 0.6383\n",
      "Epoch 5440/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0116 - val_loss: 0.6169\n",
      "Epoch 5441/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0160 - val_loss: 0.6191\n",
      "Epoch 5442/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0172 - val_loss: 0.6357\n",
      "Epoch 5443/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0174 - val_loss: 0.6147\n",
      "Epoch 5444/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0176 - val_loss: 0.6356\n",
      "Epoch 5445/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0267 - val_loss: 0.6136\n",
      "Epoch 5446/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0425 - val_loss: 0.6496\n",
      "Epoch 5447/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0354 - val_loss: 0.6525\n",
      "Epoch 5448/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0185 - val_loss: 0.6319\n",
      "Epoch 5449/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0200 - val_loss: 0.6511\n",
      "Epoch 5450/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0143 - val_loss: 0.6115\n",
      "Epoch 5451/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0108 - val_loss: 0.6428\n",
      "Epoch 5452/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0144 - val_loss: 0.6234\n",
      "Epoch 5453/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0344 - val_loss: 0.6240\n",
      "Epoch 5454/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0273 - val_loss: 0.6113\n",
      "Epoch 5455/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0156 - val_loss: 0.6215\n",
      "Epoch 5456/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0174 - val_loss: 0.6298\n",
      "Epoch 5457/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0321 - val_loss: 0.6334\n",
      "Epoch 5458/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0355 - val_loss: 0.6240\n",
      "Epoch 5459/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0240 - val_loss: 0.6304\n",
      "Epoch 5460/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0274 - val_loss: 0.6009\n",
      "Epoch 5461/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0260 - val_loss: 0.6246\n",
      "Epoch 5462/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0389 - val_loss: 0.6194\n",
      "Epoch 5463/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0208 - val_loss: 0.6266\n",
      "Epoch 5464/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0170 - val_loss: 0.6286\n",
      "Epoch 5465/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0133 - val_loss: 0.6234\n",
      "Epoch 5466/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0107 - val_loss: 0.6216\n",
      "Epoch 5467/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0125 - val_loss: 0.6352\n",
      "Epoch 5468/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0121 - val_loss: 0.6300\n",
      "Epoch 5469/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0142 - val_loss: 0.6211\n",
      "Epoch 5470/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0237 - val_loss: 0.6182\n",
      "Epoch 5471/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0385 - val_loss: 0.6256\n",
      "Epoch 5472/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0378 - val_loss: 0.5933\n",
      "Epoch 5473/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0473 - val_loss: 0.6190\n",
      "Epoch 5474/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0414 - val_loss: 0.6125\n",
      "Epoch 5475/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 750us/step - loss: 0.0210 - val_loss: 0.6061\n",
      "Epoch 5476/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0168 - val_loss: 0.6071\n",
      "Epoch 5477/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0148 - val_loss: 0.6231\n",
      "Epoch 5478/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0183 - val_loss: 0.6267\n",
      "Epoch 5479/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0131 - val_loss: 0.5972\n",
      "Epoch 5480/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0127 - val_loss: 0.6065\n",
      "Epoch 5481/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0124 - val_loss: 0.6292\n",
      "Epoch 5482/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0185 - val_loss: 0.6369\n",
      "Epoch 5483/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0261 - val_loss: 0.6365\n",
      "Epoch 5484/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0504 - val_loss: 0.6497\n",
      "Epoch 5485/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0302 - val_loss: 0.6404\n",
      "Epoch 5486/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0255 - val_loss: 0.6246\n",
      "Epoch 5487/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0203 - val_loss: 0.6248\n",
      "Epoch 5488/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0142 - val_loss: 0.6321\n",
      "Epoch 5489/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0127 - val_loss: 0.5870\n",
      "Epoch 5490/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0209 - val_loss: 0.6305\n",
      "Epoch 5491/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0214 - val_loss: 0.6390\n",
      "Epoch 5492/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0429 - val_loss: 0.6337\n",
      "Epoch 5493/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0299 - val_loss: 0.6523\n",
      "Epoch 5494/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0263 - val_loss: 0.6219\n",
      "Epoch 5495/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0195 - val_loss: 0.6026\n",
      "Epoch 5496/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0143 - val_loss: 0.6217\n",
      "Epoch 5497/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0135 - val_loss: 0.6152\n",
      "Epoch 5498/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0108 - val_loss: 0.6061\n",
      "Epoch 5499/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0136 - val_loss: 0.5999\n",
      "Epoch 5500/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0192 - val_loss: 0.6028\n",
      "Epoch 5501/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0257 - val_loss: 0.6656\n",
      "Epoch 5502/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0276 - val_loss: 0.6321\n",
      "Epoch 5503/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0290 - val_loss: 0.6346\n",
      "Epoch 5504/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0661 - val_loss: 0.5907\n",
      "Epoch 5505/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0375 - val_loss: 0.5894\n",
      "Epoch 5506/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0202 - val_loss: 0.6130\n",
      "Epoch 5507/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0122 - val_loss: 0.6115\n",
      "Epoch 5508/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0111 - val_loss: 0.6069\n",
      "Epoch 5509/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0114 - val_loss: 0.6185\n",
      "Epoch 5510/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0216 - val_loss: 0.6552\n",
      "Epoch 5511/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0261 - val_loss: 0.6595\n",
      "Epoch 5512/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0236 - val_loss: 0.6061\n",
      "Epoch 5513/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0243 - val_loss: 0.6248\n",
      "Epoch 5514/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0184 - val_loss: 0.6031\n",
      "Epoch 5515/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0209 - val_loss: 0.6290\n",
      "Epoch 5516/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0383 - val_loss: 0.6429\n",
      "Epoch 5517/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0306 - val_loss: 0.6090\n",
      "Epoch 5518/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0246 - val_loss: 0.6546\n",
      "Epoch 5519/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0343 - val_loss: 0.6303\n",
      "Epoch 5520/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0474 - val_loss: 0.6464\n",
      "Epoch 5521/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0309 - val_loss: 0.6320\n",
      "Epoch 5522/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0138 - val_loss: 0.6226\n",
      "Epoch 5523/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0103 - val_loss: 0.6060\n",
      "Epoch 5524/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0094 - val_loss: 0.6178\n",
      "Epoch 5525/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0106 - val_loss: 0.6094\n",
      "Epoch 5526/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0129 - val_loss: 0.6253\n",
      "Epoch 5527/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0175 - val_loss: 0.6167\n",
      "Epoch 5528/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0155 - val_loss: 0.6256\n",
      "Epoch 5529/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0291 - val_loss: 0.6354\n",
      "Epoch 5530/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0500 - val_loss: 0.6511\n",
      "Epoch 5531/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0670 - val_loss: 0.6160\n",
      "Epoch 5532/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0390 - val_loss: 0.5972\n",
      "Epoch 5533/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0116 - val_loss: 0.6257\n",
      "Epoch 5534/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0101 - val_loss: 0.6018\n",
      "Epoch 5535/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0113 - val_loss: 0.6093\n",
      "Epoch 5536/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0107 - val_loss: 0.6209\n",
      "Epoch 5537/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0160 - val_loss: 0.6178\n",
      "Epoch 5538/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0293 - val_loss: 0.6359\n",
      "Epoch 5539/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0272 - val_loss: 0.6288\n",
      "Epoch 5540/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0420 - val_loss: 0.6130\n",
      "Epoch 5541/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0426 - val_loss: 0.6274\n",
      "Epoch 5542/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0226 - val_loss: 0.6010\n",
      "Epoch 5543/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0226 - val_loss: 0.6127\n",
      "Epoch 5544/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0254 - val_loss: 0.5970\n",
      "Epoch 5545/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0156 - val_loss: 0.5918\n",
      "Epoch 5546/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0141 - val_loss: 0.6144\n",
      "Epoch 5547/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0155 - val_loss: 0.6239\n",
      "Epoch 5548/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0167 - val_loss: 0.6236\n",
      "Epoch 5549/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0166 - val_loss: 0.6180\n",
      "Epoch 5550/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0195 - val_loss: 0.6306\n",
      "Epoch 5551/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 744us/step - loss: 0.0281 - val_loss: 0.5994\n",
      "Epoch 5552/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0267 - val_loss: 0.6200\n",
      "Epoch 5553/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0268 - val_loss: 0.6358\n",
      "Epoch 5554/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0237 - val_loss: 0.6070\n",
      "Epoch 5555/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0217 - val_loss: 0.6117\n",
      "Epoch 5556/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0270 - val_loss: 0.5985\n",
      "Epoch 5557/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0230 - val_loss: 0.6175\n",
      "Epoch 5558/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0199 - val_loss: 0.6466\n",
      "Epoch 5559/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0152 - val_loss: 0.5924\n",
      "Epoch 5560/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0160 - val_loss: 0.6106\n",
      "Epoch 5561/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0246 - val_loss: 0.6215\n",
      "Epoch 5562/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0398 - val_loss: 0.6127\n",
      "Epoch 5563/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0372 - val_loss: 0.6261\n",
      "Epoch 5564/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0525 - val_loss: 0.6352\n",
      "Epoch 5565/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0588 - val_loss: 0.6355\n",
      "Epoch 5566/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0289 - val_loss: 0.6163\n",
      "Epoch 5567/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0155 - val_loss: 0.6144\n",
      "Epoch 5568/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0151 - val_loss: 0.6040\n",
      "Epoch 5569/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0108 - val_loss: 0.6103\n",
      "Epoch 5570/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0089 - val_loss: 0.6002\n",
      "Epoch 5571/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0098 - val_loss: 0.5827\n",
      "Epoch 5572/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0139 - val_loss: 0.6303\n",
      "Epoch 5573/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0224 - val_loss: 0.5962\n",
      "Epoch 5574/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0636 - val_loss: 0.6130\n",
      "Epoch 5575/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0644 - val_loss: 0.5866\n",
      "Epoch 5576/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0268 - val_loss: 0.5956\n",
      "Epoch 5577/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0148 - val_loss: 0.6217\n",
      "Epoch 5578/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0177 - val_loss: 0.6230\n",
      "Epoch 5579/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0169 - val_loss: 0.6269\n",
      "Epoch 5580/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0119 - val_loss: 0.6190\n",
      "Epoch 5581/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0124 - val_loss: 0.6015\n",
      "Epoch 5582/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0142 - val_loss: 0.5881\n",
      "Epoch 5583/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0197 - val_loss: 0.6139\n",
      "Epoch 5584/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0343 - val_loss: 0.6074\n",
      "Epoch 5585/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0390 - val_loss: 0.6141\n",
      "Epoch 5586/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0298 - val_loss: 0.6129\n",
      "Epoch 5587/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0222 - val_loss: 0.6328\n",
      "Epoch 5588/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0132 - val_loss: 0.6059\n",
      "Epoch 5589/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0235 - val_loss: 0.6223\n",
      "Epoch 5590/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0221 - val_loss: 0.5819\n",
      "Epoch 5591/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0280 - val_loss: 0.6218\n",
      "Epoch 5592/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0304 - val_loss: 0.6049\n",
      "Epoch 5593/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0236 - val_loss: 0.6263\n",
      "Epoch 5594/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0268 - val_loss: 0.6119\n",
      "Epoch 5595/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0159 - val_loss: 0.6124\n",
      "Epoch 5596/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0180 - val_loss: 0.6152\n",
      "Epoch 5597/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0159 - val_loss: 0.6175\n",
      "Epoch 5598/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0173 - val_loss: 0.5949\n",
      "Epoch 5599/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0148 - val_loss: 0.6128\n",
      "Epoch 5600/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0204 - val_loss: 0.6142\n",
      "Epoch 5601/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0260 - val_loss: 0.6188\n",
      "Epoch 5602/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1066 - val_loss: 0.6262\n",
      "Epoch 5603/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.1354 - val_loss: 0.6102\n",
      "Epoch 5604/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0469 - val_loss: 0.6249\n",
      "Epoch 5605/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0223 - val_loss: 0.6255\n",
      "Epoch 5606/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0156 - val_loss: 0.6107\n",
      "Epoch 5607/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0119 - val_loss: 0.6209\n",
      "Epoch 5608/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0095 - val_loss: 0.6299\n",
      "Epoch 5609/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0092 - val_loss: 0.6144\n",
      "Epoch 5610/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0110 - val_loss: 0.6137\n",
      "Epoch 5611/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0146 - val_loss: 0.6233\n",
      "Epoch 5612/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0202 - val_loss: 0.6103\n",
      "Epoch 5613/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0229 - val_loss: 0.6231\n",
      "Epoch 5614/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0393 - val_loss: 0.6472\n",
      "Epoch 5615/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0279 - val_loss: 0.6286\n",
      "Epoch 5616/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0189 - val_loss: 0.6136\n",
      "Epoch 5617/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0214 - val_loss: 0.6029\n",
      "Epoch 5618/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0450 - val_loss: 0.6335\n",
      "Epoch 5619/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0216 - val_loss: 0.6183\n",
      "Epoch 5620/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0180 - val_loss: 0.6193\n",
      "Epoch 5621/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0131 - val_loss: 0.6278\n",
      "Epoch 5622/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0109 - val_loss: 0.6261\n",
      "Epoch 5623/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0113 - val_loss: 0.6165\n",
      "Epoch 5624/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0124 - val_loss: 0.6292\n",
      "Epoch 5625/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0195 - val_loss: 0.6353\n",
      "Epoch 5626/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0409 - val_loss: 0.6106\n",
      "Epoch 5627/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 743us/step - loss: 0.0531 - val_loss: 0.6605\n",
      "Epoch 5628/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0398 - val_loss: 0.6002\n",
      "Epoch 5629/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0305 - val_loss: 0.6309\n",
      "Epoch 5630/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0235 - val_loss: 0.6077\n",
      "Epoch 5631/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0115 - val_loss: 0.6050\n",
      "Epoch 5632/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0117 - val_loss: 0.6210\n",
      "Epoch 5633/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0178 - val_loss: 0.6161\n",
      "Epoch 5634/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0237 - val_loss: 0.6200\n",
      "Epoch 5635/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0161 - val_loss: 0.6231\n",
      "Epoch 5636/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0162 - val_loss: 0.6000\n",
      "Epoch 5637/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0390 - val_loss: 0.6144\n",
      "Epoch 5638/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0227 - val_loss: 0.6288\n",
      "Epoch 5639/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0149 - val_loss: 0.6351\n",
      "Epoch 5640/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0285 - val_loss: 0.5917\n",
      "Epoch 5641/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0217 - val_loss: 0.6111\n",
      "Epoch 5642/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0356 - val_loss: 0.6634\n",
      "Epoch 5643/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0277 - val_loss: 0.6137\n",
      "Epoch 5644/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0195 - val_loss: 0.6203\n",
      "Epoch 5645/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0289 - val_loss: 0.6045\n",
      "Epoch 5646/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0430 - val_loss: 0.6441\n",
      "Epoch 5647/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0519 - val_loss: 0.6247\n",
      "Epoch 5648/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0262 - val_loss: 0.6179\n",
      "Epoch 5649/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0163 - val_loss: 0.6306\n",
      "Epoch 5650/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0140 - val_loss: 0.6288\n",
      "Epoch 5651/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0130 - val_loss: 0.6353\n",
      "Epoch 5652/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0138 - val_loss: 0.6254\n",
      "Epoch 5653/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0320 - val_loss: 0.6269\n",
      "Epoch 5654/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0407 - val_loss: 0.6388\n",
      "Epoch 5655/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0523 - val_loss: 0.6263\n",
      "Epoch 5656/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0227 - val_loss: 0.6170\n",
      "Epoch 5657/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0193 - val_loss: 0.5941\n",
      "Epoch 5658/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0138 - val_loss: 0.6180\n",
      "Epoch 5659/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0145 - val_loss: 0.6047\n",
      "Epoch 5660/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0220 - val_loss: 0.5780\n",
      "Epoch 5661/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0137 - val_loss: 0.6304\n",
      "Epoch 5662/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0250 - val_loss: 0.6234\n",
      "Epoch 5663/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0369 - val_loss: 0.6499\n",
      "Epoch 5664/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0231 - val_loss: 0.6271\n",
      "Epoch 5665/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0215 - val_loss: 0.6325\n",
      "Epoch 5666/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0333 - val_loss: 0.6248\n",
      "Epoch 5667/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0358 - val_loss: 0.6067\n",
      "Epoch 5668/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0251 - val_loss: 0.6246\n",
      "Epoch 5669/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0187 - val_loss: 0.6230\n",
      "Epoch 5670/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0143 - val_loss: 0.6303\n",
      "Epoch 5671/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0160 - val_loss: 0.6329\n",
      "Epoch 5672/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0148 - val_loss: 0.6241\n",
      "Epoch 5673/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0256 - val_loss: 0.6220\n",
      "Epoch 5674/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0169 - val_loss: 0.6087\n",
      "Epoch 5675/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0250 - val_loss: 0.6152\n",
      "Epoch 5676/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0441 - val_loss: 0.6465\n",
      "Epoch 5677/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0401 - val_loss: 0.6470\n",
      "Epoch 5678/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0229 - val_loss: 0.5909\n",
      "Epoch 5679/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0146 - val_loss: 0.6056\n",
      "Epoch 5680/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0114 - val_loss: 0.5960\n",
      "Epoch 5681/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0175 - val_loss: 0.6249\n",
      "Epoch 5682/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0289 - val_loss: 0.6265\n",
      "Epoch 5683/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0157 - val_loss: 0.6306\n",
      "Epoch 5684/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0227 - val_loss: 0.6222\n",
      "Epoch 5685/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0339 - val_loss: 0.6005\n",
      "Epoch 5686/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0160 - val_loss: 0.6032\n",
      "Epoch 5687/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0195 - val_loss: 0.6288\n",
      "Epoch 5688/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0296 - val_loss: 0.6233\n",
      "Epoch 5689/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0306 - val_loss: 0.6459\n",
      "Epoch 5690/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0385 - val_loss: 0.6072\n",
      "Epoch 5691/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0194 - val_loss: 0.6068\n",
      "Epoch 5692/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0146 - val_loss: 0.6330\n",
      "Epoch 5693/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0194 - val_loss: 0.6364\n",
      "Epoch 5694/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0233 - val_loss: 0.6051\n",
      "Epoch 5695/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0248 - val_loss: 0.6154\n",
      "Epoch 5696/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0141 - val_loss: 0.6215\n",
      "Epoch 5697/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0153 - val_loss: 0.6327\n",
      "Epoch 5698/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0235 - val_loss: 0.6063\n",
      "Epoch 5699/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0655 - val_loss: 0.6295\n",
      "Epoch 5700/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0553 - val_loss: 0.6144\n",
      "Epoch 5701/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0199 - val_loss: 0.6410\n",
      "Epoch 5702/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0153 - val_loss: 0.6312\n",
      "Epoch 5703/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 727us/step - loss: 0.0168 - val_loss: 0.6212\n",
      "Epoch 5704/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0138 - val_loss: 0.6383\n",
      "Epoch 5705/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0211 - val_loss: 0.6577\n",
      "Epoch 5706/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0287 - val_loss: 0.6102\n",
      "Epoch 5707/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0342 - val_loss: 0.6418\n",
      "Epoch 5708/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0454 - val_loss: 0.6074\n",
      "Epoch 5709/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0318 - val_loss: 0.6088\n",
      "Epoch 5710/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0220 - val_loss: 0.6217\n",
      "Epoch 5711/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0144 - val_loss: 0.6067\n",
      "Epoch 5712/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0096 - val_loss: 0.6118\n",
      "Epoch 5713/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0148 - val_loss: 0.6042\n",
      "Epoch 5714/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0191 - val_loss: 0.6195\n",
      "Epoch 5715/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0219 - val_loss: 0.6094\n",
      "Epoch 5716/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0268 - val_loss: 0.6425\n",
      "Epoch 5717/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0251 - val_loss: 0.6258\n",
      "Epoch 5718/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0310 - val_loss: 0.6141\n",
      "Epoch 5719/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0428 - val_loss: 0.5963\n",
      "Epoch 5720/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0429 - val_loss: 0.6352\n",
      "Epoch 5721/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0258 - val_loss: 0.6259\n",
      "Epoch 5722/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0208 - val_loss: 0.6037\n",
      "Epoch 5723/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0144 - val_loss: 0.6223\n",
      "Epoch 5724/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0140 - val_loss: 0.6279\n",
      "Epoch 5725/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0108 - val_loss: 0.6038\n",
      "Epoch 5726/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0116 - val_loss: 0.6291\n",
      "Epoch 5727/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0106 - val_loss: 0.5958\n",
      "Epoch 5728/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0130 - val_loss: 0.6229\n",
      "Epoch 5729/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0227 - val_loss: 0.6026\n",
      "Epoch 5730/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0428 - val_loss: 0.6220\n",
      "Epoch 5731/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0575 - val_loss: 0.6195\n",
      "Epoch 5732/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0395 - val_loss: 0.6366\n",
      "Epoch 5733/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0355 - val_loss: 0.6228\n",
      "Epoch 5734/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0280 - val_loss: 0.6378\n",
      "Epoch 5735/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0279 - val_loss: 0.6359\n",
      "Epoch 5736/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0161 - val_loss: 0.6277\n",
      "Epoch 5737/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0178 - val_loss: 0.6353\n",
      "Epoch 5738/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0227 - val_loss: 0.6362\n",
      "Epoch 5739/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0225 - val_loss: 0.5964\n",
      "Epoch 5740/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0124 - val_loss: 0.6187\n",
      "Epoch 5741/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0138 - val_loss: 0.6169\n",
      "Epoch 5742/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0147 - val_loss: 0.6200\n",
      "Epoch 5743/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0146 - val_loss: 0.6258\n",
      "Epoch 5744/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0227 - val_loss: 0.6248\n",
      "Epoch 5745/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0270 - val_loss: 0.6081\n",
      "Epoch 5746/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0304 - val_loss: 0.6351\n",
      "Epoch 5747/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0332 - val_loss: 0.6115\n",
      "Epoch 5748/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0254 - val_loss: 0.6367\n",
      "Epoch 5749/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0174 - val_loss: 0.6064\n",
      "Epoch 5750/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0184 - val_loss: 0.6461\n",
      "Epoch 5751/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0244 - val_loss: 0.6117\n",
      "Epoch 5752/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0243 - val_loss: 0.6425\n",
      "Epoch 5753/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0208 - val_loss: 0.6453\n",
      "Epoch 5754/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0294 - val_loss: 0.6494\n",
      "Epoch 5755/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0381 - val_loss: 0.6235\n",
      "Epoch 5756/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0470 - val_loss: 0.6233\n",
      "Epoch 5757/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0473 - val_loss: 0.6045\n",
      "Epoch 5758/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0304 - val_loss: 0.6173\n",
      "Epoch 5759/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0259 - val_loss: 0.6088\n",
      "Epoch 5760/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0136 - val_loss: 0.6176\n",
      "Epoch 5761/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0113 - val_loss: 0.6221\n",
      "Epoch 5762/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0079 - val_loss: 0.6232\n",
      "Epoch 5763/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0142 - val_loss: 0.6095\n",
      "Epoch 5764/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0340 - val_loss: 0.6507\n",
      "Epoch 5765/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0409 - val_loss: 0.6229\n",
      "Epoch 5766/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0201 - val_loss: 0.6196\n",
      "Epoch 5767/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0158 - val_loss: 0.5997\n",
      "Epoch 5768/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0205 - val_loss: 0.6274\n",
      "Epoch 5769/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0314 - val_loss: 0.6191\n",
      "Epoch 5770/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0353 - val_loss: 0.6286\n",
      "Epoch 5771/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0235 - val_loss: 0.6115\n",
      "Epoch 5772/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0167 - val_loss: 0.6022\n",
      "Epoch 5773/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0227 - val_loss: 0.6275\n",
      "Epoch 5774/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0258 - val_loss: 0.6072\n",
      "Epoch 5775/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0342 - val_loss: 0.5986\n",
      "Epoch 5776/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0266 - val_loss: 0.6002\n",
      "Epoch 5777/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0302 - val_loss: 0.6142\n",
      "Epoch 5778/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0284 - val_loss: 0.6197\n",
      "Epoch 5779/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 734us/step - loss: 0.0221 - val_loss: 0.6101\n",
      "Epoch 5780/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0237 - val_loss: 0.6222\n",
      "Epoch 5781/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0181 - val_loss: 0.6169\n",
      "Epoch 5782/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0167 - val_loss: 0.6210\n",
      "Epoch 5783/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0212 - val_loss: 0.6092\n",
      "Epoch 5784/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0216 - val_loss: 0.6046\n",
      "Epoch 5785/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0151 - val_loss: 0.6046\n",
      "Epoch 5786/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0144 - val_loss: 0.6085\n",
      "Epoch 5787/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0137 - val_loss: 0.6168\n",
      "Epoch 5788/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0202 - val_loss: 0.6263\n",
      "Epoch 5789/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0263 - val_loss: 0.6188\n",
      "Epoch 5790/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0288 - val_loss: 0.6242\n",
      "Epoch 5791/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0358 - val_loss: 0.6216\n",
      "Epoch 5792/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0474 - val_loss: 0.6047\n",
      "Epoch 5793/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0341 - val_loss: 0.6103\n",
      "Epoch 5794/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0278 - val_loss: 0.6144\n",
      "Epoch 5795/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0203 - val_loss: 0.6158\n",
      "Epoch 5796/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0191 - val_loss: 0.6162\n",
      "Epoch 5797/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0140 - val_loss: 0.6191\n",
      "Epoch 5798/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0136 - val_loss: 0.6108\n",
      "Epoch 5799/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0192 - val_loss: 0.5975\n",
      "Epoch 5800/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0295 - val_loss: 0.6132\n",
      "Epoch 5801/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0379 - val_loss: 0.6133\n",
      "Epoch 5802/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0269 - val_loss: 0.6355\n",
      "Epoch 5803/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0143 - val_loss: 0.6143\n",
      "Epoch 5804/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0311 - val_loss: 0.5726\n",
      "Epoch 5805/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0359 - val_loss: 0.6232\n",
      "Epoch 5806/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0355 - val_loss: 0.6436\n",
      "Epoch 5807/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0355 - val_loss: 0.6051\n",
      "Epoch 5808/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0283 - val_loss: 0.6037\n",
      "Epoch 5809/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0202 - val_loss: 0.6174\n",
      "Epoch 5810/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0166 - val_loss: 0.6166\n",
      "Epoch 5811/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0177 - val_loss: 0.6233\n",
      "Epoch 5812/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0162 - val_loss: 0.6165\n",
      "Epoch 5813/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0116 - val_loss: 0.6112\n",
      "Epoch 5814/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0121 - val_loss: 0.6025\n",
      "Epoch 5815/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0155 - val_loss: 0.6068\n",
      "Epoch 5816/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0325 - val_loss: 0.6299\n",
      "Epoch 5817/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0526 - val_loss: 0.6010\n",
      "Epoch 5818/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0438 - val_loss: 0.6493\n",
      "Epoch 5819/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0303 - val_loss: 0.6142\n",
      "Epoch 5820/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0216 - val_loss: 0.6254\n",
      "Epoch 5821/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0169 - val_loss: 0.6119\n",
      "Epoch 5822/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0201 - val_loss: 0.6197\n",
      "Epoch 5823/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0199 - val_loss: 0.6186\n",
      "Epoch 5824/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0179 - val_loss: 0.6097\n",
      "Epoch 5825/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0133 - val_loss: 0.6289\n",
      "Epoch 5826/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0203 - val_loss: 0.6090\n",
      "Epoch 5827/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0242 - val_loss: 0.6146\n",
      "Epoch 5828/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0189 - val_loss: 0.6011\n",
      "Epoch 5829/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0228 - val_loss: 0.6522\n",
      "Epoch 5830/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0248 - val_loss: 0.6570\n",
      "Epoch 5831/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0248 - val_loss: 0.6251\n",
      "Epoch 5832/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0496 - val_loss: 0.6508\n",
      "Epoch 5833/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0348 - val_loss: 0.6273\n",
      "Epoch 5834/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0151 - val_loss: 0.6251\n",
      "Epoch 5835/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0182 - val_loss: 0.5984\n",
      "Epoch 5836/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0174 - val_loss: 0.6053\n",
      "Epoch 5837/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0165 - val_loss: 0.6047\n",
      "Epoch 5838/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0591 - val_loss: 0.6435\n",
      "Epoch 5839/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0464 - val_loss: 0.6074\n",
      "Epoch 5840/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0257 - val_loss: 0.6350\n",
      "Epoch 5841/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0269 - val_loss: 0.5723\n",
      "Epoch 5842/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0183 - val_loss: 0.6270\n",
      "Epoch 5843/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0135 - val_loss: 0.6224\n",
      "Epoch 5844/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0133 - val_loss: 0.6258\n",
      "Epoch 5845/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0097 - val_loss: 0.6515\n",
      "Epoch 5846/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0136 - val_loss: 0.6275\n",
      "Epoch 5847/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0182 - val_loss: 0.5882\n",
      "Epoch 5848/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0148 - val_loss: 0.6276\n",
      "Epoch 5849/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0254 - val_loss: 0.6396\n",
      "Epoch 5850/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0368 - val_loss: 0.6048\n",
      "Epoch 5851/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0435 - val_loss: 0.6222\n",
      "Epoch 5852/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0380 - val_loss: 0.5780\n",
      "Epoch 5853/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0266 - val_loss: 0.6292\n",
      "Epoch 5854/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0452 - val_loss: 0.6213\n",
      "Epoch 5855/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 744us/step - loss: 0.0263 - val_loss: 0.6202\n",
      "Epoch 5856/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0241 - val_loss: 0.6067\n",
      "Epoch 5857/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0175 - val_loss: 0.5876\n",
      "Epoch 5858/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0205 - val_loss: 0.6079\n",
      "Epoch 5859/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0172 - val_loss: 0.6108\n",
      "Epoch 5860/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0158 - val_loss: 0.6314\n",
      "Epoch 5861/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0111 - val_loss: 0.6271\n",
      "Epoch 5862/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0131 - val_loss: 0.6157\n",
      "Epoch 5863/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0105 - val_loss: 0.6228\n",
      "Epoch 5864/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0095 - val_loss: 0.6175\n",
      "Epoch 5865/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0127 - val_loss: 0.6195\n",
      "Epoch 5866/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0348 - val_loss: 0.6127\n",
      "Epoch 5867/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0833 - val_loss: 0.6297\n",
      "Epoch 5868/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0390 - val_loss: 0.6294\n",
      "Epoch 5869/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0234 - val_loss: 0.6024\n",
      "Epoch 5870/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0263 - val_loss: 0.6498\n",
      "Epoch 5871/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0209 - val_loss: 0.6057\n",
      "Epoch 5872/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0202 - val_loss: 0.6544\n",
      "Epoch 5873/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0161 - val_loss: 0.6103\n",
      "Epoch 5874/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0139 - val_loss: 0.6441\n",
      "Epoch 5875/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0150 - val_loss: 0.6388\n",
      "Epoch 5876/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0347 - val_loss: 0.6396\n",
      "Epoch 5877/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0633 - val_loss: 0.6341\n",
      "Epoch 5878/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0442 - val_loss: 0.6352\n",
      "Epoch 5879/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0189 - val_loss: 0.6131\n",
      "Epoch 5880/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0233 - val_loss: 0.6454\n",
      "Epoch 5881/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0170 - val_loss: 0.6293\n",
      "Epoch 5882/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0230 - val_loss: 0.6639\n",
      "Epoch 5883/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0347 - val_loss: 0.6440\n",
      "Epoch 5884/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0160 - val_loss: 0.6294\n",
      "Epoch 5885/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0147 - val_loss: 0.6214\n",
      "Epoch 5886/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0130 - val_loss: 0.6380\n",
      "Epoch 5887/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0152 - val_loss: 0.5979\n",
      "Epoch 5888/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0204 - val_loss: 0.6323\n",
      "Epoch 5889/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0209 - val_loss: 0.6375\n",
      "Epoch 5890/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0171 - val_loss: 0.6390\n",
      "Epoch 5891/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0137 - val_loss: 0.6370\n",
      "Epoch 5892/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0291 - val_loss: 0.6083\n",
      "Epoch 5893/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0759 - val_loss: 0.6512\n",
      "Epoch 5894/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0533 - val_loss: 0.5898\n",
      "Epoch 5895/10000\n",
      "130/130 [==============================] - 0s 835us/step - loss: 0.0250 - val_loss: 0.6342\n",
      "Epoch 5896/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0168 - val_loss: 0.5948\n",
      "Epoch 5897/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0143 - val_loss: 0.6147\n",
      "Epoch 5898/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0147 - val_loss: 0.6127\n",
      "Epoch 5899/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0115 - val_loss: 0.5970\n",
      "Epoch 5900/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0216 - val_loss: 0.6294\n",
      "Epoch 5901/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0293 - val_loss: 0.6049\n",
      "Epoch 5902/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0409 - val_loss: 0.6250\n",
      "Epoch 5903/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0414 - val_loss: 0.6401\n",
      "Epoch 5904/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0240 - val_loss: 0.5988\n",
      "Epoch 5905/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0206 - val_loss: 0.6220\n",
      "Epoch 5906/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0154 - val_loss: 0.6139\n",
      "Epoch 5907/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0146 - val_loss: 0.6167\n",
      "Epoch 5908/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0105 - val_loss: 0.6031\n",
      "Epoch 5909/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0133 - val_loss: 0.6102\n",
      "Epoch 5910/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0209 - val_loss: 0.6182\n",
      "Epoch 5911/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0334 - val_loss: 0.5923\n",
      "Epoch 5912/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0264 - val_loss: 0.6291\n",
      "Epoch 5913/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0274 - val_loss: 0.6029\n",
      "Epoch 5914/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0149 - val_loss: 0.5925\n",
      "Epoch 5915/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0136 - val_loss: 0.6115\n",
      "Epoch 5916/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0251 - val_loss: 0.5885\n",
      "Epoch 5917/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0259 - val_loss: 0.6312\n",
      "Epoch 5918/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0298 - val_loss: 0.6500\n",
      "Epoch 5919/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0301 - val_loss: 0.6212\n",
      "Epoch 5920/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0275 - val_loss: 0.6152\n",
      "Epoch 5921/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0249 - val_loss: 0.5875\n",
      "Epoch 5922/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0266 - val_loss: 0.6025\n",
      "Epoch 5923/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0301 - val_loss: 0.5987\n",
      "Epoch 5924/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0146 - val_loss: 0.6154\n",
      "Epoch 5925/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0145 - val_loss: 0.6282\n",
      "Epoch 5926/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0271 - val_loss: 0.5900\n",
      "Epoch 5927/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0255 - val_loss: 0.5907\n",
      "Epoch 5928/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0214 - val_loss: 0.6030\n",
      "Epoch 5929/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0529 - val_loss: 0.6320\n",
      "Epoch 5930/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0313 - val_loss: 0.6083\n",
      "Epoch 5931/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 754us/step - loss: 0.0177 - val_loss: 0.5951\n",
      "Epoch 5932/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0288 - val_loss: 0.6134\n",
      "Epoch 5933/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0175 - val_loss: 0.6141\n",
      "Epoch 5934/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0202 - val_loss: 0.6286\n",
      "Epoch 5935/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0190 - val_loss: 0.6184\n",
      "Epoch 5936/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0240 - val_loss: 0.6303\n",
      "Epoch 5937/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0305 - val_loss: 0.6120\n",
      "Epoch 5938/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0500 - val_loss: 0.5984\n",
      "Epoch 5939/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0412 - val_loss: 0.6188\n",
      "Epoch 5940/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0170 - val_loss: 0.6050\n",
      "Epoch 5941/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0113 - val_loss: 0.6112\n",
      "Epoch 5942/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0121 - val_loss: 0.6079\n",
      "Epoch 5943/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0245 - val_loss: 0.6401\n",
      "Epoch 5944/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0368 - val_loss: 0.6069\n",
      "Epoch 5945/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0328 - val_loss: 0.6141\n",
      "Epoch 5946/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0247 - val_loss: 0.6064\n",
      "Epoch 5947/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0289 - val_loss: 0.6135\n",
      "Epoch 5948/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0345 - val_loss: 0.5980\n",
      "Epoch 5949/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0208 - val_loss: 0.6193\n",
      "Epoch 5950/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0165 - val_loss: 0.6093\n",
      "Epoch 5951/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0147 - val_loss: 0.5953\n",
      "Epoch 5952/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0108 - val_loss: 0.5954\n",
      "Epoch 5953/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0098 - val_loss: 0.6097\n",
      "Epoch 5954/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0148 - val_loss: 0.5985\n",
      "Epoch 5955/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0358 - val_loss: 0.6396\n",
      "Epoch 5956/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0461 - val_loss: 0.6063\n",
      "Epoch 5957/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0634 - val_loss: 0.6350\n",
      "Epoch 5958/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0238 - val_loss: 0.6270\n",
      "Epoch 5959/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0235 - val_loss: 0.6233\n",
      "Epoch 5960/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0229 - val_loss: 0.6226\n",
      "Epoch 5961/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0169 - val_loss: 0.6021\n",
      "Epoch 5962/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0120 - val_loss: 0.5949\n",
      "Epoch 5963/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0089 - val_loss: 0.5991\n",
      "Epoch 5964/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0092 - val_loss: 0.6133\n",
      "Epoch 5965/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0103 - val_loss: 0.6097\n",
      "Epoch 5966/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0211 - val_loss: 0.6198\n",
      "Epoch 5967/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0410 - val_loss: 0.6353\n",
      "Epoch 5968/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.1081 - val_loss: 0.6130\n",
      "Epoch 5969/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0870 - val_loss: 0.5804\n",
      "Epoch 5970/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0466 - val_loss: 0.6160\n",
      "Epoch 5971/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0192 - val_loss: 0.5976\n",
      "Epoch 5972/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0133 - val_loss: 0.6059\n",
      "Epoch 5973/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0108 - val_loss: 0.6070\n",
      "Epoch 5974/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0176 - val_loss: 0.6165\n",
      "Epoch 5975/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0135 - val_loss: 0.5904\n",
      "Epoch 5976/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0111 - val_loss: 0.6004\n",
      "Epoch 5977/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0179 - val_loss: 0.6046\n",
      "Epoch 5978/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0290 - val_loss: 0.6112\n",
      "Epoch 5979/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0273 - val_loss: 0.6012\n",
      "Epoch 5980/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0136 - val_loss: 0.6167\n",
      "Epoch 5981/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0152 - val_loss: 0.6246\n",
      "Epoch 5982/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0490 - val_loss: 0.6232\n",
      "Epoch 5983/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0304 - val_loss: 0.6060\n",
      "Epoch 5984/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0159 - val_loss: 0.6205\n",
      "Epoch 5985/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0126 - val_loss: 0.6193\n",
      "Epoch 5986/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0111 - val_loss: 0.6207\n",
      "Epoch 5987/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0106 - val_loss: 0.6201\n",
      "Epoch 5988/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0222 - val_loss: 0.5986\n",
      "Epoch 5989/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0327 - val_loss: 0.6255\n",
      "Epoch 5990/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0363 - val_loss: 0.6263\n",
      "Epoch 5991/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0524 - val_loss: 0.6216\n",
      "Epoch 5992/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0444 - val_loss: 0.6276\n",
      "Epoch 5993/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0310 - val_loss: 0.6152\n",
      "Epoch 5994/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0158 - val_loss: 0.6047\n",
      "Epoch 5995/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0146 - val_loss: 0.6177\n",
      "Epoch 5996/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0117 - val_loss: 0.6057\n",
      "Epoch 5997/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0134 - val_loss: 0.6060\n",
      "Epoch 5998/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0191 - val_loss: 0.6242\n",
      "Epoch 5999/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0362 - val_loss: 0.6022\n",
      "Epoch 6000/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0356 - val_loss: 0.6159\n",
      "Epoch 6001/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0269 - val_loss: 0.6151\n",
      "Epoch 6002/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0209 - val_loss: 0.5812\n",
      "Epoch 6003/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0234 - val_loss: 0.6058\n",
      "Epoch 6004/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0333 - val_loss: 0.6506\n",
      "Epoch 6005/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0177 - val_loss: 0.6261\n",
      "Epoch 6006/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0231 - val_loss: 0.6118\n",
      "Epoch 6007/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 755us/step - loss: 0.0219 - val_loss: 0.6166\n",
      "Epoch 6008/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0229 - val_loss: 0.6176\n",
      "Epoch 6009/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0266 - val_loss: 0.6100\n",
      "Epoch 6010/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0229 - val_loss: 0.6266\n",
      "Epoch 6011/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0218 - val_loss: 0.6490\n",
      "Epoch 6012/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0255 - val_loss: 0.6080\n",
      "Epoch 6013/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0243 - val_loss: 0.6159\n",
      "Epoch 6014/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0256 - val_loss: 0.6184\n",
      "Epoch 6015/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0386 - val_loss: 0.6337\n",
      "Epoch 6016/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0402 - val_loss: 0.6284\n",
      "Epoch 6017/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0308 - val_loss: 0.6227\n",
      "Epoch 6018/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0311 - val_loss: 0.6102\n",
      "Epoch 6019/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0257 - val_loss: 0.6413\n",
      "Epoch 6020/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0261 - val_loss: 0.6097\n",
      "Epoch 6021/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0140 - val_loss: 0.6083\n",
      "Epoch 6022/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0093 - val_loss: 0.6015\n",
      "Epoch 6023/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0132 - val_loss: 0.5950\n",
      "Epoch 6024/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0161 - val_loss: 0.6126\n",
      "Epoch 6025/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0183 - val_loss: 0.5863\n",
      "Epoch 6026/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0332 - val_loss: 0.6125\n",
      "Epoch 6027/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0326 - val_loss: 0.6031\n",
      "Epoch 6028/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0345 - val_loss: 0.6261\n",
      "Epoch 6029/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0354 - val_loss: 0.6315\n",
      "Epoch 6030/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0195 - val_loss: 0.6279\n",
      "Epoch 6031/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0195 - val_loss: 0.6173\n",
      "Epoch 6032/10000\n",
      "130/130 [==============================] - 0s 796us/step - loss: 0.0177 - val_loss: 0.6187\n",
      "Epoch 6033/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0132 - val_loss: 0.6304\n",
      "Epoch 6034/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0208 - val_loss: 0.6261\n",
      "Epoch 6035/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0247 - val_loss: 0.6179\n",
      "Epoch 6036/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0540 - val_loss: 0.6505\n",
      "Epoch 6037/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0513 - val_loss: 0.6218\n",
      "Epoch 6038/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0240 - val_loss: 0.6133\n",
      "Epoch 6039/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0205 - val_loss: 0.6007\n",
      "Epoch 6040/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0232 - val_loss: 0.6143\n",
      "Epoch 6041/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0339 - val_loss: 0.6248\n",
      "Epoch 6042/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0334 - val_loss: 0.6187\n",
      "Epoch 6043/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0130 - val_loss: 0.6128\n",
      "Epoch 6044/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0169 - val_loss: 0.6197\n",
      "Epoch 6045/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0168 - val_loss: 0.6176\n",
      "Epoch 6046/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0142 - val_loss: 0.6020\n",
      "Epoch 6047/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0361 - val_loss: 0.6169\n",
      "Epoch 6048/10000\n",
      "130/130 [==============================] - 0s 819us/step - loss: 0.0235 - val_loss: 0.5977\n",
      "Epoch 6049/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0184 - val_loss: 0.6234\n",
      "Epoch 6050/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0203 - val_loss: 0.5994\n",
      "Epoch 6051/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0304 - val_loss: 0.6323\n",
      "Epoch 6052/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0241 - val_loss: 0.6275\n",
      "Epoch 6053/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0452 - val_loss: 0.6289\n",
      "Epoch 6054/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0287 - val_loss: 0.6355\n",
      "Epoch 6055/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0400 - val_loss: 0.6508\n",
      "Epoch 6056/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0263 - val_loss: 0.6116\n",
      "Epoch 6057/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0178 - val_loss: 0.5978\n",
      "Epoch 6058/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0146 - val_loss: 0.6495\n",
      "Epoch 6059/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0138 - val_loss: 0.6185\n",
      "Epoch 6060/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0118 - val_loss: 0.6075\n",
      "Epoch 6061/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0090 - val_loss: 0.5923\n",
      "Epoch 6062/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0135 - val_loss: 0.5931\n",
      "Epoch 6063/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0141 - val_loss: 0.6118\n",
      "Epoch 6064/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0209 - val_loss: 0.6350\n",
      "Epoch 6065/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0728 - val_loss: 0.6204\n",
      "Epoch 6066/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0418 - val_loss: 0.6069\n",
      "Epoch 6067/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0223 - val_loss: 0.6145\n",
      "Epoch 6068/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0189 - val_loss: 0.6350\n",
      "Epoch 6069/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0147 - val_loss: 0.6465\n",
      "Epoch 6070/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0282 - val_loss: 0.5971\n",
      "Epoch 6071/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0340 - val_loss: 0.6096\n",
      "Epoch 6072/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0295 - val_loss: 0.6019\n",
      "Epoch 6073/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0216 - val_loss: 0.5919\n",
      "Epoch 6074/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0130 - val_loss: 0.6044\n",
      "Epoch 6075/10000\n",
      "130/130 [==============================] - 0s 853us/step - loss: 0.0104 - val_loss: 0.5984\n",
      "Epoch 6076/10000\n",
      "130/130 [==============================] - 0s 805us/step - loss: 0.0104 - val_loss: 0.5913\n",
      "Epoch 6077/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0294 - val_loss: 0.6123\n",
      "Epoch 6078/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0480 - val_loss: 0.6313\n",
      "Epoch 6079/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0299 - val_loss: 0.5972\n",
      "Epoch 6080/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0192 - val_loss: 0.6051\n",
      "Epoch 6081/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0164 - val_loss: 0.6077\n",
      "Epoch 6082/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0177 - val_loss: 0.6042\n",
      "Epoch 6083/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 749us/step - loss: 0.0309 - val_loss: 0.6150\n",
      "Epoch 6084/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0213 - val_loss: 0.6012\n",
      "Epoch 6085/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0151 - val_loss: 0.6174\n",
      "Epoch 6086/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0175 - val_loss: 0.6095\n",
      "Epoch 6087/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0157 - val_loss: 0.6191\n",
      "Epoch 6088/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0263 - val_loss: 0.6029\n",
      "Epoch 6089/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0221 - val_loss: 0.6324\n",
      "Epoch 6090/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0423 - val_loss: 0.6157\n",
      "Epoch 6091/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0453 - val_loss: 0.6423\n",
      "Epoch 6092/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0622 - val_loss: 0.5978\n",
      "Epoch 6093/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0235 - val_loss: 0.6118\n",
      "Epoch 6094/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0146 - val_loss: 0.6129\n",
      "Epoch 6095/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0159 - val_loss: 0.6250\n",
      "Epoch 6096/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0150 - val_loss: 0.5936\n",
      "Epoch 6097/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0156 - val_loss: 0.5932\n",
      "Epoch 6098/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0225 - val_loss: 0.6201\n",
      "Epoch 6099/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0286 - val_loss: 0.5984\n",
      "Epoch 6100/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0231 - val_loss: 0.5952\n",
      "Epoch 6101/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0134 - val_loss: 0.6024\n",
      "Epoch 6102/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0213 - val_loss: 0.6265\n",
      "Epoch 6103/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0410 - val_loss: 0.6104\n",
      "Epoch 6104/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0297 - val_loss: 0.6123\n",
      "Epoch 6105/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0258 - val_loss: 0.6034\n",
      "Epoch 6106/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0158 - val_loss: 0.6268\n",
      "Epoch 6107/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0168 - val_loss: 0.6365\n",
      "Epoch 6108/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0209 - val_loss: 0.6081\n",
      "Epoch 6109/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0328 - val_loss: 0.6174\n",
      "Epoch 6110/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0365 - val_loss: 0.6016\n",
      "Epoch 6111/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0230 - val_loss: 0.6131\n",
      "Epoch 6112/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0195 - val_loss: 0.6136\n",
      "Epoch 6113/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0293 - val_loss: 0.5914\n",
      "Epoch 6114/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0306 - val_loss: 0.6263\n",
      "Epoch 6115/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0201 - val_loss: 0.6130\n",
      "Epoch 6116/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0178 - val_loss: 0.6472\n",
      "Epoch 6117/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0116 - val_loss: 0.6454\n",
      "Epoch 6118/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0176 - val_loss: 0.6072\n",
      "Epoch 6119/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0229 - val_loss: 0.6080\n",
      "Epoch 6120/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0277 - val_loss: 0.6301\n",
      "Epoch 6121/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0277 - val_loss: 0.6078\n",
      "Epoch 6122/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0190 - val_loss: 0.6269\n",
      "Epoch 6123/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0250 - val_loss: 0.6199\n",
      "Epoch 6124/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0295 - val_loss: 0.6216\n",
      "Epoch 6125/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0354 - val_loss: 0.6205\n",
      "Epoch 6126/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0335 - val_loss: 0.6123\n",
      "Epoch 6127/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0177 - val_loss: 0.6370\n",
      "Epoch 6128/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0223 - val_loss: 0.5954\n",
      "Epoch 6129/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0261 - val_loss: 0.6395\n",
      "Epoch 6130/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0284 - val_loss: 0.6215\n",
      "Epoch 6131/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0274 - val_loss: 0.6171\n",
      "Epoch 6132/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0237 - val_loss: 0.6155\n",
      "Epoch 6133/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0163 - val_loss: 0.6202\n",
      "Epoch 6134/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0118 - val_loss: 0.6469\n",
      "Epoch 6135/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0107 - val_loss: 0.6066\n",
      "Epoch 6136/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0149 - val_loss: 0.6367\n",
      "Epoch 6137/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0256 - val_loss: 0.6337\n",
      "Epoch 6138/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0567 - val_loss: 0.6410\n",
      "Epoch 6139/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0727 - val_loss: 0.6681\n",
      "Epoch 6140/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0652 - val_loss: 0.6416\n",
      "Epoch 6141/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0411 - val_loss: 0.6103\n",
      "Epoch 6142/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0273 - val_loss: 0.6207\n",
      "Epoch 6143/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0164 - val_loss: 0.6045\n",
      "Epoch 6144/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0157 - val_loss: 0.5908\n",
      "Epoch 6145/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0184 - val_loss: 0.6109\n",
      "Epoch 6146/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0121 - val_loss: 0.6011\n",
      "Epoch 6147/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0118 - val_loss: 0.6042\n",
      "Epoch 6148/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0117 - val_loss: 0.5959\n",
      "Epoch 6149/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0185 - val_loss: 0.6111\n",
      "Epoch 6150/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0217 - val_loss: 0.6042\n",
      "Epoch 6151/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0278 - val_loss: 0.6196\n",
      "Epoch 6152/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0437 - val_loss: 0.6450\n",
      "Epoch 6153/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0312 - val_loss: 0.6119\n",
      "Epoch 6154/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0279 - val_loss: 0.6103\n",
      "Epoch 6155/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0189 - val_loss: 0.6126\n",
      "Epoch 6156/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0163 - val_loss: 0.6123\n",
      "Epoch 6157/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0218 - val_loss: 0.6172\n",
      "Epoch 6158/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0182 - val_loss: 0.6079\n",
      "Epoch 6159/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 759us/step - loss: 0.0224 - val_loss: 0.6388\n",
      "Epoch 6160/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0286 - val_loss: 0.6237\n",
      "Epoch 6161/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0320 - val_loss: 0.5791\n",
      "Epoch 6162/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0168 - val_loss: 0.6139\n",
      "Epoch 6163/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0093 - val_loss: 0.5990\n",
      "Epoch 6164/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0104 - val_loss: 0.6176\n",
      "Epoch 6165/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0126 - val_loss: 0.6522\n",
      "Epoch 6166/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0240 - val_loss: 0.5924\n",
      "Epoch 6167/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0618 - val_loss: 0.6897\n",
      "Epoch 6168/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0798 - val_loss: 0.6277\n",
      "Epoch 6169/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0332 - val_loss: 0.5950\n",
      "Epoch 6170/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0210 - val_loss: 0.6156\n",
      "Epoch 6171/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0198 - val_loss: 0.6203\n",
      "Epoch 6172/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0209 - val_loss: 0.6185\n",
      "Epoch 6173/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0155 - val_loss: 0.6175\n",
      "Epoch 6174/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0162 - val_loss: 0.5978\n",
      "Epoch 6175/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0202 - val_loss: 0.6044\n",
      "Epoch 6176/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0201 - val_loss: 0.5908\n",
      "Epoch 6177/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0235 - val_loss: 0.6095\n",
      "Epoch 6178/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0175 - val_loss: 0.6063\n",
      "Epoch 6179/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0148 - val_loss: 0.6071\n",
      "Epoch 6180/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0187 - val_loss: 0.6506\n",
      "Epoch 6181/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0163 - val_loss: 0.6102\n",
      "Epoch 6182/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0146 - val_loss: 0.6117\n",
      "Epoch 6183/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0340 - val_loss: 0.5858\n",
      "Epoch 6184/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0444 - val_loss: 0.6070\n",
      "Epoch 6185/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0495 - val_loss: 0.6348\n",
      "Epoch 6186/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0586 - val_loss: 0.6098\n",
      "Epoch 6187/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0360 - val_loss: 0.5951\n",
      "Epoch 6188/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0267 - val_loss: 0.5866\n",
      "Epoch 6189/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0307 - val_loss: 0.6140\n",
      "Epoch 6190/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0239 - val_loss: 0.6182\n",
      "Epoch 6191/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0154 - val_loss: 0.6358\n",
      "Epoch 6192/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0214 - val_loss: 0.6056\n",
      "Epoch 6193/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0292 - val_loss: 0.6489\n",
      "Epoch 6194/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0235 - val_loss: 0.6155\n",
      "Epoch 6195/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0300 - val_loss: 0.5948\n",
      "Epoch 6196/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0247 - val_loss: 0.6067\n",
      "Epoch 6197/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0277 - val_loss: 0.5914\n",
      "Epoch 6198/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0205 - val_loss: 0.6196\n",
      "Epoch 6199/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0187 - val_loss: 0.6088\n",
      "Epoch 6200/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0222 - val_loss: 0.6164\n",
      "Epoch 6201/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0155 - val_loss: 0.6065\n",
      "Epoch 6202/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0142 - val_loss: 0.6171\n",
      "Epoch 6203/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0147 - val_loss: 0.6188\n",
      "Epoch 6204/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0354 - val_loss: 0.6245\n",
      "Epoch 6205/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0190 - val_loss: 0.6224\n",
      "Epoch 6206/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0155 - val_loss: 0.5937\n",
      "Epoch 6207/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0293 - val_loss: 0.6314\n",
      "Epoch 6208/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0391 - val_loss: 0.6153\n",
      "Epoch 6209/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0412 - val_loss: 0.6268\n",
      "Epoch 6210/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0277 - val_loss: 0.6053\n",
      "Epoch 6211/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0294 - val_loss: 0.6267\n",
      "Epoch 6212/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0231 - val_loss: 0.5981\n",
      "Epoch 6213/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0294 - val_loss: 0.5881\n",
      "Epoch 6214/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0203 - val_loss: 0.5989\n",
      "Epoch 6215/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0159 - val_loss: 0.6100\n",
      "Epoch 6216/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0227 - val_loss: 0.6213\n",
      "Epoch 6217/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0141 - val_loss: 0.6092\n",
      "Epoch 6218/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0112 - val_loss: 0.6181\n",
      "Epoch 6219/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0154 - val_loss: 0.5942\n",
      "Epoch 6220/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0233 - val_loss: 0.6279\n",
      "Epoch 6221/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0424 - val_loss: 0.6211\n",
      "Epoch 6222/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0234 - val_loss: 0.6418\n",
      "Epoch 6223/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0244 - val_loss: 0.6127\n",
      "Epoch 6224/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0285 - val_loss: 0.6066\n",
      "Epoch 6225/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0210 - val_loss: 0.6237\n",
      "Epoch 6226/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0156 - val_loss: 0.6137\n",
      "Epoch 6227/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0224 - val_loss: 0.6214\n",
      "Epoch 6228/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0293 - val_loss: 0.6124\n",
      "Epoch 6229/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0319 - val_loss: 0.5899\n",
      "Epoch 6230/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0623 - val_loss: 0.6482\n",
      "Epoch 6231/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0211 - val_loss: 0.5924\n",
      "Epoch 6232/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0191 - val_loss: 0.6245\n",
      "Epoch 6233/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0211 - val_loss: 0.6128\n",
      "Epoch 6234/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0201 - val_loss: 0.6395\n",
      "Epoch 6235/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 749us/step - loss: 0.0174 - val_loss: 0.6177\n",
      "Epoch 6236/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0260 - val_loss: 0.6250\n",
      "Epoch 6237/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0360 - val_loss: 0.6238\n",
      "Epoch 6238/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0175 - val_loss: 0.6213\n",
      "Epoch 6239/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0139 - val_loss: 0.6293\n",
      "Epoch 6240/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0131 - val_loss: 0.5970\n",
      "Epoch 6241/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0118 - val_loss: 0.6183\n",
      "Epoch 6242/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0138 - val_loss: 0.6159\n",
      "Epoch 6243/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0207 - val_loss: 0.6256\n",
      "Epoch 6244/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0164 - val_loss: 0.6186\n",
      "Epoch 6245/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0379 - val_loss: 0.6076\n",
      "Epoch 6246/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0255 - val_loss: 0.6162\n",
      "Epoch 6247/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0221 - val_loss: 0.6095\n",
      "Epoch 6248/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0440 - val_loss: 0.6264\n",
      "Epoch 6249/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0416 - val_loss: 0.6355\n",
      "Epoch 6250/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0274 - val_loss: 0.6134\n",
      "Epoch 6251/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0318 - val_loss: 0.6591\n",
      "Epoch 6252/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0241 - val_loss: 0.6050\n",
      "Epoch 6253/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0174 - val_loss: 0.6382\n",
      "Epoch 6254/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0250 - val_loss: 0.6082\n",
      "Epoch 6255/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0344 - val_loss: 0.6335\n",
      "Epoch 6256/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0265 - val_loss: 0.6248\n",
      "Epoch 6257/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0379 - val_loss: 0.5781\n",
      "Epoch 6258/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0205 - val_loss: 0.6089\n",
      "Epoch 6259/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0194 - val_loss: 0.5870\n",
      "Epoch 6260/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0221 - val_loss: 0.6489\n",
      "Epoch 6261/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0231 - val_loss: 0.6278\n",
      "Epoch 6262/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0268 - val_loss: 0.6339\n",
      "Epoch 6263/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0183 - val_loss: 0.6241\n",
      "Epoch 6264/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0122 - val_loss: 0.6115\n",
      "Epoch 6265/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0163 - val_loss: 0.6237\n",
      "Epoch 6266/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0252 - val_loss: 0.6207\n",
      "Epoch 6267/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0274 - val_loss: 0.6306\n",
      "Epoch 6268/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0219 - val_loss: 0.6239\n",
      "Epoch 6269/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0223 - val_loss: 0.6265\n",
      "Epoch 6270/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0439 - val_loss: 0.5979\n",
      "Epoch 6271/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0354 - val_loss: 0.6782\n",
      "Epoch 6272/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0604 - val_loss: 0.6406\n",
      "Epoch 6273/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0176 - val_loss: 0.5998\n",
      "Epoch 6274/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0151 - val_loss: 0.5988\n",
      "Epoch 6275/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0182 - val_loss: 0.6073\n",
      "Epoch 6276/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0148 - val_loss: 0.6097\n",
      "Epoch 6277/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0273 - val_loss: 0.6157\n",
      "Epoch 6278/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0275 - val_loss: 0.6052\n",
      "Epoch 6279/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0305 - val_loss: 0.6221\n",
      "Epoch 6280/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0225 - val_loss: 0.6373\n",
      "Epoch 6281/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0228 - val_loss: 0.6268\n",
      "Epoch 6282/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0214 - val_loss: 0.6117\n",
      "Epoch 6283/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0249 - val_loss: 0.6312\n",
      "Epoch 6284/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0260 - val_loss: 0.6044\n",
      "Epoch 6285/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0179 - val_loss: 0.6152\n",
      "Epoch 6286/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0192 - val_loss: 0.6116\n",
      "Epoch 6287/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0150 - val_loss: 0.6093\n",
      "Epoch 6288/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0149 - val_loss: 0.6178\n",
      "Epoch 6289/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0173 - val_loss: 0.6124\n",
      "Epoch 6290/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0371 - val_loss: 0.6018\n",
      "Epoch 6291/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0324 - val_loss: 0.6109\n",
      "Epoch 6292/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0216 - val_loss: 0.6200\n",
      "Epoch 6293/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0205 - val_loss: 0.6218\n",
      "Epoch 6294/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0124 - val_loss: 0.6102\n",
      "Epoch 6295/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0150 - val_loss: 0.6057\n",
      "Epoch 6296/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0252 - val_loss: 0.5998\n",
      "Epoch 6297/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0287 - val_loss: 0.6371\n",
      "Epoch 6298/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0321 - val_loss: 0.6427\n",
      "Epoch 6299/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0329 - val_loss: 0.6102\n",
      "Epoch 6300/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0160 - val_loss: 0.6097\n",
      "Epoch 6301/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0173 - val_loss: 0.6348\n",
      "Epoch 6302/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0272 - val_loss: 0.6216\n",
      "Epoch 6303/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0643 - val_loss: 0.6046\n",
      "Epoch 6304/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0298 - val_loss: 0.5864\n",
      "Epoch 6305/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0258 - val_loss: 0.6175\n",
      "Epoch 6306/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0153 - val_loss: 0.5942\n",
      "Epoch 6307/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0248 - val_loss: 0.5494\n",
      "Epoch 6308/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0270 - val_loss: 0.5865\n",
      "Epoch 6309/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0372 - val_loss: 0.6385\n",
      "Epoch 6310/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0268 - val_loss: 0.6078\n",
      "Epoch 6311/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 747us/step - loss: 0.0165 - val_loss: 0.6043\n",
      "Epoch 6312/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0111 - val_loss: 0.6027\n",
      "Epoch 6313/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0118 - val_loss: 0.6254\n",
      "Epoch 6314/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0150 - val_loss: 0.6326\n",
      "Epoch 6315/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0310 - val_loss: 0.5957\n",
      "Epoch 6316/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0234 - val_loss: 0.6571\n",
      "Epoch 6317/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0327 - val_loss: 0.6016\n",
      "Epoch 6318/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0211 - val_loss: 0.5856\n",
      "Epoch 6319/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0295 - val_loss: 0.6300\n",
      "Epoch 6320/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0440 - val_loss: 0.6346\n",
      "Epoch 6321/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0327 - val_loss: 0.6364\n",
      "Epoch 6322/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0167 - val_loss: 0.6245\n",
      "Epoch 6323/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0125 - val_loss: 0.6250\n",
      "Epoch 6324/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0216 - val_loss: 0.6454\n",
      "Epoch 6325/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0225 - val_loss: 0.6255\n",
      "Epoch 6326/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0232 - val_loss: 0.6231\n",
      "Epoch 6327/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0178 - val_loss: 0.6469\n",
      "Epoch 6328/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0352 - val_loss: 0.6470\n",
      "Epoch 6329/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0628 - val_loss: 0.6066\n",
      "Epoch 6330/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0484 - val_loss: 0.6279\n",
      "Epoch 6331/10000\n",
      "130/130 [==============================] - 0s 819us/step - loss: 0.0198 - val_loss: 0.6090\n",
      "Epoch 6332/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0135 - val_loss: 0.6126\n",
      "Epoch 6333/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0164 - val_loss: 0.6130\n",
      "Epoch 6334/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0209 - val_loss: 0.6206\n",
      "Epoch 6335/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0275 - val_loss: 0.6194\n",
      "Epoch 6336/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0232 - val_loss: 0.6054\n",
      "Epoch 6337/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0129 - val_loss: 0.6142\n",
      "Epoch 6338/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0103 - val_loss: 0.6365\n",
      "Epoch 6339/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0099 - val_loss: 0.6330\n",
      "Epoch 6340/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0225 - val_loss: 0.6026\n",
      "Epoch 6341/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0351 - val_loss: 0.6340\n",
      "Epoch 6342/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0309 - val_loss: 0.6121\n",
      "Epoch 6343/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0493 - val_loss: 0.6273\n",
      "Epoch 6344/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0316 - val_loss: 0.6169\n",
      "Epoch 6345/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0215 - val_loss: 0.6088\n",
      "Epoch 6346/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0159 - val_loss: 0.6221\n",
      "Epoch 6347/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0131 - val_loss: 0.6068\n",
      "Epoch 6348/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0122 - val_loss: 0.6143\n",
      "Epoch 6349/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0122 - val_loss: 0.6002\n",
      "Epoch 6350/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0229 - val_loss: 0.6108\n",
      "Epoch 6351/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0289 - val_loss: 0.6216\n",
      "Epoch 6352/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0287 - val_loss: 0.6167\n",
      "Epoch 6353/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0288 - val_loss: 0.6335\n",
      "Epoch 6354/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0289 - val_loss: 0.6168\n",
      "Epoch 6355/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0250 - val_loss: 0.6365\n",
      "Epoch 6356/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0315 - val_loss: 0.6188\n",
      "Epoch 6357/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0333 - val_loss: 0.6300\n",
      "Epoch 6358/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0238 - val_loss: 0.6260\n",
      "Epoch 6359/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0218 - val_loss: 0.5959\n",
      "Epoch 6360/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0125 - val_loss: 0.6199\n",
      "Epoch 6361/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0132 - val_loss: 0.6357\n",
      "Epoch 6362/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0308 - val_loss: 0.6267\n",
      "Epoch 6363/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0337 - val_loss: 0.6216\n",
      "Epoch 6364/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0356 - val_loss: 0.6538\n",
      "Epoch 6365/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0421 - val_loss: 0.5957\n",
      "Epoch 6366/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0227 - val_loss: 0.6316\n",
      "Epoch 6367/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0170 - val_loss: 0.6156\n",
      "Epoch 6368/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0130 - val_loss: 0.5987\n",
      "Epoch 6369/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0391 - val_loss: 0.6271\n",
      "Epoch 6370/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0564 - val_loss: 0.6251\n",
      "Epoch 6371/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0323 - val_loss: 0.6174\n",
      "Epoch 6372/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0176 - val_loss: 0.6319\n",
      "Epoch 6373/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0265 - val_loss: 0.6021\n",
      "Epoch 6374/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0226 - val_loss: 0.6178\n",
      "Epoch 6375/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0148 - val_loss: 0.6137\n",
      "Epoch 6376/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0175 - val_loss: 0.6172\n",
      "Epoch 6377/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0134 - val_loss: 0.5915\n",
      "Epoch 6378/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0156 - val_loss: 0.5945\n",
      "Epoch 6379/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0204 - val_loss: 0.6339\n",
      "Epoch 6380/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0352 - val_loss: 0.6333\n",
      "Epoch 6381/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0350 - val_loss: 0.6297\n",
      "Epoch 6382/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0259 - val_loss: 0.6089\n",
      "Epoch 6383/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0158 - val_loss: 0.6018\n",
      "Epoch 6384/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0101 - val_loss: 0.6030\n",
      "Epoch 6385/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0099 - val_loss: 0.6161\n",
      "Epoch 6386/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0126 - val_loss: 0.5917\n",
      "Epoch 6387/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 752us/step - loss: 0.0210 - val_loss: 0.6501\n",
      "Epoch 6388/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0432 - val_loss: 0.6023\n",
      "Epoch 6389/10000\n",
      "130/130 [==============================] - 0s 804us/step - loss: 0.0266 - val_loss: 0.6339\n",
      "Epoch 6390/10000\n",
      "130/130 [==============================] - 0s 837us/step - loss: 0.0221 - val_loss: 0.6004\n",
      "Epoch 6391/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0316 - val_loss: 0.6082\n",
      "Epoch 6392/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.0237 - val_loss: 0.6066\n",
      "Epoch 6393/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0196 - val_loss: 0.6030\n",
      "Epoch 6394/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0159 - val_loss: 0.6157\n",
      "Epoch 6395/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0233 - val_loss: 0.6112\n",
      "Epoch 6396/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0732 - val_loss: 0.6053\n",
      "Epoch 6397/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0397 - val_loss: 0.5945\n",
      "Epoch 6398/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0325 - val_loss: 0.6119\n",
      "Epoch 6399/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0257 - val_loss: 0.6505\n",
      "Epoch 6400/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0211 - val_loss: 0.6350\n",
      "Epoch 6401/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0156 - val_loss: 0.6142\n",
      "Epoch 6402/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0189 - val_loss: 0.6574\n",
      "Epoch 6403/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0202 - val_loss: 0.6236\n",
      "Epoch 6404/10000\n",
      "130/130 [==============================] - 0s 857us/step - loss: 0.0094 - val_loss: 0.6075\n",
      "Epoch 6405/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0074 - val_loss: 0.6342\n",
      "Epoch 6406/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0144 - val_loss: 0.6050\n",
      "Epoch 6407/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0270 - val_loss: 0.6119\n",
      "Epoch 6408/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0307 - val_loss: 0.6013\n",
      "Epoch 6409/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0253 - val_loss: 0.6362\n",
      "Epoch 6410/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0484 - val_loss: 0.6033\n",
      "Epoch 6411/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0579 - val_loss: 0.6166\n",
      "Epoch 6412/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0331 - val_loss: 0.6285\n",
      "Epoch 6413/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0247 - val_loss: 0.6431\n",
      "Epoch 6414/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0193 - val_loss: 0.6284\n",
      "Epoch 6415/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0163 - val_loss: 0.6016\n",
      "Epoch 6416/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0126 - val_loss: 0.6270\n",
      "Epoch 6417/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0114 - val_loss: 0.6155\n",
      "Epoch 6418/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0108 - val_loss: 0.6262\n",
      "Epoch 6419/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0130 - val_loss: 0.6359\n",
      "Epoch 6420/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0267 - val_loss: 0.6255\n",
      "Epoch 6421/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0318 - val_loss: 0.6179\n",
      "Epoch 6422/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0403 - val_loss: 0.6203\n",
      "Epoch 6423/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0338 - val_loss: 0.5959\n",
      "Epoch 6424/10000\n",
      "130/130 [==============================] - 0s 843us/step - loss: 0.0317 - val_loss: 0.6374\n",
      "Epoch 6425/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0184 - val_loss: 0.5977\n",
      "Epoch 6426/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0139 - val_loss: 0.6124\n",
      "Epoch 6427/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0110 - val_loss: 0.6314\n",
      "Epoch 6428/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0162 - val_loss: 0.6198\n",
      "Epoch 6429/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0323 - val_loss: 0.6067\n",
      "Epoch 6430/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0233 - val_loss: 0.6228\n",
      "Epoch 6431/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0393 - val_loss: 0.6645\n",
      "Epoch 6432/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0427 - val_loss: 0.6100\n",
      "Epoch 6433/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0204 - val_loss: 0.6282\n",
      "Epoch 6434/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0228 - val_loss: 0.6002\n",
      "Epoch 6435/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0206 - val_loss: 0.6123\n",
      "Epoch 6436/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0145 - val_loss: 0.6340\n",
      "Epoch 6437/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0171 - val_loss: 0.6558\n",
      "Epoch 6438/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0188 - val_loss: 0.6543\n",
      "Epoch 6439/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0257 - val_loss: 0.5916\n",
      "Epoch 6440/10000\n",
      "130/130 [==============================] - 0s 940us/step - loss: 0.0298 - val_loss: 0.6779\n",
      "Epoch 6441/10000\n",
      "130/130 [==============================] - 0s 932us/step - loss: 0.0348 - val_loss: 0.6223\n",
      "Epoch 6442/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0154 - val_loss: 0.6125\n",
      "Epoch 6443/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0211 - val_loss: 0.6145\n",
      "Epoch 6444/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0365 - val_loss: 0.6077\n",
      "Epoch 6445/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0337 - val_loss: 0.5983\n",
      "Epoch 6446/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0170 - val_loss: 0.6038\n",
      "Epoch 6447/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0136 - val_loss: 0.6231\n",
      "Epoch 6448/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0128 - val_loss: 0.6182\n",
      "Epoch 6449/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0204 - val_loss: 0.6470\n",
      "Epoch 6450/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0297 - val_loss: 0.5927\n",
      "Epoch 6451/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0369 - val_loss: 0.6240\n",
      "Epoch 6452/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0347 - val_loss: 0.6135\n",
      "Epoch 6453/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0317 - val_loss: 0.6200\n",
      "Epoch 6454/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0198 - val_loss: 0.6120\n",
      "Epoch 6455/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0146 - val_loss: 0.6009\n",
      "Epoch 6456/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0176 - val_loss: 0.6409\n",
      "Epoch 6457/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0171 - val_loss: 0.6282\n",
      "Epoch 6458/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0134 - val_loss: 0.6222\n",
      "Epoch 6459/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0095 - val_loss: 0.6228\n",
      "Epoch 6460/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0187 - val_loss: 0.6344\n",
      "Epoch 6461/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0314 - val_loss: 0.6410\n",
      "Epoch 6462/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0497 - val_loss: 0.6150\n",
      "Epoch 6463/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 741us/step - loss: 0.0376 - val_loss: 0.6092\n",
      "Epoch 6464/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0277 - val_loss: 0.6406\n",
      "Epoch 6465/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0257 - val_loss: 0.6087\n",
      "Epoch 6466/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0275 - val_loss: 0.6229\n",
      "Epoch 6467/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0202 - val_loss: 0.6411\n",
      "Epoch 6468/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0198 - val_loss: 0.6485\n",
      "Epoch 6469/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0101 - val_loss: 0.6233\n",
      "Epoch 6470/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0121 - val_loss: 0.6278\n",
      "Epoch 6471/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0121 - val_loss: 0.6201\n",
      "Epoch 6472/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0093 - val_loss: 0.6315\n",
      "Epoch 6473/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0214 - val_loss: 0.6151\n",
      "Epoch 6474/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0319 - val_loss: 0.6675\n",
      "Epoch 6475/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0622 - val_loss: 0.6445\n",
      "Epoch 6476/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0418 - val_loss: 0.6468\n",
      "Epoch 6477/10000\n",
      "130/130 [==============================] - 0s 891us/step - loss: 0.0567 - val_loss: 0.5911\n",
      "Epoch 6478/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0221 - val_loss: 0.6069\n",
      "Epoch 6479/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0209 - val_loss: 0.6291\n",
      "Epoch 6480/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0244 - val_loss: 0.6238\n",
      "Epoch 6481/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0351 - val_loss: 0.6202\n",
      "Epoch 6482/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0327 - val_loss: 0.6368\n",
      "Epoch 6483/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0292 - val_loss: 0.6226\n",
      "Epoch 6484/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0202 - val_loss: 0.6260\n",
      "Epoch 6485/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0135 - val_loss: 0.6045\n",
      "Epoch 6486/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0123 - val_loss: 0.6052\n",
      "Epoch 6487/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0129 - val_loss: 0.6240\n",
      "Epoch 6488/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0120 - val_loss: 0.6193\n",
      "Epoch 6489/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0354 - val_loss: 0.5991\n",
      "Epoch 6490/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0356 - val_loss: 0.6472\n",
      "Epoch 6491/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0492 - val_loss: 0.6303\n",
      "Epoch 6492/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0353 - val_loss: 0.6004\n",
      "Epoch 6493/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0191 - val_loss: 0.6245\n",
      "Epoch 6494/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0161 - val_loss: 0.5937\n",
      "Epoch 6495/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0116 - val_loss: 0.6325\n",
      "Epoch 6496/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0209 - val_loss: 0.6014\n",
      "Epoch 6497/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0206 - val_loss: 0.6321\n",
      "Epoch 6498/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0391 - val_loss: 0.6217\n",
      "Epoch 6499/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0323 - val_loss: 0.6134\n",
      "Epoch 6500/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0126 - val_loss: 0.5966\n",
      "Epoch 6501/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0095 - val_loss: 0.6038\n",
      "Epoch 6502/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0159 - val_loss: 0.6072\n",
      "Epoch 6503/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0149 - val_loss: 0.6117\n",
      "Epoch 6504/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0293 - val_loss: 0.6145\n",
      "Epoch 6505/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0351 - val_loss: 0.6207\n",
      "Epoch 6506/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0185 - val_loss: 0.6157\n",
      "Epoch 6507/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0227 - val_loss: 0.6416\n",
      "Epoch 6508/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0414 - val_loss: 0.6283\n",
      "Epoch 6509/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0324 - val_loss: 0.6063\n",
      "Epoch 6510/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0305 - val_loss: 0.6374\n",
      "Epoch 6511/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0251 - val_loss: 0.6440\n",
      "Epoch 6512/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0226 - val_loss: 0.6070\n",
      "Epoch 6513/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0201 - val_loss: 0.6090\n",
      "Epoch 6514/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0249 - val_loss: 0.6311\n",
      "Epoch 6515/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0161 - val_loss: 0.6230\n",
      "Epoch 6516/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0254 - val_loss: 0.5843\n",
      "Epoch 6517/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0191 - val_loss: 0.6245\n",
      "Epoch 6518/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0228 - val_loss: 0.6263\n",
      "Epoch 6519/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0162 - val_loss: 0.6248\n",
      "Epoch 6520/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0113 - val_loss: 0.6175\n",
      "Epoch 6521/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0246 - val_loss: 0.6317\n",
      "Epoch 6522/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0356 - val_loss: 0.5705\n",
      "Epoch 6523/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0258 - val_loss: 0.6196\n",
      "Epoch 6524/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0362 - val_loss: 0.6138\n",
      "Epoch 6525/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0307 - val_loss: 0.5805\n",
      "Epoch 6526/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0293 - val_loss: 0.6221\n",
      "Epoch 6527/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0349 - val_loss: 0.6186\n",
      "Epoch 6528/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.6147\n",
      "Epoch 6529/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0409 - val_loss: 0.6562\n",
      "Epoch 6530/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0392 - val_loss: 0.6121\n",
      "Epoch 6531/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0263 - val_loss: 0.6211\n",
      "Epoch 6532/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0192 - val_loss: 0.6189\n",
      "Epoch 6533/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0185 - val_loss: 0.6356\n",
      "Epoch 6534/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0150 - val_loss: 0.6014\n",
      "Epoch 6535/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0142 - val_loss: 0.6291\n",
      "Epoch 6536/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0164 - val_loss: 0.6300\n",
      "Epoch 6537/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0151 - val_loss: 0.6407\n",
      "Epoch 6538/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0242 - val_loss: 0.6300\n",
      "Epoch 6539/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 772us/step - loss: 0.0577 - val_loss: 0.5994\n",
      "Epoch 6540/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0316 - val_loss: 0.5942\n",
      "Epoch 6541/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0173 - val_loss: 0.5842\n",
      "Epoch 6542/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0160 - val_loss: 0.6269\n",
      "Epoch 6543/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0167 - val_loss: 0.6130\n",
      "Epoch 6544/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0190 - val_loss: 0.6250\n",
      "Epoch 6545/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0213 - val_loss: 0.6095\n",
      "Epoch 6546/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0199 - val_loss: 0.6156\n",
      "Epoch 6547/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0194 - val_loss: 0.6280\n",
      "Epoch 6548/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0210 - val_loss: 0.6226\n",
      "Epoch 6549/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0161 - val_loss: 0.6222\n",
      "Epoch 6550/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0176 - val_loss: 0.6134\n",
      "Epoch 6551/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0196 - val_loss: 0.6325\n",
      "Epoch 6552/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0368 - val_loss: 0.6272\n",
      "Epoch 6553/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0348 - val_loss: 0.5811\n",
      "Epoch 6554/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0400 - val_loss: 0.5998\n",
      "Epoch 6555/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0285 - val_loss: 0.5807\n",
      "Epoch 6556/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0207 - val_loss: 0.6152\n",
      "Epoch 6557/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0198 - val_loss: 0.5988\n",
      "Epoch 6558/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0168 - val_loss: 0.5882\n",
      "Epoch 6559/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0169 - val_loss: 0.6034\n",
      "Epoch 6560/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0235 - val_loss: 0.5890\n",
      "Epoch 6561/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0207 - val_loss: 0.6018\n",
      "Epoch 6562/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0184 - val_loss: 0.5968\n",
      "Epoch 6563/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0240 - val_loss: 0.6051\n",
      "Epoch 6564/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0442 - val_loss: 0.6386\n",
      "Epoch 6565/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0496 - val_loss: 0.6063\n",
      "Epoch 6566/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0290 - val_loss: 0.6052\n",
      "Epoch 6567/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0190 - val_loss: 0.5997\n",
      "Epoch 6568/10000\n",
      "130/130 [==============================] - 0s 966us/step - loss: 0.0207 - val_loss: 0.6396\n",
      "Epoch 6569/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0214 - val_loss: 0.6270\n",
      "Epoch 6570/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0170 - val_loss: 0.6233\n",
      "Epoch 6571/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0156 - val_loss: 0.6224\n",
      "Epoch 6572/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0249 - val_loss: 0.6485\n",
      "Epoch 6573/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0588 - val_loss: 0.6402\n",
      "Epoch 6574/10000\n",
      "130/130 [==============================] - 0s 825us/step - loss: 0.0225 - val_loss: 0.6329\n",
      "Epoch 6575/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0292 - val_loss: 0.6206\n",
      "Epoch 6576/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0220 - val_loss: 0.6194\n",
      "Epoch 6577/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0221 - val_loss: 0.6238\n",
      "Epoch 6578/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0180 - val_loss: 0.6038\n",
      "Epoch 6579/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0193 - val_loss: 0.6341\n",
      "Epoch 6580/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0237 - val_loss: 0.6093\n",
      "Epoch 6581/10000\n",
      "130/130 [==============================] - 0s 899us/step - loss: 0.0248 - val_loss: 0.5824\n",
      "Epoch 6582/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0251 - val_loss: 0.5917\n",
      "Epoch 6583/10000\n",
      "130/130 [==============================] - 0s 922us/step - loss: 0.0226 - val_loss: 0.6040\n",
      "Epoch 6584/10000\n",
      "130/130 [==============================] - 0s 831us/step - loss: 0.0231 - val_loss: 0.6062\n",
      "Epoch 6585/10000\n",
      "130/130 [==============================] - 0s 860us/step - loss: 0.0245 - val_loss: 0.6330\n",
      "Epoch 6586/10000\n",
      "130/130 [==============================] - 0s 814us/step - loss: 0.0209 - val_loss: 0.6257\n",
      "Epoch 6587/10000\n",
      "130/130 [==============================] - 0s 830us/step - loss: 0.0245 - val_loss: 0.6159\n",
      "Epoch 6588/10000\n",
      "130/130 [==============================] - 0s 873us/step - loss: 0.0353 - val_loss: 0.6244\n",
      "Epoch 6589/10000\n",
      "130/130 [==============================] - 0s 844us/step - loss: 0.0263 - val_loss: 0.6250\n",
      "Epoch 6590/10000\n",
      "130/130 [==============================] - 0s 871us/step - loss: 0.0223 - val_loss: 0.6038\n",
      "Epoch 6591/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0295 - val_loss: 0.6421\n",
      "Epoch 6592/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0221 - val_loss: 0.5921\n",
      "Epoch 6593/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0546 - val_loss: 0.6295\n",
      "Epoch 6594/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0266 - val_loss: 0.6153\n",
      "Epoch 6595/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0200 - val_loss: 0.6248\n",
      "Epoch 6596/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0163 - val_loss: 0.6140\n",
      "Epoch 6597/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0104 - val_loss: 0.6078\n",
      "Epoch 6598/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0067 - val_loss: 0.6033\n",
      "Epoch 6599/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0105 - val_loss: 0.6106\n",
      "Epoch 6600/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0177 - val_loss: 0.5977\n",
      "Epoch 6601/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0356 - val_loss: 0.6383\n",
      "Epoch 6602/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0439 - val_loss: 0.6520\n",
      "Epoch 6603/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0439 - val_loss: 0.6493\n",
      "Epoch 6604/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0357 - val_loss: 0.6245\n",
      "Epoch 6605/10000\n",
      "130/130 [==============================] - 0s 851us/step - loss: 0.0224 - val_loss: 0.6348\n",
      "Epoch 6606/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0240 - val_loss: 0.6355\n",
      "Epoch 6607/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0133 - val_loss: 0.6071\n",
      "Epoch 6608/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0169 - val_loss: 0.6203\n",
      "Epoch 6609/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0239 - val_loss: 0.6142\n",
      "Epoch 6610/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0233 - val_loss: 0.6267\n",
      "Epoch 6611/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0213 - val_loss: 0.6166\n",
      "Epoch 6612/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0241 - val_loss: 0.6177\n",
      "Epoch 6613/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0167 - val_loss: 0.6197\n",
      "Epoch 6614/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0163 - val_loss: 0.6450\n",
      "Epoch 6615/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 801us/step - loss: 0.0209 - val_loss: 0.6047\n",
      "Epoch 6616/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0274 - val_loss: 0.6188\n",
      "Epoch 6617/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0370 - val_loss: 0.6122\n",
      "Epoch 6618/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0185 - val_loss: 0.5891\n",
      "Epoch 6619/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0206 - val_loss: 0.6326\n",
      "Epoch 6620/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0297 - val_loss: 0.5942\n",
      "Epoch 6621/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0457 - val_loss: 0.5969\n",
      "Epoch 6622/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0269 - val_loss: 0.5845\n",
      "Epoch 6623/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0158 - val_loss: 0.6170\n",
      "Epoch 6624/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0091 - val_loss: 0.6160\n",
      "Epoch 6625/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0087 - val_loss: 0.6132\n",
      "Epoch 6626/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0093 - val_loss: 0.6151\n",
      "Epoch 6627/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0191 - val_loss: 0.6444\n",
      "Epoch 6628/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0252 - val_loss: 0.6381\n",
      "Epoch 6629/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0378 - val_loss: 0.6161\n",
      "Epoch 6630/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0490 - val_loss: 0.5873\n",
      "Epoch 6631/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0333 - val_loss: 0.6084\n",
      "Epoch 6632/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0397 - val_loss: 0.6273\n",
      "Epoch 6633/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0395 - val_loss: 0.6125\n",
      "Epoch 6634/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0136 - val_loss: 0.6258\n",
      "Epoch 6635/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0090 - val_loss: 0.6124\n",
      "Epoch 6636/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0112 - val_loss: 0.6336\n",
      "Epoch 6637/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0146 - val_loss: 0.6306\n",
      "Epoch 6638/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0160 - val_loss: 0.6373\n",
      "Epoch 6639/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0456 - val_loss: 0.6398\n",
      "Epoch 6640/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0346 - val_loss: 0.6131\n",
      "Epoch 6641/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0306 - val_loss: 0.6168\n",
      "Epoch 6642/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0198 - val_loss: 0.5911\n",
      "Epoch 6643/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0134 - val_loss: 0.5844\n",
      "Epoch 6644/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0135 - val_loss: 0.5873\n",
      "Epoch 6645/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0297 - val_loss: 0.6265\n",
      "Epoch 6646/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0421 - val_loss: 0.6141\n",
      "Epoch 6647/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0309 - val_loss: 0.6401\n",
      "Epoch 6648/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0187 - val_loss: 0.6324\n",
      "Epoch 6649/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0201 - val_loss: 0.6041\n",
      "Epoch 6650/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0204 - val_loss: 0.6561\n",
      "Epoch 6651/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0244 - val_loss: 0.5608\n",
      "Epoch 6652/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0336 - val_loss: 0.5975\n",
      "Epoch 6653/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0243 - val_loss: 0.5924\n",
      "Epoch 6654/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0326 - val_loss: 0.6065\n",
      "Epoch 6655/10000\n",
      "130/130 [==============================] - 0s 831us/step - loss: 0.0343 - val_loss: 0.6333\n",
      "Epoch 6656/10000\n",
      "130/130 [==============================] - 0s 924us/step - loss: 0.0181 - val_loss: 0.6380\n",
      "Epoch 6657/10000\n",
      "130/130 [==============================] - 0s 983us/step - loss: 0.0188 - val_loss: 0.6021\n",
      "Epoch 6658/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0144 - val_loss: 0.6331\n",
      "Epoch 6659/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0131 - val_loss: 0.5914\n",
      "Epoch 6660/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0157 - val_loss: 0.6237\n",
      "Epoch 6661/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0237 - val_loss: 0.6212\n",
      "Epoch 6662/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0153 - val_loss: 0.6170\n",
      "Epoch 6663/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0124 - val_loss: 0.6036\n",
      "Epoch 6664/10000\n",
      "130/130 [==============================] - 0s 878us/step - loss: 0.0157 - val_loss: 0.6129\n",
      "Epoch 6665/10000\n",
      "130/130 [==============================] - 0s 825us/step - loss: 0.0273 - val_loss: 0.6184\n",
      "Epoch 6666/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0429 - val_loss: 0.6193\n",
      "Epoch 6667/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0392 - val_loss: 0.6258\n",
      "Epoch 6668/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0413 - val_loss: 0.5761\n",
      "Epoch 6669/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0423 - val_loss: 0.5991\n",
      "Epoch 6670/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0319 - val_loss: 0.6017\n",
      "Epoch 6671/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0142 - val_loss: 0.6000\n",
      "Epoch 6672/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0188 - val_loss: 0.5927\n",
      "Epoch 6673/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0143 - val_loss: 0.6018\n",
      "Epoch 6674/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0154 - val_loss: 0.6048\n",
      "Epoch 6675/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0192 - val_loss: 0.6144\n",
      "Epoch 6676/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0225 - val_loss: 0.6144\n",
      "Epoch 6677/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0133 - val_loss: 0.6000\n",
      "Epoch 6678/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0217 - val_loss: 0.6053\n",
      "Epoch 6679/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0584 - val_loss: 0.6276\n",
      "Epoch 6680/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0403 - val_loss: 0.5930\n",
      "Epoch 6681/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0228 - val_loss: 0.6164\n",
      "Epoch 6682/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0249 - val_loss: 0.6415\n",
      "Epoch 6683/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0205 - val_loss: 0.6382\n",
      "Epoch 6684/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0231 - val_loss: 0.6185\n",
      "Epoch 6685/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0181 - val_loss: 0.6209\n",
      "Epoch 6686/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0227 - val_loss: 0.6108\n",
      "Epoch 6687/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0252 - val_loss: 0.6121\n",
      "Epoch 6688/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0171 - val_loss: 0.6367\n",
      "Epoch 6689/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0237 - val_loss: 0.6232\n",
      "Epoch 6690/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0180 - val_loss: 0.6356\n",
      "Epoch 6691/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 737us/step - loss: 0.0567 - val_loss: 0.6082\n",
      "Epoch 6692/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0360 - val_loss: 0.6207\n",
      "Epoch 6693/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0179 - val_loss: 0.6272\n",
      "Epoch 6694/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0155 - val_loss: 0.6261\n",
      "Epoch 6695/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0109 - val_loss: 0.6315\n",
      "Epoch 6696/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0070 - val_loss: 0.6295\n",
      "Epoch 6697/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0210 - val_loss: 0.6228\n",
      "Epoch 6698/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0886 - val_loss: 0.5930\n",
      "Epoch 6699/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0667 - val_loss: 0.5927\n",
      "Epoch 6700/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0288 - val_loss: 0.6026\n",
      "Epoch 6701/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0164 - val_loss: 0.5813\n",
      "Epoch 6702/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0092 - val_loss: 0.5992\n",
      "Epoch 6703/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0077 - val_loss: 0.6106\n",
      "Epoch 6704/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0145 - val_loss: 0.5952\n",
      "Epoch 6705/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0126 - val_loss: 0.6214\n",
      "Epoch 6706/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0334 - val_loss: 0.5979\n",
      "Epoch 6707/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0482 - val_loss: 0.6139\n",
      "Epoch 6708/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0791 - val_loss: 0.6315\n",
      "Epoch 6709/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0354 - val_loss: 0.6071\n",
      "Epoch 6710/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0266 - val_loss: 0.6023\n",
      "Epoch 6711/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0136 - val_loss: 0.5942\n",
      "Epoch 6712/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0102 - val_loss: 0.6056\n",
      "Epoch 6713/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0161 - val_loss: 0.6064\n",
      "Epoch 6714/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0223 - val_loss: 0.6186\n",
      "Epoch 6715/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0218 - val_loss: 0.5896\n",
      "Epoch 6716/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0218 - val_loss: 0.6035\n",
      "Epoch 6717/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0253 - val_loss: 0.6148\n",
      "Epoch 6718/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0392 - val_loss: 0.6069\n",
      "Epoch 6719/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0363 - val_loss: 0.6096\n",
      "Epoch 6720/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0136 - val_loss: 0.5839\n",
      "Epoch 6721/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0140 - val_loss: 0.6000\n",
      "Epoch 6722/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0212 - val_loss: 0.6473\n",
      "Epoch 6723/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0262 - val_loss: 0.6426\n",
      "Epoch 6724/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0261 - val_loss: 0.6353\n",
      "Epoch 6725/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0197 - val_loss: 0.5891\n",
      "Epoch 6726/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0143 - val_loss: 0.6144\n",
      "Epoch 6727/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0154 - val_loss: 0.6011\n",
      "Epoch 6728/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0165 - val_loss: 0.6208\n",
      "Epoch 6729/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.5935\n",
      "Epoch 6730/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0236 - val_loss: 0.6464\n",
      "Epoch 6731/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0206 - val_loss: 0.6174\n",
      "Epoch 6732/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0246 - val_loss: 0.6166\n",
      "Epoch 6733/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0194 - val_loss: 0.5974\n",
      "Epoch 6734/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0178 - val_loss: 0.6127\n",
      "Epoch 6735/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0161 - val_loss: 0.6293\n",
      "Epoch 6736/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0220 - val_loss: 0.6056\n",
      "Epoch 6737/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0165 - val_loss: 0.6202\n",
      "Epoch 6738/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0253 - val_loss: 0.6416\n",
      "Epoch 6739/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0300 - val_loss: 0.6317\n",
      "Epoch 6740/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0292 - val_loss: 0.6181\n",
      "Epoch 6741/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0168 - val_loss: 0.6230\n",
      "Epoch 6742/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0142 - val_loss: 0.6248\n",
      "Epoch 6743/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0146 - val_loss: 0.5999\n",
      "Epoch 6744/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0200 - val_loss: 0.6513\n",
      "Epoch 6745/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0520 - val_loss: 0.6119\n",
      "Epoch 6746/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0420 - val_loss: 0.6303\n",
      "Epoch 6747/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0386 - val_loss: 0.6372\n",
      "Epoch 6748/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0275 - val_loss: 0.6284\n",
      "Epoch 6749/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0159 - val_loss: 0.5999\n",
      "Epoch 6750/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0217 - val_loss: 0.6014\n",
      "Epoch 6751/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0131 - val_loss: 0.6370\n",
      "Epoch 6752/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0163 - val_loss: 0.6046\n",
      "Epoch 6753/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0191 - val_loss: 0.6246\n",
      "Epoch 6754/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0799 - val_loss: 0.6183\n",
      "Epoch 6755/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0570 - val_loss: 0.6353\n",
      "Epoch 6756/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0176 - val_loss: 0.5956\n",
      "Epoch 6757/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0138 - val_loss: 0.6332\n",
      "Epoch 6758/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0110 - val_loss: 0.6228\n",
      "Epoch 6759/10000\n",
      "130/130 [==============================] - 0s 841us/step - loss: 0.0262 - val_loss: 0.6184\n",
      "Epoch 6760/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0209 - val_loss: 0.6199\n",
      "Epoch 6761/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0187 - val_loss: 0.6038\n",
      "Epoch 6762/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0152 - val_loss: 0.6028\n",
      "Epoch 6763/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0095 - val_loss: 0.6155\n",
      "Epoch 6764/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0210 - val_loss: 0.6514\n",
      "Epoch 6765/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0558 - val_loss: 0.6300\n",
      "Epoch 6766/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0337 - val_loss: 0.6187\n",
      "Epoch 6767/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 757us/step - loss: 0.0271 - val_loss: 0.5889\n",
      "Epoch 6768/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0295 - val_loss: 0.6085\n",
      "Epoch 6769/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0225 - val_loss: 0.6332\n",
      "Epoch 6770/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0162 - val_loss: 0.6143\n",
      "Epoch 6771/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0144 - val_loss: 0.6338\n",
      "Epoch 6772/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0184 - val_loss: 0.6003\n",
      "Epoch 6773/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0160 - val_loss: 0.5963\n",
      "Epoch 6774/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0168 - val_loss: 0.6373\n",
      "Epoch 6775/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0470 - val_loss: 0.6279\n",
      "Epoch 6776/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0284 - val_loss: 0.6065\n",
      "Epoch 6777/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0205 - val_loss: 0.6141\n",
      "Epoch 6778/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0201 - val_loss: 0.5935\n",
      "Epoch 6779/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0163 - val_loss: 0.6018\n",
      "Epoch 6780/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0328 - val_loss: 0.5900\n",
      "Epoch 6781/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0308 - val_loss: 0.6140\n",
      "Epoch 6782/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0253 - val_loss: 0.6204\n",
      "Epoch 6783/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0261 - val_loss: 0.6214\n",
      "Epoch 6784/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0234 - val_loss: 0.6109\n",
      "Epoch 6785/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0182 - val_loss: 0.5950\n",
      "Epoch 6786/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0166 - val_loss: 0.6161\n",
      "Epoch 6787/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0317 - val_loss: 0.5976\n",
      "Epoch 6788/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0412 - val_loss: 0.6309\n",
      "Epoch 6789/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0416 - val_loss: 0.6348\n",
      "Epoch 6790/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0244 - val_loss: 0.6044\n",
      "Epoch 6791/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0203 - val_loss: 0.6214\n",
      "Epoch 6792/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0188 - val_loss: 0.6241\n",
      "Epoch 6793/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0130 - val_loss: 0.6145\n",
      "Epoch 6794/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0230 - val_loss: 0.6123\n",
      "Epoch 6795/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0240 - val_loss: 0.6072\n",
      "Epoch 6796/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0161 - val_loss: 0.6036\n",
      "Epoch 6797/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0257 - val_loss: 0.5876\n",
      "Epoch 6798/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0220 - val_loss: 0.6365\n",
      "Epoch 6799/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0265 - val_loss: 0.5948\n",
      "Epoch 6800/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0308 - val_loss: 0.6293\n",
      "Epoch 6801/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0293 - val_loss: 0.6022\n",
      "Epoch 6802/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0191 - val_loss: 0.5928\n",
      "Epoch 6803/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0169 - val_loss: 0.5915\n",
      "Epoch 6804/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0286 - val_loss: 0.6461\n",
      "Epoch 6805/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0220 - val_loss: 0.6230\n",
      "Epoch 6806/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0165 - val_loss: 0.5931\n",
      "Epoch 6807/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0128 - val_loss: 0.5772\n",
      "Epoch 6808/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0263 - val_loss: 0.5947\n",
      "Epoch 6809/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0279 - val_loss: 0.5919\n",
      "Epoch 6810/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0245 - val_loss: 0.6463\n",
      "Epoch 6811/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0237 - val_loss: 0.5894\n",
      "Epoch 6812/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0362 - val_loss: 0.6097\n",
      "Epoch 6813/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0351 - val_loss: 0.6178\n",
      "Epoch 6814/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0153 - val_loss: 0.6182\n",
      "Epoch 6815/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0251 - val_loss: 0.6325\n",
      "Epoch 6816/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0222 - val_loss: 0.6149\n",
      "Epoch 6817/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0195 - val_loss: 0.5943\n",
      "Epoch 6818/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0187 - val_loss: 0.6228\n",
      "Epoch 6819/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0123 - val_loss: 0.5956\n",
      "Epoch 6820/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0245 - val_loss: 0.6125\n",
      "Epoch 6821/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0298 - val_loss: 0.6246\n",
      "Epoch 6822/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0456 - val_loss: 0.6344\n",
      "Epoch 6823/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0469 - val_loss: 0.5696\n",
      "Epoch 6824/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0310 - val_loss: 0.6050\n",
      "Epoch 6825/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0234 - val_loss: 0.5960\n",
      "Epoch 6826/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0161 - val_loss: 0.6159\n",
      "Epoch 6827/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0115 - val_loss: 0.6173\n",
      "Epoch 6828/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0197 - val_loss: 0.6238\n",
      "Epoch 6829/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0273 - val_loss: 0.6183\n",
      "Epoch 6830/10000\n",
      "130/130 [==============================] - 0s 805us/step - loss: 0.0316 - val_loss: 0.6169\n",
      "Epoch 6831/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0278 - val_loss: 0.6118\n",
      "Epoch 6832/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0440 - val_loss: 0.6470\n",
      "Epoch 6833/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0212 - val_loss: 0.6133\n",
      "Epoch 6834/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0174 - val_loss: 0.6118\n",
      "Epoch 6835/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0232 - val_loss: 0.6122\n",
      "Epoch 6836/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0200 - val_loss: 0.6020\n",
      "Epoch 6837/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0155 - val_loss: 0.6051\n",
      "Epoch 6838/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0161 - val_loss: 0.6051\n",
      "Epoch 6839/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0231 - val_loss: 0.5943\n",
      "Epoch 6840/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0216 - val_loss: 0.6148\n",
      "Epoch 6841/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0188 - val_loss: 0.6124\n",
      "Epoch 6842/10000\n",
      "130/130 [==============================] - 0s 867us/step - loss: 0.0159 - val_loss: 0.6002\n",
      "Epoch 6843/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 786us/step - loss: 0.0177 - val_loss: 0.6017\n",
      "Epoch 6844/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0141 - val_loss: 0.6301\n",
      "Epoch 6845/10000\n",
      "130/130 [==============================] - 0s 987us/step - loss: 0.0372 - val_loss: 0.6183\n",
      "Epoch 6846/10000\n",
      "130/130 [==============================] - 0s 995us/step - loss: 0.0294 - val_loss: 0.5988\n",
      "Epoch 6847/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0298 - val_loss: 0.6247\n",
      "Epoch 6848/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0681 - val_loss: 0.6069\n",
      "Epoch 6849/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0453 - val_loss: 0.5909\n",
      "Epoch 6850/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0119 - val_loss: 0.5890\n",
      "Epoch 6851/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0087 - val_loss: 0.6147\n",
      "Epoch 6852/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0083 - val_loss: 0.6033\n",
      "Epoch 6853/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0106 - val_loss: 0.5949\n",
      "Epoch 6854/10000\n",
      "130/130 [==============================] - 0s 833us/step - loss: 0.0126 - val_loss: 0.6203\n",
      "Epoch 6855/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0339 - val_loss: 0.6242\n",
      "Epoch 6856/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0951 - val_loss: 0.6447\n",
      "Epoch 6857/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0542 - val_loss: 0.6253\n",
      "Epoch 6858/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0162 - val_loss: 0.6158\n",
      "Epoch 6859/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0145 - val_loss: 0.5988\n",
      "Epoch 6860/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0097 - val_loss: 0.6099\n",
      "Epoch 6861/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0075 - val_loss: 0.5916\n",
      "Epoch 6862/10000\n",
      "130/130 [==============================] - 0s 840us/step - loss: 0.0127 - val_loss: 0.6059\n",
      "Epoch 6863/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0250 - val_loss: 0.5990\n",
      "Epoch 6864/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0280 - val_loss: 0.6142\n",
      "Epoch 6865/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0190 - val_loss: 0.6110\n",
      "Epoch 6866/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0168 - val_loss: 0.6341\n",
      "Epoch 6867/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0227 - val_loss: 0.6160\n",
      "Epoch 6868/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0251 - val_loss: 0.6271\n",
      "Epoch 6869/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0215 - val_loss: 0.6263\n",
      "Epoch 6870/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0186 - val_loss: 0.6088\n",
      "Epoch 6871/10000\n",
      "130/130 [==============================] - 0s 844us/step - loss: 0.0157 - val_loss: 0.6260\n",
      "Epoch 6872/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0226 - val_loss: 0.6117\n",
      "Epoch 6873/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0202 - val_loss: 0.5879\n",
      "Epoch 6874/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0244 - val_loss: 0.6354\n",
      "Epoch 6875/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0467 - val_loss: 0.6235\n",
      "Epoch 6876/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0308 - val_loss: 0.6071\n",
      "Epoch 6877/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0340 - val_loss: 0.6308\n",
      "Epoch 6878/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0229 - val_loss: 0.6192\n",
      "Epoch 6879/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0148 - val_loss: 0.6225\n",
      "Epoch 6880/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0161 - val_loss: 0.6245\n",
      "Epoch 6881/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0134 - val_loss: 0.6208\n",
      "Epoch 6882/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0088 - val_loss: 0.6109\n",
      "Epoch 6883/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0177 - val_loss: 0.6435\n",
      "Epoch 6884/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0293 - val_loss: 0.6065\n",
      "Epoch 6885/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0224 - val_loss: 0.5916\n",
      "Epoch 6886/10000\n",
      "130/130 [==============================] - 0s 847us/step - loss: 0.0346 - val_loss: 0.6457\n",
      "Epoch 6887/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0454 - val_loss: 0.6098\n",
      "Epoch 6888/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0307 - val_loss: 0.6148\n",
      "Epoch 6889/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0391 - val_loss: 0.5905\n",
      "Epoch 6890/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0210 - val_loss: 0.6284\n",
      "Epoch 6891/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0213 - val_loss: 0.5854\n",
      "Epoch 6892/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0148 - val_loss: 0.6133\n",
      "Epoch 6893/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0168 - val_loss: 0.6064\n",
      "Epoch 6894/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0181 - val_loss: 0.6452\n",
      "Epoch 6895/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0371 - val_loss: 0.6071\n",
      "Epoch 6896/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0257 - val_loss: 0.6027\n",
      "Epoch 6897/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0238 - val_loss: 0.6197\n",
      "Epoch 6898/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0241 - val_loss: 0.5711\n",
      "Epoch 6899/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0551 - val_loss: 0.5662\n",
      "Epoch 6900/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0330 - val_loss: 0.5851\n",
      "Epoch 6901/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0202 - val_loss: 0.6169\n",
      "Epoch 6902/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0169 - val_loss: 0.6177\n",
      "Epoch 6903/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0121 - val_loss: 0.5959\n",
      "Epoch 6904/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0149 - val_loss: 0.6199\n",
      "Epoch 6905/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0139 - val_loss: 0.6110\n",
      "Epoch 6906/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0142 - val_loss: 0.5978\n",
      "Epoch 6907/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0145 - val_loss: 0.6229\n",
      "Epoch 6908/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0302 - val_loss: 0.6498\n",
      "Epoch 6909/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0554 - val_loss: 0.6065\n",
      "Epoch 6910/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0346 - val_loss: 0.6170\n",
      "Epoch 6911/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0235 - val_loss: 0.5919\n",
      "Epoch 6912/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0117 - val_loss: 0.6223\n",
      "Epoch 6913/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0099 - val_loss: 0.6236\n",
      "Epoch 6914/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0168 - val_loss: 0.6396\n",
      "Epoch 6915/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0321 - val_loss: 0.6098\n",
      "Epoch 6916/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0274 - val_loss: 0.6118\n",
      "Epoch 6917/10000\n",
      "130/130 [==============================] - 0s 859us/step - loss: 0.0228 - val_loss: 0.6273\n",
      "Epoch 6918/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0311 - val_loss: 0.5888\n",
      "Epoch 6919/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 755us/step - loss: 0.0430 - val_loss: 0.6346\n",
      "Epoch 6920/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0293 - val_loss: 0.6073\n",
      "Epoch 6921/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0255 - val_loss: 0.6398\n",
      "Epoch 6922/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0128 - val_loss: 0.6334\n",
      "Epoch 6923/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0121 - val_loss: 0.6241\n",
      "Epoch 6924/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0181 - val_loss: 0.5996\n",
      "Epoch 6925/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0137 - val_loss: 0.6180\n",
      "Epoch 6926/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0230 - val_loss: 0.5925\n",
      "Epoch 6927/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0201 - val_loss: 0.6087\n",
      "Epoch 6928/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0541 - val_loss: 0.6000\n",
      "Epoch 6929/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0574 - val_loss: 0.6253\n",
      "Epoch 6930/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0273 - val_loss: 0.6045\n",
      "Epoch 6931/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0186 - val_loss: 0.6190\n",
      "Epoch 6932/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0218 - val_loss: 0.6402\n",
      "Epoch 6933/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0203 - val_loss: 0.6135\n",
      "Epoch 6934/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0304 - val_loss: 0.6137\n",
      "Epoch 6935/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0300 - val_loss: 0.6337\n",
      "Epoch 6936/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0260 - val_loss: 0.5953\n",
      "Epoch 6937/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0134 - val_loss: 0.6289\n",
      "Epoch 6938/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0303 - val_loss: 0.5936\n",
      "Epoch 6939/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0208 - val_loss: 0.6164\n",
      "Epoch 6940/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0118 - val_loss: 0.6026\n",
      "Epoch 6941/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0259 - val_loss: 0.6175\n",
      "Epoch 6942/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0307 - val_loss: 0.6140\n",
      "Epoch 6943/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0276 - val_loss: 0.6180\n",
      "Epoch 6944/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0203 - val_loss: 0.6291\n",
      "Epoch 6945/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0169 - val_loss: 0.5932\n",
      "Epoch 6946/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0133 - val_loss: 0.6129\n",
      "Epoch 6947/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0074 - val_loss: 0.6064\n",
      "Epoch 6948/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0143 - val_loss: 0.6157\n",
      "Epoch 6949/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0133 - val_loss: 0.6063\n",
      "Epoch 6950/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0167 - val_loss: 0.6040\n",
      "Epoch 6951/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0383 - val_loss: 0.6163\n",
      "Epoch 6952/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0508 - val_loss: 0.6118\n",
      "Epoch 6953/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0738 - val_loss: 0.6061\n",
      "Epoch 6954/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0586 - val_loss: 0.6288\n",
      "Epoch 6955/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0307 - val_loss: 0.6234\n",
      "Epoch 6956/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0153 - val_loss: 0.6114\n",
      "Epoch 6957/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0143 - val_loss: 0.6123\n",
      "Epoch 6958/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0149 - val_loss: 0.6011\n",
      "Epoch 6959/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0110 - val_loss: 0.6170\n",
      "Epoch 6960/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0161 - val_loss: 0.5962\n",
      "Epoch 6961/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0311 - val_loss: 0.6057\n",
      "Epoch 6962/10000\n",
      "130/130 [==============================] - 0s 829us/step - loss: 0.0396 - val_loss: 0.6385\n",
      "Epoch 6963/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0335 - val_loss: 0.5930\n",
      "Epoch 6964/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0209 - val_loss: 0.5993\n",
      "Epoch 6965/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0149 - val_loss: 0.5968\n",
      "Epoch 6966/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0108 - val_loss: 0.6164\n",
      "Epoch 6967/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0147 - val_loss: 0.6123\n",
      "Epoch 6968/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0127 - val_loss: 0.5904\n",
      "Epoch 6969/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0147 - val_loss: 0.6202\n",
      "Epoch 6970/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0261 - val_loss: 0.6406\n",
      "Epoch 6971/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0356 - val_loss: 0.6127\n",
      "Epoch 6972/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0300 - val_loss: 0.6024\n",
      "Epoch 6973/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0281 - val_loss: 0.6106\n",
      "Epoch 6974/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0259 - val_loss: 0.6211\n",
      "Epoch 6975/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0285 - val_loss: 0.6391\n",
      "Epoch 6976/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0292 - val_loss: 0.6024\n",
      "Epoch 6977/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0325 - val_loss: 0.6040\n",
      "Epoch 6978/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0224 - val_loss: 0.6066\n",
      "Epoch 6979/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0205 - val_loss: 0.6098\n",
      "Epoch 6980/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0143 - val_loss: 0.6182\n",
      "Epoch 6981/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0204 - val_loss: 0.6078\n",
      "Epoch 6982/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0157 - val_loss: 0.5871\n",
      "Epoch 6983/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0111 - val_loss: 0.5971\n",
      "Epoch 6984/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0211 - val_loss: 0.6701\n",
      "Epoch 6985/10000\n",
      "130/130 [==============================] - 0s 824us/step - loss: 0.0310 - val_loss: 0.6589\n",
      "Epoch 6986/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0468 - val_loss: 0.6148\n",
      "Epoch 6987/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0379 - val_loss: 0.6069\n",
      "Epoch 6988/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0177 - val_loss: 0.6446\n",
      "Epoch 6989/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0180 - val_loss: 0.5771\n",
      "Epoch 6990/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0144 - val_loss: 0.5925\n",
      "Epoch 6991/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0156 - val_loss: 0.6015\n",
      "Epoch 6992/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0163 - val_loss: 0.5888\n",
      "Epoch 6993/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0300 - val_loss: 0.5749\n",
      "Epoch 6994/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0309 - val_loss: 0.6165\n",
      "Epoch 6995/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 749us/step - loss: 0.0336 - val_loss: 0.6093\n",
      "Epoch 6996/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0208 - val_loss: 0.6142\n",
      "Epoch 6997/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0226 - val_loss: 0.5876\n",
      "Epoch 6998/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0134 - val_loss: 0.5984\n",
      "Epoch 6999/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0187 - val_loss: 0.6269\n",
      "Epoch 7000/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0355 - val_loss: 0.6094\n",
      "Epoch 7001/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0406 - val_loss: 0.6477\n",
      "Epoch 7002/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0225 - val_loss: 0.6354\n",
      "Epoch 7003/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0165 - val_loss: 0.5903\n",
      "Epoch 7004/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0253 - val_loss: 0.6075\n",
      "Epoch 7005/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0613 - val_loss: 0.5851\n",
      "Epoch 7006/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0329 - val_loss: 0.6256\n",
      "Epoch 7007/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0160 - val_loss: 0.6103\n",
      "Epoch 7008/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0124 - val_loss: 0.6114\n",
      "Epoch 7009/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0091 - val_loss: 0.6136\n",
      "Epoch 7010/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0089 - val_loss: 0.6064\n",
      "Epoch 7011/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0214 - val_loss: 0.5933\n",
      "Epoch 7012/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0253 - val_loss: 0.5984\n",
      "Epoch 7013/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0362 - val_loss: 0.5875\n",
      "Epoch 7014/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0349 - val_loss: 0.6245\n",
      "Epoch 7015/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0336 - val_loss: 0.6184\n",
      "Epoch 7016/10000\n",
      "130/130 [==============================] - 0s 850us/step - loss: 0.0202 - val_loss: 0.6176\n",
      "Epoch 7017/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0154 - val_loss: 0.6212\n",
      "Epoch 7018/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0218 - val_loss: 0.6141\n",
      "Epoch 7019/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0218 - val_loss: 0.6298\n",
      "Epoch 7020/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0136 - val_loss: 0.6211\n",
      "Epoch 7021/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0137 - val_loss: 0.6086\n",
      "Epoch 7022/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0242 - val_loss: 0.6332\n",
      "Epoch 7023/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0282 - val_loss: 0.6336\n",
      "Epoch 7024/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0344 - val_loss: 0.6435\n",
      "Epoch 7025/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0429 - val_loss: 0.6255\n",
      "Epoch 7026/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0290 - val_loss: 0.5924\n",
      "Epoch 7027/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0222 - val_loss: 0.6067\n",
      "Epoch 7028/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0314 - val_loss: 0.6297\n",
      "Epoch 7029/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0246 - val_loss: 0.5978\n",
      "Epoch 7030/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0162 - val_loss: 0.6178\n",
      "Epoch 7031/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0148 - val_loss: 0.6229\n",
      "Epoch 7032/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0209 - val_loss: 0.6381\n",
      "Epoch 7033/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0224 - val_loss: 0.6442\n",
      "Epoch 7034/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0150 - val_loss: 0.6067\n",
      "Epoch 7035/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0156 - val_loss: 0.6078\n",
      "Epoch 7036/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0166 - val_loss: 0.6171\n",
      "Epoch 7037/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0174 - val_loss: 0.6130\n",
      "Epoch 7038/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0153 - val_loss: 0.6138\n",
      "Epoch 7039/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0150 - val_loss: 0.6217\n",
      "Epoch 7040/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0286 - val_loss: 0.6016\n",
      "Epoch 7041/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0303 - val_loss: 0.6638\n",
      "Epoch 7042/10000\n",
      "130/130 [==============================] - 0s 803us/step - loss: 0.0424 - val_loss: 0.6518\n",
      "Epoch 7043/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0357 - val_loss: 0.6498\n",
      "Epoch 7044/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0195 - val_loss: 0.6491\n",
      "Epoch 7045/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0228 - val_loss: 0.6131\n",
      "Epoch 7046/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0222 - val_loss: 0.6368\n",
      "Epoch 7047/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0257 - val_loss: 0.6129\n",
      "Epoch 7048/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0189 - val_loss: 0.6364\n",
      "Epoch 7049/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0127 - val_loss: 0.6185\n",
      "Epoch 7050/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0119 - val_loss: 0.6119\n",
      "Epoch 7051/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0116 - val_loss: 0.6206\n",
      "Epoch 7052/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0299 - val_loss: 0.6042\n",
      "Epoch 7053/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0227 - val_loss: 0.6243\n",
      "Epoch 7054/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0191 - val_loss: 0.6352\n",
      "Epoch 7055/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0399 - val_loss: 0.6361\n",
      "Epoch 7056/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0406 - val_loss: 0.6082\n",
      "Epoch 7057/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0286 - val_loss: 0.6096\n",
      "Epoch 7058/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0221 - val_loss: 0.5748\n",
      "Epoch 7059/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0174 - val_loss: 0.5906\n",
      "Epoch 7060/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0164 - val_loss: 0.6089\n",
      "Epoch 7061/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0262 - val_loss: 0.6086\n",
      "Epoch 7062/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0349 - val_loss: 0.5977\n",
      "Epoch 7063/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0213 - val_loss: 0.6123\n",
      "Epoch 7064/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0122 - val_loss: 0.6059\n",
      "Epoch 7065/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0117 - val_loss: 0.6027\n",
      "Epoch 7066/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0173 - val_loss: 0.6198\n",
      "Epoch 7067/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0296 - val_loss: 0.6088\n",
      "Epoch 7068/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0497 - val_loss: 0.5947\n",
      "Epoch 7069/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0326 - val_loss: 0.5889\n",
      "Epoch 7070/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0195 - val_loss: 0.6041\n",
      "Epoch 7071/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 739us/step - loss: 0.0222 - val_loss: 0.6211\n",
      "Epoch 7072/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0308 - val_loss: 0.6227\n",
      "Epoch 7073/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0222 - val_loss: 0.6196\n",
      "Epoch 7074/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0163 - val_loss: 0.5982\n",
      "Epoch 7075/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0126 - val_loss: 0.6127\n",
      "Epoch 7076/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0178 - val_loss: 0.6260\n",
      "Epoch 7077/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0129 - val_loss: 0.6024\n",
      "Epoch 7078/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0162 - val_loss: 0.5925\n",
      "Epoch 7079/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0196 - val_loss: 0.6197\n",
      "Epoch 7080/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0303 - val_loss: 0.6224\n",
      "Epoch 7081/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0316 - val_loss: 0.5909\n",
      "Epoch 7082/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0510 - val_loss: 0.6065\n",
      "Epoch 7083/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0440 - val_loss: 0.6120\n",
      "Epoch 7084/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0564 - val_loss: 0.6209\n",
      "Epoch 7085/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0223 - val_loss: 0.6126\n",
      "Epoch 7086/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0352 - val_loss: 0.6073\n",
      "Epoch 7087/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0291 - val_loss: 0.6086\n",
      "Epoch 7088/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0142 - val_loss: 0.6085\n",
      "Epoch 7089/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0097 - val_loss: 0.6064\n",
      "Epoch 7090/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0197 - val_loss: 0.6085\n",
      "Epoch 7091/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0279 - val_loss: 0.6192\n",
      "Epoch 7092/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0224 - val_loss: 0.6127\n",
      "Epoch 7093/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0159 - val_loss: 0.6133\n",
      "Epoch 7094/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0142 - val_loss: 0.6471\n",
      "Epoch 7095/10000\n",
      "130/130 [==============================] - 0s 804us/step - loss: 0.0188 - val_loss: 0.5920\n",
      "Epoch 7096/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0265 - val_loss: 0.6008\n",
      "Epoch 7097/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0303 - val_loss: 0.5830\n",
      "Epoch 7098/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0265 - val_loss: 0.5995\n",
      "Epoch 7099/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0159 - val_loss: 0.6175\n",
      "Epoch 7100/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0234 - val_loss: 0.6022\n",
      "Epoch 7101/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0174 - val_loss: 0.6022\n",
      "Epoch 7102/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0192 - val_loss: 0.6328\n",
      "Epoch 7103/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0239 - val_loss: 0.6212\n",
      "Epoch 7104/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.1192 - val_loss: 0.6003\n",
      "Epoch 7105/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0738 - val_loss: 0.5837\n",
      "Epoch 7106/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0162 - val_loss: 0.6259\n",
      "Epoch 7107/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0092 - val_loss: 0.6149\n",
      "Epoch 7108/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0114 - val_loss: 0.6012\n",
      "Epoch 7109/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0110 - val_loss: 0.6106\n",
      "Epoch 7110/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0081 - val_loss: 0.6032\n",
      "Epoch 7111/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0096 - val_loss: 0.6185\n",
      "Epoch 7112/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0177 - val_loss: 0.6147\n",
      "Epoch 7113/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0175 - val_loss: 0.5943\n",
      "Epoch 7114/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0360 - val_loss: 0.6125\n",
      "Epoch 7115/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0554 - val_loss: 0.6277\n",
      "Epoch 7116/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0430 - val_loss: 0.6015\n",
      "Epoch 7117/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0241 - val_loss: 0.5848\n",
      "Epoch 7118/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0211 - val_loss: 0.6164\n",
      "Epoch 7119/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0115 - val_loss: 0.5940\n",
      "Epoch 7120/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0070 - val_loss: 0.5895\n",
      "Epoch 7121/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0130 - val_loss: 0.6112\n",
      "Epoch 7122/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0211 - val_loss: 0.6044\n",
      "Epoch 7123/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0260 - val_loss: 0.5965\n",
      "Epoch 7124/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0256 - val_loss: 0.6158\n",
      "Epoch 7125/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0198 - val_loss: 0.5990\n",
      "Epoch 7126/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0243 - val_loss: 0.6159\n",
      "Epoch 7127/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0416 - val_loss: 0.6225\n",
      "Epoch 7128/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0492 - val_loss: 0.6011\n",
      "Epoch 7129/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0297 - val_loss: 0.5954\n",
      "Epoch 7130/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0386 - val_loss: 0.6203\n",
      "Epoch 7131/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0222 - val_loss: 0.6009\n",
      "Epoch 7132/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0211 - val_loss: 0.6052\n",
      "Epoch 7133/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0224 - val_loss: 0.5935\n",
      "Epoch 7134/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0118 - val_loss: 0.6255\n",
      "Epoch 7135/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0115 - val_loss: 0.5955\n",
      "Epoch 7136/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0247 - val_loss: 0.5754\n",
      "Epoch 7137/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0208 - val_loss: 0.5980\n",
      "Epoch 7138/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0143 - val_loss: 0.5967\n",
      "Epoch 7139/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0211 - val_loss: 0.5985\n",
      "Epoch 7140/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0263 - val_loss: 0.5982\n",
      "Epoch 7141/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0282 - val_loss: 0.5874\n",
      "Epoch 7142/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0316 - val_loss: 0.6199\n",
      "Epoch 7143/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0253 - val_loss: 0.6162\n",
      "Epoch 7144/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0200 - val_loss: 0.6089\n",
      "Epoch 7145/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0215 - val_loss: 0.6170\n",
      "Epoch 7146/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0232 - val_loss: 0.6139\n",
      "Epoch 7147/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 730us/step - loss: 0.0110 - val_loss: 0.5956\n",
      "Epoch 7148/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0097 - val_loss: 0.5989\n",
      "Epoch 7149/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0112 - val_loss: 0.5985\n",
      "Epoch 7150/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0136 - val_loss: 0.6150\n",
      "Epoch 7151/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0357 - val_loss: 0.6175\n",
      "Epoch 7152/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0519 - val_loss: 0.5807\n",
      "Epoch 7153/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0378 - val_loss: 0.5792\n",
      "Epoch 7154/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0210 - val_loss: 0.5938\n",
      "Epoch 7155/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0106 - val_loss: 0.5843\n",
      "Epoch 7156/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0156 - val_loss: 0.6142\n",
      "Epoch 7157/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0144 - val_loss: 0.6079\n",
      "Epoch 7158/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0166 - val_loss: 0.6276\n",
      "Epoch 7159/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0247 - val_loss: 0.6112\n",
      "Epoch 7160/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0244 - val_loss: 0.6015\n",
      "Epoch 7161/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0421 - val_loss: 0.6103\n",
      "Epoch 7162/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0358 - val_loss: 0.5898\n",
      "Epoch 7163/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0201 - val_loss: 0.6100\n",
      "Epoch 7164/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0192 - val_loss: 0.5987\n",
      "Epoch 7165/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0331 - val_loss: 0.6327\n",
      "Epoch 7166/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0347 - val_loss: 0.6190\n",
      "Epoch 7167/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0314 - val_loss: 0.6185\n",
      "Epoch 7168/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0490 - val_loss: 0.6244\n",
      "Epoch 7169/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0263 - val_loss: 0.6060\n",
      "Epoch 7170/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0127 - val_loss: 0.5949\n",
      "Epoch 7171/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0239 - val_loss: 0.5908\n",
      "Epoch 7172/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0303 - val_loss: 0.6324\n",
      "Epoch 7173/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0220 - val_loss: 0.6181\n",
      "Epoch 7174/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0150 - val_loss: 0.6007\n",
      "Epoch 7175/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0183 - val_loss: 0.5806\n",
      "Epoch 7176/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0141 - val_loss: 0.6209\n",
      "Epoch 7177/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0182 - val_loss: 0.6462\n",
      "Epoch 7178/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0242 - val_loss: 0.6066\n",
      "Epoch 7179/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0326 - val_loss: 0.6259\n",
      "Epoch 7180/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0341 - val_loss: 0.6588\n",
      "Epoch 7181/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0335 - val_loss: 0.6362\n",
      "Epoch 7182/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0297 - val_loss: 0.6047\n",
      "Epoch 7183/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0160 - val_loss: 0.6149\n",
      "Epoch 7184/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0114 - val_loss: 0.5981\n",
      "Epoch 7185/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0144 - val_loss: 0.6161\n",
      "Epoch 7186/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0200 - val_loss: 0.6121\n",
      "Epoch 7187/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0194 - val_loss: 0.6333\n",
      "Epoch 7188/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0217 - val_loss: 0.5943\n",
      "Epoch 7189/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0300 - val_loss: 0.6069\n",
      "Epoch 7190/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0215 - val_loss: 0.6041\n",
      "Epoch 7191/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0285 - val_loss: 0.5969\n",
      "Epoch 7192/10000\n",
      "130/130 [==============================] - 0s 851us/step - loss: 0.0367 - val_loss: 0.5949\n",
      "Epoch 7193/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0250 - val_loss: 0.5889\n",
      "Epoch 7194/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0156 - val_loss: 0.5986\n",
      "Epoch 7195/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0202 - val_loss: 0.5976\n",
      "Epoch 7196/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0179 - val_loss: 0.5877\n",
      "Epoch 7197/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0120 - val_loss: 0.5854\n",
      "Epoch 7198/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0121 - val_loss: 0.6064\n",
      "Epoch 7199/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0272 - val_loss: 0.6271\n",
      "Epoch 7200/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0494 - val_loss: 0.6219\n",
      "Epoch 7201/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0529 - val_loss: 0.6338\n",
      "Epoch 7202/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0271 - val_loss: 0.6214\n",
      "Epoch 7203/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0179 - val_loss: 0.6061\n",
      "Epoch 7204/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0135 - val_loss: 0.5849\n",
      "Epoch 7205/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0197 - val_loss: 0.6117\n",
      "Epoch 7206/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0136 - val_loss: 0.6081\n",
      "Epoch 7207/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0272 - val_loss: 0.6308\n",
      "Epoch 7208/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0476 - val_loss: 0.6126\n",
      "Epoch 7209/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0260 - val_loss: 0.6243\n",
      "Epoch 7210/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0168 - val_loss: 0.6003\n",
      "Epoch 7211/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0119 - val_loss: 0.5894\n",
      "Epoch 7212/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0314 - val_loss: 0.5816\n",
      "Epoch 7213/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0459 - val_loss: 0.6100\n",
      "Epoch 7214/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0314 - val_loss: 0.5889\n",
      "Epoch 7215/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0146 - val_loss: 0.6297\n",
      "Epoch 7216/10000\n",
      "130/130 [==============================] - 0s 820us/step - loss: 0.0116 - val_loss: 0.6169\n",
      "Epoch 7217/10000\n",
      "130/130 [==============================] - 0s 894us/step - loss: 0.0150 - val_loss: 0.5962\n",
      "Epoch 7218/10000\n",
      "130/130 [==============================] - 0s 825us/step - loss: 0.0181 - val_loss: 0.5959\n",
      "Epoch 7219/10000\n",
      "130/130 [==============================] - 0s 846us/step - loss: 0.0195 - val_loss: 0.6057\n",
      "Epoch 7220/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0139 - val_loss: 0.5945\n",
      "Epoch 7221/10000\n",
      "130/130 [==============================] - 0s 716us/step - loss: 0.0171 - val_loss: 0.6308\n",
      "Epoch 7222/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0215 - val_loss: 0.6050\n",
      "Epoch 7223/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 769us/step - loss: 0.0937 - val_loss: 0.6212\n",
      "Epoch 7224/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0797 - val_loss: 0.5955\n",
      "Epoch 7225/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0313 - val_loss: 0.6068\n",
      "Epoch 7226/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0195 - val_loss: 0.6046\n",
      "Epoch 7227/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0203 - val_loss: 0.5790\n",
      "Epoch 7228/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0123 - val_loss: 0.6035\n",
      "Epoch 7229/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0102 - val_loss: 0.5960\n",
      "Epoch 7230/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0105 - val_loss: 0.6080\n",
      "Epoch 7231/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0141 - val_loss: 0.6116\n",
      "Epoch 7232/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0456 - val_loss: 0.6005\n",
      "Epoch 7233/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0324 - val_loss: 0.6035\n",
      "Epoch 7234/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0127 - val_loss: 0.5969\n",
      "Epoch 7235/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0203 - val_loss: 0.6126\n",
      "Epoch 7236/10000\n",
      "130/130 [==============================] - 0s 1ms/step - loss: 0.0191 - val_loss: 0.5998\n",
      "Epoch 7237/10000\n",
      "130/130 [==============================] - 0s 950us/step - loss: 0.0272 - val_loss: 0.6198\n",
      "Epoch 7238/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0211 - val_loss: 0.5953\n",
      "Epoch 7239/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0182 - val_loss: 0.5993\n",
      "Epoch 7240/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0307 - val_loss: 0.6034\n",
      "Epoch 7241/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0255 - val_loss: 0.6121\n",
      "Epoch 7242/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0147 - val_loss: 0.6147\n",
      "Epoch 7243/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0228 - val_loss: 0.6145\n",
      "Epoch 7244/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0227 - val_loss: 0.6224\n",
      "Epoch 7245/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0255 - val_loss: 0.6394\n",
      "Epoch 7246/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0262 - val_loss: 0.5959\n",
      "Epoch 7247/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0224 - val_loss: 0.6013\n",
      "Epoch 7248/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0123 - val_loss: 0.5927\n",
      "Epoch 7249/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0166 - val_loss: 0.5900\n",
      "Epoch 7250/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0185 - val_loss: 0.6103\n",
      "Epoch 7251/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0403 - val_loss: 0.5985\n",
      "Epoch 7252/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0265 - val_loss: 0.6134\n",
      "Epoch 7253/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0215 - val_loss: 0.5925\n",
      "Epoch 7254/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0216 - val_loss: 0.5923\n",
      "Epoch 7255/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0221 - val_loss: 0.6101\n",
      "Epoch 7256/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0155 - val_loss: 0.5819\n",
      "Epoch 7257/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0194 - val_loss: 0.6067\n",
      "Epoch 7258/10000\n",
      "130/130 [==============================] - 0s 936us/step - loss: 0.0267 - val_loss: 0.6332\n",
      "Epoch 7259/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0237 - val_loss: 0.5945\n",
      "Epoch 7260/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0213 - val_loss: 0.6242\n",
      "Epoch 7261/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0507 - val_loss: 0.6158\n",
      "Epoch 7262/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0555 - val_loss: 0.6269\n",
      "Epoch 7263/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0225 - val_loss: 0.6029\n",
      "Epoch 7264/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0119 - val_loss: 0.6001\n",
      "Epoch 7265/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0132 - val_loss: 0.5970\n",
      "Epoch 7266/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0088 - val_loss: 0.6030\n",
      "Epoch 7267/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0121 - val_loss: 0.6256\n",
      "Epoch 7268/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0140 - val_loss: 0.6211\n",
      "Epoch 7269/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0110 - val_loss: 0.5975\n",
      "Epoch 7270/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0289 - val_loss: 0.6252\n",
      "Epoch 7271/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0510 - val_loss: 0.6077\n",
      "Epoch 7272/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0314 - val_loss: 0.5799\n",
      "Epoch 7273/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0350 - val_loss: 0.5898\n",
      "Epoch 7274/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0281 - val_loss: 0.5756\n",
      "Epoch 7275/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0169 - val_loss: 0.6073\n",
      "Epoch 7276/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0102 - val_loss: 0.6005\n",
      "Epoch 7277/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0258 - val_loss: 0.6053\n",
      "Epoch 7278/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0795 - val_loss: 0.6291\n",
      "Epoch 7279/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0777 - val_loss: 0.6255\n",
      "Epoch 7280/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0216 - val_loss: 0.6029\n",
      "Epoch 7281/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0141 - val_loss: 0.6448\n",
      "Epoch 7282/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0100 - val_loss: 0.6044\n",
      "Epoch 7283/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0085 - val_loss: 0.6161\n",
      "Epoch 7284/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0126 - val_loss: 0.6071\n",
      "Epoch 7285/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0147 - val_loss: 0.6295\n",
      "Epoch 7286/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0191 - val_loss: 0.6150\n",
      "Epoch 7287/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0151 - val_loss: 0.6324\n",
      "Epoch 7288/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0208 - val_loss: 0.6125\n",
      "Epoch 7289/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0168 - val_loss: 0.5796\n",
      "Epoch 7290/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0285 - val_loss: 0.6524\n",
      "Epoch 7291/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0302 - val_loss: 0.6325\n",
      "Epoch 7292/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0397 - val_loss: 0.6134\n",
      "Epoch 7293/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0381 - val_loss: 0.6215\n",
      "Epoch 7294/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0246 - val_loss: 0.6358\n",
      "Epoch 7295/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0220 - val_loss: 0.6057\n",
      "Epoch 7296/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0254 - val_loss: 0.6125\n",
      "Epoch 7297/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0207 - val_loss: 0.6074\n",
      "Epoch 7298/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0135 - val_loss: 0.5986\n",
      "Epoch 7299/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 732us/step - loss: 0.0146 - val_loss: 0.6063\n",
      "Epoch 7300/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0093 - val_loss: 0.6225\n",
      "Epoch 7301/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0094 - val_loss: 0.6074\n",
      "Epoch 7302/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0190 - val_loss: 0.6053\n",
      "Epoch 7303/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0547 - val_loss: 0.6368\n",
      "Epoch 7304/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0821 - val_loss: 0.6119\n",
      "Epoch 7305/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0403 - val_loss: 0.6198\n",
      "Epoch 7306/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0227 - val_loss: 0.6402\n",
      "Epoch 7307/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0183 - val_loss: 0.6130\n",
      "Epoch 7308/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0148 - val_loss: 0.5977\n",
      "Epoch 7309/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0187 - val_loss: 0.5916\n",
      "Epoch 7310/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0180 - val_loss: 0.6127\n",
      "Epoch 7311/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0193 - val_loss: 0.6062\n",
      "Epoch 7312/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0167 - val_loss: 0.5929\n",
      "Epoch 7313/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0189 - val_loss: 0.6029\n",
      "Epoch 7314/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0221 - val_loss: 0.6075\n",
      "Epoch 7315/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0231 - val_loss: 0.6058\n",
      "Epoch 7316/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0304 - val_loss: 0.6016\n",
      "Epoch 7317/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0212 - val_loss: 0.6118\n",
      "Epoch 7318/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0183 - val_loss: 0.6106\n",
      "Epoch 7319/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0207 - val_loss: 0.5918\n",
      "Epoch 7320/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0180 - val_loss: 0.6365\n",
      "Epoch 7321/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0168 - val_loss: 0.6012\n",
      "Epoch 7322/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0182 - val_loss: 0.6331\n",
      "Epoch 7323/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0174 - val_loss: 0.5938\n",
      "Epoch 7324/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0298 - val_loss: 0.5713\n",
      "Epoch 7325/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0247 - val_loss: 0.6092\n",
      "Epoch 7326/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0331 - val_loss: 0.5980\n",
      "Epoch 7327/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0307 - val_loss: 0.6015\n",
      "Epoch 7328/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0215 - val_loss: 0.6170\n",
      "Epoch 7329/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0124 - val_loss: 0.5888\n",
      "Epoch 7330/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0226 - val_loss: 0.6151\n",
      "Epoch 7331/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0175 - val_loss: 0.5849\n",
      "Epoch 7332/10000\n",
      "130/130 [==============================] - 0s 880us/step - loss: 0.0452 - val_loss: 0.6307\n",
      "Epoch 7333/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0364 - val_loss: 0.6201\n",
      "Epoch 7334/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0238 - val_loss: 0.6296\n",
      "Epoch 7335/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0183 - val_loss: 0.6397\n",
      "Epoch 7336/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0320 - val_loss: 0.5957\n",
      "Epoch 7337/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0405 - val_loss: 0.5824\n",
      "Epoch 7338/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0341 - val_loss: 0.5816\n",
      "Epoch 7339/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0241 - val_loss: 0.6290\n",
      "Epoch 7340/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0235 - val_loss: 0.6116\n",
      "Epoch 7341/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0193 - val_loss: 0.6039\n",
      "Epoch 7342/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0140 - val_loss: 0.6051\n",
      "Epoch 7343/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0073 - val_loss: 0.6192\n",
      "Epoch 7344/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0072 - val_loss: 0.6018\n",
      "Epoch 7345/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0068 - val_loss: 0.6171\n",
      "Epoch 7346/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0125 - val_loss: 0.5883\n",
      "Epoch 7347/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0359 - val_loss: 0.5861\n",
      "Epoch 7348/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0489 - val_loss: 0.6206\n",
      "Epoch 7349/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0498 - val_loss: 0.6129\n",
      "Epoch 7350/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0187 - val_loss: 0.6130\n",
      "Epoch 7351/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0146 - val_loss: 0.5900\n",
      "Epoch 7352/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0189 - val_loss: 0.6223\n",
      "Epoch 7353/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0193 - val_loss: 0.6129\n",
      "Epoch 7354/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0156 - val_loss: 0.6108\n",
      "Epoch 7355/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0198 - val_loss: 0.6196\n",
      "Epoch 7356/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0232 - val_loss: 0.5823\n",
      "Epoch 7357/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0310 - val_loss: 0.6261\n",
      "Epoch 7358/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0336 - val_loss: 0.6372\n",
      "Epoch 7359/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0279 - val_loss: 0.5847\n",
      "Epoch 7360/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0206 - val_loss: 0.6076\n",
      "Epoch 7361/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0176 - val_loss: 0.6328\n",
      "Epoch 7362/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0242 - val_loss: 0.6109\n",
      "Epoch 7363/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0247 - val_loss: 0.6023\n",
      "Epoch 7364/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0273 - val_loss: 0.6441\n",
      "Epoch 7365/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0272 - val_loss: 0.6168\n",
      "Epoch 7366/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0259 - val_loss: 0.6276\n",
      "Epoch 7367/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0191 - val_loss: 0.6137\n",
      "Epoch 7368/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0100 - val_loss: 0.6230\n",
      "Epoch 7369/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0131 - val_loss: 0.5934\n",
      "Epoch 7370/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0252 - val_loss: 0.6088\n",
      "Epoch 7371/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0252 - val_loss: 0.6224\n",
      "Epoch 7372/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0219 - val_loss: 0.6197\n",
      "Epoch 7373/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0280 - val_loss: 0.5962\n",
      "Epoch 7374/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0379 - val_loss: 0.6166\n",
      "Epoch 7375/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 765us/step - loss: 0.0294 - val_loss: 0.6111\n",
      "Epoch 7376/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0249 - val_loss: 0.6089\n",
      "Epoch 7377/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0291 - val_loss: 0.5824\n",
      "Epoch 7378/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0261 - val_loss: 0.6015\n",
      "Epoch 7379/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0191 - val_loss: 0.6089\n",
      "Epoch 7380/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0125 - val_loss: 0.6108\n",
      "Epoch 7381/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0102 - val_loss: 0.6243\n",
      "Epoch 7382/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0171 - val_loss: 0.6294\n",
      "Epoch 7383/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0361 - val_loss: 0.6086\n",
      "Epoch 7384/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0322 - val_loss: 0.5963\n",
      "Epoch 7385/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0348 - val_loss: 0.5941\n",
      "Epoch 7386/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0236 - val_loss: 0.5917\n",
      "Epoch 7387/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0168 - val_loss: 0.6113\n",
      "Epoch 7388/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0249 - val_loss: 0.6315\n",
      "Epoch 7389/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0391 - val_loss: 0.6158\n",
      "Epoch 7390/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0468 - val_loss: 0.6375\n",
      "Epoch 7391/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0288 - val_loss: 0.5909\n",
      "Epoch 7392/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0271 - val_loss: 0.5858\n",
      "Epoch 7393/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0127 - val_loss: 0.6009\n",
      "Epoch 7394/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0152 - val_loss: 0.5861\n",
      "Epoch 7395/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0169 - val_loss: 0.5982\n",
      "Epoch 7396/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0115 - val_loss: 0.6169\n",
      "Epoch 7397/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0118 - val_loss: 0.6046\n",
      "Epoch 7398/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0122 - val_loss: 0.6135\n",
      "Epoch 7399/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0135 - val_loss: 0.6026\n",
      "Epoch 7400/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0218 - val_loss: 0.6107\n",
      "Epoch 7401/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0390 - val_loss: 0.6359\n",
      "Epoch 7402/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0342 - val_loss: 0.5792\n",
      "Epoch 7403/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0393 - val_loss: 0.5899\n",
      "Epoch 7404/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0263 - val_loss: 0.6174\n",
      "Epoch 7405/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0435 - val_loss: 0.6244\n",
      "Epoch 7406/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0239 - val_loss: 0.6075\n",
      "Epoch 7407/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0161 - val_loss: 0.6448\n",
      "Epoch 7408/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0338 - val_loss: 0.6076\n",
      "Epoch 7409/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0202 - val_loss: 0.6152\n",
      "Epoch 7410/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0278 - val_loss: 0.5990\n",
      "Epoch 7411/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0352 - val_loss: 0.5937\n",
      "Epoch 7412/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0457 - val_loss: 0.6017\n",
      "Epoch 7413/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0220 - val_loss: 0.6038\n",
      "Epoch 7414/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0171 - val_loss: 0.5863\n",
      "Epoch 7415/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0158 - val_loss: 0.5860\n",
      "Epoch 7416/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0169 - val_loss: 0.6051\n",
      "Epoch 7417/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0172 - val_loss: 0.6090\n",
      "Epoch 7418/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0140 - val_loss: 0.6115\n",
      "Epoch 7419/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0132 - val_loss: 0.6155\n",
      "Epoch 7420/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0303 - val_loss: 0.6285\n",
      "Epoch 7421/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0664 - val_loss: 0.6198\n",
      "Epoch 7422/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0358 - val_loss: 0.5792\n",
      "Epoch 7423/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0186 - val_loss: 0.5957\n",
      "Epoch 7424/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0147 - val_loss: 0.6080\n",
      "Epoch 7425/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0137 - val_loss: 0.6155\n",
      "Epoch 7426/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0137 - val_loss: 0.5831\n",
      "Epoch 7427/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0177 - val_loss: 0.6019\n",
      "Epoch 7428/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0365 - val_loss: 0.6004\n",
      "Epoch 7429/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0167 - val_loss: 0.5891\n",
      "Epoch 7430/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0182 - val_loss: 0.5930\n",
      "Epoch 7431/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0138 - val_loss: 0.6157\n",
      "Epoch 7432/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0211 - val_loss: 0.6311\n",
      "Epoch 7433/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0123 - val_loss: 0.6032\n",
      "Epoch 7434/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0233 - val_loss: 0.6108\n",
      "Epoch 7435/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0361 - val_loss: 0.6229\n",
      "Epoch 7436/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0496 - val_loss: 0.6188\n",
      "Epoch 7437/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0403 - val_loss: 0.6029\n",
      "Epoch 7438/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0227 - val_loss: 0.6386\n",
      "Epoch 7439/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0256 - val_loss: 0.6112\n",
      "Epoch 7440/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0169 - val_loss: 0.6204\n",
      "Epoch 7441/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0122 - val_loss: 0.6197\n",
      "Epoch 7442/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0137 - val_loss: 0.6043\n",
      "Epoch 7443/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0350 - val_loss: 0.6163\n",
      "Epoch 7444/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0316 - val_loss: 0.6062\n",
      "Epoch 7445/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0261 - val_loss: 0.6209\n",
      "Epoch 7446/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0182 - val_loss: 0.6121\n",
      "Epoch 7447/10000\n",
      "130/130 [==============================] - 0s 810us/step - loss: 0.0262 - val_loss: 0.6302\n",
      "Epoch 7448/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0163 - val_loss: 0.6203\n",
      "Epoch 7449/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0250 - val_loss: 0.6171\n",
      "Epoch 7450/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0293 - val_loss: 0.6127\n",
      "Epoch 7451/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 781us/step - loss: 0.0343 - val_loss: 0.5800\n",
      "Epoch 7452/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0190 - val_loss: 0.5940\n",
      "Epoch 7453/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0272 - val_loss: 0.6161\n",
      "Epoch 7454/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0223 - val_loss: 0.6195\n",
      "Epoch 7455/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0304 - val_loss: 0.6095\n",
      "Epoch 7456/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0495 - val_loss: 0.6215\n",
      "Epoch 7457/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0215 - val_loss: 0.6064\n",
      "Epoch 7458/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0263 - val_loss: 0.5845\n",
      "Epoch 7459/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0174 - val_loss: 0.5970\n",
      "Epoch 7460/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0149 - val_loss: 0.5882\n",
      "Epoch 7461/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0096 - val_loss: 0.5914\n",
      "Epoch 7462/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0109 - val_loss: 0.6052\n",
      "Epoch 7463/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0089 - val_loss: 0.6044\n",
      "Epoch 7464/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0259 - val_loss: 0.6121\n",
      "Epoch 7465/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0505 - val_loss: 0.6024\n",
      "Epoch 7466/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0294 - val_loss: 0.6152\n",
      "Epoch 7467/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0124 - val_loss: 0.6003\n",
      "Epoch 7468/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0173 - val_loss: 0.5999\n",
      "Epoch 7469/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0312 - val_loss: 0.5983\n",
      "Epoch 7470/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0284 - val_loss: 0.5992\n",
      "Epoch 7471/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0274 - val_loss: 0.6068\n",
      "Epoch 7472/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0350 - val_loss: 0.6094\n",
      "Epoch 7473/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0160 - val_loss: 0.6101\n",
      "Epoch 7474/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0192 - val_loss: 0.6195\n",
      "Epoch 7475/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0251 - val_loss: 0.5998\n",
      "Epoch 7476/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0157 - val_loss: 0.5998\n",
      "Epoch 7477/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0262 - val_loss: 0.6181\n",
      "Epoch 7478/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0379 - val_loss: 0.5993\n",
      "Epoch 7479/10000\n",
      "130/130 [==============================] - 0s 896us/step - loss: 0.0236 - val_loss: 0.6257\n",
      "Epoch 7480/10000\n",
      "130/130 [==============================] - 0s 857us/step - loss: 0.0192 - val_loss: 0.5858\n",
      "Epoch 7481/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0252 - val_loss: 0.6162\n",
      "Epoch 7482/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0260 - val_loss: 0.5999\n",
      "Epoch 7483/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0134 - val_loss: 0.6148\n",
      "Epoch 7484/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0154 - val_loss: 0.6174\n",
      "Epoch 7485/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0150 - val_loss: 0.5965\n",
      "Epoch 7486/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0149 - val_loss: 0.5836\n",
      "Epoch 7487/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0215 - val_loss: 0.6530\n",
      "Epoch 7488/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0224 - val_loss: 0.6064\n",
      "Epoch 7489/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0195 - val_loss: 0.6137\n",
      "Epoch 7490/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0202 - val_loss: 0.5938\n",
      "Epoch 7491/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0188 - val_loss: 0.5960\n",
      "Epoch 7492/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0312 - val_loss: 0.6035\n",
      "Epoch 7493/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0332 - val_loss: 0.6206\n",
      "Epoch 7494/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0339 - val_loss: 0.6349\n",
      "Epoch 7495/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0137 - val_loss: 0.6211\n",
      "Epoch 7496/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0135 - val_loss: 0.6162\n",
      "Epoch 7497/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0110 - val_loss: 0.6155\n",
      "Epoch 7498/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0145 - val_loss: 0.6038\n",
      "Epoch 7499/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0229 - val_loss: 0.6230\n",
      "Epoch 7500/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0321 - val_loss: 0.6258\n",
      "Epoch 7501/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0362 - val_loss: 0.6327\n",
      "Epoch 7502/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0390 - val_loss: 0.6029\n",
      "Epoch 7503/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0385 - val_loss: 0.6278\n",
      "Epoch 7504/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0555 - val_loss: 0.6199\n",
      "Epoch 7505/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0377 - val_loss: 0.6160\n",
      "Epoch 7506/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0213 - val_loss: 0.5936\n",
      "Epoch 7507/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0132 - val_loss: 0.5963\n",
      "Epoch 7508/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0168 - val_loss: 0.6071\n",
      "Epoch 7509/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0168 - val_loss: 0.5995\n",
      "Epoch 7510/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0187 - val_loss: 0.6330\n",
      "Epoch 7511/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0152 - val_loss: 0.6198\n",
      "Epoch 7512/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0143 - val_loss: 0.6360\n",
      "Epoch 7513/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0259 - val_loss: 0.6158\n",
      "Epoch 7514/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0385 - val_loss: 0.6334\n",
      "Epoch 7515/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0274 - val_loss: 0.5947\n",
      "Epoch 7516/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0177 - val_loss: 0.6052\n",
      "Epoch 7517/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0175 - val_loss: 0.6190\n",
      "Epoch 7518/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0223 - val_loss: 0.5906\n",
      "Epoch 7519/10000\n",
      "130/130 [==============================] - 0s 873us/step - loss: 0.0261 - val_loss: 0.6132\n",
      "Epoch 7520/10000\n",
      "130/130 [==============================] - 0s 868us/step - loss: 0.0168 - val_loss: 0.6017\n",
      "Epoch 7521/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0147 - val_loss: 0.6023\n",
      "Epoch 7522/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0217 - val_loss: 0.6343\n",
      "Epoch 7523/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0355 - val_loss: 0.6169\n",
      "Epoch 7524/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0338 - val_loss: 0.6115\n",
      "Epoch 7525/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0224 - val_loss: 0.6650\n",
      "Epoch 7526/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0193 - val_loss: 0.5921\n",
      "Epoch 7527/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 766us/step - loss: 0.0149 - val_loss: 0.6220\n",
      "Epoch 7528/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0134 - val_loss: 0.6256\n",
      "Epoch 7529/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0167 - val_loss: 0.6290\n",
      "Epoch 7530/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0309 - val_loss: 0.6030\n",
      "Epoch 7531/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0191 - val_loss: 0.6191\n",
      "Epoch 7532/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0123 - val_loss: 0.5957\n",
      "Epoch 7533/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0279 - val_loss: 0.6133\n",
      "Epoch 7534/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0255 - val_loss: 0.6279\n",
      "Epoch 7535/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0254 - val_loss: 0.6326\n",
      "Epoch 7536/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0244 - val_loss: 0.6205\n",
      "Epoch 7537/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0218 - val_loss: 0.6002\n",
      "Epoch 7538/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0202 - val_loss: 0.6069\n",
      "Epoch 7539/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0279 - val_loss: 0.6020\n",
      "Epoch 7540/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0279 - val_loss: 0.6120\n",
      "Epoch 7541/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0285 - val_loss: 0.6105\n",
      "Epoch 7542/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0228 - val_loss: 0.6217\n",
      "Epoch 7543/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0176 - val_loss: 0.5795\n",
      "Epoch 7544/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0164 - val_loss: 0.6097\n",
      "Epoch 7545/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0253 - val_loss: 0.6156\n",
      "Epoch 7546/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0299 - val_loss: 0.5792\n",
      "Epoch 7547/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0312 - val_loss: 0.5941\n",
      "Epoch 7548/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0193 - val_loss: 0.6104\n",
      "Epoch 7549/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0141 - val_loss: 0.6136\n",
      "Epoch 7550/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0139 - val_loss: 0.6095\n",
      "Epoch 7551/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0252 - val_loss: 0.6185\n",
      "Epoch 7552/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0456 - val_loss: 0.6248\n",
      "Epoch 7553/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0495 - val_loss: 0.6100\n",
      "Epoch 7554/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0221 - val_loss: 0.5994\n",
      "Epoch 7555/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0137 - val_loss: 0.6074\n",
      "Epoch 7556/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0157 - val_loss: 0.6178\n",
      "Epoch 7557/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0268 - val_loss: 0.5806\n",
      "Epoch 7558/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0389 - val_loss: 0.6300\n",
      "Epoch 7559/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0237 - val_loss: 0.6274\n",
      "Epoch 7560/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0247 - val_loss: 0.6144\n",
      "Epoch 7561/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0330 - val_loss: 0.6062\n",
      "Epoch 7562/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0303 - val_loss: 0.6150\n",
      "Epoch 7563/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0194 - val_loss: 0.6042\n",
      "Epoch 7564/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0097 - val_loss: 0.6057\n",
      "Epoch 7565/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0103 - val_loss: 0.6164\n",
      "Epoch 7566/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0110 - val_loss: 0.6061\n",
      "Epoch 7567/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0092 - val_loss: 0.6102\n",
      "Epoch 7568/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0174 - val_loss: 0.6234\n",
      "Epoch 7569/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0400 - val_loss: 0.5801\n",
      "Epoch 7570/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0526 - val_loss: 0.6416\n",
      "Epoch 7571/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0367 - val_loss: 0.5893\n",
      "Epoch 7572/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0202 - val_loss: 0.6182\n",
      "Epoch 7573/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0241 - val_loss: 0.6023\n",
      "Epoch 7574/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0227 - val_loss: 0.6003\n",
      "Epoch 7575/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0194 - val_loss: 0.6002\n",
      "Epoch 7576/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0113 - val_loss: 0.5876\n",
      "Epoch 7577/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0153 - val_loss: 0.5851\n",
      "Epoch 7578/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0290 - val_loss: 0.6072\n",
      "Epoch 7579/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0238 - val_loss: 0.6051\n",
      "Epoch 7580/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0205 - val_loss: 0.5843\n",
      "Epoch 7581/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0176 - val_loss: 0.6239\n",
      "Epoch 7582/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0207 - val_loss: 0.6031\n",
      "Epoch 7583/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0407 - val_loss: 0.6330\n",
      "Epoch 7584/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0265 - val_loss: 0.6185\n",
      "Epoch 7585/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0145 - val_loss: 0.6080\n",
      "Epoch 7586/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0241 - val_loss: 0.6173\n",
      "Epoch 7587/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0201 - val_loss: 0.5921\n",
      "Epoch 7588/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0204 - val_loss: 0.6026\n",
      "Epoch 7589/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0160 - val_loss: 0.5819\n",
      "Epoch 7590/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0241 - val_loss: 0.5974\n",
      "Epoch 7591/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0305 - val_loss: 0.6063\n",
      "Epoch 7592/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0399 - val_loss: 0.6094\n",
      "Epoch 7593/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0307 - val_loss: 0.6025\n",
      "Epoch 7594/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0206 - val_loss: 0.5871\n",
      "Epoch 7595/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0217 - val_loss: 0.5924\n",
      "Epoch 7596/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0211 - val_loss: 0.6063\n",
      "Epoch 7597/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0257 - val_loss: 0.6082\n",
      "Epoch 7598/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0506 - val_loss: 0.6046\n",
      "Epoch 7599/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0460 - val_loss: 0.6215\n",
      "Epoch 7600/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0337 - val_loss: 0.5877\n",
      "Epoch 7601/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0110 - val_loss: 0.5991\n",
      "Epoch 7602/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0070 - val_loss: 0.6179\n",
      "Epoch 7603/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 760us/step - loss: 0.0108 - val_loss: 0.6030\n",
      "Epoch 7604/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0131 - val_loss: 0.5819\n",
      "Epoch 7605/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0182 - val_loss: 0.5877\n",
      "Epoch 7606/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0222 - val_loss: 0.6193\n",
      "Epoch 7607/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0220 - val_loss: 0.6001\n",
      "Epoch 7608/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0257 - val_loss: 0.6038\n",
      "Epoch 7609/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0327 - val_loss: 0.6003\n",
      "Epoch 7610/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0267 - val_loss: 0.6113\n",
      "Epoch 7611/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0390 - val_loss: 0.6205\n",
      "Epoch 7612/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0223 - val_loss: 0.5844\n",
      "Epoch 7613/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0126 - val_loss: 0.6183\n",
      "Epoch 7614/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0173 - val_loss: 0.6077\n",
      "Epoch 7615/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0610 - val_loss: 0.6736\n",
      "Epoch 7616/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0438 - val_loss: 0.6040\n",
      "Epoch 7617/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0243 - val_loss: 0.6001\n",
      "Epoch 7618/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0104 - val_loss: 0.6127\n",
      "Epoch 7619/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0099 - val_loss: 0.6045\n",
      "Epoch 7620/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0140 - val_loss: 0.6061\n",
      "Epoch 7621/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0197 - val_loss: 0.6166\n",
      "Epoch 7622/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0594 - val_loss: 0.6122\n",
      "Epoch 7623/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0654 - val_loss: 0.6018\n",
      "Epoch 7624/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0358 - val_loss: 0.6341\n",
      "Epoch 7625/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0210 - val_loss: 0.6162\n",
      "Epoch 7626/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0118 - val_loss: 0.6140\n",
      "Epoch 7627/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0117 - val_loss: 0.6233\n",
      "Epoch 7628/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0135 - val_loss: 0.5891\n",
      "Epoch 7629/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0138 - val_loss: 0.5768\n",
      "Epoch 7630/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0142 - val_loss: 0.6103\n",
      "Epoch 7631/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0178 - val_loss: 0.6260\n",
      "Epoch 7632/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0250 - val_loss: 0.6329\n",
      "Epoch 7633/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0233 - val_loss: 0.5927\n",
      "Epoch 7634/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0158 - val_loss: 0.6158\n",
      "Epoch 7635/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0202 - val_loss: 0.6044\n",
      "Epoch 7636/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0135 - val_loss: 0.6048\n",
      "Epoch 7637/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0120 - val_loss: 0.5967\n",
      "Epoch 7638/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0092 - val_loss: 0.6030\n",
      "Epoch 7639/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0622 - val_loss: 0.6081\n",
      "Epoch 7640/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0974 - val_loss: 0.6155\n",
      "Epoch 7641/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0440 - val_loss: 0.6234\n",
      "Epoch 7642/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0208 - val_loss: 0.5881\n",
      "Epoch 7643/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0178 - val_loss: 0.6203\n",
      "Epoch 7644/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0145 - val_loss: 0.6125\n",
      "Epoch 7645/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0133 - val_loss: 0.6215\n",
      "Epoch 7646/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0270 - val_loss: 0.6086\n",
      "Epoch 7647/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0212 - val_loss: 0.5995\n",
      "Epoch 7648/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0234 - val_loss: 0.6042\n",
      "Epoch 7649/10000\n",
      "130/130 [==============================] - 0s 826us/step - loss: 0.0158 - val_loss: 0.6142\n",
      "Epoch 7650/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0274 - val_loss: 0.5983\n",
      "Epoch 7651/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0204 - val_loss: 0.6251\n",
      "Epoch 7652/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0398 - val_loss: 0.6205\n",
      "Epoch 7653/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0381 - val_loss: 0.5796\n",
      "Epoch 7654/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0442 - val_loss: 0.6138\n",
      "Epoch 7655/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0308 - val_loss: 0.6039\n",
      "Epoch 7656/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0137 - val_loss: 0.5689\n",
      "Epoch 7657/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0080 - val_loss: 0.5994\n",
      "Epoch 7658/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0128 - val_loss: 0.5951\n",
      "Epoch 7659/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0219 - val_loss: 0.6141\n",
      "Epoch 7660/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0277 - val_loss: 0.6143\n",
      "Epoch 7661/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0313 - val_loss: 0.6390\n",
      "Epoch 7662/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0642 - val_loss: 0.5933\n",
      "Epoch 7663/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0294 - val_loss: 0.6048\n",
      "Epoch 7664/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0129 - val_loss: 0.5819\n",
      "Epoch 7665/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0132 - val_loss: 0.5893\n",
      "Epoch 7666/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0136 - val_loss: 0.6167\n",
      "Epoch 7667/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0183 - val_loss: 0.6482\n",
      "Epoch 7668/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0220 - val_loss: 0.5990\n",
      "Epoch 7669/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0193 - val_loss: 0.5965\n",
      "Epoch 7670/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0178 - val_loss: 0.6260\n",
      "Epoch 7671/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0129 - val_loss: 0.6162\n",
      "Epoch 7672/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0115 - val_loss: 0.6206\n",
      "Epoch 7673/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0150 - val_loss: 0.6145\n",
      "Epoch 7674/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0226 - val_loss: 0.6254\n",
      "Epoch 7675/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0386 - val_loss: 0.6089\n",
      "Epoch 7676/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0605 - val_loss: 0.6149\n",
      "Epoch 7677/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0455 - val_loss: 0.5911\n",
      "Epoch 7678/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0270 - val_loss: 0.6093\n",
      "Epoch 7679/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 751us/step - loss: 0.0175 - val_loss: 0.5807\n",
      "Epoch 7680/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0180 - val_loss: 0.6078\n",
      "Epoch 7681/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0153 - val_loss: 0.6188\n",
      "Epoch 7682/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0097 - val_loss: 0.5946\n",
      "Epoch 7683/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0091 - val_loss: 0.6255\n",
      "Epoch 7684/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0156 - val_loss: 0.5747\n",
      "Epoch 7685/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0426 - val_loss: 0.6228\n",
      "Epoch 7686/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0381 - val_loss: 0.6041\n",
      "Epoch 7687/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0149 - val_loss: 0.6087\n",
      "Epoch 7688/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0226 - val_loss: 0.6324\n",
      "Epoch 7689/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0181 - val_loss: 0.6059\n",
      "Epoch 7690/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0297 - val_loss: 0.6112\n",
      "Epoch 7691/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0419 - val_loss: 0.6214\n",
      "Epoch 7692/10000\n",
      "130/130 [==============================] - 0s 803us/step - loss: 0.0303 - val_loss: 0.5861\n",
      "Epoch 7693/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0247 - val_loss: 0.6052\n",
      "Epoch 7694/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0245 - val_loss: 0.6122\n",
      "Epoch 7695/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0151 - val_loss: 0.6112\n",
      "Epoch 7696/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0174 - val_loss: 0.5996\n",
      "Epoch 7697/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0162 - val_loss: 0.6175\n",
      "Epoch 7698/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0181 - val_loss: 0.5945\n",
      "Epoch 7699/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0249 - val_loss: 0.6049\n",
      "Epoch 7700/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0227 - val_loss: 0.6079\n",
      "Epoch 7701/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0200 - val_loss: 0.6285\n",
      "Epoch 7702/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0209 - val_loss: 0.5910\n",
      "Epoch 7703/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0340 - val_loss: 0.5810\n",
      "Epoch 7704/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0254 - val_loss: 0.6099\n",
      "Epoch 7705/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0144 - val_loss: 0.5961\n",
      "Epoch 7706/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0135 - val_loss: 0.6157\n",
      "Epoch 7707/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0213 - val_loss: 0.6028\n",
      "Epoch 7708/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0177 - val_loss: 0.6028\n",
      "Epoch 7709/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0272 - val_loss: 0.5798\n",
      "Epoch 7710/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0142 - val_loss: 0.6027\n",
      "Epoch 7711/10000\n",
      "130/130 [==============================] - 0s 829us/step - loss: 0.0140 - val_loss: 0.5975\n",
      "Epoch 7712/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0152 - val_loss: 0.6160\n",
      "Epoch 7713/10000\n",
      "130/130 [==============================] - 0s 809us/step - loss: 0.0744 - val_loss: 0.5866\n",
      "Epoch 7714/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0550 - val_loss: 0.5936\n",
      "Epoch 7715/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0359 - val_loss: 0.5951\n",
      "Epoch 7716/10000\n",
      "130/130 [==============================] - 0s 796us/step - loss: 0.0202 - val_loss: 0.6116\n",
      "Epoch 7717/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0128 - val_loss: 0.5996\n",
      "Epoch 7718/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0109 - val_loss: 0.5965\n",
      "Epoch 7719/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0132 - val_loss: 0.6051\n",
      "Epoch 7720/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0143 - val_loss: 0.6087\n",
      "Epoch 7721/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0154 - val_loss: 0.6220\n",
      "Epoch 7722/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0104 - val_loss: 0.6163\n",
      "Epoch 7723/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0139 - val_loss: 0.6280\n",
      "Epoch 7724/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0652 - val_loss: 0.6148\n",
      "Epoch 7725/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0497 - val_loss: 0.6334\n",
      "Epoch 7726/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0261 - val_loss: 0.6211\n",
      "Epoch 7727/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0139 - val_loss: 0.5979\n",
      "Epoch 7728/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0114 - val_loss: 0.6211\n",
      "Epoch 7729/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0078 - val_loss: 0.6174\n",
      "Epoch 7730/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0074 - val_loss: 0.6065\n",
      "Epoch 7731/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0133 - val_loss: 0.6404\n",
      "Epoch 7732/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0248 - val_loss: 0.5942\n",
      "Epoch 7733/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0376 - val_loss: 0.5976\n",
      "Epoch 7734/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0383 - val_loss: 0.6252\n",
      "Epoch 7735/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0502 - val_loss: 0.5848\n",
      "Epoch 7736/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0249 - val_loss: 0.5970\n",
      "Epoch 7737/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0220 - val_loss: 0.6055\n",
      "Epoch 7738/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0241 - val_loss: 0.6027\n",
      "Epoch 7739/10000\n",
      "130/130 [==============================] - 0s 833us/step - loss: 0.0156 - val_loss: 0.5934\n",
      "Epoch 7740/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0229 - val_loss: 0.6212\n",
      "Epoch 7741/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0242 - val_loss: 0.6181\n",
      "Epoch 7742/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0387 - val_loss: 0.5933\n",
      "Epoch 7743/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0184 - val_loss: 0.6491\n",
      "Epoch 7744/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0153 - val_loss: 0.6004\n",
      "Epoch 7745/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0102 - val_loss: 0.6035\n",
      "Epoch 7746/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0153 - val_loss: 0.6059\n",
      "Epoch 7747/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0587 - val_loss: 0.6052\n",
      "Epoch 7748/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0898 - val_loss: 0.5977\n",
      "Epoch 7749/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0541 - val_loss: 0.6082\n",
      "Epoch 7750/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0172 - val_loss: 0.6070\n",
      "Epoch 7751/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0133 - val_loss: 0.6152\n",
      "Epoch 7752/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0166 - val_loss: 0.5950\n",
      "Epoch 7753/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0121 - val_loss: 0.6142\n",
      "Epoch 7754/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0173 - val_loss: 0.6034\n",
      "Epoch 7755/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 746us/step - loss: 0.0240 - val_loss: 0.6206\n",
      "Epoch 7756/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0183 - val_loss: 0.6254\n",
      "Epoch 7757/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0143 - val_loss: 0.6084\n",
      "Epoch 7758/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0117 - val_loss: 0.6183\n",
      "Epoch 7759/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0100 - val_loss: 0.6222\n",
      "Epoch 7760/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0078 - val_loss: 0.6339\n",
      "Epoch 7761/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0111 - val_loss: 0.6016\n",
      "Epoch 7762/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0211 - val_loss: 0.6114\n",
      "Epoch 7763/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0547 - val_loss: 0.6027\n",
      "Epoch 7764/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0386 - val_loss: 0.5770\n",
      "Epoch 7765/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0312 - val_loss: 0.6377\n",
      "Epoch 7766/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0281 - val_loss: 0.5968\n",
      "Epoch 7767/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0212 - val_loss: 0.5990\n",
      "Epoch 7768/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0177 - val_loss: 0.5760\n",
      "Epoch 7769/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0162 - val_loss: 0.5955\n",
      "Epoch 7770/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0163 - val_loss: 0.5664\n",
      "Epoch 7771/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0168 - val_loss: 0.6056\n",
      "Epoch 7772/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0166 - val_loss: 0.6074\n",
      "Epoch 7773/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0461 - val_loss: 0.6401\n",
      "Epoch 7774/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0574 - val_loss: 0.6001\n",
      "Epoch 7775/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0304 - val_loss: 0.5924\n",
      "Epoch 7776/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0213 - val_loss: 0.5900\n",
      "Epoch 7777/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0129 - val_loss: 0.6132\n",
      "Epoch 7778/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0164 - val_loss: 0.6439\n",
      "Epoch 7779/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0180 - val_loss: 0.5989\n",
      "Epoch 7780/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0137 - val_loss: 0.5998\n",
      "Epoch 7781/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0183 - val_loss: 0.6043\n",
      "Epoch 7782/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0221 - val_loss: 0.5942\n",
      "Epoch 7783/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0296 - val_loss: 0.5931\n",
      "Epoch 7784/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0209 - val_loss: 0.6002\n",
      "Epoch 7785/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0174 - val_loss: 0.5795\n",
      "Epoch 7786/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0139 - val_loss: 0.6008\n",
      "Epoch 7787/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0113 - val_loss: 0.6220\n",
      "Epoch 7788/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0157 - val_loss: 0.6039\n",
      "Epoch 7789/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0422 - val_loss: 0.5931\n",
      "Epoch 7790/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0456 - val_loss: 0.5985\n",
      "Epoch 7791/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0296 - val_loss: 0.5845\n",
      "Epoch 7792/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0162 - val_loss: 0.6141\n",
      "Epoch 7793/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0229 - val_loss: 0.6363\n",
      "Epoch 7794/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0181 - val_loss: 0.6068\n",
      "Epoch 7795/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0280 - val_loss: 0.6180\n",
      "Epoch 7796/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0231 - val_loss: 0.6093\n",
      "Epoch 7797/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0184 - val_loss: 0.6083\n",
      "Epoch 7798/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0283 - val_loss: 0.6008\n",
      "Epoch 7799/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0303 - val_loss: 0.5934\n",
      "Epoch 7800/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0143 - val_loss: 0.6195\n",
      "Epoch 7801/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0165 - val_loss: 0.6478\n",
      "Epoch 7802/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0310 - val_loss: 0.5959\n",
      "Epoch 7803/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0291 - val_loss: 0.6078\n",
      "Epoch 7804/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0415 - val_loss: 0.6073\n",
      "Epoch 7805/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0283 - val_loss: 0.6129\n",
      "Epoch 7806/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0160 - val_loss: 0.6205\n",
      "Epoch 7807/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0153 - val_loss: 0.6320\n",
      "Epoch 7808/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0196 - val_loss: 0.6167\n",
      "Epoch 7809/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0088 - val_loss: 0.6206\n",
      "Epoch 7810/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0155 - val_loss: 0.6083\n",
      "Epoch 7811/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0229 - val_loss: 0.6180\n",
      "Epoch 7812/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0245 - val_loss: 0.6387\n",
      "Epoch 7813/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0434 - val_loss: 0.6230\n",
      "Epoch 7814/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0592 - val_loss: 0.5963\n",
      "Epoch 7815/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0274 - val_loss: 0.6120\n",
      "Epoch 7816/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0174 - val_loss: 0.6047\n",
      "Epoch 7817/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0145 - val_loss: 0.5743\n",
      "Epoch 7818/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0113 - val_loss: 0.6205\n",
      "Epoch 7819/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0083 - val_loss: 0.6026\n",
      "Epoch 7820/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0077 - val_loss: 0.6030\n",
      "Epoch 7821/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0078 - val_loss: 0.6046\n",
      "Epoch 7822/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0074 - val_loss: 0.5939\n",
      "Epoch 7823/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0060 - val_loss: 0.6007\n",
      "Epoch 7824/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0405 - val_loss: 0.6258\n",
      "Epoch 7825/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0855 - val_loss: 0.6216\n",
      "Epoch 7826/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0601 - val_loss: 0.5935\n",
      "Epoch 7827/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0487 - val_loss: 0.6257\n",
      "Epoch 7828/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0315 - val_loss: 0.5806\n",
      "Epoch 7829/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0265 - val_loss: 0.6158\n",
      "Epoch 7830/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0159 - val_loss: 0.5904\n",
      "Epoch 7831/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 759us/step - loss: 0.0120 - val_loss: 0.6001\n",
      "Epoch 7832/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0174 - val_loss: 0.5660\n",
      "Epoch 7833/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0134 - val_loss: 0.5791\n",
      "Epoch 7834/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0089 - val_loss: 0.5882\n",
      "Epoch 7835/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0133 - val_loss: 0.5795\n",
      "Epoch 7836/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0110 - val_loss: 0.6020\n",
      "Epoch 7837/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0113 - val_loss: 0.6127\n",
      "Epoch 7838/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0637 - val_loss: 0.6058\n",
      "Epoch 7839/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.1313 - val_loss: 0.6121\n",
      "Epoch 7840/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0566 - val_loss: 0.6241\n",
      "Epoch 7841/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0195 - val_loss: 0.6122\n",
      "Epoch 7842/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0141 - val_loss: 0.6269\n",
      "Epoch 7843/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0175 - val_loss: 0.5927\n",
      "Epoch 7844/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0132 - val_loss: 0.5930\n",
      "Epoch 7845/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0117 - val_loss: 0.6099\n",
      "Epoch 7846/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0148 - val_loss: 0.5914\n",
      "Epoch 7847/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0189 - val_loss: 0.6031\n",
      "Epoch 7848/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0144 - val_loss: 0.6117\n",
      "Epoch 7849/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0122 - val_loss: 0.5964\n",
      "Epoch 7850/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0506 - val_loss: 0.5698\n",
      "Epoch 7851/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0424 - val_loss: 0.5887\n",
      "Epoch 7852/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0324 - val_loss: 0.6138\n",
      "Epoch 7853/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0261 - val_loss: 0.6249\n",
      "Epoch 7854/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0175 - val_loss: 0.6230\n",
      "Epoch 7855/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0177 - val_loss: 0.6213\n",
      "Epoch 7856/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0146 - val_loss: 0.6168\n",
      "Epoch 7857/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0096 - val_loss: 0.6099\n",
      "Epoch 7858/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0099 - val_loss: 0.5958\n",
      "Epoch 7859/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0145 - val_loss: 0.6703\n",
      "Epoch 7860/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0417 - val_loss: 0.6136\n",
      "Epoch 7861/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0491 - val_loss: 0.5809\n",
      "Epoch 7862/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0528 - val_loss: 0.6179\n",
      "Epoch 7863/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0374 - val_loss: 0.6294\n",
      "Epoch 7864/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0183 - val_loss: 0.5976\n",
      "Epoch 7865/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0101 - val_loss: 0.5929\n",
      "Epoch 7866/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0071 - val_loss: 0.6065\n",
      "Epoch 7867/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0074 - val_loss: 0.6163\n",
      "Epoch 7868/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0107 - val_loss: 0.6122\n",
      "Epoch 7869/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0212 - val_loss: 0.6051\n",
      "Epoch 7870/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0269 - val_loss: 0.5734\n",
      "Epoch 7871/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0332 - val_loss: 0.6017\n",
      "Epoch 7872/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0601 - val_loss: 0.5677\n",
      "Epoch 7873/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0340 - val_loss: 0.5874\n",
      "Epoch 7874/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0133 - val_loss: 0.5994\n",
      "Epoch 7875/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0117 - val_loss: 0.5929\n",
      "Epoch 7876/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0307 - val_loss: 0.6080\n",
      "Epoch 7877/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0517 - val_loss: 0.6078\n",
      "Epoch 7878/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0242 - val_loss: 0.5962\n",
      "Epoch 7879/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0170 - val_loss: 0.6168\n",
      "Epoch 7880/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0192 - val_loss: 0.5981\n",
      "Epoch 7881/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0186 - val_loss: 0.6119\n",
      "Epoch 7882/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0140 - val_loss: 0.6074\n",
      "Epoch 7883/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0117 - val_loss: 0.6043\n",
      "Epoch 7884/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0099 - val_loss: 0.6002\n",
      "Epoch 7885/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0125 - val_loss: 0.6262\n",
      "Epoch 7886/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0271 - val_loss: 0.5822\n",
      "Epoch 7887/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0655 - val_loss: 0.6243\n",
      "Epoch 7888/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0655 - val_loss: 0.5997\n",
      "Epoch 7889/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0524 - val_loss: 0.6148\n",
      "Epoch 7890/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0283 - val_loss: 0.6163\n",
      "Epoch 7891/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0129 - val_loss: 0.6218\n",
      "Epoch 7892/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0122 - val_loss: 0.5929\n",
      "Epoch 7893/10000\n",
      "130/130 [==============================] - 0s 813us/step - loss: 0.0071 - val_loss: 0.5970\n",
      "Epoch 7894/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0057 - val_loss: 0.6110\n",
      "Epoch 7895/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0053 - val_loss: 0.5981\n",
      "Epoch 7896/10000\n",
      "130/130 [==============================] - 0s 833us/step - loss: 0.0065 - val_loss: 0.5995\n",
      "Epoch 7897/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0131 - val_loss: 0.6209\n",
      "Epoch 7898/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0252 - val_loss: 0.6107\n",
      "Epoch 7899/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0527 - val_loss: 0.6416\n",
      "Epoch 7900/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0566 - val_loss: 0.6312\n",
      "Epoch 7901/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0374 - val_loss: 0.6229\n",
      "Epoch 7902/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0175 - val_loss: 0.6007\n",
      "Epoch 7903/10000\n",
      "130/130 [==============================] - 0s 805us/step - loss: 0.0108 - val_loss: 0.6097\n",
      "Epoch 7904/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0118 - val_loss: 0.6147\n",
      "Epoch 7905/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0243 - val_loss: 0.6032\n",
      "Epoch 7906/10000\n",
      "130/130 [==============================] - 0s 893us/step - loss: 0.0392 - val_loss: 0.6170\n",
      "Epoch 7907/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 745us/step - loss: 0.0243 - val_loss: 0.6272\n",
      "Epoch 7908/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0166 - val_loss: 0.6252\n",
      "Epoch 7909/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0183 - val_loss: 0.5900\n",
      "Epoch 7910/10000\n",
      "130/130 [==============================] - 0s 792us/step - loss: 0.0355 - val_loss: 0.6040\n",
      "Epoch 7911/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0231 - val_loss: 0.6159\n",
      "Epoch 7912/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0228 - val_loss: 0.6011\n",
      "Epoch 7913/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0310 - val_loss: 0.6254\n",
      "Epoch 7914/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0131 - val_loss: 0.6220\n",
      "Epoch 7915/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0148 - val_loss: 0.6244\n",
      "Epoch 7916/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0183 - val_loss: 0.5953\n",
      "Epoch 7917/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0252 - val_loss: 0.6318\n",
      "Epoch 7918/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0437 - val_loss: 0.5957\n",
      "Epoch 7919/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0226 - val_loss: 0.6050\n",
      "Epoch 7920/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0299 - val_loss: 0.5868\n",
      "Epoch 7921/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0245 - val_loss: 0.5995\n",
      "Epoch 7922/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0248 - val_loss: 0.6003\n",
      "Epoch 7923/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0276 - val_loss: 0.6201\n",
      "Epoch 7924/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0261 - val_loss: 0.5939\n",
      "Epoch 7925/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0278 - val_loss: 0.6146\n",
      "Epoch 7926/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0217 - val_loss: 0.5962\n",
      "Epoch 7927/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0113 - val_loss: 0.5873\n",
      "Epoch 7928/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0119 - val_loss: 0.6020\n",
      "Epoch 7929/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0168 - val_loss: 0.6021\n",
      "Epoch 7930/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0274 - val_loss: 0.5937\n",
      "Epoch 7931/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0300 - val_loss: 0.6215\n",
      "Epoch 7932/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0467 - val_loss: 0.6691\n",
      "Epoch 7933/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0336 - val_loss: 0.6407\n",
      "Epoch 7934/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0232 - val_loss: 0.6227\n",
      "Epoch 7935/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0165 - val_loss: 0.6268\n",
      "Epoch 7936/10000\n",
      "130/130 [==============================] - 0s 810us/step - loss: 0.0150 - val_loss: 0.6113\n",
      "Epoch 7937/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0168 - val_loss: 0.6211\n",
      "Epoch 7938/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0247 - val_loss: 0.5879\n",
      "Epoch 7939/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0212 - val_loss: 0.6295\n",
      "Epoch 7940/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0251 - val_loss: 0.5941\n",
      "Epoch 7941/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0245 - val_loss: 0.5967\n",
      "Epoch 7942/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0176 - val_loss: 0.6069\n",
      "Epoch 7943/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0209 - val_loss: 0.6119\n",
      "Epoch 7944/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0183 - val_loss: 0.5850\n",
      "Epoch 7945/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0118 - val_loss: 0.5786\n",
      "Epoch 7946/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0239 - val_loss: 0.6008\n",
      "Epoch 7947/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0245 - val_loss: 0.6357\n",
      "Epoch 7948/10000\n",
      "130/130 [==============================] - 0s 822us/step - loss: 0.0367 - val_loss: 0.6067\n",
      "Epoch 7949/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0568 - val_loss: 0.6171\n",
      "Epoch 7950/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0212 - val_loss: 0.6005\n",
      "Epoch 7951/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0200 - val_loss: 0.5894\n",
      "Epoch 7952/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0220 - val_loss: 0.5996\n",
      "Epoch 7953/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0281 - val_loss: 0.6036\n",
      "Epoch 7954/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0318 - val_loss: 0.5928\n",
      "Epoch 7955/10000\n",
      "130/130 [==============================] - 0s 803us/step - loss: 0.0222 - val_loss: 0.6089\n",
      "Epoch 7956/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0194 - val_loss: 0.6209\n",
      "Epoch 7957/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0207 - val_loss: 0.6183\n",
      "Epoch 7958/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0310 - val_loss: 0.6100\n",
      "Epoch 7959/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0144 - val_loss: 0.6043\n",
      "Epoch 7960/10000\n",
      "130/130 [==============================] - 0s 804us/step - loss: 0.0136 - val_loss: 0.6107\n",
      "Epoch 7961/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0211 - val_loss: 0.6062\n",
      "Epoch 7962/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0346 - val_loss: 0.6152\n",
      "Epoch 7963/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0343 - val_loss: 0.6016\n",
      "Epoch 7964/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0204 - val_loss: 0.5951\n",
      "Epoch 7965/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0121 - val_loss: 0.5984\n",
      "Epoch 7966/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0158 - val_loss: 0.5944\n",
      "Epoch 7967/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0130 - val_loss: 0.6105\n",
      "Epoch 7968/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0092 - val_loss: 0.6048\n",
      "Epoch 7969/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0184 - val_loss: 0.6108\n",
      "Epoch 7970/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0487 - val_loss: 0.6228\n",
      "Epoch 7971/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0301 - val_loss: 0.5995\n",
      "Epoch 7972/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0311 - val_loss: 0.6047\n",
      "Epoch 7973/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0178 - val_loss: 0.5981\n",
      "Epoch 7974/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0125 - val_loss: 0.5948\n",
      "Epoch 7975/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0142 - val_loss: 0.5930\n",
      "Epoch 7976/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0087 - val_loss: 0.5993\n",
      "Epoch 7977/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0092 - val_loss: 0.6007\n",
      "Epoch 7978/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0160 - val_loss: 0.6225\n",
      "Epoch 7979/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0362 - val_loss: 0.5951\n",
      "Epoch 7980/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0438 - val_loss: 0.5988\n",
      "Epoch 7981/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0308 - val_loss: 0.6101\n",
      "Epoch 7982/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0330 - val_loss: 0.6311\n",
      "Epoch 7983/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 752us/step - loss: 0.0295 - val_loss: 0.5945\n",
      "Epoch 7984/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0280 - val_loss: 0.6124\n",
      "Epoch 7985/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0178 - val_loss: 0.5975\n",
      "Epoch 7986/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0107 - val_loss: 0.6098\n",
      "Epoch 7987/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0100 - val_loss: 0.6206\n",
      "Epoch 7988/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0205 - val_loss: 0.6278\n",
      "Epoch 7989/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0537 - val_loss: 0.6341\n",
      "Epoch 7990/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0323 - val_loss: 0.6345\n",
      "Epoch 7991/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0236 - val_loss: 0.6117\n",
      "Epoch 7992/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0185 - val_loss: 0.5999\n",
      "Epoch 7993/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0188 - val_loss: 0.6243\n",
      "Epoch 7994/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0193 - val_loss: 0.5904\n",
      "Epoch 7995/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0129 - val_loss: 0.5921\n",
      "Epoch 7996/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0088 - val_loss: 0.5721\n",
      "Epoch 7997/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0124 - val_loss: 0.6019\n",
      "Epoch 7998/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0212 - val_loss: 0.5982\n",
      "Epoch 7999/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0271 - val_loss: 0.6026\n",
      "Epoch 8000/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0250 - val_loss: 0.6447\n",
      "Epoch 8001/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0313 - val_loss: 0.6189\n",
      "Epoch 8002/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0563 - val_loss: 0.5987\n",
      "Epoch 8003/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0320 - val_loss: 0.6127\n",
      "Epoch 8004/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0307 - val_loss: 0.6010\n",
      "Epoch 8005/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0144 - val_loss: 0.6035\n",
      "Epoch 8006/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0121 - val_loss: 0.6132\n",
      "Epoch 8007/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0153 - val_loss: 0.6093\n",
      "Epoch 8008/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0231 - val_loss: 0.6414\n",
      "Epoch 8009/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0252 - val_loss: 0.6288\n",
      "Epoch 8010/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0201 - val_loss: 0.6237\n",
      "Epoch 8011/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0253 - val_loss: 0.6046\n",
      "Epoch 8012/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0212 - val_loss: 0.5965\n",
      "Epoch 8013/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0190 - val_loss: 0.6050\n",
      "Epoch 8014/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0113 - val_loss: 0.5831\n",
      "Epoch 8015/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0151 - val_loss: 0.6136\n",
      "Epoch 8016/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0148 - val_loss: 0.6226\n",
      "Epoch 8017/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0358 - val_loss: 0.5929\n",
      "Epoch 8018/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0442 - val_loss: 0.6280\n",
      "Epoch 8019/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0350 - val_loss: 0.6164\n",
      "Epoch 8020/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0258 - val_loss: 0.5941\n",
      "Epoch 8021/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0263 - val_loss: 0.5865\n",
      "Epoch 8022/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0219 - val_loss: 0.6151\n",
      "Epoch 8023/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0246 - val_loss: 0.6292\n",
      "Epoch 8024/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0364 - val_loss: 0.6209\n",
      "Epoch 8025/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0137 - val_loss: 0.6239\n",
      "Epoch 8026/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0124 - val_loss: 0.6137\n",
      "Epoch 8027/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0098 - val_loss: 0.6198\n",
      "Epoch 8028/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0083 - val_loss: 0.6200\n",
      "Epoch 8029/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0177 - val_loss: 0.6120\n",
      "Epoch 8030/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0287 - val_loss: 0.6344\n",
      "Epoch 8031/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0555 - val_loss: 0.5934\n",
      "Epoch 8032/10000\n",
      "130/130 [==============================] - 0s 816us/step - loss: 0.0516 - val_loss: 0.6266\n",
      "Epoch 8033/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0215 - val_loss: 0.6288\n",
      "Epoch 8034/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0161 - val_loss: 0.5831\n",
      "Epoch 8035/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0135 - val_loss: 0.6352\n",
      "Epoch 8036/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0129 - val_loss: 0.6060\n",
      "Epoch 8037/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0204 - val_loss: 0.5968\n",
      "Epoch 8038/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0278 - val_loss: 0.6170\n",
      "Epoch 8039/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0167 - val_loss: 0.6098\n",
      "Epoch 8040/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0174 - val_loss: 0.5971\n",
      "Epoch 8041/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0176 - val_loss: 0.6194\n",
      "Epoch 8042/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0223 - val_loss: 0.5880\n",
      "Epoch 8043/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0225 - val_loss: 0.6412\n",
      "Epoch 8044/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0276 - val_loss: 0.6144\n",
      "Epoch 8045/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0180 - val_loss: 0.6054\n",
      "Epoch 8046/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0290 - val_loss: 0.6494\n",
      "Epoch 8047/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0231 - val_loss: 0.5998\n",
      "Epoch 8048/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0233 - val_loss: 0.6128\n",
      "Epoch 8049/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0275 - val_loss: 0.5968\n",
      "Epoch 8050/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0247 - val_loss: 0.6143\n",
      "Epoch 8051/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0183 - val_loss: 0.6085\n",
      "Epoch 8052/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0214 - val_loss: 0.5849\n",
      "Epoch 8053/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0148 - val_loss: 0.6314\n",
      "Epoch 8054/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0180 - val_loss: 0.6322\n",
      "Epoch 8055/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0143 - val_loss: 0.6110\n",
      "Epoch 8056/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0203 - val_loss: 0.5952\n",
      "Epoch 8057/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0188 - val_loss: 0.6240\n",
      "Epoch 8058/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0200 - val_loss: 0.6074\n",
      "Epoch 8059/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 731us/step - loss: 0.0202 - val_loss: 0.5877\n",
      "Epoch 8060/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0300 - val_loss: 0.6439\n",
      "Epoch 8061/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0366 - val_loss: 0.5976\n",
      "Epoch 8062/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0520 - val_loss: 0.6194\n",
      "Epoch 8063/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0213 - val_loss: 0.5985\n",
      "Epoch 8064/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0195 - val_loss: 0.6276\n",
      "Epoch 8065/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0151 - val_loss: 0.6226\n",
      "Epoch 8066/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0100 - val_loss: 0.6369\n",
      "Epoch 8067/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0226 - val_loss: 0.6227\n",
      "Epoch 8068/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0201 - val_loss: 0.6018\n",
      "Epoch 8069/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0220 - val_loss: 0.6150\n",
      "Epoch 8070/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0213 - val_loss: 0.5966\n",
      "Epoch 8071/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0250 - val_loss: 0.6225\n",
      "Epoch 8072/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0158 - val_loss: 0.6108\n",
      "Epoch 8073/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0160 - val_loss: 0.5970\n",
      "Epoch 8074/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0141 - val_loss: 0.6035\n",
      "Epoch 8075/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0203 - val_loss: 0.5968\n",
      "Epoch 8076/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0212 - val_loss: 0.5965\n",
      "Epoch 8077/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0190 - val_loss: 0.6056\n",
      "Epoch 8078/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0154 - val_loss: 0.5912\n",
      "Epoch 8079/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0270 - val_loss: 0.6299\n",
      "Epoch 8080/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0354 - val_loss: 0.6019\n",
      "Epoch 8081/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0345 - val_loss: 0.5977\n",
      "Epoch 8082/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0185 - val_loss: 0.6055\n",
      "Epoch 8083/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0092 - val_loss: 0.6015\n",
      "Epoch 8084/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0085 - val_loss: 0.5942\n",
      "Epoch 8085/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0164 - val_loss: 0.6213\n",
      "Epoch 8086/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0492 - val_loss: 0.6190\n",
      "Epoch 8087/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0496 - val_loss: 0.6038\n",
      "Epoch 8088/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0412 - val_loss: 0.6486\n",
      "Epoch 8089/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0198 - val_loss: 0.5800\n",
      "Epoch 8090/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0157 - val_loss: 0.6293\n",
      "Epoch 8091/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0248 - val_loss: 0.6092\n",
      "Epoch 8092/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0220 - val_loss: 0.6120\n",
      "Epoch 8093/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0261 - val_loss: 0.6199\n",
      "Epoch 8094/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0243 - val_loss: 0.6052\n",
      "Epoch 8095/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0254 - val_loss: 0.6207\n",
      "Epoch 8096/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0165 - val_loss: 0.6154\n",
      "Epoch 8097/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0185 - val_loss: 0.6250\n",
      "Epoch 8098/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0252 - val_loss: 0.5992\n",
      "Epoch 8099/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0171 - val_loss: 0.5811\n",
      "Epoch 8100/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0128 - val_loss: 0.5921\n",
      "Epoch 8101/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0103 - val_loss: 0.6200\n",
      "Epoch 8102/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0145 - val_loss: 0.6232\n",
      "Epoch 8103/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0213 - val_loss: 0.5889\n",
      "Epoch 8104/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0243 - val_loss: 0.5976\n",
      "Epoch 8105/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0647 - val_loss: 0.5966\n",
      "Epoch 8106/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0531 - val_loss: 0.5726\n",
      "Epoch 8107/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0267 - val_loss: 0.5808\n",
      "Epoch 8108/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0143 - val_loss: 0.5809\n",
      "Epoch 8109/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0196 - val_loss: 0.6098\n",
      "Epoch 8110/10000\n",
      "130/130 [==============================] - 0s 826us/step - loss: 0.0239 - val_loss: 0.6300\n",
      "Epoch 8111/10000\n",
      "130/130 [==============================] - 0s 816us/step - loss: 0.0240 - val_loss: 0.6002\n",
      "Epoch 8112/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0174 - val_loss: 0.6388\n",
      "Epoch 8113/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0331 - val_loss: 0.6059\n",
      "Epoch 8114/10000\n",
      "130/130 [==============================] - 0s 806us/step - loss: 0.0364 - val_loss: 0.6271\n",
      "Epoch 8115/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0141 - val_loss: 0.6031\n",
      "Epoch 8116/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0098 - val_loss: 0.6072\n",
      "Epoch 8117/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0182 - val_loss: 0.5816\n",
      "Epoch 8118/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0238 - val_loss: 0.5811\n",
      "Epoch 8119/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0215 - val_loss: 0.6273\n",
      "Epoch 8120/10000\n",
      "130/130 [==============================] - 0s 846us/step - loss: 0.0198 - val_loss: 0.6314\n",
      "Epoch 8121/10000\n",
      "130/130 [==============================] - 0s 797us/step - loss: 0.0150 - val_loss: 0.5883\n",
      "Epoch 8122/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0161 - val_loss: 0.6207\n",
      "Epoch 8123/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0178 - val_loss: 0.6060\n",
      "Epoch 8124/10000\n",
      "130/130 [==============================] - 0s 787us/step - loss: 0.0202 - val_loss: 0.6255\n",
      "Epoch 8125/10000\n",
      "130/130 [==============================] - 0s 816us/step - loss: 0.0387 - val_loss: 0.5910\n",
      "Epoch 8126/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0250 - val_loss: 0.6042\n",
      "Epoch 8127/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0242 - val_loss: 0.6094\n",
      "Epoch 8128/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0304 - val_loss: 0.6432\n",
      "Epoch 8129/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0198 - val_loss: 0.6326\n",
      "Epoch 8130/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0232 - val_loss: 0.6052\n",
      "Epoch 8131/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0269 - val_loss: 0.6301\n",
      "Epoch 8132/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0224 - val_loss: 0.5963\n",
      "Epoch 8133/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0234 - val_loss: 0.6195\n",
      "Epoch 8134/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0219 - val_loss: 0.6083\n",
      "Epoch 8135/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 740us/step - loss: 0.0333 - val_loss: 0.5851\n",
      "Epoch 8136/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0200 - val_loss: 0.6118\n",
      "Epoch 8137/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0130 - val_loss: 0.5958\n",
      "Epoch 8138/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0094 - val_loss: 0.5984\n",
      "Epoch 8139/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0101 - val_loss: 0.5967\n",
      "Epoch 8140/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0136 - val_loss: 0.5681\n",
      "Epoch 8141/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0434 - val_loss: 0.6276\n",
      "Epoch 8142/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0321 - val_loss: 0.6061\n",
      "Epoch 8143/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0197 - val_loss: 0.6147\n",
      "Epoch 8144/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0231 - val_loss: 0.5974\n",
      "Epoch 8145/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0263 - val_loss: 0.6322\n",
      "Epoch 8146/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0266 - val_loss: 0.6167\n",
      "Epoch 8147/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0217 - val_loss: 0.6051\n",
      "Epoch 8148/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0118 - val_loss: 0.6066\n",
      "Epoch 8149/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0201 - val_loss: 0.6100\n",
      "Epoch 8150/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0194 - val_loss: 0.6219\n",
      "Epoch 8151/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0207 - val_loss: 0.6345\n",
      "Epoch 8152/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0189 - val_loss: 0.6060\n",
      "Epoch 8153/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0130 - val_loss: 0.6149\n",
      "Epoch 8154/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0145 - val_loss: 0.6404\n",
      "Epoch 8155/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0182 - val_loss: 0.6281\n",
      "Epoch 8156/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0328 - val_loss: 0.6484\n",
      "Epoch 8157/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0477 - val_loss: 0.6367\n",
      "Epoch 8158/10000\n",
      "130/130 [==============================] - 0s 810us/step - loss: 0.0229 - val_loss: 0.6362\n",
      "Epoch 8159/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0155 - val_loss: 0.6017\n",
      "Epoch 8160/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0234 - val_loss: 0.6152\n",
      "Epoch 8161/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0180 - val_loss: 0.5982\n",
      "Epoch 8162/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0163 - val_loss: 0.6041\n",
      "Epoch 8163/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0153 - val_loss: 0.6039\n",
      "Epoch 8164/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0075 - val_loss: 0.6090\n",
      "Epoch 8165/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0122 - val_loss: 0.5991\n",
      "Epoch 8166/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0197 - val_loss: 0.6042\n",
      "Epoch 8167/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0276 - val_loss: 0.6167\n",
      "Epoch 8168/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0397 - val_loss: 0.6485\n",
      "Epoch 8169/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0492 - val_loss: 0.6194\n",
      "Epoch 8170/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0379 - val_loss: 0.6168\n",
      "Epoch 8171/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0203 - val_loss: 0.6027\n",
      "Epoch 8172/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0162 - val_loss: 0.5888\n",
      "Epoch 8173/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0156 - val_loss: 0.6057\n",
      "Epoch 8174/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0110 - val_loss: 0.6167\n",
      "Epoch 8175/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0150 - val_loss: 0.6200\n",
      "Epoch 8176/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0130 - val_loss: 0.6356\n",
      "Epoch 8177/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0166 - val_loss: 0.6207\n",
      "Epoch 8178/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0152 - val_loss: 0.6090\n",
      "Epoch 8179/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0230 - val_loss: 0.6189\n",
      "Epoch 8180/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0304 - val_loss: 0.6020\n",
      "Epoch 8181/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0292 - val_loss: 0.6001\n",
      "Epoch 8182/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0215 - val_loss: 0.6380\n",
      "Epoch 8183/10000\n",
      "130/130 [==============================] - 0s 800us/step - loss: 0.0631 - val_loss: 0.6631\n",
      "Epoch 8184/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0718 - val_loss: 0.6232\n",
      "Epoch 8185/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0322 - val_loss: 0.6005\n",
      "Epoch 8186/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.0183 - val_loss: 0.6089\n",
      "Epoch 8187/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0160 - val_loss: 0.6062\n",
      "Epoch 8188/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0123 - val_loss: 0.6125\n",
      "Epoch 8189/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0129 - val_loss: 0.6064\n",
      "Epoch 8190/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0105 - val_loss: 0.6164\n",
      "Epoch 8191/10000\n",
      "130/130 [==============================] - 0s 807us/step - loss: 0.0197 - val_loss: 0.6053\n",
      "Epoch 8192/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0193 - val_loss: 0.6007\n",
      "Epoch 8193/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0151 - val_loss: 0.6117\n",
      "Epoch 8194/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0235 - val_loss: 0.6052\n",
      "Epoch 8195/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0338 - val_loss: 0.6274\n",
      "Epoch 8196/10000\n",
      "130/130 [==============================] - 0s 788us/step - loss: 0.0367 - val_loss: 0.6369\n",
      "Epoch 8197/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0262 - val_loss: 0.5977\n",
      "Epoch 8198/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0171 - val_loss: 0.6315\n",
      "Epoch 8199/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0165 - val_loss: 0.6430\n",
      "Epoch 8200/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0173 - val_loss: 0.6140\n",
      "Epoch 8201/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0232 - val_loss: 0.6149\n",
      "Epoch 8202/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0272 - val_loss: 0.6222\n",
      "Epoch 8203/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0127 - val_loss: 0.6178\n",
      "Epoch 8204/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0124 - val_loss: 0.6115\n",
      "Epoch 8205/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0399 - val_loss: 0.6322\n",
      "Epoch 8206/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0413 - val_loss: 0.6335\n",
      "Epoch 8207/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0141 - val_loss: 0.6232\n",
      "Epoch 8208/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0113 - val_loss: 0.6296\n",
      "Epoch 8209/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0124 - val_loss: 0.6302\n",
      "Epoch 8210/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0180 - val_loss: 0.6403\n",
      "Epoch 8211/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 729us/step - loss: 0.0239 - val_loss: 0.6272\n",
      "Epoch 8212/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0262 - val_loss: 0.6216\n",
      "Epoch 8213/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0389 - val_loss: 0.6034\n",
      "Epoch 8214/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0276 - val_loss: 0.6333\n",
      "Epoch 8215/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0418 - val_loss: 0.6002\n",
      "Epoch 8216/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0222 - val_loss: 0.6265\n",
      "Epoch 8217/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0204 - val_loss: 0.6029\n",
      "Epoch 8218/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0268 - val_loss: 0.6221\n",
      "Epoch 8219/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0207 - val_loss: 0.6103\n",
      "Epoch 8220/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0273 - val_loss: 0.6258\n",
      "Epoch 8221/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0192 - val_loss: 0.5966\n",
      "Epoch 8222/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0242 - val_loss: 0.6481\n",
      "Epoch 8223/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0176 - val_loss: 0.6350\n",
      "Epoch 8224/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0099 - val_loss: 0.6309\n",
      "Epoch 8225/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0081 - val_loss: 0.6273\n",
      "Epoch 8226/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0090 - val_loss: 0.6345\n",
      "Epoch 8227/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0179 - val_loss: 0.6351\n",
      "Epoch 8228/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0412 - val_loss: 0.6470\n",
      "Epoch 8229/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0468 - val_loss: 0.6105\n",
      "Epoch 8230/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0425 - val_loss: 0.6088\n",
      "Epoch 8231/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0298 - val_loss: 0.6146\n",
      "Epoch 8232/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0176 - val_loss: 0.5872\n",
      "Epoch 8233/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0182 - val_loss: 0.6533\n",
      "Epoch 8234/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0145 - val_loss: 0.5958\n",
      "Epoch 8235/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0170 - val_loss: 0.6208\n",
      "Epoch 8236/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0267 - val_loss: 0.6306\n",
      "Epoch 8237/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0212 - val_loss: 0.6171\n",
      "Epoch 8238/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0176 - val_loss: 0.6313\n",
      "Epoch 8239/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0193 - val_loss: 0.6394\n",
      "Epoch 8240/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0185 - val_loss: 0.5892\n",
      "Epoch 8241/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0227 - val_loss: 0.5793\n",
      "Epoch 8242/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0294 - val_loss: 0.6124\n",
      "Epoch 8243/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0108 - val_loss: 0.6177\n",
      "Epoch 8244/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0184 - val_loss: 0.6373\n",
      "Epoch 8245/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0182 - val_loss: 0.6166\n",
      "Epoch 8246/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0274 - val_loss: 0.6260\n",
      "Epoch 8247/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0595 - val_loss: 0.5940\n",
      "Epoch 8248/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0504 - val_loss: 0.6048\n",
      "Epoch 8249/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0289 - val_loss: 0.5833\n",
      "Epoch 8250/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0252 - val_loss: 0.6207\n",
      "Epoch 8251/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0119 - val_loss: 0.6134\n",
      "Epoch 8252/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0082 - val_loss: 0.6104\n",
      "Epoch 8253/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0071 - val_loss: 0.6318\n",
      "Epoch 8254/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0088 - val_loss: 0.6120\n",
      "Epoch 8255/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0091 - val_loss: 0.6430\n",
      "Epoch 8256/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0103 - val_loss: 0.6129\n",
      "Epoch 8257/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0210 - val_loss: 0.5988\n",
      "Epoch 8258/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0404 - val_loss: 0.6541\n",
      "Epoch 8259/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0513 - val_loss: 0.5765\n",
      "Epoch 8260/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0420 - val_loss: 0.6442\n",
      "Epoch 8261/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0350 - val_loss: 0.6022\n",
      "Epoch 8262/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0206 - val_loss: 0.6043\n",
      "Epoch 8263/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0153 - val_loss: 0.6005\n",
      "Epoch 8264/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0125 - val_loss: 0.6133\n",
      "Epoch 8265/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0110 - val_loss: 0.6099\n",
      "Epoch 8266/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0078 - val_loss: 0.6056\n",
      "Epoch 8267/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0104 - val_loss: 0.5928\n",
      "Epoch 8268/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0071 - val_loss: 0.6176\n",
      "Epoch 8269/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0124 - val_loss: 0.6187\n",
      "Epoch 8270/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0418 - val_loss: 0.6643\n",
      "Epoch 8271/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0602 - val_loss: 0.6309\n",
      "Epoch 8272/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0535 - val_loss: 0.6326\n",
      "Epoch 8273/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0303 - val_loss: 0.6059\n",
      "Epoch 8274/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0125 - val_loss: 0.6360\n",
      "Epoch 8275/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0113 - val_loss: 0.5912\n",
      "Epoch 8276/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0149 - val_loss: 0.6106\n",
      "Epoch 8277/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0138 - val_loss: 0.6246\n",
      "Epoch 8278/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0317 - val_loss: 0.6289\n",
      "Epoch 8279/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0839 - val_loss: 0.6218\n",
      "Epoch 8280/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0636 - val_loss: 0.5972\n",
      "Epoch 8281/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0235 - val_loss: 0.6212\n",
      "Epoch 8282/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0188 - val_loss: 0.6213\n",
      "Epoch 8283/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0163 - val_loss: 0.6261\n",
      "Epoch 8284/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0210 - val_loss: 0.6250\n",
      "Epoch 8285/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0089 - val_loss: 0.6076\n",
      "Epoch 8286/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0111 - val_loss: 0.5968\n",
      "Epoch 8287/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 741us/step - loss: 0.0255 - val_loss: 0.6093\n",
      "Epoch 8288/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0191 - val_loss: 0.5960\n",
      "Epoch 8289/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0133 - val_loss: 0.6237\n",
      "Epoch 8290/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0117 - val_loss: 0.6352\n",
      "Epoch 8291/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0101 - val_loss: 0.6255\n",
      "Epoch 8292/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0154 - val_loss: 0.6370\n",
      "Epoch 8293/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0308 - val_loss: 0.6343\n",
      "Epoch 8294/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0278 - val_loss: 0.5896\n",
      "Epoch 8295/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0160 - val_loss: 0.5976\n",
      "Epoch 8296/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0230 - val_loss: 0.6105\n",
      "Epoch 8297/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0395 - val_loss: 0.6315\n",
      "Epoch 8298/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0261 - val_loss: 0.6014\n",
      "Epoch 8299/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0140 - val_loss: 0.6234\n",
      "Epoch 8300/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0101 - val_loss: 0.6346\n",
      "Epoch 8301/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0092 - val_loss: 0.6220\n",
      "Epoch 8302/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0154 - val_loss: 0.6192\n",
      "Epoch 8303/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0414 - val_loss: 0.6343\n",
      "Epoch 8304/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0298 - val_loss: 0.6109\n",
      "Epoch 8305/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0171 - val_loss: 0.6116\n",
      "Epoch 8306/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0218 - val_loss: 0.6344\n",
      "Epoch 8307/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0149 - val_loss: 0.6176\n",
      "Epoch 8308/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0146 - val_loss: 0.6050\n",
      "Epoch 8309/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0098 - val_loss: 0.6275\n",
      "Epoch 8310/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0188 - val_loss: 0.6261\n",
      "Epoch 8311/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0274 - val_loss: 0.6098\n",
      "Epoch 8312/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0497 - val_loss: 0.6157\n",
      "Epoch 8313/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0298 - val_loss: 0.6240\n",
      "Epoch 8314/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0158 - val_loss: 0.6091\n",
      "Epoch 8315/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0246 - val_loss: 0.6117\n",
      "Epoch 8316/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0417 - val_loss: 0.6561\n",
      "Epoch 8317/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0393 - val_loss: 0.6023\n",
      "Epoch 8318/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0130 - val_loss: 0.6058\n",
      "Epoch 8319/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0066 - val_loss: 0.6132\n",
      "Epoch 8320/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0099 - val_loss: 0.6234\n",
      "Epoch 8321/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0246 - val_loss: 0.5919\n",
      "Epoch 8322/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0220 - val_loss: 0.5891\n",
      "Epoch 8323/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0207 - val_loss: 0.6001\n",
      "Epoch 8324/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0299 - val_loss: 0.5893\n",
      "Epoch 8325/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0189 - val_loss: 0.5912\n",
      "Epoch 8326/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0127 - val_loss: 0.6017\n",
      "Epoch 8327/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0143 - val_loss: 0.5757\n",
      "Epoch 8328/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0405 - val_loss: 0.5973\n",
      "Epoch 8329/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0437 - val_loss: 0.5880\n",
      "Epoch 8330/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0331 - val_loss: 0.5838\n",
      "Epoch 8331/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0180 - val_loss: 0.6025\n",
      "Epoch 8332/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0216 - val_loss: 0.6263\n",
      "Epoch 8333/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0191 - val_loss: 0.6150\n",
      "Epoch 8334/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0163 - val_loss: 0.5815\n",
      "Epoch 8335/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0187 - val_loss: 0.5905\n",
      "Epoch 8336/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0203 - val_loss: 0.6142\n",
      "Epoch 8337/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0159 - val_loss: 0.6223\n",
      "Epoch 8338/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0306 - val_loss: 0.5789\n",
      "Epoch 8339/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0312 - val_loss: 0.6463\n",
      "Epoch 8340/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0160 - val_loss: 0.6341\n",
      "Epoch 8341/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0152 - val_loss: 0.5944\n",
      "Epoch 8342/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0218 - val_loss: 0.6180\n",
      "Epoch 8343/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0186 - val_loss: 0.5815\n",
      "Epoch 8344/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0090 - val_loss: 0.6285\n",
      "Epoch 8345/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0072 - val_loss: 0.6324\n",
      "Epoch 8346/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0127 - val_loss: 0.6020\n",
      "Epoch 8347/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0219 - val_loss: 0.5949\n",
      "Epoch 8348/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0226 - val_loss: 0.6139\n",
      "Epoch 8349/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0386 - val_loss: 0.6342\n",
      "Epoch 8350/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0616 - val_loss: 0.6769\n",
      "Epoch 8351/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0407 - val_loss: 0.6196\n",
      "Epoch 8352/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.6105\n",
      "Epoch 8353/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0229 - val_loss: 0.6074\n",
      "Epoch 8354/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0162 - val_loss: 0.6204\n",
      "Epoch 8355/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0090 - val_loss: 0.5737\n",
      "Epoch 8356/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0082 - val_loss: 0.5847\n",
      "Epoch 8357/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0087 - val_loss: 0.5987\n",
      "Epoch 8358/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0068 - val_loss: 0.5978\n",
      "Epoch 8359/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0087 - val_loss: 0.5959\n",
      "Epoch 8360/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0137 - val_loss: 0.5792\n",
      "Epoch 8361/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0362 - val_loss: 0.5990\n",
      "Epoch 8362/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0709 - val_loss: 0.6208\n",
      "Epoch 8363/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 724us/step - loss: 0.0386 - val_loss: 0.6005\n",
      "Epoch 8364/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0270 - val_loss: 0.6033\n",
      "Epoch 8365/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0252 - val_loss: 0.5951\n",
      "Epoch 8366/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0206 - val_loss: 0.6091\n",
      "Epoch 8367/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0156 - val_loss: 0.6214\n",
      "Epoch 8368/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0110 - val_loss: 0.6087\n",
      "Epoch 8369/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0122 - val_loss: 0.6099\n",
      "Epoch 8370/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0236 - val_loss: 0.6143\n",
      "Epoch 8371/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0286 - val_loss: 0.5993\n",
      "Epoch 8372/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0312 - val_loss: 0.6182\n",
      "Epoch 8373/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0250 - val_loss: 0.5856\n",
      "Epoch 8374/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0459 - val_loss: 0.5837\n",
      "Epoch 8375/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0164 - val_loss: 0.5970\n",
      "Epoch 8376/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0122 - val_loss: 0.5904\n",
      "Epoch 8377/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0130 - val_loss: 0.6178\n",
      "Epoch 8378/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0173 - val_loss: 0.6059\n",
      "Epoch 8379/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0151 - val_loss: 0.6146\n",
      "Epoch 8380/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0151 - val_loss: 0.5805\n",
      "Epoch 8381/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0124 - val_loss: 0.6062\n",
      "Epoch 8382/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0146 - val_loss: 0.5860\n",
      "Epoch 8383/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0127 - val_loss: 0.5959\n",
      "Epoch 8384/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0230 - val_loss: 0.6129\n",
      "Epoch 8385/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0696 - val_loss: 0.6393\n",
      "Epoch 8386/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0620 - val_loss: 0.5518\n",
      "Epoch 8387/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0220 - val_loss: 0.5899\n",
      "Epoch 8388/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0250 - val_loss: 0.5712\n",
      "Epoch 8389/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0177 - val_loss: 0.6210\n",
      "Epoch 8390/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0102 - val_loss: 0.6068\n",
      "Epoch 8391/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0129 - val_loss: 0.6016\n",
      "Epoch 8392/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0164 - val_loss: 0.5859\n",
      "Epoch 8393/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0138 - val_loss: 0.5736\n",
      "Epoch 8394/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0150 - val_loss: 0.5886\n",
      "Epoch 8395/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0138 - val_loss: 0.5956\n",
      "Epoch 8396/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0133 - val_loss: 0.6008\n",
      "Epoch 8397/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0120 - val_loss: 0.5928\n",
      "Epoch 8398/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0143 - val_loss: 0.6211\n",
      "Epoch 8399/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0242 - val_loss: 0.6242\n",
      "Epoch 8400/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0337 - val_loss: 0.5836\n",
      "Epoch 8401/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0432 - val_loss: 0.5833\n",
      "Epoch 8402/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0382 - val_loss: 0.5868\n",
      "Epoch 8403/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0301 - val_loss: 0.6083\n",
      "Epoch 8404/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0154 - val_loss: 0.6130\n",
      "Epoch 8405/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0129 - val_loss: 0.6364\n",
      "Epoch 8406/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0248 - val_loss: 0.6183\n",
      "Epoch 8407/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0197 - val_loss: 0.6074\n",
      "Epoch 8408/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0160 - val_loss: 0.6258\n",
      "Epoch 8409/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0222 - val_loss: 0.6014\n",
      "Epoch 8410/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0300 - val_loss: 0.5889\n",
      "Epoch 8411/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0190 - val_loss: 0.6010\n",
      "Epoch 8412/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0379 - val_loss: 0.6267\n",
      "Epoch 8413/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0465 - val_loss: 0.6226\n",
      "Epoch 8414/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0282 - val_loss: 0.6014\n",
      "Epoch 8415/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0211 - val_loss: 0.6052\n",
      "Epoch 8416/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0147 - val_loss: 0.5983\n",
      "Epoch 8417/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0226 - val_loss: 0.6013\n",
      "Epoch 8418/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0214 - val_loss: 0.6077\n",
      "Epoch 8419/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0197 - val_loss: 0.6110\n",
      "Epoch 8420/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0099 - val_loss: 0.5882\n",
      "Epoch 8421/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0064 - val_loss: 0.6046\n",
      "Epoch 8422/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0054 - val_loss: 0.6133\n",
      "Epoch 8423/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0081 - val_loss: 0.6198\n",
      "Epoch 8424/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0069 - val_loss: 0.6301\n",
      "Epoch 8425/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0219 - val_loss: 0.6158\n",
      "Epoch 8426/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0421 - val_loss: 0.6053\n",
      "Epoch 8427/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0825 - val_loss: 0.6328\n",
      "Epoch 8428/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0547 - val_loss: 0.6375\n",
      "Epoch 8429/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0303 - val_loss: 0.6115\n",
      "Epoch 8430/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0177 - val_loss: 0.5974\n",
      "Epoch 8431/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0111 - val_loss: 0.6144\n",
      "Epoch 8432/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0130 - val_loss: 0.6220\n",
      "Epoch 8433/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0157 - val_loss: 0.6043\n",
      "Epoch 8434/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0355 - val_loss: 0.6264\n",
      "Epoch 8435/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0261 - val_loss: 0.5858\n",
      "Epoch 8436/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0296 - val_loss: 0.5854\n",
      "Epoch 8437/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0208 - val_loss: 0.5811\n",
      "Epoch 8438/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0115 - val_loss: 0.6050\n",
      "Epoch 8439/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 759us/step - loss: 0.0111 - val_loss: 0.5987\n",
      "Epoch 8440/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0110 - val_loss: 0.6025\n",
      "Epoch 8441/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0331 - val_loss: 0.6014\n",
      "Epoch 8442/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0636 - val_loss: 0.5993\n",
      "Epoch 8443/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0251 - val_loss: 0.6182\n",
      "Epoch 8444/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0163 - val_loss: 0.5958\n",
      "Epoch 8445/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0132 - val_loss: 0.6030\n",
      "Epoch 8446/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0131 - val_loss: 0.6203\n",
      "Epoch 8447/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0161 - val_loss: 0.6263\n",
      "Epoch 8448/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0144 - val_loss: 0.6230\n",
      "Epoch 8449/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0397 - val_loss: 0.6564\n",
      "Epoch 8450/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0462 - val_loss: 0.6019\n",
      "Epoch 8451/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0308 - val_loss: 0.6374\n",
      "Epoch 8452/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0263 - val_loss: 0.6476\n",
      "Epoch 8453/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0200 - val_loss: 0.6072\n",
      "Epoch 8454/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0208 - val_loss: 0.6278\n",
      "Epoch 8455/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0122 - val_loss: 0.5940\n",
      "Epoch 8456/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0094 - val_loss: 0.6241\n",
      "Epoch 8457/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0193 - val_loss: 0.6252\n",
      "Epoch 8458/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0142 - val_loss: 0.6051\n",
      "Epoch 8459/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0162 - val_loss: 0.5967\n",
      "Epoch 8460/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0188 - val_loss: 0.6063\n",
      "Epoch 8461/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0213 - val_loss: 0.6186\n",
      "Epoch 8462/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0179 - val_loss: 0.5995\n",
      "Epoch 8463/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0369 - val_loss: 0.6397\n",
      "Epoch 8464/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0598 - val_loss: 0.5981\n",
      "Epoch 8465/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0226 - val_loss: 0.6208\n",
      "Epoch 8466/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0139 - val_loss: 0.6424\n",
      "Epoch 8467/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0146 - val_loss: 0.6053\n",
      "Epoch 8468/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0123 - val_loss: 0.6161\n",
      "Epoch 8469/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0149 - val_loss: 0.6164\n",
      "Epoch 8470/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0244 - val_loss: 0.6277\n",
      "Epoch 8471/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0292 - val_loss: 0.6248\n",
      "Epoch 8472/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0262 - val_loss: 0.5749\n",
      "Epoch 8473/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0185 - val_loss: 0.5901\n",
      "Epoch 8474/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0126 - val_loss: 0.6105\n",
      "Epoch 8475/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0152 - val_loss: 0.6137\n",
      "Epoch 8476/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0136 - val_loss: 0.6089\n",
      "Epoch 8477/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0308 - val_loss: 0.6147\n",
      "Epoch 8478/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0456 - val_loss: 0.6441\n",
      "Epoch 8479/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0285 - val_loss: 0.6129\n",
      "Epoch 8480/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0351 - val_loss: 0.6296\n",
      "Epoch 8481/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0261 - val_loss: 0.6153\n",
      "Epoch 8482/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0133 - val_loss: 0.6301\n",
      "Epoch 8483/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0203 - val_loss: 0.6026\n",
      "Epoch 8484/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0301 - val_loss: 0.5870\n",
      "Epoch 8485/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0243 - val_loss: 0.6044\n",
      "Epoch 8486/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0394 - val_loss: 0.6107\n",
      "Epoch 8487/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0339 - val_loss: 0.6164\n",
      "Epoch 8488/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0159 - val_loss: 0.6006\n",
      "Epoch 8489/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0079 - val_loss: 0.6094\n",
      "Epoch 8490/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0087 - val_loss: 0.5840\n",
      "Epoch 8491/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0089 - val_loss: 0.6061\n",
      "Epoch 8492/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0098 - val_loss: 0.6056\n",
      "Epoch 8493/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0135 - val_loss: 0.6260\n",
      "Epoch 8494/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0177 - val_loss: 0.6143\n",
      "Epoch 8495/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0441 - val_loss: 0.5969\n",
      "Epoch 8496/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0535 - val_loss: 0.6394\n",
      "Epoch 8497/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0282 - val_loss: 0.5880\n",
      "Epoch 8498/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0159 - val_loss: 0.5860\n",
      "Epoch 8499/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0144 - val_loss: 0.5807\n",
      "Epoch 8500/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0163 - val_loss: 0.5973\n",
      "Epoch 8501/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0135 - val_loss: 0.6005\n",
      "Epoch 8502/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0125 - val_loss: 0.6199\n",
      "Epoch 8503/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0243 - val_loss: 0.6115\n",
      "Epoch 8504/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0107 - val_loss: 0.5964\n",
      "Epoch 8505/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0148 - val_loss: 0.6105\n",
      "Epoch 8506/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0182 - val_loss: 0.6041\n",
      "Epoch 8507/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0225 - val_loss: 0.5953\n",
      "Epoch 8508/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0264 - val_loss: 0.6071\n",
      "Epoch 8509/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0264 - val_loss: 0.6099\n",
      "Epoch 8510/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0252 - val_loss: 0.6125\n",
      "Epoch 8511/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0241 - val_loss: 0.6178\n",
      "Epoch 8512/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0207 - val_loss: 0.5823\n",
      "Epoch 8513/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0171 - val_loss: 0.6108\n",
      "Epoch 8514/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0246 - val_loss: 0.6184\n",
      "Epoch 8515/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 735us/step - loss: 0.0232 - val_loss: 0.6093\n",
      "Epoch 8516/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0151 - val_loss: 0.6116\n",
      "Epoch 8517/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0163 - val_loss: 0.6041\n",
      "Epoch 8518/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0532 - val_loss: 0.6174\n",
      "Epoch 8519/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0296 - val_loss: 0.6366\n",
      "Epoch 8520/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0411 - val_loss: 0.6014\n",
      "Epoch 8521/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0336 - val_loss: 0.5991\n",
      "Epoch 8522/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0140 - val_loss: 0.6030\n",
      "Epoch 8523/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0243 - val_loss: 0.6275\n",
      "Epoch 8524/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0144 - val_loss: 0.5957\n",
      "Epoch 8525/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0135 - val_loss: 0.6155\n",
      "Epoch 8526/10000\n",
      "130/130 [==============================] - 0s 789us/step - loss: 0.0111 - val_loss: 0.5771\n",
      "Epoch 8527/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0178 - val_loss: 0.6468\n",
      "Epoch 8528/10000\n",
      "130/130 [==============================] - 0s 985us/step - loss: 0.0315 - val_loss: 0.6252\n",
      "Epoch 8529/10000\n",
      "130/130 [==============================] - 0s 782us/step - loss: 0.0287 - val_loss: 0.5786\n",
      "Epoch 8530/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0254 - val_loss: 0.6261\n",
      "Epoch 8531/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0204 - val_loss: 0.6012\n",
      "Epoch 8532/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0204 - val_loss: 0.5897\n",
      "Epoch 8533/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0205 - val_loss: 0.6090\n",
      "Epoch 8534/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0227 - val_loss: 0.5943\n",
      "Epoch 8535/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0432 - val_loss: 0.6315\n",
      "Epoch 8536/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0240 - val_loss: 0.5967\n",
      "Epoch 8537/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0250 - val_loss: 0.5849\n",
      "Epoch 8538/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0128 - val_loss: 0.6112\n",
      "Epoch 8539/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0211 - val_loss: 0.6065\n",
      "Epoch 8540/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0123 - val_loss: 0.6027\n",
      "Epoch 8541/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0143 - val_loss: 0.6251\n",
      "Epoch 8542/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0137 - val_loss: 0.5873\n",
      "Epoch 8543/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0236 - val_loss: 0.6256\n",
      "Epoch 8544/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0438 - val_loss: 0.5960\n",
      "Epoch 8545/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0385 - val_loss: 0.5877\n",
      "Epoch 8546/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0326 - val_loss: 0.6002\n",
      "Epoch 8547/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0155 - val_loss: 0.6200\n",
      "Epoch 8548/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0094 - val_loss: 0.6137\n",
      "Epoch 8549/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0166 - val_loss: 0.6456\n",
      "Epoch 8550/10000\n",
      "130/130 [==============================] - 0s 801us/step - loss: 0.0294 - val_loss: 0.5857\n",
      "Epoch 8551/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0397 - val_loss: 0.6153\n",
      "Epoch 8552/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0337 - val_loss: 0.6242\n",
      "Epoch 8553/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0214 - val_loss: 0.5764\n",
      "Epoch 8554/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0134 - val_loss: 0.5899\n",
      "Epoch 8555/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0197 - val_loss: 0.5931\n",
      "Epoch 8556/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0120 - val_loss: 0.6063\n",
      "Epoch 8557/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0119 - val_loss: 0.6194\n",
      "Epoch 8558/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0244 - val_loss: 0.6129\n",
      "Epoch 8559/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0247 - val_loss: 0.6081\n",
      "Epoch 8560/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0246 - val_loss: 0.5960\n",
      "Epoch 8561/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0274 - val_loss: 0.5782\n",
      "Epoch 8562/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0321 - val_loss: 0.6095\n",
      "Epoch 8563/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0339 - val_loss: 0.5940\n",
      "Epoch 8564/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0259 - val_loss: 0.6176\n",
      "Epoch 8565/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0219 - val_loss: 0.6100\n",
      "Epoch 8566/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0095 - val_loss: 0.5698\n",
      "Epoch 8567/10000\n",
      "130/130 [==============================] - 0s 927us/step - loss: 0.0074 - val_loss: 0.6043\n",
      "Epoch 8568/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0110 - val_loss: 0.6045\n",
      "Epoch 8569/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0135 - val_loss: 0.6119\n",
      "Epoch 8570/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0095 - val_loss: 0.5847\n",
      "Epoch 8571/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0347 - val_loss: 0.6064\n",
      "Epoch 8572/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0397 - val_loss: 0.6028\n",
      "Epoch 8573/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0481 - val_loss: 0.6087\n",
      "Epoch 8574/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0331 - val_loss: 0.6056\n",
      "Epoch 8575/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0281 - val_loss: 0.5880\n",
      "Epoch 8576/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0208 - val_loss: 0.6082\n",
      "Epoch 8577/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0186 - val_loss: 0.6337\n",
      "Epoch 8578/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0121 - val_loss: 0.6186\n",
      "Epoch 8579/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0111 - val_loss: 0.6026\n",
      "Epoch 8580/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0140 - val_loss: 0.6117\n",
      "Epoch 8581/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0331 - val_loss: 0.5886\n",
      "Epoch 8582/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0266 - val_loss: 0.5976\n",
      "Epoch 8583/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0181 - val_loss: 0.6404\n",
      "Epoch 8584/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0243 - val_loss: 0.5859\n",
      "Epoch 8585/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0117 - val_loss: 0.6003\n",
      "Epoch 8586/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0217 - val_loss: 0.6279\n",
      "Epoch 8587/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0221 - val_loss: 0.6051\n",
      "Epoch 8588/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0210 - val_loss: 0.5940\n",
      "Epoch 8589/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0254 - val_loss: 0.5831\n",
      "Epoch 8590/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0243 - val_loss: 0.6172\n",
      "Epoch 8591/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 739us/step - loss: 0.0347 - val_loss: 0.6006\n",
      "Epoch 8592/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0168 - val_loss: 0.5789\n",
      "Epoch 8593/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0158 - val_loss: 0.5983\n",
      "Epoch 8594/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0211 - val_loss: 0.6159\n",
      "Epoch 8595/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0201 - val_loss: 0.5843\n",
      "Epoch 8596/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0138 - val_loss: 0.6068\n",
      "Epoch 8597/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0101 - val_loss: 0.5902\n",
      "Epoch 8598/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0113 - val_loss: 0.5927\n",
      "Epoch 8599/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0176 - val_loss: 0.5937\n",
      "Epoch 8600/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0353 - val_loss: 0.6204\n",
      "Epoch 8601/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0303 - val_loss: 0.5938\n",
      "Epoch 8602/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0329 - val_loss: 0.5853\n",
      "Epoch 8603/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0273 - val_loss: 0.6141\n",
      "Epoch 8604/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0112 - val_loss: 0.6062\n",
      "Epoch 8605/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0155 - val_loss: 0.5886\n",
      "Epoch 8606/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0178 - val_loss: 0.5942\n",
      "Epoch 8607/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0159 - val_loss: 0.6022\n",
      "Epoch 8608/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0141 - val_loss: 0.5920\n",
      "Epoch 8609/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0559 - val_loss: 0.6206\n",
      "Epoch 8610/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0547 - val_loss: 0.5971\n",
      "Epoch 8611/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0271 - val_loss: 0.5901\n",
      "Epoch 8612/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0235 - val_loss: 0.6264\n",
      "Epoch 8613/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0256 - val_loss: 0.6201\n",
      "Epoch 8614/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0131 - val_loss: 0.5879\n",
      "Epoch 8615/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0111 - val_loss: 0.5856\n",
      "Epoch 8616/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0104 - val_loss: 0.5870\n",
      "Epoch 8617/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0073 - val_loss: 0.5804\n",
      "Epoch 8618/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0163 - val_loss: 0.5833\n",
      "Epoch 8619/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0230 - val_loss: 0.6112\n",
      "Epoch 8620/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0271 - val_loss: 0.5944\n",
      "Epoch 8621/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0273 - val_loss: 0.6089\n",
      "Epoch 8622/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0467 - val_loss: 0.6436\n",
      "Epoch 8623/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0308 - val_loss: 0.6048\n",
      "Epoch 8624/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0232 - val_loss: 0.6268\n",
      "Epoch 8625/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0224 - val_loss: 0.6021\n",
      "Epoch 8626/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0232 - val_loss: 0.6086\n",
      "Epoch 8627/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0181 - val_loss: 0.6099\n",
      "Epoch 8628/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0155 - val_loss: 0.6038\n",
      "Epoch 8629/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0094 - val_loss: 0.6126\n",
      "Epoch 8630/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0125 - val_loss: 0.6020\n",
      "Epoch 8631/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0389 - val_loss: 0.6357\n",
      "Epoch 8632/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0413 - val_loss: 0.6207\n",
      "Epoch 8633/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0268 - val_loss: 0.6039\n",
      "Epoch 8634/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0208 - val_loss: 0.6256\n",
      "Epoch 8635/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0304 - val_loss: 0.6372\n",
      "Epoch 8636/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0324 - val_loss: 0.6288\n",
      "Epoch 8637/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0177 - val_loss: 0.6029\n",
      "Epoch 8638/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0250 - val_loss: 0.5881\n",
      "Epoch 8639/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0227 - val_loss: 0.6177\n",
      "Epoch 8640/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0213 - val_loss: 0.5874\n",
      "Epoch 8641/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0163 - val_loss: 0.6085\n",
      "Epoch 8642/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0248 - val_loss: 0.6043\n",
      "Epoch 8643/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0243 - val_loss: 0.6201\n",
      "Epoch 8644/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0151 - val_loss: 0.6067\n",
      "Epoch 8645/10000\n",
      "130/130 [==============================] - 0s 808us/step - loss: 0.0137 - val_loss: 0.6206\n",
      "Epoch 8646/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0161 - val_loss: 0.6322\n",
      "Epoch 8647/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0213 - val_loss: 0.6154\n",
      "Epoch 8648/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0196 - val_loss: 0.6138\n",
      "Epoch 8649/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0157 - val_loss: 0.6122\n",
      "Epoch 8650/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0132 - val_loss: 0.6088\n",
      "Epoch 8651/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0241 - val_loss: 0.5866\n",
      "Epoch 8652/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0267 - val_loss: 0.5719\n",
      "Epoch 8653/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0227 - val_loss: 0.5883\n",
      "Epoch 8654/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0243 - val_loss: 0.6141\n",
      "Epoch 8655/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0215 - val_loss: 0.6120\n",
      "Epoch 8656/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0192 - val_loss: 0.5966\n",
      "Epoch 8657/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0303 - val_loss: 0.6045\n",
      "Epoch 8658/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0284 - val_loss: 0.5872\n",
      "Epoch 8659/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0185 - val_loss: 0.6000\n",
      "Epoch 8660/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0118 - val_loss: 0.5931\n",
      "Epoch 8661/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0081 - val_loss: 0.5998\n",
      "Epoch 8662/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0061 - val_loss: 0.6104\n",
      "Epoch 8663/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0064 - val_loss: 0.6102\n",
      "Epoch 8664/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0497 - val_loss: 0.6491\n",
      "Epoch 8665/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0564 - val_loss: 0.6391\n",
      "Epoch 8666/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0436 - val_loss: 0.6055\n",
      "Epoch 8667/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 730us/step - loss: 0.0256 - val_loss: 0.6128\n",
      "Epoch 8668/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0213 - val_loss: 0.6309\n",
      "Epoch 8669/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0180 - val_loss: 0.5889\n",
      "Epoch 8670/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0124 - val_loss: 0.6084\n",
      "Epoch 8671/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0116 - val_loss: 0.6224\n",
      "Epoch 8672/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0119 - val_loss: 0.6183\n",
      "Epoch 8673/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0121 - val_loss: 0.5962\n",
      "Epoch 8674/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0099 - val_loss: 0.6334\n",
      "Epoch 8675/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0139 - val_loss: 0.6204\n",
      "Epoch 8676/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0192 - val_loss: 0.6265\n",
      "Epoch 8677/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0276 - val_loss: 0.6261\n",
      "Epoch 8678/10000\n",
      "130/130 [==============================] - 0s 960us/step - loss: 0.0480 - val_loss: 0.6203\n",
      "Epoch 8679/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.1032 - val_loss: 0.5976\n",
      "Epoch 8680/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0525 - val_loss: 0.6163\n",
      "Epoch 8681/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0217 - val_loss: 0.6318\n",
      "Epoch 8682/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0162 - val_loss: 0.6060\n",
      "Epoch 8683/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0143 - val_loss: 0.6112\n",
      "Epoch 8684/10000\n",
      "130/130 [==============================] - 0s 777us/step - loss: 0.0099 - val_loss: 0.6039\n",
      "Epoch 8685/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0122 - val_loss: 0.6126\n",
      "Epoch 8686/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0098 - val_loss: 0.5991\n",
      "Epoch 8687/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0140 - val_loss: 0.6113\n",
      "Epoch 8688/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0087 - val_loss: 0.6082\n",
      "Epoch 8689/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0114 - val_loss: 0.6332\n",
      "Epoch 8690/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0152 - val_loss: 0.6327\n",
      "Epoch 8691/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0281 - val_loss: 0.6219\n",
      "Epoch 8692/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0324 - val_loss: 0.6438\n",
      "Epoch 8693/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0644 - val_loss: 0.6227\n",
      "Epoch 8694/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0417 - val_loss: 0.5990\n",
      "Epoch 8695/10000\n",
      "130/130 [==============================] - 0s 813us/step - loss: 0.0278 - val_loss: 0.6005\n",
      "Epoch 8696/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0327 - val_loss: 0.5991\n",
      "Epoch 8697/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0173 - val_loss: 0.5977\n",
      "Epoch 8698/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0089 - val_loss: 0.5953\n",
      "Epoch 8699/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0131 - val_loss: 0.6076\n",
      "Epoch 8700/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0118 - val_loss: 0.6273\n",
      "Epoch 8701/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0248 - val_loss: 0.6019\n",
      "Epoch 8702/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0334 - val_loss: 0.6407\n",
      "Epoch 8703/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0194 - val_loss: 0.6153\n",
      "Epoch 8704/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0151 - val_loss: 0.6087\n",
      "Epoch 8705/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0103 - val_loss: 0.5911\n",
      "Epoch 8706/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0090 - val_loss: 0.6004\n",
      "Epoch 8707/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0134 - val_loss: 0.6061\n",
      "Epoch 8708/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0227 - val_loss: 0.6101\n",
      "Epoch 8709/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0250 - val_loss: 0.6309\n",
      "Epoch 8710/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0302 - val_loss: 0.6098\n",
      "Epoch 8711/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0575 - val_loss: 0.5738\n",
      "Epoch 8712/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0411 - val_loss: 0.5955\n",
      "Epoch 8713/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0205 - val_loss: 0.6054\n",
      "Epoch 8714/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0090 - val_loss: 0.6094\n",
      "Epoch 8715/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0076 - val_loss: 0.6092\n",
      "Epoch 8716/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0310 - val_loss: 0.6005\n",
      "Epoch 8717/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0382 - val_loss: 0.6440\n",
      "Epoch 8718/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0178 - val_loss: 0.6143\n",
      "Epoch 8719/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0110 - val_loss: 0.6010\n",
      "Epoch 8720/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0091 - val_loss: 0.5986\n",
      "Epoch 8721/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0101 - val_loss: 0.6119\n",
      "Epoch 8722/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0096 - val_loss: 0.6069\n",
      "Epoch 8723/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0280 - val_loss: 0.6194\n",
      "Epoch 8724/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0306 - val_loss: 0.5964\n",
      "Epoch 8725/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0292 - val_loss: 0.5910\n",
      "Epoch 8726/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0218 - val_loss: 0.6022\n",
      "Epoch 8727/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0171 - val_loss: 0.6172\n",
      "Epoch 8728/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0206 - val_loss: 0.6030\n",
      "Epoch 8729/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0303 - val_loss: 0.6300\n",
      "Epoch 8730/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0236 - val_loss: 0.6021\n",
      "Epoch 8731/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0189 - val_loss: 0.6351\n",
      "Epoch 8732/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0288 - val_loss: 0.5751\n",
      "Epoch 8733/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0187 - val_loss: 0.5795\n",
      "Epoch 8734/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0184 - val_loss: 0.6158\n",
      "Epoch 8735/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0305 - val_loss: 0.5831\n",
      "Epoch 8736/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0413 - val_loss: 0.6085\n",
      "Epoch 8737/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0484 - val_loss: 0.5912\n",
      "Epoch 8738/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0245 - val_loss: 0.5911\n",
      "Epoch 8739/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0144 - val_loss: 0.5892\n",
      "Epoch 8740/10000\n",
      "130/130 [==============================] - 0s 791us/step - loss: 0.0090 - val_loss: 0.5813\n",
      "Epoch 8741/10000\n",
      "130/130 [==============================] - 0s 819us/step - loss: 0.0139 - val_loss: 0.6011\n",
      "Epoch 8742/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0171 - val_loss: 0.5976\n",
      "Epoch 8743/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 798us/step - loss: 0.0105 - val_loss: 0.5964\n",
      "Epoch 8744/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0120 - val_loss: 0.5979\n",
      "Epoch 8745/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0150 - val_loss: 0.6093\n",
      "Epoch 8746/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0322 - val_loss: 0.6055\n",
      "Epoch 8747/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0195 - val_loss: 0.6156\n",
      "Epoch 8748/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0228 - val_loss: 0.5906\n",
      "Epoch 8749/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0336 - val_loss: 0.6097\n",
      "Epoch 8750/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0571 - val_loss: 0.6076\n",
      "Epoch 8751/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0204 - val_loss: 0.6062\n",
      "Epoch 8752/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0154 - val_loss: 0.6164\n",
      "Epoch 8753/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0150 - val_loss: 0.6158\n",
      "Epoch 8754/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0176 - val_loss: 0.6209\n",
      "Epoch 8755/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0121 - val_loss: 0.6319\n",
      "Epoch 8756/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0224 - val_loss: 0.6123\n",
      "Epoch 8757/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0381 - val_loss: 0.6649\n",
      "Epoch 8758/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0284 - val_loss: 0.6151\n",
      "Epoch 8759/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0317 - val_loss: 0.6144\n",
      "Epoch 8760/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0196 - val_loss: 0.6283\n",
      "Epoch 8761/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0120 - val_loss: 0.6181\n",
      "Epoch 8762/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0109 - val_loss: 0.6142\n",
      "Epoch 8763/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0201 - val_loss: 0.6077\n",
      "Epoch 8764/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0209 - val_loss: 0.6205\n",
      "Epoch 8765/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0218 - val_loss: 0.6025\n",
      "Epoch 8766/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0185 - val_loss: 0.6146\n",
      "Epoch 8767/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0178 - val_loss: 0.6081\n",
      "Epoch 8768/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0350 - val_loss: 0.6071\n",
      "Epoch 8769/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0356 - val_loss: 0.6041\n",
      "Epoch 8770/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0158 - val_loss: 0.5818\n",
      "Epoch 8771/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0171 - val_loss: 0.6183\n",
      "Epoch 8772/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0196 - val_loss: 0.6084\n",
      "Epoch 8773/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0214 - val_loss: 0.6056\n",
      "Epoch 8774/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0233 - val_loss: 0.6302\n",
      "Epoch 8775/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0231 - val_loss: 0.6127\n",
      "Epoch 8776/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0294 - val_loss: 0.6276\n",
      "Epoch 8777/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0197 - val_loss: 0.6299\n",
      "Epoch 8778/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0103 - val_loss: 0.6182\n",
      "Epoch 8779/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0154 - val_loss: 0.6061\n",
      "Epoch 8780/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0535 - val_loss: 0.5815\n",
      "Epoch 8781/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0362 - val_loss: 0.6330\n",
      "Epoch 8782/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0181 - val_loss: 0.6178\n",
      "Epoch 8783/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0166 - val_loss: 0.6075\n",
      "Epoch 8784/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0219 - val_loss: 0.6013\n",
      "Epoch 8785/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0220 - val_loss: 0.5956\n",
      "Epoch 8786/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0181 - val_loss: 0.5881\n",
      "Epoch 8787/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0199 - val_loss: 0.5971\n",
      "Epoch 8788/10000\n",
      "130/130 [==============================] - 0s 721us/step - loss: 0.0104 - val_loss: 0.6028\n",
      "Epoch 8789/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0168 - val_loss: 0.6070\n",
      "Epoch 8790/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0232 - val_loss: 0.6280\n",
      "Epoch 8791/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0208 - val_loss: 0.6082\n",
      "Epoch 8792/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0230 - val_loss: 0.5830\n",
      "Epoch 8793/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0158 - val_loss: 0.5949\n",
      "Epoch 8794/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0144 - val_loss: 0.6190\n",
      "Epoch 8795/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0187 - val_loss: 0.5674\n",
      "Epoch 8796/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0213 - val_loss: 0.6204\n",
      "Epoch 8797/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0281 - val_loss: 0.6105\n",
      "Epoch 8798/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0469 - val_loss: 0.6144\n",
      "Epoch 8799/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0412 - val_loss: 0.6170\n",
      "Epoch 8800/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0369 - val_loss: 0.6156\n",
      "Epoch 8801/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0228 - val_loss: 0.6269\n",
      "Epoch 8802/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0108 - val_loss: 0.6250\n",
      "Epoch 8803/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0086 - val_loss: 0.6168\n",
      "Epoch 8804/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0181 - val_loss: 0.5960\n",
      "Epoch 8805/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0356 - val_loss: 0.5756\n",
      "Epoch 8806/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0410 - val_loss: 0.6084\n",
      "Epoch 8807/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0205 - val_loss: 0.6099\n",
      "Epoch 8808/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0213 - val_loss: 0.6229\n",
      "Epoch 8809/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0600 - val_loss: 0.5632\n",
      "Epoch 8810/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0252 - val_loss: 0.5956\n",
      "Epoch 8811/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0115 - val_loss: 0.5899\n",
      "Epoch 8812/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0080 - val_loss: 0.5787\n",
      "Epoch 8813/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0077 - val_loss: 0.6007\n",
      "Epoch 8814/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0067 - val_loss: 0.6017\n",
      "Epoch 8815/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0154 - val_loss: 0.5861\n",
      "Epoch 8816/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0240 - val_loss: 0.5925\n",
      "Epoch 8817/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0163 - val_loss: 0.5905\n",
      "Epoch 8818/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0125 - val_loss: 0.6166\n",
      "Epoch 8819/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 740us/step - loss: 0.0103 - val_loss: 0.6189\n",
      "Epoch 8820/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0241 - val_loss: 0.6081\n",
      "Epoch 8821/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0572 - val_loss: 0.5886\n",
      "Epoch 8822/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0678 - val_loss: 0.6423\n",
      "Epoch 8823/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0618 - val_loss: 0.6172\n",
      "Epoch 8824/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0288 - val_loss: 0.5996\n",
      "Epoch 8825/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0134 - val_loss: 0.6193\n",
      "Epoch 8826/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0108 - val_loss: 0.6002\n",
      "Epoch 8827/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0099 - val_loss: 0.6107\n",
      "Epoch 8828/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0095 - val_loss: 0.6437\n",
      "Epoch 8829/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0119 - val_loss: 0.6315\n",
      "Epoch 8830/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0188 - val_loss: 0.6389\n",
      "Epoch 8831/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0236 - val_loss: 0.6022\n",
      "Epoch 8832/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0193 - val_loss: 0.6388\n",
      "Epoch 8833/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0175 - val_loss: 0.6029\n",
      "Epoch 8834/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0147 - val_loss: 0.6108\n",
      "Epoch 8835/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0215 - val_loss: 0.5939\n",
      "Epoch 8836/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0182 - val_loss: 0.5675\n",
      "Epoch 8837/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0117 - val_loss: 0.6285\n",
      "Epoch 8838/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0204 - val_loss: 0.6091\n",
      "Epoch 8839/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0262 - val_loss: 0.6396\n",
      "Epoch 8840/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0250 - val_loss: 0.6021\n",
      "Epoch 8841/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0327 - val_loss: 0.5929\n",
      "Epoch 8842/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0160 - val_loss: 0.6054\n",
      "Epoch 8843/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0122 - val_loss: 0.5918\n",
      "Epoch 8844/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0143 - val_loss: 0.5967\n",
      "Epoch 8845/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0266 - val_loss: 0.5733\n",
      "Epoch 8846/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0314 - val_loss: 0.6119\n",
      "Epoch 8847/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0391 - val_loss: 0.5923\n",
      "Epoch 8848/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0529 - val_loss: 0.6176\n",
      "Epoch 8849/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0405 - val_loss: 0.5831\n",
      "Epoch 8850/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0187 - val_loss: 0.5927\n",
      "Epoch 8851/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0196 - val_loss: 0.6023\n",
      "Epoch 8852/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0154 - val_loss: 0.5974\n",
      "Epoch 8853/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0165 - val_loss: 0.6127\n",
      "Epoch 8854/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0338 - val_loss: 0.5950\n",
      "Epoch 8855/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0246 - val_loss: 0.5977\n",
      "Epoch 8856/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0269 - val_loss: 0.6368\n",
      "Epoch 8857/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0183 - val_loss: 0.6062\n",
      "Epoch 8858/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0110 - val_loss: 0.6093\n",
      "Epoch 8859/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0181 - val_loss: 0.6245\n",
      "Epoch 8860/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0201 - val_loss: 0.6021\n",
      "Epoch 8861/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0199 - val_loss: 0.6239\n",
      "Epoch 8862/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0118 - val_loss: 0.6286\n",
      "Epoch 8863/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0108 - val_loss: 0.6219\n",
      "Epoch 8864/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0148 - val_loss: 0.6227\n",
      "Epoch 8865/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0191 - val_loss: 0.6376\n",
      "Epoch 8866/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0312 - val_loss: 0.5968\n",
      "Epoch 8867/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0335 - val_loss: 0.5796\n",
      "Epoch 8868/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0324 - val_loss: 0.6285\n",
      "Epoch 8869/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0343 - val_loss: 0.6231\n",
      "Epoch 8870/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0475 - val_loss: 0.6305\n",
      "Epoch 8871/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0310 - val_loss: 0.6018\n",
      "Epoch 8872/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0282 - val_loss: 0.6043\n",
      "Epoch 8873/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0132 - val_loss: 0.6292\n",
      "Epoch 8874/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0107 - val_loss: 0.6158\n",
      "Epoch 8875/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0108 - val_loss: 0.6179\n",
      "Epoch 8876/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0084 - val_loss: 0.5966\n",
      "Epoch 8877/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0105 - val_loss: 0.5930\n",
      "Epoch 8878/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0119 - val_loss: 0.5999\n",
      "Epoch 8879/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0165 - val_loss: 0.6154\n",
      "Epoch 8880/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0321 - val_loss: 0.5911\n",
      "Epoch 8881/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0279 - val_loss: 0.6000\n",
      "Epoch 8882/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0211 - val_loss: 0.6002\n",
      "Epoch 8883/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0185 - val_loss: 0.6235\n",
      "Epoch 8884/10000\n",
      "130/130 [==============================] - 0s 850us/step - loss: 0.0284 - val_loss: 0.6129\n",
      "Epoch 8885/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0493 - val_loss: 0.6402\n",
      "Epoch 8886/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0305 - val_loss: 0.5922\n",
      "Epoch 8887/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0168 - val_loss: 0.6068\n",
      "Epoch 8888/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0107 - val_loss: 0.6242\n",
      "Epoch 8889/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0201 - val_loss: 0.6387\n",
      "Epoch 8890/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0347 - val_loss: 0.6401\n",
      "Epoch 8891/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0194 - val_loss: 0.6026\n",
      "Epoch 8892/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0179 - val_loss: 0.6094\n",
      "Epoch 8893/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0210 - val_loss: 0.6085\n",
      "Epoch 8894/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0152 - val_loss: 0.5806\n",
      "Epoch 8895/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 747us/step - loss: 0.0148 - val_loss: 0.6116\n",
      "Epoch 8896/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0160 - val_loss: 0.6070\n",
      "Epoch 8897/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0233 - val_loss: 0.5926\n",
      "Epoch 8898/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0184 - val_loss: 0.5957\n",
      "Epoch 8899/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0139 - val_loss: 0.6072\n",
      "Epoch 8900/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0136 - val_loss: 0.6027\n",
      "Epoch 8901/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0302 - val_loss: 0.6063\n",
      "Epoch 8902/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0281 - val_loss: 0.5860\n",
      "Epoch 8903/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0251 - val_loss: 0.6059\n",
      "Epoch 8904/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0422 - val_loss: 0.6292\n",
      "Epoch 8905/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0293 - val_loss: 0.6155\n",
      "Epoch 8906/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0225 - val_loss: 0.6205\n",
      "Epoch 8907/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0137 - val_loss: 0.6065\n",
      "Epoch 8908/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0181 - val_loss: 0.5991\n",
      "Epoch 8909/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0265 - val_loss: 0.6112\n",
      "Epoch 8910/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0375 - val_loss: 0.6042\n",
      "Epoch 8911/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0266 - val_loss: 0.6013\n",
      "Epoch 8912/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0215 - val_loss: 0.5770\n",
      "Epoch 8913/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0122 - val_loss: 0.5865\n",
      "Epoch 8914/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0103 - val_loss: 0.6032\n",
      "Epoch 8915/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0076 - val_loss: 0.5937\n",
      "Epoch 8916/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0064 - val_loss: 0.5784\n",
      "Epoch 8917/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0092 - val_loss: 0.6062\n",
      "Epoch 8918/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0243 - val_loss: 0.6127\n",
      "Epoch 8919/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0434 - val_loss: 0.6315\n",
      "Epoch 8920/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0370 - val_loss: 0.6511\n",
      "Epoch 8921/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0314 - val_loss: 0.6269\n",
      "Epoch 8922/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0260 - val_loss: 0.5891\n",
      "Epoch 8923/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0175 - val_loss: 0.5952\n",
      "Epoch 8924/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0103 - val_loss: 0.6148\n",
      "Epoch 8925/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0159 - val_loss: 0.6198\n",
      "Epoch 8926/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.5952\n",
      "Epoch 8927/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0215 - val_loss: 0.6008\n",
      "Epoch 8928/10000\n",
      "130/130 [==============================] - 0s 720us/step - loss: 0.0172 - val_loss: 0.5967\n",
      "Epoch 8929/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0111 - val_loss: 0.6141\n",
      "Epoch 8930/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0215 - val_loss: 0.6241\n",
      "Epoch 8931/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0359 - val_loss: 0.6117\n",
      "Epoch 8932/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0258 - val_loss: 0.6029\n",
      "Epoch 8933/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0316 - val_loss: 0.6132\n",
      "Epoch 8934/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0523 - val_loss: 0.6073\n",
      "Epoch 8935/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0236 - val_loss: 0.5833\n",
      "Epoch 8936/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0092 - val_loss: 0.6045\n",
      "Epoch 8937/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0089 - val_loss: 0.5970\n",
      "Epoch 8938/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0086 - val_loss: 0.5972\n",
      "Epoch 8939/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0066 - val_loss: 0.5682\n",
      "Epoch 8940/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0065 - val_loss: 0.6015\n",
      "Epoch 8941/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0117 - val_loss: 0.6118\n",
      "Epoch 8942/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0149 - val_loss: 0.6132\n",
      "Epoch 8943/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0202 - val_loss: 0.6125\n",
      "Epoch 8944/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0418 - val_loss: 0.6192\n",
      "Epoch 8945/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0758 - val_loss: 0.6011\n",
      "Epoch 8946/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0510 - val_loss: 0.6024\n",
      "Epoch 8947/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0244 - val_loss: 0.5835\n",
      "Epoch 8948/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0195 - val_loss: 0.6039\n",
      "Epoch 8949/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0133 - val_loss: 0.6074\n",
      "Epoch 8950/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0098 - val_loss: 0.5932\n",
      "Epoch 8951/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0130 - val_loss: 0.5943\n",
      "Epoch 8952/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0300 - val_loss: 0.6110\n",
      "Epoch 8953/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0420 - val_loss: 0.6071\n",
      "Epoch 8954/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0309 - val_loss: 0.6298\n",
      "Epoch 8955/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0252 - val_loss: 0.6016\n",
      "Epoch 8956/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0288 - val_loss: 0.6356\n",
      "Epoch 8957/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0229 - val_loss: 0.5818\n",
      "Epoch 8958/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0206 - val_loss: 0.6071\n",
      "Epoch 8959/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0129 - val_loss: 0.5975\n",
      "Epoch 8960/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0100 - val_loss: 0.5834\n",
      "Epoch 8961/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0110 - val_loss: 0.5808\n",
      "Epoch 8962/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0087 - val_loss: 0.5897\n",
      "Epoch 8963/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0096 - val_loss: 0.5989\n",
      "Epoch 8964/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0155 - val_loss: 0.5946\n",
      "Epoch 8965/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0424 - val_loss: 0.6179\n",
      "Epoch 8966/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0444 - val_loss: 0.5712\n",
      "Epoch 8967/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0165 - val_loss: 0.5903\n",
      "Epoch 8968/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0196 - val_loss: 0.6028\n",
      "Epoch 8969/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0279 - val_loss: 0.5896\n",
      "Epoch 8970/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0147 - val_loss: 0.6179\n",
      "Epoch 8971/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 742us/step - loss: 0.0111 - val_loss: 0.6129\n",
      "Epoch 8972/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0106 - val_loss: 0.5978\n",
      "Epoch 8973/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0127 - val_loss: 0.5870\n",
      "Epoch 8974/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0186 - val_loss: 0.6041\n",
      "Epoch 8975/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0416 - val_loss: 0.6161\n",
      "Epoch 8976/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0776 - val_loss: 0.5944\n",
      "Epoch 8977/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0513 - val_loss: 0.6397\n",
      "Epoch 8978/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0174 - val_loss: 0.5958\n",
      "Epoch 8979/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0149 - val_loss: 0.5934\n",
      "Epoch 8980/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0116 - val_loss: 0.5882\n",
      "Epoch 8981/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0091 - val_loss: 0.6318\n",
      "Epoch 8982/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0157 - val_loss: 0.6180\n",
      "Epoch 8983/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0225 - val_loss: 0.6192\n",
      "Epoch 8984/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0130 - val_loss: 0.6068\n",
      "Epoch 8985/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0144 - val_loss: 0.6197\n",
      "Epoch 8986/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0156 - val_loss: 0.6136\n",
      "Epoch 8987/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0213 - val_loss: 0.6083\n",
      "Epoch 8988/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0187 - val_loss: 0.5973\n",
      "Epoch 8989/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0235 - val_loss: 0.6064\n",
      "Epoch 8990/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0251 - val_loss: 0.5831\n",
      "Epoch 8991/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0201 - val_loss: 0.5908\n",
      "Epoch 8992/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0357 - val_loss: 0.6186\n",
      "Epoch 8993/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0274 - val_loss: 0.5787\n",
      "Epoch 8994/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0215 - val_loss: 0.6126\n",
      "Epoch 8995/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0232 - val_loss: 0.5886\n",
      "Epoch 8996/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0188 - val_loss: 0.5847\n",
      "Epoch 8997/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0230 - val_loss: 0.6034\n",
      "Epoch 8998/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0124 - val_loss: 0.6108\n",
      "Epoch 8999/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0102 - val_loss: 0.5899\n",
      "Epoch 9000/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0107 - val_loss: 0.6069\n",
      "Epoch 9001/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0233 - val_loss: 0.5904\n",
      "Epoch 9002/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0535 - val_loss: 0.6092\n",
      "Epoch 9003/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0776 - val_loss: 0.6259\n",
      "Epoch 9004/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0869 - val_loss: 0.6006\n",
      "Epoch 9005/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0278 - val_loss: 0.6117\n",
      "Epoch 9006/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0192 - val_loss: 0.6075\n",
      "Epoch 9007/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0104 - val_loss: 0.6043\n",
      "Epoch 9008/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0114 - val_loss: 0.5907\n",
      "Epoch 9009/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0205 - val_loss: 0.6080\n",
      "Epoch 9010/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0138 - val_loss: 0.5782\n",
      "Epoch 9011/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0117 - val_loss: 0.5764\n",
      "Epoch 9012/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0107 - val_loss: 0.6134\n",
      "Epoch 9013/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0130 - val_loss: 0.5921\n",
      "Epoch 9014/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0128 - val_loss: 0.5783\n",
      "Epoch 9015/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0141 - val_loss: 0.5971\n",
      "Epoch 9016/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0144 - val_loss: 0.6345\n",
      "Epoch 9017/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0224 - val_loss: 0.6215\n",
      "Epoch 9018/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0812 - val_loss: 0.5940\n",
      "Epoch 9019/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0446 - val_loss: 0.6204\n",
      "Epoch 9020/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0151 - val_loss: 0.6034\n",
      "Epoch 9021/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0178 - val_loss: 0.6126\n",
      "Epoch 9022/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0177 - val_loss: 0.6091\n",
      "Epoch 9023/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0121 - val_loss: 0.5970\n",
      "Epoch 9024/10000\n",
      "130/130 [==============================] - 0s 776us/step - loss: 0.0102 - val_loss: 0.5812\n",
      "Epoch 9025/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0085 - val_loss: 0.6015\n",
      "Epoch 9026/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0320 - val_loss: 0.6252\n",
      "Epoch 9027/10000\n",
      "130/130 [==============================] - 0s 821us/step - loss: 0.0228 - val_loss: 0.5995\n",
      "Epoch 9028/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0160 - val_loss: 0.6195\n",
      "Epoch 9029/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0113 - val_loss: 0.6277\n",
      "Epoch 9030/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0138 - val_loss: 0.6105\n",
      "Epoch 9031/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0220 - val_loss: 0.5880\n",
      "Epoch 9032/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0311 - val_loss: 0.5857\n",
      "Epoch 9033/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0326 - val_loss: 0.6307\n",
      "Epoch 9034/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0258 - val_loss: 0.5665\n",
      "Epoch 9035/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0187 - val_loss: 0.6116\n",
      "Epoch 9036/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0198 - val_loss: 0.6082\n",
      "Epoch 9037/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0246 - val_loss: 0.6288\n",
      "Epoch 9038/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0292 - val_loss: 0.6420\n",
      "Epoch 9039/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0190 - val_loss: 0.6157\n",
      "Epoch 9040/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0234 - val_loss: 0.5963\n",
      "Epoch 9041/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0623 - val_loss: 0.5989\n",
      "Epoch 9042/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0396 - val_loss: 0.6362\n",
      "Epoch 9043/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0280 - val_loss: 0.5961\n",
      "Epoch 9044/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0125 - val_loss: 0.6029\n",
      "Epoch 9045/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0109 - val_loss: 0.6008\n",
      "Epoch 9046/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0081 - val_loss: 0.5898\n",
      "Epoch 9047/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 740us/step - loss: 0.0082 - val_loss: 0.6004\n",
      "Epoch 9048/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0067 - val_loss: 0.6137\n",
      "Epoch 9049/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0068 - val_loss: 0.5962\n",
      "Epoch 9050/10000\n",
      "130/130 [==============================] - 0s 812us/step - loss: 0.0118 - val_loss: 0.6284\n",
      "Epoch 9051/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0398 - val_loss: 0.6044\n",
      "Epoch 9052/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0733 - val_loss: 0.6067\n",
      "Epoch 9053/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0285 - val_loss: 0.5911\n",
      "Epoch 9054/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0216 - val_loss: 0.6081\n",
      "Epoch 9055/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0172 - val_loss: 0.5998\n",
      "Epoch 9056/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0114 - val_loss: 0.6240\n",
      "Epoch 9057/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0097 - val_loss: 0.5953\n",
      "Epoch 9058/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0247 - val_loss: 0.6406\n",
      "Epoch 9059/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0281 - val_loss: 0.5899\n",
      "Epoch 9060/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0378 - val_loss: 0.6104\n",
      "Epoch 9061/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0345 - val_loss: 0.6084\n",
      "Epoch 9062/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0218 - val_loss: 0.6093\n",
      "Epoch 9063/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0162 - val_loss: 0.6150\n",
      "Epoch 9064/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0158 - val_loss: 0.5852\n",
      "Epoch 9065/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0144 - val_loss: 0.5961\n",
      "Epoch 9066/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0147 - val_loss: 0.5853\n",
      "Epoch 9067/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0191 - val_loss: 0.6048\n",
      "Epoch 9068/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0230 - val_loss: 0.6082\n",
      "Epoch 9069/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0198 - val_loss: 0.5968\n",
      "Epoch 9070/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0216 - val_loss: 0.6227\n",
      "Epoch 9071/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0344 - val_loss: 0.6086\n",
      "Epoch 9072/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0390 - val_loss: 0.6350\n",
      "Epoch 9073/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0366 - val_loss: 0.6098\n",
      "Epoch 9074/10000\n",
      "130/130 [==============================] - 0s 817us/step - loss: 0.0158 - val_loss: 0.6148\n",
      "Epoch 9075/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0142 - val_loss: 0.5876\n",
      "Epoch 9076/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0145 - val_loss: 0.5736\n",
      "Epoch 9077/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0225 - val_loss: 0.5709\n",
      "Epoch 9078/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0345 - val_loss: 0.6278\n",
      "Epoch 9079/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0141 - val_loss: 0.6082\n",
      "Epoch 9080/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0083 - val_loss: 0.5931\n",
      "Epoch 9081/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0107 - val_loss: 0.5895\n",
      "Epoch 9082/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0073 - val_loss: 0.6182\n",
      "Epoch 9083/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0072 - val_loss: 0.6034\n",
      "Epoch 9084/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0091 - val_loss: 0.5992\n",
      "Epoch 9085/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0196 - val_loss: 0.6300\n",
      "Epoch 9086/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0386 - val_loss: 0.6121\n",
      "Epoch 9087/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0592 - val_loss: 0.6039\n",
      "Epoch 9088/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0343 - val_loss: 0.5988\n",
      "Epoch 9089/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0169 - val_loss: 0.6041\n",
      "Epoch 9090/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0134 - val_loss: 0.5826\n",
      "Epoch 9091/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0169 - val_loss: 0.6128\n",
      "Epoch 9092/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0297 - val_loss: 0.6039\n",
      "Epoch 9093/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0351 - val_loss: 0.6197\n",
      "Epoch 9094/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0574 - val_loss: 0.6025\n",
      "Epoch 9095/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0292 - val_loss: 0.5987\n",
      "Epoch 9096/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0177 - val_loss: 0.6042\n",
      "Epoch 9097/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0170 - val_loss: 0.5974\n",
      "Epoch 9098/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0117 - val_loss: 0.6040\n",
      "Epoch 9099/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0122 - val_loss: 0.5919\n",
      "Epoch 9100/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0220 - val_loss: 0.5774\n",
      "Epoch 9101/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0225 - val_loss: 0.6140\n",
      "Epoch 9102/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0266 - val_loss: 0.5759\n",
      "Epoch 9103/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0209 - val_loss: 0.6451\n",
      "Epoch 9104/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0267 - val_loss: 0.5812\n",
      "Epoch 9105/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0260 - val_loss: 0.5950\n",
      "Epoch 9106/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0334 - val_loss: 0.6330\n",
      "Epoch 9107/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0214 - val_loss: 0.5952\n",
      "Epoch 9108/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0302 - val_loss: 0.5583\n",
      "Epoch 9109/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0302 - val_loss: 0.6235\n",
      "Epoch 9110/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0342 - val_loss: 0.6107\n",
      "Epoch 9111/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0152 - val_loss: 0.5770\n",
      "Epoch 9112/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0174 - val_loss: 0.6033\n",
      "Epoch 9113/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0182 - val_loss: 0.6037\n",
      "Epoch 9114/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0206 - val_loss: 0.6182\n",
      "Epoch 9115/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0306 - val_loss: 0.5757\n",
      "Epoch 9116/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0112 - val_loss: 0.5874\n",
      "Epoch 9117/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0131 - val_loss: 0.5922\n",
      "Epoch 9118/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0108 - val_loss: 0.5741\n",
      "Epoch 9119/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0081 - val_loss: 0.5945\n",
      "Epoch 9120/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0062 - val_loss: 0.5852\n",
      "Epoch 9121/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0073 - val_loss: 0.5892\n",
      "Epoch 9122/10000\n",
      "130/130 [==============================] - 0s 780us/step - loss: 0.0184 - val_loss: 0.5843\n",
      "Epoch 9123/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 830us/step - loss: 0.0358 - val_loss: 0.6009\n",
      "Epoch 9124/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0475 - val_loss: 0.5862\n",
      "Epoch 9125/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0488 - val_loss: 0.6118\n",
      "Epoch 9126/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0232 - val_loss: 0.6130\n",
      "Epoch 9127/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0200 - val_loss: 0.5703\n",
      "Epoch 9128/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0211 - val_loss: 0.5916\n",
      "Epoch 9129/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0143 - val_loss: 0.5721\n",
      "Epoch 9130/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0207 - val_loss: 0.6117\n",
      "Epoch 9131/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0153 - val_loss: 0.6030\n",
      "Epoch 9132/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0111 - val_loss: 0.6022\n",
      "Epoch 9133/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0105 - val_loss: 0.5795\n",
      "Epoch 9134/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0096 - val_loss: 0.5904\n",
      "Epoch 9135/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0079 - val_loss: 0.5942\n",
      "Epoch 9136/10000\n",
      "130/130 [==============================] - 0s 778us/step - loss: 0.0202 - val_loss: 0.6188\n",
      "Epoch 9137/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0609 - val_loss: 0.6210\n",
      "Epoch 9138/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0361 - val_loss: 0.6254\n",
      "Epoch 9139/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0323 - val_loss: 0.6147\n",
      "Epoch 9140/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0271 - val_loss: 0.6008\n",
      "Epoch 9141/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0372 - val_loss: 0.5907\n",
      "Epoch 9142/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0245 - val_loss: 0.5720\n",
      "Epoch 9143/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0198 - val_loss: 0.6027\n",
      "Epoch 9144/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0148 - val_loss: 0.6237\n",
      "Epoch 9145/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0087 - val_loss: 0.6108\n",
      "Epoch 9146/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0191 - val_loss: 0.6113\n",
      "Epoch 9147/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0255 - val_loss: 0.6047\n",
      "Epoch 9148/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0178 - val_loss: 0.5923\n",
      "Epoch 9149/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0178 - val_loss: 0.6048\n",
      "Epoch 9150/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0198 - val_loss: 0.6141\n",
      "Epoch 9151/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0233 - val_loss: 0.6078\n",
      "Epoch 9152/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0208 - val_loss: 0.6162\n",
      "Epoch 9153/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0232 - val_loss: 0.5592\n",
      "Epoch 9154/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0297 - val_loss: 0.5928\n",
      "Epoch 9155/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0336 - val_loss: 0.5637\n",
      "Epoch 9156/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0199 - val_loss: 0.6149\n",
      "Epoch 9157/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0193 - val_loss: 0.5936\n",
      "Epoch 9158/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0195 - val_loss: 0.6061\n",
      "Epoch 9159/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0130 - val_loss: 0.6321\n",
      "Epoch 9160/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0114 - val_loss: 0.6050\n",
      "Epoch 9161/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0109 - val_loss: 0.5998\n",
      "Epoch 9162/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0129 - val_loss: 0.6281\n",
      "Epoch 9163/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0175 - val_loss: 0.5890\n",
      "Epoch 9164/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0519 - val_loss: 0.6069\n",
      "Epoch 9165/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0625 - val_loss: 0.6258\n",
      "Epoch 9166/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0299 - val_loss: 0.6072\n",
      "Epoch 9167/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0117 - val_loss: 0.5712\n",
      "Epoch 9168/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0118 - val_loss: 0.6080\n",
      "Epoch 9169/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0122 - val_loss: 0.5929\n",
      "Epoch 9170/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0208 - val_loss: 0.5570\n",
      "Epoch 9171/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0233 - val_loss: 0.6175\n",
      "Epoch 9172/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0288 - val_loss: 0.6181\n",
      "Epoch 9173/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0251 - val_loss: 0.5938\n",
      "Epoch 9174/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0224 - val_loss: 0.5952\n",
      "Epoch 9175/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0189 - val_loss: 0.6037\n",
      "Epoch 9176/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0204 - val_loss: 0.6160\n",
      "Epoch 9177/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0152 - val_loss: 0.6010\n",
      "Epoch 9178/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0178 - val_loss: 0.6001\n",
      "Epoch 9179/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0153 - val_loss: 0.5908\n",
      "Epoch 9180/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0118 - val_loss: 0.6031\n",
      "Epoch 9181/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0271 - val_loss: 0.5976\n",
      "Epoch 9182/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0247 - val_loss: 0.5732\n",
      "Epoch 9183/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0279 - val_loss: 0.5850\n",
      "Epoch 9184/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0324 - val_loss: 0.5847\n",
      "Epoch 9185/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0193 - val_loss: 0.5772\n",
      "Epoch 9186/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0219 - val_loss: 0.5897\n",
      "Epoch 9187/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0164 - val_loss: 0.6125\n",
      "Epoch 9188/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0252 - val_loss: 0.5617\n",
      "Epoch 9189/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0587 - val_loss: 0.6196\n",
      "Epoch 9190/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0281 - val_loss: 0.5816\n",
      "Epoch 9191/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0115 - val_loss: 0.6012\n",
      "Epoch 9192/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0153 - val_loss: 0.5769\n",
      "Epoch 9193/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0100 - val_loss: 0.5925\n",
      "Epoch 9194/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0087 - val_loss: 0.5925\n",
      "Epoch 9195/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0084 - val_loss: 0.6160\n",
      "Epoch 9196/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0144 - val_loss: 0.6152\n",
      "Epoch 9197/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0167 - val_loss: 0.6204\n",
      "Epoch 9198/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0383 - val_loss: 0.6264\n",
      "Epoch 9199/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 730us/step - loss: 0.0396 - val_loss: 0.6209\n",
      "Epoch 9200/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0316 - val_loss: 0.5835\n",
      "Epoch 9201/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0241 - val_loss: 0.6214\n",
      "Epoch 9202/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0247 - val_loss: 0.5817\n",
      "Epoch 9203/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0166 - val_loss: 0.5861\n",
      "Epoch 9204/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0208 - val_loss: 0.6100\n",
      "Epoch 9205/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0151 - val_loss: 0.6062\n",
      "Epoch 9206/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0147 - val_loss: 0.5860\n",
      "Epoch 9207/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0161 - val_loss: 0.6007\n",
      "Epoch 9208/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0223 - val_loss: 0.6012\n",
      "Epoch 9209/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0225 - val_loss: 0.6183\n",
      "Epoch 9210/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0362 - val_loss: 0.6369\n",
      "Epoch 9211/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0230 - val_loss: 0.5867\n",
      "Epoch 9212/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0192 - val_loss: 0.6175\n",
      "Epoch 9213/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0118 - val_loss: 0.5932\n",
      "Epoch 9214/10000\n",
      "130/130 [==============================] - 0s 795us/step - loss: 0.0161 - val_loss: 0.6129\n",
      "Epoch 9215/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0209 - val_loss: 0.6103\n",
      "Epoch 9216/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0242 - val_loss: 0.6252\n",
      "Epoch 9217/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0165 - val_loss: 0.5973\n",
      "Epoch 9218/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0177 - val_loss: 0.6091\n",
      "Epoch 9219/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0217 - val_loss: 0.6036\n",
      "Epoch 9220/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0171 - val_loss: 0.6018\n",
      "Epoch 9221/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0208 - val_loss: 0.6081\n",
      "Epoch 9222/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0587 - val_loss: 0.6023\n",
      "Epoch 9223/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0412 - val_loss: 0.6066\n",
      "Epoch 9224/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0159 - val_loss: 0.5789\n",
      "Epoch 9225/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0098 - val_loss: 0.5885\n",
      "Epoch 9226/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0087 - val_loss: 0.5983\n",
      "Epoch 9227/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0092 - val_loss: 0.5779\n",
      "Epoch 9228/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0217 - val_loss: 0.6291\n",
      "Epoch 9229/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0583 - val_loss: 0.5963\n",
      "Epoch 9230/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0536 - val_loss: 0.6334\n",
      "Epoch 9231/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0300 - val_loss: 0.6095\n",
      "Epoch 9232/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0116 - val_loss: 0.6037\n",
      "Epoch 9233/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0155 - val_loss: 0.5816\n",
      "Epoch 9234/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0206 - val_loss: 0.5936\n",
      "Epoch 9235/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0257 - val_loss: 0.5984\n",
      "Epoch 9236/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0176 - val_loss: 0.5826\n",
      "Epoch 9237/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0149 - val_loss: 0.5800\n",
      "Epoch 9238/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0089 - val_loss: 0.6017\n",
      "Epoch 9239/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0091 - val_loss: 0.6003\n",
      "Epoch 9240/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0081 - val_loss: 0.5983\n",
      "Epoch 9241/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0084 - val_loss: 0.6181\n",
      "Epoch 9242/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0139 - val_loss: 0.6166\n",
      "Epoch 9243/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0311 - val_loss: 0.5798\n",
      "Epoch 9244/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0667 - val_loss: 0.6021\n",
      "Epoch 9245/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0528 - val_loss: 0.5805\n",
      "Epoch 9246/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0382 - val_loss: 0.5893\n",
      "Epoch 9247/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0202 - val_loss: 0.6006\n",
      "Epoch 9248/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0180 - val_loss: 0.5830\n",
      "Epoch 9249/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0132 - val_loss: 0.6249\n",
      "Epoch 9250/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0161 - val_loss: 0.5934\n",
      "Epoch 9251/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0141 - val_loss: 0.6047\n",
      "Epoch 9252/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0189 - val_loss: 0.6026\n",
      "Epoch 9253/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0154 - val_loss: 0.6177\n",
      "Epoch 9254/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0236 - val_loss: 0.5988\n",
      "Epoch 9255/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0202 - val_loss: 0.6028\n",
      "Epoch 9256/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0178 - val_loss: 0.6025\n",
      "Epoch 9257/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0138 - val_loss: 0.6325\n",
      "Epoch 9258/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0204 - val_loss: 0.6233\n",
      "Epoch 9259/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0260 - val_loss: 0.6219\n",
      "Epoch 9260/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0230 - val_loss: 0.6136\n",
      "Epoch 9261/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0282 - val_loss: 0.6026\n",
      "Epoch 9262/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0258 - val_loss: 0.5778\n",
      "Epoch 9263/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0175 - val_loss: 0.5980\n",
      "Epoch 9264/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0114 - val_loss: 0.5994\n",
      "Epoch 9265/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0128 - val_loss: 0.6088\n",
      "Epoch 9266/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0314 - val_loss: 0.5934\n",
      "Epoch 9267/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0235 - val_loss: 0.5867\n",
      "Epoch 9268/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0212 - val_loss: 0.6035\n",
      "Epoch 9269/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0220 - val_loss: 0.5682\n",
      "Epoch 9270/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0147 - val_loss: 0.6050\n",
      "Epoch 9271/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0128 - val_loss: 0.6184\n",
      "Epoch 9272/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0100 - val_loss: 0.6337\n",
      "Epoch 9273/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0114 - val_loss: 0.5870\n",
      "Epoch 9274/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0117 - val_loss: 0.6023\n",
      "Epoch 9275/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 732us/step - loss: 0.0237 - val_loss: 0.6061\n",
      "Epoch 9276/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0355 - val_loss: 0.6313\n",
      "Epoch 9277/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0328 - val_loss: 0.5996\n",
      "Epoch 9278/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0329 - val_loss: 0.5771\n",
      "Epoch 9279/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0198 - val_loss: 0.5744\n",
      "Epoch 9280/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0223 - val_loss: 0.6026\n",
      "Epoch 9281/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0226 - val_loss: 0.5682\n",
      "Epoch 9282/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0324 - val_loss: 0.6274\n",
      "Epoch 9283/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0315 - val_loss: 0.6347\n",
      "Epoch 9284/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0317 - val_loss: 0.6262\n",
      "Epoch 9285/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0431 - val_loss: 0.6139\n",
      "Epoch 9286/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0269 - val_loss: 0.5939\n",
      "Epoch 9287/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0159 - val_loss: 0.6003\n",
      "Epoch 9288/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0110 - val_loss: 0.6181\n",
      "Epoch 9289/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0142 - val_loss: 0.6123\n",
      "Epoch 9290/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0179 - val_loss: 0.6204\n",
      "Epoch 9291/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0244 - val_loss: 0.6041\n",
      "Epoch 9292/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0209 - val_loss: 0.5803\n",
      "Epoch 9293/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0288 - val_loss: 0.6041\n",
      "Epoch 9294/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0105 - val_loss: 0.5929\n",
      "Epoch 9295/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0097 - val_loss: 0.5836\n",
      "Epoch 9296/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0120 - val_loss: 0.5726\n",
      "Epoch 9297/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0216 - val_loss: 0.5704\n",
      "Epoch 9298/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0366 - val_loss: 0.6087\n",
      "Epoch 9299/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0402 - val_loss: 0.5957\n",
      "Epoch 9300/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0241 - val_loss: 0.5826\n",
      "Epoch 9301/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0175 - val_loss: 0.6015\n",
      "Epoch 9302/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0153 - val_loss: 0.6211\n",
      "Epoch 9303/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0122 - val_loss: 0.5983\n",
      "Epoch 9304/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0098 - val_loss: 0.5860\n",
      "Epoch 9305/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0238 - val_loss: 0.6181\n",
      "Epoch 9306/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0246 - val_loss: 0.6152\n",
      "Epoch 9307/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0277 - val_loss: 0.5888\n",
      "Epoch 9308/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0507 - val_loss: 0.6066\n",
      "Epoch 9309/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0291 - val_loss: 0.5998\n",
      "Epoch 9310/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0152 - val_loss: 0.6058\n",
      "Epoch 9311/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0180 - val_loss: 0.6106\n",
      "Epoch 9312/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0133 - val_loss: 0.5948\n",
      "Epoch 9313/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0167 - val_loss: 0.5613\n",
      "Epoch 9314/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0182 - val_loss: 0.5922\n",
      "Epoch 9315/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0254 - val_loss: 0.5825\n",
      "Epoch 9316/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0170 - val_loss: 0.5936\n",
      "Epoch 9317/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0181 - val_loss: 0.5939\n",
      "Epoch 9318/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0231 - val_loss: 0.5962\n",
      "Epoch 9319/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0662 - val_loss: 0.6145\n",
      "Epoch 9320/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0490 - val_loss: 0.5972\n",
      "Epoch 9321/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0184 - val_loss: 0.6027\n",
      "Epoch 9322/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0144 - val_loss: 0.6008\n",
      "Epoch 9323/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0238 - val_loss: 0.5944\n",
      "Epoch 9324/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0159 - val_loss: 0.6042\n",
      "Epoch 9325/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0145 - val_loss: 0.5900\n",
      "Epoch 9326/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0164 - val_loss: 0.5786\n",
      "Epoch 9327/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0185 - val_loss: 0.5737\n",
      "Epoch 9328/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0131 - val_loss: 0.5916\n",
      "Epoch 9329/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0133 - val_loss: 0.5994\n",
      "Epoch 9330/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0163 - val_loss: 0.5899\n",
      "Epoch 9331/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0120 - val_loss: 0.6007\n",
      "Epoch 9332/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0134 - val_loss: 0.6218\n",
      "Epoch 9333/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0243 - val_loss: 0.6017\n",
      "Epoch 9334/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0192 - val_loss: 0.6292\n",
      "Epoch 9335/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0306 - val_loss: 0.6045\n",
      "Epoch 9336/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0256 - val_loss: 0.5933\n",
      "Epoch 9337/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0350 - val_loss: 0.5884\n",
      "Epoch 9338/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0211 - val_loss: 0.6143\n",
      "Epoch 9339/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0150 - val_loss: 0.5905\n",
      "Epoch 9340/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0097 - val_loss: 0.6074\n",
      "Epoch 9341/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0243 - val_loss: 0.5930\n",
      "Epoch 9342/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0250 - val_loss: 0.5937\n",
      "Epoch 9343/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0246 - val_loss: 0.5789\n",
      "Epoch 9344/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0155 - val_loss: 0.6082\n",
      "Epoch 9345/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0211 - val_loss: 0.5922\n",
      "Epoch 9346/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0156 - val_loss: 0.5912\n",
      "Epoch 9347/10000\n",
      "130/130 [==============================] - 0s 813us/step - loss: 0.0176 - val_loss: 0.5956\n",
      "Epoch 9348/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0199 - val_loss: 0.6230\n",
      "Epoch 9349/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0318 - val_loss: 0.5546\n",
      "Epoch 9350/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0295 - val_loss: 0.5959\n",
      "Epoch 9351/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 741us/step - loss: 0.0181 - val_loss: 0.5736\n",
      "Epoch 9352/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0128 - val_loss: 0.5783\n",
      "Epoch 9353/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0211 - val_loss: 0.6225\n",
      "Epoch 9354/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0451 - val_loss: 0.6313\n",
      "Epoch 9355/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0404 - val_loss: 0.6185\n",
      "Epoch 9356/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0215 - val_loss: 0.6231\n",
      "Epoch 9357/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0176 - val_loss: 0.5889\n",
      "Epoch 9358/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0185 - val_loss: 0.6153\n",
      "Epoch 9359/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0154 - val_loss: 0.5890\n",
      "Epoch 9360/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0168 - val_loss: 0.6150\n",
      "Epoch 9361/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0145 - val_loss: 0.5971\n",
      "Epoch 9362/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0133 - val_loss: 0.5935\n",
      "Epoch 9363/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0145 - val_loss: 0.5707\n",
      "Epoch 9364/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0228 - val_loss: 0.5893\n",
      "Epoch 9365/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0250 - val_loss: 0.5948\n",
      "Epoch 9366/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0239 - val_loss: 0.6084\n",
      "Epoch 9367/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0177 - val_loss: 0.6112\n",
      "Epoch 9368/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0155 - val_loss: 0.6024\n",
      "Epoch 9369/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0184 - val_loss: 0.6125\n",
      "Epoch 9370/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0312 - val_loss: 0.6230\n",
      "Epoch 9371/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0264 - val_loss: 0.6090\n",
      "Epoch 9372/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0216 - val_loss: 0.6413\n",
      "Epoch 9373/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0377 - val_loss: 0.6151\n",
      "Epoch 9374/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0353 - val_loss: 0.6078\n",
      "Epoch 9375/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0154 - val_loss: 0.5769\n",
      "Epoch 9376/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0161 - val_loss: 0.5846\n",
      "Epoch 9377/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0168 - val_loss: 0.6073\n",
      "Epoch 9378/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0096 - val_loss: 0.6006\n",
      "Epoch 9379/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0075 - val_loss: 0.5959\n",
      "Epoch 9380/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0098 - val_loss: 0.5848\n",
      "Epoch 9381/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0156 - val_loss: 0.6255\n",
      "Epoch 9382/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0145 - val_loss: 0.5917\n",
      "Epoch 9383/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0308 - val_loss: 0.5925\n",
      "Epoch 9384/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0241 - val_loss: 0.5789\n",
      "Epoch 9385/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0279 - val_loss: 0.5937\n",
      "Epoch 9386/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0225 - val_loss: 0.5957\n",
      "Epoch 9387/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0257 - val_loss: 0.6125\n",
      "Epoch 9388/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0343 - val_loss: 0.6104\n",
      "Epoch 9389/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0216 - val_loss: 0.6167\n",
      "Epoch 9390/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0239 - val_loss: 0.6323\n",
      "Epoch 9391/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0211 - val_loss: 0.6241\n",
      "Epoch 9392/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0175 - val_loss: 0.6153\n",
      "Epoch 9393/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0153 - val_loss: 0.5998\n",
      "Epoch 9394/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0149 - val_loss: 0.6016\n",
      "Epoch 9395/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0119 - val_loss: 0.5923\n",
      "Epoch 9396/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0169 - val_loss: 0.6147\n",
      "Epoch 9397/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0394 - val_loss: 0.6119\n",
      "Epoch 9398/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0301 - val_loss: 0.5865\n",
      "Epoch 9399/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0200 - val_loss: 0.5948\n",
      "Epoch 9400/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0200 - val_loss: 0.5947\n",
      "Epoch 9401/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0149 - val_loss: 0.6232\n",
      "Epoch 9402/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0070 - val_loss: 0.5971\n",
      "Epoch 9403/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0067 - val_loss: 0.6045\n",
      "Epoch 9404/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0048 - val_loss: 0.6015\n",
      "Epoch 9405/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0128 - val_loss: 0.6061\n",
      "Epoch 9406/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0314 - val_loss: 0.6259\n",
      "Epoch 9407/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0545 - val_loss: 0.6182\n",
      "Epoch 9408/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0380 - val_loss: 0.6186\n",
      "Epoch 9409/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0226 - val_loss: 0.5933\n",
      "Epoch 9410/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0309 - val_loss: 0.6115\n",
      "Epoch 9411/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0733 - val_loss: 0.5893\n",
      "Epoch 9412/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0286 - val_loss: 0.5960\n",
      "Epoch 9413/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0099 - val_loss: 0.5863\n",
      "Epoch 9414/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0069 - val_loss: 0.5896\n",
      "Epoch 9415/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0061 - val_loss: 0.5789\n",
      "Epoch 9416/10000\n",
      "130/130 [==============================] - 0s 794us/step - loss: 0.0156 - val_loss: 0.6500\n",
      "Epoch 9417/10000\n",
      "130/130 [==============================] - 0s 799us/step - loss: 0.0516 - val_loss: 0.6019\n",
      "Epoch 9418/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0331 - val_loss: 0.5870\n",
      "Epoch 9419/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0287 - val_loss: 0.5948\n",
      "Epoch 9420/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0239 - val_loss: 0.6049\n",
      "Epoch 9421/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0234 - val_loss: 0.6010\n",
      "Epoch 9422/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0232 - val_loss: 0.5996\n",
      "Epoch 9423/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0174 - val_loss: 0.5936\n",
      "Epoch 9424/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0122 - val_loss: 0.6143\n",
      "Epoch 9425/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0168 - val_loss: 0.5799\n",
      "Epoch 9426/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0075 - val_loss: 0.5927\n",
      "Epoch 9427/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 740us/step - loss: 0.0061 - val_loss: 0.6001\n",
      "Epoch 9428/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0054 - val_loss: 0.5999\n",
      "Epoch 9429/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0058 - val_loss: 0.5969\n",
      "Epoch 9430/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0149 - val_loss: 0.5844\n",
      "Epoch 9431/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0407 - val_loss: 0.6151\n",
      "Epoch 9432/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0297 - val_loss: 0.5696\n",
      "Epoch 9433/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0257 - val_loss: 0.6121\n",
      "Epoch 9434/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0704 - val_loss: 0.6280\n",
      "Epoch 9435/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0321 - val_loss: 0.5979\n",
      "Epoch 9436/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0138 - val_loss: 0.6179\n",
      "Epoch 9437/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0107 - val_loss: 0.6008\n",
      "Epoch 9438/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0082 - val_loss: 0.6181\n",
      "Epoch 9439/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0082 - val_loss: 0.6147\n",
      "Epoch 9440/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0064 - val_loss: 0.6196\n",
      "Epoch 9441/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0158 - val_loss: 0.6224\n",
      "Epoch 9442/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0299 - val_loss: 0.5830\n",
      "Epoch 9443/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0233 - val_loss: 0.6210\n",
      "Epoch 9444/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0252 - val_loss: 0.6034\n",
      "Epoch 9445/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0203 - val_loss: 0.6016\n",
      "Epoch 9446/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0258 - val_loss: 0.5852\n",
      "Epoch 9447/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0251 - val_loss: 0.6122\n",
      "Epoch 9448/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0269 - val_loss: 0.5842\n",
      "Epoch 9449/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0255 - val_loss: 0.5721\n",
      "Epoch 9450/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0200 - val_loss: 0.6127\n",
      "Epoch 9451/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0133 - val_loss: 0.5928\n",
      "Epoch 9452/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0215 - val_loss: 0.6008\n",
      "Epoch 9453/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0337 - val_loss: 0.5881\n",
      "Epoch 9454/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0180 - val_loss: 0.5934\n",
      "Epoch 9455/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0130 - val_loss: 0.5937\n",
      "Epoch 9456/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0105 - val_loss: 0.5921\n",
      "Epoch 9457/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0120 - val_loss: 0.5859\n",
      "Epoch 9458/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0114 - val_loss: 0.5941\n",
      "Epoch 9459/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0139 - val_loss: 0.6144\n",
      "Epoch 9460/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0604 - val_loss: 0.6221\n",
      "Epoch 9461/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.1006 - val_loss: 0.6037\n",
      "Epoch 9462/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0651 - val_loss: 0.6175\n",
      "Epoch 9463/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0186 - val_loss: 0.6147\n",
      "Epoch 9464/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0139 - val_loss: 0.5973\n",
      "Epoch 9465/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0141 - val_loss: 0.5950\n",
      "Epoch 9466/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0121 - val_loss: 0.5883\n",
      "Epoch 9467/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0069 - val_loss: 0.5899\n",
      "Epoch 9468/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0053 - val_loss: 0.6058\n",
      "Epoch 9469/10000\n",
      "130/130 [==============================] - 0s 793us/step - loss: 0.0047 - val_loss: 0.6040\n",
      "Epoch 9470/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0058 - val_loss: 0.5919\n",
      "Epoch 9471/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0243 - val_loss: 0.6073\n",
      "Epoch 9472/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0545 - val_loss: 0.6424\n",
      "Epoch 9473/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0298 - val_loss: 0.5971\n",
      "Epoch 9474/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0257 - val_loss: 0.6183\n",
      "Epoch 9475/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0242 - val_loss: 0.5941\n",
      "Epoch 9476/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0181 - val_loss: 0.6193\n",
      "Epoch 9477/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0139 - val_loss: 0.5811\n",
      "Epoch 9478/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0142 - val_loss: 0.5808\n",
      "Epoch 9479/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0372 - val_loss: 0.6070\n",
      "Epoch 9480/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0364 - val_loss: 0.6482\n",
      "Epoch 9481/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0360 - val_loss: 0.6138\n",
      "Epoch 9482/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0221 - val_loss: 0.5960\n",
      "Epoch 9483/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0285 - val_loss: 0.6358\n",
      "Epoch 9484/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0160 - val_loss: 0.6132\n",
      "Epoch 9485/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0161 - val_loss: 0.6081\n",
      "Epoch 9486/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0130 - val_loss: 0.6088\n",
      "Epoch 9487/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0098 - val_loss: 0.6203\n",
      "Epoch 9488/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0185 - val_loss: 0.5901\n",
      "Epoch 9489/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0228 - val_loss: 0.6205\n",
      "Epoch 9490/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0335 - val_loss: 0.5945\n",
      "Epoch 9491/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0203 - val_loss: 0.5874\n",
      "Epoch 9492/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0275 - val_loss: 0.6533\n",
      "Epoch 9493/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0187 - val_loss: 0.6052\n",
      "Epoch 9494/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0156 - val_loss: 0.6053\n",
      "Epoch 9495/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0183 - val_loss: 0.5938\n",
      "Epoch 9496/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0125 - val_loss: 0.6065\n",
      "Epoch 9497/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0144 - val_loss: 0.6142\n",
      "Epoch 9498/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0152 - val_loss: 0.6200\n",
      "Epoch 9499/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0196 - val_loss: 0.6328\n",
      "Epoch 9500/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0246 - val_loss: 0.5979\n",
      "Epoch 9501/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0213 - val_loss: 0.6291\n",
      "Epoch 9502/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0367 - val_loss: 0.6254\n",
      "Epoch 9503/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 739us/step - loss: 0.0250 - val_loss: 0.6053\n",
      "Epoch 9504/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0192 - val_loss: 0.5913\n",
      "Epoch 9505/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0097 - val_loss: 0.6034\n",
      "Epoch 9506/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0070 - val_loss: 0.5967\n",
      "Epoch 9507/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0081 - val_loss: 0.6192\n",
      "Epoch 9508/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0193 - val_loss: 0.5927\n",
      "Epoch 9509/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0197 - val_loss: 0.6097\n",
      "Epoch 9510/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0147 - val_loss: 0.6051\n",
      "Epoch 9511/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0145 - val_loss: 0.6228\n",
      "Epoch 9512/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0235 - val_loss: 0.6623\n",
      "Epoch 9513/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0221 - val_loss: 0.6258\n",
      "Epoch 9514/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0414 - val_loss: 0.6593\n",
      "Epoch 9515/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0513 - val_loss: 0.6162\n",
      "Epoch 9516/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0205 - val_loss: 0.6156\n",
      "Epoch 9517/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0182 - val_loss: 0.6169\n",
      "Epoch 9518/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0157 - val_loss: 0.6032\n",
      "Epoch 9519/10000\n",
      "130/130 [==============================] - 0s 901us/step - loss: 0.0121 - val_loss: 0.6193\n",
      "Epoch 9520/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0179 - val_loss: 0.5978\n",
      "Epoch 9521/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0249 - val_loss: 0.6047\n",
      "Epoch 9522/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0171 - val_loss: 0.6202\n",
      "Epoch 9523/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0201 - val_loss: 0.6150\n",
      "Epoch 9524/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0245 - val_loss: 0.6426\n",
      "Epoch 9525/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0334 - val_loss: 0.6332\n",
      "Epoch 9526/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0296 - val_loss: 0.6074\n",
      "Epoch 9527/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0185 - val_loss: 0.5940\n",
      "Epoch 9528/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0404 - val_loss: 0.6291\n",
      "Epoch 9529/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0358 - val_loss: 0.6148\n",
      "Epoch 9530/10000\n",
      "130/130 [==============================] - 0s 779us/step - loss: 0.0171 - val_loss: 0.5874\n",
      "Epoch 9531/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0113 - val_loss: 0.6135\n",
      "Epoch 9532/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0081 - val_loss: 0.5926\n",
      "Epoch 9533/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0133 - val_loss: 0.5906\n",
      "Epoch 9534/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0148 - val_loss: 0.5851\n",
      "Epoch 9535/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0122 - val_loss: 0.6042\n",
      "Epoch 9536/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0111 - val_loss: 0.6013\n",
      "Epoch 9537/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0201 - val_loss: 0.6051\n",
      "Epoch 9538/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0369 - val_loss: 0.5988\n",
      "Epoch 9539/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0502 - val_loss: 0.6193\n",
      "Epoch 9540/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0297 - val_loss: 0.5933\n",
      "Epoch 9541/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0144 - val_loss: 0.5921\n",
      "Epoch 9542/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0115 - val_loss: 0.5997\n",
      "Epoch 9543/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0132 - val_loss: 0.6205\n",
      "Epoch 9544/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0142 - val_loss: 0.6054\n",
      "Epoch 9545/10000\n",
      "130/130 [==============================] - 0s 723us/step - loss: 0.0129 - val_loss: 0.6276\n",
      "Epoch 9546/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0128 - val_loss: 0.6164\n",
      "Epoch 9547/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0119 - val_loss: 0.6101\n",
      "Epoch 9548/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0180 - val_loss: 0.6295\n",
      "Epoch 9549/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0504 - val_loss: 0.6168\n",
      "Epoch 9550/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0995 - val_loss: 0.6120\n",
      "Epoch 9551/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0979 - val_loss: 0.6022\n",
      "Epoch 9552/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0349 - val_loss: 0.5826\n",
      "Epoch 9553/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0181 - val_loss: 0.5820\n",
      "Epoch 9554/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0205 - val_loss: 0.5986\n",
      "Epoch 9555/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0109 - val_loss: 0.5920\n",
      "Epoch 9556/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0130 - val_loss: 0.5904\n",
      "Epoch 9557/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0141 - val_loss: 0.5935\n",
      "Epoch 9558/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0152 - val_loss: 0.5918\n",
      "Epoch 9559/10000\n",
      "130/130 [==============================] - 0s 827us/step - loss: 0.0168 - val_loss: 0.6138\n",
      "Epoch 9560/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0148 - val_loss: 0.6238\n",
      "Epoch 9561/10000\n",
      "130/130 [==============================] - 0s 790us/step - loss: 0.0103 - val_loss: 0.6190\n",
      "Epoch 9562/10000\n",
      "130/130 [==============================] - 0s 811us/step - loss: 0.0112 - val_loss: 0.5983\n",
      "Epoch 9563/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0242 - val_loss: 0.6207\n",
      "Epoch 9564/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0304 - val_loss: 0.5940\n",
      "Epoch 9565/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0178 - val_loss: 0.6203\n",
      "Epoch 9566/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0214 - val_loss: 0.6012\n",
      "Epoch 9567/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0259 - val_loss: 0.6038\n",
      "Epoch 9568/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0255 - val_loss: 0.5894\n",
      "Epoch 9569/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0417 - val_loss: 0.6115\n",
      "Epoch 9570/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0271 - val_loss: 0.6015\n",
      "Epoch 9571/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0261 - val_loss: 0.5852\n",
      "Epoch 9572/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0136 - val_loss: 0.6248\n",
      "Epoch 9573/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0154 - val_loss: 0.6174\n",
      "Epoch 9574/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0189 - val_loss: 0.6372\n",
      "Epoch 9575/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0218 - val_loss: 0.6073\n",
      "Epoch 9576/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0195 - val_loss: 0.5928\n",
      "Epoch 9577/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0148 - val_loss: 0.6021\n",
      "Epoch 9578/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0132 - val_loss: 0.6135\n",
      "Epoch 9579/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 743us/step - loss: 0.0197 - val_loss: 0.6040\n",
      "Epoch 9580/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0171 - val_loss: 0.5914\n",
      "Epoch 9581/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0451 - val_loss: 0.6080\n",
      "Epoch 9582/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0349 - val_loss: 0.5968\n",
      "Epoch 9583/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0205 - val_loss: 0.5827\n",
      "Epoch 9584/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0197 - val_loss: 0.5900\n",
      "Epoch 9585/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0134 - val_loss: 0.6107\n",
      "Epoch 9586/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0118 - val_loss: 0.5793\n",
      "Epoch 9587/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0228 - val_loss: 0.5923\n",
      "Epoch 9588/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0172 - val_loss: 0.6012\n",
      "Epoch 9589/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0205 - val_loss: 0.6001\n",
      "Epoch 9590/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0315 - val_loss: 0.6064\n",
      "Epoch 9591/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0245 - val_loss: 0.5817\n",
      "Epoch 9592/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0273 - val_loss: 0.6057\n",
      "Epoch 9593/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0247 - val_loss: 0.5783\n",
      "Epoch 9594/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0189 - val_loss: 0.5836\n",
      "Epoch 9595/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0104 - val_loss: 0.6038\n",
      "Epoch 9596/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0075 - val_loss: 0.5944\n",
      "Epoch 9597/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0200 - val_loss: 0.6105\n",
      "Epoch 9598/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0312 - val_loss: 0.6081\n",
      "Epoch 9599/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0215 - val_loss: 0.6218\n",
      "Epoch 9600/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0246 - val_loss: 0.6017\n",
      "Epoch 9601/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0281 - val_loss: 0.6677\n",
      "Epoch 9602/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0431 - val_loss: 0.6002\n",
      "Epoch 9603/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0373 - val_loss: 0.5830\n",
      "Epoch 9604/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0132 - val_loss: 0.5976\n",
      "Epoch 9605/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0156 - val_loss: 0.5774\n",
      "Epoch 9606/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0215 - val_loss: 0.6012\n",
      "Epoch 9607/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0207 - val_loss: 0.6050\n",
      "Epoch 9608/10000\n",
      "130/130 [==============================] - 0s 772us/step - loss: 0.0215 - val_loss: 0.5740\n",
      "Epoch 9609/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0212 - val_loss: 0.5821\n",
      "Epoch 9610/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0151 - val_loss: 0.6074\n",
      "Epoch 9611/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0132 - val_loss: 0.5943\n",
      "Epoch 9612/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0122 - val_loss: 0.5749\n",
      "Epoch 9613/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0113 - val_loss: 0.5732\n",
      "Epoch 9614/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0090 - val_loss: 0.5708\n",
      "Epoch 9615/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0152 - val_loss: 0.5952\n",
      "Epoch 9616/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0251 - val_loss: 0.5992\n",
      "Epoch 9617/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0242 - val_loss: 0.6082\n",
      "Epoch 9618/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0259 - val_loss: 0.5935\n",
      "Epoch 9619/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0161 - val_loss: 0.5962\n",
      "Epoch 9620/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0178 - val_loss: 0.5841\n",
      "Epoch 9621/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0277 - val_loss: 0.6049\n",
      "Epoch 9622/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0317 - val_loss: 0.6140\n",
      "Epoch 9623/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0669 - val_loss: 0.5866\n",
      "Epoch 9624/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0294 - val_loss: 0.5853\n",
      "Epoch 9625/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0132 - val_loss: 0.5970\n",
      "Epoch 9626/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0103 - val_loss: 0.5885\n",
      "Epoch 9627/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0091 - val_loss: 0.5916\n",
      "Epoch 9628/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0125 - val_loss: 0.5952\n",
      "Epoch 9629/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0222 - val_loss: 0.5899\n",
      "Epoch 9630/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0236 - val_loss: 0.6051\n",
      "Epoch 9631/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0119 - val_loss: 0.5816\n",
      "Epoch 9632/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0377 - val_loss: 0.5986\n",
      "Epoch 9633/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0327 - val_loss: 0.6026\n",
      "Epoch 9634/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0210 - val_loss: 0.5946\n",
      "Epoch 9635/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0182 - val_loss: 0.5804\n",
      "Epoch 9636/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0124 - val_loss: 0.5983\n",
      "Epoch 9637/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0294 - val_loss: 0.5847\n",
      "Epoch 9638/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0130 - val_loss: 0.6035\n",
      "Epoch 9639/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0134 - val_loss: 0.6125\n",
      "Epoch 9640/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0106 - val_loss: 0.6224\n",
      "Epoch 9641/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0143 - val_loss: 0.5936\n",
      "Epoch 9642/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0114 - val_loss: 0.6132\n",
      "Epoch 9643/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0208 - val_loss: 0.5807\n",
      "Epoch 9644/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0245 - val_loss: 0.6179\n",
      "Epoch 9645/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0612 - val_loss: 0.5866\n",
      "Epoch 9646/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0616 - val_loss: 0.6173\n",
      "Epoch 9647/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0607 - val_loss: 0.6067\n",
      "Epoch 9648/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0251 - val_loss: 0.6104\n",
      "Epoch 9649/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0135 - val_loss: 0.6097\n",
      "Epoch 9650/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0110 - val_loss: 0.6166\n",
      "Epoch 9651/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0147 - val_loss: 0.6120\n",
      "Epoch 9652/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0294 - val_loss: 0.6240\n",
      "Epoch 9653/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0133 - val_loss: 0.6061\n",
      "Epoch 9654/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0076 - val_loss: 0.6151\n",
      "Epoch 9655/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 748us/step - loss: 0.0104 - val_loss: 0.6263\n",
      "Epoch 9656/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0116 - val_loss: 0.6110\n",
      "Epoch 9657/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0115 - val_loss: 0.6045\n",
      "Epoch 9658/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0149 - val_loss: 0.6447\n",
      "Epoch 9659/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0268 - val_loss: 0.6285\n",
      "Epoch 9660/10000\n",
      "130/130 [==============================] - 0s 820us/step - loss: 0.0386 - val_loss: 0.5975\n",
      "Epoch 9661/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0430 - val_loss: 0.6155\n",
      "Epoch 9662/10000\n",
      "130/130 [==============================] - 0s 771us/step - loss: 0.0333 - val_loss: 0.6244\n",
      "Epoch 9663/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0179 - val_loss: 0.6263\n",
      "Epoch 9664/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0129 - val_loss: 0.6034\n",
      "Epoch 9665/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0127 - val_loss: 0.5916\n",
      "Epoch 9666/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0311 - val_loss: 0.6049\n",
      "Epoch 9667/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0292 - val_loss: 0.5937\n",
      "Epoch 9668/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0271 - val_loss: 0.6040\n",
      "Epoch 9669/10000\n",
      "130/130 [==============================] - 0s 842us/step - loss: 0.0240 - val_loss: 0.6209\n",
      "Epoch 9670/10000\n",
      "130/130 [==============================] - 0s 781us/step - loss: 0.0118 - val_loss: 0.6138\n",
      "Epoch 9671/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0103 - val_loss: 0.6084\n",
      "Epoch 9672/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0112 - val_loss: 0.6021\n",
      "Epoch 9673/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0073 - val_loss: 0.6004\n",
      "Epoch 9674/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0107 - val_loss: 0.6014\n",
      "Epoch 9675/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0101 - val_loss: 0.5856\n",
      "Epoch 9676/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0223 - val_loss: 0.6085\n",
      "Epoch 9677/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0332 - val_loss: 0.6190\n",
      "Epoch 9678/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0333 - val_loss: 0.5797\n",
      "Epoch 9679/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0436 - val_loss: 0.5980\n",
      "Epoch 9680/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0562 - val_loss: 0.5892\n",
      "Epoch 9681/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0319 - val_loss: 0.5917\n",
      "Epoch 9682/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0128 - val_loss: 0.5911\n",
      "Epoch 9683/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0085 - val_loss: 0.5775\n",
      "Epoch 9684/10000\n",
      "130/130 [==============================] - 0s 762us/step - loss: 0.0051 - val_loss: 0.5909\n",
      "Epoch 9685/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0050 - val_loss: 0.5919\n",
      "Epoch 9686/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0062 - val_loss: 0.5922\n",
      "Epoch 9687/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0076 - val_loss: 0.5899\n",
      "Epoch 9688/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0153 - val_loss: 0.6289\n",
      "Epoch 9689/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0173 - val_loss: 0.6093\n",
      "Epoch 9690/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0343 - val_loss: 0.5716\n",
      "Epoch 9691/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0535 - val_loss: 0.6052\n",
      "Epoch 9692/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0448 - val_loss: 0.5851\n",
      "Epoch 9693/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0219 - val_loss: 0.5844\n",
      "Epoch 9694/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0333 - val_loss: 0.6196\n",
      "Epoch 9695/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0283 - val_loss: 0.6077\n",
      "Epoch 9696/10000\n",
      "130/130 [==============================] - 0s 770us/step - loss: 0.0193 - val_loss: 0.6034\n",
      "Epoch 9697/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0165 - val_loss: 0.5788\n",
      "Epoch 9698/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0222 - val_loss: 0.5813\n",
      "Epoch 9699/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0174 - val_loss: 0.6094\n",
      "Epoch 9700/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0181 - val_loss: 0.5999\n",
      "Epoch 9701/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0161 - val_loss: 0.5917\n",
      "Epoch 9702/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0135 - val_loss: 0.5880\n",
      "Epoch 9703/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0294 - val_loss: 0.6220\n",
      "Epoch 9704/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0206 - val_loss: 0.5956\n",
      "Epoch 9705/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0182 - val_loss: 0.5869\n",
      "Epoch 9706/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0138 - val_loss: 0.5914\n",
      "Epoch 9707/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0233 - val_loss: 0.6002\n",
      "Epoch 9708/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0164 - val_loss: 0.6007\n",
      "Epoch 9709/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0148 - val_loss: 0.6076\n",
      "Epoch 9710/10000\n",
      "130/130 [==============================] - 0s 757us/step - loss: 0.0209 - val_loss: 0.5995\n",
      "Epoch 9711/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0169 - val_loss: 0.6034\n",
      "Epoch 9712/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0344 - val_loss: 0.6387\n",
      "Epoch 9713/10000\n",
      "130/130 [==============================] - 0s 753us/step - loss: 0.0533 - val_loss: 0.5841\n",
      "Epoch 9714/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0311 - val_loss: 0.5763\n",
      "Epoch 9715/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0240 - val_loss: 0.5950\n",
      "Epoch 9716/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0210 - val_loss: 0.5919\n",
      "Epoch 9717/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0172 - val_loss: 0.6172\n",
      "Epoch 9718/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0233 - val_loss: 0.5651\n",
      "Epoch 9719/10000\n",
      "130/130 [==============================] - 0s 774us/step - loss: 0.0190 - val_loss: 0.5910\n",
      "Epoch 9720/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0546 - val_loss: 0.6013\n",
      "Epoch 9721/10000\n",
      "130/130 [==============================] - 0s 773us/step - loss: 0.0347 - val_loss: 0.6045\n",
      "Epoch 9722/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0311 - val_loss: 0.6106\n",
      "Epoch 9723/10000\n",
      "130/130 [==============================] - 0s 767us/step - loss: 0.0182 - val_loss: 0.5823\n",
      "Epoch 9724/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0153 - val_loss: 0.5992\n",
      "Epoch 9725/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0126 - val_loss: 0.5877\n",
      "Epoch 9726/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0143 - val_loss: 0.6094\n",
      "Epoch 9727/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0144 - val_loss: 0.5944\n",
      "Epoch 9728/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0173 - val_loss: 0.6205\n",
      "Epoch 9729/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0133 - val_loss: 0.6015\n",
      "Epoch 9730/10000\n",
      "130/130 [==============================] - 0s 775us/step - loss: 0.0066 - val_loss: 0.6026\n",
      "Epoch 9731/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 737us/step - loss: 0.0081 - val_loss: 0.6137\n",
      "Epoch 9732/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0245 - val_loss: 0.6023\n",
      "Epoch 9733/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0275 - val_loss: 0.5741\n",
      "Epoch 9734/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0501 - val_loss: 0.5948\n",
      "Epoch 9735/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0485 - val_loss: 0.6290\n",
      "Epoch 9736/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0303 - val_loss: 0.6033\n",
      "Epoch 9737/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0167 - val_loss: 0.5990\n",
      "Epoch 9738/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0155 - val_loss: 0.5997\n",
      "Epoch 9739/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0146 - val_loss: 0.6021\n",
      "Epoch 9740/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0145 - val_loss: 0.6018\n",
      "Epoch 9741/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0195 - val_loss: 0.6216\n",
      "Epoch 9742/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0156 - val_loss: 0.6113\n",
      "Epoch 9743/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0203 - val_loss: 0.6021\n",
      "Epoch 9744/10000\n",
      "130/130 [==============================] - 0s 755us/step - loss: 0.0264 - val_loss: 0.6301\n",
      "Epoch 9745/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0277 - val_loss: 0.6114\n",
      "Epoch 9746/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0156 - val_loss: 0.6171\n",
      "Epoch 9747/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0134 - val_loss: 0.6035\n",
      "Epoch 9748/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0112 - val_loss: 0.5967\n",
      "Epoch 9749/10000\n",
      "130/130 [==============================] - 0s 805us/step - loss: 0.0141 - val_loss: 0.6419\n",
      "Epoch 9750/10000\n",
      "130/130 [==============================] - 0s 802us/step - loss: 0.0174 - val_loss: 0.6288\n",
      "Epoch 9751/10000\n",
      "130/130 [==============================] - 0s 820us/step - loss: 0.0297 - val_loss: 0.6338\n",
      "Epoch 9752/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0308 - val_loss: 0.6314\n",
      "Epoch 9753/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0145 - val_loss: 0.6099\n",
      "Epoch 9754/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0178 - val_loss: 0.6217\n",
      "Epoch 9755/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0097 - val_loss: 0.6268\n",
      "Epoch 9756/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0112 - val_loss: 0.6303\n",
      "Epoch 9757/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0382 - val_loss: 0.6418\n",
      "Epoch 9758/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0293 - val_loss: 0.6214\n",
      "Epoch 9759/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0197 - val_loss: 0.5941\n",
      "Epoch 9760/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0155 - val_loss: 0.6272\n",
      "Epoch 9761/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0267 - val_loss: 0.6276\n",
      "Epoch 9762/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0228 - val_loss: 0.5765\n",
      "Epoch 9763/10000\n",
      "130/130 [==============================] - 0s 749us/step - loss: 0.0186 - val_loss: 0.5819\n",
      "Epoch 9764/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0196 - val_loss: 0.6336\n",
      "Epoch 9765/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0191 - val_loss: 0.6057\n",
      "Epoch 9766/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0233 - val_loss: 0.6133\n",
      "Epoch 9767/10000\n",
      "130/130 [==============================] - 0s 752us/step - loss: 0.0091 - val_loss: 0.6072\n",
      "Epoch 9768/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0101 - val_loss: 0.6210\n",
      "Epoch 9769/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0163 - val_loss: 0.6060\n",
      "Epoch 9770/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0297 - val_loss: 0.6285\n",
      "Epoch 9771/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0381 - val_loss: 0.6219\n",
      "Epoch 9772/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0386 - val_loss: 0.6513\n",
      "Epoch 9773/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0337 - val_loss: 0.6046\n",
      "Epoch 9774/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0203 - val_loss: 0.6336\n",
      "Epoch 9775/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0227 - val_loss: 0.6353\n",
      "Epoch 9776/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0106 - val_loss: 0.6087\n",
      "Epoch 9777/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0102 - val_loss: 0.6357\n",
      "Epoch 9778/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0179 - val_loss: 0.6134\n",
      "Epoch 9779/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0284 - val_loss: 0.6386\n",
      "Epoch 9780/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0174 - val_loss: 0.6321\n",
      "Epoch 9781/10000\n",
      "130/130 [==============================] - 0s 750us/step - loss: 0.0175 - val_loss: 0.5913\n",
      "Epoch 9782/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0206 - val_loss: 0.6221\n",
      "Epoch 9783/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0300 - val_loss: 0.6084\n",
      "Epoch 9784/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0210 - val_loss: 0.5819\n",
      "Epoch 9785/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0166 - val_loss: 0.6139\n",
      "Epoch 9786/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0199 - val_loss: 0.6341\n",
      "Epoch 9787/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0156 - val_loss: 0.5944\n",
      "Epoch 9788/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0147 - val_loss: 0.6079\n",
      "Epoch 9789/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0113 - val_loss: 0.6067\n",
      "Epoch 9790/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0121 - val_loss: 0.6165\n",
      "Epoch 9791/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0122 - val_loss: 0.5859\n",
      "Epoch 9792/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0345 - val_loss: 0.6081\n",
      "Epoch 9793/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0338 - val_loss: 0.5956\n",
      "Epoch 9794/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0355 - val_loss: 0.6196\n",
      "Epoch 9795/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0362 - val_loss: 0.6118\n",
      "Epoch 9796/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0221 - val_loss: 0.6148\n",
      "Epoch 9797/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0144 - val_loss: 0.5925\n",
      "Epoch 9798/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0128 - val_loss: 0.5843\n",
      "Epoch 9799/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0191 - val_loss: 0.6087\n",
      "Epoch 9800/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0280 - val_loss: 0.6162\n",
      "Epoch 9801/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0241 - val_loss: 0.6139\n",
      "Epoch 9802/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0298 - val_loss: 0.6097\n",
      "Epoch 9803/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0145 - val_loss: 0.5753\n",
      "Epoch 9804/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0175 - val_loss: 0.5905\n",
      "Epoch 9805/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0215 - val_loss: 0.6041\n",
      "Epoch 9806/10000\n",
      "130/130 [==============================] - 0s 746us/step - loss: 0.0133 - val_loss: 0.5834\n",
      "Epoch 9807/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 746us/step - loss: 0.0089 - val_loss: 0.6063\n",
      "Epoch 9808/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0182 - val_loss: 0.6067\n",
      "Epoch 9809/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0252 - val_loss: 0.5882\n",
      "Epoch 9810/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0396 - val_loss: 0.5991\n",
      "Epoch 9811/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0338 - val_loss: 0.6168\n",
      "Epoch 9812/10000\n",
      "130/130 [==============================] - 0s 798us/step - loss: 0.0226 - val_loss: 0.5837\n",
      "Epoch 9813/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0352 - val_loss: 0.6325\n",
      "Epoch 9814/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0230 - val_loss: 0.6022\n",
      "Epoch 9815/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0227 - val_loss: 0.6008\n",
      "Epoch 9816/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0125 - val_loss: 0.6280\n",
      "Epoch 9817/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0134 - val_loss: 0.6198\n",
      "Epoch 9818/10000\n",
      "130/130 [==============================] - 0s 766us/step - loss: 0.0091 - val_loss: 0.6185\n",
      "Epoch 9819/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0098 - val_loss: 0.5949\n",
      "Epoch 9820/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0096 - val_loss: 0.5951\n",
      "Epoch 9821/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0170 - val_loss: 0.5998\n",
      "Epoch 9822/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0178 - val_loss: 0.5942\n",
      "Epoch 9823/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0173 - val_loss: 0.6035\n",
      "Epoch 9824/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0241 - val_loss: 0.5997\n",
      "Epoch 9825/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0356 - val_loss: 0.6013\n",
      "Epoch 9826/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0475 - val_loss: 0.5806\n",
      "Epoch 9827/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0331 - val_loss: 0.6051\n",
      "Epoch 9828/10000\n",
      "130/130 [==============================] - 0s 783us/step - loss: 0.0167 - val_loss: 0.6107\n",
      "Epoch 9829/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0132 - val_loss: 0.5911\n",
      "Epoch 9830/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0109 - val_loss: 0.5952\n",
      "Epoch 9831/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0101 - val_loss: 0.6172\n",
      "Epoch 9832/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0111 - val_loss: 0.6111\n",
      "Epoch 9833/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0360 - val_loss: 0.6011\n",
      "Epoch 9834/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0320 - val_loss: 0.6146\n",
      "Epoch 9835/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0165 - val_loss: 0.5892\n",
      "Epoch 9836/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0109 - val_loss: 0.6180\n",
      "Epoch 9837/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0116 - val_loss: 0.6036\n",
      "Epoch 9838/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0156 - val_loss: 0.6339\n",
      "Epoch 9839/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0286 - val_loss: 0.6230\n",
      "Epoch 9840/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0450 - val_loss: 0.5951\n",
      "Epoch 9841/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0297 - val_loss: 0.6020\n",
      "Epoch 9842/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0215 - val_loss: 0.6159\n",
      "Epoch 9843/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0195 - val_loss: 0.6215\n",
      "Epoch 9844/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0188 - val_loss: 0.6099\n",
      "Epoch 9845/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0138 - val_loss: 0.6250\n",
      "Epoch 9846/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0180 - val_loss: 0.6061\n",
      "Epoch 9847/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0257 - val_loss: 0.6139\n",
      "Epoch 9848/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0195 - val_loss: 0.6292\n",
      "Epoch 9849/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0326 - val_loss: 0.6098\n",
      "Epoch 9850/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0237 - val_loss: 0.6289\n",
      "Epoch 9851/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0250 - val_loss: 0.5934\n",
      "Epoch 9852/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0206 - val_loss: 0.6257\n",
      "Epoch 9853/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0295 - val_loss: 0.6401\n",
      "Epoch 9854/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0339 - val_loss: 0.5875\n",
      "Epoch 9855/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0186 - val_loss: 0.6053\n",
      "Epoch 9856/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0187 - val_loss: 0.5948\n",
      "Epoch 9857/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0222 - val_loss: 0.6052\n",
      "Epoch 9858/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0097 - val_loss: 0.6199\n",
      "Epoch 9859/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0256 - val_loss: 0.6055\n",
      "Epoch 9860/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0162 - val_loss: 0.6085\n",
      "Epoch 9861/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0243 - val_loss: 0.5816\n",
      "Epoch 9862/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0149 - val_loss: 0.6164\n",
      "Epoch 9863/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0616 - val_loss: 0.6476\n",
      "Epoch 9864/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0470 - val_loss: 0.6039\n",
      "Epoch 9865/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0270 - val_loss: 0.6105\n",
      "Epoch 9866/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0151 - val_loss: 0.6124\n",
      "Epoch 9867/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0101 - val_loss: 0.5959\n",
      "Epoch 9868/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0076 - val_loss: 0.5890\n",
      "Epoch 9869/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0084 - val_loss: 0.6062\n",
      "Epoch 9870/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0309 - val_loss: 0.5794\n",
      "Epoch 9871/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0271 - val_loss: 0.6046\n",
      "Epoch 9872/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0197 - val_loss: 0.6403\n",
      "Epoch 9873/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0236 - val_loss: 0.5957\n",
      "Epoch 9874/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0237 - val_loss: 0.5797\n",
      "Epoch 9875/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0297 - val_loss: 0.5790\n",
      "Epoch 9876/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0270 - val_loss: 0.5918\n",
      "Epoch 9877/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0214 - val_loss: 0.6025\n",
      "Epoch 9878/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0140 - val_loss: 0.6073\n",
      "Epoch 9879/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0116 - val_loss: 0.5803\n",
      "Epoch 9880/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0085 - val_loss: 0.5866\n",
      "Epoch 9881/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0127 - val_loss: 0.6024\n",
      "Epoch 9882/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0112 - val_loss: 0.5976\n",
      "Epoch 9883/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 733us/step - loss: 0.0170 - val_loss: 0.6146\n",
      "Epoch 9884/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0180 - val_loss: 0.5935\n",
      "Epoch 9885/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0249 - val_loss: 0.6226\n",
      "Epoch 9886/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0370 - val_loss: 0.6018\n",
      "Epoch 9887/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0143 - val_loss: 0.6218\n",
      "Epoch 9888/10000\n",
      "130/130 [==============================] - 0s 722us/step - loss: 0.0140 - val_loss: 0.6058\n",
      "Epoch 9889/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0132 - val_loss: 0.5839\n",
      "Epoch 9890/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0195 - val_loss: 0.6379\n",
      "Epoch 9891/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0508 - val_loss: 0.6349\n",
      "Epoch 9892/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0494 - val_loss: 0.6235\n",
      "Epoch 9893/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0519 - val_loss: 0.5923\n",
      "Epoch 9894/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0235 - val_loss: 0.6160\n",
      "Epoch 9895/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0158 - val_loss: 0.5936\n",
      "Epoch 9896/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0173 - val_loss: 0.6217\n",
      "Epoch 9897/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0107 - val_loss: 0.6102\n",
      "Epoch 9898/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0104 - val_loss: 0.6138\n",
      "Epoch 9899/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0114 - val_loss: 0.6047\n",
      "Epoch 9900/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0135 - val_loss: 0.5843\n",
      "Epoch 9901/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0189 - val_loss: 0.5955\n",
      "Epoch 9902/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0199 - val_loss: 0.5928\n",
      "Epoch 9903/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0179 - val_loss: 0.6281\n",
      "Epoch 9904/10000\n",
      "130/130 [==============================] - 0s 724us/step - loss: 0.0164 - val_loss: 0.5881\n",
      "Epoch 9905/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0179 - val_loss: 0.6028\n",
      "Epoch 9906/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0231 - val_loss: 0.6347\n",
      "Epoch 9907/10000\n",
      "130/130 [==============================] - 0s 728us/step - loss: 0.0521 - val_loss: 0.6271\n",
      "Epoch 9908/10000\n",
      "130/130 [==============================] - 0s 751us/step - loss: 0.0455 - val_loss: 0.5731\n",
      "Epoch 9909/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0254 - val_loss: 0.6027\n",
      "Epoch 9910/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0162 - val_loss: 0.5946\n",
      "Epoch 9911/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0122 - val_loss: 0.6051\n",
      "Epoch 9912/10000\n",
      "130/130 [==============================] - 0s 761us/step - loss: 0.0058 - val_loss: 0.5821\n",
      "Epoch 9913/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0106 - val_loss: 0.5881\n",
      "Epoch 9914/10000\n",
      "130/130 [==============================] - 0s 760us/step - loss: 0.0298 - val_loss: 0.5906\n",
      "Epoch 9915/10000\n",
      "130/130 [==============================] - 0s 765us/step - loss: 0.0464 - val_loss: 0.6387\n",
      "Epoch 9916/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0459 - val_loss: 0.5933\n",
      "Epoch 9917/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0278 - val_loss: 0.6066\n",
      "Epoch 9918/10000\n",
      "130/130 [==============================] - 0s 769us/step - loss: 0.0119 - val_loss: 0.6040\n",
      "Epoch 9919/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0183 - val_loss: 0.6083\n",
      "Epoch 9920/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0460 - val_loss: 0.6106\n",
      "Epoch 9921/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0358 - val_loss: 0.6101\n",
      "Epoch 9922/10000\n",
      "130/130 [==============================] - 0s 878us/step - loss: 0.0184 - val_loss: 0.6003\n",
      "Epoch 9923/10000\n",
      "130/130 [==============================] - 0s 784us/step - loss: 0.0091 - val_loss: 0.5967\n",
      "Epoch 9924/10000\n",
      "130/130 [==============================] - 0s 763us/step - loss: 0.0062 - val_loss: 0.5985\n",
      "Epoch 9925/10000\n",
      "130/130 [==============================] - 0s 744us/step - loss: 0.0075 - val_loss: 0.6086\n",
      "Epoch 9926/10000\n",
      "130/130 [==============================] - 0s 759us/step - loss: 0.0170 - val_loss: 0.5748\n",
      "Epoch 9927/10000\n",
      "130/130 [==============================] - 0s 745us/step - loss: 0.0148 - val_loss: 0.5960\n",
      "Epoch 9928/10000\n",
      "130/130 [==============================] - 0s 821us/step - loss: 0.0190 - val_loss: 0.6202\n",
      "Epoch 9929/10000\n",
      "130/130 [==============================] - 0s 786us/step - loss: 0.0274 - val_loss: 0.5957\n",
      "Epoch 9930/10000\n",
      "130/130 [==============================] - 0s 785us/step - loss: 0.0167 - val_loss: 0.5969\n",
      "Epoch 9931/10000\n",
      "130/130 [==============================] - 0s 768us/step - loss: 0.0184 - val_loss: 0.6062\n",
      "Epoch 9932/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0199 - val_loss: 0.6010\n",
      "Epoch 9933/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0161 - val_loss: 0.5924\n",
      "Epoch 9934/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0094 - val_loss: 0.6157\n",
      "Epoch 9935/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0103 - val_loss: 0.6042\n",
      "Epoch 9936/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0385 - val_loss: 0.5963\n",
      "Epoch 9937/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0891 - val_loss: 0.5911\n",
      "Epoch 9938/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0564 - val_loss: 0.6258\n",
      "Epoch 9939/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0314 - val_loss: 0.6116\n",
      "Epoch 9940/10000\n",
      "130/130 [==============================] - 0s 756us/step - loss: 0.0185 - val_loss: 0.5965\n",
      "Epoch 9941/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0212 - val_loss: 0.6036\n",
      "Epoch 9942/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0122 - val_loss: 0.6053\n",
      "Epoch 9943/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0083 - val_loss: 0.6020\n",
      "Epoch 9944/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0105 - val_loss: 0.5889\n",
      "Epoch 9945/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0110 - val_loss: 0.6134\n",
      "Epoch 9946/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0125 - val_loss: 0.6165\n",
      "Epoch 9947/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0236 - val_loss: 0.6195\n",
      "Epoch 9948/10000\n",
      "130/130 [==============================] - 0s 818us/step - loss: 0.0285 - val_loss: 0.6149\n",
      "Epoch 9949/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0378 - val_loss: 0.6311\n",
      "Epoch 9950/10000\n",
      "130/130 [==============================] - 0s 726us/step - loss: 0.0266 - val_loss: 0.6177\n",
      "Epoch 9951/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0101 - val_loss: 0.6054\n",
      "Epoch 9952/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0099 - val_loss: 0.6079\n",
      "Epoch 9953/10000\n",
      "130/130 [==============================] - 0s 764us/step - loss: 0.0099 - val_loss: 0.6107\n",
      "Epoch 9954/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0136 - val_loss: 0.5671\n",
      "Epoch 9955/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0232 - val_loss: 0.5796\n",
      "Epoch 9956/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0311 - val_loss: 0.5924\n",
      "Epoch 9957/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0259 - val_loss: 0.5910\n",
      "Epoch 9958/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0215 - val_loss: 0.6095\n",
      "Epoch 9959/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 724us/step - loss: 0.0185 - val_loss: 0.6299\n",
      "Epoch 9960/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0189 - val_loss: 0.6214\n",
      "Epoch 9961/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0127 - val_loss: 0.6216\n",
      "Epoch 9962/10000\n",
      "130/130 [==============================] - 0s 730us/step - loss: 0.0117 - val_loss: 0.6162\n",
      "Epoch 9963/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0228 - val_loss: 0.5928\n",
      "Epoch 9964/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0225 - val_loss: 0.5891\n",
      "Epoch 9965/10000\n",
      "130/130 [==============================] - 0s 735us/step - loss: 0.0131 - val_loss: 0.5778\n",
      "Epoch 9966/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0145 - val_loss: 0.6326\n",
      "Epoch 9967/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0292 - val_loss: 0.6332\n",
      "Epoch 9968/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0340 - val_loss: 0.6220\n",
      "Epoch 9969/10000\n",
      "130/130 [==============================] - 0s 748us/step - loss: 0.0382 - val_loss: 0.6043\n",
      "Epoch 9970/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0357 - val_loss: 0.6053\n",
      "Epoch 9971/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0255 - val_loss: 0.6091\n",
      "Epoch 9972/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0175 - val_loss: 0.5818\n",
      "Epoch 9973/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0319 - val_loss: 0.5896\n",
      "Epoch 9974/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0263 - val_loss: 0.5857\n",
      "Epoch 9975/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0174 - val_loss: 0.6301\n",
      "Epoch 9976/10000\n",
      "130/130 [==============================] - 0s 725us/step - loss: 0.0209 - val_loss: 0.6675\n",
      "Epoch 9977/10000\n",
      "130/130 [==============================] - 0s 741us/step - loss: 0.0502 - val_loss: 0.6065\n",
      "Epoch 9978/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0248 - val_loss: 0.6049\n",
      "Epoch 9979/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0134 - val_loss: 0.6083\n",
      "Epoch 9980/10000\n",
      "130/130 [==============================] - 0s 731us/step - loss: 0.0103 - val_loss: 0.6103\n",
      "Epoch 9981/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0126 - val_loss: 0.5967\n",
      "Epoch 9982/10000\n",
      "130/130 [==============================] - 0s 736us/step - loss: 0.0129 - val_loss: 0.6153\n",
      "Epoch 9983/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0105 - val_loss: 0.6130\n",
      "Epoch 9984/10000\n",
      "130/130 [==============================] - 0s 747us/step - loss: 0.0076 - val_loss: 0.6215\n",
      "Epoch 9985/10000\n",
      "130/130 [==============================] - 0s 727us/step - loss: 0.0121 - val_loss: 0.6208\n",
      "Epoch 9986/10000\n",
      "130/130 [==============================] - 0s 758us/step - loss: 0.0105 - val_loss: 0.6169\n",
      "Epoch 9987/10000\n",
      "130/130 [==============================] - 0s 754us/step - loss: 0.0194 - val_loss: 0.6109\n",
      "Epoch 9988/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0280 - val_loss: 0.6264\n",
      "Epoch 9989/10000\n",
      "130/130 [==============================] - 0s 739us/step - loss: 0.0467 - val_loss: 0.6012\n",
      "Epoch 9990/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0427 - val_loss: 0.6149\n",
      "Epoch 9991/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0328 - val_loss: 0.6125\n",
      "Epoch 9992/10000\n",
      "130/130 [==============================] - 0s 729us/step - loss: 0.0220 - val_loss: 0.5940\n",
      "Epoch 9993/10000\n",
      "130/130 [==============================] - 0s 743us/step - loss: 0.0219 - val_loss: 0.5998\n",
      "Epoch 9994/10000\n",
      "130/130 [==============================] - 0s 734us/step - loss: 0.0122 - val_loss: 0.5872\n",
      "Epoch 9995/10000\n",
      "130/130 [==============================] - 0s 733us/step - loss: 0.0096 - val_loss: 0.5995\n",
      "Epoch 9996/10000\n",
      "130/130 [==============================] - 0s 738us/step - loss: 0.0220 - val_loss: 0.6224\n",
      "Epoch 9997/10000\n",
      "130/130 [==============================] - 0s 732us/step - loss: 0.0288 - val_loss: 0.6083\n",
      "Epoch 9998/10000\n",
      "130/130 [==============================] - 0s 742us/step - loss: 0.0348 - val_loss: 0.6254\n",
      "Epoch 9999/10000\n",
      "130/130 [==============================] - 0s 740us/step - loss: 0.0169 - val_loss: 0.6176\n",
      "Epoch 10000/10000\n",
      "130/130 [==============================] - 0s 737us/step - loss: 0.0178 - val_loss: 0.6131\n",
      "CPU times: user 35min 33s, sys: 6min 29s, total: 42min 3s\n",
      "Wall time: 16min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tmp = fp_datamodel.fit(\n",
    "    x[p],y[p],\n",
    "    epochs=10000,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(smooth(history['loss'],20)[100:])\n",
    "plt.plot(smooth(history['val_loss'],20)[100:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565715319027951\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.square(y.mean() - y.flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8150286108644117\n",
      "1.58125\n"
     ]
    }
   ],
   "source": [
    "pred = fp_datamodel.predict(test_dfs[-1].drop('quality',axis=1).to_numpy())\n",
    "print(np.mean(np.square(pred.flatten() - test_dfs[-1]['quality'].to_numpy().flatten())))\n",
    "print(np.mean(np.square(test_dfs[0]['quality'].mean() - test_dfs[-1]['quality'].to_numpy().flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36627927928501364\n",
      "0.6231343283582089\n"
     ]
    }
   ],
   "source": [
    "pred = fp_datamodel.predict(test_dfs[0].drop('quality',axis=1).to_numpy())\n",
    "print(np.mean(np.square(pred.flatten() - test_dfs[0]['quality'].to_numpy().flatten())))\n",
    "print(np.mean(np.square(test_dfs[0]['quality'].mean() - test_dfs[0]['quality'].to_numpy().flatten())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CWAcc1(tf.keras.metrics.Metric):\n",
    "    def __init__(self, class_idx, name='classwise_accuracy1', num_classes=10, **kwargs):\n",
    "        super(CWAcc1, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.class_idx = class_idx\n",
    "        self.num_correct = self.add_weight(name='num_correct',initializer='zeros')\n",
    "        self.num_samples = self.add_weight(name='num_samples',initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.reshape(tf.cast(y_true, tf.int16),(1,-1))\n",
    "        y_pred = tf.reshape(tf.cast(tf.argmax(y_pred,axis=1), tf.int16),(1,-1))\n",
    "                \n",
    "        count_correct = tf.math.reduce_sum(tf.cast(tf.math.logical_and(\n",
    "            tf.equal(y_true,y_pred),\n",
    "            tf.equal(y_true,tf.math.multiply(tf.ones_like(y_true),self.class_idx))\n",
    "        ),dtype=tf.float32))\n",
    "        \n",
    "        count_class = tf.math.reduce_sum(tf.cast(\n",
    "            tf.equal(y_true,tf.math.multiply(tf.ones_like(y_true),self.class_idx)),\n",
    "            dtype=tf.float32\n",
    "        ))\n",
    "        \n",
    "        self.num_correct.assign_add(count_correct)\n",
    "        self.num_samples.assign_add(count_class)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.math.divide_no_nan(self.num_correct,self.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth[:-box_pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[0.7664722 , 0.        , 0.        , 0.8010844 , 0.26033926,\n",
       "        0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_mask(grads):\n",
    "    mask = []\n",
    "    for g in grads:\n",
    "        size = g.shape[0]\n",
    "        m = 2\n",
    "        assert m%1==0\n",
    "\n",
    "        split = tf.concat([tf.ones(size//m)*i for i in range(m)],0)\n",
    "        split = tf.random.shuffle(split)\n",
    "        mask.append(tf.reshape(split,(1,-1)))\n",
    "\n",
    "    return mask\n",
    "\n",
    "grads = [tf.random.uniform(((x+1)*2,)) for x in range(10)]\n",
    "\n",
    "res = gen_mask(grads)\n",
    "tf.math.multiply(res[2],grads[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import random\n",
    "\n",
    "class Car():\n",
    "    def __init__(self,neighbors,p=1.0):\n",
    "        self.neighbors = neighbors\n",
    "        self.fwd_q = []\n",
    "        self.rec_grad = set()\n",
    "        self.new_grad = []\n",
    "        self.p = p\n",
    "        \n",
    "    def forward(self,lst_cars,):\n",
    "        for n,c in enumerate(lst_cars):\n",
    "            if n in self.neighbors:\n",
    "                for grad in self.fwd_q:\n",
    "                    if self.p < random.random():\n",
    "                        c.receive(grad)\n",
    "                    \n",
    "    def _hash(self,data):\n",
    "        bts = str(data).encode('utf-8')#tf.io.serialize_tensor(grad)\n",
    "        return hashlib.sha256(bts).digest()\n",
    "    \n",
    "    def _mark_seen(self,data,hash=False):\n",
    "        tmp = self._hash(data) if hash else data\n",
    "        self.rec_grad.add(tmp)\n",
    "        \n",
    "    def already_rec(self,grad,):\n",
    "        hashed = self._hash(grad)\n",
    "        \n",
    "        if hashed in self.rec_grad:\n",
    "            return (True,hashed)\n",
    "        else:\n",
    "            return (False,hashed)\n",
    "        \n",
    "    def apply_grad(self,grad,hashed,target,):\n",
    "        self._mark_seen(hashed)\n",
    "        return [tf.math.add(t,g) for t,g in zip(target,grad)]\n",
    "    \n",
    "    def apply_grads(self,target,):\n",
    "        self.fwd_q=[]\n",
    "        for g in self.new_grad:\n",
    "            bl,hashed = self.already_rec(g)\n",
    "            if not bl:\n",
    "                target = self.apply_grad(g,hashed,target)\n",
    "                self.fwd_q.append(g)\n",
    "        self.new_grad=[]\n",
    "        return target\n",
    "    \n",
    "    def receive(self,grad,):\n",
    "        self.new_grad.append(grad)\n",
    "        \n",
    "    def load(self,grad,):\n",
    "        self.fwd_q.append(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from copy import deepcopy\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cw_acc(y_true,y_pred):\n",
    "    y_pred = np.argmax(y_pred,axis=1)\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    return matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "def gen_mask(grads,m=2):\n",
    "    mask = []\n",
    "    for g in grads:\n",
    "        size = g.shape[-1]\n",
    "        assert m%1==0\n",
    "\n",
    "        split = tf.concat([tf.ones(size//m)*i for i in range(m)],0)\n",
    "        split = tf.random.shuffle(split)\n",
    "        mask.append(tf.reshape(split,(1,-1)))\n",
    "\n",
    "    return mask\n",
    "\n",
    "class DistMLP(keras.Model):\n",
    "    def __init__(self,mode='none',p=1.0):\n",
    "        super(DistMLP, self).__init__()\n",
    "        self.mod1 = Sequential([\n",
    "            layers.Dense(64, activation='sigmoid', input_shape=(11,)),\n",
    "            layers.Dense(32, activation='sigmoid'),\n",
    "            layers.Dense(16, activation='sigmoid'),\n",
    "            layers.Dense(1, 'linear')\n",
    "        ])\n",
    "        \n",
    "        self.mod2 = tf.keras.models.clone_model(self.mod1)\n",
    "        self.mod3 = tf.keras.models.clone_model(self.mod1)\n",
    "        self.mod4 = tf.keras.models.clone_model(self.mod1)\n",
    "        \n",
    "        self.mode=mode\n",
    "        \n",
    "        self.cars = [Car([i%2,],p=p) for i in range(1,5)]\n",
    "        self.gradients = []\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.mod1(data)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x1,y1,x2,y2,x3,y3,x4,y4, = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred1 = self.mod1(x1,training=True)\n",
    "            y_pred2 = self.mod2(x2,training=True)\n",
    "            y_pred3 = self.mod3(x3,training=True)\n",
    "            y_pred4 = self.mod4(x4,training=True)\n",
    "            loss1 = self.compiled_loss(y1,y_pred1)\n",
    "            loss2 = self.compiled_loss(y2,y_pred2)\n",
    "            loss3 = self.compiled_loss(y3,y_pred3)\n",
    "            loss4 = self.compiled_loss(y4,y_pred4)\n",
    "\n",
    "        grads = tape.gradient([loss1,loss2,loss3,loss4], self.trainable_weights)\n",
    "        \n",
    "        if self.mode=='none':\n",
    "            # Independent Learning\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        elif self.mode=='simple_add':\n",
    "            # Traditional Federated Learning: https://www.cs.cornell.edu/~shmat/shmat_ccs15.pdf\n",
    "            temp = [tf.math.divide(tf.math.add_n([grads[n+i*(len(grads)//4)] for i in range(4)]) for n in range(len(grads)//4),4)]\n",
    "            self.optimizer.apply_gradients(zip([*temp,*temp,*temp,*temp], self.trainable_weights))\n",
    "        elif self.mode=='djgrad':\n",
    "            # Proposed Method\n",
    "            grad_mask = [tf.reshape(m,(-1,)) if len(g.shape)==1 else m for m,g in zip(gen_mask(grads),grads)]\n",
    "            masked_grads = [tf.math.multiply(g,m) for m,g in zip(grad_mask,grads)]\n",
    "            new_grads = []\n",
    "            \n",
    "            for n,c in enumerate(self.cars):\n",
    "                i1,i2 = (len(grads)//4)*n,(len(grads)//4)*(n+1)\n",
    "                new_grads+=c.apply_grads(grads[i1:i2])\n",
    "                c.load(masked_grads[i1:i2])\n",
    "                c._mark_seen(masked_grads[i1:i2],True)\n",
    "                c.forward(self.cars)\n",
    "                 \n",
    "            self.optimizer.apply_gradients(zip(\n",
    "                [tf.math.add(g,n) for g,n in zip(grads,new_grads)],\n",
    "                self.trainable_weights))\n",
    "        \n",
    "        # Need a metric that gives accuracy for each model individually\n",
    "        for m in self.compiled_metrics._user_metrics:\n",
    "            m.update_state(tf.concat([y1,y2,y3,y4],0), tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0),source_array=tf.concat([x1[:,-1],x2[:,-1],x3[:,-1],x4[:,-1]],0))\n",
    "\n",
    "        return {m.name: m.result() for m in self.compiled_metrics._user_metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        y_pred1 = self.mod1(x,training=False)\n",
    "        y_pred2 = self.mod2(x,training=False)\n",
    "        y_pred3 = self.mod3(x,training=False)\n",
    "        y_pred4 = self.mod4(x,training=False)\n",
    "                \n",
    "        self.compiled_loss(tf.concat([y,y,y,y,],0),tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0))\n",
    "        for m in self.compiled_metrics._user_metrics:\n",
    "            m.update_state(tf.concat([y,y,y,y],0),tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0),source_array=tf.concat([x[:,-1],x[:,-1],x[:,-1],x[:,-1]],0))\n",
    "\n",
    "        return {m.name: m.result() for m in self.compiled_metrics._user_metrics}\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        for m in self.compiled_metrics._user_metrics:\n",
    "            m.reset_state()\n",
    "        for m in self.metrics:\n",
    "            m.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CWMet(tf.keras.metrics.Metric):\n",
    "    def __init__(self, car_idx, minmax, name='classwise_accuracy', num_cars=4, **kwargs):\n",
    "        super(CWMet, self).__init__(name=name, **kwargs)\n",
    "        self.num_cars = num_cars\n",
    "        self.car_idx = car_idx\n",
    "        self.minmax = minmax\n",
    "        self.loss = self.add_weight(name='loss',initializer='zeros')\n",
    "        self.num_samples = self.add_weight(name='num_samples',initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, source_array=None, sample_weight=None):\n",
    "        y_true = tf.reshape(y_true, (4,-1))[self.car_idx]\n",
    "        y_pred = tf.reshape(y_pred, (4,-1))[self.car_idx]\n",
    "        source_array = tf.reshape(source_array, (4,-1))[self.car_idx]\n",
    "\n",
    "        bl_mask = tf.math.logical_and(\n",
    "            tf.math.greater_equal(source_array, self.minmax[0]),\n",
    "            tf.math.greater_equal(self.minmax[1],source_array),\n",
    "        )\n",
    "        \n",
    "#         print(source_array)\n",
    "        print(y_true.shape,tf.boolean_mask(tf.cast(y_true, tf.float32), bl_mask).shape)\n",
    "        \n",
    "        y_true = tf.boolean_mask(tf.cast(y_true, tf.float32), bl_mask)\n",
    "        y_pred = tf.boolean_mask(tf.cast(y_pred, tf.float32), bl_mask)\n",
    "        \n",
    "#         print(np.max(source_array),np.min(source_array),self.minmax,source_array.shape,y_true)\n",
    "#         print(tf.math.greater_equal(self.minmax[0],source_array))\n",
    "        \n",
    "        loss = tf.math.reduce_sum(tf.math.square(y_true-y_pred))\n",
    "\n",
    "        count_class = tf.math.reduce_sum(tf.cast(bl_mask,dtype=tf.float32))#tf.cast(y_true.get_shape().as_list()[0],dtype=tf.float32)\n",
    "        \n",
    "        self.loss.assign_add(loss)\n",
    "        self.num_samples.assign_add(count_class)\n",
    "\n",
    "    def result(self):\n",
    "#         print(self.num_samples)\n",
    "        return tf.math.divide_no_nan(self.loss,self.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len = min([x.shape[0] for x in train_dfs])\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    train_dfs[0].drop('quality',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[0]['quality'].to_numpy()[:min_len],\n",
    "    train_dfs[1].drop('quality',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[1]['quality'].to_numpy()[:min_len],\n",
    "    train_dfs[2].drop('quality',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[2]['quality'].to_numpy()[:min_len],\n",
    "    train_dfs[3].drop('quality',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[3]['quality'].to_numpy()[:min_len],\n",
    ")).shuffle(100).batch(128,True)\n",
    "\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    np.concatenate((\n",
    "        test_dfs[0].drop('quality',axis=1).to_numpy(),\n",
    "        test_dfs[1].drop('quality',axis=1).to_numpy(),\n",
    "        test_dfs[2].drop('quality',axis=1).to_numpy(),\n",
    "        test_dfs[3].drop('quality',axis=1).to_numpy(),\n",
    "    )),\n",
    "    np.concatenate((\n",
    "        test_dfs[0]['quality'].to_numpy(),\n",
    "        test_dfs[1]['quality'].to_numpy(),\n",
    "        test_dfs[2]['quality'].to_numpy(),\n",
    "        test_dfs[3]['quality'].to_numpy(),\n",
    "    ))\n",
    ")).shuffle(100).batch(128,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 35.2617 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 25.2402 - ca2-[9.5,10.3): 26.1241 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 26.6720 - ca3-[10.3,11.3): 29.7240 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 34.3360 - ca4-[11.3,14.9): 36.5978 - val_ca1-[8.0,9.5): 31.5946 - val_ca1-[9.5,10.3): 33.0574 - val_ca1-[10.3,11.3): 37.4782 - val_ca1-[11.3,14.9): 43.8057 - val_ca2-[8.0,9.5): 22.6141 - val_ca2-[9.5,10.3): 23.7830 - val_ca2-[10.3,11.3): 27.5970 - val_ca2-[11.3,14.9): 33.0448 - val_ca3-[8.0,9.5): 21.5477 - val_ca3-[9.5,10.3): 22.6995 - val_ca3-[10.3,11.3): 26.4370 - val_ca3-[11.3,14.9): 31.7492 - val_ca4-[8.0,9.5): 23.0317 - val_ca4-[9.5,10.3): 24.2364 - val_ca4-[10.3,11.3): 28.0360 - val_ca4-[11.3,14.9): 33.4734\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 31.1642 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 21.8687 - ca2-[9.5,10.3): 22.8079 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 22.8432 - ca3-[10.3,11.3): 25.6363 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 30.5075 - ca4-[11.3,14.9): 32.5921 - val_ca1-[8.0,9.5): 27.8593 - val_ca1-[9.5,10.3): 29.2114 - val_ca1-[10.3,11.3): 33.3605 - val_ca1-[11.3,14.9): 39.5640 - val_ca2-[8.0,9.5): 19.7112 - val_ca2-[9.5,10.3): 20.7947 - val_ca2-[10.3,11.3): 24.3554 - val_ca2-[11.3,14.9): 29.6616 - val_ca3-[8.0,9.5): 18.1308 - val_ca3-[9.5,10.3): 19.1838 - val_ca3-[10.3,11.3): 22.6341 - val_ca3-[11.3,14.9): 27.7296 - val_ca4-[8.0,9.5): 19.9751 - val_ca4-[9.5,10.3): 21.0660 - val_ca4-[10.3,11.3): 24.6024 - val_ca4-[11.3,14.9): 29.8838\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 27.5205 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 18.9372 - ca2-[9.5,10.3): 19.9333 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 19.3708 - ca3-[10.3,11.3): 21.8690 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 26.5994 - ca4-[11.3,14.9): 28.8835 - val_ca1-[8.0,9.5): 24.5031 - val_ca1-[9.5,10.3): 25.7639 - val_ca1-[10.3,11.3): 29.6956 - val_ca1-[11.3,14.9): 35.5634 - val_ca2-[8.0,9.5): 17.0958 - val_ca2-[9.5,10.3): 18.1086 - val_ca2-[10.3,11.3): 21.4527 - val_ca2-[11.3,14.9): 26.4418 - val_ca3-[8.0,9.5): 15.0913 - val_ca3-[9.5,10.3): 16.0487 - val_ca3-[10.3,11.3): 19.2378 - val_ca3-[11.3,14.9): 23.9511 - val_ca4-[8.0,9.5): 17.3981 - val_ca4-[9.5,10.3): 18.3971 - val_ca4-[10.3,11.3): 21.7347 - val_ca4-[11.3,14.9): 26.7186\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 24.2687 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 16.5538 - ca2-[9.5,10.3): 17.3664 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 16.2063 - ca3-[10.3,11.3): 18.6549 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 23.3267 - ca4-[11.3,14.9): 25.8155 - val_ca1-[8.0,9.5): 21.6315 - val_ca1-[9.5,10.3): 22.8040 - val_ca1-[10.3,11.3): 26.5529 - val_ca1-[11.3,14.9): 32.0257 - val_ca2-[8.0,9.5): 14.7603 - val_ca2-[9.5,10.3): 15.7025 - val_ca2-[10.3,11.3): 18.8708 - val_ca2-[11.3,14.9): 23.4904 - val_ca3-[8.0,9.5): 12.4432 - val_ca3-[9.5,10.3): 13.3116 - val_ca3-[10.3,11.3): 16.2877 - val_ca3-[11.3,14.9): 20.5874 - val_ca4-[8.0,9.5): 15.2677 - val_ca4-[9.5,10.3): 16.1847 - val_ca4-[10.3,11.3): 19.3681 - val_ca4-[11.3,14.9): 24.0224\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 21.4102 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 14.2779 - ca2-[9.5,10.3): 14.9749 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 13.5525 - ca3-[10.3,11.3): 15.7137 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 21.1085 - ca4-[11.3,14.9): 23.1893 - val_ca1-[8.0,9.5): 19.1844 - val_ca1-[9.5,10.3): 20.2644 - val_ca1-[10.3,11.3): 23.8125 - val_ca1-[11.3,14.9): 28.9432 - val_ca2-[8.0,9.5): 12.7219 - val_ca2-[9.5,10.3): 13.5903 - val_ca2-[10.3,11.3): 16.5629 - val_ca2-[11.3,14.9): 20.8473 - val_ca3-[8.0,9.5): 10.2022 - val_ca3-[9.5,10.3): 10.9647 - val_ca3-[10.3,11.3): 13.6987 - val_ca3-[11.3,14.9): 17.6042 - val_ca4-[8.0,9.5): 13.4608 - val_ca4-[9.5,10.3): 14.2997 - val_ca4-[10.3,11.3): 17.3064 - val_ca4-[11.3,14.9): 21.6662\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 18.9335 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 12.1594 - ca2-[9.5,10.3): 12.9065 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 11.1353 - ca3-[10.3,11.3): 13.2616 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 19.1786 - ca4-[11.3,14.9): 20.9419 - val_ca1-[8.0,9.5): 17.0683 - val_ca1-[9.5,10.3): 18.0600 - val_ca1-[10.3,11.3): 21.4191 - val_ca1-[11.3,14.9): 26.1542 - val_ca2-[8.0,9.5): 10.9765 - val_ca2-[9.5,10.3): 11.7699 - val_ca2-[10.3,11.3): 14.5569 - val_ca2-[11.3,14.9): 18.4696 - val_ca3-[8.0,9.5): 8.3992 - val_ca3-[9.5,10.3): 9.0616 - val_ca3-[10.3,11.3): 11.5509 - val_ca3-[11.3,14.9): 15.0276 - val_ca4-[8.0,9.5): 11.8586 - val_ca4-[9.5,10.3): 12.6392 - val_ca4-[10.3,11.3): 15.4749 - val_ca4-[11.3,14.9): 19.4999\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 16.9320 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 10.6113 - ca2-[9.5,10.3): 11.1828 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 9.3939 - ca3-[10.3,11.3): 11.2191 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 17.3299 - ca4-[11.3,14.9): 19.1167 - val_ca1-[8.0,9.5): 15.2723 - val_ca1-[9.5,10.3): 16.2079 - val_ca1-[10.3,11.3): 19.3882 - val_ca1-[11.3,14.9): 23.9315 - val_ca2-[8.0,9.5): 9.5159 - val_ca2-[9.5,10.3): 10.2373 - val_ca2-[10.3,11.3): 12.8406 - val_ca2-[11.3,14.9): 16.5479 - val_ca3-[8.0,9.5): 6.9634 - val_ca3-[9.5,10.3): 7.5461 - val_ca3-[10.3,11.3): 9.8297 - val_ca3-[11.3,14.9): 13.0724 - val_ca4-[8.0,9.5): 10.4467 - val_ca4-[9.5,10.3): 11.1816 - val_ca4-[10.3,11.3): 13.8611 - val_ca4-[11.3,14.9): 17.7126\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 15.1796 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 8.9984 - ca2-[9.5,10.3): 9.7792 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 7.7495 - ca3-[10.3,11.3): 9.6359 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 15.3015 - ca4-[11.3,14.9): 17.3039 - val_ca1-[8.0,9.5): 13.7890 - val_ca1-[9.5,10.3): 14.6770 - val_ca1-[10.3,11.3): 17.7268 - val_ca1-[11.3,14.9): 22.1134 - val_ca2-[8.0,9.5): 8.2960 - val_ca2-[9.5,10.3): 8.9547 - val_ca2-[10.3,11.3): 11.4068 - val_ca2-[11.3,14.9): 14.9290 - val_ca3-[8.0,9.5): 5.8132 - val_ca3-[9.5,10.3): 6.3276 - val_ca3-[10.3,11.3): 8.4417 - val_ca3-[11.3,14.9): 11.4688 - val_ca4-[8.0,9.5): 9.2595 - val_ca4-[9.5,10.3): 9.9488 - val_ca4-[10.3,11.3): 12.5030 - val_ca4-[11.3,14.9): 16.1913\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 13.7458 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 7.9122 - ca2-[9.5,10.3): 8.5527 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 6.5145 - ca3-[10.3,11.3): 8.2731 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 14.1492 - ca4-[11.3,14.9): 15.8119 - val_ca1-[8.0,9.5): 12.5406 - val_ca1-[9.5,10.3): 13.4022 - val_ca1-[10.3,11.3): 16.3553 - val_ca1-[11.3,14.9): 20.5556 - val_ca2-[8.0,9.5): 7.2664 - val_ca2-[9.5,10.3): 7.8782 - val_ca2-[10.3,11.3): 10.2125 - val_ca2-[11.3,14.9): 13.5344 - val_ca3-[8.0,9.5): 4.8809 - val_ca3-[9.5,10.3): 5.3381 - val_ca3-[10.3,11.3): 7.3125 - val_ca3-[11.3,14.9): 10.1164 - val_ca4-[8.0,9.5): 8.2399 - val_ca4-[9.5,10.3): 8.8990 - val_ca4-[10.3,11.3): 11.3502 - val_ca4-[11.3,14.9): 14.8530\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 12.4744 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 6.9463 - ca2-[9.5,10.3): 7.5533 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 5.5736 - ca3-[10.3,11.3): 7.1227 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 12.8298 - ca4-[11.3,14.9): 14.5038 - val_ca1-[8.0,9.5): 11.5038 - val_ca1-[9.5,10.3): 12.3112 - val_ca1-[10.3,11.3): 15.1409 - val_ca1-[11.3,14.9): 19.2884 - val_ca2-[8.0,9.5): 6.3874 - val_ca2-[9.5,10.3): 6.9407 - val_ca2-[10.3,11.3): 9.1450 - val_ca2-[11.3,14.9): 12.3697 - val_ca3-[8.0,9.5): 4.1021 - val_ca3-[9.5,10.3): 4.4950 - val_ca3-[10.3,11.3): 6.3244 - val_ca3-[11.3,14.9): 8.9965 - val_ca4-[8.0,9.5): 7.3631 - val_ca4-[9.5,10.3): 7.9717 - val_ca4-[10.3,11.3): 10.3032 - val_ca4-[11.3,14.9): 13.7255\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 11.5659 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 6.1515 - ca2-[9.5,10.3): 6.6958 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 4.7713 - ca3-[10.3,11.3): 6.2247 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 11.5160 - ca4-[11.3,14.9): 13.2924 - val_ca1-[8.0,9.5): 10.5938 - val_ca1-[9.5,10.3): 11.3626 - val_ca1-[10.3,11.3): 14.1438 - val_ca1-[11.3,14.9): 18.1403 - val_ca2-[8.0,9.5): 5.6445 - val_ca2-[9.5,10.3): 6.1538 - val_ca2-[10.3,11.3): 8.2859 - val_ca2-[11.3,14.9): 11.3358 - val_ca3-[8.0,9.5): 3.4657 - val_ca3-[9.5,10.3): 3.8076 - val_ca3-[10.3,11.3): 5.5445 - val_ca3-[11.3,14.9): 8.0244 - val_ca4-[8.0,9.5): 6.6023 - val_ca4-[9.5,10.3): 7.1680 - val_ca4-[10.3,11.3): 9.4370 - val_ca4-[11.3,14.9): 12.6941\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 10.6827 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 5.4198 - ca2-[9.5,10.3): 5.9147 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 4.3125 - ca3-[10.3,11.3): 5.4794 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 10.7182 - ca4-[11.3,14.9): 12.3179 - val_ca1-[8.0,9.5): 9.8174 - val_ca1-[9.5,10.3): 10.5473 - val_ca1-[10.3,11.3): 13.2169 - val_ca1-[11.3,14.9): 17.0809 - val_ca2-[8.0,9.5): 5.0259 - val_ca2-[9.5,10.3): 5.4916 - val_ca2-[10.3,11.3): 7.5096 - val_ca2-[11.3,14.9): 10.4186 - val_ca3-[8.0,9.5): 2.9432 - val_ca3-[9.5,10.3): 3.2388 - val_ca3-[10.3,11.3): 4.8505 - val_ca3-[11.3,14.9): 7.1743 - val_ca4-[8.0,9.5): 5.9321 - val_ca4-[9.5,10.3): 6.4553 - val_ca4-[10.3,11.3): 8.6125 - val_ca4-[11.3,14.9): 11.7296\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 9.9171 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 4.7604 - ca2-[9.5,10.3): 5.3121 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 3.5528 - ca3-[10.3,11.3): 4.7268 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 10.0213 - ca4-[11.3,14.9): 11.4384 - val_ca1-[8.0,9.5): 9.1324 - val_ca1-[9.5,10.3): 9.8284 - val_ca1-[10.3,11.3): 12.4133 - val_ca1-[11.3,14.9): 15.9827 - val_ca2-[8.0,9.5): 4.4871 - val_ca2-[9.5,10.3): 4.9143 - val_ca2-[10.3,11.3): 6.8395 - val_ca2-[11.3,14.9): 9.4807 - val_ca3-[8.0,9.5): 2.5084 - val_ca3-[9.5,10.3): 2.7630 - val_ca3-[10.3,11.3): 4.2730 - val_ca3-[11.3,14.9): 6.3396 - val_ca4-[8.0,9.5): 5.3385 - val_ca4-[9.5,10.3): 5.8234 - val_ca4-[10.3,11.3): 7.8914 - val_ca4-[11.3,14.9): 10.7328\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 9.1996 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 4.2234 - ca2-[9.5,10.3): 4.7340 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 3.1922 - ca3-[10.3,11.3): 4.2332 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 8.9767 - ca4-[11.3,14.9): 10.5397 - val_ca1-[8.0,9.5): 8.5086 - val_ca1-[9.5,10.3): 9.1754 - val_ca1-[10.3,11.3): 11.6857 - val_ca1-[11.3,14.9): 15.3763 - val_ca2-[8.0,9.5): 4.0057 - val_ca2-[9.5,10.3): 4.3968 - val_ca2-[10.3,11.3): 6.2342 - val_ca2-[11.3,14.9): 8.9174 - val_ca3-[8.0,9.5): 2.1558 - val_ca3-[9.5,10.3): 2.3723 - val_ca3-[10.3,11.3): 3.7884 - val_ca3-[11.3,14.9): 5.8501 - val_ca4-[8.0,9.5): 4.8113 - val_ca4-[9.5,10.3): 5.2607 - val_ca4-[10.3,11.3): 7.2424 - val_ca4-[11.3,14.9): 10.1412\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 8.5699 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 3.7090 - ca2-[9.5,10.3): 4.2316 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.6391 - ca3-[10.3,11.3): 3.7759 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 8.5536 - ca4-[11.3,14.9): 9.8738 - val_ca1-[8.0,9.5): 7.9459 - val_ca1-[9.5,10.3): 8.5836 - val_ca1-[10.3,11.3): 11.0201 - val_ca1-[11.3,14.9): 14.4746 - val_ca2-[8.0,9.5): 3.5739 - val_ca2-[9.5,10.3): 3.9303 - val_ca2-[10.3,11.3): 5.6788 - val_ca2-[11.3,14.9): 8.1468 - val_ca3-[8.0,9.5): 1.8577 - val_ca3-[9.5,10.3): 2.0395 - val_ca3-[10.3,11.3): 3.3636 - val_ca3-[11.3,14.9): 5.2289 - val_ca4-[8.0,9.5): 4.3377 - val_ca4-[9.5,10.3): 4.7529 - val_ca4-[10.3,11.3): 6.6471 - val_ca4-[11.3,14.9): 9.3237\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 8.0965 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 3.3316 - ca2-[9.5,10.3): 3.7835 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.2636 - ca3-[10.3,11.3): 3.3087 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 7.6057 - ca4-[11.3,14.9): 9.1836 - val_ca1-[8.0,9.5): 7.4455 - val_ca1-[9.5,10.3): 8.0560 - val_ca1-[10.3,11.3): 10.4395 - val_ca1-[11.3,14.9): 13.8331 - val_ca2-[8.0,9.5): 3.1863 - val_ca2-[9.5,10.3): 3.5090 - val_ca2-[10.3,11.3): 5.1838 - val_ca2-[11.3,14.9): 7.5548 - val_ca3-[8.0,9.5): 1.6137 - val_ca3-[9.5,10.3): 1.7641 - val_ca3-[10.3,11.3): 3.0173 - val_ca3-[11.3,14.9): 4.7821 - val_ca4-[8.0,9.5): 3.9141 - val_ca4-[9.5,10.3): 4.2967 - val_ca4-[10.3,11.3): 6.1199 - val_ca4-[11.3,14.9): 8.7058\n",
      "Epoch 17/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 7.5480 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.9895 - ca2-[9.5,10.3): 3.4055 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.0038 - ca3-[10.3,11.3): 2.9673 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 7.2304 - ca4-[11.3,14.9): 8.5130 - val_ca1-[8.0,9.5): 6.9946 - val_ca1-[9.5,10.3): 7.5803 - val_ca1-[10.3,11.3): 9.8452 - val_ca1-[11.3,14.9): 13.1565 - val_ca2-[8.0,9.5): 2.8372 - val_ca2-[9.5,10.3): 3.1275 - val_ca2-[10.3,11.3): 4.6837 - val_ca2-[11.3,14.9): 6.9386 - val_ca3-[8.0,9.5): 1.4187 - val_ca3-[9.5,10.3): 1.5398 - val_ca3-[10.3,11.3): 2.6918 - val_ca3-[11.3,14.9): 4.3458 - val_ca4-[8.0,9.5): 3.5322 - val_ca4-[9.5,10.3): 3.8837 - val_ca4-[10.3,11.3): 5.5876 - val_ca4-[11.3,14.9): 8.0637\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 7.0565 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.6137 - ca2-[9.5,10.3): 3.0463 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.7422 - ca3-[10.3,11.3): 2.6533 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 6.5722 - ca4-[11.3,14.9): 7.8718 - val_ca1-[8.0,9.5): 6.5822 - val_ca1-[9.5,10.3): 7.1442 - val_ca1-[10.3,11.3): 9.4037 - val_ca1-[11.3,14.9): 12.5854 - val_ca2-[8.0,9.5): 2.5242 - val_ca2-[9.5,10.3): 2.7834 - val_ca2-[10.3,11.3): 4.3030 - val_ca2-[11.3,14.9): 6.4291 - val_ca3-[8.0,9.5): 1.2553 - val_ca3-[9.5,10.3): 1.3496 - val_ca3-[10.3,11.3): 2.4678 - val_ca3-[11.3,14.9): 4.0219 - val_ca4-[8.0,9.5): 3.1869 - val_ca4-[9.5,10.3): 3.5086 - val_ca4-[10.3,11.3): 5.1816 - val_ca4-[11.3,14.9): 7.5277\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 6.6461 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.3012 - ca2-[9.5,10.3): 2.7344 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.6246 - ca3-[10.3,11.3): 2.4573 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 6.1740 - ca4-[11.3,14.9): 7.3523 - val_ca1-[8.0,9.5): 6.2029 - val_ca1-[9.5,10.3): 6.7421 - val_ca1-[10.3,11.3): 8.9463 - val_ca1-[11.3,14.9): 12.0551 - val_ca2-[8.0,9.5): 2.2457 - val_ca2-[9.5,10.3): 2.4749 - val_ca2-[10.3,11.3): 3.9217 - val_ca2-[11.3,14.9): 5.9456 - val_ca3-[8.0,9.5): 1.1207 - val_ca3-[9.5,10.3): 1.1900 - val_ca3-[10.3,11.3): 2.2479 - val_ca3-[11.3,14.9): 3.7151 - val_ca4-[8.0,9.5): 2.8741 - val_ca4-[9.5,10.3): 3.1670 - val_ca4-[10.3,11.3): 4.7701 - val_ca4-[11.3,14.9): 7.0187\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 6.3992 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.0173 - ca2-[9.5,10.3): 2.4058 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.3827 - ca3-[10.3,11.3): 2.2218 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.8625 - ca4-[11.3,14.9): 6.8229 - val_ca1-[8.0,9.5): 5.8636 - val_ca1-[9.5,10.3): 6.3662 - val_ca1-[10.3,11.3): 8.5169 - val_ca1-[11.3,14.9): 11.5653 - val_ca2-[8.0,9.5): 2.0062 - val_ca2-[9.5,10.3): 2.2011 - val_ca2-[10.3,11.3): 3.5776 - val_ca2-[11.3,14.9): 5.5118 - val_ca3-[8.0,9.5): 1.0109 - val_ca3-[9.5,10.3): 1.0557 - val_ca3-[10.3,11.3): 2.0562 - val_ca3-[11.3,14.9): 3.4496 - val_ca4-[8.0,9.5): 2.5986 - val_ca4-[9.5,10.3): 2.8561 - val_ca4-[10.3,11.3): 4.3907 - val_ca4-[11.3,14.9): 6.5530\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 5.9449 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.7803 - ca2-[9.5,10.3): 2.1645 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.2786 - ca3-[10.3,11.3): 2.0507 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.3850 - ca4-[11.3,14.9): 6.3934 - val_ca1-[8.0,9.5): 5.5187 - val_ca1-[9.5,10.3): 6.0150 - val_ca1-[10.3,11.3): 8.1151 - val_ca1-[11.3,14.9): 11.0409 - val_ca2-[8.0,9.5): 1.7851 - val_ca2-[9.5,10.3): 1.9586 - val_ca2-[10.3,11.3): 3.2714 - val_ca2-[11.3,14.9): 5.0794 - val_ca3-[8.0,9.5): 0.9172 - val_ca3-[9.5,10.3): 0.9419 - val_ca3-[10.3,11.3): 1.8930 - val_ca3-[11.3,14.9): 3.1878 - val_ca4-[8.0,9.5): 2.3351 - val_ca4-[9.5,10.3): 2.5733 - val_ca4-[10.3,11.3): 4.0445 - val_ca4-[11.3,14.9): 6.0778\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 5.6269 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.5929 - ca2-[9.5,10.3): 1.9276 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.1791 - ca3-[10.3,11.3): 1.8756 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.9909 - ca4-[11.3,14.9): 5.9867 - val_ca1-[8.0,9.5): 5.2101 - val_ca1-[9.5,10.3): 5.6861 - val_ca1-[10.3,11.3): 7.7160 - val_ca1-[11.3,14.9): 10.6783 - val_ca2-[8.0,9.5): 1.5982 - val_ca2-[9.5,10.3): 1.7462 - val_ca2-[10.3,11.3): 2.9824 - val_ca2-[11.3,14.9): 4.7658 - val_ca3-[8.0,9.5): 0.8406 - val_ca3-[9.5,10.3): 0.8451 - val_ca3-[10.3,11.3): 1.7354 - val_ca3-[11.3,14.9): 3.0050 - val_ca4-[8.0,9.5): 2.1046 - val_ca4-[9.5,10.3): 2.3170 - val_ca4-[10.3,11.3): 3.7095 - val_ca4-[11.3,14.9): 5.7254\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 5.2919 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.3964 - ca2-[9.5,10.3): 1.7394 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.0593 - ca3-[10.3,11.3): 1.7383 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.5200 - ca4-[11.3,14.9): 5.5247 - val_ca1-[8.0,9.5): 4.9209 - val_ca1-[9.5,10.3): 5.3773 - val_ca1-[10.3,11.3): 7.3596 - val_ca1-[11.3,14.9): 10.2155 - val_ca2-[8.0,9.5): 1.4367 - val_ca2-[9.5,10.3): 1.5607 - val_ca2-[10.3,11.3): 2.7390 - val_ca2-[11.3,14.9): 4.4227 - val_ca3-[8.0,9.5): 0.7774 - val_ca3-[9.5,10.3): 0.7630 - val_ca3-[10.3,11.3): 1.6074 - val_ca3-[11.3,14.9): 2.8048 - val_ca4-[8.0,9.5): 1.8969 - val_ca4-[9.5,10.3): 2.0842 - val_ca4-[10.3,11.3): 3.4162 - val_ca4-[11.3,14.9): 5.3243\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 4.9871 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.2665 - ca2-[9.5,10.3): 1.5303 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.9858 - ca3-[10.3,11.3): 1.5954 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.2026 - ca4-[11.3,14.9): 5.1960 - val_ca1-[8.0,9.5): 4.6496 - val_ca1-[9.5,10.3): 5.0870 - val_ca1-[10.3,11.3): 7.0425 - val_ca1-[11.3,14.9): 9.7462 - val_ca2-[8.0,9.5): 1.2982 - val_ca2-[9.5,10.3): 1.3997 - val_ca2-[10.3,11.3): 2.5347 - val_ca2-[11.3,14.9): 4.0776 - val_ca3-[8.0,9.5): 0.7260 - val_ca3-[9.5,10.3): 0.6937 - val_ca3-[10.3,11.3): 1.5028 - val_ca3-[11.3,14.9): 2.5848 - val_ca4-[8.0,9.5): 1.7100 - val_ca4-[9.5,10.3): 1.8731 - val_ca4-[10.3,11.3): 3.1588 - val_ca4-[11.3,14.9): 4.9153\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 4.7688 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.0745 - ca2-[9.5,10.3): 1.3860 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.8816 - ca3-[10.3,11.3): 1.5011 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.1080 - ca4-[11.3,14.9): 4.8631 - val_ca1-[8.0,9.5): 4.3952 - val_ca1-[9.5,10.3): 4.8141 - val_ca1-[10.3,11.3): 6.7247 - val_ca1-[11.3,14.9): 9.4507 - val_ca2-[8.0,9.5): 1.1797 - val_ca2-[9.5,10.3): 1.2602 - val_ca2-[10.3,11.3): 2.3440 - val_ca2-[11.3,14.9): 3.8622 - val_ca3-[8.0,9.5): 0.6847 - val_ca3-[9.5,10.3): 0.6356 - val_ca3-[10.3,11.3): 1.4039 - val_ca3-[11.3,14.9): 2.4613 - val_ca4-[8.0,9.5): 1.5427 - val_ca4-[9.5,10.3): 1.6822 - val_ca4-[10.3,11.3): 2.9106 - val_ca4-[11.3,14.9): 4.6403\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 4.4423 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.9632 - ca2-[9.5,10.3): 1.2551 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.7996 - ca3-[10.3,11.3): 1.3881 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.6215 - ca4-[11.3,14.9): 4.5377 - val_ca1-[8.0,9.5): 4.1566 - val_ca1-[9.5,10.3): 4.5577 - val_ca1-[10.3,11.3): 6.4253 - val_ca1-[11.3,14.9): 9.0355 - val_ca2-[8.0,9.5): 1.0784 - val_ca2-[9.5,10.3): 1.1391 - val_ca2-[10.3,11.3): 2.1764 - val_ca2-[11.3,14.9): 3.6021 - val_ca3-[8.0,9.5): 0.6521 - val_ca3-[9.5,10.3): 0.5872 - val_ca3-[10.3,11.3): 1.3188 - val_ca3-[11.3,14.9): 2.3086 - val_ca4-[8.0,9.5): 1.3933 - val_ca4-[9.5,10.3): 1.5100 - val_ca4-[10.3,11.3): 2.6840 - val_ca4-[11.3,14.9): 4.3052\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 4.2928 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.8705 - ca2-[9.5,10.3): 1.1672 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.7746 - ca3-[10.3,11.3): 1.3144 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.2614 - ca4-[11.3,14.9): 4.2133 - val_ca1-[8.0,9.5): 3.9327 - val_ca1-[9.5,10.3): 4.3165 - val_ca1-[10.3,11.3): 6.1600 - val_ca1-[11.3,14.9): 8.7357 - val_ca2-[8.0,9.5): 0.9919 - val_ca2-[9.5,10.3): 1.0342 - val_ca2-[10.3,11.3): 2.0296 - val_ca2-[11.3,14.9): 3.4011 - val_ca3-[8.0,9.5): 0.6267 - val_ca3-[9.5,10.3): 0.5470 - val_ca3-[10.3,11.3): 1.2400 - val_ca3-[11.3,14.9): 2.1823 - val_ca4-[8.0,9.5): 1.2607 - val_ca4-[9.5,10.3): 1.3553 - val_ca4-[10.3,11.3): 2.4809 - val_ca4-[11.3,14.9): 4.0376\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 4.0250 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.7818 - ca2-[9.5,10.3): 1.0459 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6850 - ca3-[10.3,11.3): 1.2312 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.9581 - ca4-[11.3,14.9): 3.9429 - val_ca1-[8.0,9.5): 3.7223 - val_ca1-[9.5,10.3): 4.0893 - val_ca1-[10.3,11.3): 5.8738 - val_ca1-[11.3,14.9): 8.3996 - val_ca2-[8.0,9.5): 0.9188 - val_ca2-[9.5,10.3): 0.9439 - val_ca2-[10.3,11.3): 1.8943 - val_ca2-[11.3,14.9): 3.2104 - val_ca3-[8.0,9.5): 0.6077 - val_ca3-[9.5,10.3): 0.5139 - val_ca3-[10.3,11.3): 1.1750 - val_ca3-[11.3,14.9): 2.0714 - val_ca4-[8.0,9.5): 1.1429 - val_ca4-[9.5,10.3): 1.2160 - val_ca4-[10.3,11.3): 2.2839 - val_ca4-[11.3,14.9): 3.7706\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 3.7976 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.7771 - ca2-[9.5,10.3): 0.9872 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6518 - ca3-[10.3,11.3): 1.1743 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.8651 - ca4-[11.3,14.9): 3.6562 - val_ca1-[8.0,9.5): 3.5237 - val_ca1-[9.5,10.3): 3.8743 - val_ca1-[10.3,11.3): 5.6182 - val_ca1-[11.3,14.9): 8.0838 - val_ca2-[8.0,9.5): 0.8572 - val_ca2-[9.5,10.3): 0.8663 - val_ca2-[10.3,11.3): 1.7764 - val_ca2-[11.3,14.9): 3.0392 - val_ca3-[8.0,9.5): 0.5942 - val_ca3-[9.5,10.3): 0.4872 - val_ca3-[10.3,11.3): 1.1142 - val_ca3-[11.3,14.9): 1.9688 - val_ca4-[8.0,9.5): 1.0397 - val_ca4-[9.5,10.3): 1.0921 - val_ca4-[10.3,11.3): 2.1080 - val_ca4-[11.3,14.9): 3.5238\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 3.6014 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.6753 - ca2-[9.5,10.3): 0.9262 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6422 - ca3-[10.3,11.3): 1.1062 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.6806 - ca4-[11.3,14.9): 3.4052 - val_ca1-[8.0,9.5): 3.3364 - val_ca1-[9.5,10.3): 3.6710 - val_ca1-[10.3,11.3): 5.3433 - val_ca1-[11.3,14.9): 7.7968 - val_ca2-[8.0,9.5): 0.8052 - val_ca2-[9.5,10.3): 0.7995 - val_ca2-[10.3,11.3): 1.6581 - val_ca2-[11.3,14.9): 2.8875 - val_ca3-[8.0,9.5): 0.5852 - val_ca3-[9.5,10.3): 0.4658 - val_ca3-[10.3,11.3): 1.0529 - val_ca3-[11.3,14.9): 1.8743 - val_ca4-[8.0,9.5): 0.9497 - val_ca4-[9.5,10.3): 0.9820 - val_ca4-[10.3,11.3): 1.9316 - val_ca4-[11.3,14.9): 3.2985\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 3.4351 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.5999 - ca2-[9.5,10.3): 0.8275 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5947 - ca3-[10.3,11.3): 1.0592 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.4115 - ca4-[11.3,14.9): 3.2074 - val_ca1-[8.0,9.5): 3.1602 - val_ca1-[9.5,10.3): 3.4793 - val_ca1-[10.3,11.3): 5.1465 - val_ca1-[11.3,14.9): 7.5427 - val_ca2-[8.0,9.5): 0.7616 - val_ca2-[9.5,10.3): 0.7420 - val_ca2-[10.3,11.3): 1.5819 - val_ca2-[11.3,14.9): 2.7698 - val_ca3-[8.0,9.5): 0.5803 - val_ca3-[9.5,10.3): 0.4490 - val_ca3-[10.3,11.3): 1.0168 - val_ca3-[11.3,14.9): 1.8074 - val_ca4-[8.0,9.5): 0.8718 - val_ca4-[9.5,10.3): 0.8846 - val_ca4-[10.3,11.3): 1.8039 - val_ca4-[11.3,14.9): 3.1082\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 3.2513 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.5647 - ca2-[9.5,10.3): 0.7951 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5748 - ca3-[10.3,11.3): 1.0092 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.1765 - ca4-[11.3,14.9): 2.9597 - val_ca1-[8.0,9.5): 2.9942 - val_ca1-[9.5,10.3): 3.2982 - val_ca1-[10.3,11.3): 4.9398 - val_ca1-[11.3,14.9): 7.2241 - val_ca2-[8.0,9.5): 0.7252 - val_ca2-[9.5,10.3): 0.6926 - val_ca2-[10.3,11.3): 1.5057 - val_ca2-[11.3,14.9): 2.6215 - val_ca3-[8.0,9.5): 0.5787 - val_ca3-[9.5,10.3): 0.4363 - val_ca3-[10.3,11.3): 0.9796 - val_ca3-[11.3,14.9): 1.7150 - val_ca4-[8.0,9.5): 0.8049 - val_ca4-[9.5,10.3): 0.7989 - val_ca4-[10.3,11.3): 1.6773 - val_ca4-[11.3,14.9): 2.8857\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 3.0526 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4914 - ca2-[9.5,10.3): 0.7400 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5125 - ca3-[10.3,11.3): 0.9792 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.2312 - ca4-[11.3,14.9): 2.8257 - val_ca1-[8.0,9.5): 2.8378 - val_ca1-[9.5,10.3): 3.1272 - val_ca1-[10.3,11.3): 4.7068 - val_ca1-[11.3,14.9): 6.9762 - val_ca2-[8.0,9.5): 0.6948 - val_ca2-[9.5,10.3): 0.6502 - val_ca2-[10.3,11.3): 1.4234 - val_ca2-[11.3,14.9): 2.5105 - val_ca3-[8.0,9.5): 0.5799 - val_ca3-[9.5,10.3): 0.4270 - val_ca3-[10.3,11.3): 0.9391 - val_ca3-[11.3,14.9): 1.6438 - val_ca4-[8.0,9.5): 0.7483 - val_ca4-[9.5,10.3): 0.7239 - val_ca4-[10.3,11.3): 1.5461 - val_ca4-[11.3,14.9): 2.7055\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 2.8980 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4843 - ca2-[9.5,10.3): 0.7069 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5333 - ca3-[10.3,11.3): 0.9433 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.9245 - ca4-[11.3,14.9): 2.5852 - val_ca1-[8.0,9.5): 2.6900 - val_ca1-[9.5,10.3): 2.9607 - val_ca1-[10.3,11.3): 4.5394 - val_ca1-[11.3,14.9): 6.7814 - val_ca2-[8.0,9.5): 0.6698 - val_ca2-[9.5,10.3): 0.6133 - val_ca2-[10.3,11.3): 1.3678 - val_ca2-[11.3,14.9): 2.4309 - val_ca3-[8.0,9.5): 0.5835 - val_ca3-[9.5,10.3): 0.4212 - val_ca3-[10.3,11.3): 0.9099 - val_ca3-[11.3,14.9): 1.5928 - val_ca4-[8.0,9.5): 0.7014 - val_ca4-[9.5,10.3): 0.6585 - val_ca4-[10.3,11.3): 1.4474 - val_ca4-[11.3,14.9): 2.5601\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 2.7855 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4629 - ca2-[9.5,10.3): 0.6789 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4986 - ca3-[10.3,11.3): 0.9149 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.8438 - ca4-[11.3,14.9): 2.4640 - val_ca1-[8.0,9.5): 2.5503 - val_ca1-[9.5,10.3): 2.8112 - val_ca1-[10.3,11.3): 4.3362 - val_ca1-[11.3,14.9): 6.4924 - val_ca2-[8.0,9.5): 0.6493 - val_ca2-[9.5,10.3): 0.5831 - val_ca2-[10.3,11.3): 1.3093 - val_ca2-[11.3,14.9): 2.3135 - val_ca3-[8.0,9.5): 0.5891 - val_ca3-[9.5,10.3): 0.4170 - val_ca3-[10.3,11.3): 0.8852 - val_ca3-[11.3,14.9): 1.5173 - val_ca4-[8.0,9.5): 0.6633 - val_ca4-[9.5,10.3): 0.6041 - val_ca4-[10.3,11.3): 1.3478 - val_ca4-[11.3,14.9): 2.3772\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 2.5925 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4550 - ca2-[9.5,10.3): 0.6560 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5120 - ca3-[10.3,11.3): 0.8739 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.6983 - ca4-[11.3,14.9): 2.2968 - val_ca1-[8.0,9.5): 2.4190 - val_ca1-[9.5,10.3): 2.6662 - val_ca1-[10.3,11.3): 4.1679 - val_ca1-[11.3,14.9): 6.3151 - val_ca2-[8.0,9.5): 0.6327 - val_ca2-[9.5,10.3): 0.5570 - val_ca2-[10.3,11.3): 1.2638 - val_ca2-[11.3,14.9): 2.2536 - val_ca3-[8.0,9.5): 0.5962 - val_ca3-[9.5,10.3): 0.4154 - val_ca3-[10.3,11.3): 0.8642 - val_ca3-[11.3,14.9): 1.4784 - val_ca4-[8.0,9.5): 0.6332 - val_ca4-[9.5,10.3): 0.5575 - val_ca4-[10.3,11.3): 1.2647 - val_ca4-[11.3,14.9): 2.2553\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 2.4571 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4160 - ca2-[9.5,10.3): 0.6325 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4905 - ca3-[10.3,11.3): 0.8427 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.5462 - ca4-[11.3,14.9): 2.1633 - val_ca1-[8.0,9.5): 2.2949 - val_ca1-[9.5,10.3): 2.5287 - val_ca1-[10.3,11.3): 3.9877 - val_ca1-[11.3,14.9): 6.0422 - val_ca2-[8.0,9.5): 0.6194 - val_ca2-[9.5,10.3): 0.5347 - val_ca2-[10.3,11.3): 1.2160 - val_ca2-[11.3,14.9): 2.1490 - val_ca3-[8.0,9.5): 0.6044 - val_ca3-[9.5,10.3): 0.4155 - val_ca3-[10.3,11.3): 0.8427 - val_ca3-[11.3,14.9): 1.4093 - val_ca4-[8.0,9.5): 0.6104 - val_ca4-[9.5,10.3): 0.5187 - val_ca4-[10.3,11.3): 1.1831 - val_ca4-[11.3,14.9): 2.0919\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 2.3391 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4171 - ca2-[9.5,10.3): 0.6189 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4890 - ca3-[10.3,11.3): 0.8459 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.4676 - ca4-[11.3,14.9): 2.0221 - val_ca1-[8.0,9.5): 2.1779 - val_ca1-[9.5,10.3): 2.3987 - val_ca1-[10.3,11.3): 3.8257 - val_ca1-[11.3,14.9): 5.7948 - val_ca2-[8.0,9.5): 0.6087 - val_ca2-[9.5,10.3): 0.5159 - val_ca2-[10.3,11.3): 1.1774 - val_ca2-[11.3,14.9): 2.0633 - val_ca3-[8.0,9.5): 0.6136 - val_ca3-[9.5,10.3): 0.4171 - val_ca3-[10.3,11.3): 0.8256 - val_ca3-[11.3,14.9): 1.3539 - val_ca4-[8.0,9.5): 0.5941 - val_ca4-[9.5,10.3): 0.4870 - val_ca4-[10.3,11.3): 1.1137 - val_ca4-[11.3,14.9): 1.9507\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 2.2287 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4185 - ca2-[9.5,10.3): 0.6023 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4846 - ca3-[10.3,11.3): 0.8186 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.4028 - ca4-[11.3,14.9): 1.8720 - val_ca1-[8.0,9.5): 2.0675 - val_ca1-[9.5,10.3): 2.2755 - val_ca1-[10.3,11.3): 3.6242 - val_ca1-[11.3,14.9): 5.6329 - val_ca2-[8.0,9.5): 0.6003 - val_ca2-[9.5,10.3): 0.5000 - val_ca2-[10.3,11.3): 1.1184 - val_ca2-[11.3,14.9): 2.0255 - val_ca3-[8.0,9.5): 0.6235 - val_ca3-[9.5,10.3): 0.4199 - val_ca3-[10.3,11.3): 0.7939 - val_ca3-[11.3,14.9): 1.3325 - val_ca4-[8.0,9.5): 0.5839 - val_ca4-[9.5,10.3): 0.4619 - val_ca4-[10.3,11.3): 1.0292 - val_ca4-[11.3,14.9): 1.8595\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 2.1455 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3765 - ca2-[9.5,10.3): 0.5738 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4811 - ca3-[10.3,11.3): 0.8096 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.2688 - ca4-[11.3,14.9): 1.7786 - val_ca1-[8.0,9.5): 1.9630 - val_ca1-[9.5,10.3): 2.1585 - val_ca1-[10.3,11.3): 3.4972 - val_ca1-[11.3,14.9): 5.4718 - val_ca2-[8.0,9.5): 0.5939 - val_ca2-[9.5,10.3): 0.4867 - val_ca2-[10.3,11.3): 1.1013 - val_ca2-[11.3,14.9): 1.9845 - val_ca3-[8.0,9.5): 0.6339 - val_ca3-[9.5,10.3): 0.4236 - val_ca3-[10.3,11.3): 0.7916 - val_ca3-[11.3,14.9): 1.3033 - val_ca4-[8.0,9.5): 0.5792 - val_ca4-[9.5,10.3): 0.4428 - val_ca4-[10.3,11.3): 0.9877 - val_ca4-[11.3,14.9): 1.7661\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 2.0164 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3950 - ca2-[9.5,10.3): 0.5703 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4906 - ca3-[10.3,11.3): 0.8005 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.2664 - ca4-[11.3,14.9): 1.6883 - val_ca1-[8.0,9.5): 1.8645 - val_ca1-[9.5,10.3): 2.0477 - val_ca1-[10.3,11.3): 3.3831 - val_ca1-[11.3,14.9): 5.2610 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4755 - val_ca2-[10.3,11.3): 1.0865 - val_ca2-[11.3,14.9): 1.9131 - val_ca3-[8.0,9.5): 0.6445 - val_ca3-[9.5,10.3): 0.4280 - val_ca3-[10.3,11.3): 0.7876 - val_ca3-[11.3,14.9): 1.2492 - val_ca4-[8.0,9.5): 0.5793 - val_ca4-[9.5,10.3): 0.4292 - val_ca4-[10.3,11.3): 0.9507 - val_ca4-[11.3,14.9): 1.6475\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 1.8878 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3795 - ca2-[9.5,10.3): 0.5467 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4919 - ca3-[10.3,11.3): 0.7696 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.1014 - ca4-[11.3,14.9): 1.6210 - val_ca1-[8.0,9.5): 1.7717 - val_ca1-[9.5,10.3): 1.9430 - val_ca1-[10.3,11.3): 3.2365 - val_ca1-[11.3,14.9): 5.1052 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.4662 - val_ca2-[10.3,11.3): 1.0578 - val_ca2-[11.3,14.9): 1.8839 - val_ca3-[8.0,9.5): 0.6553 - val_ca3-[9.5,10.3): 0.4330 - val_ca3-[10.3,11.3): 0.7752 - val_ca3-[11.3,14.9): 1.2312 - val_ca4-[8.0,9.5): 0.5839 - val_ca4-[9.5,10.3): 0.4204 - val_ca4-[10.3,11.3): 0.9048 - val_ca4-[11.3,14.9): 1.5720\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 1.8047 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3636 - ca2-[9.5,10.3): 0.5529 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4748 - ca3-[10.3,11.3): 0.7650 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.0251 - ca4-[11.3,14.9): 1.5153 - val_ca1-[8.0,9.5): 1.6842 - val_ca1-[9.5,10.3): 1.8437 - val_ca1-[10.3,11.3): 3.1224 - val_ca1-[11.3,14.9): 4.8991 - val_ca2-[8.0,9.5): 0.5827 - val_ca2-[9.5,10.3): 0.4584 - val_ca2-[10.3,11.3): 1.0447 - val_ca2-[11.3,14.9): 1.8339 - val_ca3-[8.0,9.5): 0.6662 - val_ca3-[9.5,10.3): 0.4384 - val_ca3-[10.3,11.3): 0.7725 - val_ca3-[11.3,14.9): 1.2022 - val_ca4-[8.0,9.5): 0.5923 - val_ca4-[9.5,10.3): 0.4160 - val_ca4-[10.3,11.3): 0.8755 - val_ca4-[11.3,14.9): 1.4842\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.7006 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3859 - ca2-[9.5,10.3): 0.5353 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4954 - ca3-[10.3,11.3): 0.7653 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.9264 - ca4-[11.3,14.9): 1.4563 - val_ca1-[8.0,9.5): 1.6017 - val_ca1-[9.5,10.3): 1.7497 - val_ca1-[10.3,11.3): 2.9882 - val_ca1-[11.3,14.9): 4.7370 - val_ca2-[8.0,9.5): 0.5809 - val_ca2-[9.5,10.3): 0.4517 - val_ca2-[10.3,11.3): 1.0209 - val_ca2-[11.3,14.9): 1.7987 - val_ca3-[8.0,9.5): 0.6767 - val_ca3-[9.5,10.3): 0.4439 - val_ca3-[10.3,11.3): 0.7632 - val_ca3-[11.3,14.9): 1.1785 - val_ca4-[8.0,9.5): 0.6043 - val_ca4-[9.5,10.3): 0.4155 - val_ca4-[10.3,11.3): 0.8407 - val_ca4-[11.3,14.9): 1.4099\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.6261 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3688 - ca2-[9.5,10.3): 0.5350 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4919 - ca3-[10.3,11.3): 0.7593 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8233 - ca4-[11.3,14.9): 1.3666 - val_ca1-[8.0,9.5): 1.5236 - val_ca1-[9.5,10.3): 1.6603 - val_ca1-[10.3,11.3): 2.8703 - val_ca1-[11.3,14.9): 4.6274 - val_ca2-[8.0,9.5): 0.5797 - val_ca2-[9.5,10.3): 0.4461 - val_ca2-[10.3,11.3): 1.0029 - val_ca2-[11.3,14.9): 1.7958 - val_ca3-[8.0,9.5): 0.6869 - val_ca3-[9.5,10.3): 0.4495 - val_ca3-[10.3,11.3): 0.7556 - val_ca3-[11.3,14.9): 1.1786 - val_ca4-[8.0,9.5): 0.6194 - val_ca4-[9.5,10.3): 0.4186 - val_ca4-[10.3,11.3): 0.8129 - val_ca4-[11.3,14.9): 1.3661\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.5358 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3679 - ca2-[9.5,10.3): 0.5412 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4895 - ca3-[10.3,11.3): 0.7210 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8841 - ca4-[11.3,14.9): 1.3228 - val_ca1-[8.0,9.5): 1.4497 - val_ca1-[9.5,10.3): 1.5753 - val_ca1-[10.3,11.3): 2.7711 - val_ca1-[11.3,14.9): 4.4823 - val_ca2-[8.0,9.5): 0.5790 - val_ca2-[9.5,10.3): 0.4413 - val_ca2-[10.3,11.3): 0.9953 - val_ca2-[11.3,14.9): 1.7674 - val_ca3-[8.0,9.5): 0.6968 - val_ca3-[9.5,10.3): 0.4552 - val_ca3-[10.3,11.3): 0.7558 - val_ca3-[11.3,14.9): 1.1574 - val_ca4-[8.0,9.5): 0.6373 - val_ca4-[9.5,10.3): 0.4249 - val_ca4-[10.3,11.3): 0.7966 - val_ca4-[11.3,14.9): 1.3022\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.4981 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3444 - ca2-[9.5,10.3): 0.5191 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5201 - ca3-[10.3,11.3): 0.7266 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8073 - ca4-[11.3,14.9): 1.2373 - val_ca1-[8.0,9.5): 1.3796 - val_ca1-[9.5,10.3): 1.4942 - val_ca1-[10.3,11.3): 2.6518 - val_ca1-[11.3,14.9): 4.3221 - val_ca2-[8.0,9.5): 0.5787 - val_ca2-[9.5,10.3): 0.4374 - val_ca2-[10.3,11.3): 0.9773 - val_ca2-[11.3,14.9): 1.7342 - val_ca3-[8.0,9.5): 0.7064 - val_ca3-[9.5,10.3): 0.4609 - val_ca3-[10.3,11.3): 0.7493 - val_ca3-[11.3,14.9): 1.1345 - val_ca4-[8.0,9.5): 0.6574 - val_ca4-[9.5,10.3): 0.4340 - val_ca4-[10.3,11.3): 0.7756 - val_ca4-[11.3,14.9): 1.2395\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 1.3937 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3755 - ca2-[9.5,10.3): 0.5317 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4944 - ca3-[10.3,11.3): 0.7378 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7722 - ca4-[11.3,14.9): 1.1789 - val_ca1-[8.0,9.5): 1.3131 - val_ca1-[9.5,10.3): 1.4167 - val_ca1-[10.3,11.3): 2.5590 - val_ca1-[11.3,14.9): 4.1222 - val_ca2-[8.0,9.5): 0.5787 - val_ca2-[9.5,10.3): 0.4341 - val_ca2-[10.3,11.3): 0.9713 - val_ca2-[11.3,14.9): 1.6768 - val_ca3-[8.0,9.5): 0.7155 - val_ca3-[9.5,10.3): 0.4664 - val_ca3-[10.3,11.3): 0.7486 - val_ca3-[11.3,14.9): 1.0930 - val_ca4-[8.0,9.5): 0.6795 - val_ca4-[9.5,10.3): 0.4454 - val_ca4-[10.3,11.3): 0.7643 - val_ca4-[11.3,14.9): 1.1608\n",
      "Epoch 49/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 1.3546 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3606 - ca2-[9.5,10.3): 0.5187 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5191 - ca3-[10.3,11.3): 0.7453 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7005 - ca4-[11.3,14.9): 1.1213 - val_ca1-[8.0,9.5): 1.2501 - val_ca1-[9.5,10.3): 1.3429 - val_ca1-[10.3,11.3): 2.4468 - val_ca1-[11.3,14.9): 4.0592 - val_ca2-[8.0,9.5): 0.5789 - val_ca2-[9.5,10.3): 0.4314 - val_ca2-[10.3,11.3): 0.9545 - val_ca2-[11.3,14.9): 1.7011 - val_ca3-[8.0,9.5): 0.7245 - val_ca3-[9.5,10.3): 0.4719 - val_ca3-[10.3,11.3): 0.7412 - val_ca3-[11.3,14.9): 1.1094 - val_ca4-[8.0,9.5): 0.7032 - val_ca4-[9.5,10.3): 0.4590 - val_ca4-[10.3,11.3): 0.7484 - val_ca4-[11.3,14.9): 1.1466\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 1.2628 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3740 - ca2-[9.5,10.3): 0.5232 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5110 - ca3-[10.3,11.3): 0.7263 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6850 - ca4-[11.3,14.9): 1.0777 - val_ca1-[8.0,9.5): 1.1903 - val_ca1-[9.5,10.3): 1.2723 - val_ca1-[10.3,11.3): 2.3608 - val_ca1-[11.3,14.9): 3.8687 - val_ca2-[8.0,9.5): 0.5793 - val_ca2-[9.5,10.3): 0.4293 - val_ca2-[10.3,11.3): 0.9511 - val_ca2-[11.3,14.9): 1.6471 - val_ca3-[8.0,9.5): 0.7334 - val_ca3-[9.5,10.3): 0.4775 - val_ca3-[10.3,11.3): 0.7411 - val_ca3-[11.3,14.9): 1.0672 - val_ca4-[8.0,9.5): 0.7282 - val_ca4-[9.5,10.3): 0.4743 - val_ca4-[10.3,11.3): 0.7425 - val_ca4-[11.3,14.9): 1.0752\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 1.1613 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3792 - ca2-[9.5,10.3): 0.5195 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5303 - ca3-[10.3,11.3): 0.7456 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7185 - ca4-[11.3,14.9): 1.0603 - val_ca1-[8.0,9.5): 1.1334 - val_ca1-[9.5,10.3): 1.2048 - val_ca1-[10.3,11.3): 2.2582 - val_ca1-[11.3,14.9): 3.7434 - val_ca2-[8.0,9.5): 0.5798 - val_ca2-[9.5,10.3): 0.4274 - val_ca2-[10.3,11.3): 0.9407 - val_ca2-[11.3,14.9): 1.6342 - val_ca3-[8.0,9.5): 0.7419 - val_ca3-[9.5,10.3): 0.4829 - val_ca3-[10.3,11.3): 0.7391 - val_ca3-[11.3,14.9): 1.0558 - val_ca4-[8.0,9.5): 0.7542 - val_ca4-[9.5,10.3): 0.4910 - val_ca4-[10.3,11.3): 0.7367 - val_ca4-[11.3,14.9): 1.0380\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.1438 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3569 - ca2-[9.5,10.3): 0.5140 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4961 - ca3-[10.3,11.3): 0.7383 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6774 - ca4-[11.3,14.9): 1.0178 - val_ca1-[8.0,9.5): 1.0792 - val_ca1-[9.5,10.3): 1.1398 - val_ca1-[10.3,11.3): 2.1759 - val_ca1-[11.3,14.9): 3.6166 - val_ca2-[8.0,9.5): 0.5803 - val_ca2-[9.5,10.3): 0.4258 - val_ca2-[10.3,11.3): 0.9368 - val_ca2-[11.3,14.9): 1.6297 - val_ca3-[8.0,9.5): 0.7494 - val_ca3-[9.5,10.3): 0.4878 - val_ca3-[10.3,11.3): 0.7375 - val_ca3-[11.3,14.9): 1.0584 - val_ca4-[8.0,9.5): 0.7811 - val_ca4-[9.5,10.3): 0.5090 - val_ca4-[10.3,11.3): 0.7329 - val_ca4-[11.3,14.9): 1.0171\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.0997 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3702 - ca2-[9.5,10.3): 0.5226 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5184 - ca3-[10.3,11.3): 0.7205 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6778 - ca4-[11.3,14.9): 0.9568 - val_ca1-[8.0,9.5): 1.0280 - val_ca1-[9.5,10.3): 1.0779 - val_ca1-[10.3,11.3): 2.0909 - val_ca1-[11.3,14.9): 3.5424 - val_ca2-[8.0,9.5): 0.5810 - val_ca2-[9.5,10.3): 0.4244 - val_ca2-[10.3,11.3): 0.9342 - val_ca2-[11.3,14.9): 1.6439 - val_ca3-[8.0,9.5): 0.7566 - val_ca3-[9.5,10.3): 0.4925 - val_ca3-[10.3,11.3): 0.7406 - val_ca3-[11.3,14.9): 1.0642 - val_ca4-[8.0,9.5): 0.8085 - val_ca4-[9.5,10.3): 0.5279 - val_ca4-[10.3,11.3): 0.7356 - val_ca4-[11.3,14.9): 0.9997\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 1.0479 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3735 - ca2-[9.5,10.3): 0.5245 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5365 - ca3-[10.3,11.3): 0.7205 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6257 - ca4-[11.3,14.9): 0.9532 - val_ca1-[8.0,9.5): 0.9800 - val_ca1-[9.5,10.3): 1.0194 - val_ca1-[10.3,11.3): 2.0097 - val_ca1-[11.3,14.9): 3.3756 - val_ca2-[8.0,9.5): 0.5816 - val_ca2-[9.5,10.3): 0.4233 - val_ca2-[10.3,11.3): 0.9272 - val_ca2-[11.3,14.9): 1.6071 - val_ca3-[8.0,9.5): 0.7632 - val_ca3-[9.5,10.3): 0.4969 - val_ca3-[10.3,11.3): 0.7353 - val_ca3-[11.3,14.9): 1.0408 - val_ca4-[8.0,9.5): 0.8366 - val_ca4-[9.5,10.3): 0.5478 - val_ca4-[10.3,11.3): 0.7308 - val_ca4-[11.3,14.9): 0.9583\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 1.0043 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3711 - ca2-[9.5,10.3): 0.5319 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5381 - ca3-[10.3,11.3): 0.7257 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6434 - ca4-[11.3,14.9): 0.9112 - val_ca1-[8.0,9.5): 0.9356 - val_ca1-[9.5,10.3): 0.9646 - val_ca1-[10.3,11.3): 1.9264 - val_ca1-[11.3,14.9): 3.2683 - val_ca2-[8.0,9.5): 0.5822 - val_ca2-[9.5,10.3): 0.4223 - val_ca2-[10.3,11.3): 0.9240 - val_ca2-[11.3,14.9): 1.5974 - val_ca3-[8.0,9.5): 0.7695 - val_ca3-[9.5,10.3): 0.5011 - val_ca3-[10.3,11.3): 0.7386 - val_ca3-[11.3,14.9): 1.0284 - val_ca4-[8.0,9.5): 0.8647 - val_ca4-[9.5,10.3): 0.5682 - val_ca4-[10.3,11.3): 0.7371 - val_ca4-[11.3,14.9): 0.9271\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.9377 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3629 - ca2-[9.5,10.3): 0.5230 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5050 - ca3-[10.3,11.3): 0.7153 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5235 - ca4-[11.3,14.9): 0.8959 - val_ca1-[8.0,9.5): 0.8952 - val_ca1-[9.5,10.3): 0.9141 - val_ca1-[10.3,11.3): 1.8501 - val_ca1-[11.3,14.9): 3.0936 - val_ca2-[8.0,9.5): 0.5829 - val_ca2-[9.5,10.3): 0.4214 - val_ca2-[10.3,11.3): 0.9174 - val_ca2-[11.3,14.9): 1.5471 - val_ca3-[8.0,9.5): 0.7750 - val_ca3-[9.5,10.3): 0.5048 - val_ca3-[10.3,11.3): 0.7357 - val_ca3-[11.3,14.9): 0.9957 - val_ca4-[8.0,9.5): 0.8931 - val_ca4-[9.5,10.3): 0.5891 - val_ca4-[10.3,11.3): 0.7375 - val_ca4-[11.3,14.9): 0.8825\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.8964 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3572 - ca2-[9.5,10.3): 0.5228 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5285 - ca3-[10.3,11.3): 0.7243 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5863 - ca4-[11.3,14.9): 0.8770 - val_ca1-[8.0,9.5): 0.8581 - val_ca1-[9.5,10.3): 0.8673 - val_ca1-[10.3,11.3): 1.7827 - val_ca1-[11.3,14.9): 3.0773 - val_ca2-[8.0,9.5): 0.5835 - val_ca2-[9.5,10.3): 0.4208 - val_ca2-[10.3,11.3): 0.9098 - val_ca2-[11.3,14.9): 1.5905 - val_ca3-[8.0,9.5): 0.7803 - val_ca3-[9.5,10.3): 0.5084 - val_ca3-[10.3,11.3): 0.7268 - val_ca3-[11.3,14.9): 1.0178 - val_ca4-[8.0,9.5): 0.9214 - val_ca4-[9.5,10.3): 0.6103 - val_ca4-[10.3,11.3): 0.7315 - val_ca4-[11.3,14.9): 0.8824\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.8621 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3777 - ca2-[9.5,10.3): 0.5278 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5080 - ca3-[10.3,11.3): 0.7157 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5507 - ca4-[11.3,14.9): 0.8566 - val_ca1-[8.0,9.5): 0.8248 - val_ca1-[9.5,10.3): 0.8247 - val_ca1-[10.3,11.3): 1.7056 - val_ca1-[11.3,14.9): 2.9602 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.4202 - val_ca2-[10.3,11.3): 0.9056 - val_ca2-[11.3,14.9): 1.5756 - val_ca3-[8.0,9.5): 0.7849 - val_ca3-[9.5,10.3): 0.5115 - val_ca3-[10.3,11.3): 0.7328 - val_ca3-[11.3,14.9): 1.0122 - val_ca4-[8.0,9.5): 0.9496 - val_ca4-[9.5,10.3): 0.6317 - val_ca4-[10.3,11.3): 0.7455 - val_ca4-[11.3,14.9): 0.8660\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.8246 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3798 - ca2-[9.5,10.3): 0.5203 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5245 - ca3-[10.3,11.3): 0.7157 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5759 - ca4-[11.3,14.9): 0.8164 - val_ca1-[8.0,9.5): 0.7951 - val_ca1-[9.5,10.3): 0.7860 - val_ca1-[10.3,11.3): 1.6454 - val_ca1-[11.3,14.9): 2.8397 - val_ca2-[8.0,9.5): 0.5846 - val_ca2-[9.5,10.3): 0.4197 - val_ca2-[10.3,11.3): 0.9027 - val_ca2-[11.3,14.9): 1.5456 - val_ca3-[8.0,9.5): 0.7896 - val_ca3-[9.5,10.3): 0.5147 - val_ca3-[10.3,11.3): 0.7324 - val_ca3-[11.3,14.9): 0.9865 - val_ca4-[8.0,9.5): 0.9774 - val_ca4-[9.5,10.3): 0.6531 - val_ca4-[10.3,11.3): 0.7513 - val_ca4-[11.3,14.9): 0.8302\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.7588 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3657 - ca2-[9.5,10.3): 0.5165 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5452 - ca3-[10.3,11.3): 0.7329 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5449 - ca4-[11.3,14.9): 0.8084 - val_ca1-[8.0,9.5): 0.7683 - val_ca1-[9.5,10.3): 0.7507 - val_ca1-[10.3,11.3): 1.5637 - val_ca1-[11.3,14.9): 2.7260 - val_ca2-[8.0,9.5): 0.5850 - val_ca2-[9.5,10.3): 0.4193 - val_ca2-[10.3,11.3): 0.8812 - val_ca2-[11.3,14.9): 1.5183 - val_ca3-[8.0,9.5): 0.7937 - val_ca3-[9.5,10.3): 0.5176 - val_ca3-[10.3,11.3): 0.7178 - val_ca3-[11.3,14.9): 0.9635 - val_ca4-[8.0,9.5): 1.0051 - val_ca4-[9.5,10.3): 0.6745 - val_ca4-[10.3,11.3): 0.7458 - val_ca4-[11.3,14.9): 0.7986\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.7538 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3908 - ca2-[9.5,10.3): 0.5179 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5065 - ca3-[10.3,11.3): 0.7147 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5471 - ca4-[11.3,14.9): 0.8173 - val_ca1-[8.0,9.5): 0.7443 - val_ca1-[9.5,10.3): 0.7185 - val_ca1-[10.3,11.3): 1.5438 - val_ca1-[11.3,14.9): 2.6814 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.4190 - val_ca2-[10.3,11.3): 0.9008 - val_ca2-[11.3,14.9): 1.5336 - val_ca3-[8.0,9.5): 0.7976 - val_ca3-[9.5,10.3): 0.5202 - val_ca3-[10.3,11.3): 0.7315 - val_ca3-[11.3,14.9): 0.9669 - val_ca4-[8.0,9.5): 1.0325 - val_ca4-[9.5,10.3): 0.6960 - val_ca4-[10.3,11.3): 0.7629 - val_ca4-[11.3,14.9): 0.7860\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.7273 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3828 - ca2-[9.5,10.3): 0.5135 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5347 - ca3-[10.3,11.3): 0.7106 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5504 - ca4-[11.3,14.9): 0.7866 - val_ca1-[8.0,9.5): 0.7229 - val_ca1-[9.5,10.3): 0.6893 - val_ca1-[10.3,11.3): 1.4988 - val_ca1-[11.3,14.9): 2.6404 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.4187 - val_ca2-[10.3,11.3): 0.9029 - val_ca2-[11.3,14.9): 1.5619 - val_ca3-[8.0,9.5): 0.8008 - val_ca3-[9.5,10.3): 0.5224 - val_ca3-[10.3,11.3): 0.7358 - val_ca3-[11.3,14.9): 0.9930 - val_ca4-[8.0,9.5): 1.0589 - val_ca4-[9.5,10.3): 0.7169 - val_ca4-[10.3,11.3): 0.7750 - val_ca4-[11.3,14.9): 0.8019\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.6999 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3706 - ca2-[9.5,10.3): 0.5123 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5474 - ca3-[10.3,11.3): 0.7214 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5757 - ca4-[11.3,14.9): 0.7737 - val_ca1-[8.0,9.5): 0.7041 - val_ca1-[9.5,10.3): 0.6631 - val_ca1-[10.3,11.3): 1.4438 - val_ca1-[11.3,14.9): 2.5225 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.4185 - val_ca2-[10.3,11.3): 0.8926 - val_ca2-[11.3,14.9): 1.5247 - val_ca3-[8.0,9.5): 0.8038 - val_ca3-[9.5,10.3): 0.5245 - val_ca3-[10.3,11.3): 0.7294 - val_ca3-[11.3,14.9): 0.9691 - val_ca4-[8.0,9.5): 1.0846 - val_ca4-[9.5,10.3): 0.7373 - val_ca4-[10.3,11.3): 0.7778 - val_ca4-[11.3,14.9): 0.7777\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.6895 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3803 - ca2-[9.5,10.3): 0.5345 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5586 - ca3-[10.3,11.3): 0.7232 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5647 - ca4-[11.3,14.9): 0.7765 - val_ca1-[8.0,9.5): 0.6873 - val_ca1-[9.5,10.3): 0.6394 - val_ca1-[10.3,11.3): 1.4120 - val_ca1-[11.3,14.9): 2.5109 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.4183 - val_ca2-[10.3,11.3): 0.8975 - val_ca2-[11.3,14.9): 1.5629 - val_ca3-[8.0,9.5): 0.8065 - val_ca3-[9.5,10.3): 0.5264 - val_ca3-[10.3,11.3): 0.7333 - val_ca3-[11.3,14.9): 0.9963 - val_ca4-[8.0,9.5): 1.1100 - val_ca4-[9.5,10.3): 0.7577 - val_ca4-[10.3,11.3): 0.7882 - val_ca4-[11.3,14.9): 0.7905\n",
      "Epoch 65/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.6582 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3665 - ca2-[9.5,10.3): 0.5193 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5287 - ca3-[10.3,11.3): 0.7303 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5399 - ca4-[11.3,14.9): 0.7670 - val_ca1-[8.0,9.5): 0.6725 - val_ca1-[9.5,10.3): 0.6178 - val_ca1-[10.3,11.3): 1.3652 - val_ca1-[11.3,14.9): 2.3901 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.4180 - val_ca2-[10.3,11.3): 0.8896 - val_ca2-[11.3,14.9): 1.5177 - val_ca3-[8.0,9.5): 0.8095 - val_ca3-[9.5,10.3): 0.5285 - val_ca3-[10.3,11.3): 0.7293 - val_ca3-[11.3,14.9): 0.9677 - val_ca4-[8.0,9.5): 1.1347 - val_ca4-[9.5,10.3): 0.7776 - val_ca4-[10.3,11.3): 0.7941 - val_ca4-[11.3,14.9): 0.7674\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.6359 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3820 - ca2-[9.5,10.3): 0.5174 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5541 - ca3-[10.3,11.3): 0.7133 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5291 - ca4-[11.3,14.9): 0.7431 - val_ca1-[8.0,9.5): 0.6595 - val_ca1-[9.5,10.3): 0.5985 - val_ca1-[10.3,11.3): 1.3394 - val_ca1-[11.3,14.9): 2.3541 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.4179 - val_ca2-[10.3,11.3): 0.8946 - val_ca2-[11.3,14.9): 1.5278 - val_ca3-[8.0,9.5): 0.8122 - val_ca3-[9.5,10.3): 0.5303 - val_ca3-[10.3,11.3): 0.7331 - val_ca3-[11.3,14.9): 0.9706 - val_ca4-[8.0,9.5): 1.1581 - val_ca4-[9.5,10.3): 0.7965 - val_ca4-[10.3,11.3): 0.8044 - val_ca4-[11.3,14.9): 0.7603\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.6230 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3710 - ca2-[9.5,10.3): 0.5250 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5411 - ca3-[10.3,11.3): 0.7092 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5394 - ca4-[11.3,14.9): 0.7430 - val_ca1-[8.0,9.5): 0.6482 - val_ca1-[9.5,10.3): 0.5812 - val_ca1-[10.3,11.3): 1.3058 - val_ca1-[11.3,14.9): 2.3277 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.4177 - val_ca2-[10.3,11.3): 0.8916 - val_ca2-[11.3,14.9): 1.5450 - val_ca3-[8.0,9.5): 0.8147 - val_ca3-[9.5,10.3): 0.5321 - val_ca3-[10.3,11.3): 0.7308 - val_ca3-[11.3,14.9): 0.9799 - val_ca4-[8.0,9.5): 1.1808 - val_ca4-[9.5,10.3): 0.8150 - val_ca4-[10.3,11.3): 0.8101 - val_ca4-[11.3,14.9): 0.7598\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.6143 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3798 - ca2-[9.5,10.3): 0.5223 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5561 - ca3-[10.3,11.3): 0.7106 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5166 - ca4-[11.3,14.9): 0.7202 - val_ca1-[8.0,9.5): 0.6380 - val_ca1-[9.5,10.3): 0.5653 - val_ca1-[10.3,11.3): 1.2641 - val_ca1-[11.3,14.9): 2.2595 - val_ca2-[8.0,9.5): 0.5876 - val_ca2-[9.5,10.3): 0.4176 - val_ca2-[10.3,11.3): 0.8840 - val_ca2-[11.3,14.9): 1.5263 - val_ca3-[8.0,9.5): 0.8170 - val_ca3-[9.5,10.3): 0.5337 - val_ca3-[10.3,11.3): 0.7297 - val_ca3-[11.3,14.9): 0.9615 - val_ca4-[8.0,9.5): 1.2027 - val_ca4-[9.5,10.3): 0.8328 - val_ca4-[10.3,11.3): 0.8215 - val_ca4-[11.3,14.9): 0.7383\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.6025 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3720 - ca2-[9.5,10.3): 0.5199 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5510 - ca3-[10.3,11.3): 0.7123 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5308 - ca4-[11.3,14.9): 0.7240 - val_ca1-[8.0,9.5): 0.6292 - val_ca1-[9.5,10.3): 0.5510 - val_ca1-[10.3,11.3): 1.2418 - val_ca1-[11.3,14.9): 2.2281 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4176 - val_ca2-[10.3,11.3): 0.8858 - val_ca2-[11.3,14.9): 1.5416 - val_ca3-[8.0,9.5): 0.8190 - val_ca3-[9.5,10.3): 0.5352 - val_ca3-[10.3,11.3): 0.7291 - val_ca3-[11.3,14.9): 0.9777 - val_ca4-[8.0,9.5): 1.2238 - val_ca4-[9.5,10.3): 0.8501 - val_ca4-[10.3,11.3): 0.8267 - val_ca4-[11.3,14.9): 0.7523\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5885 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3688 - ca2-[9.5,10.3): 0.5246 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5574 - ca3-[10.3,11.3): 0.7300 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5477 - ca4-[11.3,14.9): 0.7241 - val_ca1-[8.0,9.5): 0.6215 - val_ca1-[9.5,10.3): 0.5381 - val_ca1-[10.3,11.3): 1.2164 - val_ca1-[11.3,14.9): 2.1164 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4175 - val_ca2-[10.3,11.3): 0.8854 - val_ca2-[11.3,14.9): 1.4887 - val_ca3-[8.0,9.5): 0.8207 - val_ca3-[9.5,10.3): 0.5364 - val_ca3-[10.3,11.3): 0.7291 - val_ca3-[11.3,14.9): 0.9441 - val_ca4-[8.0,9.5): 1.2438 - val_ca4-[9.5,10.3): 0.8665 - val_ca4-[10.3,11.3): 0.8345 - val_ca4-[11.3,14.9): 0.7324\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5965 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3738 - ca2-[9.5,10.3): 0.5167 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5280 - ca3-[10.3,11.3): 0.7188 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5571 - ca4-[11.3,14.9): 0.7189 - val_ca1-[8.0,9.5): 0.6147 - val_ca1-[9.5,10.3): 0.5235 - val_ca1-[10.3,11.3): 1.1994 - val_ca1-[11.3,14.9): 2.1052 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4114 - val_ca2-[10.3,11.3): 0.8893 - val_ca2-[11.3,14.9): 1.5097 - val_ca3-[8.0,9.5): 0.8221 - val_ca3-[9.5,10.3): 0.5272 - val_ca3-[10.3,11.3): 0.7307 - val_ca3-[11.3,14.9): 0.9556 - val_ca4-[8.0,9.5): 1.2628 - val_ca4-[9.5,10.3): 0.8687 - val_ca4-[10.3,11.3): 0.8415 - val_ca4-[11.3,14.9): 0.7337\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5737 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3728 - ca2-[9.5,10.3): 0.5274 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5037 - ca3-[10.3,11.3): 0.7158 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5570 - ca4-[11.3,14.9): 0.7284 - val_ca1-[8.0,9.5): 0.6089 - val_ca1-[9.5,10.3): 0.5161 - val_ca1-[10.3,11.3): 1.1777 - val_ca1-[11.3,14.9): 2.0557 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4174 - val_ca2-[10.3,11.3): 0.8890 - val_ca2-[11.3,14.9): 1.4999 - val_ca3-[8.0,9.5): 0.8233 - val_ca3-[9.5,10.3): 0.5381 - val_ca3-[10.3,11.3): 0.7307 - val_ca3-[11.3,14.9): 0.9495 - val_ca4-[8.0,9.5): 1.2814 - val_ca4-[9.5,10.3): 0.8976 - val_ca4-[10.3,11.3): 0.8490 - val_ca4-[11.3,14.9): 0.7289\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5708 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3585 - ca2-[9.5,10.3): 0.5164 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5336 - ca3-[10.3,11.3): 0.7093 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5062 - ca4-[11.3,14.9): 0.7096 - val_ca1-[8.0,9.5): 0.6038 - val_ca1-[9.5,10.3): 0.5065 - val_ca1-[10.3,11.3): 1.1626 - val_ca1-[11.3,14.9): 2.0626 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4174 - val_ca2-[10.3,11.3): 0.8926 - val_ca2-[11.3,14.9): 1.5317 - val_ca3-[8.0,9.5): 0.8247 - val_ca3-[9.5,10.3): 0.5392 - val_ca3-[10.3,11.3): 0.7327 - val_ca3-[11.3,14.9): 0.9652 - val_ca4-[8.0,9.5): 1.2993 - val_ca4-[9.5,10.3): 0.9125 - val_ca4-[10.3,11.3): 0.8567 - val_ca4-[11.3,14.9): 0.7294\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5623 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3841 - ca2-[9.5,10.3): 0.5228 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5659 - ca3-[10.3,11.3): 0.7252 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5016 - ca4-[11.3,14.9): 0.7131 - val_ca1-[8.0,9.5): 0.5994 - val_ca1-[9.5,10.3): 0.4980 - val_ca1-[10.3,11.3): 1.1123 - val_ca1-[11.3,14.9): 2.0113 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8669 - val_ca2-[11.3,14.9): 1.5178 - val_ca3-[8.0,9.5): 0.8260 - val_ca3-[9.5,10.3): 0.5401 - val_ca3-[10.3,11.3): 0.7174 - val_ca3-[11.3,14.9): 0.9585 - val_ca4-[8.0,9.5): 1.3159 - val_ca4-[9.5,10.3): 0.9263 - val_ca4-[10.3,11.3): 0.8575 - val_ca4-[11.3,14.9): 0.7280\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5645 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3585 - ca2-[9.5,10.3): 0.5109 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5084 - ca3-[10.3,11.3): 0.7080 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5214 - ca4-[11.3,14.9): 0.7053 - val_ca1-[8.0,9.5): 0.5957 - val_ca1-[9.5,10.3): 0.4904 - val_ca1-[10.3,11.3): 1.1266 - val_ca1-[11.3,14.9): 2.0121 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8922 - val_ca2-[11.3,14.9): 1.5376 - val_ca3-[8.0,9.5): 0.8271 - val_ca3-[9.5,10.3): 0.5409 - val_ca3-[10.3,11.3): 0.7327 - val_ca3-[11.3,14.9): 0.9566 - val_ca4-[8.0,9.5): 1.3319 - val_ca4-[9.5,10.3): 0.9396 - val_ca4-[10.3,11.3): 0.8705 - val_ca4-[11.3,14.9): 0.7056\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5375 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3689 - ca2-[9.5,10.3): 0.5221 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5209 - ca3-[10.3,11.3): 0.7140 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5578 - ca4-[11.3,14.9): 0.7176 - val_ca1-[8.0,9.5): 0.5925 - val_ca1-[9.5,10.3): 0.4834 - val_ca1-[10.3,11.3): 1.1059 - val_ca1-[11.3,14.9): 1.9739 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4178 - val_ca2-[10.3,11.3): 0.8860 - val_ca2-[11.3,14.9): 1.5334 - val_ca3-[8.0,9.5): 0.8280 - val_ca3-[9.5,10.3): 0.5432 - val_ca3-[10.3,11.3): 0.7239 - val_ca3-[11.3,14.9): 0.9602 - val_ca4-[8.0,9.5): 1.3471 - val_ca4-[9.5,10.3): 0.9552 - val_ca4-[10.3,11.3): 0.8659 - val_ca4-[11.3,14.9): 0.7158\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5490 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3839 - ca2-[9.5,10.3): 0.5201 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5482 - ca3-[10.3,11.3): 0.7080 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5429 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5899 - val_ca1-[9.5,10.3): 0.4775 - val_ca1-[10.3,11.3): 1.0829 - val_ca1-[11.3,14.9): 1.9508 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8814 - val_ca2-[11.3,14.9): 1.5393 - val_ca3-[8.0,9.5): 0.8286 - val_ca3-[9.5,10.3): 0.5418 - val_ca3-[10.3,11.3): 0.7273 - val_ca3-[11.3,14.9): 0.9710 - val_ca4-[8.0,9.5): 1.3613 - val_ca4-[9.5,10.3): 0.9642 - val_ca4-[10.3,11.3): 0.8829 - val_ca4-[11.3,14.9): 0.7301\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5392 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3837 - ca2-[9.5,10.3): 0.5090 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5367 - ca3-[10.3,11.3): 0.7031 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5837 - ca4-[11.3,14.9): 0.7097 - val_ca1-[8.0,9.5): 0.5876 - val_ca1-[9.5,10.3): 0.4720 - val_ca1-[10.3,11.3): 1.0720 - val_ca1-[11.3,14.9): 1.9283 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8811 - val_ca2-[11.3,14.9): 1.5386 - val_ca3-[8.0,9.5): 0.8293 - val_ca3-[9.5,10.3): 0.5423 - val_ca3-[10.3,11.3): 0.7223 - val_ca3-[11.3,14.9): 0.9652 - val_ca4-[8.0,9.5): 1.3751 - val_ca4-[9.5,10.3): 0.9758 - val_ca4-[10.3,11.3): 0.8792 - val_ca4-[11.3,14.9): 0.7182\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5237 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3828 - ca2-[9.5,10.3): 0.5160 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5497 - ca3-[10.3,11.3): 0.7225 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5351 - ca4-[11.3,14.9): 0.6968 - val_ca1-[8.0,9.5): 0.5857 - val_ca1-[9.5,10.3): 0.4670 - val_ca1-[10.3,11.3): 1.0560 - val_ca1-[11.3,14.9): 1.8889 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8813 - val_ca2-[11.3,14.9): 1.5240 - val_ca3-[8.0,9.5): 0.8303 - val_ca3-[9.5,10.3): 0.5430 - val_ca3-[10.3,11.3): 0.7297 - val_ca3-[11.3,14.9): 0.9504 - val_ca4-[8.0,9.5): 1.3880 - val_ca4-[9.5,10.3): 0.9866 - val_ca4-[10.3,11.3): 0.9000 - val_ca4-[11.3,14.9): 0.7043\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5470 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3681 - ca2-[9.5,10.3): 0.5147 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5783 - ca3-[10.3,11.3): 0.7317 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5618 - ca4-[11.3,14.9): 0.7030 - val_ca1-[8.0,9.5): 0.5841 - val_ca1-[9.5,10.3): 0.4625 - val_ca1-[10.3,11.3): 1.0556 - val_ca1-[11.3,14.9): 1.8599 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8903 - val_ca2-[11.3,14.9): 1.5206 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5436 - val_ca3-[10.3,11.3): 0.7328 - val_ca3-[11.3,14.9): 0.9517 - val_ca4-[8.0,9.5): 1.4004 - val_ca4-[9.5,10.3): 0.9971 - val_ca4-[10.3,11.3): 0.9031 - val_ca4-[11.3,14.9): 0.7111\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5312 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3761 - ca2-[9.5,10.3): 0.5301 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5802 - ca3-[10.3,11.3): 0.7062 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5424 - ca4-[11.3,14.9): 0.7051 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4585 - val_ca1-[10.3,11.3): 1.0450 - val_ca1-[11.3,14.9): 1.8454 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8904 - val_ca2-[11.3,14.9): 1.5248 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5445 - val_ca3-[10.3,11.3): 0.7328 - val_ca3-[11.3,14.9): 0.9508 - val_ca4-[8.0,9.5): 1.4129 - val_ca4-[9.5,10.3): 1.0075 - val_ca4-[10.3,11.3): 0.9088 - val_ca4-[11.3,14.9): 0.7066\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5359 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3555 - ca2-[9.5,10.3): 0.5088 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5559 - ca3-[10.3,11.3): 0.7372 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5034 - ca4-[11.3,14.9): 0.6850 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4549 - val_ca1-[10.3,11.3): 1.0254 - val_ca1-[11.3,14.9): 1.8402 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8796 - val_ca2-[11.3,14.9): 1.5372 - val_ca3-[8.0,9.5): 0.8333 - val_ca3-[9.5,10.3): 0.5451 - val_ca3-[10.3,11.3): 0.7200 - val_ca3-[11.3,14.9): 0.9602 - val_ca4-[8.0,9.5): 1.4241 - val_ca4-[9.5,10.3): 1.0170 - val_ca4-[10.3,11.3): 0.8988 - val_ca4-[11.3,14.9): 0.7132\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5286 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3879 - ca2-[9.5,10.3): 0.5192 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5329 - ca3-[10.3,11.3): 0.6959 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5258 - ca4-[11.3,14.9): 0.6939 - val_ca1-[8.0,9.5): 0.5809 - val_ca1-[9.5,10.3): 0.4516 - val_ca1-[10.3,11.3): 1.0259 - val_ca1-[11.3,14.9): 1.8040 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8901 - val_ca2-[11.3,14.9): 1.5201 - val_ca3-[8.0,9.5): 0.8337 - val_ca3-[9.5,10.3): 0.5454 - val_ca3-[10.3,11.3): 0.7327 - val_ca3-[11.3,14.9): 0.9464 - val_ca4-[8.0,9.5): 1.4345 - val_ca4-[9.5,10.3): 1.0257 - val_ca4-[10.3,11.3): 0.9187 - val_ca4-[11.3,14.9): 0.7026\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5338 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3917 - ca2-[9.5,10.3): 0.5249 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5646 - ca3-[10.3,11.3): 0.7159 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5570 - ca4-[11.3,14.9): 0.6933 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4487 - val_ca1-[10.3,11.3): 1.0158 - val_ca1-[11.3,14.9): 1.7821 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4172 - val_ca2-[10.3,11.3): 0.8877 - val_ca2-[11.3,14.9): 1.5167 - val_ca3-[8.0,9.5): 0.8336 - val_ca3-[9.5,10.3): 0.5453 - val_ca3-[10.3,11.3): 0.7304 - val_ca3-[11.3,14.9): 0.9533 - val_ca4-[8.0,9.5): 1.4443 - val_ca4-[9.5,10.3): 1.0341 - val_ca4-[10.3,11.3): 0.9208 - val_ca4-[11.3,14.9): 0.7185\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5250 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3745 - ca2-[9.5,10.3): 0.5240 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5517 - ca3-[10.3,11.3): 0.7096 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5788 - ca4-[11.3,14.9): 0.6956 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4461 - val_ca1-[10.3,11.3): 1.0029 - val_ca1-[11.3,14.9): 1.7690 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4172 - val_ca2-[10.3,11.3): 0.8827 - val_ca2-[11.3,14.9): 1.5153 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5450 - val_ca3-[10.3,11.3): 0.7289 - val_ca3-[11.3,14.9): 0.9484 - val_ca4-[8.0,9.5): 1.4536 - val_ca4-[9.5,10.3): 1.0419 - val_ca4-[10.3,11.3): 0.9266 - val_ca4-[11.3,14.9): 0.7072\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5303 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3784 - ca2-[9.5,10.3): 0.5163 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5550 - ca3-[10.3,11.3): 0.7145 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5708 - ca4-[11.3,14.9): 0.6889 - val_ca1-[8.0,9.5): 0.5793 - val_ca1-[9.5,10.3): 0.4439 - val_ca1-[10.3,11.3): 1.0011 - val_ca1-[11.3,14.9): 1.7434 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4176 - val_ca2-[10.3,11.3): 0.8860 - val_ca2-[11.3,14.9): 1.5024 - val_ca3-[8.0,9.5): 0.8329 - val_ca3-[9.5,10.3): 0.5466 - val_ca3-[10.3,11.3): 0.7303 - val_ca3-[11.3,14.9): 0.9418 - val_ca4-[8.0,9.5): 1.4622 - val_ca4-[9.5,10.3): 1.0523 - val_ca4-[10.3,11.3): 0.9292 - val_ca4-[11.3,14.9): 0.7037\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5277 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3955 - ca2-[9.5,10.3): 0.5185 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5459 - ca3-[10.3,11.3): 0.7096 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5674 - ca4-[11.3,14.9): 0.6937 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4417 - val_ca1-[10.3,11.3): 0.9892 - val_ca1-[11.3,14.9): 1.7609 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8811 - val_ca2-[11.3,14.9): 1.5269 - val_ca3-[8.0,9.5): 0.8333 - val_ca3-[9.5,10.3): 0.5450 - val_ca3-[10.3,11.3): 0.7288 - val_ca3-[11.3,14.9): 0.9517 - val_ca4-[8.0,9.5): 1.4703 - val_ca4-[9.5,10.3): 1.0561 - val_ca4-[10.3,11.3): 0.9346 - val_ca4-[11.3,14.9): 0.6966\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5120 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3713 - ca2-[9.5,10.3): 0.5064 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5694 - ca3-[10.3,11.3): 0.7169 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5550 - ca4-[11.3,14.9): 0.6793 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4398 - val_ca1-[10.3,11.3): 0.9832 - val_ca1-[11.3,14.9): 1.7306 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8809 - val_ca2-[11.3,14.9): 1.5111 - val_ca3-[8.0,9.5): 0.8330 - val_ca3-[9.5,10.3): 0.5448 - val_ca3-[10.3,11.3): 0.7288 - val_ca3-[11.3,14.9): 0.9459 - val_ca4-[8.0,9.5): 1.4773 - val_ca4-[9.5,10.3): 1.0620 - val_ca4-[10.3,11.3): 0.9380 - val_ca4-[11.3,14.9): 0.7003\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5130 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3739 - ca2-[9.5,10.3): 0.5175 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5505 - ca3-[10.3,11.3): 0.7186 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5490 - ca4-[11.3,14.9): 0.6917 - val_ca1-[8.0,9.5): 0.5788 - val_ca1-[9.5,10.3): 0.4380 - val_ca1-[10.3,11.3): 0.9864 - val_ca1-[11.3,14.9): 1.7241 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8889 - val_ca2-[11.3,14.9): 1.5169 - val_ca3-[8.0,9.5): 0.8324 - val_ca3-[9.5,10.3): 0.5444 - val_ca3-[10.3,11.3): 0.7347 - val_ca3-[11.3,14.9): 0.9580 - val_ca4-[8.0,9.5): 1.4849 - val_ca4-[9.5,10.3): 1.0684 - val_ca4-[10.3,11.3): 0.9452 - val_ca4-[11.3,14.9): 0.7172\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3832 - ca2-[9.5,10.3): 0.5253 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5484 - ca3-[10.3,11.3): 0.7157 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5290 - ca4-[11.3,14.9): 0.6923 - val_ca1-[8.0,9.5): 0.5787 - val_ca1-[9.5,10.3): 0.4364 - val_ca1-[10.3,11.3): 0.9743 - val_ca1-[11.3,14.9): 1.7363 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8809 - val_ca2-[11.3,14.9): 1.5368 - val_ca3-[8.0,9.5): 0.8327 - val_ca3-[9.5,10.3): 0.5446 - val_ca3-[10.3,11.3): 0.7212 - val_ca3-[11.3,14.9): 0.9642 - val_ca4-[8.0,9.5): 1.4905 - val_ca4-[9.5,10.3): 1.0732 - val_ca4-[10.3,11.3): 0.9284 - val_ca4-[11.3,14.9): 0.7090\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5189 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3752 - ca2-[9.5,10.3): 0.5179 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5426 - ca3-[10.3,11.3): 0.7146 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5537 - ca4-[11.3,14.9): 0.6867 - val_ca1-[8.0,9.5): 0.5787 - val_ca1-[9.5,10.3): 0.4351 - val_ca1-[10.3,11.3): 0.9745 - val_ca1-[11.3,14.9): 1.6903 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8870 - val_ca2-[11.3,14.9): 1.5041 - val_ca3-[8.0,9.5): 0.8327 - val_ca3-[9.5,10.3): 0.5445 - val_ca3-[10.3,11.3): 0.7324 - val_ca3-[11.3,14.9): 0.9473 - val_ca4-[8.0,9.5): 1.4957 - val_ca4-[9.5,10.3): 1.0776 - val_ca4-[10.3,11.3): 0.9478 - val_ca4-[11.3,14.9): 0.7093\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5331 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3835 - ca2-[9.5,10.3): 0.5105 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5876 - ca3-[10.3,11.3): 0.7116 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5359 - ca4-[11.3,14.9): 0.6971 - val_ca1-[8.0,9.5): 0.5788 - val_ca1-[9.5,10.3): 0.4338 - val_ca1-[10.3,11.3): 0.9649 - val_ca1-[11.3,14.9): 1.6796 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8826 - val_ca2-[11.3,14.9): 1.5023 - val_ca3-[8.0,9.5): 0.8334 - val_ca3-[9.5,10.3): 0.5450 - val_ca3-[10.3,11.3): 0.7309 - val_ca3-[11.3,14.9): 0.9445 - val_ca4-[8.0,9.5): 1.5010 - val_ca4-[9.5,10.3): 1.0821 - val_ca4-[10.3,11.3): 0.9521 - val_ca4-[11.3,14.9): 0.7063\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5218 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3737 - ca2-[9.5,10.3): 0.5101 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5308 - ca3-[10.3,11.3): 0.7189 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5850 - ca4-[11.3,14.9): 0.6936 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4326 - val_ca1-[10.3,11.3): 0.9607 - val_ca1-[11.3,14.9): 1.7072 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8826 - val_ca2-[11.3,14.9): 1.5363 - val_ca3-[8.0,9.5): 0.8341 - val_ca3-[9.5,10.3): 0.5455 - val_ca3-[10.3,11.3): 0.7308 - val_ca3-[11.3,14.9): 0.9678 - val_ca4-[8.0,9.5): 1.5072 - val_ca4-[9.5,10.3): 1.0874 - val_ca4-[10.3,11.3): 0.9551 - val_ca4-[11.3,14.9): 0.7191\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5141 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3695 - ca2-[9.5,10.3): 0.5200 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5819 - ca3-[10.3,11.3): 0.7274 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5952 - ca4-[11.3,14.9): 0.6904 - val_ca1-[8.0,9.5): 0.5790 - val_ca1-[9.5,10.3): 0.4316 - val_ca1-[10.3,11.3): 0.9618 - val_ca1-[11.3,14.9): 1.6749 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8871 - val_ca2-[11.3,14.9): 1.5134 - val_ca3-[8.0,9.5): 0.8339 - val_ca3-[9.5,10.3): 0.5454 - val_ca3-[10.3,11.3): 0.7323 - val_ca3-[11.3,14.9): 0.9481 - val_ca4-[8.0,9.5): 1.5121 - val_ca4-[9.5,10.3): 1.0916 - val_ca4-[10.3,11.3): 0.9558 - val_ca4-[11.3,14.9): 0.7032\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5244 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3921 - ca2-[9.5,10.3): 0.5185 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5633 - ca3-[10.3,11.3): 0.7071 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5538 - ca4-[11.3,14.9): 0.6929 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4306 - val_ca1-[10.3,11.3): 0.9547 - val_ca1-[11.3,14.9): 1.6858 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8828 - val_ca2-[11.3,14.9): 1.5301 - val_ca3-[8.0,9.5): 0.8342 - val_ca3-[9.5,10.3): 0.5455 - val_ca3-[10.3,11.3): 0.7232 - val_ca3-[11.3,14.9): 0.9560 - val_ca4-[8.0,9.5): 1.5170 - val_ca4-[9.5,10.3): 1.0957 - val_ca4-[10.3,11.3): 0.9436 - val_ca4-[11.3,14.9): 0.7011\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5248 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3723 - ca2-[9.5,10.3): 0.5250 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5487 - ca3-[10.3,11.3): 0.7259 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5357 - ca4-[11.3,14.9): 0.7096 - val_ca1-[8.0,9.5): 0.5793 - val_ca1-[9.5,10.3): 0.4296 - val_ca1-[10.3,11.3): 0.9524 - val_ca1-[11.3,14.9): 1.6229 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8857 - val_ca2-[11.3,14.9): 1.4798 - val_ca3-[8.0,9.5): 0.8342 - val_ca3-[9.5,10.3): 0.5455 - val_ca3-[10.3,11.3): 0.7300 - val_ca3-[11.3,14.9): 0.9223 - val_ca4-[8.0,9.5): 1.5209 - val_ca4-[9.5,10.3): 1.0990 - val_ca4-[10.3,11.3): 0.9575 - val_ca4-[11.3,14.9): 0.6883\n",
      "Epoch 97/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5176 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3748 - ca2-[9.5,10.3): 0.5263 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5850 - ca3-[10.3,11.3): 0.7278 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5022 - ca4-[11.3,14.9): 0.6878 - val_ca1-[8.0,9.5): 0.5795 - val_ca1-[9.5,10.3): 0.4287 - val_ca1-[10.3,11.3): 0.9507 - val_ca1-[11.3,14.9): 1.6353 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8878 - val_ca2-[11.3,14.9): 1.4997 - val_ca3-[8.0,9.5): 0.8338 - val_ca3-[9.5,10.3): 0.5452 - val_ca3-[10.3,11.3): 0.7322 - val_ca3-[11.3,14.9): 0.9395 - val_ca4-[8.0,9.5): 1.5248 - val_ca4-[9.5,10.3): 1.1024 - val_ca4-[10.3,11.3): 0.9620 - val_ca4-[11.3,14.9): 0.7020\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5268 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3827 - ca2-[9.5,10.3): 0.5147 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5616 - ca3-[10.3,11.3): 0.7164 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5650 - ca4-[11.3,14.9): 0.6893 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4280 - val_ca1-[10.3,11.3): 0.9458 - val_ca1-[11.3,14.9): 1.6370 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8862 - val_ca2-[11.3,14.9): 1.5070 - val_ca3-[8.0,9.5): 0.8337 - val_ca3-[9.5,10.3): 0.5451 - val_ca3-[10.3,11.3): 0.7299 - val_ca3-[11.3,14.9): 0.9381 - val_ca4-[8.0,9.5): 1.5279 - val_ca4-[9.5,10.3): 1.1050 - val_ca4-[10.3,11.3): 0.9609 - val_ca4-[11.3,14.9): 0.6916\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5276 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4024 - ca2-[9.5,10.3): 0.5202 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5401 - ca3-[10.3,11.3): 0.7226 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5298 - ca4-[11.3,14.9): 0.6998 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4273 - val_ca1-[10.3,11.3): 0.9425 - val_ca1-[11.3,14.9): 1.6366 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8861 - val_ca2-[11.3,14.9): 1.5140 - val_ca3-[8.0,9.5): 0.8335 - val_ca3-[9.5,10.3): 0.5450 - val_ca3-[10.3,11.3): 0.7303 - val_ca3-[11.3,14.9): 0.9498 - val_ca4-[8.0,9.5): 1.5306 - val_ca4-[9.5,10.3): 1.1073 - val_ca4-[10.3,11.3): 0.9638 - val_ca4-[11.3,14.9): 0.7092\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5074 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3666 - ca2-[9.5,10.3): 0.5145 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5522 - ca3-[10.3,11.3): 0.7182 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5947 - ca4-[11.3,14.9): 0.6950 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4267 - val_ca1-[10.3,11.3): 0.9374 - val_ca1-[11.3,14.9): 1.6134 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8845 - val_ca2-[11.3,14.9): 1.4979 - val_ca3-[8.0,9.5): 0.8335 - val_ca3-[9.5,10.3): 0.5449 - val_ca3-[10.3,11.3): 0.7305 - val_ca3-[11.3,14.9): 0.9365 - val_ca4-[8.0,9.5): 1.5333 - val_ca4-[9.5,10.3): 1.1096 - val_ca4-[10.3,11.3): 0.9680 - val_ca4-[11.3,14.9): 0.7000\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5097 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3614 - ca2-[9.5,10.3): 0.5186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5307 - ca3-[10.3,11.3): 0.7042 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5964 - ca4-[11.3,14.9): 0.7014 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4261 - val_ca1-[10.3,11.3): 0.9285 - val_ca1-[11.3,14.9): 1.5986 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8783 - val_ca2-[11.3,14.9): 1.4893 - val_ca3-[8.0,9.5): 0.8336 - val_ca3-[9.5,10.3): 0.5449 - val_ca3-[10.3,11.3): 0.7267 - val_ca3-[11.3,14.9): 0.9341 - val_ca4-[8.0,9.5): 1.5363 - val_ca4-[9.5,10.3): 1.1121 - val_ca4-[10.3,11.3): 0.9686 - val_ca4-[11.3,14.9): 0.7057\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5264 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3584 - ca2-[9.5,10.3): 0.5080 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5432 - ca3-[10.3,11.3): 0.7270 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5526 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5805 - val_ca1-[9.5,10.3): 0.4257 - val_ca1-[10.3,11.3): 0.9359 - val_ca1-[11.3,14.9): 1.6290 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4172 - val_ca2-[10.3,11.3): 0.8876 - val_ca2-[11.3,14.9): 1.5232 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5446 - val_ca3-[10.3,11.3): 0.7297 - val_ca3-[11.3,14.9): 0.9513 - val_ca4-[8.0,9.5): 1.5387 - val_ca4-[9.5,10.3): 1.1143 - val_ca4-[10.3,11.3): 0.9663 - val_ca4-[11.3,14.9): 0.7042\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5106 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3850 - ca2-[9.5,10.3): 0.5205 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5411 - ca3-[10.3,11.3): 0.7276 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5532 - ca4-[11.3,14.9): 0.6978 - val_ca1-[8.0,9.5): 0.5806 - val_ca1-[9.5,10.3): 0.4253 - val_ca1-[10.3,11.3): 0.9299 - val_ca1-[11.3,14.9): 1.6295 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8829 - val_ca2-[11.3,14.9): 1.5258 - val_ca3-[8.0,9.5): 0.8321 - val_ca3-[9.5,10.3): 0.5438 - val_ca3-[10.3,11.3): 0.7236 - val_ca3-[11.3,14.9): 0.9455 - val_ca4-[8.0,9.5): 1.5420 - val_ca4-[9.5,10.3): 1.1171 - val_ca4-[10.3,11.3): 0.9602 - val_ca4-[11.3,14.9): 0.6862\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5083 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3800 - ca2-[9.5,10.3): 0.5166 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5221 - ca3-[10.3,11.3): 0.7034 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5876 - ca4-[11.3,14.9): 0.6990 - val_ca1-[8.0,9.5): 0.5808 - val_ca1-[9.5,10.3): 0.4250 - val_ca1-[10.3,11.3): 0.9328 - val_ca1-[11.3,14.9): 1.6296 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8872 - val_ca2-[11.3,14.9): 1.5292 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5431 - val_ca3-[10.3,11.3): 0.7295 - val_ca3-[11.3,14.9): 0.9545 - val_ca4-[8.0,9.5): 1.5438 - val_ca4-[9.5,10.3): 1.1186 - val_ca4-[10.3,11.3): 0.9688 - val_ca4-[11.3,14.9): 0.6992\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5337 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3818 - ca2-[9.5,10.3): 0.5197 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5711 - ca3-[10.3,11.3): 0.7169 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5540 - ca4-[11.3,14.9): 0.6896 - val_ca1-[8.0,9.5): 0.5809 - val_ca1-[9.5,10.3): 0.4246 - val_ca1-[10.3,11.3): 0.9265 - val_ca1-[11.3,14.9): 1.6122 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8821 - val_ca2-[11.3,14.9): 1.5144 - val_ca3-[8.0,9.5): 0.8309 - val_ca3-[9.5,10.3): 0.5429 - val_ca3-[10.3,11.3): 0.7280 - val_ca3-[11.3,14.9): 0.9495 - val_ca4-[8.0,9.5): 1.5465 - val_ca4-[9.5,10.3): 1.1208 - val_ca4-[10.3,11.3): 0.9719 - val_ca4-[11.3,14.9): 0.7032\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5273 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3727 - ca2-[9.5,10.3): 0.5225 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5701 - ca3-[10.3,11.3): 0.6987 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5664 - ca4-[11.3,14.9): 0.6846 - val_ca1-[8.0,9.5): 0.5811 - val_ca1-[9.5,10.3): 0.4243 - val_ca1-[10.3,11.3): 0.9250 - val_ca1-[11.3,14.9): 1.6165 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8817 - val_ca2-[11.3,14.9): 1.5200 - val_ca3-[8.0,9.5): 0.8308 - val_ca3-[9.5,10.3): 0.5428 - val_ca3-[10.3,11.3): 0.7279 - val_ca3-[11.3,14.9): 0.9482 - val_ca4-[8.0,9.5): 1.5490 - val_ca4-[9.5,10.3): 1.1230 - val_ca4-[10.3,11.3): 0.9732 - val_ca4-[11.3,14.9): 0.6926\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5330 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3744 - ca2-[9.5,10.3): 0.5124 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5628 - ca3-[10.3,11.3): 0.7280 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5534 - ca4-[11.3,14.9): 0.6853 - val_ca1-[8.0,9.5): 0.5813 - val_ca1-[9.5,10.3): 0.4243 - val_ca1-[10.3,11.3): 0.9272 - val_ca1-[11.3,14.9): 1.6272 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4174 - val_ca2-[10.3,11.3): 0.8855 - val_ca2-[11.3,14.9): 1.5350 - val_ca3-[8.0,9.5): 0.8304 - val_ca3-[9.5,10.3): 0.5443 - val_ca3-[10.3,11.3): 0.7324 - val_ca3-[11.3,14.9): 0.9699 - val_ca4-[8.0,9.5): 1.5511 - val_ca4-[9.5,10.3): 1.1281 - val_ca4-[10.3,11.3): 0.9795 - val_ca4-[11.3,14.9): 0.7214\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5224 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3768 - ca2-[9.5,10.3): 0.5175 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5658 - ca3-[10.3,11.3): 0.7286 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5755 - ca4-[11.3,14.9): 0.6982 - val_ca1-[8.0,9.5): 0.5814 - val_ca1-[9.5,10.3): 0.4237 - val_ca1-[10.3,11.3): 0.9308 - val_ca1-[11.3,14.9): 1.5951 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8902 - val_ca2-[11.3,14.9): 1.5060 - val_ca3-[8.0,9.5): 0.8309 - val_ca3-[9.5,10.3): 0.5429 - val_ca3-[10.3,11.3): 0.7338 - val_ca3-[11.3,14.9): 0.9406 - val_ca4-[8.0,9.5): 1.5528 - val_ca4-[9.5,10.3): 1.1263 - val_ca4-[10.3,11.3): 0.9785 - val_ca4-[11.3,14.9): 0.6939\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.4995 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3706 - ca2-[9.5,10.3): 0.5191 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5620 - ca3-[10.3,11.3): 0.7118 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5715 - ca4-[11.3,14.9): 0.6946 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4235 - val_ca1-[10.3,11.3): 0.9256 - val_ca1-[11.3,14.9): 1.6267 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8863 - val_ca2-[11.3,14.9): 1.5400 - val_ca3-[8.0,9.5): 0.8315 - val_ca3-[9.5,10.3): 0.5432 - val_ca3-[10.3,11.3): 0.7293 - val_ca3-[11.3,14.9): 0.9692 - val_ca4-[8.0,9.5): 1.5543 - val_ca4-[9.5,10.3): 1.1275 - val_ca4-[10.3,11.3): 0.9740 - val_ca4-[11.3,14.9): 0.7175\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5206 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3861 - ca2-[9.5,10.3): 0.5235 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5426 - ca3-[10.3,11.3): 0.7062 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6050 - ca4-[11.3,14.9): 0.7041 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4232 - val_ca1-[10.3,11.3): 0.9198 - val_ca1-[11.3,14.9): 1.5918 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8823 - val_ca2-[11.3,14.9): 1.5088 - val_ca3-[8.0,9.5): 0.8319 - val_ca3-[9.5,10.3): 0.5435 - val_ca3-[10.3,11.3): 0.7277 - val_ca3-[11.3,14.9): 0.9366 - val_ca4-[8.0,9.5): 1.5554 - val_ca4-[9.5,10.3): 1.1285 - val_ca4-[10.3,11.3): 0.9764 - val_ca4-[11.3,14.9): 0.6852\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5169 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3834 - ca2-[9.5,10.3): 0.5168 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5383 - ca3-[10.3,11.3): 0.7012 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5584 - ca4-[11.3,14.9): 0.6890 - val_ca1-[8.0,9.5): 0.5819 - val_ca1-[9.5,10.3): 0.4230 - val_ca1-[10.3,11.3): 0.9187 - val_ca1-[11.3,14.9): 1.5891 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8821 - val_ca2-[11.3,14.9): 1.5084 - val_ca3-[8.0,9.5): 0.8321 - val_ca3-[9.5,10.3): 0.5436 - val_ca3-[10.3,11.3): 0.7276 - val_ca3-[11.3,14.9): 0.9388 - val_ca4-[8.0,9.5): 1.5568 - val_ca4-[9.5,10.3): 1.1297 - val_ca4-[10.3,11.3): 0.9771 - val_ca4-[11.3,14.9): 0.6909\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5148 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3833 - ca2-[9.5,10.3): 0.5186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5780 - ca3-[10.3,11.3): 0.7063 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5742 - ca4-[11.3,14.9): 0.6851 - val_ca1-[8.0,9.5): 0.5820 - val_ca1-[9.5,10.3): 0.4227 - val_ca1-[10.3,11.3): 0.9166 - val_ca1-[11.3,14.9): 1.5858 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8815 - val_ca2-[11.3,14.9): 1.5080 - val_ca3-[8.0,9.5): 0.8324 - val_ca3-[9.5,10.3): 0.5437 - val_ca3-[10.3,11.3): 0.7306 - val_ca3-[11.3,14.9): 0.9435 - val_ca4-[8.0,9.5): 1.5580 - val_ca4-[9.5,10.3): 1.1307 - val_ca4-[10.3,11.3): 0.9848 - val_ca4-[11.3,14.9): 0.7022\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5241 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3942 - ca2-[9.5,10.3): 0.5172 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5440 - ca3-[10.3,11.3): 0.7202 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5378 - ca4-[11.3,14.9): 0.6862 - val_ca1-[8.0,9.5): 0.5821 - val_ca1-[9.5,10.3): 0.4226 - val_ca1-[10.3,11.3): 0.9212 - val_ca1-[11.3,14.9): 1.5904 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8867 - val_ca2-[11.3,14.9): 1.5154 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5442 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9491 - val_ca4-[8.0,9.5): 1.5592 - val_ca4-[9.5,10.3): 1.1317 - val_ca4-[10.3,11.3): 0.9764 - val_ca4-[11.3,14.9): 0.7087\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5099 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3773 - ca2-[9.5,10.3): 0.5301 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5492 - ca3-[10.3,11.3): 0.7185 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5539 - ca4-[11.3,14.9): 0.6877 - val_ca1-[8.0,9.5): 0.5822 - val_ca1-[9.5,10.3): 0.4225 - val_ca1-[10.3,11.3): 0.9180 - val_ca1-[11.3,14.9): 1.5752 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8843 - val_ca2-[11.3,14.9): 1.5010 - val_ca3-[8.0,9.5): 0.8338 - val_ca3-[9.5,10.3): 0.5446 - val_ca3-[10.3,11.3): 0.7297 - val_ca3-[11.3,14.9): 0.9306 - val_ca4-[8.0,9.5): 1.5605 - val_ca4-[9.5,10.3): 1.1328 - val_ca4-[10.3,11.3): 0.9815 - val_ca4-[11.3,14.9): 0.6873\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5203 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3844 - ca2-[9.5,10.3): 0.5190 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5595 - ca3-[10.3,11.3): 0.7030 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5827 - ca4-[11.3,14.9): 0.6972 - val_ca1-[8.0,9.5): 0.5823 - val_ca1-[9.5,10.3): 0.4224 - val_ca1-[10.3,11.3): 0.9174 - val_ca1-[11.3,14.9): 1.5876 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8833 - val_ca2-[11.3,14.9): 1.5130 - val_ca3-[8.0,9.5): 0.8338 - val_ca3-[9.5,10.3): 0.5445 - val_ca3-[10.3,11.3): 0.7296 - val_ca3-[11.3,14.9): 0.9506 - val_ca4-[8.0,9.5): 1.5614 - val_ca4-[9.5,10.3): 1.1336 - val_ca4-[10.3,11.3): 0.9820 - val_ca4-[11.3,14.9): 0.7143\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5275 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3917 - ca2-[9.5,10.3): 0.5252 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5473 - ca3-[10.3,11.3): 0.7095 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6217 - ca4-[11.3,14.9): 0.6997 - val_ca1-[8.0,9.5): 0.5824 - val_ca1-[9.5,10.3): 0.4222 - val_ca1-[10.3,11.3): 0.9124 - val_ca1-[11.3,14.9): 1.5853 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8784 - val_ca2-[11.3,14.9): 1.5102 - val_ca3-[8.0,9.5): 0.8340 - val_ca3-[9.5,10.3): 0.5446 - val_ca3-[10.3,11.3): 0.7255 - val_ca3-[11.3,14.9): 0.9430 - val_ca4-[8.0,9.5): 1.5623 - val_ca4-[9.5,10.3): 1.1344 - val_ca4-[10.3,11.3): 0.9788 - val_ca4-[11.3,14.9): 0.7001\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5102 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3829 - ca2-[9.5,10.3): 0.5100 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5523 - ca3-[10.3,11.3): 0.7120 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5617 - ca4-[11.3,14.9): 0.6883 - val_ca1-[8.0,9.5): 0.5824 - val_ca1-[9.5,10.3): 0.4221 - val_ca1-[10.3,11.3): 0.9190 - val_ca1-[11.3,14.9): 1.5788 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8845 - val_ca2-[11.3,14.9): 1.5041 - val_ca3-[8.0,9.5): 0.8342 - val_ca3-[9.5,10.3): 0.5447 - val_ca3-[10.3,11.3): 0.7287 - val_ca3-[11.3,14.9): 0.9436 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1356 - val_ca4-[10.3,11.3): 0.9787 - val_ca4-[11.3,14.9): 0.7079\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5081 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3725 - ca2-[9.5,10.3): 0.5054 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5464 - ca3-[10.3,11.3): 0.7071 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5614 - ca4-[11.3,14.9): 0.6953 - val_ca1-[8.0,9.5): 0.5825 - val_ca1-[9.5,10.3): 0.4221 - val_ca1-[10.3,11.3): 0.9102 - val_ca1-[11.3,14.9): 1.5678 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8759 - val_ca2-[11.3,14.9): 1.4937 - val_ca3-[8.0,9.5): 0.8346 - val_ca3-[9.5,10.3): 0.5449 - val_ca3-[10.3,11.3): 0.7181 - val_ca3-[11.3,14.9): 0.9309 - val_ca4-[8.0,9.5): 1.5647 - val_ca4-[9.5,10.3): 1.1364 - val_ca4-[10.3,11.3): 0.9662 - val_ca4-[11.3,14.9): 0.6940\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5269 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3651 - ca2-[9.5,10.3): 0.5199 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5711 - ca3-[10.3,11.3): 0.7201 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5903 - ca4-[11.3,14.9): 0.6883 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9174 - val_ca1-[11.3,14.9): 1.5921 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8847 - val_ca2-[11.3,14.9): 1.5209 - val_ca3-[8.0,9.5): 0.8339 - val_ca3-[9.5,10.3): 0.5444 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9547 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9813 - val_ca4-[11.3,14.9): 0.7140\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5266 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3785 - ca2-[9.5,10.3): 0.5094 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5416 - ca3-[10.3,11.3): 0.7213 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5906 - ca4-[11.3,14.9): 0.6793 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9210 - val_ca1-[11.3,14.9): 1.6146 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8897 - val_ca2-[11.3,14.9): 1.5460 - val_ca3-[8.0,9.5): 0.8336 - val_ca3-[9.5,10.3): 0.5441 - val_ca3-[10.3,11.3): 0.7304 - val_ca3-[11.3,14.9): 0.9669 - val_ca4-[8.0,9.5): 1.5651 - val_ca4-[9.5,10.3): 1.1367 - val_ca4-[10.3,11.3): 0.9790 - val_ca4-[11.3,14.9): 0.7123\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3686 - ca2-[9.5,10.3): 0.5111 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5605 - ca3-[10.3,11.3): 0.7067 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5925 - ca4-[11.3,14.9): 0.7056 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.5701 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8843 - val_ca2-[11.3,14.9): 1.5052 - val_ca3-[8.0,9.5): 0.8334 - val_ca3-[9.5,10.3): 0.5440 - val_ca3-[10.3,11.3): 0.7216 - val_ca3-[11.3,14.9): 0.9306 - val_ca4-[8.0,9.5): 1.5643 - val_ca4-[9.5,10.3): 1.1361 - val_ca4-[10.3,11.3): 0.9667 - val_ca4-[11.3,14.9): 0.6833\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5257 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3693 - ca2-[9.5,10.3): 0.5084 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5331 - ca3-[10.3,11.3): 0.7194 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5669 - ca4-[11.3,14.9): 0.6970 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9200 - val_ca1-[11.3,14.9): 1.5727 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8902 - val_ca2-[11.3,14.9): 1.5085 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5437 - val_ca3-[10.3,11.3): 0.7328 - val_ca3-[11.3,14.9): 0.9440 - val_ca4-[8.0,9.5): 1.5641 - val_ca4-[9.5,10.3): 1.1359 - val_ca4-[10.3,11.3): 0.9841 - val_ca4-[11.3,14.9): 0.7079\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5246 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3832 - ca2-[9.5,10.3): 0.5191 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5453 - ca3-[10.3,11.3): 0.6958 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5494 - ca4-[11.3,14.9): 0.6783 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9135 - val_ca1-[11.3,14.9): 1.5749 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8839 - val_ca2-[11.3,14.9): 1.5110 - val_ca3-[8.0,9.5): 0.8334 - val_ca3-[9.5,10.3): 0.5439 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9472 - val_ca4-[8.0,9.5): 1.5646 - val_ca4-[9.5,10.3): 1.1363 - val_ca4-[10.3,11.3): 0.9836 - val_ca4-[11.3,14.9): 0.7125\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5010 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3769 - ca2-[9.5,10.3): 0.5273 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5328 - ca3-[10.3,11.3): 0.7246 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5440 - ca4-[11.3,14.9): 0.6835 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9116 - val_ca1-[11.3,14.9): 1.5867 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8812 - val_ca2-[11.3,14.9): 1.5198 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5437 - val_ca3-[10.3,11.3): 0.7266 - val_ca3-[11.3,14.9): 0.9461 - val_ca4-[8.0,9.5): 1.5645 - val_ca4-[9.5,10.3): 1.1362 - val_ca4-[10.3,11.3): 0.9809 - val_ca4-[11.3,14.9): 0.6979\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5220 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3843 - ca2-[9.5,10.3): 0.5148 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5450 - ca3-[10.3,11.3): 0.7309 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5679 - ca4-[11.3,14.9): 0.6820 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9134 - val_ca1-[11.3,14.9): 1.5793 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4164 - val_ca2-[10.3,11.3): 0.8824 - val_ca2-[11.3,14.9): 1.5118 - val_ca3-[8.0,9.5): 0.8333 - val_ca3-[9.5,10.3): 0.5437 - val_ca3-[10.3,11.3): 0.7288 - val_ca3-[11.3,14.9): 0.9473 - val_ca4-[8.0,9.5): 1.5649 - val_ca4-[9.5,10.3): 1.1365 - val_ca4-[10.3,11.3): 0.9837 - val_ca4-[11.3,14.9): 0.7086\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3866 - ca2-[9.5,10.3): 0.5276 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5475 - ca3-[10.3,11.3): 0.7026 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5986 - ca4-[11.3,14.9): 0.6846 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9199 - val_ca1-[11.3,14.9): 1.5743 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8889 - val_ca2-[11.3,14.9): 1.5083 - val_ca3-[8.0,9.5): 0.8330 - val_ca3-[9.5,10.3): 0.5434 - val_ca3-[10.3,11.3): 0.7299 - val_ca3-[11.3,14.9): 0.9446 - val_ca4-[8.0,9.5): 1.5655 - val_ca4-[9.5,10.3): 1.1370 - val_ca4-[10.3,11.3): 0.9791 - val_ca4-[11.3,14.9): 0.7068\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5029 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3826 - ca2-[9.5,10.3): 0.5109 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5626 - ca3-[10.3,11.3): 0.7178 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5545 - ca4-[11.3,14.9): 0.6801 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4222 - val_ca1-[10.3,11.3): 0.9174 - val_ca1-[11.3,14.9): 1.5936 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8873 - val_ca2-[11.3,14.9): 1.5286 - val_ca3-[8.0,9.5): 0.8328 - val_ca3-[9.5,10.3): 0.5423 - val_ca3-[10.3,11.3): 0.7300 - val_ca3-[11.3,14.9): 0.9586 - val_ca4-[8.0,9.5): 1.5657 - val_ca4-[9.5,10.3): 1.1346 - val_ca4-[10.3,11.3): 0.9822 - val_ca4-[11.3,14.9): 0.7146\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5213 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3873 - ca2-[9.5,10.3): 0.5260 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5385 - ca3-[10.3,11.3): 0.7143 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5834 - ca4-[11.3,14.9): 0.6938 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9107 - val_ca1-[11.3,14.9): 1.5456 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4164 - val_ca2-[10.3,11.3): 0.8813 - val_ca2-[11.3,14.9): 1.4822 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5427 - val_ca3-[10.3,11.3): 0.7260 - val_ca3-[11.3,14.9): 0.9133 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9818 - val_ca4-[11.3,14.9): 0.6707\n",
      "Epoch 129/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5314 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3811 - ca2-[9.5,10.3): 0.5318 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5367 - ca3-[10.3,11.3): 0.7028 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5709 - ca4-[11.3,14.9): 0.6999 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9111 - val_ca1-[11.3,14.9): 1.5641 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8811 - val_ca2-[11.3,14.9): 1.5005 - val_ca3-[8.0,9.5): 0.8314 - val_ca3-[9.5,10.3): 0.5419 - val_ca3-[10.3,11.3): 0.7184 - val_ca3-[11.3,14.9): 0.9325 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9651 - val_ca4-[11.3,14.9): 0.6899\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5132 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3747 - ca2-[9.5,10.3): 0.5219 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5210 - ca3-[10.3,11.3): 0.7100 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5278 - ca4-[11.3,14.9): 0.6843 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9167 - val_ca1-[11.3,14.9): 1.5856 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4162 - val_ca2-[10.3,11.3): 0.8869 - val_ca2-[11.3,14.9): 1.5215 - val_ca3-[8.0,9.5): 0.8303 - val_ca3-[9.5,10.3): 0.5411 - val_ca3-[10.3,11.3): 0.7294 - val_ca3-[11.3,14.9): 0.9534 - val_ca4-[8.0,9.5): 1.5667 - val_ca4-[9.5,10.3): 1.1381 - val_ca4-[10.3,11.3): 0.9827 - val_ca4-[11.3,14.9): 0.7082\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5245 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3777 - ca2-[9.5,10.3): 0.5206 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5653 - ca3-[10.3,11.3): 0.7201 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5429 - ca4-[11.3,14.9): 0.7106 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9101 - val_ca1-[11.3,14.9): 1.5831 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4161 - val_ca2-[10.3,11.3): 0.8802 - val_ca2-[11.3,14.9): 1.5183 - val_ca3-[8.0,9.5): 0.8302 - val_ca3-[9.5,10.3): 0.5410 - val_ca3-[10.3,11.3): 0.7255 - val_ca3-[11.3,14.9): 0.9526 - val_ca4-[8.0,9.5): 1.5670 - val_ca4-[9.5,10.3): 1.1383 - val_ca4-[10.3,11.3): 0.9821 - val_ca4-[11.3,14.9): 0.7093\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5247 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3849 - ca2-[9.5,10.3): 0.5092 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5139 - ca3-[10.3,11.3): 0.6999 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5708 - ca4-[11.3,14.9): 0.6960 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9166 - val_ca1-[11.3,14.9): 1.5426 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8862 - val_ca2-[11.3,14.9): 1.4787 - val_ca3-[8.0,9.5): 0.8296 - val_ca3-[9.5,10.3): 0.5405 - val_ca3-[10.3,11.3): 0.7292 - val_ca3-[11.3,14.9): 0.9296 - val_ca4-[8.0,9.5): 1.5678 - val_ca4-[9.5,10.3): 1.1390 - val_ca4-[10.3,11.3): 0.9832 - val_ca4-[11.3,14.9): 0.7049\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5198 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3655 - ca2-[9.5,10.3): 0.5104 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5525 - ca3-[10.3,11.3): 0.7172 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5346 - ca4-[11.3,14.9): 0.6835 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5978 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8836 - val_ca2-[11.3,14.9): 1.5325 - val_ca3-[8.0,9.5): 0.8293 - val_ca3-[9.5,10.3): 0.5402 - val_ca3-[10.3,11.3): 0.7299 - val_ca3-[11.3,14.9): 0.9642 - val_ca4-[8.0,9.5): 1.5681 - val_ca4-[9.5,10.3): 1.1392 - val_ca4-[10.3,11.3): 0.9879 - val_ca4-[11.3,14.9): 0.7153\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5227 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3696 - ca2-[9.5,10.3): 0.5121 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5687 - ca3-[10.3,11.3): 0.7234 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5629 - ca4-[11.3,14.9): 0.6915 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.5958 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8848 - val_ca2-[11.3,14.9): 1.5323 - val_ca3-[8.0,9.5): 0.8301 - val_ca3-[9.5,10.3): 0.5407 - val_ca3-[10.3,11.3): 0.7268 - val_ca3-[11.3,14.9): 0.9625 - val_ca4-[8.0,9.5): 1.5678 - val_ca4-[9.5,10.3): 1.1390 - val_ca4-[10.3,11.3): 0.9806 - val_ca4-[11.3,14.9): 0.7164\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5273 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3684 - ca2-[9.5,10.3): 0.5168 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5265 - ca3-[10.3,11.3): 0.7178 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6045 - ca4-[11.3,14.9): 0.6907 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9119 - val_ca1-[11.3,14.9): 1.5589 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8828 - val_ca2-[11.3,14.9): 1.4971 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5414 - val_ca3-[10.3,11.3): 0.7275 - val_ca3-[11.3,14.9): 0.9317 - val_ca4-[8.0,9.5): 1.5681 - val_ca4-[9.5,10.3): 1.1392 - val_ca4-[10.3,11.3): 0.9852 - val_ca4-[11.3,14.9): 0.6938\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5108 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3905 - ca2-[9.5,10.3): 0.5091 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5435 - ca3-[10.3,11.3): 0.7299 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5414 - ca4-[11.3,14.9): 0.6832 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9028 - val_ca1-[11.3,14.9): 1.5611 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8739 - val_ca2-[11.3,14.9): 1.4991 - val_ca3-[8.0,9.5): 0.8312 - val_ca3-[9.5,10.3): 0.5414 - val_ca3-[10.3,11.3): 0.7244 - val_ca3-[11.3,14.9): 0.9397 - val_ca4-[8.0,9.5): 1.5685 - val_ca4-[9.5,10.3): 1.1395 - val_ca4-[10.3,11.3): 0.9893 - val_ca4-[11.3,14.9): 0.7098\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5221 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3755 - ca2-[9.5,10.3): 0.5201 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5414 - ca3-[10.3,11.3): 0.7288 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5481 - ca4-[11.3,14.9): 0.6994 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.5530 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4159 - val_ca2-[10.3,11.3): 0.8866 - val_ca2-[11.3,14.9): 1.4894 - val_ca3-[8.0,9.5): 0.8318 - val_ca3-[9.5,10.3): 0.5418 - val_ca3-[10.3,11.3): 0.7289 - val_ca3-[11.3,14.9): 0.9319 - val_ca4-[8.0,9.5): 1.5687 - val_ca4-[9.5,10.3): 1.1397 - val_ca4-[10.3,11.3): 0.9836 - val_ca4-[11.3,14.9): 0.7045\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5140 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3780 - ca2-[9.5,10.3): 0.5177 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5530 - ca3-[10.3,11.3): 0.7186 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5735 - ca4-[11.3,14.9): 0.6907 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9134 - val_ca1-[11.3,14.9): 1.5742 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4158 - val_ca2-[10.3,11.3): 0.8818 - val_ca2-[11.3,14.9): 1.5077 - val_ca3-[8.0,9.5): 0.8309 - val_ca3-[9.5,10.3): 0.5411 - val_ca3-[10.3,11.3): 0.7198 - val_ca3-[11.3,14.9): 0.9365 - val_ca4-[8.0,9.5): 1.5686 - val_ca4-[9.5,10.3): 1.1397 - val_ca4-[10.3,11.3): 0.9687 - val_ca4-[11.3,14.9): 0.6895\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5245 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3593 - ca2-[9.5,10.3): 0.5187 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5453 - ca3-[10.3,11.3): 0.7090 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5841 - ca4-[11.3,14.9): 0.6914 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9126 - val_ca1-[11.3,14.9): 1.5934 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4156 - val_ca2-[10.3,11.3): 0.8809 - val_ca2-[11.3,14.9): 1.5252 - val_ca3-[8.0,9.5): 0.8305 - val_ca3-[9.5,10.3): 0.5408 - val_ca3-[10.3,11.3): 0.7272 - val_ca3-[11.3,14.9): 0.9560 - val_ca4-[8.0,9.5): 1.5678 - val_ca4-[9.5,10.3): 1.1389 - val_ca4-[10.3,11.3): 0.9850 - val_ca4-[11.3,14.9): 0.7088\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5029 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3919 - ca2-[9.5,10.3): 0.5188 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5804 - ca3-[10.3,11.3): 0.7174 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5742 - ca4-[11.3,14.9): 0.6855 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9107 - val_ca1-[11.3,14.9): 1.5779 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4155 - val_ca2-[10.3,11.3): 0.8782 - val_ca2-[11.3,14.9): 1.5087 - val_ca3-[8.0,9.5): 0.8302 - val_ca3-[9.5,10.3): 0.5405 - val_ca3-[10.3,11.3): 0.7248 - val_ca3-[11.3,14.9): 0.9453 - val_ca4-[8.0,9.5): 1.5677 - val_ca4-[9.5,10.3): 1.1389 - val_ca4-[10.3,11.3): 0.9824 - val_ca4-[11.3,14.9): 0.7027\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.4991 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3765 - ca2-[9.5,10.3): 0.5150 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5542 - ca3-[10.3,11.3): 0.7103 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5160 - ca4-[11.3,14.9): 0.6868 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9175 - val_ca1-[11.3,14.9): 1.5802 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4154 - val_ca2-[10.3,11.3): 0.8842 - val_ca2-[11.3,14.9): 1.5103 - val_ca3-[8.0,9.5): 0.8303 - val_ca3-[9.5,10.3): 0.5405 - val_ca3-[10.3,11.3): 0.7260 - val_ca3-[11.3,14.9): 0.9481 - val_ca4-[8.0,9.5): 1.5673 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9773 - val_ca4-[11.3,14.9): 0.7073\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5126 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3876 - ca2-[9.5,10.3): 0.5159 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5636 - ca3-[10.3,11.3): 0.7228 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5767 - ca4-[11.3,14.9): 0.6939 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9153 - val_ca1-[11.3,14.9): 1.5714 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4153 - val_ca2-[10.3,11.3): 0.8818 - val_ca2-[11.3,14.9): 1.5006 - val_ca3-[8.0,9.5): 0.8295 - val_ca3-[9.5,10.3): 0.5399 - val_ca3-[10.3,11.3): 0.7261 - val_ca3-[11.3,14.9): 0.9389 - val_ca4-[8.0,9.5): 1.5662 - val_ca4-[9.5,10.3): 1.1375 - val_ca4-[10.3,11.3): 0.9796 - val_ca4-[11.3,14.9): 0.6962\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5131 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3573 - ca2-[9.5,10.3): 0.4988 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5248 - ca3-[10.3,11.3): 0.7186 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5665 - ca4-[11.3,14.9): 0.6936 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9210 - val_ca1-[11.3,14.9): 1.5710 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4153 - val_ca2-[10.3,11.3): 0.8884 - val_ca2-[11.3,14.9): 1.5025 - val_ca3-[8.0,9.5): 0.8299 - val_ca3-[9.5,10.3): 0.5401 - val_ca3-[10.3,11.3): 0.7328 - val_ca3-[11.3,14.9): 0.9386 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1373 - val_ca4-[10.3,11.3): 0.9874 - val_ca4-[11.3,14.9): 0.6962\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5203 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3776 - ca2-[9.5,10.3): 0.5204 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5427 - ca3-[10.3,11.3): 0.7299 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5833 - ca4-[11.3,14.9): 0.7006 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9152 - val_ca1-[11.3,14.9): 1.5572 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4152 - val_ca2-[10.3,11.3): 0.8819 - val_ca2-[11.3,14.9): 1.4883 - val_ca3-[8.0,9.5): 0.8314 - val_ca3-[9.5,10.3): 0.5412 - val_ca3-[10.3,11.3): 0.7260 - val_ca3-[11.3,14.9): 0.9344 - val_ca4-[8.0,9.5): 1.5656 - val_ca4-[9.5,10.3): 1.1370 - val_ca4-[10.3,11.3): 0.9793 - val_ca4-[11.3,14.9): 0.7062\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5288 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3754 - ca2-[9.5,10.3): 0.5276 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5702 - ca3-[10.3,11.3): 0.7200 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5562 - ca4-[11.3,14.9): 0.7124 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9149 - val_ca1-[11.3,14.9): 1.5902 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4151 - val_ca2-[10.3,11.3): 0.8815 - val_ca2-[11.3,14.9): 1.5198 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5417 - val_ca3-[10.3,11.3): 0.7259 - val_ca3-[11.3,14.9): 0.9527 - val_ca4-[8.0,9.5): 1.5657 - val_ca4-[9.5,10.3): 1.1371 - val_ca4-[10.3,11.3): 0.9793 - val_ca4-[11.3,14.9): 0.7098\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5112 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3808 - ca2-[9.5,10.3): 0.5179 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5510 - ca3-[10.3,11.3): 0.7088 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5700 - ca4-[11.3,14.9): 0.6879 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9093 - val_ca1-[11.3,14.9): 1.5986 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4151 - val_ca2-[10.3,11.3): 0.8769 - val_ca2-[11.3,14.9): 1.5294 - val_ca3-[8.0,9.5): 0.8327 - val_ca3-[9.5,10.3): 0.5420 - val_ca3-[10.3,11.3): 0.7274 - val_ca3-[11.3,14.9): 0.9595 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1372 - val_ca4-[10.3,11.3): 0.9885 - val_ca4-[11.3,14.9): 0.7152\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5076 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3747 - ca2-[9.5,10.3): 0.5152 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5451 - ca3-[10.3,11.3): 0.7107 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5739 - ca4-[11.3,14.9): 0.6992 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9165 - val_ca1-[11.3,14.9): 1.5802 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4155 - val_ca2-[10.3,11.3): 0.8835 - val_ca2-[11.3,14.9): 1.5126 - val_ca3-[8.0,9.5): 0.8321 - val_ca3-[9.5,10.3): 0.5432 - val_ca3-[10.3,11.3): 0.7254 - val_ca3-[11.3,14.9): 0.9494 - val_ca4-[8.0,9.5): 1.5672 - val_ca4-[9.5,10.3): 1.1416 - val_ca4-[10.3,11.3): 0.9771 - val_ca4-[11.3,14.9): 0.7119\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3684 - ca2-[9.5,10.3): 0.5133 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5410 - ca3-[10.3,11.3): 0.7203 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5791 - ca4-[11.3,14.9): 0.6809 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9143 - val_ca1-[11.3,14.9): 1.5821 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.4149 - val_ca2-[10.3,11.3): 0.8815 - val_ca2-[11.3,14.9): 1.5139 - val_ca3-[8.0,9.5): 0.8316 - val_ca3-[9.5,10.3): 0.5410 - val_ca3-[10.3,11.3): 0.7255 - val_ca3-[11.3,14.9): 0.9491 - val_ca4-[8.0,9.5): 1.5674 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9801 - val_ca4-[11.3,14.9): 0.7090\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5021 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3881 - ca2-[9.5,10.3): 0.5192 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5510 - ca3-[10.3,11.3): 0.7055 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5461 - ca4-[11.3,14.9): 0.6858 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.8959 - val_ca1-[11.3,14.9): 1.5484 - val_ca2-[8.0,9.5): 0.5876 - val_ca2-[9.5,10.3): 0.4148 - val_ca2-[10.3,11.3): 0.8642 - val_ca2-[11.3,14.9): 1.4821 - val_ca3-[8.0,9.5): 0.8317 - val_ca3-[9.5,10.3): 0.5409 - val_ca3-[10.3,11.3): 0.7194 - val_ca3-[11.3,14.9): 0.9324 - val_ca4-[8.0,9.5): 1.5674 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9878 - val_ca4-[11.3,14.9): 0.7111\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5110 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3589 - ca2-[9.5,10.3): 0.5199 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5297 - ca3-[10.3,11.3): 0.7335 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5328 - ca4-[11.3,14.9): 0.6779 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9142 - val_ca1-[11.3,14.9): 1.5559 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.4149 - val_ca2-[10.3,11.3): 0.8823 - val_ca2-[11.3,14.9): 1.4904 - val_ca3-[8.0,9.5): 0.8322 - val_ca3-[9.5,10.3): 0.5412 - val_ca3-[10.3,11.3): 0.7253 - val_ca3-[11.3,14.9): 0.9249 - val_ca4-[8.0,9.5): 1.5678 - val_ca4-[9.5,10.3): 1.1388 - val_ca4-[10.3,11.3): 0.9803 - val_ca4-[11.3,14.9): 0.6889\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5207 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3808 - ca2-[9.5,10.3): 0.5118 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5738 - ca3-[10.3,11.3): 0.7101 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5745 - ca4-[11.3,14.9): 0.6926 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9162 - val_ca1-[11.3,14.9): 1.5756 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.4147 - val_ca2-[10.3,11.3): 0.8840 - val_ca2-[11.3,14.9): 1.5098 - val_ca3-[8.0,9.5): 0.8321 - val_ca3-[9.5,10.3): 0.5411 - val_ca3-[10.3,11.3): 0.7274 - val_ca3-[11.3,14.9): 0.9420 - val_ca4-[8.0,9.5): 1.5684 - val_ca4-[9.5,10.3): 1.1393 - val_ca4-[10.3,11.3): 0.9832 - val_ca4-[11.3,14.9): 0.7025\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5084 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3947 - ca2-[9.5,10.3): 0.5156 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5519 - ca3-[10.3,11.3): 0.7198 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5926 - ca4-[11.3,14.9): 0.6717 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9203 - val_ca1-[11.3,14.9): 1.5890 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.4145 - val_ca2-[10.3,11.3): 0.8869 - val_ca2-[11.3,14.9): 1.5204 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5417 - val_ca3-[10.3,11.3): 0.7319 - val_ca3-[11.3,14.9): 0.9511 - val_ca4-[8.0,9.5): 1.5675 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9880 - val_ca4-[11.3,14.9): 0.7097\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5237 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3841 - ca2-[9.5,10.3): 0.5169 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5441 - ca3-[10.3,11.3): 0.7039 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5703 - ca4-[11.3,14.9): 0.6991 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9162 - val_ca1-[11.3,14.9): 1.5751 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.4144 - val_ca2-[10.3,11.3): 0.8830 - val_ca2-[11.3,14.9): 1.5079 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5417 - val_ca3-[10.3,11.3): 0.7273 - val_ca3-[11.3,14.9): 0.9460 - val_ca4-[8.0,9.5): 1.5667 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9823 - val_ca4-[11.3,14.9): 0.7139\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5253 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3844 - ca2-[9.5,10.3): 0.5172 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5418 - ca3-[10.3,11.3): 0.7076 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5663 - ca4-[11.3,14.9): 0.6904 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5962 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.4148 - val_ca2-[10.3,11.3): 0.8822 - val_ca2-[11.3,14.9): 1.5275 - val_ca3-[8.0,9.5): 0.8338 - val_ca3-[9.5,10.3): 0.5411 - val_ca3-[10.3,11.3): 0.7251 - val_ca3-[11.3,14.9): 0.9556 - val_ca4-[8.0,9.5): 1.5663 - val_ca4-[9.5,10.3): 1.1348 - val_ca4-[10.3,11.3): 0.9780 - val_ca4-[11.3,14.9): 0.7121\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5206 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3680 - ca2-[9.5,10.3): 0.5237 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5593 - ca3-[10.3,11.3): 0.7188 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5344 - ca4-[11.3,14.9): 0.6912 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9144 - val_ca1-[11.3,14.9): 1.5502 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.4142 - val_ca2-[10.3,11.3): 0.8805 - val_ca2-[11.3,14.9): 1.4814 - val_ca3-[8.0,9.5): 0.8329 - val_ca3-[9.5,10.3): 0.5413 - val_ca3-[10.3,11.3): 0.7247 - val_ca3-[11.3,14.9): 0.9146 - val_ca4-[8.0,9.5): 1.5660 - val_ca4-[9.5,10.3): 1.1372 - val_ca4-[10.3,11.3): 0.9793 - val_ca4-[11.3,14.9): 0.6766\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5299 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3730 - ca2-[9.5,10.3): 0.5138 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5376 - ca3-[10.3,11.3): 0.6936 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5648 - ca4-[11.3,14.9): 0.6877 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9147 - val_ca1-[11.3,14.9): 1.5836 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.4140 - val_ca2-[10.3,11.3): 0.8795 - val_ca2-[11.3,14.9): 1.5118 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5408 - val_ca3-[10.3,11.3): 0.7245 - val_ca3-[11.3,14.9): 0.9426 - val_ca4-[8.0,9.5): 1.5667 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9796 - val_ca4-[11.3,14.9): 0.6975\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5151 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3670 - ca2-[9.5,10.3): 0.5195 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5470 - ca3-[10.3,11.3): 0.7258 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5575 - ca4-[11.3,14.9): 0.6797 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9101 - val_ca1-[11.3,14.9): 1.5968 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.4137 - val_ca2-[10.3,11.3): 0.8741 - val_ca2-[11.3,14.9): 1.5225 - val_ca3-[8.0,9.5): 0.8321 - val_ca3-[9.5,10.3): 0.5405 - val_ca3-[10.3,11.3): 0.7229 - val_ca3-[11.3,14.9): 0.9529 - val_ca4-[8.0,9.5): 1.5670 - val_ca4-[9.5,10.3): 1.1380 - val_ca4-[10.3,11.3): 0.9816 - val_ca4-[11.3,14.9): 0.7046\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5097 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3763 - ca2-[9.5,10.3): 0.4971 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5405 - ca3-[10.3,11.3): 0.7201 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5794 - ca4-[11.3,14.9): 0.7002 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9167 - val_ca1-[11.3,14.9): 1.5765 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.4136 - val_ca2-[10.3,11.3): 0.8805 - val_ca2-[11.3,14.9): 1.5040 - val_ca3-[8.0,9.5): 0.8315 - val_ca3-[9.5,10.3): 0.5399 - val_ca3-[10.3,11.3): 0.7264 - val_ca3-[11.3,14.9): 0.9443 - val_ca4-[8.0,9.5): 1.5673 - val_ca4-[9.5,10.3): 1.1382 - val_ca4-[10.3,11.3): 0.9824 - val_ca4-[11.3,14.9): 0.7081\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5236 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3594 - ca2-[9.5,10.3): 0.5010 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5586 - ca3-[10.3,11.3): 0.7066 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5528 - ca4-[11.3,14.9): 0.6899 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9180 - val_ca1-[11.3,14.9): 1.5850 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.4136 - val_ca2-[10.3,11.3): 0.8834 - val_ca2-[11.3,14.9): 1.5157 - val_ca3-[8.0,9.5): 0.8306 - val_ca3-[9.5,10.3): 0.5391 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9499 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1375 - val_ca4-[10.3,11.3): 0.9862 - val_ca4-[11.3,14.9): 0.7077\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5073 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3590 - ca2-[9.5,10.3): 0.5176 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5311 - ca3-[10.3,11.3): 0.7052 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5897 - ca4-[11.3,14.9): 0.6913 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9143 - val_ca1-[11.3,14.9): 1.5755 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.4135 - val_ca2-[10.3,11.3): 0.8799 - val_ca2-[11.3,14.9): 1.5079 - val_ca3-[8.0,9.5): 0.8306 - val_ca3-[9.5,10.3): 0.5390 - val_ca3-[10.3,11.3): 0.7238 - val_ca3-[11.3,14.9): 0.9451 - val_ca4-[8.0,9.5): 1.5661 - val_ca4-[9.5,10.3): 1.1372 - val_ca4-[10.3,11.3): 0.9792 - val_ca4-[11.3,14.9): 0.7081\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5216 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3811 - ca2-[9.5,10.3): 0.5163 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5303 - ca3-[10.3,11.3): 0.7092 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5668 - ca4-[11.3,14.9): 0.6940 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9160 - val_ca1-[11.3,14.9): 1.5911 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.4134 - val_ca2-[10.3,11.3): 0.8817 - val_ca2-[11.3,14.9): 1.5229 - val_ca3-[8.0,9.5): 0.8298 - val_ca3-[9.5,10.3): 0.5382 - val_ca3-[10.3,11.3): 0.7258 - val_ca3-[11.3,14.9): 0.9515 - val_ca4-[8.0,9.5): 1.5670 - val_ca4-[9.5,10.3): 1.1379 - val_ca4-[10.3,11.3): 0.9822 - val_ca4-[11.3,14.9): 0.7027\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5227 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3682 - ca2-[9.5,10.3): 0.5193 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5438 - ca3-[10.3,11.3): 0.7093 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5897 - ca4-[11.3,14.9): 0.7103 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.8922 - val_ca1-[11.3,14.9): 1.5889 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.4132 - val_ca2-[10.3,11.3): 0.8582 - val_ca2-[11.3,14.9): 1.5197 - val_ca3-[8.0,9.5): 0.8281 - val_ca3-[9.5,10.3): 0.5366 - val_ca3-[10.3,11.3): 0.7100 - val_ca3-[11.3,14.9): 0.9521 - val_ca4-[8.0,9.5): 1.5681 - val_ca4-[9.5,10.3): 1.1389 - val_ca4-[10.3,11.3): 0.9770 - val_ca4-[11.3,14.9): 0.7038\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5166 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3588 - ca2-[9.5,10.3): 0.5173 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5315 - ca3-[10.3,11.3): 0.7307 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5750 - ca4-[11.3,14.9): 0.6989 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5736 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.4130 - val_ca2-[10.3,11.3): 0.8808 - val_ca2-[11.3,14.9): 1.5057 - val_ca3-[8.0,9.5): 0.8289 - val_ca3-[9.5,10.3): 0.5370 - val_ca3-[10.3,11.3): 0.7280 - val_ca3-[11.3,14.9): 0.9438 - val_ca4-[8.0,9.5): 1.5686 - val_ca4-[9.5,10.3): 1.1392 - val_ca4-[10.3,11.3): 0.9902 - val_ca4-[11.3,14.9): 0.7051\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5167 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3734 - ca2-[9.5,10.3): 0.5062 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5257 - ca3-[10.3,11.3): 0.7075 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5719 - ca4-[11.3,14.9): 0.7036 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9180 - val_ca1-[11.3,14.9): 1.5976 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.4127 - val_ca2-[10.3,11.3): 0.8820 - val_ca2-[11.3,14.9): 1.5269 - val_ca3-[8.0,9.5): 0.8286 - val_ca3-[9.5,10.3): 0.5365 - val_ca3-[10.3,11.3): 0.7268 - val_ca3-[11.3,14.9): 0.9587 - val_ca4-[8.0,9.5): 1.5692 - val_ca4-[9.5,10.3): 1.1397 - val_ca4-[10.3,11.3): 0.9859 - val_ca4-[11.3,14.9): 0.7092\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5231 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3637 - ca2-[9.5,10.3): 0.5072 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5600 - ca3-[10.3,11.3): 0.6994 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5645 - ca4-[11.3,14.9): 0.6879 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5713 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.4126 - val_ca2-[10.3,11.3): 0.8806 - val_ca2-[11.3,14.9): 1.5028 - val_ca3-[8.0,9.5): 0.8276 - val_ca3-[9.5,10.3): 0.5355 - val_ca3-[10.3,11.3): 0.7218 - val_ca3-[11.3,14.9): 0.9361 - val_ca4-[8.0,9.5): 1.5697 - val_ca4-[9.5,10.3): 1.1401 - val_ca4-[10.3,11.3): 0.9779 - val_ca4-[11.3,14.9): 0.6890\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5210 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3761 - ca2-[9.5,10.3): 0.5074 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5224 - ca3-[10.3,11.3): 0.7232 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5884 - ca4-[11.3,14.9): 0.7019 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9172 - val_ca1-[11.3,14.9): 1.5931 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.4123 - val_ca2-[10.3,11.3): 0.8814 - val_ca2-[11.3,14.9): 1.5234 - val_ca3-[8.0,9.5): 0.8265 - val_ca3-[9.5,10.3): 0.5344 - val_ca3-[10.3,11.3): 0.7267 - val_ca3-[11.3,14.9): 0.9522 - val_ca4-[8.0,9.5): 1.5696 - val_ca4-[9.5,10.3): 1.1400 - val_ca4-[10.3,11.3): 0.9877 - val_ca4-[11.3,14.9): 0.6957\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3678 - ca2-[9.5,10.3): 0.5137 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5349 - ca3-[10.3,11.3): 0.7283 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5630 - ca4-[11.3,14.9): 0.6808 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9160 - val_ca1-[11.3,14.9): 1.5707 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.4121 - val_ca2-[10.3,11.3): 0.8789 - val_ca2-[11.3,14.9): 1.4989 - val_ca3-[8.0,9.5): 0.8268 - val_ca3-[9.5,10.3): 0.5342 - val_ca3-[10.3,11.3): 0.7235 - val_ca3-[11.3,14.9): 0.9437 - val_ca4-[8.0,9.5): 1.5694 - val_ca4-[9.5,10.3): 1.1398 - val_ca4-[10.3,11.3): 0.9833 - val_ca4-[11.3,14.9): 0.7061\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5187 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3797 - ca2-[9.5,10.3): 0.5191 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5412 - ca3-[10.3,11.3): 0.7187 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5939 - ca4-[11.3,14.9): 0.6807 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9117 - val_ca1-[11.3,14.9): 1.5648 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.4125 - val_ca2-[10.3,11.3): 0.8751 - val_ca2-[11.3,14.9): 1.4955 - val_ca3-[8.0,9.5): 0.8292 - val_ca3-[9.5,10.3): 0.5373 - val_ca3-[10.3,11.3): 0.7218 - val_ca3-[11.3,14.9): 0.9384 - val_ca4-[8.0,9.5): 1.5696 - val_ca4-[9.5,10.3): 1.1432 - val_ca4-[10.3,11.3): 0.9853 - val_ca4-[11.3,14.9): 0.7054\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5162 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3563 - ca2-[9.5,10.3): 0.4992 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5238 - ca3-[10.3,11.3): 0.7026 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5702 - ca4-[11.3,14.9): 0.6821 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9101 - val_ca1-[11.3,14.9): 1.5634 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.4116 - val_ca2-[10.3,11.3): 0.8722 - val_ca2-[11.3,14.9): 1.4903 - val_ca3-[8.0,9.5): 0.8287 - val_ca3-[9.5,10.3): 0.5348 - val_ca3-[10.3,11.3): 0.7189 - val_ca3-[11.3,14.9): 0.9318 - val_ca4-[8.0,9.5): 1.5704 - val_ca4-[9.5,10.3): 1.1406 - val_ca4-[10.3,11.3): 0.9831 - val_ca4-[11.3,14.9): 0.6949\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5107 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3629 - ca2-[9.5,10.3): 0.5066 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5313 - ca3-[10.3,11.3): 0.7230 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5817 - ca4-[11.3,14.9): 0.7005 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9210 - val_ca1-[11.3,14.9): 1.6039 - val_ca2-[8.0,9.5): 0.5852 - val_ca2-[9.5,10.3): 0.4114 - val_ca2-[10.3,11.3): 0.8822 - val_ca2-[11.3,14.9): 1.5287 - val_ca3-[8.0,9.5): 0.8282 - val_ca3-[9.5,10.3): 0.5340 - val_ca3-[10.3,11.3): 0.7242 - val_ca3-[11.3,14.9): 0.9578 - val_ca4-[8.0,9.5): 1.5695 - val_ca4-[9.5,10.3): 1.1398 - val_ca4-[10.3,11.3): 0.9829 - val_ca4-[11.3,14.9): 0.7049\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5160 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3732 - ca2-[9.5,10.3): 0.5099 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5476 - ca3-[10.3,11.3): 0.7052 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5022 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5896 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.4111 - val_ca2-[10.3,11.3): 0.8774 - val_ca2-[11.3,14.9): 1.5140 - val_ca3-[8.0,9.5): 0.8287 - val_ca3-[9.5,10.3): 0.5339 - val_ca3-[10.3,11.3): 0.7214 - val_ca3-[11.3,14.9): 0.9565 - val_ca4-[8.0,9.5): 1.5698 - val_ca4-[9.5,10.3): 1.1400 - val_ca4-[10.3,11.3): 0.9834 - val_ca4-[11.3,14.9): 0.7206\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5285 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3579 - ca2-[9.5,10.3): 0.5110 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5384 - ca3-[10.3,11.3): 0.7294 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5655 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9110 - val_ca1-[11.3,14.9): 1.5768 - val_ca2-[8.0,9.5): 0.5846 - val_ca2-[9.5,10.3): 0.4109 - val_ca2-[10.3,11.3): 0.8721 - val_ca2-[11.3,14.9): 1.5034 - val_ca3-[8.0,9.5): 0.8273 - val_ca3-[9.5,10.3): 0.5323 - val_ca3-[10.3,11.3): 0.7099 - val_ca3-[11.3,14.9): 0.9425 - val_ca4-[8.0,9.5): 1.5693 - val_ca4-[9.5,10.3): 1.1396 - val_ca4-[10.3,11.3): 0.9658 - val_ca4-[11.3,14.9): 0.7020\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5263 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3547 - ca2-[9.5,10.3): 0.5045 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5444 - ca3-[10.3,11.3): 0.7203 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5627 - ca4-[11.3,14.9): 0.6908 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9103 - val_ca1-[11.3,14.9): 1.5730 - val_ca2-[8.0,9.5): 0.5842 - val_ca2-[9.5,10.3): 0.4106 - val_ca2-[10.3,11.3): 0.8712 - val_ca2-[11.3,14.9): 1.4981 - val_ca3-[8.0,9.5): 0.8273 - val_ca3-[9.5,10.3): 0.5317 - val_ca3-[10.3,11.3): 0.7158 - val_ca3-[11.3,14.9): 0.9380 - val_ca4-[8.0,9.5): 1.5694 - val_ca4-[9.5,10.3): 1.1396 - val_ca4-[10.3,11.3): 0.9824 - val_ca4-[11.3,14.9): 0.7002\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5052 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3772 - ca2-[9.5,10.3): 0.5084 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5193 - ca3-[10.3,11.3): 0.7187 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5425 - ca4-[11.3,14.9): 0.6953 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9069 - val_ca1-[11.3,14.9): 1.5856 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.4101 - val_ca2-[10.3,11.3): 0.8665 - val_ca2-[11.3,14.9): 1.5074 - val_ca3-[8.0,9.5): 0.8270 - val_ca3-[9.5,10.3): 0.5309 - val_ca3-[10.3,11.3): 0.7069 - val_ca3-[11.3,14.9): 0.9349 - val_ca4-[8.0,9.5): 1.5690 - val_ca4-[9.5,10.3): 1.1393 - val_ca4-[10.3,11.3): 0.9674 - val_ca4-[11.3,14.9): 0.6797\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5232 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3717 - ca2-[9.5,10.3): 0.5157 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5612 - ca3-[10.3,11.3): 0.7211 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5939 - ca4-[11.3,14.9): 0.6868 - val_ca1-[8.0,9.5): 0.5838 - val_ca1-[9.5,10.3): 0.4226 - val_ca1-[10.3,11.3): 0.9213 - val_ca1-[11.3,14.9): 1.5981 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.4109 - val_ca2-[10.3,11.3): 0.8789 - val_ca2-[11.3,14.9): 1.5184 - val_ca3-[8.0,9.5): 0.8279 - val_ca3-[9.5,10.3): 0.5303 - val_ca3-[10.3,11.3): 0.7202 - val_ca3-[11.3,14.9): 0.9582 - val_ca4-[8.0,9.5): 1.5726 - val_ca4-[9.5,10.3): 1.1394 - val_ca4-[10.3,11.3): 0.9822 - val_ca4-[11.3,14.9): 0.7116\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5157 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3633 - ca2-[9.5,10.3): 0.5122 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5346 - ca3-[10.3,11.3): 0.7027 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5874 - ca4-[11.3,14.9): 0.6973 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4149 - val_ca1-[10.3,11.3): 0.8883 - val_ca1-[11.3,14.9): 1.5830 - val_ca2-[8.0,9.5): 0.5834 - val_ca2-[9.5,10.3): 0.4028 - val_ca2-[10.3,11.3): 0.8480 - val_ca2-[11.3,14.9): 1.5067 - val_ca3-[8.0,9.5): 0.8261 - val_ca3-[9.5,10.3): 0.5263 - val_ca3-[10.3,11.3): 0.7002 - val_ca3-[11.3,14.9): 0.9387 - val_ca4-[8.0,9.5): 1.5677 - val_ca4-[9.5,10.3): 1.1407 - val_ca4-[10.3,11.3): 0.9783 - val_ca4-[11.3,14.9): 0.6885\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5147 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3645 - ca2-[9.5,10.3): 0.5025 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5267 - ca3-[10.3,11.3): 0.6983 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5633 - ca4-[11.3,14.9): 0.6750 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9125 - val_ca1-[11.3,14.9): 1.5572 - val_ca2-[8.0,9.5): 0.5826 - val_ca2-[9.5,10.3): 0.4089 - val_ca2-[10.3,11.3): 0.8723 - val_ca2-[11.3,14.9): 1.4846 - val_ca3-[8.0,9.5): 0.8270 - val_ca3-[9.5,10.3): 0.5289 - val_ca3-[10.3,11.3): 0.7146 - val_ca3-[11.3,14.9): 0.9296 - val_ca4-[8.0,9.5): 1.5665 - val_ca4-[9.5,10.3): 1.1371 - val_ca4-[10.3,11.3): 0.9835 - val_ca4-[11.3,14.9): 0.7054\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5063 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3577 - ca2-[9.5,10.3): 0.4995 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5203 - ca3-[10.3,11.3): 0.7020 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5278 - ca4-[11.3,14.9): 0.6943 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5970 - val_ca2-[8.0,9.5): 0.5816 - val_ca2-[9.5,10.3): 0.4083 - val_ca2-[10.3,11.3): 0.8772 - val_ca2-[11.3,14.9): 1.5274 - val_ca3-[8.0,9.5): 0.8281 - val_ca3-[9.5,10.3): 0.5289 - val_ca3-[10.3,11.3): 0.7150 - val_ca3-[11.3,14.9): 0.9517 - val_ca4-[8.0,9.5): 1.5647 - val_ca4-[9.5,10.3): 1.1355 - val_ca4-[10.3,11.3): 0.9807 - val_ca4-[11.3,14.9): 0.7097\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5130 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3657 - ca2-[9.5,10.3): 0.5106 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4998 - ca3-[10.3,11.3): 0.7076 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5887 - ca4-[11.3,14.9): 0.7035 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9167 - val_ca1-[11.3,14.9): 1.5696 - val_ca2-[8.0,9.5): 0.5808 - val_ca2-[9.5,10.3): 0.4075 - val_ca2-[10.3,11.3): 0.8765 - val_ca2-[11.3,14.9): 1.5021 - val_ca3-[8.0,9.5): 0.8287 - val_ca3-[9.5,10.3): 0.5285 - val_ca3-[10.3,11.3): 0.7139 - val_ca3-[11.3,14.9): 0.9382 - val_ca4-[8.0,9.5): 1.5628 - val_ca4-[9.5,10.3): 1.1338 - val_ca4-[10.3,11.3): 0.9797 - val_ca4-[11.3,14.9): 0.7125\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5270 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3731 - ca2-[9.5,10.3): 0.4950 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5293 - ca3-[10.3,11.3): 0.7071 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5769 - ca4-[11.3,14.9): 0.6938 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9148 - val_ca1-[11.3,14.9): 1.5775 - val_ca2-[8.0,9.5): 0.5796 - val_ca2-[9.5,10.3): 0.4071 - val_ca2-[10.3,11.3): 0.8761 - val_ca2-[11.3,14.9): 1.5133 - val_ca3-[8.0,9.5): 0.8282 - val_ca3-[9.5,10.3): 0.5270 - val_ca3-[10.3,11.3): 0.7059 - val_ca3-[11.3,14.9): 0.9370 - val_ca4-[8.0,9.5): 1.5613 - val_ca4-[9.5,10.3): 1.1326 - val_ca4-[10.3,11.3): 0.9667 - val_ca4-[11.3,14.9): 0.7036\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3621 - ca2-[9.5,10.3): 0.4916 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5214 - ca3-[10.3,11.3): 0.6981 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5122 - ca4-[11.3,14.9): 0.6891 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9059 - val_ca1-[11.3,14.9): 1.5831 - val_ca2-[8.0,9.5): 0.5791 - val_ca2-[9.5,10.3): 0.4063 - val_ca2-[10.3,11.3): 0.8679 - val_ca2-[11.3,14.9): 1.5189 - val_ca3-[8.0,9.5): 0.8254 - val_ca3-[9.5,10.3): 0.5238 - val_ca3-[10.3,11.3): 0.7003 - val_ca3-[11.3,14.9): 0.9385 - val_ca4-[8.0,9.5): 1.5615 - val_ca4-[9.5,10.3): 1.1327 - val_ca4-[10.3,11.3): 0.9635 - val_ca4-[11.3,14.9): 0.6911\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5297 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3613 - ca2-[9.5,10.3): 0.5061 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5173 - ca3-[10.3,11.3): 0.6958 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5741 - ca4-[11.3,14.9): 0.6803 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9162 - val_ca1-[11.3,14.9): 1.6022 - val_ca2-[8.0,9.5): 0.5786 - val_ca2-[9.5,10.3): 0.4055 - val_ca2-[10.3,11.3): 0.8763 - val_ca2-[11.3,14.9): 1.5363 - val_ca3-[8.0,9.5): 0.8242 - val_ca3-[9.5,10.3): 0.5214 - val_ca3-[10.3,11.3): 0.7088 - val_ca3-[11.3,14.9): 0.9542 - val_ca4-[8.0,9.5): 1.5616 - val_ca4-[9.5,10.3): 1.1327 - val_ca4-[10.3,11.3): 0.9790 - val_ca4-[11.3,14.9): 0.7105\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5240 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3435 - ca2-[9.5,10.3): 0.5006 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5497 - ca3-[10.3,11.3): 0.7048 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5908 - ca4-[11.3,14.9): 0.6960 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9115 - val_ca1-[11.3,14.9): 1.5708 - val_ca2-[8.0,9.5): 0.5788 - val_ca2-[9.5,10.3): 0.4044 - val_ca2-[10.3,11.3): 0.8686 - val_ca2-[11.3,14.9): 1.5004 - val_ca3-[8.0,9.5): 0.8179 - val_ca3-[9.5,10.3): 0.5148 - val_ca3-[10.3,11.3): 0.7057 - val_ca3-[11.3,14.9): 0.9434 - val_ca4-[8.0,9.5): 1.5623 - val_ca4-[9.5,10.3): 1.1333 - val_ca4-[10.3,11.3): 0.9812 - val_ca4-[11.3,14.9): 0.7113\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3569 - ca2-[9.5,10.3): 0.4962 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5178 - ca3-[10.3,11.3): 0.6829 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5469 - ca4-[11.3,14.9): 0.6896 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9118 - val_ca1-[11.3,14.9): 1.6023 - val_ca2-[8.0,9.5): 0.5783 - val_ca2-[9.5,10.3): 0.4036 - val_ca2-[10.3,11.3): 0.8679 - val_ca2-[11.3,14.9): 1.5287 - val_ca3-[8.0,9.5): 0.8248 - val_ca3-[9.5,10.3): 0.5192 - val_ca3-[10.3,11.3): 0.7026 - val_ca3-[11.3,14.9): 0.9488 - val_ca4-[8.0,9.5): 1.5631 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9760 - val_ca4-[11.3,14.9): 0.7046\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5308 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3643 - ca2-[9.5,10.3): 0.4924 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5119 - ca3-[10.3,11.3): 0.6627 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5809 - ca4-[11.3,14.9): 0.6983 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9097 - val_ca1-[11.3,14.9): 1.5821 - val_ca2-[8.0,9.5): 0.5775 - val_ca2-[9.5,10.3): 0.4032 - val_ca2-[10.3,11.3): 0.8661 - val_ca2-[11.3,14.9): 1.5129 - val_ca3-[8.0,9.5): 0.8243 - val_ca3-[9.5,10.3): 0.5174 - val_ca3-[10.3,11.3): 0.7005 - val_ca3-[11.3,14.9): 0.9390 - val_ca4-[8.0,9.5): 1.5630 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9789 - val_ca4-[11.3,14.9): 0.7081\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5183 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3493 - ca2-[9.5,10.3): 0.4896 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5155 - ca3-[10.3,11.3): 0.6763 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5746 - ca4-[11.3,14.9): 0.6911 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9113 - val_ca1-[11.3,14.9): 1.6013 - val_ca2-[8.0,9.5): 0.5768 - val_ca2-[9.5,10.3): 0.4026 - val_ca2-[10.3,11.3): 0.8677 - val_ca2-[11.3,14.9): 1.5315 - val_ca3-[8.0,9.5): 0.8180 - val_ca3-[9.5,10.3): 0.5110 - val_ca3-[10.3,11.3): 0.7009 - val_ca3-[11.3,14.9): 0.9601 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1344 - val_ca4-[10.3,11.3): 0.9819 - val_ca4-[11.3,14.9): 0.7161\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5190 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3483 - ca2-[9.5,10.3): 0.4812 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5018 - ca3-[10.3,11.3): 0.7101 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5529 - ca4-[11.3,14.9): 0.6923 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5529 - val_ca2-[8.0,9.5): 0.5764 - val_ca2-[9.5,10.3): 0.4019 - val_ca2-[10.3,11.3): 0.8662 - val_ca2-[11.3,14.9): 1.4853 - val_ca3-[8.0,9.5): 0.8236 - val_ca3-[9.5,10.3): 0.5147 - val_ca3-[10.3,11.3): 0.6951 - val_ca3-[11.3,14.9): 0.9223 - val_ca4-[8.0,9.5): 1.5644 - val_ca4-[9.5,10.3): 1.1350 - val_ca4-[10.3,11.3): 0.9736 - val_ca4-[11.3,14.9): 0.7022\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5210 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3541 - ca2-[9.5,10.3): 0.4754 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4970 - ca3-[10.3,11.3): 0.6725 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6039 - ca4-[11.3,14.9): 0.6875 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9140 - val_ca1-[11.3,14.9): 1.5822 - val_ca2-[8.0,9.5): 0.5755 - val_ca2-[9.5,10.3): 0.4018 - val_ca2-[10.3,11.3): 0.8697 - val_ca2-[11.3,14.9): 1.5169 - val_ca3-[8.0,9.5): 0.8211 - val_ca3-[9.5,10.3): 0.5107 - val_ca3-[10.3,11.3): 0.6967 - val_ca3-[11.3,14.9): 0.9365 - val_ca4-[8.0,9.5): 1.5637 - val_ca4-[9.5,10.3): 1.1343 - val_ca4-[10.3,11.3): 0.9773 - val_ca4-[11.3,14.9): 0.6967\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5186 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3569 - ca2-[9.5,10.3): 0.4866 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4808 - ca3-[10.3,11.3): 0.6848 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5146 - ca4-[11.3,14.9): 0.6963 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5895 - val_ca2-[8.0,9.5): 0.5762 - val_ca2-[9.5,10.3): 0.4014 - val_ca2-[10.3,11.3): 0.8653 - val_ca2-[11.3,14.9): 1.5100 - val_ca3-[8.0,9.5): 0.8160 - val_ca3-[9.5,10.3): 0.5065 - val_ca3-[10.3,11.3): 0.6983 - val_ca3-[11.3,14.9): 0.9499 - val_ca4-[8.0,9.5): 1.5639 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9845 - val_ca4-[11.3,14.9): 0.7104\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5127 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3569 - ca2-[9.5,10.3): 0.4881 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5072 - ca3-[10.3,11.3): 0.6762 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5756 - ca4-[11.3,14.9): 0.7041 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9133 - val_ca1-[11.3,14.9): 1.5641 - val_ca2-[8.0,9.5): 0.5754 - val_ca2-[9.5,10.3): 0.4009 - val_ca2-[10.3,11.3): 0.8684 - val_ca2-[11.3,14.9): 1.4972 - val_ca3-[8.0,9.5): 0.8228 - val_ca3-[9.5,10.3): 0.5097 - val_ca3-[10.3,11.3): 0.6977 - val_ca3-[11.3,14.9): 0.9293 - val_ca4-[8.0,9.5): 1.5643 - val_ca4-[9.5,10.3): 1.1347 - val_ca4-[10.3,11.3): 0.9846 - val_ca4-[11.3,14.9): 0.7046\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5102 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3599 - ca2-[9.5,10.3): 0.4865 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5146 - ca3-[10.3,11.3): 0.6965 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5669 - ca4-[11.3,14.9): 0.6842 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9158 - val_ca1-[11.3,14.9): 1.5796 - val_ca2-[8.0,9.5): 0.5756 - val_ca2-[9.5,10.3): 0.4013 - val_ca2-[10.3,11.3): 0.8681 - val_ca2-[11.3,14.9): 1.5096 - val_ca3-[8.0,9.5): 0.8253 - val_ca3-[9.5,10.3): 0.5119 - val_ca3-[10.3,11.3): 0.6956 - val_ca3-[11.3,14.9): 0.9338 - val_ca4-[8.0,9.5): 1.5636 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9797 - val_ca4-[11.3,14.9): 0.7050\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5283 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3516 - ca2-[9.5,10.3): 0.4802 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5471 - ca3-[10.3,11.3): 0.6778 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5445 - ca4-[11.3,14.9): 0.6852 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9110 - val_ca1-[11.3,14.9): 1.5609 - val_ca2-[8.0,9.5): 0.5756 - val_ca2-[9.5,10.3): 0.4006 - val_ca2-[10.3,11.3): 0.8648 - val_ca2-[11.3,14.9): 1.4928 - val_ca3-[8.0,9.5): 0.8282 - val_ca3-[9.5,10.3): 0.5108 - val_ca3-[10.3,11.3): 0.6936 - val_ca3-[11.3,14.9): 0.9206 - val_ca4-[8.0,9.5): 1.5624 - val_ca4-[9.5,10.3): 1.1330 - val_ca4-[10.3,11.3): 0.9810 - val_ca4-[11.3,14.9): 0.6999\n",
      "Epoch 193/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5101 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3506 - ca2-[9.5,10.3): 0.4979 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5001 - ca3-[10.3,11.3): 0.6771 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5251 - ca4-[11.3,14.9): 0.7011 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9064 - val_ca1-[11.3,14.9): 1.5792 - val_ca2-[8.0,9.5): 0.5767 - val_ca2-[9.5,10.3): 0.4007 - val_ca2-[10.3,11.3): 0.8576 - val_ca2-[11.3,14.9): 1.5045 - val_ca3-[8.0,9.5): 0.8319 - val_ca3-[9.5,10.3): 0.5118 - val_ca3-[10.3,11.3): 0.6919 - val_ca3-[11.3,14.9): 0.9292 - val_ca4-[8.0,9.5): 1.5621 - val_ca4-[9.5,10.3): 1.1301 - val_ca4-[10.3,11.3): 0.9827 - val_ca4-[11.3,14.9): 0.7049\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5261 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3539 - ca2-[9.5,10.3): 0.4873 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5042 - ca3-[10.3,11.3): 0.6866 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5576 - ca4-[11.3,14.9): 0.6995 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9139 - val_ca1-[11.3,14.9): 1.5682 - val_ca2-[8.0,9.5): 0.5782 - val_ca2-[9.5,10.3): 0.3994 - val_ca2-[10.3,11.3): 0.8566 - val_ca2-[11.3,14.9): 1.4826 - val_ca3-[8.0,9.5): 0.8437 - val_ca3-[9.5,10.3): 0.5220 - val_ca3-[10.3,11.3): 0.6917 - val_ca3-[11.3,14.9): 0.9068 - val_ca4-[8.0,9.5): 1.5627 - val_ca4-[9.5,10.3): 1.1332 - val_ca4-[10.3,11.3): 0.9766 - val_ca4-[11.3,14.9): 0.7007\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5115 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3512 - ca2-[9.5,10.3): 0.4953 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5165 - ca3-[10.3,11.3): 0.6645 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5740 - ca4-[11.3,14.9): 0.6978 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9115 - val_ca1-[11.3,14.9): 1.5579 - val_ca2-[8.0,9.5): 0.5788 - val_ca2-[9.5,10.3): 0.3993 - val_ca2-[10.3,11.3): 0.8547 - val_ca2-[11.3,14.9): 1.4751 - val_ca3-[8.0,9.5): 0.8289 - val_ca3-[9.5,10.3): 0.5056 - val_ca3-[10.3,11.3): 0.6918 - val_ca3-[11.3,14.9): 0.9271 - val_ca4-[8.0,9.5): 1.5630 - val_ca4-[9.5,10.3): 1.1334 - val_ca4-[10.3,11.3): 0.9812 - val_ca4-[11.3,14.9): 0.6982\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5162 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3492 - ca2-[9.5,10.3): 0.4695 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5064 - ca3-[10.3,11.3): 0.6747 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5418 - ca4-[11.3,14.9): 0.6604 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9118 - val_ca1-[11.3,14.9): 1.5692 - val_ca2-[8.0,9.5): 0.5794 - val_ca2-[9.5,10.3): 0.3994 - val_ca2-[10.3,11.3): 0.8545 - val_ca2-[11.3,14.9): 1.4865 - val_ca3-[8.0,9.5): 0.8407 - val_ca3-[9.5,10.3): 0.5143 - val_ca3-[10.3,11.3): 0.6902 - val_ca3-[11.3,14.9): 0.9209 - val_ca4-[8.0,9.5): 1.5637 - val_ca4-[9.5,10.3): 1.1340 - val_ca4-[10.3,11.3): 0.9815 - val_ca4-[11.3,14.9): 0.7063\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5201 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3486 - ca2-[9.5,10.3): 0.4737 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5206 - ca3-[10.3,11.3): 0.6754 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5776 - ca4-[11.3,14.9): 0.6857 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5983 - val_ca2-[8.0,9.5): 0.5797 - val_ca2-[9.5,10.3): 0.3998 - val_ca2-[10.3,11.3): 0.8568 - val_ca2-[11.3,14.9): 1.5085 - val_ca3-[8.0,9.5): 0.8525 - val_ca3-[9.5,10.3): 0.5227 - val_ca3-[10.3,11.3): 0.6907 - val_ca3-[11.3,14.9): 0.9175 - val_ca4-[8.0,9.5): 1.5640 - val_ca4-[9.5,10.3): 1.1342 - val_ca4-[10.3,11.3): 0.9842 - val_ca4-[11.3,14.9): 0.7024\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5217 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3488 - ca2-[9.5,10.3): 0.4871 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4791 - ca3-[10.3,11.3): 0.6586 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5516 - ca4-[11.3,14.9): 0.7032 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9164 - val_ca1-[11.3,14.9): 1.5899 - val_ca2-[8.0,9.5): 0.5821 - val_ca2-[9.5,10.3): 0.3987 - val_ca2-[10.3,11.3): 0.8484 - val_ca2-[11.3,14.9): 1.4703 - val_ca3-[8.0,9.5): 0.8489 - val_ca3-[9.5,10.3): 0.5167 - val_ca3-[10.3,11.3): 0.6883 - val_ca3-[11.3,14.9): 0.9107 - val_ca4-[8.0,9.5): 1.5632 - val_ca4-[9.5,10.3): 1.1334 - val_ca4-[10.3,11.3): 0.9793 - val_ca4-[11.3,14.9): 0.6968\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3561 - ca2-[9.5,10.3): 0.4869 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4818 - ca3-[10.3,11.3): 0.6595 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5709 - ca4-[11.3,14.9): 0.6856 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.5686 - val_ca2-[8.0,9.5): 0.5806 - val_ca2-[9.5,10.3): 0.4012 - val_ca2-[10.3,11.3): 0.8560 - val_ca2-[11.3,14.9): 1.4756 - val_ca3-[8.0,9.5): 0.8532 - val_ca3-[9.5,10.3): 0.5215 - val_ca3-[10.3,11.3): 0.6853 - val_ca3-[11.3,14.9): 0.8994 - val_ca4-[8.0,9.5): 1.5634 - val_ca4-[9.5,10.3): 1.1369 - val_ca4-[10.3,11.3): 0.9738 - val_ca4-[11.3,14.9): 0.7033\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5222 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3615 - ca2-[9.5,10.3): 0.4895 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5139 - ca3-[10.3,11.3): 0.6613 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5847 - ca4-[11.3,14.9): 0.6870 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.6026 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3986 - val_ca2-[10.3,11.3): 0.8430 - val_ca2-[11.3,14.9): 1.4864 - val_ca3-[8.0,9.5): 0.8546 - val_ca3-[9.5,10.3): 0.5194 - val_ca3-[10.3,11.3): 0.6855 - val_ca3-[11.3,14.9): 0.9269 - val_ca4-[8.0,9.5): 1.5627 - val_ca4-[9.5,10.3): 1.1330 - val_ca4-[10.3,11.3): 0.9764 - val_ca4-[11.3,14.9): 0.7154\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5168 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3550 - ca2-[9.5,10.3): 0.4772 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5068 - ca3-[10.3,11.3): 0.6593 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5702 - ca4-[11.3,14.9): 0.6743 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9093 - val_ca1-[11.3,14.9): 1.5680 - val_ca2-[8.0,9.5): 0.5833 - val_ca2-[9.5,10.3): 0.3992 - val_ca2-[10.3,11.3): 0.8422 - val_ca2-[11.3,14.9): 1.4642 - val_ca3-[8.0,9.5): 0.8699 - val_ca3-[9.5,10.3): 0.5315 - val_ca3-[10.3,11.3): 0.6838 - val_ca3-[11.3,14.9): 0.8907 - val_ca4-[8.0,9.5): 1.5635 - val_ca4-[9.5,10.3): 1.1336 - val_ca4-[10.3,11.3): 0.9787 - val_ca4-[11.3,14.9): 0.7062\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5060 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3606 - ca2-[9.5,10.3): 0.4748 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5147 - ca3-[10.3,11.3): 0.6435 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5862 - ca4-[11.3,14.9): 0.6914 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5846 - val_ca2-[8.0,9.5): 0.5825 - val_ca2-[9.5,10.3): 0.4003 - val_ca2-[10.3,11.3): 0.8538 - val_ca2-[11.3,14.9): 1.4872 - val_ca3-[8.0,9.5): 0.8552 - val_ca3-[9.5,10.3): 0.5169 - val_ca3-[10.3,11.3): 0.6845 - val_ca3-[11.3,14.9): 0.9103 - val_ca4-[8.0,9.5): 1.5652 - val_ca4-[9.5,10.3): 1.1351 - val_ca4-[10.3,11.3): 0.9802 - val_ca4-[11.3,14.9): 0.7066\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5245 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3490 - ca2-[9.5,10.3): 0.4771 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4987 - ca3-[10.3,11.3): 0.6677 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5663 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9104 - val_ca1-[11.3,14.9): 1.5895 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3986 - val_ca2-[10.3,11.3): 0.8412 - val_ca2-[11.3,14.9): 1.4751 - val_ca3-[8.0,9.5): 0.8635 - val_ca3-[9.5,10.3): 0.5240 - val_ca3-[10.3,11.3): 0.6787 - val_ca3-[11.3,14.9): 0.9058 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1356 - val_ca4-[10.3,11.3): 0.9632 - val_ca4-[11.3,14.9): 0.6913\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5232 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3634 - ca2-[9.5,10.3): 0.4760 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5118 - ca3-[10.3,11.3): 0.6653 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5931 - ca4-[11.3,14.9): 0.6866 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9101 - val_ca1-[11.3,14.9): 1.5755 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3975 - val_ca2-[10.3,11.3): 0.8330 - val_ca2-[11.3,14.9): 1.4362 - val_ca3-[8.0,9.5): 0.8690 - val_ca3-[9.5,10.3): 0.5280 - val_ca3-[10.3,11.3): 0.6779 - val_ca3-[11.3,14.9): 0.8864 - val_ca4-[8.0,9.5): 1.5681 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9643 - val_ca4-[11.3,14.9): 0.6896\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5108 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3590 - ca2-[9.5,10.3): 0.4796 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5177 - ca3-[10.3,11.3): 0.6708 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5893 - ca4-[11.3,14.9): 0.7008 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9142 - val_ca1-[11.3,14.9): 1.5429 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.3998 - val_ca2-[10.3,11.3): 0.8469 - val_ca2-[11.3,14.9): 1.4388 - val_ca3-[8.0,9.5): 0.8601 - val_ca3-[9.5,10.3): 0.5200 - val_ca3-[10.3,11.3): 0.6828 - val_ca3-[11.3,14.9): 0.8707 - val_ca4-[8.0,9.5): 1.5690 - val_ca4-[9.5,10.3): 1.1382 - val_ca4-[10.3,11.3): 0.9794 - val_ca4-[11.3,14.9): 0.6802\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.4981 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3724 - ca2-[9.5,10.3): 0.4806 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5259 - ca3-[10.3,11.3): 0.6517 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5698 - ca4-[11.3,14.9): 0.6926 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9096 - val_ca1-[11.3,14.9): 1.6019 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3983 - val_ca2-[10.3,11.3): 0.8353 - val_ca2-[11.3,14.9): 1.4709 - val_ca3-[8.0,9.5): 0.8633 - val_ca3-[9.5,10.3): 0.5211 - val_ca3-[10.3,11.3): 0.6803 - val_ca3-[11.3,14.9): 0.9182 - val_ca4-[8.0,9.5): 1.5694 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9815 - val_ca4-[11.3,14.9): 0.7154\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5266 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3555 - ca2-[9.5,10.3): 0.4794 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5093 - ca3-[10.3,11.3): 0.6520 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5633 - ca4-[11.3,14.9): 0.6817 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9051 - val_ca1-[11.3,14.9): 1.6027 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3984 - val_ca2-[10.3,11.3): 0.8351 - val_ca2-[11.3,14.9): 1.4822 - val_ca3-[8.0,9.5): 0.8737 - val_ca3-[9.5,10.3): 0.5276 - val_ca3-[10.3,11.3): 0.6780 - val_ca3-[11.3,14.9): 0.9064 - val_ca4-[8.0,9.5): 1.5686 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9734 - val_ca4-[11.3,14.9): 0.7039\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5265 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3513 - ca2-[9.5,10.3): 0.4779 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5036 - ca3-[10.3,11.3): 0.6679 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5932 - ca4-[11.3,14.9): 0.6814 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.5428 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3986 - val_ca2-[10.3,11.3): 0.8416 - val_ca2-[11.3,14.9): 1.4306 - val_ca3-[8.0,9.5): 0.8744 - val_ca3-[9.5,10.3): 0.5279 - val_ca3-[10.3,11.3): 0.6781 - val_ca3-[11.3,14.9): 0.8674 - val_ca4-[8.0,9.5): 1.5692 - val_ca4-[9.5,10.3): 1.1383 - val_ca4-[10.3,11.3): 0.9794 - val_ca4-[11.3,14.9): 0.6975\n",
      "Epoch 209/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5181 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3521 - ca2-[9.5,10.3): 0.4810 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5140 - ca3-[10.3,11.3): 0.6525 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5845 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9170 - val_ca1-[11.3,14.9): 1.5972 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.3983 - val_ca2-[10.3,11.3): 0.8428 - val_ca2-[11.3,14.9): 1.4780 - val_ca3-[8.0,9.5): 0.8701 - val_ca3-[9.5,10.3): 0.5244 - val_ca3-[10.3,11.3): 0.6807 - val_ca3-[11.3,14.9): 0.9091 - val_ca4-[8.0,9.5): 1.5679 - val_ca4-[9.5,10.3): 1.1371 - val_ca4-[10.3,11.3): 0.9813 - val_ca4-[11.3,14.9): 0.7144\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5267 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3599 - ca2-[9.5,10.3): 0.4751 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5238 - ca3-[10.3,11.3): 0.6653 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5526 - ca4-[11.3,14.9): 0.6884 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9101 - val_ca1-[11.3,14.9): 1.5525 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3981 - val_ca2-[10.3,11.3): 0.8352 - val_ca2-[11.3,14.9): 1.4371 - val_ca3-[8.0,9.5): 0.8826 - val_ca3-[9.5,10.3): 0.5346 - val_ca3-[10.3,11.3): 0.6778 - val_ca3-[11.3,14.9): 0.8675 - val_ca4-[8.0,9.5): 1.5666 - val_ca4-[9.5,10.3): 1.1360 - val_ca4-[10.3,11.3): 0.9800 - val_ca4-[11.3,14.9): 0.6970\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5159 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3584 - ca2-[9.5,10.3): 0.4785 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4972 - ca3-[10.3,11.3): 0.6442 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5761 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9121 - val_ca1-[11.3,14.9): 1.5862 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.3982 - val_ca2-[10.3,11.3): 0.8367 - val_ca2-[11.3,14.9): 1.4664 - val_ca3-[8.0,9.5): 0.8741 - val_ca3-[9.5,10.3): 0.5257 - val_ca3-[10.3,11.3): 0.6777 - val_ca3-[11.3,14.9): 0.8933 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1358 - val_ca4-[10.3,11.3): 0.9770 - val_ca4-[11.3,14.9): 0.6836\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5162 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3567 - ca2-[9.5,10.3): 0.4846 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5219 - ca3-[10.3,11.3): 0.6518 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5442 - ca4-[11.3,14.9): 0.7060 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5730 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3988 - val_ca2-[10.3,11.3): 0.8408 - val_ca2-[11.3,14.9): 1.4538 - val_ca3-[8.0,9.5): 0.8733 - val_ca3-[9.5,10.3): 0.5240 - val_ca3-[10.3,11.3): 0.6783 - val_ca3-[11.3,14.9): 0.8900 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1357 - val_ca4-[10.3,11.3): 0.9805 - val_ca4-[11.3,14.9): 0.6990\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5117 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3591 - ca2-[9.5,10.3): 0.4678 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5293 - ca3-[10.3,11.3): 0.6441 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5980 - ca4-[11.3,14.9): 0.7025 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9069 - val_ca1-[11.3,14.9): 1.5803 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3982 - val_ca2-[10.3,11.3): 0.8325 - val_ca2-[11.3,14.9): 1.4470 - val_ca3-[8.0,9.5): 0.8719 - val_ca3-[9.5,10.3): 0.5217 - val_ca3-[10.3,11.3): 0.6734 - val_ca3-[11.3,14.9): 0.8938 - val_ca4-[8.0,9.5): 1.5650 - val_ca4-[9.5,10.3): 1.1345 - val_ca4-[10.3,11.3): 0.9644 - val_ca4-[11.3,14.9): 0.7055\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5200 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3587 - ca2-[9.5,10.3): 0.4770 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5153 - ca3-[10.3,11.3): 0.6411 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5608 - ca4-[11.3,14.9): 0.6908 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.6040 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.3992 - val_ca2-[10.3,11.3): 0.8439 - val_ca2-[11.3,14.9): 1.4821 - val_ca3-[8.0,9.5): 0.8820 - val_ca3-[9.5,10.3): 0.5295 - val_ca3-[10.3,11.3): 0.6769 - val_ca3-[11.3,14.9): 0.8949 - val_ca4-[8.0,9.5): 1.5634 - val_ca4-[9.5,10.3): 1.1330 - val_ca4-[10.3,11.3): 0.9789 - val_ca4-[11.3,14.9): 0.7152\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5144 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3597 - ca2-[9.5,10.3): 0.4660 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5195 - ca3-[10.3,11.3): 0.6463 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5754 - ca4-[11.3,14.9): 0.7021 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9102 - val_ca1-[11.3,14.9): 1.6035 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.3987 - val_ca2-[10.3,11.3): 0.8362 - val_ca2-[11.3,14.9): 1.4756 - val_ca3-[8.0,9.5): 0.8871 - val_ca3-[9.5,10.3): 0.5332 - val_ca3-[10.3,11.3): 0.6736 - val_ca3-[11.3,14.9): 0.8896 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1334 - val_ca4-[10.3,11.3): 0.9784 - val_ca4-[11.3,14.9): 0.7097\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5132 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3538 - ca2-[9.5,10.3): 0.4685 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5135 - ca3-[10.3,11.3): 0.6343 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5801 - ca4-[11.3,14.9): 0.6870 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9141 - val_ca1-[11.3,14.9): 1.6077 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.3979 - val_ca2-[10.3,11.3): 0.8371 - val_ca2-[11.3,14.9): 1.4790 - val_ca3-[8.0,9.5): 0.8796 - val_ca3-[9.5,10.3): 0.5264 - val_ca3-[10.3,11.3): 0.6756 - val_ca3-[11.3,14.9): 0.9037 - val_ca4-[8.0,9.5): 1.5637 - val_ca4-[9.5,10.3): 1.1333 - val_ca4-[10.3,11.3): 0.9779 - val_ca4-[11.3,14.9): 0.7130\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5298 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3567 - ca2-[9.5,10.3): 0.4726 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4989 - ca3-[10.3,11.3): 0.6480 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5503 - ca4-[11.3,14.9): 0.6863 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9170 - val_ca1-[11.3,14.9): 1.5795 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.3987 - val_ca2-[10.3,11.3): 0.8416 - val_ca2-[11.3,14.9): 1.4542 - val_ca3-[8.0,9.5): 0.8845 - val_ca3-[9.5,10.3): 0.5293 - val_ca3-[10.3,11.3): 0.6725 - val_ca3-[11.3,14.9): 0.8659 - val_ca4-[8.0,9.5): 1.5637 - val_ca4-[9.5,10.3): 1.1332 - val_ca4-[10.3,11.3): 0.9735 - val_ca4-[11.3,14.9): 0.6995\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5203 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3508 - ca2-[9.5,10.3): 0.4816 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5106 - ca3-[10.3,11.3): 0.6328 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5774 - ca4-[11.3,14.9): 0.6914 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9147 - val_ca1-[11.3,14.9): 1.5837 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3978 - val_ca2-[10.3,11.3): 0.8337 - val_ca2-[11.3,14.9): 1.4534 - val_ca3-[8.0,9.5): 0.8891 - val_ca3-[9.5,10.3): 0.5319 - val_ca3-[10.3,11.3): 0.6705 - val_ca3-[11.3,14.9): 0.8733 - val_ca4-[8.0,9.5): 1.5619 - val_ca4-[9.5,10.3): 1.1317 - val_ca4-[10.3,11.3): 0.9754 - val_ca4-[11.3,14.9): 0.6958\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5184 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3535 - ca2-[9.5,10.3): 0.4605 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5464 - ca3-[10.3,11.3): 0.6353 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5101 - ca4-[11.3,14.9): 0.6823 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9147 - val_ca1-[11.3,14.9): 1.5572 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3992 - val_ca2-[10.3,11.3): 0.8426 - val_ca2-[11.3,14.9): 1.4423 - val_ca3-[8.0,9.5): 0.8856 - val_ca3-[9.5,10.3): 0.5284 - val_ca3-[10.3,11.3): 0.6706 - val_ca3-[11.3,14.9): 0.8583 - val_ca4-[8.0,9.5): 1.5614 - val_ca4-[9.5,10.3): 1.1312 - val_ca4-[10.3,11.3): 0.9751 - val_ca4-[11.3,14.9): 0.6870\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5162 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3663 - ca2-[9.5,10.3): 0.4695 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5172 - ca3-[10.3,11.3): 0.6403 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5801 - ca4-[11.3,14.9): 0.6772 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9119 - val_ca1-[11.3,14.9): 1.5633 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3970 - val_ca2-[10.3,11.3): 0.8318 - val_ca2-[11.3,14.9): 1.4355 - val_ca3-[8.0,9.5): 0.8826 - val_ca3-[9.5,10.3): 0.5257 - val_ca3-[10.3,11.3): 0.6718 - val_ca3-[11.3,14.9): 0.8721 - val_ca4-[8.0,9.5): 1.5618 - val_ca4-[9.5,10.3): 1.1315 - val_ca4-[10.3,11.3): 0.9798 - val_ca4-[11.3,14.9): 0.6935\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5097 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3447 - ca2-[9.5,10.3): 0.4660 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5001 - ca3-[10.3,11.3): 0.6430 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5691 - ca4-[11.3,14.9): 0.6985 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9072 - val_ca1-[11.3,14.9): 1.5894 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3969 - val_ca2-[10.3,11.3): 0.8296 - val_ca2-[11.3,14.9): 1.4658 - val_ca3-[8.0,9.5): 0.8752 - val_ca3-[9.5,10.3): 0.5198 - val_ca3-[10.3,11.3): 0.6723 - val_ca3-[11.3,14.9): 0.9005 - val_ca4-[8.0,9.5): 1.5627 - val_ca4-[9.5,10.3): 1.1322 - val_ca4-[10.3,11.3): 0.9821 - val_ca4-[11.3,14.9): 0.7078\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5282 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3596 - ca2-[9.5,10.3): 0.4758 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5207 - ca3-[10.3,11.3): 0.6439 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5158 - ca4-[11.3,14.9): 0.6894 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9098 - val_ca1-[11.3,14.9): 1.5889 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.3979 - val_ca2-[10.3,11.3): 0.8347 - val_ca2-[11.3,14.9): 1.4704 - val_ca3-[8.0,9.5): 0.8977 - val_ca3-[9.5,10.3): 0.5370 - val_ca3-[10.3,11.3): 0.6677 - val_ca3-[11.3,14.9): 0.8681 - val_ca4-[8.0,9.5): 1.5643 - val_ca4-[9.5,10.3): 1.1336 - val_ca4-[10.3,11.3): 0.9783 - val_ca4-[11.3,14.9): 0.7133\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5189 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3494 - ca2-[9.5,10.3): 0.4680 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5178 - ca3-[10.3,11.3): 0.6207 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5320 - ca4-[11.3,14.9): 0.6788 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9116 - val_ca1-[11.3,14.9): 1.5559 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3975 - val_ca2-[10.3,11.3): 0.8350 - val_ca2-[11.3,14.9): 1.4494 - val_ca3-[8.0,9.5): 0.8745 - val_ca3-[9.5,10.3): 0.5188 - val_ca3-[10.3,11.3): 0.6719 - val_ca3-[11.3,14.9): 0.8866 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1349 - val_ca4-[10.3,11.3): 0.9817 - val_ca4-[11.3,14.9): 0.6927\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5159 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3668 - ca2-[9.5,10.3): 0.4782 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5007 - ca3-[10.3,11.3): 0.6422 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5537 - ca4-[11.3,14.9): 0.6994 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9095 - val_ca1-[11.3,14.9): 1.5627 - val_ca2-[8.0,9.5): 0.5895 - val_ca2-[9.5,10.3): 0.3962 - val_ca2-[10.3,11.3): 0.8245 - val_ca2-[11.3,14.9): 1.4261 - val_ca3-[8.0,9.5): 0.8932 - val_ca3-[9.5,10.3): 0.5319 - val_ca3-[10.3,11.3): 0.6647 - val_ca3-[11.3,14.9): 0.8388 - val_ca4-[8.0,9.5): 1.5668 - val_ca4-[9.5,10.3): 1.1357 - val_ca4-[10.3,11.3): 0.9796 - val_ca4-[11.3,14.9): 0.6817\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5027 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3547 - ca2-[9.5,10.3): 0.4698 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5094 - ca3-[10.3,11.3): 0.6414 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5243 - ca4-[11.3,14.9): 0.6944 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9164 - val_ca1-[11.3,14.9): 1.5962 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.3967 - val_ca2-[10.3,11.3): 0.8338 - val_ca2-[11.3,14.9): 1.4640 - val_ca3-[8.0,9.5): 0.8921 - val_ca3-[9.5,10.3): 0.5309 - val_ca3-[10.3,11.3): 0.6676 - val_ca3-[11.3,14.9): 0.8756 - val_ca4-[8.0,9.5): 1.5687 - val_ca4-[9.5,10.3): 1.1372 - val_ca4-[10.3,11.3): 0.9811 - val_ca4-[11.3,14.9): 0.7084\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5147 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3534 - ca2-[9.5,10.3): 0.4683 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5148 - ca3-[10.3,11.3): 0.6212 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6499 - ca4-[11.3,14.9): 0.6858 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9149 - val_ca1-[11.3,14.9): 1.5842 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.3963 - val_ca2-[10.3,11.3): 0.8314 - val_ca2-[11.3,14.9): 1.4601 - val_ca3-[8.0,9.5): 0.8789 - val_ca3-[9.5,10.3): 0.5207 - val_ca3-[10.3,11.3): 0.6681 - val_ca3-[11.3,14.9): 0.8883 - val_ca4-[8.0,9.5): 1.5694 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9788 - val_ca4-[11.3,14.9): 0.6955\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5178 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3583 - ca2-[9.5,10.3): 0.4848 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5190 - ca3-[10.3,11.3): 0.6039 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5634 - ca4-[11.3,14.9): 0.6888 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9105 - val_ca1-[11.3,14.9): 1.6046 - val_ca2-[8.0,9.5): 0.5904 - val_ca2-[9.5,10.3): 0.3951 - val_ca2-[10.3,11.3): 0.8218 - val_ca2-[11.3,14.9): 1.4582 - val_ca3-[8.0,9.5): 0.8822 - val_ca3-[9.5,10.3): 0.5230 - val_ca3-[10.3,11.3): 0.6677 - val_ca3-[11.3,14.9): 0.8825 - val_ca4-[8.0,9.5): 1.5698 - val_ca4-[9.5,10.3): 1.1381 - val_ca4-[10.3,11.3): 0.9809 - val_ca4-[11.3,14.9): 0.7033\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5176 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3561 - ca2-[9.5,10.3): 0.4658 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5247 - ca3-[10.3,11.3): 0.6326 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5623 - ca4-[11.3,14.9): 0.6948 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9123 - val_ca1-[11.3,14.9): 1.5771 - val_ca2-[8.0,9.5): 0.5892 - val_ca2-[9.5,10.3): 0.3956 - val_ca2-[10.3,11.3): 0.8294 - val_ca2-[11.3,14.9): 1.4545 - val_ca3-[8.0,9.5): 0.8871 - val_ca3-[9.5,10.3): 0.5261 - val_ca3-[10.3,11.3): 0.6676 - val_ca3-[11.3,14.9): 0.8746 - val_ca4-[8.0,9.5): 1.5694 - val_ca4-[9.5,10.3): 1.1377 - val_ca4-[10.3,11.3): 0.9833 - val_ca4-[11.3,14.9): 0.7061\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5167 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3747 - ca2-[9.5,10.3): 0.4683 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5277 - ca3-[10.3,11.3): 0.6167 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5741 - ca4-[11.3,14.9): 0.6821 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9102 - val_ca1-[11.3,14.9): 1.5832 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3960 - val_ca2-[10.3,11.3): 0.8306 - val_ca2-[11.3,14.9): 1.4715 - val_ca3-[8.0,9.5): 0.8752 - val_ca3-[9.5,10.3): 0.5152 - val_ca3-[10.3,11.3): 0.6642 - val_ca3-[11.3,14.9): 0.8924 - val_ca4-[8.0,9.5): 1.5680 - val_ca4-[9.5,10.3): 1.1365 - val_ca4-[10.3,11.3): 0.9799 - val_ca4-[11.3,14.9): 0.7125\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5120 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3681 - ca2-[9.5,10.3): 0.4650 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5224 - ca3-[10.3,11.3): 0.6377 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5217 - ca4-[11.3,14.9): 0.6983 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9112 - val_ca1-[11.3,14.9): 1.5710 - val_ca2-[8.0,9.5): 0.5894 - val_ca2-[9.5,10.3): 0.3947 - val_ca2-[10.3,11.3): 0.8282 - val_ca2-[11.3,14.9): 1.4425 - val_ca3-[8.0,9.5): 0.8976 - val_ca3-[9.5,10.3): 0.5320 - val_ca3-[10.3,11.3): 0.6608 - val_ca3-[11.3,14.9): 0.8441 - val_ca4-[8.0,9.5): 1.5668 - val_ca4-[9.5,10.3): 1.1354 - val_ca4-[10.3,11.3): 0.9627 - val_ca4-[11.3,14.9): 0.6940\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5039 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3462 - ca2-[9.5,10.3): 0.4766 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5589 - ca3-[10.3,11.3): 0.6359 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5534 - ca4-[11.3,14.9): 0.6850 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9099 - val_ca1-[11.3,14.9): 1.5856 - val_ca2-[8.0,9.5): 0.5893 - val_ca2-[9.5,10.3): 0.3947 - val_ca2-[10.3,11.3): 0.8233 - val_ca2-[11.3,14.9): 1.4567 - val_ca3-[8.0,9.5): 0.8858 - val_ca3-[9.5,10.3): 0.5219 - val_ca3-[10.3,11.3): 0.6597 - val_ca3-[11.3,14.9): 0.8690 - val_ca4-[8.0,9.5): 1.5660 - val_ca4-[9.5,10.3): 1.1346 - val_ca4-[10.3,11.3): 0.9788 - val_ca4-[11.3,14.9): 0.6998\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3720 - ca2-[9.5,10.3): 0.4675 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5207 - ca3-[10.3,11.3): 0.6352 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5789 - ca4-[11.3,14.9): 0.6798 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9016 - val_ca1-[11.3,14.9): 1.5528 - val_ca2-[8.0,9.5): 0.5895 - val_ca2-[9.5,10.3): 0.3946 - val_ca2-[10.3,11.3): 0.8222 - val_ca2-[11.3,14.9): 1.4221 - val_ca3-[8.0,9.5): 0.8772 - val_ca3-[9.5,10.3): 0.5154 - val_ca3-[10.3,11.3): 0.6616 - val_ca3-[11.3,14.9): 0.8676 - val_ca4-[8.0,9.5): 1.5656 - val_ca4-[9.5,10.3): 1.1342 - val_ca4-[10.3,11.3): 0.9657 - val_ca4-[11.3,14.9): 0.6907\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5109 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3727 - ca2-[9.5,10.3): 0.4737 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5250 - ca3-[10.3,11.3): 0.6238 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5581 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9166 - val_ca1-[11.3,14.9): 1.5967 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.3947 - val_ca2-[10.3,11.3): 0.8335 - val_ca2-[11.3,14.9): 1.4840 - val_ca3-[8.0,9.5): 0.8836 - val_ca3-[9.5,10.3): 0.5200 - val_ca3-[10.3,11.3): 0.6651 - val_ca3-[11.3,14.9): 0.8890 - val_ca4-[8.0,9.5): 1.5652 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9790 - val_ca4-[11.3,14.9): 0.7081\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5163 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3686 - ca2-[9.5,10.3): 0.4613 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4958 - ca3-[10.3,11.3): 0.6253 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5853 - ca4-[11.3,14.9): 0.6983 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9184 - val_ca1-[11.3,14.9): 1.5624 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.3949 - val_ca2-[10.3,11.3): 0.8368 - val_ca2-[11.3,14.9): 1.4518 - val_ca3-[8.0,9.5): 0.8965 - val_ca3-[9.5,10.3): 0.5290 - val_ca3-[10.3,11.3): 0.6651 - val_ca3-[11.3,14.9): 0.8419 - val_ca4-[8.0,9.5): 1.5656 - val_ca4-[9.5,10.3): 1.1342 - val_ca4-[10.3,11.3): 0.9817 - val_ca4-[11.3,14.9): 0.6790\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3669 - ca2-[9.5,10.3): 0.4568 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5418 - ca3-[10.3,11.3): 0.6251 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5765 - ca4-[11.3,14.9): 0.6902 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9143 - val_ca1-[11.3,14.9): 1.5360 - val_ca2-[8.0,9.5): 0.5896 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8269 - val_ca2-[11.3,14.9): 1.4169 - val_ca3-[8.0,9.5): 0.8753 - val_ca3-[9.5,10.3): 0.5114 - val_ca3-[10.3,11.3): 0.6627 - val_ca3-[11.3,14.9): 0.8600 - val_ca4-[8.0,9.5): 1.5656 - val_ca4-[9.5,10.3): 1.1342 - val_ca4-[10.3,11.3): 0.9765 - val_ca4-[11.3,14.9): 0.6901\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3743 - ca2-[9.5,10.3): 0.4685 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4948 - ca3-[10.3,11.3): 0.6204 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5857 - ca4-[11.3,14.9): 0.6950 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9099 - val_ca1-[11.3,14.9): 1.5791 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3952 - val_ca2-[10.3,11.3): 0.8344 - val_ca2-[11.3,14.9): 1.4840 - val_ca3-[8.0,9.5): 0.8961 - val_ca3-[9.5,10.3): 0.5275 - val_ca3-[10.3,11.3): 0.6605 - val_ca3-[11.3,14.9): 0.8605 - val_ca4-[8.0,9.5): 1.5657 - val_ca4-[9.5,10.3): 1.1342 - val_ca4-[10.3,11.3): 0.9783 - val_ca4-[11.3,14.9): 0.6992\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5171 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3454 - ca2-[9.5,10.3): 0.4622 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5412 - ca3-[10.3,11.3): 0.6176 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5494 - ca4-[11.3,14.9): 0.6849 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9098 - val_ca1-[11.3,14.9): 1.5759 - val_ca2-[8.0,9.5): 0.5904 - val_ca2-[9.5,10.3): 0.3926 - val_ca2-[10.3,11.3): 0.8212 - val_ca2-[11.3,14.9): 1.4537 - val_ca3-[8.0,9.5): 0.8842 - val_ca3-[9.5,10.3): 0.5182 - val_ca3-[10.3,11.3): 0.6623 - val_ca3-[11.3,14.9): 0.8723 - val_ca4-[8.0,9.5): 1.5643 - val_ca4-[9.5,10.3): 1.1329 - val_ca4-[10.3,11.3): 0.9776 - val_ca4-[11.3,14.9): 0.7060\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5208 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3681 - ca2-[9.5,10.3): 0.4670 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5130 - ca3-[10.3,11.3): 0.6226 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5728 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9164 - val_ca1-[11.3,14.9): 1.6051 - val_ca2-[8.0,9.5): 0.5893 - val_ca2-[9.5,10.3): 0.3921 - val_ca2-[10.3,11.3): 0.8307 - val_ca2-[11.3,14.9): 1.4906 - val_ca3-[8.0,9.5): 0.8915 - val_ca3-[9.5,10.3): 0.5244 - val_ca3-[10.3,11.3): 0.6625 - val_ca3-[11.3,14.9): 0.8810 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1353 - val_ca4-[10.3,11.3): 0.9777 - val_ca4-[11.3,14.9): 0.7132\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5106 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3643 - ca2-[9.5,10.3): 0.4706 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5435 - ca3-[10.3,11.3): 0.6144 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5850 - ca4-[11.3,14.9): 0.7013 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9166 - val_ca1-[11.3,14.9): 1.5987 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.3924 - val_ca2-[10.3,11.3): 0.8316 - val_ca2-[11.3,14.9): 1.4700 - val_ca3-[8.0,9.5): 0.8800 - val_ca3-[9.5,10.3): 0.5149 - val_ca3-[10.3,11.3): 0.6631 - val_ca3-[11.3,14.9): 0.8802 - val_ca4-[8.0,9.5): 1.5642 - val_ca4-[9.5,10.3): 1.1327 - val_ca4-[10.3,11.3): 0.9780 - val_ca4-[11.3,14.9): 0.7180\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5149 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3461 - ca2-[9.5,10.3): 0.4574 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5307 - ca3-[10.3,11.3): 0.6215 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5697 - ca4-[11.3,14.9): 0.6952 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9195 - val_ca1-[11.3,14.9): 1.5897 - val_ca2-[8.0,9.5): 0.5904 - val_ca2-[9.5,10.3): 0.3912 - val_ca2-[10.3,11.3): 0.8270 - val_ca2-[11.3,14.9): 1.4617 - val_ca3-[8.0,9.5): 0.8929 - val_ca3-[9.5,10.3): 0.5235 - val_ca3-[10.3,11.3): 0.6584 - val_ca3-[11.3,14.9): 0.8608 - val_ca4-[8.0,9.5): 1.5634 - val_ca4-[9.5,10.3): 1.1320 - val_ca4-[10.3,11.3): 0.9746 - val_ca4-[11.3,14.9): 0.7042\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5148 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3425 - ca2-[9.5,10.3): 0.4595 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5298 - ca3-[10.3,11.3): 0.6219 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5781 - ca4-[11.3,14.9): 0.6942 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9105 - val_ca1-[11.3,14.9): 1.5646 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.3916 - val_ca2-[10.3,11.3): 0.8249 - val_ca2-[11.3,14.9): 1.4465 - val_ca3-[8.0,9.5): 0.8790 - val_ca3-[9.5,10.3): 0.5121 - val_ca3-[10.3,11.3): 0.6578 - val_ca3-[11.3,14.9): 0.8613 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1318 - val_ca4-[10.3,11.3): 0.9767 - val_ca4-[11.3,14.9): 0.6926\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5115 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3647 - ca2-[9.5,10.3): 0.4678 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5462 - ca3-[10.3,11.3): 0.6147 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5743 - ca4-[11.3,14.9): 0.6798 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9124 - val_ca1-[11.3,14.9): 1.5903 - val_ca2-[8.0,9.5): 0.5902 - val_ca2-[9.5,10.3): 0.3906 - val_ca2-[10.3,11.3): 0.8217 - val_ca2-[11.3,14.9): 1.4596 - val_ca3-[8.0,9.5): 0.8935 - val_ca3-[9.5,10.3): 0.5228 - val_ca3-[10.3,11.3): 0.6579 - val_ca3-[11.3,14.9): 0.8655 - val_ca4-[8.0,9.5): 1.5647 - val_ca4-[9.5,10.3): 1.1329 - val_ca4-[10.3,11.3): 0.9799 - val_ca4-[11.3,14.9): 0.7181\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5252 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3496 - ca2-[9.5,10.3): 0.4530 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5280 - ca3-[10.3,11.3): 0.6175 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5606 - ca4-[11.3,14.9): 0.6958 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9183 - val_ca1-[11.3,14.9): 1.5853 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3930 - val_ca2-[10.3,11.3): 0.8401 - val_ca2-[11.3,14.9): 1.5023 - val_ca3-[8.0,9.5): 0.8758 - val_ca3-[9.5,10.3): 0.5095 - val_ca3-[10.3,11.3): 0.6613 - val_ca3-[11.3,14.9): 0.8756 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1321 - val_ca4-[10.3,11.3): 0.9801 - val_ca4-[11.3,14.9): 0.7049\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5085 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3705 - ca2-[9.5,10.3): 0.4573 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5137 - ca3-[10.3,11.3): 0.6274 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6039 - ca4-[11.3,14.9): 0.6853 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9137 - val_ca1-[11.3,14.9): 1.6011 - val_ca2-[8.0,9.5): 0.5896 - val_ca2-[9.5,10.3): 0.3902 - val_ca2-[10.3,11.3): 0.8209 - val_ca2-[11.3,14.9): 1.4673 - val_ca3-[8.0,9.5): 0.8824 - val_ca3-[9.5,10.3): 0.5143 - val_ca3-[10.3,11.3): 0.6578 - val_ca3-[11.3,14.9): 0.8821 - val_ca4-[8.0,9.5): 1.5643 - val_ca4-[9.5,10.3): 1.1323 - val_ca4-[10.3,11.3): 0.9750 - val_ca4-[11.3,14.9): 0.7136\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5214 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3627 - ca2-[9.5,10.3): 0.4558 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5176 - ca3-[10.3,11.3): 0.6148 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5757 - ca4-[11.3,14.9): 0.6900 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9083 - val_ca1-[11.3,14.9): 1.5876 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.3906 - val_ca2-[10.3,11.3): 0.8228 - val_ca2-[11.3,14.9): 1.4768 - val_ca3-[8.0,9.5): 0.8869 - val_ca3-[9.5,10.3): 0.5165 - val_ca3-[10.3,11.3): 0.6579 - val_ca3-[11.3,14.9): 0.8746 - val_ca4-[8.0,9.5): 1.5650 - val_ca4-[9.5,10.3): 1.1328 - val_ca4-[10.3,11.3): 0.9786 - val_ca4-[11.3,14.9): 0.7139\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5122 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3454 - ca2-[9.5,10.3): 0.4534 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5080 - ca3-[10.3,11.3): 0.6218 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5926 - ca4-[11.3,14.9): 0.6871 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9067 - val_ca1-[11.3,14.9): 1.5510 - val_ca2-[8.0,9.5): 0.5908 - val_ca2-[9.5,10.3): 0.3897 - val_ca2-[10.3,11.3): 0.8155 - val_ca2-[11.3,14.9): 1.4235 - val_ca3-[8.0,9.5): 0.8824 - val_ca3-[9.5,10.3): 0.5127 - val_ca3-[10.3,11.3): 0.6589 - val_ca3-[11.3,14.9): 0.8547 - val_ca4-[8.0,9.5): 1.5648 - val_ca4-[9.5,10.3): 1.1325 - val_ca4-[10.3,11.3): 0.9814 - val_ca4-[11.3,14.9): 0.6953\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5053 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3580 - ca2-[9.5,10.3): 0.4557 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5267 - ca3-[10.3,11.3): 0.6169 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5440 - ca4-[11.3,14.9): 0.6913 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.5705 - val_ca2-[8.0,9.5): 0.5900 - val_ca2-[9.5,10.3): 0.3903 - val_ca2-[10.3,11.3): 0.8217 - val_ca2-[11.3,14.9): 1.4492 - val_ca3-[8.0,9.5): 0.8921 - val_ca3-[9.5,10.3): 0.5195 - val_ca3-[10.3,11.3): 0.6550 - val_ca3-[11.3,14.9): 0.8416 - val_ca4-[8.0,9.5): 1.5655 - val_ca4-[9.5,10.3): 1.1329 - val_ca4-[10.3,11.3): 0.9751 - val_ca4-[11.3,14.9): 0.6810\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5148 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3480 - ca2-[9.5,10.3): 0.4523 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5114 - ca3-[10.3,11.3): 0.6119 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5998 - ca4-[11.3,14.9): 0.6925 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9162 - val_ca1-[11.3,14.9): 1.5405 - val_ca2-[8.0,9.5): 0.5893 - val_ca2-[9.5,10.3): 0.3905 - val_ca2-[10.3,11.3): 0.8268 - val_ca2-[11.3,14.9): 1.4486 - val_ca3-[8.0,9.5): 0.8874 - val_ca3-[9.5,10.3): 0.5169 - val_ca3-[10.3,11.3): 0.6574 - val_ca3-[11.3,14.9): 0.8414 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1314 - val_ca4-[10.3,11.3): 0.9767 - val_ca4-[11.3,14.9): 0.6544\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5311 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3424 - ca2-[9.5,10.3): 0.4544 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5120 - ca3-[10.3,11.3): 0.6071 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5805 - ca4-[11.3,14.9): 0.6943 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9144 - val_ca1-[11.3,14.9): 1.5703 - val_ca2-[8.0,9.5): 0.5904 - val_ca2-[9.5,10.3): 0.3892 - val_ca2-[10.3,11.3): 0.8178 - val_ca2-[11.3,14.9): 1.4586 - val_ca3-[8.0,9.5): 0.8801 - val_ca3-[9.5,10.3): 0.5102 - val_ca3-[10.3,11.3): 0.6538 - val_ca3-[11.3,14.9): 0.8669 - val_ca4-[8.0,9.5): 1.5625 - val_ca4-[9.5,10.3): 1.1301 - val_ca4-[10.3,11.3): 0.9733 - val_ca4-[11.3,14.9): 0.6871\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5157 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3618 - ca2-[9.5,10.3): 0.4472 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5015 - ca3-[10.3,11.3): 0.6190 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5607 - ca4-[11.3,14.9): 0.6875 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9054 - val_ca1-[11.3,14.9): 1.5231 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.3898 - val_ca2-[10.3,11.3): 0.8166 - val_ca2-[11.3,14.9): 1.4093 - val_ca3-[8.0,9.5): 0.8876 - val_ca3-[9.5,10.3): 0.5164 - val_ca3-[10.3,11.3): 0.6528 - val_ca3-[11.3,14.9): 0.8226 - val_ca4-[8.0,9.5): 1.5632 - val_ca4-[9.5,10.3): 1.1305 - val_ca4-[10.3,11.3): 0.9772 - val_ca4-[11.3,14.9): 0.6926\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5135 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3657 - ca2-[9.5,10.3): 0.4477 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5337 - ca3-[10.3,11.3): 0.6060 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5616 - ca4-[11.3,14.9): 0.6915 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9104 - val_ca1-[11.3,14.9): 1.5698 - val_ca2-[8.0,9.5): 0.5900 - val_ca2-[9.5,10.3): 0.3883 - val_ca2-[10.3,11.3): 0.8141 - val_ca2-[11.3,14.9): 1.4402 - val_ca3-[8.0,9.5): 0.8745 - val_ca3-[9.5,10.3): 0.5074 - val_ca3-[10.3,11.3): 0.6537 - val_ca3-[11.3,14.9): 0.8679 - val_ca4-[8.0,9.5): 1.5623 - val_ca4-[9.5,10.3): 1.1296 - val_ca4-[10.3,11.3): 0.9582 - val_ca4-[11.3,14.9): 0.6867\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5213 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3530 - ca2-[9.5,10.3): 0.4500 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5237 - ca3-[10.3,11.3): 0.6137 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5972 - ca4-[11.3,14.9): 0.6871 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9135 - val_ca1-[11.3,14.9): 1.5401 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.3884 - val_ca2-[10.3,11.3): 0.8193 - val_ca2-[11.3,14.9): 1.4296 - val_ca3-[8.0,9.5): 0.8866 - val_ca3-[9.5,10.3): 0.5152 - val_ca3-[10.3,11.3): 0.6512 - val_ca3-[11.3,14.9): 0.8265 - val_ca4-[8.0,9.5): 1.5616 - val_ca4-[9.5,10.3): 1.1288 - val_ca4-[10.3,11.3): 0.9602 - val_ca4-[11.3,14.9): 0.6544\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5107 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3625 - ca2-[9.5,10.3): 0.4584 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5349 - ca3-[10.3,11.3): 0.6082 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5775 - ca4-[11.3,14.9): 0.6869 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9192 - val_ca1-[11.3,14.9): 1.5995 - val_ca2-[8.0,9.5): 0.5856 - val_ca2-[9.5,10.3): 0.3902 - val_ca2-[10.3,11.3): 0.8367 - val_ca2-[11.3,14.9): 1.5055 - val_ca3-[8.0,9.5): 0.8727 - val_ca3-[9.5,10.3): 0.5051 - val_ca3-[10.3,11.3): 0.6528 - val_ca3-[11.3,14.9): 0.8817 - val_ca4-[8.0,9.5): 1.5609 - val_ca4-[9.5,10.3): 1.1281 - val_ca4-[10.3,11.3): 0.9714 - val_ca4-[11.3,14.9): 0.7161\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5137 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3534 - ca2-[9.5,10.3): 0.4466 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5323 - ca3-[10.3,11.3): 0.6169 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5823 - ca4-[11.3,14.9): 0.7008 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9147 - val_ca1-[11.3,14.9): 1.5568 - val_ca2-[8.0,9.5): 0.5915 - val_ca2-[9.5,10.3): 0.3871 - val_ca2-[10.3,11.3): 0.8074 - val_ca2-[11.3,14.9): 1.4111 - val_ca3-[8.0,9.5): 0.8831 - val_ca3-[9.5,10.3): 0.5126 - val_ca3-[10.3,11.3): 0.6490 - val_ca3-[11.3,14.9): 0.8393 - val_ca4-[8.0,9.5): 1.5614 - val_ca4-[9.5,10.3): 1.1283 - val_ca4-[10.3,11.3): 0.9716 - val_ca4-[11.3,14.9): 0.6955\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5162 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3530 - ca2-[9.5,10.3): 0.4533 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5494 - ca3-[10.3,11.3): 0.6315 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5500 - ca4-[11.3,14.9): 0.6737 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9143 - val_ca1-[11.3,14.9): 1.5505 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.3882 - val_ca2-[10.3,11.3): 0.8220 - val_ca2-[11.3,14.9): 1.4459 - val_ca3-[8.0,9.5): 0.8890 - val_ca3-[9.5,10.3): 0.5159 - val_ca3-[10.3,11.3): 0.6484 - val_ca3-[11.3,14.9): 0.8241 - val_ca4-[8.0,9.5): 1.5609 - val_ca4-[9.5,10.3): 1.1277 - val_ca4-[10.3,11.3): 0.9711 - val_ca4-[11.3,14.9): 0.6717\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5115 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3676 - ca2-[9.5,10.3): 0.4568 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5272 - ca3-[10.3,11.3): 0.6101 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5743 - ca4-[11.3,14.9): 0.6915 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9119 - val_ca1-[11.3,14.9): 1.5960 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.3879 - val_ca2-[10.3,11.3): 0.8219 - val_ca2-[11.3,14.9): 1.4911 - val_ca3-[8.0,9.5): 0.8629 - val_ca3-[9.5,10.3): 0.4974 - val_ca3-[10.3,11.3): 0.6513 - val_ca3-[11.3,14.9): 0.8830 - val_ca4-[8.0,9.5): 1.5607 - val_ca4-[9.5,10.3): 1.1273 - val_ca4-[10.3,11.3): 0.9753 - val_ca4-[11.3,14.9): 0.7166\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5135 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3473 - ca2-[9.5,10.3): 0.4375 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5492 - ca3-[10.3,11.3): 0.6159 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5854 - ca4-[11.3,14.9): 0.6978 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9094 - val_ca1-[11.3,14.9): 1.6048 - val_ca2-[8.0,9.5): 0.5899 - val_ca2-[9.5,10.3): 0.3862 - val_ca2-[10.3,11.3): 0.8063 - val_ca2-[11.3,14.9): 1.4643 - val_ca3-[8.0,9.5): 0.8841 - val_ca3-[9.5,10.3): 0.5140 - val_ca3-[10.3,11.3): 0.6509 - val_ca3-[11.3,14.9): 0.8652 - val_ca4-[8.0,9.5): 1.5619 - val_ca4-[9.5,10.3): 1.1281 - val_ca4-[10.3,11.3): 0.9639 - val_ca4-[11.3,14.9): 0.6993\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5244 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3486 - ca2-[9.5,10.3): 0.4472 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5510 - ca3-[10.3,11.3): 0.6129 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5716 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9144 - val_ca1-[11.3,14.9): 1.5958 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3884 - val_ca2-[10.3,11.3): 0.8238 - val_ca2-[11.3,14.9): 1.4899 - val_ca3-[8.0,9.5): 0.8589 - val_ca3-[9.5,10.3): 0.4948 - val_ca3-[10.3,11.3): 0.6474 - val_ca3-[11.3,14.9): 0.8815 - val_ca4-[8.0,9.5): 1.5625 - val_ca4-[9.5,10.3): 1.1284 - val_ca4-[10.3,11.3): 0.9713 - val_ca4-[11.3,14.9): 0.7164\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5142 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3467 - ca2-[9.5,10.3): 0.4380 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5123 - ca3-[10.3,11.3): 0.6184 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5657 - ca4-[11.3,14.9): 0.6992 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9098 - val_ca1-[11.3,14.9): 1.5828 - val_ca2-[8.0,9.5): 0.5925 - val_ca2-[9.5,10.3): 0.3855 - val_ca2-[10.3,11.3): 0.7950 - val_ca2-[11.3,14.9): 1.4189 - val_ca3-[8.0,9.5): 0.8755 - val_ca3-[9.5,10.3): 0.5063 - val_ca3-[10.3,11.3): 0.6433 - val_ca3-[11.3,14.9): 0.8533 - val_ca4-[8.0,9.5): 1.5621 - val_ca4-[9.5,10.3): 1.1278 - val_ca4-[10.3,11.3): 0.9727 - val_ca4-[11.3,14.9): 0.7037\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5121 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3417 - ca2-[9.5,10.3): 0.4464 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5203 - ca3-[10.3,11.3): 0.6102 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5433 - ca4-[11.3,14.9): 0.6945 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9191 - val_ca1-[11.3,14.9): 1.5800 - val_ca2-[8.0,9.5): 0.5844 - val_ca2-[9.5,10.3): 0.3880 - val_ca2-[10.3,11.3): 0.8305 - val_ca2-[11.3,14.9): 1.4860 - val_ca3-[8.0,9.5): 0.8600 - val_ca3-[9.5,10.3): 0.4964 - val_ca3-[10.3,11.3): 0.6480 - val_ca3-[11.3,14.9): 0.8540 - val_ca4-[8.0,9.5): 1.5597 - val_ca4-[9.5,10.3): 1.1255 - val_ca4-[10.3,11.3): 0.9691 - val_ca4-[11.3,14.9): 0.6953\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5179 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3385 - ca2-[9.5,10.3): 0.4227 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5052 - ca3-[10.3,11.3): 0.6115 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5643 - ca4-[11.3,14.9): 0.6893 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9150 - val_ca1-[11.3,14.9): 1.6108 - val_ca2-[8.0,9.5): 0.5918 - val_ca2-[9.5,10.3): 0.3837 - val_ca2-[10.3,11.3): 0.7949 - val_ca2-[11.3,14.9): 1.4335 - val_ca3-[8.0,9.5): 0.8701 - val_ca3-[9.5,10.3): 0.5040 - val_ca3-[10.3,11.3): 0.6446 - val_ca3-[11.3,14.9): 0.8655 - val_ca4-[8.0,9.5): 1.5570 - val_ca4-[9.5,10.3): 1.1229 - val_ca4-[10.3,11.3): 0.9678 - val_ca4-[11.3,14.9): 0.7114\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5180 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3524 - ca2-[9.5,10.3): 0.4399 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5510 - ca3-[10.3,11.3): 0.6126 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5558 - ca4-[11.3,14.9): 0.6913 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9208 - val_ca1-[11.3,14.9): 1.5521 - val_ca2-[8.0,9.5): 0.5833 - val_ca2-[9.5,10.3): 0.3862 - val_ca2-[10.3,11.3): 0.8247 - val_ca2-[11.3,14.9): 1.4542 - val_ca3-[8.0,9.5): 0.8433 - val_ca3-[9.5,10.3): 0.4871 - val_ca3-[10.3,11.3): 0.6511 - val_ca3-[11.3,14.9): 0.8626 - val_ca4-[8.0,9.5): 1.5560 - val_ca4-[9.5,10.3): 1.1250 - val_ca4-[10.3,11.3): 0.9748 - val_ca4-[11.3,14.9): 0.6899\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5199 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3482 - ca2-[9.5,10.3): 0.4349 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4918 - ca3-[10.3,11.3): 0.6086 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5560 - ca4-[11.3,14.9): 0.6742 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9052 - val_ca1-[11.3,14.9): 1.5828 - val_ca2-[8.0,9.5): 0.5856 - val_ca2-[9.5,10.3): 0.3835 - val_ca2-[10.3,11.3): 0.7958 - val_ca2-[11.3,14.9): 1.4367 - val_ca3-[8.0,9.5): 0.8718 - val_ca3-[9.5,10.3): 0.5067 - val_ca3-[10.3,11.3): 0.6367 - val_ca3-[11.3,14.9): 0.8390 - val_ca4-[8.0,9.5): 1.5569 - val_ca4-[9.5,10.3): 1.1223 - val_ca4-[10.3,11.3): 0.9707 - val_ca4-[11.3,14.9): 0.7079\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5267 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3514 - ca2-[9.5,10.3): 0.4411 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5327 - ca3-[10.3,11.3): 0.6069 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5267 - ca4-[11.3,14.9): 0.6851 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9122 - val_ca1-[11.3,14.9): 1.5758 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3844 - val_ca2-[10.3,11.3): 0.8063 - val_ca2-[11.3,14.9): 1.4426 - val_ca3-[8.0,9.5): 0.8334 - val_ca3-[9.5,10.3): 0.4819 - val_ca3-[10.3,11.3): 0.6475 - val_ca3-[11.3,14.9): 0.8797 - val_ca4-[8.0,9.5): 1.5569 - val_ca4-[9.5,10.3): 1.1195 - val_ca4-[10.3,11.3): 0.9659 - val_ca4-[11.3,14.9): 0.6813\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5175 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3442 - ca2-[9.5,10.3): 0.4304 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4754 - ca3-[10.3,11.3): 0.5887 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6037 - ca4-[11.3,14.9): 0.6784 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9159 - val_ca1-[11.3,14.9): 1.5954 - val_ca2-[8.0,9.5): 0.5824 - val_ca2-[9.5,10.3): 0.3847 - val_ca2-[10.3,11.3): 0.8222 - val_ca2-[11.3,14.9): 1.4846 - val_ca3-[8.0,9.5): 0.8765 - val_ca3-[9.5,10.3): 0.5118 - val_ca3-[10.3,11.3): 0.6434 - val_ca3-[11.3,14.9): 0.8380 - val_ca4-[8.0,9.5): 1.5555 - val_ca4-[9.5,10.3): 1.1205 - val_ca4-[10.3,11.3): 0.9684 - val_ca4-[11.3,14.9): 0.7036\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3543 - ca2-[9.5,10.3): 0.4314 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5004 - ca3-[10.3,11.3): 0.5933 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5398 - ca4-[11.3,14.9): 0.6846 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9158 - val_ca1-[11.3,14.9): 1.5973 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3838 - val_ca2-[10.3,11.3): 0.8052 - val_ca2-[11.3,14.9): 1.4490 - val_ca3-[8.0,9.5): 0.8426 - val_ca3-[9.5,10.3): 0.4893 - val_ca3-[10.3,11.3): 0.6427 - val_ca3-[11.3,14.9): 0.8767 - val_ca4-[8.0,9.5): 1.5540 - val_ca4-[9.5,10.3): 1.1221 - val_ca4-[10.3,11.3): 0.9673 - val_ca4-[11.3,14.9): 0.7134\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5247 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3341 - ca2-[9.5,10.3): 0.4272 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5187 - ca3-[10.3,11.3): 0.5997 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5800 - ca4-[11.3,14.9): 0.6969 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9105 - val_ca1-[11.3,14.9): 1.5902 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.3807 - val_ca2-[10.3,11.3): 0.7894 - val_ca2-[11.3,14.9): 1.4124 - val_ca3-[8.0,9.5): 0.8481 - val_ca3-[9.5,10.3): 0.4922 - val_ca3-[10.3,11.3): 0.6395 - val_ca3-[11.3,14.9): 0.8562 - val_ca4-[8.0,9.5): 1.5561 - val_ca4-[9.5,10.3): 1.1202 - val_ca4-[10.3,11.3): 0.9512 - val_ca4-[11.3,14.9): 0.6854\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5187 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3293 - ca2-[9.5,10.3): 0.4324 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5243 - ca3-[10.3,11.3): 0.6056 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5264 - ca4-[11.3,14.9): 0.6979 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9096 - val_ca1-[11.3,14.9): 1.5629 - val_ca2-[8.0,9.5): 0.5826 - val_ca2-[9.5,10.3): 0.3828 - val_ca2-[10.3,11.3): 0.8072 - val_ca2-[11.3,14.9): 1.4396 - val_ca3-[8.0,9.5): 0.8442 - val_ca3-[9.5,10.3): 0.4904 - val_ca3-[10.3,11.3): 0.6381 - val_ca3-[11.3,14.9): 0.8411 - val_ca4-[8.0,9.5): 1.5570 - val_ca4-[9.5,10.3): 1.1205 - val_ca4-[10.3,11.3): 0.9673 - val_ca4-[11.3,14.9): 0.6876\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5126 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3492 - ca2-[9.5,10.3): 0.4396 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5261 - ca3-[10.3,11.3): 0.5948 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5455 - ca4-[11.3,14.9): 0.6754 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9053 - val_ca1-[11.3,14.9): 1.5896 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.3807 - val_ca2-[10.3,11.3): 0.7788 - val_ca2-[11.3,14.9): 1.4141 - val_ca3-[8.0,9.5): 0.8359 - val_ca3-[9.5,10.3): 0.4872 - val_ca3-[10.3,11.3): 0.6314 - val_ca3-[11.3,14.9): 0.8528 - val_ca4-[8.0,9.5): 1.5586 - val_ca4-[9.5,10.3): 1.1215 - val_ca4-[10.3,11.3): 0.9693 - val_ca4-[11.3,14.9): 0.7073\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5260 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3175 - ca2-[9.5,10.3): 0.4286 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5020 - ca3-[10.3,11.3): 0.6015 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5684 - ca4-[11.3,14.9): 0.6865 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9130 - val_ca1-[11.3,14.9): 1.5910 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3812 - val_ca2-[10.3,11.3): 0.7983 - val_ca2-[11.3,14.9): 1.4462 - val_ca3-[8.0,9.5): 0.8421 - val_ca3-[9.5,10.3): 0.4921 - val_ca3-[10.3,11.3): 0.6408 - val_ca3-[11.3,14.9): 0.8559 - val_ca4-[8.0,9.5): 1.5587 - val_ca4-[9.5,10.3): 1.1212 - val_ca4-[10.3,11.3): 0.9724 - val_ca4-[11.3,14.9): 0.6954\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5063 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3402 - ca2-[9.5,10.3): 0.4276 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5033 - ca3-[10.3,11.3): 0.5909 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5330 - ca4-[11.3,14.9): 0.6771 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9177 - val_ca1-[11.3,14.9): 1.6013 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.3805 - val_ca2-[10.3,11.3): 0.7980 - val_ca2-[11.3,14.9): 1.4368 - val_ca3-[8.0,9.5): 0.8242 - val_ca3-[9.5,10.3): 0.4812 - val_ca3-[10.3,11.3): 0.6408 - val_ca3-[11.3,14.9): 0.8726 - val_ca4-[8.0,9.5): 1.5554 - val_ca4-[9.5,10.3): 1.1177 - val_ca4-[10.3,11.3): 0.9626 - val_ca4-[11.3,14.9): 0.7020\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5206 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3151 - ca2-[9.5,10.3): 0.4234 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5077 - ca3-[10.3,11.3): 0.5940 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5957 - ca4-[11.3,14.9): 0.6896 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9174 - val_ca1-[11.3,14.9): 1.6074 - val_ca2-[8.0,9.5): 0.5941 - val_ca2-[9.5,10.3): 0.3793 - val_ca2-[10.3,11.3): 0.7741 - val_ca2-[11.3,14.9): 1.3805 - val_ca3-[8.0,9.5): 0.8350 - val_ca3-[9.5,10.3): 0.4904 - val_ca3-[10.3,11.3): 0.6383 - val_ca3-[11.3,14.9): 0.8613 - val_ca4-[8.0,9.5): 1.5563 - val_ca4-[9.5,10.3): 1.1180 - val_ca4-[10.3,11.3): 0.9681 - val_ca4-[11.3,14.9): 0.7135\n",
      "Epoch 273/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5042 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3348 - ca2-[9.5,10.3): 0.4346 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5276 - ca3-[10.3,11.3): 0.5991 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5477 - ca4-[11.3,14.9): 0.6859 - val_ca1-[8.0,9.5): 0.5837 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9132 - val_ca1-[11.3,14.9): 1.5695 - val_ca2-[8.0,9.5): 0.5800 - val_ca2-[9.5,10.3): 0.3796 - val_ca2-[10.3,11.3): 0.8065 - val_ca2-[11.3,14.9): 1.4367 - val_ca3-[8.0,9.5): 0.8190 - val_ca3-[9.5,10.3): 0.4782 - val_ca3-[10.3,11.3): 0.6330 - val_ca3-[11.3,14.9): 0.8479 - val_ca4-[8.0,9.5): 1.5632 - val_ca4-[9.5,10.3): 1.1229 - val_ca4-[10.3,11.3): 0.9636 - val_ca4-[11.3,14.9): 0.7023\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5144 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3299 - ca2-[9.5,10.3): 0.4228 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5076 - ca3-[10.3,11.3): 0.5898 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5826 - ca4-[11.3,14.9): 0.6749 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9087 - val_ca1-[11.3,14.9): 1.5938 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.3787 - val_ca2-[10.3,11.3): 0.7917 - val_ca2-[11.3,14.9): 1.4453 - val_ca3-[8.0,9.5): 0.8093 - val_ca3-[9.5,10.3): 0.4734 - val_ca3-[10.3,11.3): 0.6318 - val_ca3-[11.3,14.9): 0.8693 - val_ca4-[8.0,9.5): 1.5546 - val_ca4-[9.5,10.3): 1.1151 - val_ca4-[10.3,11.3): 0.9626 - val_ca4-[11.3,14.9): 0.7057\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5197 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3358 - ca2-[9.5,10.3): 0.4336 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5109 - ca3-[10.3,11.3): 0.5965 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5889 - ca4-[11.3,14.9): 0.6759 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9081 - val_ca1-[11.3,14.9): 1.5864 - val_ca2-[8.0,9.5): 0.5897 - val_ca2-[9.5,10.3): 0.3779 - val_ca2-[10.3,11.3): 0.7709 - val_ca2-[11.3,14.9): 1.3876 - val_ca3-[8.0,9.5): 0.8023 - val_ca3-[9.5,10.3): 0.4706 - val_ca3-[10.3,11.3): 0.6327 - val_ca3-[11.3,14.9): 0.8702 - val_ca4-[8.0,9.5): 1.5520 - val_ca4-[9.5,10.3): 1.1122 - val_ca4-[10.3,11.3): 0.9605 - val_ca4-[11.3,14.9): 0.6947\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3328 - ca2-[9.5,10.3): 0.4274 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5148 - ca3-[10.3,11.3): 0.5781 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5728 - ca4-[11.3,14.9): 0.6811 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9100 - val_ca1-[11.3,14.9): 1.5730 - val_ca2-[8.0,9.5): 0.5839 - val_ca2-[9.5,10.3): 0.3783 - val_ca2-[10.3,11.3): 0.7892 - val_ca2-[11.3,14.9): 1.4134 - val_ca3-[8.0,9.5): 0.8163 - val_ca3-[9.5,10.3): 0.4818 - val_ca3-[10.3,11.3): 0.6328 - val_ca3-[11.3,14.9): 0.8374 - val_ca4-[8.0,9.5): 1.5511 - val_ca4-[9.5,10.3): 1.1107 - val_ca4-[10.3,11.3): 0.9618 - val_ca4-[11.3,14.9): 0.6917\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5095 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3297 - ca2-[9.5,10.3): 0.4257 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5027 - ca3-[10.3,11.3): 0.5770 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5707 - ca4-[11.3,14.9): 0.6875 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9103 - val_ca1-[11.3,14.9): 1.5664 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.3783 - val_ca2-[10.3,11.3): 0.7893 - val_ca2-[11.3,14.9): 1.4102 - val_ca3-[8.0,9.5): 0.8064 - val_ca3-[9.5,10.3): 0.4752 - val_ca3-[10.3,11.3): 0.6308 - val_ca3-[11.3,14.9): 0.8418 - val_ca4-[8.0,9.5): 1.5540 - val_ca4-[9.5,10.3): 1.1126 - val_ca4-[10.3,11.3): 0.9624 - val_ca4-[11.3,14.9): 0.7011\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3295 - ca2-[9.5,10.3): 0.4193 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4926 - ca3-[10.3,11.3): 0.5873 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5265 - ca4-[11.3,14.9): 0.6946 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9116 - val_ca1-[11.3,14.9): 1.5877 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.3771 - val_ca2-[10.3,11.3): 0.7778 - val_ca2-[11.3,14.9): 1.3923 - val_ca3-[8.0,9.5): 0.8023 - val_ca3-[9.5,10.3): 0.4711 - val_ca3-[10.3,11.3): 0.6322 - val_ca3-[11.3,14.9): 0.8476 - val_ca4-[8.0,9.5): 1.5538 - val_ca4-[9.5,10.3): 1.1116 - val_ca4-[10.3,11.3): 0.9642 - val_ca4-[11.3,14.9): 0.7017\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5115 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3242 - ca2-[9.5,10.3): 0.4231 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4927 - ca3-[10.3,11.3): 0.5905 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5543 - ca4-[11.3,14.9): 0.6893 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9123 - val_ca1-[11.3,14.9): 1.5588 - val_ca2-[8.0,9.5): 0.5830 - val_ca2-[9.5,10.3): 0.3772 - val_ca2-[10.3,11.3): 0.7898 - val_ca2-[11.3,14.9): 1.3970 - val_ca3-[8.0,9.5): 0.7862 - val_ca3-[9.5,10.3): 0.4624 - val_ca3-[10.3,11.3): 0.6301 - val_ca3-[11.3,14.9): 0.8385 - val_ca4-[8.0,9.5): 1.5541 - val_ca4-[9.5,10.3): 1.1111 - val_ca4-[10.3,11.3): 0.9565 - val_ca4-[11.3,14.9): 0.6875\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3296 - ca2-[9.5,10.3): 0.4211 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4922 - ca3-[10.3,11.3): 0.5810 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5699 - ca4-[11.3,14.9): 0.6963 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9105 - val_ca1-[11.3,14.9): 1.5671 - val_ca2-[8.0,9.5): 0.5907 - val_ca2-[9.5,10.3): 0.3752 - val_ca2-[10.3,11.3): 0.7695 - val_ca2-[11.3,14.9): 1.3580 - val_ca3-[8.0,9.5): 0.8094 - val_ca3-[9.5,10.3): 0.4795 - val_ca3-[10.3,11.3): 0.6301 - val_ca3-[11.3,14.9): 0.8163 - val_ca4-[8.0,9.5): 1.5522 - val_ca4-[9.5,10.3): 1.1087 - val_ca4-[10.3,11.3): 0.9435 - val_ca4-[11.3,14.9): 0.6551\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5146 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3347 - ca2-[9.5,10.3): 0.4219 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5260 - ca3-[10.3,11.3): 0.5953 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5295 - ca4-[11.3,14.9): 0.6816 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9108 - val_ca1-[11.3,14.9): 1.5944 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3755 - val_ca2-[10.3,11.3): 0.7751 - val_ca2-[11.3,14.9): 1.3990 - val_ca3-[8.0,9.5): 0.7645 - val_ca3-[9.5,10.3): 0.4491 - val_ca3-[10.3,11.3): 0.6277 - val_ca3-[11.3,14.9): 0.8712 - val_ca4-[8.0,9.5): 1.5512 - val_ca4-[9.5,10.3): 1.1070 - val_ca4-[10.3,11.3): 0.9577 - val_ca4-[11.3,14.9): 0.7015\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5259 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3302 - ca2-[9.5,10.3): 0.4186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4941 - ca3-[10.3,11.3): 0.5895 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5686 - ca4-[11.3,14.9): 0.6870 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9085 - val_ca1-[11.3,14.9): 1.5735 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3751 - val_ca2-[10.3,11.3): 0.7703 - val_ca2-[11.3,14.9): 1.3734 - val_ca3-[8.0,9.5): 0.7768 - val_ca3-[9.5,10.3): 0.4593 - val_ca3-[10.3,11.3): 0.6234 - val_ca3-[11.3,14.9): 0.8439 - val_ca4-[8.0,9.5): 1.5506 - val_ca4-[9.5,10.3): 1.1057 - val_ca4-[10.3,11.3): 0.9540 - val_ca4-[11.3,14.9): 0.6998\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5118 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3186 - ca2-[9.5,10.3): 0.4168 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5053 - ca3-[10.3,11.3): 0.5882 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5681 - ca4-[11.3,14.9): 0.6765 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.8998 - val_ca1-[11.3,14.9): 1.5937 - val_ca2-[8.0,9.5): 0.5838 - val_ca2-[9.5,10.3): 0.3748 - val_ca2-[10.3,11.3): 0.7707 - val_ca2-[11.3,14.9): 1.4185 - val_ca3-[8.0,9.5): 0.8034 - val_ca3-[9.5,10.3): 0.4805 - val_ca3-[10.3,11.3): 0.6169 - val_ca3-[11.3,14.9): 0.8163 - val_ca4-[8.0,9.5): 1.5524 - val_ca4-[9.5,10.3): 1.1064 - val_ca4-[10.3,11.3): 0.9416 - val_ca4-[11.3,14.9): 0.6900\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5159 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3348 - ca2-[9.5,10.3): 0.4203 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5153 - ca3-[10.3,11.3): 0.5819 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5670 - ca4-[11.3,14.9): 0.6776 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9041 - val_ca1-[11.3,14.9): 1.5804 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.3726 - val_ca2-[10.3,11.3): 0.7596 - val_ca2-[11.3,14.9): 1.3644 - val_ca3-[8.0,9.5): 0.7376 - val_ca3-[9.5,10.3): 0.4369 - val_ca3-[10.3,11.3): 0.6254 - val_ca3-[11.3,14.9): 0.8814 - val_ca4-[8.0,9.5): 1.5510 - val_ca4-[9.5,10.3): 1.1043 - val_ca4-[10.3,11.3): 0.9541 - val_ca4-[11.3,14.9): 0.7047\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5290 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3313 - ca2-[9.5,10.3): 0.4132 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4614 - ca3-[10.3,11.3): 0.5700 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5636 - ca4-[11.3,14.9): 0.6837 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9131 - val_ca1-[11.3,14.9): 1.5673 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.3734 - val_ca2-[10.3,11.3): 0.7653 - val_ca2-[11.3,14.9): 1.3477 - val_ca3-[8.0,9.5): 0.7643 - val_ca3-[9.5,10.3): 0.4549 - val_ca3-[10.3,11.3): 0.6227 - val_ca3-[11.3,14.9): 0.8266 - val_ca4-[8.0,9.5): 1.5489 - val_ca4-[9.5,10.3): 1.1015 - val_ca4-[10.3,11.3): 0.9481 - val_ca4-[11.3,14.9): 0.6913\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5138 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3173 - ca2-[9.5,10.3): 0.4108 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4731 - ca3-[10.3,11.3): 0.5725 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5292 - ca4-[11.3,14.9): 0.6871 - val_ca1-[8.0,9.5): 0.5825 - val_ca1-[9.5,10.3): 0.4141 - val_ca1-[10.3,11.3): 0.9091 - val_ca1-[11.3,14.9): 1.5860 - val_ca2-[8.0,9.5): 0.5815 - val_ca2-[9.5,10.3): 0.3672 - val_ca2-[10.3,11.3): 0.7777 - val_ca2-[11.3,14.9): 1.4147 - val_ca3-[8.0,9.5): 0.7412 - val_ca3-[9.5,10.3): 0.4377 - val_ca3-[10.3,11.3): 0.6195 - val_ca3-[11.3,14.9): 0.8565 - val_ca4-[8.0,9.5): 1.5459 - val_ca4-[9.5,10.3): 1.1000 - val_ca4-[10.3,11.3): 0.9471 - val_ca4-[11.3,14.9): 0.6651\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5248 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3247 - ca2-[9.5,10.3): 0.4103 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4830 - ca3-[10.3,11.3): 0.5731 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5739 - ca4-[11.3,14.9): 0.6867 - val_ca1-[8.0,9.5): 0.5825 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.8952 - val_ca1-[11.3,14.9): 1.5841 - val_ca2-[8.0,9.5): 0.5902 - val_ca2-[9.5,10.3): 0.3707 - val_ca2-[10.3,11.3): 0.7326 - val_ca2-[11.3,14.9): 1.3268 - val_ca3-[8.0,9.5): 0.7249 - val_ca3-[9.5,10.3): 0.4327 - val_ca3-[10.3,11.3): 0.6136 - val_ca3-[11.3,14.9): 0.8664 - val_ca4-[8.0,9.5): 1.5424 - val_ca4-[9.5,10.3): 1.0938 - val_ca4-[10.3,11.3): 0.9436 - val_ca4-[11.3,14.9): 0.6909\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5261 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3228 - ca2-[9.5,10.3): 0.4074 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4655 - ca3-[10.3,11.3): 0.5675 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5648 - ca4-[11.3,14.9): 0.6815 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9129 - val_ca1-[11.3,14.9): 1.5605 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3699 - val_ca2-[10.3,11.3): 0.7564 - val_ca2-[11.3,14.9): 1.3203 - val_ca3-[8.0,9.5): 0.8023 - val_ca3-[9.5,10.3): 0.4857 - val_ca3-[10.3,11.3): 0.6203 - val_ca3-[11.3,14.9): 0.7765 - val_ca4-[8.0,9.5): 1.5372 - val_ca4-[9.5,10.3): 1.0867 - val_ca4-[10.3,11.3): 0.9369 - val_ca4-[11.3,14.9): 0.6818\n",
      "Epoch 289/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5203 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3189 - ca2-[9.5,10.3): 0.4111 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4834 - ca3-[10.3,11.3): 0.5753 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5311 - ca4-[11.3,14.9): 0.6706 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9140 - val_ca1-[11.3,14.9): 1.5787 - val_ca2-[8.0,9.5): 0.5832 - val_ca2-[9.5,10.3): 0.3704 - val_ca2-[10.3,11.3): 0.7697 - val_ca2-[11.3,14.9): 1.3529 - val_ca3-[8.0,9.5): 0.7845 - val_ca3-[9.5,10.3): 0.4751 - val_ca3-[10.3,11.3): 0.6197 - val_ca3-[11.3,14.9): 0.7868 - val_ca4-[8.0,9.5): 1.5325 - val_ca4-[9.5,10.3): 1.0805 - val_ca4-[10.3,11.3): 0.9345 - val_ca4-[11.3,14.9): 0.6815\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5246 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3191 - ca2-[9.5,10.3): 0.4211 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5392 - ca3-[10.3,11.3): 0.5718 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5956 - ca4-[11.3,14.9): 0.6739 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9097 - val_ca1-[11.3,14.9): 1.5816 - val_ca2-[8.0,9.5): 0.6055 - val_ca2-[9.5,10.3): 0.3727 - val_ca2-[10.3,11.3): 0.7164 - val_ca2-[11.3,14.9): 1.2268 - val_ca3-[8.0,9.5): 0.6934 - val_ca3-[9.5,10.3): 0.4157 - val_ca3-[10.3,11.3): 0.6192 - val_ca3-[11.3,14.9): 0.8782 - val_ca4-[8.0,9.5): 1.5387 - val_ca4-[9.5,10.3): 1.0840 - val_ca4-[10.3,11.3): 0.9370 - val_ca4-[11.3,14.9): 0.6895\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5163 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3391 - ca2-[9.5,10.3): 0.4182 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4897 - ca3-[10.3,11.3): 0.5709 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5564 - ca4-[11.3,14.9): 0.6793 - val_ca1-[8.0,9.5): 0.5823 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9131 - val_ca1-[11.3,14.9): 1.5678 - val_ca2-[8.0,9.5): 0.5828 - val_ca2-[9.5,10.3): 0.3710 - val_ca2-[10.3,11.3): 0.7645 - val_ca2-[11.3,14.9): 1.3276 - val_ca3-[8.0,9.5): 0.7155 - val_ca3-[9.5,10.3): 0.4329 - val_ca3-[10.3,11.3): 0.6173 - val_ca3-[11.3,14.9): 0.8276 - val_ca4-[8.0,9.5): 1.5404 - val_ca4-[9.5,10.3): 1.0835 - val_ca4-[10.3,11.3): 0.9306 - val_ca4-[11.3,14.9): 0.6751\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5234 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3226 - ca2-[9.5,10.3): 0.4119 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4849 - ca3-[10.3,11.3): 0.5642 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5526 - ca4-[11.3,14.9): 0.6703 - val_ca1-[8.0,9.5): 0.5821 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9143 - val_ca1-[11.3,14.9): 1.5646 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.3699 - val_ca2-[10.3,11.3): 0.7567 - val_ca2-[11.3,14.9): 1.3181 - val_ca3-[8.0,9.5): 0.7474 - val_ca3-[9.5,10.3): 0.4563 - val_ca3-[10.3,11.3): 0.6154 - val_ca3-[11.3,14.9): 0.7941 - val_ca4-[8.0,9.5): 1.5410 - val_ca4-[9.5,10.3): 1.0822 - val_ca4-[10.3,11.3): 0.9285 - val_ca4-[11.3,14.9): 0.6625\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5201 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3290 - ca2-[9.5,10.3): 0.4146 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5078 - ca3-[10.3,11.3): 0.5825 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5414 - ca4-[11.3,14.9): 0.6612 - val_ca1-[8.0,9.5): 0.5819 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9173 - val_ca1-[11.3,14.9): 1.6082 - val_ca2-[8.0,9.5): 0.5917 - val_ca2-[9.5,10.3): 0.3684 - val_ca2-[10.3,11.3): 0.7395 - val_ca2-[11.3,14.9): 1.3024 - val_ca3-[8.0,9.5): 0.7121 - val_ca3-[9.5,10.3): 0.4313 - val_ca3-[10.3,11.3): 0.6163 - val_ca3-[11.3,14.9): 0.8555 - val_ca4-[8.0,9.5): 1.5325 - val_ca4-[9.5,10.3): 1.0719 - val_ca4-[10.3,11.3): 0.9184 - val_ca4-[11.3,14.9): 0.6860\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3234 - ca2-[9.5,10.3): 0.4104 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4858 - ca3-[10.3,11.3): 0.5742 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5338 - ca4-[11.3,14.9): 0.6671 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5934 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3681 - val_ca2-[10.3,11.3): 0.7498 - val_ca2-[11.3,14.9): 1.3230 - val_ca3-[8.0,9.5): 0.7210 - val_ca3-[9.5,10.3): 0.4375 - val_ca3-[10.3,11.3): 0.6149 - val_ca3-[11.3,14.9): 0.8326 - val_ca4-[8.0,9.5): 1.5323 - val_ca4-[9.5,10.3): 1.0684 - val_ca4-[10.3,11.3): 0.9153 - val_ca4-[11.3,14.9): 0.6723\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5094 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3136 - ca2-[9.5,10.3): 0.4024 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4972 - ca3-[10.3,11.3): 0.5655 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5321 - ca4-[11.3,14.9): 0.6690 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9110 - val_ca1-[11.3,14.9): 1.5934 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.3670 - val_ca2-[10.3,11.3): 0.7414 - val_ca2-[11.3,14.9): 1.3120 - val_ca3-[8.0,9.5): 0.7162 - val_ca3-[9.5,10.3): 0.4380 - val_ca3-[10.3,11.3): 0.6135 - val_ca3-[11.3,14.9): 0.8339 - val_ca4-[8.0,9.5): 1.5434 - val_ca4-[9.5,10.3): 1.0755 - val_ca4-[10.3,11.3): 0.9183 - val_ca4-[11.3,14.9): 0.6826\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5197 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3113 - ca2-[9.5,10.3): 0.4029 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4699 - ca3-[10.3,11.3): 0.5567 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5525 - ca4-[11.3,14.9): 0.6607 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.8925 - val_ca1-[11.3,14.9): 1.5701 - val_ca2-[8.0,9.5): 0.5824 - val_ca2-[9.5,10.3): 0.3677 - val_ca2-[10.3,11.3): 0.7396 - val_ca2-[11.3,14.9): 1.3152 - val_ca3-[8.0,9.5): 0.7161 - val_ca3-[9.5,10.3): 0.4393 - val_ca3-[10.3,11.3): 0.6032 - val_ca3-[11.3,14.9): 0.8096 - val_ca4-[8.0,9.5): 1.5328 - val_ca4-[9.5,10.3): 1.0603 - val_ca4-[10.3,11.3): 0.8991 - val_ca4-[11.3,14.9): 0.6610\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3227 - ca2-[9.5,10.3): 0.4088 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4867 - ca3-[10.3,11.3): 0.5679 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5783 - ca4-[11.3,14.9): 0.6742 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9099 - val_ca1-[11.3,14.9): 1.5920 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3668 - val_ca2-[10.3,11.3): 0.7435 - val_ca2-[11.3,14.9): 1.3178 - val_ca3-[8.0,9.5): 0.7369 - val_ca3-[9.5,10.3): 0.4554 - val_ca3-[10.3,11.3): 0.6145 - val_ca3-[11.3,14.9): 0.7959 - val_ca4-[8.0,9.5): 1.5379 - val_ca4-[9.5,10.3): 1.0619 - val_ca4-[10.3,11.3): 0.9040 - val_ca4-[11.3,14.9): 0.6576\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5203 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3145 - ca2-[9.5,10.3): 0.4116 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5179 - ca3-[10.3,11.3): 0.5831 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5838 - ca4-[11.3,14.9): 0.6574 - val_ca1-[8.0,9.5): 0.5815 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9190 - val_ca1-[11.3,14.9): 1.5688 - val_ca2-[8.0,9.5): 0.5930 - val_ca2-[9.5,10.3): 0.3663 - val_ca2-[10.3,11.3): 0.7281 - val_ca2-[11.3,14.9): 1.2505 - val_ca3-[8.0,9.5): 0.7090 - val_ca3-[9.5,10.3): 0.4368 - val_ca3-[10.3,11.3): 0.6142 - val_ca3-[11.3,14.9): 0.8158 - val_ca4-[8.0,9.5): 1.5353 - val_ca4-[9.5,10.3): 1.0565 - val_ca4-[10.3,11.3): 0.8943 - val_ca4-[11.3,14.9): 0.6578\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5243 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3179 - ca2-[9.5,10.3): 0.4026 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4968 - ca3-[10.3,11.3): 0.5589 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5434 - ca4-[11.3,14.9): 0.6574 - val_ca1-[8.0,9.5): 0.5814 - val_ca1-[9.5,10.3): 0.4202 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.6082 - val_ca2-[8.0,9.5): 0.5823 - val_ca2-[9.5,10.3): 0.3676 - val_ca2-[10.3,11.3): 0.7564 - val_ca2-[11.3,14.9): 1.3541 - val_ca3-[8.0,9.5): 0.7107 - val_ca3-[9.5,10.3): 0.4396 - val_ca3-[10.3,11.3): 0.6125 - val_ca3-[11.3,14.9): 0.8236 - val_ca4-[8.0,9.5): 1.5364 - val_ca4-[9.5,10.3): 1.0557 - val_ca4-[10.3,11.3): 0.8844 - val_ca4-[11.3,14.9): 0.6697\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5280 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3245 - ca2-[9.5,10.3): 0.3988 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4752 - ca3-[10.3,11.3): 0.5509 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5352 - ca4-[11.3,14.9): 0.6497 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4199 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5833 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3669 - val_ca2-[10.3,11.3): 0.7539 - val_ca2-[11.3,14.9): 1.3299 - val_ca3-[8.0,9.5): 0.7317 - val_ca3-[9.5,10.3): 0.4529 - val_ca3-[10.3,11.3): 0.6177 - val_ca3-[11.3,14.9): 0.8013 - val_ca4-[8.0,9.5): 1.5394 - val_ca4-[9.5,10.3): 1.0541 - val_ca4-[10.3,11.3): 0.8774 - val_ca4-[11.3,14.9): 0.6570\n",
      "CPU times: user 4min 51s, sys: 3.58 s, total: 4min 54s\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('none')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2})') for ca,(q1,q2) in product(range(4),zip(quants[:-1],quants[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "\n",
    "history = m.fit(\n",
    "    train_dataset,\n",
    "#     validation_split=0.2,\n",
    "    epochs=300,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "# with open(os.path.join(fp_local,'no_sharing.pickle'), 'wb') as handle:\n",
    "#     pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "for k in [k for k in history.history if 'val_ca1' in k]:\n",
    "    plt.plot(history.history[k], label=k.split('-')[1])\n",
    "        \n",
    "plt.legend()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ca1-[8.0,9.5)</th>\n",
       "      <td>0.535245</td>\n",
       "      <td>0.581586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[9.5,10.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.419885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[10.3,11.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.913556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.583314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[8.0,9.5)</th>\n",
       "      <td>0.3199</td>\n",
       "      <td>0.584090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[9.5,10.3)</th>\n",
       "      <td>0.401625</td>\n",
       "      <td>0.366941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[10.3,11.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.753857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.329918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[8.0,9.5)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.731701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[9.5,10.3)</th>\n",
       "      <td>0.476711</td>\n",
       "      <td>0.452902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[10.3,11.3)</th>\n",
       "      <td>0.541894</td>\n",
       "      <td>0.617743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.801322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[8.0,9.5)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.539445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[9.5,10.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.054114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[10.3,11.3)</th>\n",
       "      <td>0.532472</td>\n",
       "      <td>0.877374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[11.3,14.9)</th>\n",
       "      <td>0.68225</td>\n",
       "      <td>0.657031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train      test\n",
       "ca1-[8.0,9.5)    0.535245  0.581586\n",
       "ca1-[9.5,10.3)          -  0.419885\n",
       "ca1-[10.3,11.3)         -  0.913556\n",
       "ca1-[11.3,14.9)         -  1.583314\n",
       "ca2-[8.0,9.5)      0.3199  0.584090\n",
       "ca2-[9.5,10.3)   0.401625  0.366941\n",
       "ca2-[10.3,11.3)         -  0.753857\n",
       "ca2-[11.3,14.9)         -  1.329918\n",
       "ca3-[8.0,9.5)           -  0.731701\n",
       "ca3-[9.5,10.3)   0.476711  0.452902\n",
       "ca3-[10.3,11.3)  0.541894  0.617743\n",
       "ca3-[11.3,14.9)         -  0.801322\n",
       "ca4-[8.0,9.5)           -  1.539445\n",
       "ca4-[9.5,10.3)          -  1.054114\n",
       "ca4-[10.3,11.3)  0.532472  0.877374\n",
       "ca4-[11.3,14.9)   0.68225  0.657031"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data=[[history.history[k][-1] if history.history[k][-1]!=0 else '-',history.history['val_'+k][-1]] for k in history.history if 'val' not in k],\n",
    "    index=[k for k in history.history if 'val' not in k],\n",
    "    columns=['train','test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 35.7258 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 25.1393 - ca2-[9.5,10.3): 26.3098 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 26.9516 - ca3-[10.3,11.3): 30.1896 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 33.9205 - ca4-[11.3,14.9): 36.9218 - val_ca1-[8.0,9.5): 33.2254 - val_ca1-[9.5,10.3): 34.7467 - val_ca1-[10.3,11.3): 39.3311 - val_ca1-[11.3,14.9): 45.7539 - val_ca2-[8.0,9.5): 23.8989 - val_ca2-[9.5,10.3): 25.1148 - val_ca2-[10.3,11.3): 29.0738 - val_ca2-[11.3,14.9): 34.6114 - val_ca3-[8.0,9.5): 22.7986 - val_ca3-[9.5,10.3): 24.0028 - val_ca3-[10.3,11.3): 27.8744 - val_ca3-[11.3,14.9): 33.2806 - val_ca4-[8.0,9.5): 24.2383 - val_ca4-[9.5,10.3): 25.4981 - val_ca4-[10.3,11.3): 29.4465 - val_ca4-[11.3,14.9): 34.9687\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 33.1961 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 23.4670 - ca2-[9.5,10.3): 24.4686 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 24.4398 - ca3-[10.3,11.3): 27.2946 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 31.6503 - ca4-[11.3,14.9): 34.1949 - val_ca1-[8.0,9.5): 30.8486 - val_ca1-[9.5,10.3): 32.3081 - val_ca1-[10.3,11.3): 36.7769 - val_ca1-[11.3,14.9): 43.2450 - val_ca2-[8.0,9.5): 22.1244 - val_ca2-[9.5,10.3): 23.2948 - val_ca2-[10.3,11.3): 27.1481 - val_ca2-[11.3,14.9): 32.7065 - val_ca3-[8.0,9.5): 20.4669 - val_ca3-[9.5,10.3): 21.6141 - val_ca3-[10.3,11.3): 25.3343 - val_ca3-[11.3,14.9): 30.6893 - val_ca4-[8.0,9.5): 22.1926 - val_ca4-[9.5,10.3): 23.3850 - val_ca4-[10.3,11.3): 27.2161 - val_ca4-[11.3,14.9): 32.7307\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 30.8041 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 21.4955 - ca2-[9.5,10.3): 22.5295 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 22.3297 - ca3-[10.3,11.3): 24.9286 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 29.5790 - ca4-[11.3,14.9): 31.8399 - val_ca1-[8.0,9.5): 28.5609 - val_ca1-[9.5,10.3): 29.9606 - val_ca1-[10.3,11.3): 34.1759 - val_ca1-[11.3,14.9): 40.4534 - val_ca2-[8.0,9.5): 20.4456 - val_ca2-[9.5,10.3): 21.5842 - val_ca2-[10.3,11.3): 25.2235 - val_ca2-[11.3,14.9): 30.6178 - val_ca3-[8.0,9.5): 18.3348 - val_ca3-[9.5,10.3): 19.4196 - val_ca3-[10.3,11.3): 22.8857 - val_ca3-[11.3,14.9): 28.0165 - val_ca4-[8.0,9.5): 20.3951 - val_ca4-[9.5,10.3): 21.5364 - val_ca4-[10.3,11.3): 25.1584 - val_ca4-[11.3,14.9): 30.5115\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 28.5347 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 20.1118 - ca2-[9.5,10.3): 20.8866 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 19.9292 - ca3-[10.3,11.3): 22.5084 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 27.7274 - ca4-[11.3,14.9): 29.7717 - val_ca1-[8.0,9.5): 26.3677 - val_ca1-[9.5,10.3): 27.7203 - val_ca1-[10.3,11.3): 31.8383 - val_ca1-[11.3,14.9): 37.9139 - val_ca2-[8.0,9.5): 18.8697 - val_ca2-[9.5,10.3): 19.9711 - val_ca2-[10.3,11.3): 23.5252 - val_ca2-[11.3,14.9): 28.7560 - val_ca3-[8.0,9.5): 16.4025 - val_ca3-[9.5,10.3): 17.4195 - val_ca3-[10.3,11.3): 20.7565 - val_ca3-[11.3,14.9): 25.6671 - val_ca4-[8.0,9.5): 18.8428 - val_ca4-[9.5,10.3): 19.9387 - val_ca4-[10.3,11.3): 23.4877 - val_ca4-[11.3,14.9): 28.6872\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 26.3318 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 18.4151 - ca2-[9.5,10.3): 19.4081 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 17.7157 - ca3-[10.3,11.3): 20.4025 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 25.3709 - ca4-[11.3,14.9): 28.0564 - val_ca1-[8.0,9.5): 24.3360 - val_ca1-[9.5,10.3): 25.6284 - val_ca1-[10.3,11.3): 29.6339 - val_ca1-[11.3,14.9): 35.2505 - val_ca2-[8.0,9.5): 17.3989 - val_ca2-[9.5,10.3): 18.4533 - val_ca2-[10.3,11.3): 21.9099 - val_ca2-[11.3,14.9): 26.7449 - val_ca3-[8.0,9.5): 14.6521 - val_ca3-[9.5,10.3): 15.6035 - val_ca3-[10.3,11.3): 18.8059 - val_ca3-[11.3,14.9): 23.2910 - val_ca4-[8.0,9.5): 17.4982 - val_ca4-[9.5,10.3): 18.5455 - val_ca4-[10.3,11.3): 22.0073 - val_ca4-[11.3,14.9): 26.8332\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 24.3896 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 17.1094 - ca2-[9.5,10.3): 18.0056 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 16.4028 - ca3-[10.3,11.3): 18.4630 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 24.3082 - ca4-[11.3,14.9): 26.4069 - val_ca1-[8.0,9.5): 22.4566 - val_ca1-[9.5,10.3): 23.6832 - val_ca1-[10.3,11.3): 27.5248 - val_ca1-[11.3,14.9): 32.8739 - val_ca2-[8.0,9.5): 16.0178 - val_ca2-[9.5,10.3): 17.0178 - val_ca2-[10.3,11.3): 20.3305 - val_ca2-[11.3,14.9): 24.9313 - val_ca3-[8.0,9.5): 13.0778 - val_ca3-[9.5,10.3): 13.9672 - val_ca3-[10.3,11.3): 16.9964 - val_ca3-[11.3,14.9): 21.2116 - val_ca4-[8.0,9.5): 16.2778 - val_ca4-[9.5,10.3): 17.2789 - val_ca4-[10.3,11.3): 20.6053 - val_ca4-[11.3,14.9): 25.2199\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 22.4155 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 15.5829 - ca2-[9.5,10.3): 16.4560 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 14.8242 - ca3-[10.3,11.3): 16.8171 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 22.7174 - ca4-[11.3,14.9): 24.8343 - val_ca1-[8.0,9.5): 20.7162 - val_ca1-[9.5,10.3): 21.8866 - val_ca1-[10.3,11.3): 25.6453 - val_ca1-[11.3,14.9): 30.8436 - val_ca2-[8.0,9.5): 14.7036 - val_ca2-[9.5,10.3): 15.6512 - val_ca2-[10.3,11.3): 18.8874 - val_ca2-[11.3,14.9): 23.3502 - val_ca3-[8.0,9.5): 11.6948 - val_ca3-[9.5,10.3): 12.5248 - val_ca3-[10.3,11.3): 15.4439 - val_ca3-[11.3,14.9): 19.4845 - val_ca4-[8.0,9.5): 15.1357 - val_ca4-[9.5,10.3): 16.0954 - val_ca4-[10.3,11.3): 19.3614 - val_ca4-[11.3,14.9): 23.8666\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 20.7461 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 14.1971 - ca2-[9.5,10.3): 15.0952 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 12.8437 - ca3-[10.3,11.3): 15.1714 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 21.0849 - ca4-[11.3,14.9): 23.5302 - val_ca1-[8.0,9.5): 19.1067 - val_ca1-[9.5,10.3): 20.2524 - val_ca1-[10.3,11.3): 23.7895 - val_ca1-[11.3,14.9): 28.8982 - val_ca2-[8.0,9.5): 13.4370 - val_ca2-[9.5,10.3): 14.3568 - val_ca2-[10.3,11.3): 17.3902 - val_ca2-[11.3,14.9): 21.7646 - val_ca3-[8.0,9.5): 10.4667 - val_ca3-[9.5,10.3): 11.2511 - val_ca3-[10.3,11.3): 13.9535 - val_ca3-[11.3,14.9): 17.8780 - val_ca4-[8.0,9.5): 14.0734 - val_ca4-[9.5,10.3): 15.0033 - val_ca4-[10.3,11.3): 18.0809 - val_ca4-[11.3,14.9): 22.5334\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 19.1940 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 13.1019 - ca2-[9.5,10.3): 13.9368 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 11.8617 - ca3-[10.3,11.3): 13.7542 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 20.2274 - ca4-[11.3,14.9): 22.1124 - val_ca1-[8.0,9.5): 17.6590 - val_ca1-[9.5,10.3): 18.7500 - val_ca1-[10.3,11.3): 22.1695 - val_ca1-[11.3,14.9): 27.3184 - val_ca2-[8.0,9.5): 12.2480 - val_ca2-[9.5,10.3): 13.1104 - val_ca2-[10.3,11.3): 16.0168 - val_ca2-[11.3,14.9): 20.4010 - val_ca3-[8.0,9.5): 9.3496 - val_ca3-[9.5,10.3): 10.0693 - val_ca3-[10.3,11.3): 12.6311 - val_ca3-[11.3,14.9): 16.5331 - val_ca4-[8.0,9.5): 13.0472 - val_ca4-[9.5,10.3): 13.9213 - val_ca4-[10.3,11.3): 16.8931 - val_ca4-[11.3,14.9): 21.3931\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 17.7674 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 11.8935 - ca2-[9.5,10.3): 12.6770 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 10.4863 - ca3-[10.3,11.3): 12.4852 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 19.1508 - ca4-[11.3,14.9): 20.7854 - val_ca1-[8.0,9.5): 16.3691 - val_ca1-[9.5,10.3): 17.4204 - val_ca1-[10.3,11.3): 20.7927 - val_ca1-[11.3,14.9): 25.4328 - val_ca2-[8.0,9.5): 11.1266 - val_ca2-[9.5,10.3): 11.9427 - val_ca2-[10.3,11.3): 14.7888 - val_ca2-[11.3,14.9): 18.7059 - val_ca3-[8.0,9.5): 8.3354 - val_ca3-[9.5,10.3): 9.0054 - val_ca3-[10.3,11.3): 11.4956 - val_ca3-[11.3,14.9): 14.9555 - val_ca4-[8.0,9.5): 12.0609 - val_ca4-[9.5,10.3): 12.8978 - val_ca4-[10.3,11.3): 15.8331 - val_ca4-[11.3,14.9): 19.8848\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 16.5079 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 10.6991 - ca2-[9.5,10.3): 11.5088 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 9.3907 - ca3-[10.3,11.3): 11.3383 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 17.6498 - ca4-[11.3,14.9): 19.6374 - val_ca1-[8.0,9.5): 15.1916 - val_ca1-[9.5,10.3): 16.2033 - val_ca1-[10.3,11.3): 19.4415 - val_ca1-[11.3,14.9): 23.9934 - val_ca2-[8.0,9.5): 10.0606 - val_ca2-[9.5,10.3): 10.8293 - val_ca2-[10.3,11.3): 13.5328 - val_ca2-[11.3,14.9): 17.3335 - val_ca3-[8.0,9.5): 7.4133 - val_ca3-[9.5,10.3): 8.0364 - val_ca3-[10.3,11.3): 10.3847 - val_ca3-[11.3,14.9): 13.7200 - val_ca4-[8.0,9.5): 11.1371 - val_ca4-[9.5,10.3): 11.9374 - val_ca4-[10.3,11.3): 14.7519 - val_ca4-[11.3,14.9): 18.7201\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 15.2283 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 9.8241 - ca2-[9.5,10.3): 10.4672 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 8.6765 - ca3-[10.3,11.3): 10.2870 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 16.3894 - ca4-[11.3,14.9): 18.4598 - val_ca1-[8.0,9.5): 14.0985 - val_ca1-[9.5,10.3): 15.0747 - val_ca1-[10.3,11.3): 18.2474 - val_ca1-[11.3,14.9): 22.5683 - val_ca2-[8.0,9.5): 9.0453 - val_ca2-[9.5,10.3): 9.7661 - val_ca2-[10.3,11.3): 12.3781 - val_ca2-[11.3,14.9): 15.9446 - val_ca3-[8.0,9.5): 6.5695 - val_ca3-[9.5,10.3): 7.1461 - val_ca3-[10.3,11.3): 9.4025 - val_ca3-[11.3,14.9): 12.5160 - val_ca4-[8.0,9.5): 10.2754 - val_ca4-[9.5,10.3): 11.0388 - val_ca4-[10.3,11.3): 13.7879 - val_ca4-[11.3,14.9): 17.5488\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 14.1972 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 8.6356 - ca2-[9.5,10.3): 9.3449 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 7.6186 - ca3-[10.3,11.3): 9.2956 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 15.6180 - ca4-[11.3,14.9): 17.3157 - val_ca1-[8.0,9.5): 13.1313 - val_ca1-[9.5,10.3): 14.0701 - val_ca1-[10.3,11.3): 17.1192 - val_ca1-[11.3,14.9): 21.5852 - val_ca2-[8.0,9.5): 8.0926 - val_ca2-[9.5,10.3): 8.7653 - val_ca2-[10.3,11.3): 11.2352 - val_ca2-[11.3,14.9): 14.8593 - val_ca3-[8.0,9.5): 5.8027 - val_ca3-[9.5,10.3): 6.3330 - val_ca3-[10.3,11.3): 8.4569 - val_ca3-[11.3,14.9): 11.6033 - val_ca4-[8.0,9.5): 9.4628 - val_ca4-[9.5,10.3): 10.1895 - val_ca4-[10.3,11.3): 12.8194 - val_ca4-[11.3,14.9): 16.6878\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 13.1797 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 7.7291 - ca2-[9.5,10.3): 8.4096 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 6.8764 - ca3-[10.3,11.3): 8.3032 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 14.6681 - ca4-[11.3,14.9): 16.1624 - val_ca1-[8.0,9.5): 12.2529 - val_ca1-[9.5,10.3): 13.1563 - val_ca1-[10.3,11.3): 16.1196 - val_ca1-[11.3,14.9): 20.3667 - val_ca2-[8.0,9.5): 7.2062 - val_ca2-[9.5,10.3): 7.8308 - val_ca2-[10.3,11.3): 10.1851 - val_ca2-[11.3,14.9): 13.5627 - val_ca3-[8.0,9.5): 5.1133 - val_ca3-[9.5,10.3): 5.5987 - val_ca3-[10.3,11.3): 7.6156 - val_ca3-[11.3,14.9): 10.5341 - val_ca4-[8.0,9.5): 8.6944 - val_ca4-[9.5,10.3): 9.3847 - val_ca4-[10.3,11.3): 11.9227 - val_ca4-[11.3,14.9): 15.5747\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 12.3214 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 6.9594 - ca2-[9.5,10.3): 7.5089 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 5.8323 - ca3-[10.3,11.3): 7.5013 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 13.5820 - ca4-[11.3,14.9): 15.1537 - val_ca1-[8.0,9.5): 11.4361 - val_ca1-[9.5,10.3): 12.3054 - val_ca1-[10.3,11.3): 15.1863 - val_ca1-[11.3,14.9): 19.3362 - val_ca2-[8.0,9.5): 6.3935 - val_ca2-[9.5,10.3): 6.9709 - val_ca2-[10.3,11.3): 9.2120 - val_ca2-[11.3,14.9): 12.4512 - val_ca3-[8.0,9.5): 4.4973 - val_ca3-[9.5,10.3): 4.9403 - val_ca3-[10.3,11.3): 6.8534 - val_ca3-[11.3,14.9): 9.6425 - val_ca4-[8.0,9.5): 7.9660 - val_ca4-[9.5,10.3): 8.6205 - val_ca4-[10.3,11.3): 11.0676 - val_ca4-[11.3,14.9): 14.6128\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 116ms/step - ca1-[8.0,9.5): 11.5362 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 6.0510 - ca2-[9.5,10.3): 6.6869 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 5.2929 - ca3-[10.3,11.3): 6.7702 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 12.8545 - ca4-[11.3,14.9): 14.3343 - val_ca1-[8.0,9.5): 10.6699 - val_ca1-[9.5,10.3): 11.5049 - val_ca1-[10.3,11.3): 14.3046 - val_ca1-[11.3,14.9): 18.1914 - val_ca2-[8.0,9.5): 5.6579 - val_ca2-[9.5,10.3): 6.1892 - val_ca2-[10.3,11.3): 8.3199 - val_ca2-[11.3,14.9): 11.2822 - val_ca3-[8.0,9.5): 3.9462 - val_ca3-[9.5,10.3): 4.3486 - val_ca3-[10.3,11.3): 6.1628 - val_ca3-[11.3,14.9): 8.7002 - val_ca4-[8.0,9.5): 7.2818 - val_ca4-[9.5,10.3): 7.9000 - val_ca4-[10.3,11.3): 10.2560 - val_ca4-[11.3,14.9): 13.5428\n",
      "Epoch 17/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 118ms/step - ca1-[8.0,9.5): 10.8251 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 5.3723 - ca2-[9.5,10.3): 5.9700 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 4.7088 - ca3-[10.3,11.3): 6.1380 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 11.7437 - ca4-[11.3,14.9): 13.3005 - val_ca1-[8.0,9.5): 9.9492 - val_ca1-[9.5,10.3): 10.7503 - val_ca1-[10.3,11.3): 13.4438 - val_ca1-[11.3,14.9): 17.2489 - val_ca2-[8.0,9.5): 4.9951 - val_ca2-[9.5,10.3): 5.4817 - val_ca2-[10.3,11.3): 7.4862 - val_ca2-[11.3,14.9): 10.3245 - val_ca3-[8.0,9.5): 3.4562 - val_ca3-[9.5,10.3): 3.8191 - val_ca3-[10.3,11.3): 5.5219 - val_ca3-[11.3,14.9): 7.9468 - val_ca4-[8.0,9.5): 6.6437 - val_ca4-[9.5,10.3): 7.2253 - val_ca4-[10.3,11.3): 9.4688 - val_ca4-[11.3,14.9): 12.6579\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 10.0799 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 4.7057 - ca2-[9.5,10.3): 5.2854 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 4.2300 - ca3-[10.3,11.3): 5.4749 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 11.0366 - ca4-[11.3,14.9): 12.4539 - val_ca1-[8.0,9.5): 9.2687 - val_ca1-[9.5,10.3): 10.0272 - val_ca1-[10.3,11.3): 12.7205 - val_ca1-[11.3,14.9): 16.5928 - val_ca2-[8.0,9.5): 4.4046 - val_ca2-[9.5,10.3): 4.8431 - val_ca2-[10.3,11.3): 6.8038 - val_ca2-[11.3,14.9): 9.6275 - val_ca3-[8.0,9.5): 3.0222 - val_ca3-[9.5,10.3): 3.3423 - val_ca3-[10.3,11.3): 5.0030 - val_ca3-[11.3,14.9): 7.4059 - val_ca4-[8.0,9.5): 6.0460 - val_ca4-[9.5,10.3): 6.5843 - val_ca4-[10.3,11.3): 8.8036 - val_ca4-[11.3,14.9): 12.0179\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 9.3567 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 4.2190 - ca2-[9.5,10.3): 4.6828 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 3.7410 - ca3-[10.3,11.3): 4.9666 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 9.8893 - ca4-[11.3,14.9): 11.5849 - val_ca1-[8.0,9.5): 8.6292 - val_ca1-[9.5,10.3): 9.3630 - val_ca1-[10.3,11.3): 11.9252 - val_ca1-[11.3,14.9): 15.6275 - val_ca2-[8.0,9.5): 3.8794 - val_ca2-[9.5,10.3): 4.2838 - val_ca2-[10.3,11.3): 6.1085 - val_ca2-[11.3,14.9): 8.7429 - val_ca3-[8.0,9.5): 2.6431 - val_ca3-[9.5,10.3): 2.9312 - val_ca3-[10.3,11.3): 4.4724 - val_ca3-[11.3,14.9): 6.7055 - val_ca4-[8.0,9.5): 5.4794 - val_ca4-[9.5,10.3): 5.9890 - val_ca4-[10.3,11.3): 8.0764 - val_ca4-[11.3,14.9): 11.1131\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 8.7198 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 3.5480 - ca2-[9.5,10.3): 4.1164 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 3.2932 - ca3-[10.3,11.3): 4.4411 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 9.2041 - ca4-[11.3,14.9): 10.7603 - val_ca1-[8.0,9.5): 8.0277 - val_ca1-[9.5,10.3): 8.7284 - val_ca1-[10.3,11.3): 11.1822 - val_ca1-[11.3,14.9): 14.8323 - val_ca2-[8.0,9.5): 3.4155 - val_ca2-[9.5,10.3): 3.7818 - val_ca2-[10.3,11.3): 5.4897 - val_ca2-[11.3,14.9): 8.0370 - val_ca3-[8.0,9.5): 2.3138 - val_ca3-[9.5,10.3): 2.5671 - val_ca3-[10.3,11.3): 4.0064 - val_ca3-[11.3,14.9): 6.1628 - val_ca4-[8.0,9.5): 4.9598 - val_ca4-[9.5,10.3): 5.4332 - val_ca4-[10.3,11.3): 7.4103 - val_ca4-[11.3,14.9): 10.3769\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 8.0994 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 3.2023 - ca2-[9.5,10.3): 3.6590 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.8533 - ca3-[10.3,11.3): 4.0112 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 8.6921 - ca4-[11.3,14.9): 10.1151 - val_ca1-[8.0,9.5): 7.4637 - val_ca1-[9.5,10.3): 8.1313 - val_ca1-[10.3,11.3): 10.5645 - val_ca1-[11.3,14.9): 13.8693 - val_ca2-[8.0,9.5): 3.0041 - val_ca2-[9.5,10.3): 3.3330 - val_ca2-[10.3,11.3): 4.9915 - val_ca2-[11.3,14.9): 7.2444 - val_ca3-[8.0,9.5): 2.0224 - val_ca3-[9.5,10.3): 2.2414 - val_ca3-[10.3,11.3): 3.6340 - val_ca3-[11.3,14.9): 5.5337 - val_ca4-[8.0,9.5): 4.4925 - val_ca4-[9.5,10.3): 4.9318 - val_ca4-[10.3,11.3): 6.8729 - val_ca4-[11.3,14.9): 9.5316\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 7.5686 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.8002 - ca2-[9.5,10.3): 3.2452 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.4701 - ca3-[10.3,11.3): 3.6000 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 7.8510 - ca4-[11.3,14.9): 9.2858 - val_ca1-[8.0,9.5): 6.9385 - val_ca1-[9.5,10.3): 7.5741 - val_ca1-[10.3,11.3): 9.9395 - val_ca1-[11.3,14.9): 13.2666 - val_ca2-[8.0,9.5): 2.6402 - val_ca2-[9.5,10.3): 2.9327 - val_ca2-[10.3,11.3): 4.5051 - val_ca2-[11.3,14.9): 6.7205 - val_ca3-[8.0,9.5): 1.7670 - val_ca3-[9.5,10.3): 1.9531 - val_ca3-[10.3,11.3): 3.2663 - val_ca3-[11.3,14.9): 5.1263 - val_ca4-[8.0,9.5): 4.0693 - val_ca4-[9.5,10.3): 4.4763 - val_ca4-[10.3,11.3): 6.3404 - val_ca4-[11.3,14.9): 8.9857\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 116ms/step - ca1-[8.0,9.5): 6.9846 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.4053 - ca2-[9.5,10.3): 2.8489 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.2715 - ca3-[10.3,11.3): 3.2479 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 7.4386 - ca4-[11.3,14.9): 8.7499 - val_ca1-[8.0,9.5): 6.4514 - val_ca1-[9.5,10.3): 7.0560 - val_ca1-[10.3,11.3): 9.3456 - val_ca1-[11.3,14.9): 12.4777 - val_ca2-[8.0,9.5): 2.3186 - val_ca2-[9.5,10.3): 2.5766 - val_ca2-[10.3,11.3): 4.0669 - val_ca2-[11.3,14.9): 6.1010 - val_ca3-[8.0,9.5): 1.5480 - val_ca3-[9.5,10.3): 1.7028 - val_ca3-[10.3,11.3): 2.9445 - val_ca3-[11.3,14.9): 4.6441 - val_ca4-[8.0,9.5): 3.6805 - val_ca4-[9.5,10.3): 4.0558 - val_ca4-[10.3,11.3): 5.8417 - val_ca4-[11.3,14.9): 8.3033\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 6.5443 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.1074 - ca2-[9.5,10.3): 2.4940 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.9872 - ca3-[10.3,11.3): 2.8942 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 6.9083 - ca4-[11.3,14.9): 8.1150 - val_ca1-[8.0,9.5): 5.9972 - val_ca1-[9.5,10.3): 6.5715 - val_ca1-[10.3,11.3): 8.8161 - val_ca1-[11.3,14.9): 11.9972 - val_ca2-[8.0,9.5): 2.0383 - val_ca2-[9.5,10.3): 2.2637 - val_ca2-[10.3,11.3): 3.6856 - val_ca2-[11.3,14.9): 5.7074 - val_ca3-[8.0,9.5): 1.3599 - val_ca3-[9.5,10.3): 1.4849 - val_ca3-[10.3,11.3): 2.6624 - val_ca3-[11.3,14.9): 4.3460 - val_ca4-[8.0,9.5): 3.3253 - val_ca4-[9.5,10.3): 3.6697 - val_ca4-[10.3,11.3): 5.3976 - val_ca4-[11.3,14.9): 7.8724\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 6.0754 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.8839 - ca2-[9.5,10.3): 2.2292 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.7421 - ca3-[10.3,11.3): 2.6289 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 6.2003 - ca4-[11.3,14.9): 7.5514 - val_ca1-[8.0,9.5): 5.5756 - val_ca1-[9.5,10.3): 6.1206 - val_ca1-[10.3,11.3): 8.2291 - val_ca1-[11.3,14.9): 11.3549 - val_ca2-[8.0,9.5): 1.7953 - val_ca2-[9.5,10.3): 1.9894 - val_ca2-[10.3,11.3): 3.2896 - val_ca2-[11.3,14.9): 5.2283 - val_ca3-[8.0,9.5): 1.1992 - val_ca3-[9.5,10.3): 1.2958 - val_ca3-[10.3,11.3): 2.3657 - val_ca3-[11.3,14.9): 3.9717 - val_ca4-[8.0,9.5): 3.0033 - val_ca4-[9.5,10.3): 3.3179 - val_ca4-[10.3,11.3): 4.9190 - val_ca4-[11.3,14.9): 7.3210\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 5.6930 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.6367 - ca2-[9.5,10.3): 1.9739 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.6098 - ca3-[10.3,11.3): 2.3570 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.9743 - ca4-[11.3,14.9): 7.0701 - val_ca1-[8.0,9.5): 5.1855 - val_ca1-[9.5,10.3): 5.7024 - val_ca1-[10.3,11.3): 7.7916 - val_ca1-[11.3,14.9): 10.7028 - val_ca2-[8.0,9.5): 1.5840 - val_ca2-[9.5,10.3): 1.7480 - val_ca2-[10.3,11.3): 3.0136 - val_ca2-[11.3,14.9): 4.7690 - val_ca3-[8.0,9.5): 1.0626 - val_ca3-[9.5,10.3): 1.1320 - val_ca3-[10.3,11.3): 2.1715 - val_ca3-[11.3,14.9): 3.6152 - val_ca4-[8.0,9.5): 2.7120 - val_ca4-[9.5,10.3): 2.9980 - val_ca4-[10.3,11.3): 4.5706 - val_ca4-[11.3,14.9): 6.7772\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 116ms/step - ca1-[8.0,9.5): 5.2822 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.3516 - ca2-[9.5,10.3): 1.6931 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.2475 - ca3-[10.3,11.3): 2.1608 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.5881 - ca4-[11.3,14.9): 6.6301 - val_ca1-[8.0,9.5): 4.8255 - val_ca1-[9.5,10.3): 5.3154 - val_ca1-[10.3,11.3): 7.3152 - val_ca1-[11.3,14.9): 10.1046 - val_ca2-[8.0,9.5): 1.4021 - val_ca2-[9.5,10.3): 1.5374 - val_ca2-[10.3,11.3): 2.7177 - val_ca2-[11.3,14.9): 4.3495 - val_ca3-[8.0,9.5): 0.9472 - val_ca3-[9.5,10.3): 0.9904 - val_ca3-[10.3,11.3): 1.9530 - val_ca3-[11.3,14.9): 3.2825 - val_ca4-[8.0,9.5): 2.4496 - val_ca4-[9.5,10.3): 2.7082 - val_ca4-[10.3,11.3): 4.1942 - val_ca4-[11.3,14.9): 6.2758\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 4.9429 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.2215 - ca2-[9.5,10.3): 1.5440 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.2165 - ca3-[10.3,11.3): 1.9374 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.0015 - ca4-[11.3,14.9): 6.1673 - val_ca1-[8.0,9.5): 4.4932 - val_ca1-[9.5,10.3): 4.9572 - val_ca1-[10.3,11.3): 6.9250 - val_ca1-[11.3,14.9): 9.6919 - val_ca2-[8.0,9.5): 1.2449 - val_ca2-[9.5,10.3): 1.3530 - val_ca2-[10.3,11.3): 2.4859 - val_ca2-[11.3,14.9): 4.0663 - val_ca3-[8.0,9.5): 0.8520 - val_ca3-[9.5,10.3): 0.8702 - val_ca3-[10.3,11.3): 1.7885 - val_ca3-[11.3,14.9): 3.0684 - val_ca4-[8.0,9.5): 2.2127 - val_ca4-[9.5,10.3): 2.4448 - val_ca4-[10.3,11.3): 3.8880 - val_ca4-[11.3,14.9): 5.9283\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 4.5643 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.0417 - ca2-[9.5,10.3): 1.3515 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.0946 - ca3-[10.3,11.3): 1.7745 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.5911 - ca4-[11.3,14.9): 5.7640 - val_ca1-[8.0,9.5): 4.1868 - val_ca1-[9.5,10.3): 4.6259 - val_ca1-[10.3,11.3): 6.5186 - val_ca1-[11.3,14.9): 9.2071 - val_ca2-[8.0,9.5): 1.1110 - val_ca2-[9.5,10.3): 1.1931 - val_ca2-[10.3,11.3): 2.2545 - val_ca2-[11.3,14.9): 3.7388 - val_ca3-[8.0,9.5): 0.7738 - val_ca3-[9.5,10.3): 0.7681 - val_ca3-[10.3,11.3): 1.6217 - val_ca3-[11.3,14.9): 2.8101 - val_ca4-[8.0,9.5): 1.9992 - val_ca4-[9.5,10.3): 2.2058 - val_ca4-[10.3,11.3): 3.5746 - val_ca4-[11.3,14.9): 5.5226\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 4.2576 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.8992 - ca2-[9.5,10.3): 1.1845 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.9691 - ca3-[10.3,11.3): 1.6050 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.4152 - ca4-[11.3,14.9): 5.3849 - val_ca1-[8.0,9.5): 3.9045 - val_ca1-[9.5,10.3): 4.3198 - val_ca1-[10.3,11.3): 6.1749 - val_ca1-[11.3,14.9): 8.7263 - val_ca2-[8.0,9.5): 0.9979 - val_ca2-[9.5,10.3): 1.0554 - val_ca2-[10.3,11.3): 2.0669 - val_ca2-[11.3,14.9): 3.4453 - val_ca3-[8.0,9.5): 0.7111 - val_ca3-[9.5,10.3): 0.6824 - val_ca3-[10.3,11.3): 1.4881 - val_ca3-[11.3,14.9): 2.5838 - val_ca4-[8.0,9.5): 1.8082 - val_ca4-[9.5,10.3): 1.9903 - val_ca4-[10.3,11.3): 3.3124 - val_ca4-[11.3,14.9): 5.1392\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 3.9848 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.8156 - ca2-[9.5,10.3): 1.0734 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.8573 - ca3-[10.3,11.3): 1.4615 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.2046 - ca4-[11.3,14.9): 5.0343 - val_ca1-[8.0,9.5): 3.6441 - val_ca1-[9.5,10.3): 4.0365 - val_ca1-[10.3,11.3): 5.8575 - val_ca1-[11.3,14.9): 8.2525 - val_ca2-[8.0,9.5): 0.9030 - val_ca2-[9.5,10.3): 0.9373 - val_ca2-[10.3,11.3): 1.8990 - val_ca2-[11.3,14.9): 3.1465 - val_ca3-[8.0,9.5): 0.6626 - val_ca3-[9.5,10.3): 0.6120 - val_ca3-[10.3,11.3): 1.3682 - val_ca3-[11.3,14.9): 2.3446 - val_ca4-[8.0,9.5): 1.6376 - val_ca4-[9.5,10.3): 1.7962 - val_ca4-[10.3,11.3): 3.0723 - val_ca4-[11.3,14.9): 4.7558\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 3.6678 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.7101 - ca2-[9.5,10.3): 0.9605 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.7552 - ca3-[10.3,11.3): 1.3502 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.8758 - ca4-[11.3,14.9): 4.7600 - val_ca1-[8.0,9.5): 3.4041 - val_ca1-[9.5,10.3): 3.7744 - val_ca1-[10.3,11.3): 5.5259 - val_ca1-[11.3,14.9): 8.0094 - val_ca2-[8.0,9.5): 0.8241 - val_ca2-[9.5,10.3): 0.8363 - val_ca2-[10.3,11.3): 1.7401 - val_ca2-[11.3,14.9): 3.0103 - val_ca3-[8.0,9.5): 0.6261 - val_ca3-[9.5,10.3): 0.5547 - val_ca3-[10.3,11.3): 1.2592 - val_ca3-[11.3,14.9): 2.2479 - val_ca4-[8.0,9.5): 1.4858 - val_ca4-[9.5,10.3): 1.6219 - val_ca4-[10.3,11.3): 2.8334 - val_ca4-[11.3,14.9): 4.5592\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 116ms/step - ca1-[8.0,9.5): 3.4619 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.6303 - ca2-[9.5,10.3): 0.8573 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.7138 - ca3-[10.3,11.3): 1.2482 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.5230 - ca4-[11.3,14.9): 4.3811 - val_ca1-[8.0,9.5): 3.1830 - val_ca1-[9.5,10.3): 3.5322 - val_ca1-[10.3,11.3): 5.2350 - val_ca1-[11.3,14.9): 7.6157 - val_ca2-[8.0,9.5): 0.7593 - val_ca2-[9.5,10.3): 0.7507 - val_ca2-[10.3,11.3): 1.6049 - val_ca2-[11.3,14.9): 2.7799 - val_ca3-[8.0,9.5): 0.6004 - val_ca3-[9.5,10.3): 0.5089 - val_ca3-[10.3,11.3): 1.1659 - val_ca3-[11.3,14.9): 2.0638 - val_ca4-[8.0,9.5): 1.3512 - val_ca4-[9.5,10.3): 1.4657 - val_ca4-[10.3,11.3): 2.6253 - val_ca4-[11.3,14.9): 4.2497\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 117ms/step - ca1-[8.0,9.5): 3.2315 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.5837 - ca2-[9.5,10.3): 0.7952 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6319 - ca3-[10.3,11.3): 1.1578 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.2579 - ca4-[11.3,14.9): 4.1281 - val_ca1-[8.0,9.5): 2.9799 - val_ca1-[9.5,10.3): 3.3089 - val_ca1-[10.3,11.3): 4.9515 - val_ca1-[11.3,14.9): 7.3285 - val_ca2-[8.0,9.5): 0.7070 - val_ca2-[9.5,10.3): 0.6786 - val_ca2-[10.3,11.3): 1.4819 - val_ca2-[11.3,14.9): 2.6268 - val_ca3-[8.0,9.5): 0.5843 - val_ca3-[9.5,10.3): 0.4737 - val_ca3-[10.3,11.3): 1.0837 - val_ca3-[11.3,14.9): 1.9482 - val_ca4-[8.0,9.5): 1.2321 - val_ca4-[9.5,10.3): 1.3260 - val_ca4-[10.3,11.3): 2.4279 - val_ca4-[11.3,14.9): 4.0266\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 3.0407 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4903 - ca2-[9.5,10.3): 0.7360 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6079 - ca3-[10.3,11.3): 1.0531 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.0186 - ca4-[11.3,14.9): 3.8579 - val_ca1-[8.0,9.5): 2.7933 - val_ca1-[9.5,10.3): 3.1031 - val_ca1-[10.3,11.3): 4.7166 - val_ca1-[11.3,14.9): 6.9973 - val_ca2-[8.0,9.5): 0.6655 - val_ca2-[9.5,10.3): 0.6185 - val_ca2-[10.3,11.3): 1.3847 - val_ca2-[11.3,14.9): 2.4265 - val_ca3-[8.0,9.5): 0.5766 - val_ca3-[9.5,10.3): 0.4478 - val_ca3-[10.3,11.3): 1.0207 - val_ca3-[11.3,14.9): 1.7828 - val_ca4-[8.0,9.5): 1.1271 - val_ca4-[9.5,10.3): 1.2011 - val_ca4-[10.3,11.3): 2.2659 - val_ca4-[11.3,14.9): 3.7575\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 2.8448 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4769 - ca2-[9.5,10.3): 0.6850 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5788 - ca3-[10.3,11.3): 1.0197 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.5482 - ca4-[11.3,14.9): 3.6074 - val_ca1-[8.0,9.5): 2.6216 - val_ca1-[9.5,10.3): 2.9131 - val_ca1-[10.3,11.3): 4.4832 - val_ca1-[11.3,14.9): 6.6851 - val_ca2-[8.0,9.5): 0.6334 - val_ca2-[9.5,10.3): 0.5688 - val_ca2-[10.3,11.3): 1.2913 - val_ca2-[11.3,14.9): 2.2793 - val_ca3-[8.0,9.5): 0.5761 - val_ca3-[9.5,10.3): 0.4299 - val_ca3-[10.3,11.3): 0.9600 - val_ca3-[11.3,14.9): 1.6748 - val_ca4-[8.0,9.5): 1.0352 - val_ca4-[9.5,10.3): 1.0902 - val_ca4-[10.3,11.3): 2.1078 - val_ca4-[11.3,14.9): 3.5311\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 2.6795 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4234 - ca2-[9.5,10.3): 0.6252 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5051 - ca3-[10.3,11.3): 0.9514 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.6666 - ca4-[11.3,14.9): 3.4188 - val_ca1-[8.0,9.5): 2.4641 - val_ca1-[9.5,10.3): 2.7380 - val_ca1-[10.3,11.3): 4.2520 - val_ca1-[11.3,14.9): 6.4104 - val_ca2-[8.0,9.5): 0.6096 - val_ca2-[9.5,10.3): 0.5285 - val_ca2-[10.3,11.3): 1.2037 - val_ca2-[11.3,14.9): 2.1460 - val_ca3-[8.0,9.5): 0.5817 - val_ca3-[9.5,10.3): 0.4192 - val_ca3-[10.3,11.3): 0.9043 - val_ca3-[11.3,14.9): 1.5737 - val_ca4-[8.0,9.5): 0.9551 - val_ca4-[9.5,10.3): 0.9920 - val_ca4-[10.3,11.3): 1.9551 - val_ca4-[11.3,14.9): 3.3275\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 2.4982 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4148 - ca2-[9.5,10.3): 0.6044 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5164 - ca3-[10.3,11.3): 0.8954 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.4874 - ca4-[11.3,14.9): 3.2816 - val_ca1-[8.0,9.5): 2.3191 - val_ca1-[9.5,10.3): 2.5762 - val_ca1-[10.3,11.3): 4.0372 - val_ca1-[11.3,14.9): 6.1167 - val_ca2-[8.0,9.5): 0.5928 - val_ca2-[9.5,10.3): 0.4961 - val_ca2-[10.3,11.3): 1.1285 - val_ca2-[11.3,14.9): 2.0069 - val_ca3-[8.0,9.5): 0.5927 - val_ca3-[9.5,10.3): 0.4145 - val_ca3-[10.3,11.3): 0.8590 - val_ca3-[11.3,14.9): 1.4678 - val_ca4-[8.0,9.5): 0.8855 - val_ca4-[9.5,10.3): 0.9050 - val_ca4-[10.3,11.3): 1.8175 - val_ca4-[11.3,14.9): 3.1132\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 2.3720 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3876 - ca2-[9.5,10.3): 0.5688 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4904 - ca3-[10.3,11.3): 0.8403 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.2008 - ca4-[11.3,14.9): 3.0375 - val_ca1-[8.0,9.5): 2.1858 - val_ca1-[9.5,10.3): 2.4267 - val_ca1-[10.3,11.3): 3.8787 - val_ca1-[11.3,14.9): 5.9355 - val_ca2-[8.0,9.5): 0.5819 - val_ca2-[9.5,10.3): 0.4705 - val_ca2-[10.3,11.3): 1.0797 - val_ca2-[11.3,14.9): 1.9163 - val_ca3-[8.0,9.5): 0.6081 - val_ca3-[9.5,10.3): 0.4151 - val_ca3-[10.3,11.3): 0.8329 - val_ca3-[11.3,14.9): 1.3949 - val_ca4-[8.0,9.5): 0.8255 - val_ca4-[9.5,10.3): 0.8283 - val_ca4-[10.3,11.3): 1.7185 - val_ca4-[11.3,14.9): 2.9720\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 2.2365 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3658 - ca2-[9.5,10.3): 0.5617 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4693 - ca3-[10.3,11.3): 0.8103 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.1297 - ca4-[11.3,14.9): 2.8898 - val_ca1-[8.0,9.5): 2.0636 - val_ca1-[9.5,10.3): 2.2892 - val_ca1-[10.3,11.3): 3.7055 - val_ca1-[11.3,14.9): 5.5996 - val_ca2-[8.0,9.5): 0.5761 - val_ca2-[9.5,10.3): 0.4511 - val_ca2-[10.3,11.3): 1.0278 - val_ca2-[11.3,14.9): 1.7685 - val_ca3-[8.0,9.5): 0.6273 - val_ca3-[9.5,10.3): 0.4202 - val_ca3-[10.3,11.3): 0.8047 - val_ca3-[11.3,14.9): 1.2849 - val_ca4-[8.0,9.5): 0.7744 - val_ca4-[9.5,10.3): 0.7612 - val_ca4-[10.3,11.3): 1.6131 - val_ca4-[11.3,14.9): 2.7430\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 2.1078 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3700 - ca2-[9.5,10.3): 0.5368 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4582 - ca3-[10.3,11.3): 0.7918 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.0702 - ca4-[11.3,14.9): 2.7239 - val_ca1-[8.0,9.5): 1.9512 - val_ca1-[9.5,10.3): 2.1623 - val_ca1-[10.3,11.3): 3.5183 - val_ca1-[11.3,14.9): 5.4196 - val_ca2-[8.0,9.5): 0.5745 - val_ca2-[9.5,10.3): 0.4367 - val_ca2-[10.3,11.3): 0.9728 - val_ca2-[11.3,14.9): 1.6942 - val_ca3-[8.0,9.5): 0.6495 - val_ca3-[9.5,10.3): 0.4290 - val_ca3-[10.3,11.3): 0.7760 - val_ca3-[11.3,14.9): 1.2276 - val_ca4-[8.0,9.5): 0.7309 - val_ca4-[9.5,10.3): 0.7026 - val_ca4-[10.3,11.3): 1.5022 - val_ca4-[11.3,14.9): 2.6120\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 1.9639 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3737 - ca2-[9.5,10.3): 0.5350 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4875 - ca3-[10.3,11.3): 0.7530 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.8970 - ca4-[11.3,14.9): 2.5430 - val_ca1-[8.0,9.5): 1.8484 - val_ca1-[9.5,10.3): 2.0455 - val_ca1-[10.3,11.3): 3.3838 - val_ca1-[11.3,14.9): 5.3115 - val_ca2-[8.0,9.5): 0.5763 - val_ca2-[9.5,10.3): 0.4266 - val_ca2-[10.3,11.3): 0.9416 - val_ca2-[11.3,14.9): 1.6544 - val_ca3-[8.0,9.5): 0.6740 - val_ca3-[9.5,10.3): 0.4409 - val_ca3-[10.3,11.3): 0.7639 - val_ca3-[11.3,14.9): 1.1962 - val_ca4-[8.0,9.5): 0.6944 - val_ca4-[9.5,10.3): 0.6516 - val_ca4-[10.3,11.3): 1.4259 - val_ca4-[11.3,14.9): 2.5309\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 1.8394 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3678 - ca2-[9.5,10.3): 0.5048 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5025 - ca3-[10.3,11.3): 0.7373 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.8143 - ca4-[11.3,14.9): 2.3999 - val_ca1-[8.0,9.5): 1.7543 - val_ca1-[9.5,10.3): 1.9382 - val_ca1-[10.3,11.3): 3.2573 - val_ca1-[11.3,14.9): 5.0732 - val_ca2-[8.0,9.5): 0.5808 - val_ca2-[9.5,10.3): 0.4201 - val_ca2-[10.3,11.3): 0.9116 - val_ca2-[11.3,14.9): 1.5570 - val_ca3-[8.0,9.5): 0.7004 - val_ca3-[9.5,10.3): 0.4554 - val_ca3-[10.3,11.3): 0.7510 - val_ca3-[11.3,14.9): 1.1221 - val_ca4-[8.0,9.5): 0.6643 - val_ca4-[9.5,10.3): 0.6076 - val_ca4-[10.3,11.3): 1.3543 - val_ca4-[11.3,14.9): 2.3689\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.7886 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3848 - ca2-[9.5,10.3): 0.5162 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4945 - ca3-[10.3,11.3): 0.7436 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.7044 - ca4-[11.3,14.9): 2.3106 - val_ca1-[8.0,9.5): 1.6679 - val_ca1-[9.5,10.3): 1.8393 - val_ca1-[10.3,11.3): 3.1055 - val_ca1-[11.3,14.9): 4.8827 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8773 - val_ca2-[11.3,14.9): 1.4914 - val_ca3-[8.0,9.5): 0.7281 - val_ca3-[9.5,10.3): 0.4718 - val_ca3-[10.3,11.3): 0.7387 - val_ca3-[11.3,14.9): 1.0758 - val_ca4-[8.0,9.5): 0.6398 - val_ca4-[9.5,10.3): 0.5700 - val_ca4-[10.3,11.3): 1.2729 - val_ca4-[11.3,14.9): 2.2447\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 1.6818 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3918 - ca2-[9.5,10.3): 0.5247 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5037 - ca3-[10.3,11.3): 0.7256 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.5556 - ca4-[11.3,14.9): 2.2149 - val_ca1-[8.0,9.5): 1.5890 - val_ca1-[9.5,10.3): 1.7485 - val_ca1-[10.3,11.3): 3.0287 - val_ca1-[11.3,14.9): 4.7136 - val_ca2-[8.0,9.5): 0.5952 - val_ca2-[9.5,10.3): 0.4151 - val_ca2-[10.3,11.3): 0.8599 - val_ca2-[11.3,14.9): 1.4117 - val_ca3-[8.0,9.5): 0.7561 - val_ca3-[9.5,10.3): 0.4893 - val_ca3-[10.3,11.3): 0.7295 - val_ca3-[11.3,14.9): 1.0062 - val_ca4-[8.0,9.5): 0.6202 - val_ca4-[9.5,10.3): 0.5378 - val_ca4-[10.3,11.3): 1.2273 - val_ca4-[11.3,14.9): 2.1182\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.6132 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3855 - ca2-[9.5,10.3): 0.5185 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5156 - ca3-[10.3,11.3): 0.7239 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.4688 - ca4-[11.3,14.9): 2.1015 - val_ca1-[8.0,9.5): 1.5166 - val_ca1-[9.5,10.3): 1.6649 - val_ca1-[10.3,11.3): 2.9003 - val_ca1-[11.3,14.9): 4.6522 - val_ca2-[8.0,9.5): 0.6039 - val_ca2-[9.5,10.3): 0.4155 - val_ca2-[10.3,11.3): 0.8411 - val_ca2-[11.3,14.9): 1.4177 - val_ca3-[8.0,9.5): 0.7845 - val_ca3-[9.5,10.3): 0.5079 - val_ca3-[10.3,11.3): 0.7304 - val_ca3-[11.3,14.9): 1.0155 - val_ca4-[8.0,9.5): 0.6051 - val_ca4-[9.5,10.3): 0.5107 - val_ca4-[10.3,11.3): 1.1662 - val_ca4-[11.3,14.9): 2.0840\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 1.5412 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4039 - ca2-[9.5,10.3): 0.5172 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5241 - ca3-[10.3,11.3): 0.7077 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.4181 - ca4-[11.3,14.9): 2.0164 - val_ca1-[8.0,9.5): 1.4502 - val_ca1-[9.5,10.3): 1.5877 - val_ca1-[10.3,11.3): 2.8074 - val_ca1-[11.3,14.9): 4.4374 - val_ca2-[8.0,9.5): 0.6127 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8219 - val_ca2-[11.3,14.9): 1.3358 - val_ca3-[8.0,9.5): 0.8131 - val_ca3-[9.5,10.3): 0.5272 - val_ca3-[10.3,11.3): 0.7220 - val_ca3-[11.3,14.9): 0.9503 - val_ca4-[8.0,9.5): 0.5937 - val_ca4-[9.5,10.3): 0.4878 - val_ca4-[10.3,11.3): 1.1160 - val_ca4-[11.3,14.9): 1.9409\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.4785 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3967 - ca2-[9.5,10.3): 0.5173 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5387 - ca3-[10.3,11.3): 0.7090 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.2931 - ca4-[11.3,14.9): 1.8994 - val_ca1-[8.0,9.5): 1.3892 - val_ca1-[9.5,10.3): 1.5165 - val_ca1-[10.3,11.3): 2.7118 - val_ca1-[11.3,14.9): 4.3378 - val_ca2-[8.0,9.5): 0.6201 - val_ca2-[9.5,10.3): 0.4184 - val_ca2-[10.3,11.3): 0.8160 - val_ca2-[11.3,14.9): 1.3289 - val_ca3-[8.0,9.5): 0.8410 - val_ca3-[9.5,10.3): 0.5463 - val_ca3-[10.3,11.3): 0.7300 - val_ca3-[11.3,14.9): 0.9475 - val_ca4-[8.0,9.5): 0.5857 - val_ca4-[9.5,10.3): 0.4690 - val_ca4-[10.3,11.3): 1.0755 - val_ca4-[11.3,14.9): 1.8870\n",
      "Epoch 49/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.4100 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3991 - ca2-[9.5,10.3): 0.5279 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5405 - ca3-[10.3,11.3): 0.7140 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.2185 - ca4-[11.3,14.9): 1.8365 - val_ca1-[8.0,9.5): 1.3332 - val_ca1-[9.5,10.3): 1.4508 - val_ca1-[10.3,11.3): 2.6156 - val_ca1-[11.3,14.9): 4.2059 - val_ca2-[8.0,9.5): 0.6199 - val_ca2-[9.5,10.3): 0.4176 - val_ca2-[10.3,11.3): 0.8138 - val_ca2-[11.3,14.9): 1.3225 - val_ca3-[8.0,9.5): 0.8684 - val_ca3-[9.5,10.3): 0.5655 - val_ca3-[10.3,11.3): 0.7312 - val_ca3-[11.3,14.9): 0.9196 - val_ca4-[8.0,9.5): 0.5808 - val_ca4-[9.5,10.3): 0.4536 - val_ca4-[10.3,11.3): 1.0319 - val_ca4-[11.3,14.9): 1.8033\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.3264 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4050 - ca2-[9.5,10.3): 0.5201 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5581 - ca3-[10.3,11.3): 0.6968 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.2716 - ca4-[11.3,14.9): 1.7614 - val_ca1-[8.0,9.5): 1.2820 - val_ca1-[9.5,10.3): 1.3906 - val_ca1-[10.3,11.3): 2.5339 - val_ca1-[11.3,14.9): 4.1077 - val_ca2-[8.0,9.5): 0.6244 - val_ca2-[9.5,10.3): 0.4196 - val_ca2-[10.3,11.3): 0.8089 - val_ca2-[11.3,14.9): 1.3124 - val_ca3-[8.0,9.5): 0.8932 - val_ca3-[9.5,10.3): 0.5830 - val_ca3-[10.3,11.3): 0.7331 - val_ca3-[11.3,14.9): 0.9013 - val_ca4-[8.0,9.5): 0.5784 - val_ca4-[9.5,10.3): 0.4414 - val_ca4-[10.3,11.3): 0.9956 - val_ca4-[11.3,14.9): 1.7384\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.2883 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3997 - ca2-[9.5,10.3): 0.5142 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5931 - ca3-[10.3,11.3): 0.6983 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.1877 - ca4-[11.3,14.9): 1.6950 - val_ca1-[8.0,9.5): 1.2348 - val_ca1-[9.5,10.3): 1.3348 - val_ca1-[10.3,11.3): 2.4275 - val_ca1-[11.3,14.9): 4.0002 - val_ca2-[8.0,9.5): 0.6308 - val_ca2-[9.5,10.3): 0.4217 - val_ca2-[10.3,11.3): 0.7847 - val_ca2-[11.3,14.9): 1.2857 - val_ca3-[8.0,9.5): 0.9155 - val_ca3-[9.5,10.3): 0.5988 - val_ca3-[10.3,11.3): 0.7225 - val_ca3-[11.3,14.9): 0.8777 - val_ca4-[8.0,9.5): 0.5784 - val_ca4-[9.5,10.3): 0.4318 - val_ca4-[10.3,11.3): 0.9431 - val_ca4-[11.3,14.9): 1.6689\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 1.2340 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4183 - ca2-[9.5,10.3): 0.5222 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5870 - ca3-[10.3,11.3): 0.7158 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.0638 - ca4-[11.3,14.9): 1.6378 - val_ca1-[8.0,9.5): 1.1913 - val_ca1-[9.5,10.3): 1.2832 - val_ca1-[10.3,11.3): 2.3869 - val_ca1-[11.3,14.9): 3.9571 - val_ca2-[8.0,9.5): 0.6366 - val_ca2-[9.5,10.3): 0.4237 - val_ca2-[10.3,11.3): 0.7961 - val_ca2-[11.3,14.9): 1.2890 - val_ca3-[8.0,9.5): 0.9345 - val_ca3-[9.5,10.3): 0.6122 - val_ca3-[10.3,11.3): 0.7379 - val_ca3-[11.3,14.9): 0.8756 - val_ca4-[8.0,9.5): 0.5804 - val_ca4-[9.5,10.3): 0.4247 - val_ca4-[10.3,11.3): 0.9337 - val_ca4-[11.3,14.9): 1.6354\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 1.2042 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4187 - ca2-[9.5,10.3): 0.5231 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5865 - ca3-[10.3,11.3): 0.7074 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.0513 - ca4-[11.3,14.9): 1.5595 - val_ca1-[8.0,9.5): 1.1514 - val_ca1-[9.5,10.3): 1.2358 - val_ca1-[10.3,11.3): 2.3199 - val_ca1-[11.3,14.9): 3.8223 - val_ca2-[8.0,9.5): 0.6408 - val_ca2-[9.5,10.3): 0.4251 - val_ca2-[10.3,11.3): 0.7902 - val_ca2-[11.3,14.9): 1.2602 - val_ca3-[8.0,9.5): 0.9467 - val_ca3-[9.5,10.3): 0.6208 - val_ca3-[10.3,11.3): 0.7372 - val_ca3-[11.3,14.9): 0.8559 - val_ca4-[8.0,9.5): 0.5842 - val_ca4-[9.5,10.3): 0.4197 - val_ca4-[10.3,11.3): 0.9056 - val_ca4-[11.3,14.9): 1.5557\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 1.1687 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4212 - ca2-[9.5,10.3): 0.5270 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5916 - ca3-[10.3,11.3): 0.7211 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.0578 - ca4-[11.3,14.9): 1.5328 - val_ca1-[8.0,9.5): 1.1144 - val_ca1-[9.5,10.3): 1.1918 - val_ca1-[10.3,11.3): 2.2588 - val_ca1-[11.3,14.9): 3.7732 - val_ca2-[8.0,9.5): 0.6431 - val_ca2-[9.5,10.3): 0.4258 - val_ca2-[10.3,11.3): 0.7886 - val_ca2-[11.3,14.9): 1.2734 - val_ca3-[8.0,9.5): 0.9524 - val_ca3-[9.5,10.3): 0.6247 - val_ca3-[10.3,11.3): 0.7374 - val_ca3-[11.3,14.9): 0.8592 - val_ca4-[8.0,9.5): 0.5896 - val_ca4-[9.5,10.3): 0.4166 - val_ca4-[10.3,11.3): 0.8821 - val_ca4-[11.3,14.9): 1.5222\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 1.1347 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4250 - ca2-[9.5,10.3): 0.5316 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6063 - ca3-[10.3,11.3): 0.7052 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.9868 - ca4-[11.3,14.9): 1.4589 - val_ca1-[8.0,9.5): 1.0805 - val_ca1-[9.5,10.3): 1.1512 - val_ca1-[10.3,11.3): 2.2020 - val_ca1-[11.3,14.9): 3.6241 - val_ca2-[8.0,9.5): 0.6428 - val_ca2-[9.5,10.3): 0.4256 - val_ca2-[10.3,11.3): 0.7904 - val_ca2-[11.3,14.9): 1.2527 - val_ca3-[8.0,9.5): 0.9618 - val_ca3-[9.5,10.3): 0.6305 - val_ca3-[10.3,11.3): 0.7382 - val_ca3-[11.3,14.9): 0.8436 - val_ca4-[8.0,9.5): 0.5964 - val_ca4-[9.5,10.3): 0.4153 - val_ca4-[10.3,11.3): 0.8610 - val_ca4-[11.3,14.9): 1.4412\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.0902 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4249 - ca2-[9.5,10.3): 0.5286 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5882 - ca3-[10.3,11.3): 0.7241 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.9941 - ca4-[11.3,14.9): 1.4067 - val_ca1-[8.0,9.5): 1.0490 - val_ca1-[9.5,10.3): 1.1133 - val_ca1-[10.3,11.3): 2.1617 - val_ca1-[11.3,14.9): 3.5746 - val_ca2-[8.0,9.5): 0.6380 - val_ca2-[9.5,10.3): 0.4238 - val_ca2-[10.3,11.3): 0.7944 - val_ca2-[11.3,14.9): 1.2751 - val_ca3-[8.0,9.5): 0.9731 - val_ca3-[9.5,10.3): 0.6375 - val_ca3-[10.3,11.3): 0.7313 - val_ca3-[11.3,14.9): 0.8354 - val_ca4-[8.0,9.5): 0.6044 - val_ca4-[9.5,10.3): 0.4155 - val_ca4-[10.3,11.3): 0.8410 - val_ca4-[11.3,14.9): 1.4031\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 1.0775 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4207 - ca2-[9.5,10.3): 0.5375 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6084 - ca3-[10.3,11.3): 0.7202 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.9275 - ca4-[11.3,14.9): 1.3691 - val_ca1-[8.0,9.5): 1.0192 - val_ca1-[9.5,10.3): 1.0753 - val_ca1-[10.3,11.3): 2.1029 - val_ca1-[11.3,14.9): 3.5047 - val_ca2-[8.0,9.5): 0.6242 - val_ca2-[9.5,10.3): 0.4187 - val_ca2-[10.3,11.3): 0.8188 - val_ca2-[11.3,14.9): 1.3154 - val_ca3-[8.0,9.5): 0.9830 - val_ca3-[9.5,10.3): 0.6476 - val_ca3-[10.3,11.3): 0.7516 - val_ca3-[11.3,14.9): 0.8261 - val_ca4-[8.0,9.5): 0.6136 - val_ca4-[9.5,10.3): 0.4179 - val_ca4-[10.3,11.3): 0.8335 - val_ca4-[11.3,14.9): 1.3573\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 1.0141 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3992 - ca2-[9.5,10.3): 0.5227 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5991 - ca3-[10.3,11.3): 0.7121 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8554 - ca4-[11.3,14.9): 1.3333 - val_ca1-[8.0,9.5): 0.9906 - val_ca1-[9.5,10.3): 1.0422 - val_ca1-[10.3,11.3): 2.0466 - val_ca1-[11.3,14.9): 3.4430 - val_ca2-[8.0,9.5): 0.6181 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8177 - val_ca2-[11.3,14.9): 1.3530 - val_ca3-[8.0,9.5): 0.9871 - val_ca3-[9.5,10.3): 0.6483 - val_ca3-[10.3,11.3): 0.7433 - val_ca3-[11.3,14.9): 0.8467 - val_ca4-[8.0,9.5): 0.6240 - val_ca4-[9.5,10.3): 0.4200 - val_ca4-[10.3,11.3): 0.8100 - val_ca4-[11.3,14.9): 1.3351\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.9979 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4061 - ca2-[9.5,10.3): 0.5240 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6443 - ca3-[10.3,11.3): 0.7051 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7834 - ca4-[11.3,14.9): 1.2793 - val_ca1-[8.0,9.5): 0.9635 - val_ca1-[9.5,10.3): 1.0090 - val_ca1-[10.3,11.3): 1.9798 - val_ca1-[11.3,14.9): 3.3717 - val_ca2-[8.0,9.5): 0.6194 - val_ca2-[9.5,10.3): 0.4159 - val_ca2-[10.3,11.3): 0.8086 - val_ca2-[11.3,14.9): 1.3425 - val_ca3-[8.0,9.5): 0.9798 - val_ca3-[9.5,10.3): 0.6422 - val_ca3-[10.3,11.3): 0.7405 - val_ca3-[11.3,14.9): 0.8434 - val_ca4-[8.0,9.5): 0.6356 - val_ca4-[9.5,10.3): 0.4242 - val_ca4-[10.3,11.3): 0.7895 - val_ca4-[11.3,14.9): 1.2883\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.9745 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3920 - ca2-[9.5,10.3): 0.5130 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5919 - ca3-[10.3,11.3): 0.6996 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8672 - ca4-[11.3,14.9): 1.2509 - val_ca1-[8.0,9.5): 0.9380 - val_ca1-[9.5,10.3): 0.9776 - val_ca1-[10.3,11.3): 1.9526 - val_ca1-[11.3,14.9): 3.2894 - val_ca2-[8.0,9.5): 0.6208 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8125 - val_ca2-[11.3,14.9): 1.3328 - val_ca3-[8.0,9.5): 0.9680 - val_ca3-[9.5,10.3): 0.6315 - val_ca3-[10.3,11.3): 0.7373 - val_ca3-[11.3,14.9): 0.8527 - val_ca4-[8.0,9.5): 0.6483 - val_ca4-[9.5,10.3): 0.4296 - val_ca4-[10.3,11.3): 0.7840 - val_ca4-[11.3,14.9): 1.2461\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.9666 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4023 - ca2-[9.5,10.3): 0.5189 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6143 - ca3-[10.3,11.3): 0.7087 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7531 - ca4-[11.3,14.9): 1.2114 - val_ca1-[8.0,9.5): 0.9141 - val_ca1-[9.5,10.3): 0.9480 - val_ca1-[10.3,11.3): 1.9040 - val_ca1-[11.3,14.9): 3.2696 - val_ca2-[8.0,9.5): 0.6223 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8020 - val_ca2-[11.3,14.9): 1.3416 - val_ca3-[8.0,9.5): 0.9416 - val_ca3-[9.5,10.3): 0.6099 - val_ca3-[10.3,11.3): 0.7193 - val_ca3-[11.3,14.9): 0.8649 - val_ca4-[8.0,9.5): 0.6618 - val_ca4-[9.5,10.3): 0.4361 - val_ca4-[10.3,11.3): 0.7637 - val_ca4-[11.3,14.9): 1.2181\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.9345 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4107 - ca2-[9.5,10.3): 0.5141 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5541 - ca3-[10.3,11.3): 0.7114 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7859 - ca4-[11.3,14.9): 1.1820 - val_ca1-[8.0,9.5): 0.8914 - val_ca1-[9.5,10.3): 0.9198 - val_ca1-[10.3,11.3): 1.8511 - val_ca1-[11.3,14.9): 3.1270 - val_ca2-[8.0,9.5): 0.6183 - val_ca2-[9.5,10.3): 0.4145 - val_ca2-[10.3,11.3): 0.8109 - val_ca2-[11.3,14.9): 1.3199 - val_ca3-[8.0,9.5): 0.9036 - val_ca3-[9.5,10.3): 0.5779 - val_ca3-[10.3,11.3): 0.7224 - val_ca3-[11.3,14.9): 0.8777 - val_ca4-[8.0,9.5): 0.6765 - val_ca4-[9.5,10.3): 0.4437 - val_ca4-[10.3,11.3): 0.7602 - val_ca4-[11.3,14.9): 1.1580\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.8786 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4099 - ca2-[9.5,10.3): 0.5237 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5552 - ca3-[10.3,11.3): 0.6959 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7026 - ca4-[11.3,14.9): 1.1472 - val_ca1-[8.0,9.5): 0.8695 - val_ca1-[9.5,10.3): 0.8921 - val_ca1-[10.3,11.3): 1.8001 - val_ca1-[11.3,14.9): 3.0433 - val_ca2-[8.0,9.5): 0.6176 - val_ca2-[9.5,10.3): 0.4140 - val_ca2-[10.3,11.3): 0.8003 - val_ca2-[11.3,14.9): 1.3067 - val_ca3-[8.0,9.5): 0.8909 - val_ca3-[9.5,10.3): 0.5669 - val_ca3-[10.3,11.3): 0.7075 - val_ca3-[11.3,14.9): 0.8724 - val_ca4-[8.0,9.5): 0.6918 - val_ca4-[9.5,10.3): 0.4522 - val_ca4-[10.3,11.3): 0.7420 - val_ca4-[11.3,14.9): 1.1139\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.8584 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3878 - ca2-[9.5,10.3): 0.5008 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5566 - ca3-[10.3,11.3): 0.6807 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7011 - ca4-[11.3,14.9): 1.0961 - val_ca1-[8.0,9.5): 0.8484 - val_ca1-[9.5,10.3): 0.8650 - val_ca1-[10.3,11.3): 1.7843 - val_ca1-[11.3,14.9): 3.0310 - val_ca2-[8.0,9.5): 0.6180 - val_ca2-[9.5,10.3): 0.4142 - val_ca2-[10.3,11.3): 0.8154 - val_ca2-[11.3,14.9): 1.3360 - val_ca3-[8.0,9.5): 0.8987 - val_ca3-[9.5,10.3): 0.5703 - val_ca3-[10.3,11.3): 0.7155 - val_ca3-[11.3,14.9): 0.8844 - val_ca4-[8.0,9.5): 0.7079 - val_ca4-[9.5,10.3): 0.4617 - val_ca4-[10.3,11.3): 0.7489 - val_ca4-[11.3,14.9): 1.1103\n",
      "Epoch 65/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.8236 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4120 - ca2-[9.5,10.3): 0.5246 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5368 - ca3-[10.3,11.3): 0.6871 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7297 - ca4-[11.3,14.9): 1.0846 - val_ca1-[8.0,9.5): 0.8284 - val_ca1-[9.5,10.3): 0.8391 - val_ca1-[10.3,11.3): 1.7460 - val_ca1-[11.3,14.9): 2.9732 - val_ca2-[8.0,9.5): 0.6201 - val_ca2-[9.5,10.3): 0.4144 - val_ca2-[10.3,11.3): 0.8146 - val_ca2-[11.3,14.9): 1.3268 - val_ca3-[8.0,9.5): 0.9107 - val_ca3-[9.5,10.3): 0.5769 - val_ca3-[10.3,11.3): 0.7175 - val_ca3-[11.3,14.9): 0.8695 - val_ca4-[8.0,9.5): 0.7248 - val_ca4-[9.5,10.3): 0.4720 - val_ca4-[10.3,11.3): 0.7455 - val_ca4-[11.3,14.9): 1.0800\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.8317 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3939 - ca2-[9.5,10.3): 0.5155 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5396 - ca3-[10.3,11.3): 0.6978 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5782 - ca4-[11.3,14.9): 1.0381 - val_ca1-[8.0,9.5): 0.8100 - val_ca1-[9.5,10.3): 0.8151 - val_ca1-[10.3,11.3): 1.6877 - val_ca1-[11.3,14.9): 2.9075 - val_ca2-[8.0,9.5): 0.6209 - val_ca2-[9.5,10.3): 0.4144 - val_ca2-[10.3,11.3): 0.8036 - val_ca2-[11.3,14.9): 1.3149 - val_ca3-[8.0,9.5): 0.9161 - val_ca3-[9.5,10.3): 0.5792 - val_ca3-[10.3,11.3): 0.7109 - val_ca3-[11.3,14.9): 0.8581 - val_ca4-[8.0,9.5): 0.7419 - val_ca4-[9.5,10.3): 0.4829 - val_ca4-[10.3,11.3): 0.7342 - val_ca4-[11.3,14.9): 1.0441\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.8167 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3977 - ca2-[9.5,10.3): 0.5232 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5533 - ca3-[10.3,11.3): 0.6860 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6578 - ca4-[11.3,14.9): 1.0271 - val_ca1-[8.0,9.5): 0.7930 - val_ca1-[9.5,10.3): 0.7929 - val_ca1-[10.3,11.3): 1.6738 - val_ca1-[11.3,14.9): 2.8660 - val_ca2-[8.0,9.5): 0.6206 - val_ca2-[9.5,10.3): 0.4142 - val_ca2-[10.3,11.3): 0.8148 - val_ca2-[11.3,14.9): 1.3265 - val_ca3-[8.0,9.5): 0.9124 - val_ca3-[9.5,10.3): 0.5756 - val_ca3-[10.3,11.3): 0.7174 - val_ca3-[11.3,14.9): 0.8701 - val_ca4-[8.0,9.5): 0.7591 - val_ca4-[9.5,10.3): 0.4941 - val_ca4-[10.3,11.3): 0.7377 - val_ca4-[11.3,14.9): 1.0295\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.7946 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4076 - ca2-[9.5,10.3): 0.5364 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5469 - ca3-[10.3,11.3): 0.6793 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6730 - ca4-[11.3,14.9): 0.9999 - val_ca1-[8.0,9.5): 0.7772 - val_ca1-[9.5,10.3): 0.7720 - val_ca1-[10.3,11.3): 1.6310 - val_ca1-[11.3,14.9): 2.8291 - val_ca2-[8.0,9.5): 0.6190 - val_ca2-[9.5,10.3): 0.4138 - val_ca2-[10.3,11.3): 0.8119 - val_ca2-[11.3,14.9): 1.3472 - val_ca3-[8.0,9.5): 0.9119 - val_ca3-[9.5,10.3): 0.5743 - val_ca3-[10.3,11.3): 0.7139 - val_ca3-[11.3,14.9): 0.8869 - val_ca4-[8.0,9.5): 0.7766 - val_ca4-[9.5,10.3): 0.5058 - val_ca4-[10.3,11.3): 0.7312 - val_ca4-[11.3,14.9): 1.0200\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.7741 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4038 - ca2-[9.5,10.3): 0.5285 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5424 - ca3-[10.3,11.3): 0.6957 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6600 - ca4-[11.3,14.9): 0.9995 - val_ca1-[8.0,9.5): 0.7622 - val_ca1-[9.5,10.3): 0.7520 - val_ca1-[10.3,11.3): 1.6036 - val_ca1-[11.3,14.9): 2.8150 - val_ca2-[8.0,9.5): 0.6193 - val_ca2-[9.5,10.3): 0.4137 - val_ca2-[10.3,11.3): 0.8137 - val_ca2-[11.3,14.9): 1.3704 - val_ca3-[8.0,9.5): 0.9196 - val_ca3-[9.5,10.3): 0.5784 - val_ca3-[10.3,11.3): 0.7141 - val_ca3-[11.3,14.9): 0.8945 - val_ca4-[8.0,9.5): 0.7946 - val_ca4-[9.5,10.3): 0.5181 - val_ca4-[10.3,11.3): 0.7297 - val_ca4-[11.3,14.9): 1.0149\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.7556 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3985 - ca2-[9.5,10.3): 0.5100 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5445 - ca3-[10.3,11.3): 0.7102 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5810 - ca4-[11.3,14.9): 0.9682 - val_ca1-[8.0,9.5): 0.7486 - val_ca1-[9.5,10.3): 0.7336 - val_ca1-[10.3,11.3): 1.5856 - val_ca1-[11.3,14.9): 2.7073 - val_ca2-[8.0,9.5): 0.6198 - val_ca2-[9.5,10.3): 0.4135 - val_ca2-[10.3,11.3): 0.8136 - val_ca2-[11.3,14.9): 1.3212 - val_ca3-[8.0,9.5): 0.9106 - val_ca3-[9.5,10.3): 0.5716 - val_ca3-[10.3,11.3): 0.7069 - val_ca3-[11.3,14.9): 0.8645 - val_ca4-[8.0,9.5): 0.8124 - val_ca4-[9.5,10.3): 0.5305 - val_ca4-[10.3,11.3): 0.7240 - val_ca4-[11.3,14.9): 0.9509\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.7223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4147 - ca2-[9.5,10.3): 0.5225 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5096 - ca3-[10.3,11.3): 0.6981 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6033 - ca4-[11.3,14.9): 0.9380 - val_ca1-[8.0,9.5): 0.7358 - val_ca1-[9.5,10.3): 0.7163 - val_ca1-[10.3,11.3): 1.5458 - val_ca1-[11.3,14.9): 2.7297 - val_ca2-[8.0,9.5): 0.6192 - val_ca2-[9.5,10.3): 0.4134 - val_ca2-[10.3,11.3): 0.8150 - val_ca2-[11.3,14.9): 1.3617 - val_ca3-[8.0,9.5): 0.9033 - val_ca3-[9.5,10.3): 0.5667 - val_ca3-[10.3,11.3): 0.7117 - val_ca3-[11.3,14.9): 0.8882 - val_ca4-[8.0,9.5): 0.8304 - val_ca4-[9.5,10.3): 0.5433 - val_ca4-[10.3,11.3): 0.7289 - val_ca4-[11.3,14.9): 0.9562\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.7254 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4094 - ca2-[9.5,10.3): 0.5145 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5296 - ca3-[10.3,11.3): 0.6909 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6599 - ca4-[11.3,14.9): 0.9391 - val_ca1-[8.0,9.5): 0.7238 - val_ca1-[9.5,10.3): 0.6996 - val_ca1-[10.3,11.3): 1.5210 - val_ca1-[11.3,14.9): 2.6717 - val_ca2-[8.0,9.5): 0.6185 - val_ca2-[9.5,10.3): 0.4132 - val_ca2-[10.3,11.3): 0.8174 - val_ca2-[11.3,14.9): 1.3553 - val_ca3-[8.0,9.5): 0.9083 - val_ca3-[9.5,10.3): 0.5698 - val_ca3-[10.3,11.3): 0.7122 - val_ca3-[11.3,14.9): 0.8784 - val_ca4-[8.0,9.5): 0.8487 - val_ca4-[9.5,10.3): 0.5564 - val_ca4-[10.3,11.3): 0.7312 - val_ca4-[11.3,14.9): 0.9333\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.7025 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4008 - ca2-[9.5,10.3): 0.5082 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5277 - ca3-[10.3,11.3): 0.7017 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5951 - ca4-[11.3,14.9): 0.8959 - val_ca1-[8.0,9.5): 0.7125 - val_ca1-[9.5,10.3): 0.6838 - val_ca1-[10.3,11.3): 1.5007 - val_ca1-[11.3,14.9): 2.6308 - val_ca2-[8.0,9.5): 0.6186 - val_ca2-[9.5,10.3): 0.4128 - val_ca2-[10.3,11.3): 0.8202 - val_ca2-[11.3,14.9): 1.3660 - val_ca3-[8.0,9.5): 0.9204 - val_ca3-[9.5,10.3): 0.5775 - val_ca3-[10.3,11.3): 0.7152 - val_ca3-[11.3,14.9): 0.8856 - val_ca4-[8.0,9.5): 0.8670 - val_ca4-[9.5,10.3): 0.5697 - val_ca4-[10.3,11.3): 0.7342 - val_ca4-[11.3,14.9): 0.9318\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.7028 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3983 - ca2-[9.5,10.3): 0.5143 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5392 - ca3-[10.3,11.3): 0.6923 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6442 - ca4-[11.3,14.9): 0.9064 - val_ca1-[8.0,9.5): 0.7021 - val_ca1-[9.5,10.3): 0.6692 - val_ca1-[10.3,11.3): 1.4621 - val_ca1-[11.3,14.9): 2.5700 - val_ca2-[8.0,9.5): 0.6183 - val_ca2-[9.5,10.3): 0.4124 - val_ca2-[10.3,11.3): 0.8125 - val_ca2-[11.3,14.9): 1.3496 - val_ca3-[8.0,9.5): 0.9219 - val_ca3-[9.5,10.3): 0.5783 - val_ca3-[10.3,11.3): 0.7125 - val_ca3-[11.3,14.9): 0.8709 - val_ca4-[8.0,9.5): 0.8851 - val_ca4-[9.5,10.3): 0.5831 - val_ca4-[10.3,11.3): 0.7328 - val_ca4-[11.3,14.9): 0.9058\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.6747 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3988 - ca2-[9.5,10.3): 0.5146 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5644 - ca3-[10.3,11.3): 0.6945 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5752 - ca4-[11.3,14.9): 0.8694 - val_ca1-[8.0,9.5): 0.6927 - val_ca1-[9.5,10.3): 0.6559 - val_ca1-[10.3,11.3): 1.4265 - val_ca1-[11.3,14.9): 2.4612 - val_ca2-[8.0,9.5): 0.6171 - val_ca2-[9.5,10.3): 0.4120 - val_ca2-[10.3,11.3): 0.8090 - val_ca2-[11.3,14.9): 1.3051 - val_ca3-[8.0,9.5): 0.9133 - val_ca3-[9.5,10.3): 0.5725 - val_ca3-[10.3,11.3): 0.7121 - val_ca3-[11.3,14.9): 0.8500 - val_ca4-[8.0,9.5): 0.9027 - val_ca4-[9.5,10.3): 0.5961 - val_ca4-[10.3,11.3): 0.7352 - val_ca4-[11.3,14.9): 0.8556\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.6724 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3978 - ca2-[9.5,10.3): 0.5181 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5438 - ca3-[10.3,11.3): 0.6947 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5455 - ca4-[11.3,14.9): 0.8567 - val_ca1-[8.0,9.5): 0.6836 - val_ca1-[9.5,10.3): 0.6427 - val_ca1-[10.3,11.3): 1.4185 - val_ca1-[11.3,14.9): 2.5213 - val_ca2-[8.0,9.5): 0.6169 - val_ca2-[9.5,10.3): 0.4118 - val_ca2-[10.3,11.3): 0.8158 - val_ca2-[11.3,14.9): 1.3741 - val_ca3-[8.0,9.5): 0.9195 - val_ca3-[9.5,10.3): 0.5761 - val_ca3-[10.3,11.3): 0.7147 - val_ca3-[11.3,14.9): 0.8923 - val_ca4-[8.0,9.5): 0.9207 - val_ca4-[9.5,10.3): 0.6097 - val_ca4-[10.3,11.3): 0.7400 - val_ca4-[11.3,14.9): 0.8953\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.6546 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3981 - ca2-[9.5,10.3): 0.5231 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5473 - ca3-[10.3,11.3): 0.6781 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5742 - ca4-[11.3,14.9): 0.8441 - val_ca1-[8.0,9.5): 0.6753 - val_ca1-[9.5,10.3): 0.6305 - val_ca1-[10.3,11.3): 1.3900 - val_ca1-[11.3,14.9): 2.4503 - val_ca2-[8.0,9.5): 0.6168 - val_ca2-[9.5,10.3): 0.4115 - val_ca2-[10.3,11.3): 0.8118 - val_ca2-[11.3,14.9): 1.3525 - val_ca3-[8.0,9.5): 0.9190 - val_ca3-[9.5,10.3): 0.5754 - val_ca3-[10.3,11.3): 0.7135 - val_ca3-[11.3,14.9): 0.8843 - val_ca4-[8.0,9.5): 0.9384 - val_ca4-[9.5,10.3): 0.6231 - val_ca4-[10.3,11.3): 0.7422 - val_ca4-[11.3,14.9): 0.8731\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.6451 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3866 - ca2-[9.5,10.3): 0.4953 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5378 - ca3-[10.3,11.3): 0.6989 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5627 - ca4-[11.3,14.9): 0.8414 - val_ca1-[8.0,9.5): 0.6676 - val_ca1-[9.5,10.3): 0.6190 - val_ca1-[10.3,11.3): 1.3751 - val_ca1-[11.3,14.9): 2.4498 - val_ca2-[8.0,9.5): 0.6163 - val_ca2-[9.5,10.3): 0.4112 - val_ca2-[10.3,11.3): 0.8133 - val_ca2-[11.3,14.9): 1.3681 - val_ca3-[8.0,9.5): 0.9199 - val_ca3-[9.5,10.3): 0.5758 - val_ca3-[10.3,11.3): 0.7122 - val_ca3-[11.3,14.9): 0.8849 - val_ca4-[8.0,9.5): 0.9559 - val_ca4-[9.5,10.3): 0.6364 - val_ca4-[10.3,11.3): 0.7440 - val_ca4-[11.3,14.9): 0.8649\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.6441 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3934 - ca2-[9.5,10.3): 0.5114 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5317 - ca3-[10.3,11.3): 0.6978 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5432 - ca4-[11.3,14.9): 0.8290 - val_ca1-[8.0,9.5): 0.6605 - val_ca1-[9.5,10.3): 0.6083 - val_ca1-[10.3,11.3): 1.3652 - val_ca1-[11.3,14.9): 2.3864 - val_ca2-[8.0,9.5): 0.6154 - val_ca2-[9.5,10.3): 0.4109 - val_ca2-[10.3,11.3): 0.8151 - val_ca2-[11.3,14.9): 1.3459 - val_ca3-[8.0,9.5): 0.9183 - val_ca3-[9.5,10.3): 0.5744 - val_ca3-[10.3,11.3): 0.7064 - val_ca3-[11.3,14.9): 0.8684 - val_ca4-[8.0,9.5): 0.9730 - val_ca4-[9.5,10.3): 0.6495 - val_ca4-[10.3,11.3): 0.7401 - val_ca4-[11.3,14.9): 0.8316\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.6322 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4000 - ca2-[9.5,10.3): 0.5116 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5356 - ca3-[10.3,11.3): 0.6843 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5897 - ca4-[11.3,14.9): 0.8189 - val_ca1-[8.0,9.5): 0.6537 - val_ca1-[9.5,10.3): 0.5980 - val_ca1-[10.3,11.3): 1.3442 - val_ca1-[11.3,14.9): 2.3764 - val_ca2-[8.0,9.5): 0.6152 - val_ca2-[9.5,10.3): 0.4107 - val_ca2-[10.3,11.3): 0.8180 - val_ca2-[11.3,14.9): 1.3635 - val_ca3-[8.0,9.5): 0.9173 - val_ca3-[9.5,10.3): 0.5735 - val_ca3-[10.3,11.3): 0.7125 - val_ca3-[11.3,14.9): 0.8804 - val_ca4-[8.0,9.5): 0.9900 - val_ca4-[9.5,10.3): 0.6627 - val_ca4-[10.3,11.3): 0.7520 - val_ca4-[11.3,14.9): 0.8375\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.6146 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3967 - ca2-[9.5,10.3): 0.5095 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5498 - ca3-[10.3,11.3): 0.6959 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5642 - ca4-[11.3,14.9): 0.8126 - val_ca1-[8.0,9.5): 0.6476 - val_ca1-[9.5,10.3): 0.5886 - val_ca1-[10.3,11.3): 1.3131 - val_ca1-[11.3,14.9): 2.3219 - val_ca2-[8.0,9.5): 0.6132 - val_ca2-[9.5,10.3): 0.4104 - val_ca2-[10.3,11.3): 0.8147 - val_ca2-[11.3,14.9): 1.3547 - val_ca3-[8.0,9.5): 0.9120 - val_ca3-[9.5,10.3): 0.5699 - val_ca3-[10.3,11.3): 0.7118 - val_ca3-[11.3,14.9): 0.8762 - val_ca4-[8.0,9.5): 1.0064 - val_ca4-[9.5,10.3): 0.6754 - val_ca4-[10.3,11.3): 0.7549 - val_ca4-[11.3,14.9): 0.8197\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.6199 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3872 - ca2-[9.5,10.3): 0.5110 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5406 - ca3-[10.3,11.3): 0.6946 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5725 - ca4-[11.3,14.9): 0.8036 - val_ca1-[8.0,9.5): 0.6418 - val_ca1-[9.5,10.3): 0.5794 - val_ca1-[10.3,11.3): 1.3047 - val_ca1-[11.3,14.9): 2.2897 - val_ca2-[8.0,9.5): 0.6134 - val_ca2-[9.5,10.3): 0.4101 - val_ca2-[10.3,11.3): 0.8187 - val_ca2-[11.3,14.9): 1.3472 - val_ca3-[8.0,9.5): 0.9131 - val_ca3-[9.5,10.3): 0.5702 - val_ca3-[10.3,11.3): 0.7143 - val_ca3-[11.3,14.9): 0.8670 - val_ca4-[8.0,9.5): 1.0228 - val_ca4-[9.5,10.3): 0.6883 - val_ca4-[10.3,11.3): 0.7619 - val_ca4-[11.3,14.9): 0.8051\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.6150 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3929 - ca2-[9.5,10.3): 0.5101 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5419 - ca3-[10.3,11.3): 0.7094 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5520 - ca4-[11.3,14.9): 0.7848 - val_ca1-[8.0,9.5): 0.6363 - val_ca1-[9.5,10.3): 0.5706 - val_ca1-[10.3,11.3): 1.2929 - val_ca1-[11.3,14.9): 2.2807 - val_ca2-[8.0,9.5): 0.6136 - val_ca2-[9.5,10.3): 0.4099 - val_ca2-[10.3,11.3): 0.8188 - val_ca2-[11.3,14.9): 1.3671 - val_ca3-[8.0,9.5): 0.9190 - val_ca3-[9.5,10.3): 0.5734 - val_ca3-[10.3,11.3): 0.7123 - val_ca3-[11.3,14.9): 0.8842 - val_ca4-[8.0,9.5): 1.0391 - val_ca4-[9.5,10.3): 0.7010 - val_ca4-[10.3,11.3): 0.7642 - val_ca4-[11.3,14.9): 0.8226\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5945 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3966 - ca2-[9.5,10.3): 0.5182 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5251 - ca3-[10.3,11.3): 0.6817 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5287 - ca4-[11.3,14.9): 0.7917 - val_ca1-[8.0,9.5): 0.6312 - val_ca1-[9.5,10.3): 0.5622 - val_ca1-[10.3,11.3): 1.2702 - val_ca1-[11.3,14.9): 2.2297 - val_ca2-[8.0,9.5): 0.6138 - val_ca2-[9.5,10.3): 0.4097 - val_ca2-[10.3,11.3): 0.8144 - val_ca2-[11.3,14.9): 1.3423 - val_ca3-[8.0,9.5): 0.9258 - val_ca3-[9.5,10.3): 0.5773 - val_ca3-[10.3,11.3): 0.7120 - val_ca3-[11.3,14.9): 0.8636 - val_ca4-[8.0,9.5): 1.0554 - val_ca4-[9.5,10.3): 0.7139 - val_ca4-[10.3,11.3): 0.7685 - val_ca4-[11.3,14.9): 0.7933\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.6082 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3728 - ca2-[9.5,10.3): 0.5116 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5489 - ca3-[10.3,11.3): 0.6777 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5505 - ca4-[11.3,14.9): 0.7762 - val_ca1-[8.0,9.5): 0.6266 - val_ca1-[9.5,10.3): 0.5546 - val_ca1-[10.3,11.3): 1.2617 - val_ca1-[11.3,14.9): 2.2626 - val_ca2-[8.0,9.5): 0.6117 - val_ca2-[9.5,10.3): 0.4094 - val_ca2-[10.3,11.3): 0.8167 - val_ca2-[11.3,14.9): 1.3865 - val_ca3-[8.0,9.5): 0.9244 - val_ca3-[9.5,10.3): 0.5762 - val_ca3-[10.3,11.3): 0.7037 - val_ca3-[11.3,14.9): 0.8774 - val_ca4-[8.0,9.5): 1.0708 - val_ca4-[9.5,10.3): 0.7261 - val_ca4-[10.3,11.3): 0.7618 - val_ca4-[11.3,14.9): 0.7909\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5873 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3887 - ca2-[9.5,10.3): 0.5178 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5273 - ca3-[10.3,11.3): 0.6948 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4941 - ca4-[11.3,14.9): 0.7804 - val_ca1-[8.0,9.5): 0.6224 - val_ca1-[9.5,10.3): 0.5475 - val_ca1-[10.3,11.3): 1.2538 - val_ca1-[11.3,14.9): 2.2228 - val_ca2-[8.0,9.5): 0.6106 - val_ca2-[9.5,10.3): 0.4092 - val_ca2-[10.3,11.3): 0.8274 - val_ca2-[11.3,14.9): 1.3777 - val_ca3-[8.0,9.5): 0.9162 - val_ca3-[9.5,10.3): 0.5711 - val_ca3-[10.3,11.3): 0.7146 - val_ca3-[11.3,14.9): 0.8707 - val_ca4-[8.0,9.5): 1.0859 - val_ca4-[9.5,10.3): 0.7381 - val_ca4-[10.3,11.3): 0.7788 - val_ca4-[11.3,14.9): 0.7751\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5727 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3949 - ca2-[9.5,10.3): 0.5127 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5324 - ca3-[10.3,11.3): 0.6837 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5097 - ca4-[11.3,14.9): 0.7576 - val_ca1-[8.0,9.5): 0.6184 - val_ca1-[9.5,10.3): 0.5406 - val_ca1-[10.3,11.3): 1.2292 - val_ca1-[11.3,14.9): 2.1708 - val_ca2-[8.0,9.5): 0.6099 - val_ca2-[9.5,10.3): 0.4089 - val_ca2-[10.3,11.3): 0.8181 - val_ca2-[11.3,14.9): 1.3668 - val_ca3-[8.0,9.5): 0.9172 - val_ca3-[9.5,10.3): 0.5714 - val_ca3-[10.3,11.3): 0.7054 - val_ca3-[11.3,14.9): 0.8713 - val_ca4-[8.0,9.5): 1.1009 - val_ca4-[9.5,10.3): 0.7501 - val_ca4-[10.3,11.3): 0.7731 - val_ca4-[11.3,14.9): 0.7733\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5824 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3884 - ca2-[9.5,10.3): 0.5073 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5276 - ca3-[10.3,11.3): 0.6840 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5340 - ca4-[11.3,14.9): 0.7731 - val_ca1-[8.0,9.5): 0.6147 - val_ca1-[9.5,10.3): 0.5337 - val_ca1-[10.3,11.3): 1.2228 - val_ca1-[11.3,14.9): 2.1669 - val_ca2-[8.0,9.5): 0.6100 - val_ca2-[9.5,10.3): 0.4093 - val_ca2-[10.3,11.3): 0.8247 - val_ca2-[11.3,14.9): 1.3837 - val_ca3-[8.0,9.5): 0.9213 - val_ca3-[9.5,10.3): 0.5754 - val_ca3-[10.3,11.3): 0.7137 - val_ca3-[11.3,14.9): 0.8894 - val_ca4-[8.0,9.5): 1.1154 - val_ca4-[9.5,10.3): 0.7643 - val_ca4-[10.3,11.3): 0.7894 - val_ca4-[11.3,14.9): 0.7911\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5952 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3865 - ca2-[9.5,10.3): 0.5107 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5495 - ca3-[10.3,11.3): 0.6783 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5353 - ca4-[11.3,14.9): 0.7583 - val_ca1-[8.0,9.5): 0.6113 - val_ca1-[9.5,10.3): 0.5280 - val_ca1-[10.3,11.3): 1.2023 - val_ca1-[11.3,14.9): 2.1452 - val_ca2-[8.0,9.5): 0.6091 - val_ca2-[9.5,10.3): 0.4084 - val_ca2-[10.3,11.3): 0.8209 - val_ca2-[11.3,14.9): 1.3841 - val_ca3-[8.0,9.5): 0.9195 - val_ca3-[9.5,10.3): 0.5723 - val_ca3-[10.3,11.3): 0.7111 - val_ca3-[11.3,14.9): 0.8828 - val_ca4-[8.0,9.5): 1.1293 - val_ca4-[9.5,10.3): 0.7729 - val_ca4-[10.3,11.3): 0.7917 - val_ca4-[11.3,14.9): 0.7781\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5784 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3944 - ca2-[9.5,10.3): 0.5025 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5495 - ca3-[10.3,11.3): 0.6957 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5435 - ca4-[11.3,14.9): 0.7491 - val_ca1-[8.0,9.5): 0.6082 - val_ca1-[9.5,10.3): 0.5222 - val_ca1-[10.3,11.3): 1.1778 - val_ca1-[11.3,14.9): 2.1103 - val_ca2-[8.0,9.5): 0.6082 - val_ca2-[9.5,10.3): 0.4082 - val_ca2-[10.3,11.3): 0.8117 - val_ca2-[11.3,14.9): 1.3767 - val_ca3-[8.0,9.5): 0.9173 - val_ca3-[9.5,10.3): 0.5708 - val_ca3-[10.3,11.3): 0.7047 - val_ca3-[11.3,14.9): 0.8790 - val_ca4-[8.0,9.5): 1.1431 - val_ca4-[9.5,10.3): 0.7841 - val_ca4-[10.3,11.3): 0.7903 - val_ca4-[11.3,14.9): 0.7646\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5836 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3822 - ca2-[9.5,10.3): 0.5149 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5259 - ca3-[10.3,11.3): 0.6758 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4810 - ca4-[11.3,14.9): 0.7312 - val_ca1-[8.0,9.5): 0.6053 - val_ca1-[9.5,10.3): 0.5168 - val_ca1-[10.3,11.3): 1.1853 - val_ca1-[11.3,14.9): 2.1044 - val_ca2-[8.0,9.5): 0.6068 - val_ca2-[9.5,10.3): 0.4079 - val_ca2-[10.3,11.3): 0.8273 - val_ca2-[11.3,14.9): 1.3935 - val_ca3-[8.0,9.5): 0.9158 - val_ca3-[9.5,10.3): 0.5696 - val_ca3-[10.3,11.3): 0.7109 - val_ca3-[11.3,14.9): 0.8876 - val_ca4-[8.0,9.5): 1.1563 - val_ca4-[9.5,10.3): 0.7948 - val_ca4-[10.3,11.3): 0.8007 - val_ca4-[11.3,14.9): 0.7691\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5663 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3919 - ca2-[9.5,10.3): 0.5108 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4969 - ca3-[10.3,11.3): 0.6835 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5047 - ca4-[11.3,14.9): 0.7514 - val_ca1-[8.0,9.5): 0.6026 - val_ca1-[9.5,10.3): 0.5117 - val_ca1-[10.3,11.3): 1.1751 - val_ca1-[11.3,14.9): 2.0334 - val_ca2-[8.0,9.5): 0.6057 - val_ca2-[9.5,10.3): 0.4076 - val_ca2-[10.3,11.3): 0.8259 - val_ca2-[11.3,14.9): 1.3529 - val_ca3-[8.0,9.5): 0.9192 - val_ca3-[9.5,10.3): 0.5713 - val_ca3-[10.3,11.3): 0.7045 - val_ca3-[11.3,14.9): 0.8491 - val_ca4-[8.0,9.5): 1.1694 - val_ca4-[9.5,10.3): 0.8053 - val_ca4-[10.3,11.3): 0.7956 - val_ca4-[11.3,14.9): 0.7368\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 0.5612 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3907 - ca2-[9.5,10.3): 0.5134 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5491 - ca3-[10.3,11.3): 0.6918 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5093 - ca4-[11.3,14.9): 0.7350 - val_ca1-[8.0,9.5): 0.6001 - val_ca1-[9.5,10.3): 0.5067 - val_ca1-[10.3,11.3): 1.1654 - val_ca1-[11.3,14.9): 2.0810 - val_ca2-[8.0,9.5): 0.6057 - val_ca2-[9.5,10.3): 0.4074 - val_ca2-[10.3,11.3): 0.8290 - val_ca2-[11.3,14.9): 1.4072 - val_ca3-[8.0,9.5): 0.9218 - val_ca3-[9.5,10.3): 0.5728 - val_ca3-[10.3,11.3): 0.7128 - val_ca3-[11.3,14.9): 0.8934 - val_ca4-[8.0,9.5): 1.1823 - val_ca4-[9.5,10.3): 0.8159 - val_ca4-[10.3,11.3): 0.8124 - val_ca4-[11.3,14.9): 0.7696\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5636 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3834 - ca2-[9.5,10.3): 0.5078 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5548 - ca3-[10.3,11.3): 0.6748 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5334 - ca4-[11.3,14.9): 0.7549 - val_ca1-[8.0,9.5): 0.5978 - val_ca1-[9.5,10.3): 0.5036 - val_ca1-[10.3,11.3): 1.1474 - val_ca1-[11.3,14.9): 2.0248 - val_ca2-[8.0,9.5): 0.6047 - val_ca2-[9.5,10.3): 0.4075 - val_ca2-[10.3,11.3): 0.8242 - val_ca2-[11.3,14.9): 1.3807 - val_ca3-[8.0,9.5): 0.9243 - val_ca3-[9.5,10.3): 0.5734 - val_ca3-[10.3,11.3): 0.7103 - val_ca3-[11.3,14.9): 0.8721 - val_ca4-[8.0,9.5): 1.1948 - val_ca4-[9.5,10.3): 0.8242 - val_ca4-[10.3,11.3): 0.8149 - val_ca4-[11.3,14.9): 0.7552\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5633 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3832 - ca2-[9.5,10.3): 0.4942 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5511 - ca3-[10.3,11.3): 0.6876 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5268 - ca4-[11.3,14.9): 0.7342 - val_ca1-[8.0,9.5): 0.5958 - val_ca1-[9.5,10.3): 0.4978 - val_ca1-[10.3,11.3): 1.1398 - val_ca1-[11.3,14.9): 2.0489 - val_ca2-[8.0,9.5): 0.6039 - val_ca2-[9.5,10.3): 0.4067 - val_ca2-[10.3,11.3): 0.8262 - val_ca2-[11.3,14.9): 1.4122 - val_ca3-[8.0,9.5): 0.9203 - val_ca3-[9.5,10.3): 0.5721 - val_ca3-[10.3,11.3): 0.7122 - val_ca3-[11.3,14.9): 0.8910 - val_ca4-[8.0,9.5): 1.2064 - val_ca4-[9.5,10.3): 0.8356 - val_ca4-[10.3,11.3): 0.8218 - val_ca4-[11.3,14.9): 0.7624\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5611 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3860 - ca2-[9.5,10.3): 0.5129 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5483 - ca3-[10.3,11.3): 0.6909 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5311 - ca4-[11.3,14.9): 0.7455 - val_ca1-[8.0,9.5): 0.5939 - val_ca1-[9.5,10.3): 0.4938 - val_ca1-[10.3,11.3): 1.1229 - val_ca1-[11.3,14.9): 2.0213 - val_ca2-[8.0,9.5): 0.6035 - val_ca2-[9.5,10.3): 0.4063 - val_ca2-[10.3,11.3): 0.8197 - val_ca2-[11.3,14.9): 1.4046 - val_ca3-[8.0,9.5): 0.9173 - val_ca3-[9.5,10.3): 0.5700 - val_ca3-[10.3,11.3): 0.7093 - val_ca3-[11.3,14.9): 0.8940 - val_ca4-[8.0,9.5): 1.2180 - val_ca4-[9.5,10.3): 0.8450 - val_ca4-[10.3,11.3): 0.8243 - val_ca4-[11.3,14.9): 0.7577\n",
      "Epoch 97/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5515 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3953 - ca2-[9.5,10.3): 0.4987 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5348 - ca3-[10.3,11.3): 0.6867 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5186 - ca4-[11.3,14.9): 0.7322 - val_ca1-[8.0,9.5): 0.5921 - val_ca1-[9.5,10.3): 0.4899 - val_ca1-[10.3,11.3): 1.1259 - val_ca1-[11.3,14.9): 1.9602 - val_ca2-[8.0,9.5): 0.6011 - val_ca2-[9.5,10.3): 0.4060 - val_ca2-[10.3,11.3): 0.8313 - val_ca2-[11.3,14.9): 1.3783 - val_ca3-[8.0,9.5): 0.9196 - val_ca3-[9.5,10.3): 0.5713 - val_ca3-[10.3,11.3): 0.7103 - val_ca3-[11.3,14.9): 0.8654 - val_ca4-[8.0,9.5): 1.2291 - val_ca4-[9.5,10.3): 0.8542 - val_ca4-[10.3,11.3): 0.8274 - val_ca4-[11.3,14.9): 0.7388\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5467 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3790 - ca2-[9.5,10.3): 0.5065 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5138 - ca3-[10.3,11.3): 0.6896 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5555 - ca4-[11.3,14.9): 0.7411 - val_ca1-[8.0,9.5): 0.5905 - val_ca1-[9.5,10.3): 0.4862 - val_ca1-[10.3,11.3): 1.1190 - val_ca1-[11.3,14.9): 1.9678 - val_ca2-[8.0,9.5): 0.6000 - val_ca2-[9.5,10.3): 0.4056 - val_ca2-[10.3,11.3): 0.8341 - val_ca2-[11.3,14.9): 1.3990 - val_ca3-[8.0,9.5): 0.9236 - val_ca3-[9.5,10.3): 0.5737 - val_ca3-[10.3,11.3): 0.7126 - val_ca3-[11.3,14.9): 0.8713 - val_ca4-[8.0,9.5): 1.2403 - val_ca4-[9.5,10.3): 0.8633 - val_ca4-[10.3,11.3): 0.8342 - val_ca4-[11.3,14.9): 0.7420\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5557 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3698 - ca2-[9.5,10.3): 0.5017 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5534 - ca3-[10.3,11.3): 0.6772 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5669 - ca4-[11.3,14.9): 0.7075 - val_ca1-[8.0,9.5): 0.5890 - val_ca1-[9.5,10.3): 0.4828 - val_ca1-[10.3,11.3): 1.1053 - val_ca1-[11.3,14.9): 1.9811 - val_ca2-[8.0,9.5): 0.5989 - val_ca2-[9.5,10.3): 0.4051 - val_ca2-[10.3,11.3): 0.8312 - val_ca2-[11.3,14.9): 1.4260 - val_ca3-[8.0,9.5): 0.9222 - val_ca3-[9.5,10.3): 0.5728 - val_ca3-[10.3,11.3): 0.7121 - val_ca3-[11.3,14.9): 0.8890 - val_ca4-[8.0,9.5): 1.2504 - val_ca4-[9.5,10.3): 0.8717 - val_ca4-[10.3,11.3): 0.8389 - val_ca4-[11.3,14.9): 0.7516\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5399 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3947 - ca2-[9.5,10.3): 0.4936 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5571 - ca3-[10.3,11.3): 0.6859 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4911 - ca4-[11.3,14.9): 0.7205 - val_ca1-[8.0,9.5): 0.5877 - val_ca1-[9.5,10.3): 0.4796 - val_ca1-[10.3,11.3): 1.0976 - val_ca1-[11.3,14.9): 1.9162 - val_ca2-[8.0,9.5): 0.5965 - val_ca2-[9.5,10.3): 0.4049 - val_ca2-[10.3,11.3): 0.8361 - val_ca2-[11.3,14.9): 1.3957 - val_ca3-[8.0,9.5): 0.9202 - val_ca3-[9.5,10.3): 0.5719 - val_ca3-[10.3,11.3): 0.7121 - val_ca3-[11.3,14.9): 0.8632 - val_ca4-[8.0,9.5): 1.2604 - val_ca4-[9.5,10.3): 0.8799 - val_ca4-[10.3,11.3): 0.8429 - val_ca4-[11.3,14.9): 0.7322\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5480 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3814 - ca2-[9.5,10.3): 0.5044 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5457 - ca3-[10.3,11.3): 0.7011 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4992 - ca4-[11.3,14.9): 0.7215 - val_ca1-[8.0,9.5): 0.5865 - val_ca1-[9.5,10.3): 0.4765 - val_ca1-[10.3,11.3): 1.0960 - val_ca1-[11.3,14.9): 1.9468 - val_ca2-[8.0,9.5): 0.5961 - val_ca2-[9.5,10.3): 0.4045 - val_ca2-[10.3,11.3): 0.8377 - val_ca2-[11.3,14.9): 1.4246 - val_ca3-[8.0,9.5): 0.9152 - val_ca3-[9.5,10.3): 0.5688 - val_ca3-[10.3,11.3): 0.7121 - val_ca3-[11.3,14.9): 0.8827 - val_ca4-[8.0,9.5): 1.2705 - val_ca4-[9.5,10.3): 0.8883 - val_ca4-[10.3,11.3): 0.8462 - val_ca4-[11.3,14.9): 0.7340\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5312 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3741 - ca2-[9.5,10.3): 0.5036 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5526 - ca3-[10.3,11.3): 0.6976 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5149 - ca4-[11.3,14.9): 0.7077 - val_ca1-[8.0,9.5): 0.5853 - val_ca1-[9.5,10.3): 0.4737 - val_ca1-[10.3,11.3): 1.0903 - val_ca1-[11.3,14.9): 1.9339 - val_ca2-[8.0,9.5): 0.5954 - val_ca2-[9.5,10.3): 0.4041 - val_ca2-[10.3,11.3): 0.8374 - val_ca2-[11.3,14.9): 1.4250 - val_ca3-[8.0,9.5): 0.9181 - val_ca3-[9.5,10.3): 0.5698 - val_ca3-[10.3,11.3): 0.7103 - val_ca3-[11.3,14.9): 0.8827 - val_ca4-[8.0,9.5): 1.2801 - val_ca4-[9.5,10.3): 0.8962 - val_ca4-[10.3,11.3): 0.8455 - val_ca4-[11.3,14.9): 0.7321\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5386 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3603 - ca2-[9.5,10.3): 0.4999 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5451 - ca3-[10.3,11.3): 0.6864 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4946 - ca4-[11.3,14.9): 0.7092 - val_ca1-[8.0,9.5): 0.5843 - val_ca1-[9.5,10.3): 0.4710 - val_ca1-[10.3,11.3): 1.0804 - val_ca1-[11.3,14.9): 1.8666 - val_ca2-[8.0,9.5): 0.5941 - val_ca2-[9.5,10.3): 0.4039 - val_ca2-[10.3,11.3): 0.8377 - val_ca2-[11.3,14.9): 1.3859 - val_ca3-[8.0,9.5): 0.9135 - val_ca3-[9.5,10.3): 0.5673 - val_ca3-[10.3,11.3): 0.7095 - val_ca3-[11.3,14.9): 0.8557 - val_ca4-[8.0,9.5): 1.2891 - val_ca4-[9.5,10.3): 0.9036 - val_ca4-[10.3,11.3): 0.8512 - val_ca4-[11.3,14.9): 0.7093\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5317 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3758 - ca2-[9.5,10.3): 0.4985 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5423 - ca3-[10.3,11.3): 0.6897 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5384 - ca4-[11.3,14.9): 0.7098 - val_ca1-[8.0,9.5): 0.5834 - val_ca1-[9.5,10.3): 0.4683 - val_ca1-[10.3,11.3): 1.0561 - val_ca1-[11.3,14.9): 1.8918 - val_ca2-[8.0,9.5): 0.5934 - val_ca2-[9.5,10.3): 0.4035 - val_ca2-[10.3,11.3): 0.8228 - val_ca2-[11.3,14.9): 1.4183 - val_ca3-[8.0,9.5): 0.9147 - val_ca3-[9.5,10.3): 0.5680 - val_ca3-[10.3,11.3): 0.7028 - val_ca3-[11.3,14.9): 0.8787 - val_ca4-[8.0,9.5): 1.2983 - val_ca4-[9.5,10.3): 0.9112 - val_ca4-[10.3,11.3): 0.8505 - val_ca4-[11.3,14.9): 0.7208\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5370 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3654 - ca2-[9.5,10.3): 0.4975 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5629 - ca3-[10.3,11.3): 0.6873 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5087 - ca4-[11.3,14.9): 0.7204 - val_ca1-[8.0,9.5): 0.5825 - val_ca1-[9.5,10.3): 0.4658 - val_ca1-[10.3,11.3): 1.0496 - val_ca1-[11.3,14.9): 1.8396 - val_ca2-[8.0,9.5): 0.5930 - val_ca2-[9.5,10.3): 0.4031 - val_ca2-[10.3,11.3): 0.8221 - val_ca2-[11.3,14.9): 1.3858 - val_ca3-[8.0,9.5): 0.9239 - val_ca3-[9.5,10.3): 0.5726 - val_ca3-[10.3,11.3): 0.7031 - val_ca3-[11.3,14.9): 0.8566 - val_ca4-[8.0,9.5): 1.3074 - val_ca4-[9.5,10.3): 0.9188 - val_ca4-[10.3,11.3): 0.8543 - val_ca4-[11.3,14.9): 0.7157\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5342 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3674 - ca2-[9.5,10.3): 0.4842 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5313 - ca3-[10.3,11.3): 0.7000 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5479 - ca4-[11.3,14.9): 0.7100 - val_ca1-[8.0,9.5): 0.5818 - val_ca1-[9.5,10.3): 0.4634 - val_ca1-[10.3,11.3): 1.0645 - val_ca1-[11.3,14.9): 1.8814 - val_ca2-[8.0,9.5): 0.5920 - val_ca2-[9.5,10.3): 0.4028 - val_ca2-[10.3,11.3): 0.8416 - val_ca2-[11.3,14.9): 1.4325 - val_ca3-[8.0,9.5): 0.9257 - val_ca3-[9.5,10.3): 0.5736 - val_ca3-[10.3,11.3): 0.7139 - val_ca3-[11.3,14.9): 0.8821 - val_ca4-[8.0,9.5): 1.3162 - val_ca4-[9.5,10.3): 0.9261 - val_ca4-[10.3,11.3): 0.8675 - val_ca4-[11.3,14.9): 0.7347\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5262 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3774 - ca2-[9.5,10.3): 0.4981 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5685 - ca3-[10.3,11.3): 0.6883 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5419 - ca4-[11.3,14.9): 0.7133 - val_ca1-[8.0,9.5): 0.5811 - val_ca1-[9.5,10.3): 0.4613 - val_ca1-[10.3,11.3): 1.0554 - val_ca1-[11.3,14.9): 1.8618 - val_ca2-[8.0,9.5): 0.5906 - val_ca2-[9.5,10.3): 0.4027 - val_ca2-[10.3,11.3): 0.8406 - val_ca2-[11.3,14.9): 1.4336 - val_ca3-[8.0,9.5): 0.9187 - val_ca3-[9.5,10.3): 0.5700 - val_ca3-[10.3,11.3): 0.7089 - val_ca3-[11.3,14.9): 0.8805 - val_ca4-[8.0,9.5): 1.3241 - val_ca4-[9.5,10.3): 0.9326 - val_ca4-[10.3,11.3): 0.8658 - val_ca4-[11.3,14.9): 0.7276\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5154 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3745 - ca2-[9.5,10.3): 0.4944 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5317 - ca3-[10.3,11.3): 0.6808 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5186 - ca4-[11.3,14.9): 0.6951 - val_ca1-[8.0,9.5): 0.5805 - val_ca1-[9.5,10.3): 0.4594 - val_ca1-[10.3,11.3): 1.0522 - val_ca1-[11.3,14.9): 1.8446 - val_ca2-[8.0,9.5): 0.5897 - val_ca2-[9.5,10.3): 0.4023 - val_ca2-[10.3,11.3): 0.8428 - val_ca2-[11.3,14.9): 1.4302 - val_ca3-[8.0,9.5): 0.9134 - val_ca3-[9.5,10.3): 0.5664 - val_ca3-[10.3,11.3): 0.7109 - val_ca3-[11.3,14.9): 0.8863 - val_ca4-[8.0,9.5): 1.3312 - val_ca4-[9.5,10.3): 0.9386 - val_ca4-[10.3,11.3): 0.8713 - val_ca4-[11.3,14.9): 0.7298\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5329 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3737 - ca2-[9.5,10.3): 0.4868 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5527 - ca3-[10.3,11.3): 0.7079 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5478 - ca4-[11.3,14.9): 0.7091 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4574 - val_ca1-[10.3,11.3): 1.0468 - val_ca1-[11.3,14.9): 1.8661 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4018 - val_ca2-[10.3,11.3): 0.8427 - val_ca2-[11.3,14.9): 1.4532 - val_ca3-[8.0,9.5): 0.9220 - val_ca3-[9.5,10.3): 0.5706 - val_ca3-[10.3,11.3): 0.7112 - val_ca3-[11.3,14.9): 0.8894 - val_ca4-[8.0,9.5): 1.3389 - val_ca4-[9.5,10.3): 0.9449 - val_ca4-[10.3,11.3): 0.8746 - val_ca4-[11.3,14.9): 0.7248\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5207 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3683 - ca2-[9.5,10.3): 0.4924 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5453 - ca3-[10.3,11.3): 0.6920 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5112 - ca4-[11.3,14.9): 0.7007 - val_ca1-[8.0,9.5): 0.5795 - val_ca1-[9.5,10.3): 0.4555 - val_ca1-[10.3,11.3): 1.0361 - val_ca1-[11.3,14.9): 1.8116 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4015 - val_ca2-[10.3,11.3): 0.8395 - val_ca2-[11.3,14.9): 1.4220 - val_ca3-[8.0,9.5): 0.9257 - val_ca3-[9.5,10.3): 0.5724 - val_ca3-[10.3,11.3): 0.7111 - val_ca3-[11.3,14.9): 0.8723 - val_ca4-[8.0,9.5): 1.3466 - val_ca4-[9.5,10.3): 0.9513 - val_ca4-[10.3,11.3): 0.8790 - val_ca4-[11.3,14.9): 0.7148\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5229 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3704 - ca2-[9.5,10.3): 0.4861 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5410 - ca3-[10.3,11.3): 0.6891 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5149 - ca4-[11.3,14.9): 0.7114 - val_ca1-[8.0,9.5): 0.5790 - val_ca1-[9.5,10.3): 0.4537 - val_ca1-[10.3,11.3): 1.0203 - val_ca1-[11.3,14.9): 1.8511 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4012 - val_ca2-[10.3,11.3): 0.8305 - val_ca2-[11.3,14.9): 1.4603 - val_ca3-[8.0,9.5): 0.9174 - val_ca3-[9.5,10.3): 0.5685 - val_ca3-[10.3,11.3): 0.7080 - val_ca3-[11.3,14.9): 0.9038 - val_ca4-[8.0,9.5): 1.3540 - val_ca4-[9.5,10.3): 0.9575 - val_ca4-[10.3,11.3): 0.8845 - val_ca4-[11.3,14.9): 0.7389\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5283 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3778 - ca2-[9.5,10.3): 0.4855 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5325 - ca3-[10.3,11.3): 0.6910 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4783 - ca4-[11.3,14.9): 0.6973 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4520 - val_ca1-[10.3,11.3): 1.0314 - val_ca1-[11.3,14.9): 1.8292 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4018 - val_ca2-[10.3,11.3): 0.8423 - val_ca2-[11.3,14.9): 1.4503 - val_ca3-[8.0,9.5): 0.9232 - val_ca3-[9.5,10.3): 0.5720 - val_ca3-[10.3,11.3): 0.7107 - val_ca3-[11.3,14.9): 0.8957 - val_ca4-[8.0,9.5): 1.3653 - val_ca4-[9.5,10.3): 0.9667 - val_ca4-[10.3,11.3): 0.8844 - val_ca4-[11.3,14.9): 0.7343\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5249 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3830 - ca2-[9.5,10.3): 0.4845 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5224 - ca3-[10.3,11.3): 0.6944 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5092 - ca4-[11.3,14.9): 0.6965 - val_ca1-[8.0,9.5): 0.5783 - val_ca1-[9.5,10.3): 0.4502 - val_ca1-[10.3,11.3): 1.0247 - val_ca1-[11.3,14.9): 1.7808 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.4007 - val_ca2-[10.3,11.3): 0.8399 - val_ca2-[11.3,14.9): 1.4162 - val_ca3-[8.0,9.5): 0.9187 - val_ca3-[9.5,10.3): 0.5692 - val_ca3-[10.3,11.3): 0.7082 - val_ca3-[11.3,14.9): 0.8679 - val_ca4-[8.0,9.5): 1.3691 - val_ca4-[9.5,10.3): 0.9700 - val_ca4-[10.3,11.3): 0.8851 - val_ca4-[11.3,14.9): 0.7117\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5246 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3691 - ca2-[9.5,10.3): 0.4958 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5472 - ca3-[10.3,11.3): 0.6968 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5702 - ca4-[11.3,14.9): 0.7107 - val_ca1-[8.0,9.5): 0.5779 - val_ca1-[9.5,10.3): 0.4487 - val_ca1-[10.3,11.3): 1.0081 - val_ca1-[11.3,14.9): 1.7933 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.4004 - val_ca2-[10.3,11.3): 0.8289 - val_ca2-[11.3,14.9): 1.4310 - val_ca3-[8.0,9.5): 0.9094 - val_ca3-[9.5,10.3): 0.5642 - val_ca3-[10.3,11.3): 0.7027 - val_ca3-[11.3,14.9): 0.8782 - val_ca4-[8.0,9.5): 1.3758 - val_ca4-[9.5,10.3): 0.9757 - val_ca4-[10.3,11.3): 0.8843 - val_ca4-[11.3,14.9): 0.7030\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5304 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3730 - ca2-[9.5,10.3): 0.4853 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5293 - ca3-[10.3,11.3): 0.6898 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5492 - ca4-[11.3,14.9): 0.6998 - val_ca1-[8.0,9.5): 0.5777 - val_ca1-[9.5,10.3): 0.4473 - val_ca1-[10.3,11.3): 1.0161 - val_ca1-[11.3,14.9): 1.7738 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.3999 - val_ca2-[10.3,11.3): 0.8377 - val_ca2-[11.3,14.9): 1.4192 - val_ca3-[8.0,9.5): 0.9193 - val_ca3-[9.5,10.3): 0.5689 - val_ca3-[10.3,11.3): 0.7081 - val_ca3-[11.3,14.9): 0.8721 - val_ca4-[8.0,9.5): 1.3821 - val_ca4-[9.5,10.3): 0.9809 - val_ca4-[10.3,11.3): 0.8909 - val_ca4-[11.3,14.9): 0.7117\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5260 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3689 - ca2-[9.5,10.3): 0.4958 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5736 - ca3-[10.3,11.3): 0.7053 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5441 - ca4-[11.3,14.9): 0.7091 - val_ca1-[8.0,9.5): 0.5775 - val_ca1-[9.5,10.3): 0.4460 - val_ca1-[10.3,11.3): 1.0069 - val_ca1-[11.3,14.9): 1.7781 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.3997 - val_ca2-[10.3,11.3): 0.8357 - val_ca2-[11.3,14.9): 1.4329 - val_ca3-[8.0,9.5): 0.9186 - val_ca3-[9.5,10.3): 0.5687 - val_ca3-[10.3,11.3): 0.7076 - val_ca3-[11.3,14.9): 0.8882 - val_ca4-[8.0,9.5): 1.3878 - val_ca4-[9.5,10.3): 0.9857 - val_ca4-[10.3,11.3): 0.8946 - val_ca4-[11.3,14.9): 0.7291\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5287 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3697 - ca2-[9.5,10.3): 0.4890 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5386 - ca3-[10.3,11.3): 0.6822 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5385 - ca4-[11.3,14.9): 0.6896 - val_ca1-[8.0,9.5): 0.5773 - val_ca1-[9.5,10.3): 0.4447 - val_ca1-[10.3,11.3): 1.0120 - val_ca1-[11.3,14.9): 1.7668 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3996 - val_ca2-[10.3,11.3): 0.8436 - val_ca2-[11.3,14.9): 1.4261 - val_ca3-[8.0,9.5): 0.9197 - val_ca3-[9.5,10.3): 0.5695 - val_ca3-[10.3,11.3): 0.7121 - val_ca3-[11.3,14.9): 0.8689 - val_ca4-[8.0,9.5): 1.3934 - val_ca4-[9.5,10.3): 0.9904 - val_ca4-[10.3,11.3): 0.9010 - val_ca4-[11.3,14.9): 0.7014\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5319 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3617 - ca2-[9.5,10.3): 0.4846 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5315 - ca3-[10.3,11.3): 0.6957 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5355 - ca4-[11.3,14.9): 0.6792 - val_ca1-[8.0,9.5): 0.5772 - val_ca1-[9.5,10.3): 0.4435 - val_ca1-[10.3,11.3): 0.9914 - val_ca1-[11.3,14.9): 1.7677 - val_ca2-[8.0,9.5): 0.5852 - val_ca2-[9.5,10.3): 0.3994 - val_ca2-[10.3,11.3): 0.8300 - val_ca2-[11.3,14.9): 1.4441 - val_ca3-[8.0,9.5): 0.9201 - val_ca3-[9.5,10.3): 0.5694 - val_ca3-[10.3,11.3): 0.6978 - val_ca3-[11.3,14.9): 0.8791 - val_ca4-[8.0,9.5): 1.3990 - val_ca4-[9.5,10.3): 0.9950 - val_ca4-[10.3,11.3): 0.8871 - val_ca4-[11.3,14.9): 0.7021\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5281 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3714 - ca2-[9.5,10.3): 0.4904 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5373 - ca3-[10.3,11.3): 0.6694 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5357 - ca4-[11.3,14.9): 0.6943 - val_ca1-[8.0,9.5): 0.5770 - val_ca1-[9.5,10.3): 0.4424 - val_ca1-[10.3,11.3): 1.0028 - val_ca1-[11.3,14.9): 1.7394 - val_ca2-[8.0,9.5): 0.5847 - val_ca2-[9.5,10.3): 0.3991 - val_ca2-[10.3,11.3): 0.8425 - val_ca2-[11.3,14.9): 1.4216 - val_ca3-[8.0,9.5): 0.9275 - val_ca3-[9.5,10.3): 0.5728 - val_ca3-[10.3,11.3): 0.7101 - val_ca3-[11.3,14.9): 0.8687 - val_ca4-[8.0,9.5): 1.4042 - val_ca4-[9.5,10.3): 0.9993 - val_ca4-[10.3,11.3): 0.9031 - val_ca4-[11.3,14.9): 0.7125\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3584 - ca2-[9.5,10.3): 0.4726 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5380 - ca3-[10.3,11.3): 0.6879 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5407 - ca4-[11.3,14.9): 0.7120 - val_ca1-[8.0,9.5): 0.5769 - val_ca1-[9.5,10.3): 0.4414 - val_ca1-[10.3,11.3): 1.0005 - val_ca1-[11.3,14.9): 1.7471 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.3990 - val_ca2-[10.3,11.3): 0.8421 - val_ca2-[11.3,14.9): 1.4390 - val_ca3-[8.0,9.5): 0.9153 - val_ca3-[9.5,10.3): 0.5668 - val_ca3-[10.3,11.3): 0.7069 - val_ca3-[11.3,14.9): 0.8890 - val_ca4-[8.0,9.5): 1.4087 - val_ca4-[9.5,10.3): 1.0031 - val_ca4-[10.3,11.3): 0.9002 - val_ca4-[11.3,14.9): 0.7200\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5229 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3692 - ca2-[9.5,10.3): 0.4902 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5443 - ca3-[10.3,11.3): 0.6832 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5346 - ca4-[11.3,14.9): 0.6862 - val_ca1-[8.0,9.5): 0.5769 - val_ca1-[9.5,10.3): 0.4404 - val_ca1-[10.3,11.3): 0.9915 - val_ca1-[11.3,14.9): 1.7847 - val_ca2-[8.0,9.5): 0.5850 - val_ca2-[9.5,10.3): 0.3985 - val_ca2-[10.3,11.3): 0.8366 - val_ca2-[11.3,14.9): 1.4702 - val_ca3-[8.0,9.5): 0.9146 - val_ca3-[9.5,10.3): 0.5663 - val_ca3-[10.3,11.3): 0.7080 - val_ca3-[11.3,14.9): 0.9051 - val_ca4-[8.0,9.5): 1.4133 - val_ca4-[9.5,10.3): 1.0069 - val_ca4-[10.3,11.3): 0.9086 - val_ca4-[11.3,14.9): 0.7215\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5233 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3523 - ca2-[9.5,10.3): 0.4857 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5645 - ca3-[10.3,11.3): 0.7016 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5227 - ca4-[11.3,14.9): 0.6885 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4393 - val_ca1-[10.3,11.3): 0.9911 - val_ca1-[11.3,14.9): 1.7122 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3980 - val_ca2-[10.3,11.3): 0.8341 - val_ca2-[11.3,14.9): 1.4034 - val_ca3-[8.0,9.5): 0.9285 - val_ca3-[9.5,10.3): 0.5734 - val_ca3-[10.3,11.3): 0.7068 - val_ca3-[11.3,14.9): 0.8532 - val_ca4-[8.0,9.5): 1.4189 - val_ca4-[9.5,10.3): 1.0115 - val_ca4-[10.3,11.3): 0.9072 - val_ca4-[11.3,14.9): 0.6897\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3684 - ca2-[9.5,10.3): 0.4814 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5371 - ca3-[10.3,11.3): 0.7083 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5721 - ca4-[11.3,14.9): 0.7043 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4384 - val_ca1-[10.3,11.3): 0.9881 - val_ca1-[11.3,14.9): 1.7277 - val_ca2-[8.0,9.5): 0.5850 - val_ca2-[9.5,10.3): 0.3981 - val_ca2-[10.3,11.3): 0.8367 - val_ca2-[11.3,14.9): 1.4244 - val_ca3-[8.0,9.5): 0.9276 - val_ca3-[9.5,10.3): 0.5730 - val_ca3-[10.3,11.3): 0.7064 - val_ca3-[11.3,14.9): 0.8647 - val_ca4-[8.0,9.5): 1.4233 - val_ca4-[9.5,10.3): 1.0152 - val_ca4-[10.3,11.3): 0.9092 - val_ca4-[11.3,14.9): 0.6984\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5238 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3731 - ca2-[9.5,10.3): 0.4857 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5498 - ca3-[10.3,11.3): 0.6755 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5584 - ca4-[11.3,14.9): 0.7143 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4377 - val_ca1-[10.3,11.3): 0.9856 - val_ca1-[11.3,14.9): 1.7142 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3981 - val_ca2-[10.3,11.3): 0.8386 - val_ca2-[11.3,14.9): 1.4232 - val_ca3-[8.0,9.5): 0.9168 - val_ca3-[9.5,10.3): 0.5670 - val_ca3-[10.3,11.3): 0.7060 - val_ca3-[11.3,14.9): 0.8699 - val_ca4-[8.0,9.5): 1.4271 - val_ca4-[9.5,10.3): 1.0183 - val_ca4-[10.3,11.3): 0.9109 - val_ca4-[11.3,14.9): 0.7019\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5263 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3588 - ca2-[9.5,10.3): 0.4929 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5381 - ca3-[10.3,11.3): 0.6879 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5725 - ca4-[11.3,14.9): 0.6920 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4369 - val_ca1-[10.3,11.3): 0.9849 - val_ca1-[11.3,14.9): 1.7338 - val_ca2-[8.0,9.5): 0.5848 - val_ca2-[9.5,10.3): 0.3976 - val_ca2-[10.3,11.3): 0.8375 - val_ca2-[11.3,14.9): 1.4417 - val_ca3-[8.0,9.5): 0.9165 - val_ca3-[9.5,10.3): 0.5665 - val_ca3-[10.3,11.3): 0.7082 - val_ca3-[11.3,14.9): 0.8953 - val_ca4-[8.0,9.5): 1.4311 - val_ca4-[9.5,10.3): 1.0217 - val_ca4-[10.3,11.3): 0.9152 - val_ca4-[11.3,14.9): 0.7271\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5260 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3679 - ca2-[9.5,10.3): 0.4964 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5459 - ca3-[10.3,11.3): 0.6689 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5463 - ca4-[11.3,14.9): 0.6683 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4361 - val_ca1-[10.3,11.3): 0.9673 - val_ca1-[11.3,14.9): 1.7019 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3971 - val_ca2-[10.3,11.3): 0.8231 - val_ca2-[11.3,14.9): 1.4051 - val_ca3-[8.0,9.5): 0.9221 - val_ca3-[9.5,10.3): 0.5695 - val_ca3-[10.3,11.3): 0.6967 - val_ca3-[11.3,14.9): 0.8500 - val_ca4-[8.0,9.5): 1.4353 - val_ca4-[9.5,10.3): 1.0251 - val_ca4-[10.3,11.3): 0.9033 - val_ca4-[11.3,14.9): 0.6684\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5328 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3617 - ca2-[9.5,10.3): 0.4917 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5418 - ca3-[10.3,11.3): 0.6846 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5662 - ca4-[11.3,14.9): 0.6970 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4354 - val_ca1-[10.3,11.3): 0.9778 - val_ca1-[11.3,14.9): 1.7334 - val_ca2-[8.0,9.5): 0.5842 - val_ca2-[9.5,10.3): 0.3973 - val_ca2-[10.3,11.3): 0.8360 - val_ca2-[11.3,14.9): 1.4527 - val_ca3-[8.0,9.5): 0.9224 - val_ca3-[9.5,10.3): 0.5695 - val_ca3-[10.3,11.3): 0.7055 - val_ca3-[11.3,14.9): 0.8886 - val_ca4-[8.0,9.5): 1.4389 - val_ca4-[9.5,10.3): 1.0282 - val_ca4-[10.3,11.3): 0.9162 - val_ca4-[11.3,14.9): 0.7123\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5101 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3646 - ca2-[9.5,10.3): 0.4896 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5524 - ca3-[10.3,11.3): 0.6878 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5406 - ca4-[11.3,14.9): 0.6980 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4347 - val_ca1-[10.3,11.3): 0.9694 - val_ca1-[11.3,14.9): 1.7315 - val_ca2-[8.0,9.5): 0.5833 - val_ca2-[9.5,10.3): 0.3974 - val_ca2-[10.3,11.3): 0.8308 - val_ca2-[11.3,14.9): 1.4541 - val_ca3-[8.0,9.5): 0.9129 - val_ca3-[9.5,10.3): 0.5641 - val_ca3-[10.3,11.3): 0.6973 - val_ca3-[11.3,14.9): 0.8949 - val_ca4-[8.0,9.5): 1.4424 - val_ca4-[9.5,10.3): 1.0311 - val_ca4-[10.3,11.3): 0.9077 - val_ca4-[11.3,14.9): 0.7161\n",
      "Epoch 129/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5283 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3748 - ca2-[9.5,10.3): 0.4888 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5488 - ca3-[10.3,11.3): 0.6907 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5119 - ca4-[11.3,14.9): 0.6880 - val_ca1-[8.0,9.5): 0.5768 - val_ca1-[9.5,10.3): 0.4342 - val_ca1-[10.3,11.3): 0.9736 - val_ca1-[11.3,14.9): 1.7249 - val_ca2-[8.0,9.5): 0.5820 - val_ca2-[9.5,10.3): 0.3976 - val_ca2-[10.3,11.3): 0.8412 - val_ca2-[11.3,14.9): 1.4601 - val_ca3-[8.0,9.5): 0.9126 - val_ca3-[9.5,10.3): 0.5634 - val_ca3-[10.3,11.3): 0.7047 - val_ca3-[11.3,14.9): 0.8951 - val_ca4-[8.0,9.5): 1.4444 - val_ca4-[9.5,10.3): 1.0327 - val_ca4-[10.3,11.3): 0.9187 - val_ca4-[11.3,14.9): 0.7168\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5303 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3592 - ca2-[9.5,10.3): 0.4821 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5314 - ca3-[10.3,11.3): 0.6839 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5652 - ca4-[11.3,14.9): 0.6940 - val_ca1-[8.0,9.5): 0.5769 - val_ca1-[9.5,10.3): 0.4336 - val_ca1-[10.3,11.3): 0.9714 - val_ca1-[11.3,14.9): 1.6984 - val_ca2-[8.0,9.5): 0.5827 - val_ca2-[9.5,10.3): 0.3968 - val_ca2-[10.3,11.3): 0.8375 - val_ca2-[11.3,14.9): 1.4387 - val_ca3-[8.0,9.5): 0.9215 - val_ca3-[9.5,10.3): 0.5679 - val_ca3-[10.3,11.3): 0.7049 - val_ca3-[11.3,14.9): 0.8816 - val_ca4-[8.0,9.5): 1.4471 - val_ca4-[9.5,10.3): 1.0349 - val_ca4-[10.3,11.3): 0.9198 - val_ca4-[11.3,14.9): 0.7127\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5174 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3570 - ca2-[9.5,10.3): 0.4894 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4957 - ca3-[10.3,11.3): 0.6935 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5509 - ca4-[11.3,14.9): 0.7021 - val_ca1-[8.0,9.5): 0.5770 - val_ca1-[9.5,10.3): 0.4330 - val_ca1-[10.3,11.3): 0.9730 - val_ca1-[11.3,14.9): 1.6393 - val_ca2-[8.0,9.5): 0.5825 - val_ca2-[9.5,10.3): 0.3968 - val_ca2-[10.3,11.3): 0.8405 - val_ca2-[11.3,14.9): 1.3824 - val_ca3-[8.0,9.5): 0.9136 - val_ca3-[9.5,10.3): 0.5635 - val_ca3-[10.3,11.3): 0.7085 - val_ca3-[11.3,14.9): 0.8456 - val_ca4-[8.0,9.5): 1.4500 - val_ca4-[9.5,10.3): 1.0373 - val_ca4-[10.3,11.3): 0.9263 - val_ca4-[11.3,14.9): 0.6855\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5149 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3704 - ca2-[9.5,10.3): 0.4885 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5452 - ca3-[10.3,11.3): 0.6822 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5842 - ca4-[11.3,14.9): 0.6888 - val_ca1-[8.0,9.5): 0.5770 - val_ca1-[9.5,10.3): 0.4324 - val_ca1-[10.3,11.3): 0.9587 - val_ca1-[11.3,14.9): 1.6954 - val_ca2-[8.0,9.5): 0.5835 - val_ca2-[9.5,10.3): 0.3963 - val_ca2-[10.3,11.3): 0.8278 - val_ca2-[11.3,14.9): 1.4407 - val_ca3-[8.0,9.5): 0.9082 - val_ca3-[9.5,10.3): 0.5607 - val_ca3-[10.3,11.3): 0.7032 - val_ca3-[11.3,14.9): 0.8945 - val_ca4-[8.0,9.5): 1.4535 - val_ca4-[9.5,10.3): 1.0403 - val_ca4-[10.3,11.3): 0.9283 - val_ca4-[11.3,14.9): 0.7161\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5189 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3588 - ca2-[9.5,10.3): 0.4771 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5328 - ca3-[10.3,11.3): 0.6554 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5112 - ca4-[11.3,14.9): 0.6775 - val_ca1-[8.0,9.5): 0.5771 - val_ca1-[9.5,10.3): 0.4319 - val_ca1-[10.3,11.3): 0.9652 - val_ca1-[11.3,14.9): 1.6815 - val_ca2-[8.0,9.5): 0.5815 - val_ca2-[9.5,10.3): 0.3969 - val_ca2-[10.3,11.3): 0.8400 - val_ca2-[11.3,14.9): 1.4369 - val_ca3-[8.0,9.5): 0.9131 - val_ca3-[9.5,10.3): 0.5630 - val_ca3-[10.3,11.3): 0.7033 - val_ca3-[11.3,14.9): 0.8734 - val_ca4-[8.0,9.5): 1.4551 - val_ca4-[9.5,10.3): 1.0416 - val_ca4-[10.3,11.3): 0.9235 - val_ca4-[11.3,14.9): 0.6951\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5149 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3552 - ca2-[9.5,10.3): 0.4737 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5614 - ca3-[10.3,11.3): 0.6947 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5482 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5772 - val_ca1-[9.5,10.3): 0.4314 - val_ca1-[10.3,11.3): 0.9471 - val_ca1-[11.3,14.9): 1.6774 - val_ca2-[8.0,9.5): 0.5829 - val_ca2-[9.5,10.3): 0.3962 - val_ca2-[10.3,11.3): 0.8206 - val_ca2-[11.3,14.9): 1.4273 - val_ca3-[8.0,9.5): 0.9112 - val_ca3-[9.5,10.3): 0.5619 - val_ca3-[10.3,11.3): 0.6962 - val_ca3-[11.3,14.9): 0.8775 - val_ca4-[8.0,9.5): 1.4581 - val_ca4-[9.5,10.3): 1.0441 - val_ca4-[10.3,11.3): 0.9216 - val_ca4-[11.3,14.9): 0.6951\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3587 - ca2-[9.5,10.3): 0.4729 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5388 - ca3-[10.3,11.3): 0.6685 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5668 - ca4-[11.3,14.9): 0.7020 - val_ca1-[8.0,9.5): 0.5773 - val_ca1-[9.5,10.3): 0.4239 - val_ca1-[10.3,11.3): 0.9605 - val_ca1-[11.3,14.9): 1.6736 - val_ca2-[8.0,9.5): 0.5833 - val_ca2-[9.5,10.3): 0.3890 - val_ca2-[10.3,11.3): 0.8324 - val_ca2-[11.3,14.9): 1.4259 - val_ca3-[8.0,9.5): 0.9143 - val_ca3-[9.5,10.3): 0.5611 - val_ca3-[10.3,11.3): 0.7053 - val_ca3-[11.3,14.9): 0.8849 - val_ca4-[8.0,9.5): 1.4602 - val_ca4-[9.5,10.3): 1.0478 - val_ca4-[10.3,11.3): 0.9325 - val_ca4-[11.3,14.9): 0.7205\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5217 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3580 - ca2-[9.5,10.3): 0.4829 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5275 - ca3-[10.3,11.3): 0.6707 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5589 - ca4-[11.3,14.9): 0.7112 - val_ca1-[8.0,9.5): 0.5773 - val_ca1-[9.5,10.3): 0.4305 - val_ca1-[10.3,11.3): 0.9618 - val_ca1-[11.3,14.9): 1.6819 - val_ca2-[8.0,9.5): 0.5819 - val_ca2-[9.5,10.3): 0.3962 - val_ca2-[10.3,11.3): 0.8393 - val_ca2-[11.3,14.9): 1.4442 - val_ca3-[8.0,9.5): 0.9165 - val_ca3-[9.5,10.3): 0.5644 - val_ca3-[10.3,11.3): 0.7048 - val_ca3-[11.3,14.9): 0.8892 - val_ca4-[8.0,9.5): 1.4615 - val_ca4-[9.5,10.3): 1.0469 - val_ca4-[10.3,11.3): 0.9290 - val_ca4-[11.3,14.9): 0.7235\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5136 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3555 - ca2-[9.5,10.3): 0.4955 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5372 - ca3-[10.3,11.3): 0.6881 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5520 - ca4-[11.3,14.9): 0.6849 - val_ca1-[8.0,9.5): 0.5774 - val_ca1-[9.5,10.3): 0.4304 - val_ca1-[10.3,11.3): 0.9581 - val_ca1-[11.3,14.9): 1.6614 - val_ca2-[8.0,9.5): 0.5824 - val_ca2-[9.5,10.3): 0.3968 - val_ca2-[10.3,11.3): 0.8353 - val_ca2-[11.3,14.9): 1.4209 - val_ca3-[8.0,9.5): 0.9146 - val_ca3-[9.5,10.3): 0.5649 - val_ca3-[10.3,11.3): 0.7025 - val_ca3-[11.3,14.9): 0.8701 - val_ca4-[8.0,9.5): 1.4639 - val_ca4-[9.5,10.3): 1.0520 - val_ca4-[10.3,11.3): 0.9276 - val_ca4-[11.3,14.9): 0.7035\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5123 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3563 - ca2-[9.5,10.3): 0.4884 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5292 - ca3-[10.3,11.3): 0.6902 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5703 - ca4-[11.3,14.9): 0.7018 - val_ca1-[8.0,9.5): 0.5775 - val_ca1-[9.5,10.3): 0.4297 - val_ca1-[10.3,11.3): 0.9605 - val_ca1-[11.3,14.9): 1.6797 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3952 - val_ca2-[10.3,11.3): 0.8341 - val_ca2-[11.3,14.9): 1.4329 - val_ca3-[8.0,9.5): 0.9031 - val_ca3-[9.5,10.3): 0.5563 - val_ca3-[10.3,11.3): 0.7064 - val_ca3-[11.3,14.9): 0.8925 - val_ca4-[8.0,9.5): 1.4665 - val_ca4-[9.5,10.3): 1.0511 - val_ca4-[10.3,11.3): 0.9340 - val_ca4-[11.3,14.9): 0.7063\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5133 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3647 - ca2-[9.5,10.3): 0.4792 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4946 - ca3-[10.3,11.3): 0.6888 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4909 - ca4-[11.3,14.9): 0.6928 - val_ca1-[8.0,9.5): 0.5776 - val_ca1-[9.5,10.3): 0.4293 - val_ca1-[10.3,11.3): 0.9502 - val_ca1-[11.3,14.9): 1.6245 - val_ca2-[8.0,9.5): 0.5839 - val_ca2-[9.5,10.3): 0.3951 - val_ca2-[10.3,11.3): 0.8269 - val_ca2-[11.3,14.9): 1.3909 - val_ca3-[8.0,9.5): 0.9081 - val_ca3-[9.5,10.3): 0.5589 - val_ca3-[10.3,11.3): 0.7013 - val_ca3-[11.3,14.9): 0.8687 - val_ca4-[8.0,9.5): 1.4685 - val_ca4-[9.5,10.3): 1.0528 - val_ca4-[10.3,11.3): 0.9314 - val_ca4-[11.3,14.9): 0.7050\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5163 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3540 - ca2-[9.5,10.3): 0.4773 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5152 - ca3-[10.3,11.3): 0.6801 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5365 - ca4-[11.3,14.9): 0.6967 - val_ca1-[8.0,9.5): 0.5777 - val_ca1-[9.5,10.3): 0.4289 - val_ca1-[10.3,11.3): 0.9579 - val_ca1-[11.3,14.9): 1.6378 - val_ca2-[8.0,9.5): 0.5820 - val_ca2-[9.5,10.3): 0.3957 - val_ca2-[10.3,11.3): 0.8397 - val_ca2-[11.3,14.9): 1.4118 - val_ca3-[8.0,9.5): 0.9137 - val_ca3-[9.5,10.3): 0.5621 - val_ca3-[10.3,11.3): 0.7036 - val_ca3-[11.3,14.9): 0.8671 - val_ca4-[8.0,9.5): 1.4701 - val_ca4-[9.5,10.3): 1.0541 - val_ca4-[10.3,11.3): 0.9303 - val_ca4-[11.3,14.9): 0.7061\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5266 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3659 - ca2-[9.5,10.3): 0.4758 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5060 - ca3-[10.3,11.3): 0.6696 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5646 - ca4-[11.3,14.9): 0.6948 - val_ca1-[8.0,9.5): 0.5778 - val_ca1-[9.5,10.3): 0.4285 - val_ca1-[10.3,11.3): 0.9558 - val_ca1-[11.3,14.9): 1.6573 - val_ca2-[8.0,9.5): 0.5832 - val_ca2-[9.5,10.3): 0.3952 - val_ca2-[10.3,11.3): 0.8360 - val_ca2-[11.3,14.9): 1.4199 - val_ca3-[8.0,9.5): 0.9111 - val_ca3-[9.5,10.3): 0.5608 - val_ca3-[10.3,11.3): 0.7053 - val_ca3-[11.3,14.9): 0.8800 - val_ca4-[8.0,9.5): 1.4722 - val_ca4-[9.5,10.3): 1.0559 - val_ca4-[10.3,11.3): 0.9366 - val_ca4-[11.3,14.9): 0.7134\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5075 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3597 - ca2-[9.5,10.3): 0.4796 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5283 - ca3-[10.3,11.3): 0.6886 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5269 - ca4-[11.3,14.9): 0.6941 - val_ca1-[8.0,9.5): 0.5779 - val_ca1-[9.5,10.3): 0.4282 - val_ca1-[10.3,11.3): 0.9569 - val_ca1-[11.3,14.9): 1.6619 - val_ca2-[8.0,9.5): 0.5832 - val_ca2-[9.5,10.3): 0.3952 - val_ca2-[10.3,11.3): 0.8378 - val_ca2-[11.3,14.9): 1.4293 - val_ca3-[8.0,9.5): 0.9061 - val_ca3-[9.5,10.3): 0.5578 - val_ca3-[10.3,11.3): 0.7052 - val_ca3-[11.3,14.9): 0.8848 - val_ca4-[8.0,9.5): 1.4743 - val_ca4-[9.5,10.3): 1.0577 - val_ca4-[10.3,11.3): 0.9350 - val_ca4-[11.3,14.9): 0.7088\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5101 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3648 - ca2-[9.5,10.3): 0.4869 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4952 - ca3-[10.3,11.3): 0.6825 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4983 - ca4-[11.3,14.9): 0.6878 - val_ca1-[8.0,9.5): 0.5779 - val_ca1-[9.5,10.3): 0.4279 - val_ca1-[10.3,11.3): 0.9377 - val_ca1-[11.3,14.9): 1.6442 - val_ca2-[8.0,9.5): 0.5834 - val_ca2-[9.5,10.3): 0.3949 - val_ca2-[10.3,11.3): 0.8234 - val_ca2-[11.3,14.9): 1.4188 - val_ca3-[8.0,9.5): 0.9015 - val_ca3-[9.5,10.3): 0.5546 - val_ca3-[10.3,11.3): 0.6990 - val_ca3-[11.3,14.9): 0.8834 - val_ca4-[8.0,9.5): 1.4752 - val_ca4-[9.5,10.3): 1.0584 - val_ca4-[10.3,11.3): 0.9349 - val_ca4-[11.3,14.9): 0.7026\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5320 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3638 - ca2-[9.5,10.3): 0.4865 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5238 - ca3-[10.3,11.3): 0.6822 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5481 - ca4-[11.3,14.9): 0.6856 - val_ca1-[8.0,9.5): 0.5780 - val_ca1-[9.5,10.3): 0.4277 - val_ca1-[10.3,11.3): 0.9424 - val_ca1-[11.3,14.9): 1.6613 - val_ca2-[8.0,9.5): 0.5823 - val_ca2-[9.5,10.3): 0.3951 - val_ca2-[10.3,11.3): 0.8296 - val_ca2-[11.3,14.9): 1.4433 - val_ca3-[8.0,9.5): 0.9064 - val_ca3-[9.5,10.3): 0.5572 - val_ca3-[10.3,11.3): 0.6936 - val_ca3-[11.3,14.9): 0.8849 - val_ca4-[8.0,9.5): 1.4762 - val_ca4-[9.5,10.3): 1.0591 - val_ca4-[10.3,11.3): 0.9231 - val_ca4-[11.3,14.9): 0.6957\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5276 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3656 - ca2-[9.5,10.3): 0.4789 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5128 - ca3-[10.3,11.3): 0.6928 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5495 - ca4-[11.3,14.9): 0.6888 - val_ca1-[8.0,9.5): 0.5781 - val_ca1-[9.5,10.3): 0.4274 - val_ca1-[10.3,11.3): 0.9513 - val_ca1-[11.3,14.9): 1.6628 - val_ca2-[8.0,9.5): 0.5827 - val_ca2-[9.5,10.3): 0.3948 - val_ca2-[10.3,11.3): 0.8353 - val_ca2-[11.3,14.9): 1.4374 - val_ca3-[8.0,9.5): 0.9045 - val_ca3-[9.5,10.3): 0.5559 - val_ca3-[10.3,11.3): 0.7037 - val_ca3-[11.3,14.9): 0.8901 - val_ca4-[8.0,9.5): 1.4772 - val_ca4-[9.5,10.3): 1.0600 - val_ca4-[10.3,11.3): 0.9389 - val_ca4-[11.3,14.9): 0.7097\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5186 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3645 - ca2-[9.5,10.3): 0.4822 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4896 - ca3-[10.3,11.3): 0.6721 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5225 - ca4-[11.3,14.9): 0.6824 - val_ca1-[8.0,9.5): 0.5782 - val_ca1-[9.5,10.3): 0.4271 - val_ca1-[10.3,11.3): 0.9435 - val_ca1-[11.3,14.9): 1.6074 - val_ca2-[8.0,9.5): 0.5827 - val_ca2-[9.5,10.3): 0.3948 - val_ca2-[10.3,11.3): 0.8304 - val_ca2-[11.3,14.9): 1.3925 - val_ca3-[8.0,9.5): 0.9072 - val_ca3-[9.5,10.3): 0.5572 - val_ca3-[10.3,11.3): 0.7009 - val_ca3-[11.3,14.9): 0.8613 - val_ca4-[8.0,9.5): 1.4786 - val_ca4-[9.5,10.3): 1.0611 - val_ca4-[10.3,11.3): 0.9385 - val_ca4-[11.3,14.9): 0.6989\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5279 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3547 - ca2-[9.5,10.3): 0.4768 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5450 - ca3-[10.3,11.3): 0.6805 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5278 - ca4-[11.3,14.9): 0.6886 - val_ca1-[8.0,9.5): 0.5783 - val_ca1-[9.5,10.3): 0.4269 - val_ca1-[10.3,11.3): 0.9418 - val_ca1-[11.3,14.9): 1.6408 - val_ca2-[8.0,9.5): 0.5827 - val_ca2-[9.5,10.3): 0.3948 - val_ca2-[10.3,11.3): 0.8292 - val_ca2-[11.3,14.9): 1.4231 - val_ca3-[8.0,9.5): 0.9090 - val_ca3-[9.5,10.3): 0.5581 - val_ca3-[10.3,11.3): 0.6908 - val_ca3-[11.3,14.9): 0.8641 - val_ca4-[8.0,9.5): 1.4801 - val_ca4-[9.5,10.3): 1.0624 - val_ca4-[10.3,11.3): 0.9208 - val_ca4-[11.3,14.9): 0.6763\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5188 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3648 - ca2-[9.5,10.3): 0.4758 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5396 - ca3-[10.3,11.3): 0.6686 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5454 - ca4-[11.3,14.9): 0.6879 - val_ca1-[8.0,9.5): 0.5784 - val_ca1-[9.5,10.3): 0.4266 - val_ca1-[10.3,11.3): 0.9461 - val_ca1-[11.3,14.9): 1.6658 - val_ca2-[8.0,9.5): 0.5835 - val_ca2-[9.5,10.3): 0.3945 - val_ca2-[10.3,11.3): 0.8312 - val_ca2-[11.3,14.9): 1.4416 - val_ca3-[8.0,9.5): 0.9121 - val_ca3-[9.5,10.3): 0.5600 - val_ca3-[10.3,11.3): 0.7006 - val_ca3-[11.3,14.9): 0.8811 - val_ca4-[8.0,9.5): 1.4817 - val_ca4-[9.5,10.3): 1.0637 - val_ca4-[10.3,11.3): 0.9383 - val_ca4-[11.3,14.9): 0.6971\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5115 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3654 - ca2-[9.5,10.3): 0.4726 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5429 - ca3-[10.3,11.3): 0.6807 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5460 - ca4-[11.3,14.9): 0.6890 - val_ca1-[8.0,9.5): 0.5784 - val_ca1-[9.5,10.3): 0.4264 - val_ca1-[10.3,11.3): 0.9157 - val_ca1-[11.3,14.9): 1.6193 - val_ca2-[8.0,9.5): 0.5834 - val_ca2-[9.5,10.3): 0.3947 - val_ca2-[10.3,11.3): 0.8032 - val_ca2-[11.3,14.9): 1.4020 - val_ca3-[8.0,9.5): 0.9024 - val_ca3-[9.5,10.3): 0.5546 - val_ca3-[10.3,11.3): 0.6852 - val_ca3-[11.3,14.9): 0.8728 - val_ca4-[8.0,9.5): 1.4834 - val_ca4-[9.5,10.3): 1.0651 - val_ca4-[10.3,11.3): 0.9340 - val_ca4-[11.3,14.9): 0.7069\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5228 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3559 - ca2-[9.5,10.3): 0.4826 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5236 - ca3-[10.3,11.3): 0.6852 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5739 - ca4-[11.3,14.9): 0.6728 - val_ca1-[8.0,9.5): 0.5785 - val_ca1-[9.5,10.3): 0.4262 - val_ca1-[10.3,11.3): 0.9422 - val_ca1-[11.3,14.9): 1.6325 - val_ca2-[8.0,9.5): 0.5847 - val_ca2-[9.5,10.3): 0.3942 - val_ca2-[10.3,11.3): 0.8262 - val_ca2-[11.3,14.9): 1.4032 - val_ca3-[8.0,9.5): 0.8984 - val_ca3-[9.5,10.3): 0.5520 - val_ca3-[10.3,11.3): 0.6974 - val_ca3-[11.3,14.9): 0.8769 - val_ca4-[8.0,9.5): 1.4849 - val_ca4-[9.5,10.3): 1.0664 - val_ca4-[10.3,11.3): 0.9372 - val_ca4-[11.3,14.9): 0.7034\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5207 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3605 - ca2-[9.5,10.3): 0.4835 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5356 - ca3-[10.3,11.3): 0.6862 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5621 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5786 - val_ca1-[9.5,10.3): 0.4260 - val_ca1-[10.3,11.3): 0.9440 - val_ca1-[11.3,14.9): 1.6116 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3939 - val_ca2-[10.3,11.3): 0.8268 - val_ca2-[11.3,14.9): 1.3908 - val_ca3-[8.0,9.5): 0.9106 - val_ca3-[9.5,10.3): 0.5589 - val_ca3-[10.3,11.3): 0.6974 - val_ca3-[11.3,14.9): 0.8581 - val_ca4-[8.0,9.5): 1.4854 - val_ca4-[9.5,10.3): 1.0667 - val_ca4-[10.3,11.3): 0.9349 - val_ca4-[11.3,14.9): 0.6897\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5248 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3683 - ca2-[9.5,10.3): 0.4810 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5399 - ca3-[10.3,11.3): 0.6743 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5109 - ca4-[11.3,14.9): 0.6911 - val_ca1-[8.0,9.5): 0.5786 - val_ca1-[9.5,10.3): 0.4259 - val_ca1-[10.3,11.3): 0.9376 - val_ca1-[11.3,14.9): 1.6126 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3940 - val_ca2-[10.3,11.3): 0.8248 - val_ca2-[11.3,14.9): 1.3993 - val_ca3-[8.0,9.5): 0.8994 - val_ca3-[9.5,10.3): 0.5523 - val_ca3-[10.3,11.3): 0.6885 - val_ca3-[11.3,14.9): 0.8574 - val_ca4-[8.0,9.5): 1.4844 - val_ca4-[9.5,10.3): 1.0658 - val_ca4-[10.3,11.3): 0.9226 - val_ca4-[11.3,14.9): 0.6678\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5216 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3555 - ca2-[9.5,10.3): 0.4758 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5147 - ca3-[10.3,11.3): 0.6714 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5146 - ca4-[11.3,14.9): 0.6934 - val_ca1-[8.0,9.5): 0.5786 - val_ca1-[9.5,10.3): 0.4258 - val_ca1-[10.3,11.3): 0.9405 - val_ca1-[11.3,14.9): 1.6629 - val_ca2-[8.0,9.5): 0.5846 - val_ca2-[9.5,10.3): 0.3937 - val_ca2-[10.3,11.3): 0.8251 - val_ca2-[11.3,14.9): 1.4362 - val_ca3-[8.0,9.5): 0.8971 - val_ca3-[9.5,10.3): 0.5510 - val_ca3-[10.3,11.3): 0.6959 - val_ca3-[11.3,14.9): 0.9028 - val_ca4-[8.0,9.5): 1.4844 - val_ca4-[9.5,10.3): 1.0658 - val_ca4-[10.3,11.3): 0.9368 - val_ca4-[11.3,14.9): 0.7191\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5229 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3558 - ca2-[9.5,10.3): 0.4750 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5132 - ca3-[10.3,11.3): 0.6721 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5695 - ca4-[11.3,14.9): 0.7030 - val_ca1-[8.0,9.5): 0.5788 - val_ca1-[9.5,10.3): 0.4256 - val_ca1-[10.3,11.3): 0.9435 - val_ca1-[11.3,14.9): 1.6429 - val_ca2-[8.0,9.5): 0.5843 - val_ca2-[9.5,10.3): 0.3938 - val_ca2-[10.3,11.3): 0.8302 - val_ca2-[11.3,14.9): 1.4215 - val_ca3-[8.0,9.5): 0.9103 - val_ca3-[9.5,10.3): 0.5592 - val_ca3-[10.3,11.3): 0.7002 - val_ca3-[11.3,14.9): 0.8796 - val_ca4-[8.0,9.5): 1.4851 - val_ca4-[9.5,10.3): 1.0663 - val_ca4-[10.3,11.3): 0.9422 - val_ca4-[11.3,14.9): 0.7094\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5097 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3593 - ca2-[9.5,10.3): 0.4632 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5307 - ca3-[10.3,11.3): 0.6620 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5636 - ca4-[11.3,14.9): 0.6950 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4254 - val_ca1-[10.3,11.3): 0.9445 - val_ca1-[11.3,14.9): 1.6391 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3938 - val_ca2-[10.3,11.3): 0.8295 - val_ca2-[11.3,14.9): 1.4188 - val_ca3-[8.0,9.5): 0.9035 - val_ca3-[9.5,10.3): 0.5551 - val_ca3-[10.3,11.3): 0.7021 - val_ca3-[11.3,14.9): 0.8851 - val_ca4-[8.0,9.5): 1.4873 - val_ca4-[9.5,10.3): 1.0681 - val_ca4-[10.3,11.3): 0.9457 - val_ca4-[11.3,14.9): 0.7106\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5076 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3558 - ca2-[9.5,10.3): 0.4668 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5224 - ca3-[10.3,11.3): 0.6718 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5767 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4252 - val_ca1-[10.3,11.3): 0.9370 - val_ca1-[11.3,14.9): 1.6427 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8201 - val_ca2-[11.3,14.9): 1.4141 - val_ca3-[8.0,9.5): 0.8930 - val_ca3-[9.5,10.3): 0.5488 - val_ca3-[10.3,11.3): 0.6992 - val_ca3-[11.3,14.9): 0.8916 - val_ca4-[8.0,9.5): 1.4889 - val_ca4-[9.5,10.3): 1.0694 - val_ca4-[10.3,11.3): 0.9455 - val_ca4-[11.3,14.9): 0.7085\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5052 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3536 - ca2-[9.5,10.3): 0.4650 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5193 - ca3-[10.3,11.3): 0.6622 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5242 - ca4-[11.3,14.9): 0.6791 - val_ca1-[8.0,9.5): 0.5790 - val_ca1-[9.5,10.3): 0.4250 - val_ca1-[10.3,11.3): 0.9294 - val_ca1-[11.3,14.9): 1.6348 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.3938 - val_ca2-[10.3,11.3): 0.8171 - val_ca2-[11.3,14.9): 1.4059 - val_ca3-[8.0,9.5): 0.9097 - val_ca3-[9.5,10.3): 0.5583 - val_ca3-[10.3,11.3): 0.6967 - val_ca3-[11.3,14.9): 0.8822 - val_ca4-[8.0,9.5): 1.4897 - val_ca4-[9.5,10.3): 1.0700 - val_ca4-[10.3,11.3): 0.9449 - val_ca4-[11.3,14.9): 0.7213\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3545 - ca2-[9.5,10.3): 0.4776 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5257 - ca3-[10.3,11.3): 0.6723 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5493 - ca4-[11.3,14.9): 0.6885 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4248 - val_ca1-[10.3,11.3): 0.9360 - val_ca1-[11.3,14.9): 1.5852 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3941 - val_ca2-[10.3,11.3): 0.8229 - val_ca2-[11.3,14.9): 1.3629 - val_ca3-[8.0,9.5): 0.9129 - val_ca3-[9.5,10.3): 0.5603 - val_ca3-[10.3,11.3): 0.6948 - val_ca3-[11.3,14.9): 0.8410 - val_ca4-[8.0,9.5): 1.4907 - val_ca4-[9.5,10.3): 1.0708 - val_ca4-[10.3,11.3): 0.9394 - val_ca4-[11.3,14.9): 0.6920\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5310 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3551 - ca2-[9.5,10.3): 0.4773 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5332 - ca3-[10.3,11.3): 0.6644 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5578 - ca4-[11.3,14.9): 0.6883 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4247 - val_ca1-[10.3,11.3): 0.9170 - val_ca1-[11.3,14.9): 1.5929 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8016 - val_ca2-[11.3,14.9): 1.3656 - val_ca3-[8.0,9.5): 0.8895 - val_ca3-[9.5,10.3): 0.5464 - val_ca3-[10.3,11.3): 0.6851 - val_ca3-[11.3,14.9): 0.8523 - val_ca4-[8.0,9.5): 1.4919 - val_ca4-[9.5,10.3): 1.0718 - val_ca4-[10.3,11.3): 0.9411 - val_ca4-[11.3,14.9): 0.6689\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5279 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3606 - ca2-[9.5,10.3): 0.4858 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5160 - ca3-[10.3,11.3): 0.6664 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5414 - ca4-[11.3,14.9): 0.6800 - val_ca1-[8.0,9.5): 0.5792 - val_ca1-[9.5,10.3): 0.4245 - val_ca1-[10.3,11.3): 0.9348 - val_ca1-[11.3,14.9): 1.6039 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.3934 - val_ca2-[10.3,11.3): 0.8157 - val_ca2-[11.3,14.9): 1.3747 - val_ca3-[8.0,9.5): 0.8960 - val_ca3-[9.5,10.3): 0.5495 - val_ca3-[10.3,11.3): 0.6938 - val_ca3-[11.3,14.9): 0.8714 - val_ca4-[8.0,9.5): 1.4931 - val_ca4-[9.5,10.3): 1.0728 - val_ca4-[10.3,11.3): 0.9405 - val_ca4-[11.3,14.9): 0.7068\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5222 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3610 - ca2-[9.5,10.3): 0.4710 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5297 - ca3-[10.3,11.3): 0.6756 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5574 - ca4-[11.3,14.9): 0.6948 - val_ca1-[8.0,9.5): 0.5792 - val_ca1-[9.5,10.3): 0.4245 - val_ca1-[10.3,11.3): 0.9367 - val_ca1-[11.3,14.9): 1.6308 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3947 - val_ca2-[10.3,11.3): 0.8276 - val_ca2-[11.3,14.9): 1.4199 - val_ca3-[8.0,9.5): 0.8926 - val_ca3-[9.5,10.3): 0.5469 - val_ca3-[10.3,11.3): 0.6954 - val_ca3-[11.3,14.9): 0.8858 - val_ca4-[8.0,9.5): 1.4917 - val_ca4-[9.5,10.3): 1.0716 - val_ca4-[10.3,11.3): 0.9423 - val_ca4-[11.3,14.9): 0.7104\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5175 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3520 - ca2-[9.5,10.3): 0.4657 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5307 - ca3-[10.3,11.3): 0.6597 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5117 - ca4-[11.3,14.9): 0.6823 - val_ca1-[8.0,9.5): 0.5792 - val_ca1-[9.5,10.3): 0.4244 - val_ca1-[10.3,11.3): 0.9316 - val_ca1-[11.3,14.9): 1.6368 - val_ca2-[8.0,9.5): 0.5838 - val_ca2-[9.5,10.3): 0.3949 - val_ca2-[10.3,11.3): 0.8294 - val_ca2-[11.3,14.9): 1.4308 - val_ca3-[8.0,9.5): 0.8971 - val_ca3-[9.5,10.3): 0.5494 - val_ca3-[10.3,11.3): 0.6795 - val_ca3-[11.3,14.9): 0.8726 - val_ca4-[8.0,9.5): 1.4909 - val_ca4-[9.5,10.3): 1.0708 - val_ca4-[10.3,11.3): 0.9102 - val_ca4-[11.3,14.9): 0.6866\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5197 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3618 - ca2-[9.5,10.3): 0.4842 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5377 - ca3-[10.3,11.3): 0.6748 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5597 - ca4-[11.3,14.9): 0.6871 - val_ca1-[8.0,9.5): 0.5793 - val_ca1-[9.5,10.3): 0.4242 - val_ca1-[10.3,11.3): 0.9378 - val_ca1-[11.3,14.9): 1.6199 - val_ca2-[8.0,9.5): 0.5876 - val_ca2-[9.5,10.3): 0.3934 - val_ca2-[10.3,11.3): 0.8207 - val_ca2-[11.3,14.9): 1.3921 - val_ca3-[8.0,9.5): 0.8965 - val_ca3-[9.5,10.3): 0.5490 - val_ca3-[10.3,11.3): 0.6928 - val_ca3-[11.3,14.9): 0.8790 - val_ca4-[8.0,9.5): 1.4935 - val_ca4-[9.5,10.3): 1.0730 - val_ca4-[10.3,11.3): 0.9402 - val_ca4-[11.3,14.9): 0.7121\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5144 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3586 - ca2-[9.5,10.3): 0.4640 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5140 - ca3-[10.3,11.3): 0.6773 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5516 - ca4-[11.3,14.9): 0.6708 - val_ca1-[8.0,9.5): 0.5793 - val_ca1-[9.5,10.3): 0.4241 - val_ca1-[10.3,11.3): 0.9296 - val_ca1-[11.3,14.9): 1.6151 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3937 - val_ca2-[10.3,11.3): 0.8164 - val_ca2-[11.3,14.9): 1.3922 - val_ca3-[8.0,9.5): 0.8830 - val_ca3-[9.5,10.3): 0.5412 - val_ca3-[10.3,11.3): 0.6846 - val_ca3-[11.3,14.9): 0.8783 - val_ca4-[8.0,9.5): 1.4946 - val_ca4-[9.5,10.3): 1.0738 - val_ca4-[10.3,11.3): 0.9265 - val_ca4-[11.3,14.9): 0.6915\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5247 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3532 - ca2-[9.5,10.3): 0.4769 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5255 - ca3-[10.3,11.3): 0.6706 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5871 - ca4-[11.3,14.9): 0.6976 - val_ca1-[8.0,9.5): 0.5794 - val_ca1-[9.5,10.3): 0.4239 - val_ca1-[10.3,11.3): 0.9343 - val_ca1-[11.3,14.9): 1.6216 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3935 - val_ca2-[10.3,11.3): 0.8197 - val_ca2-[11.3,14.9): 1.4001 - val_ca3-[8.0,9.5): 0.8953 - val_ca3-[9.5,10.3): 0.5483 - val_ca3-[10.3,11.3): 0.6942 - val_ca3-[11.3,14.9): 0.8834 - val_ca4-[8.0,9.5): 1.4954 - val_ca4-[9.5,10.3): 1.0745 - val_ca4-[10.3,11.3): 0.9437 - val_ca4-[11.3,14.9): 0.7137\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5178 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3575 - ca2-[9.5,10.3): 0.4772 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5285 - ca3-[10.3,11.3): 0.6652 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5159 - ca4-[11.3,14.9): 0.6782 - val_ca1-[8.0,9.5): 0.5795 - val_ca1-[9.5,10.3): 0.4238 - val_ca1-[10.3,11.3): 0.9262 - val_ca1-[11.3,14.9): 1.5914 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3940 - val_ca2-[10.3,11.3): 0.8205 - val_ca2-[11.3,14.9): 1.3863 - val_ca3-[8.0,9.5): 0.9063 - val_ca3-[9.5,10.3): 0.5549 - val_ca3-[10.3,11.3): 0.6951 - val_ca3-[11.3,14.9): 0.8553 - val_ca4-[8.0,9.5): 1.4953 - val_ca4-[9.5,10.3): 1.0742 - val_ca4-[10.3,11.3): 0.9495 - val_ca4-[11.3,14.9): 0.7000\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5086 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3667 - ca2-[9.5,10.3): 0.4682 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5127 - ca3-[10.3,11.3): 0.6792 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5541 - ca4-[11.3,14.9): 0.6827 - val_ca1-[8.0,9.5): 0.5795 - val_ca1-[9.5,10.3): 0.4237 - val_ca1-[10.3,11.3): 0.9312 - val_ca1-[11.3,14.9): 1.5969 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3938 - val_ca2-[10.3,11.3): 0.8204 - val_ca2-[11.3,14.9): 1.3800 - val_ca3-[8.0,9.5): 0.8850 - val_ca3-[9.5,10.3): 0.5428 - val_ca3-[10.3,11.3): 0.6913 - val_ca3-[11.3,14.9): 0.8580 - val_ca4-[8.0,9.5): 1.4966 - val_ca4-[9.5,10.3): 1.0754 - val_ca4-[10.3,11.3): 0.9416 - val_ca4-[11.3,14.9): 0.6781\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5239 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3669 - ca2-[9.5,10.3): 0.4702 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5014 - ca3-[10.3,11.3): 0.6739 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5450 - ca4-[11.3,14.9): 0.6862 - val_ca1-[8.0,9.5): 0.5796 - val_ca1-[9.5,10.3): 0.4236 - val_ca1-[10.3,11.3): 0.9306 - val_ca1-[11.3,14.9): 1.6291 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8198 - val_ca2-[11.3,14.9): 1.4122 - val_ca3-[8.0,9.5): 0.8914 - val_ca3-[9.5,10.3): 0.5466 - val_ca3-[10.3,11.3): 0.6910 - val_ca3-[11.3,14.9): 0.8860 - val_ca4-[8.0,9.5): 1.4972 - val_ca4-[9.5,10.3): 1.0758 - val_ca4-[10.3,11.3): 0.9418 - val_ca4-[11.3,14.9): 0.7107\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5207 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3552 - ca2-[9.5,10.3): 0.4631 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5225 - ca3-[10.3,11.3): 0.6671 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5073 - ca4-[11.3,14.9): 0.6943 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4234 - val_ca1-[10.3,11.3): 0.9164 - val_ca1-[11.3,14.9): 1.5840 - val_ca2-[8.0,9.5): 0.5852 - val_ca2-[9.5,10.3): 0.3941 - val_ca2-[10.3,11.3): 0.8114 - val_ca2-[11.3,14.9): 1.3794 - val_ca3-[8.0,9.5): 0.8921 - val_ca3-[9.5,10.3): 0.5465 - val_ca3-[10.3,11.3): 0.6855 - val_ca3-[11.3,14.9): 0.8519 - val_ca4-[8.0,9.5): 1.4974 - val_ca4-[9.5,10.3): 1.0759 - val_ca4-[10.3,11.3): 0.9414 - val_ca4-[11.3,14.9): 0.6862\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3631 - ca2-[9.5,10.3): 0.4657 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5222 - ca3-[10.3,11.3): 0.6677 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5455 - ca4-[11.3,14.9): 0.6926 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4234 - val_ca1-[10.3,11.3): 0.9272 - val_ca1-[11.3,14.9): 1.6095 - val_ca2-[8.0,9.5): 0.5843 - val_ca2-[9.5,10.3): 0.3943 - val_ca2-[10.3,11.3): 0.8244 - val_ca2-[11.3,14.9): 1.4119 - val_ca3-[8.0,9.5): 0.8915 - val_ca3-[9.5,10.3): 0.5459 - val_ca3-[10.3,11.3): 0.6914 - val_ca3-[11.3,14.9): 0.8771 - val_ca4-[8.0,9.5): 1.4971 - val_ca4-[9.5,10.3): 1.0756 - val_ca4-[10.3,11.3): 0.9458 - val_ca4-[11.3,14.9): 0.7120\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5169 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3574 - ca2-[9.5,10.3): 0.4688 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5191 - ca3-[10.3,11.3): 0.6939 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5315 - ca4-[11.3,14.9): 0.6798 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4233 - val_ca1-[10.3,11.3): 0.9202 - val_ca1-[11.3,14.9): 1.5993 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8154 - val_ca2-[11.3,14.9): 1.3951 - val_ca3-[8.0,9.5): 0.8968 - val_ca3-[9.5,10.3): 0.5489 - val_ca3-[10.3,11.3): 0.6891 - val_ca3-[11.3,14.9): 0.8704 - val_ca4-[8.0,9.5): 1.4977 - val_ca4-[9.5,10.3): 1.0760 - val_ca4-[10.3,11.3): 0.9452 - val_ca4-[11.3,14.9): 0.7122\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5129 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3433 - ca2-[9.5,10.3): 0.4620 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5366 - ca3-[10.3,11.3): 0.6656 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5907 - ca4-[11.3,14.9): 0.6767 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4233 - val_ca1-[10.3,11.3): 0.9247 - val_ca1-[11.3,14.9): 1.6331 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3933 - val_ca2-[10.3,11.3): 0.8157 - val_ca2-[11.3,14.9): 1.4202 - val_ca3-[8.0,9.5): 0.8796 - val_ca3-[9.5,10.3): 0.5388 - val_ca3-[10.3,11.3): 0.6897 - val_ca3-[11.3,14.9): 0.9002 - val_ca4-[8.0,9.5): 1.4975 - val_ca4-[9.5,10.3): 1.0758 - val_ca4-[10.3,11.3): 0.9434 - val_ca4-[11.3,14.9): 0.7167\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5083 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3512 - ca2-[9.5,10.3): 0.4641 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5206 - ca3-[10.3,11.3): 0.6683 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5574 - ca4-[11.3,14.9): 0.6900 - val_ca1-[8.0,9.5): 0.5798 - val_ca1-[9.5,10.3): 0.4231 - val_ca1-[10.3,11.3): 0.9324 - val_ca1-[11.3,14.9): 1.6144 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.3934 - val_ca2-[10.3,11.3): 0.8224 - val_ca2-[11.3,14.9): 1.4025 - val_ca3-[8.0,9.5): 0.8880 - val_ca3-[9.5,10.3): 0.5438 - val_ca3-[10.3,11.3): 0.6939 - val_ca3-[11.3,14.9): 0.8784 - val_ca4-[8.0,9.5): 1.4983 - val_ca4-[9.5,10.3): 1.0763 - val_ca4-[10.3,11.3): 0.9472 - val_ca4-[11.3,14.9): 0.7074\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3498 - ca2-[9.5,10.3): 0.4708 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5119 - ca3-[10.3,11.3): 0.6801 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5424 - ca4-[11.3,14.9): 0.6812 - val_ca1-[8.0,9.5): 0.5798 - val_ca1-[9.5,10.3): 0.4230 - val_ca1-[10.3,11.3): 0.9282 - val_ca1-[11.3,14.9): 1.6519 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8196 - val_ca2-[11.3,14.9): 1.4332 - val_ca3-[8.0,9.5): 0.8858 - val_ca3-[9.5,10.3): 0.5425 - val_ca3-[10.3,11.3): 0.6892 - val_ca3-[11.3,14.9): 0.8911 - val_ca4-[8.0,9.5): 1.4994 - val_ca4-[9.5,10.3): 1.0772 - val_ca4-[10.3,11.3): 0.9424 - val_ca4-[11.3,14.9): 0.7027\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5045 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3497 - ca2-[9.5,10.3): 0.4703 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5145 - ca3-[10.3,11.3): 0.6715 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5357 - ca4-[11.3,14.9): 0.6978 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4229 - val_ca1-[10.3,11.3): 0.9298 - val_ca1-[11.3,14.9): 1.5943 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.3931 - val_ca2-[10.3,11.3): 0.8187 - val_ca2-[11.3,14.9): 1.3736 - val_ca3-[8.0,9.5): 0.8937 - val_ca3-[9.5,10.3): 0.5469 - val_ca3-[10.3,11.3): 0.6912 - val_ca3-[11.3,14.9): 0.8309 - val_ca4-[8.0,9.5): 1.4996 - val_ca4-[9.5,10.3): 1.0773 - val_ca4-[10.3,11.3): 0.9450 - val_ca4-[11.3,14.9): 0.6342\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5163 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3642 - ca2-[9.5,10.3): 0.4785 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5287 - ca3-[10.3,11.3): 0.6598 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5394 - ca4-[11.3,14.9): 0.6868 - val_ca1-[8.0,9.5): 0.5798 - val_ca1-[9.5,10.3): 0.4229 - val_ca1-[10.3,11.3): 0.9319 - val_ca1-[11.3,14.9): 1.5938 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8240 - val_ca2-[11.3,14.9): 1.3899 - val_ca3-[8.0,9.5): 0.8828 - val_ca3-[9.5,10.3): 0.5399 - val_ca3-[10.3,11.3): 0.6929 - val_ca3-[11.3,14.9): 0.8719 - val_ca4-[8.0,9.5): 1.4994 - val_ca4-[9.5,10.3): 1.0771 - val_ca4-[10.3,11.3): 0.9474 - val_ca4-[11.3,14.9): 0.7083\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5116 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3507 - ca2-[9.5,10.3): 0.4679 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5301 - ca3-[10.3,11.3): 0.6752 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5200 - ca4-[11.3,14.9): 0.6812 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4229 - val_ca1-[10.3,11.3): 0.9249 - val_ca1-[11.3,14.9): 1.6125 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.3930 - val_ca2-[10.3,11.3): 0.8165 - val_ca2-[11.3,14.9): 1.3986 - val_ca3-[8.0,9.5): 0.8880 - val_ca3-[9.5,10.3): 0.5427 - val_ca3-[10.3,11.3): 0.6906 - val_ca3-[11.3,14.9): 0.8779 - val_ca4-[8.0,9.5): 1.5001 - val_ca4-[9.5,10.3): 1.0777 - val_ca4-[10.3,11.3): 0.9468 - val_ca4-[11.3,14.9): 0.7023\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3558 - ca2-[9.5,10.3): 0.4620 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4913 - ca3-[10.3,11.3): 0.6600 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5495 - ca4-[11.3,14.9): 0.6895 - val_ca1-[8.0,9.5): 0.5798 - val_ca1-[9.5,10.3): 0.4228 - val_ca1-[10.3,11.3): 0.9295 - val_ca1-[11.3,14.9): 1.6362 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.3931 - val_ca2-[10.3,11.3): 0.8205 - val_ca2-[11.3,14.9): 1.4189 - val_ca3-[8.0,9.5): 0.8780 - val_ca3-[9.5,10.3): 0.5364 - val_ca3-[10.3,11.3): 0.6903 - val_ca3-[11.3,14.9): 0.8967 - val_ca4-[8.0,9.5): 1.5002 - val_ca4-[9.5,10.3): 1.0776 - val_ca4-[10.3,11.3): 0.9451 - val_ca4-[11.3,14.9): 0.7171\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5274 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3641 - ca2-[9.5,10.3): 0.4786 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5119 - ca3-[10.3,11.3): 0.6762 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5203 - ca4-[11.3,14.9): 0.6770 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4228 - val_ca1-[10.3,11.3): 0.9226 - val_ca1-[11.3,14.9): 1.6284 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3936 - val_ca2-[10.3,11.3): 0.8187 - val_ca2-[11.3,14.9): 1.4250 - val_ca3-[8.0,9.5): 0.8853 - val_ca3-[9.5,10.3): 0.5405 - val_ca3-[10.3,11.3): 0.6873 - val_ca3-[11.3,14.9): 0.8868 - val_ca4-[8.0,9.5): 1.5001 - val_ca4-[9.5,10.3): 1.0775 - val_ca4-[10.3,11.3): 0.9440 - val_ca4-[11.3,14.9): 0.7107\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5171 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3511 - ca2-[9.5,10.3): 0.4668 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5317 - ca3-[10.3,11.3): 0.6700 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5474 - ca4-[11.3,14.9): 0.6791 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4227 - val_ca1-[10.3,11.3): 0.9269 - val_ca1-[11.3,14.9): 1.5883 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.3926 - val_ca2-[10.3,11.3): 0.8163 - val_ca2-[11.3,14.9): 1.3738 - val_ca3-[8.0,9.5): 0.8881 - val_ca3-[9.5,10.3): 0.5422 - val_ca3-[10.3,11.3): 0.6874 - val_ca3-[11.3,14.9): 0.8586 - val_ca4-[8.0,9.5): 1.5004 - val_ca4-[9.5,10.3): 1.0776 - val_ca4-[10.3,11.3): 0.9423 - val_ca4-[11.3,14.9): 0.6941\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5084 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3452 - ca2-[9.5,10.3): 0.4696 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4993 - ca3-[10.3,11.3): 0.6905 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5785 - ca4-[11.3,14.9): 0.6993 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4226 - val_ca1-[10.3,11.3): 0.9228 - val_ca1-[11.3,14.9): 1.5740 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3928 - val_ca2-[10.3,11.3): 0.8155 - val_ca2-[11.3,14.9): 1.3672 - val_ca3-[8.0,9.5): 0.8790 - val_ca3-[9.5,10.3): 0.5367 - val_ca3-[10.3,11.3): 0.6799 - val_ca3-[11.3,14.9): 0.8499 - val_ca4-[8.0,9.5): 1.5009 - val_ca4-[9.5,10.3): 1.0779 - val_ca4-[10.3,11.3): 0.9281 - val_ca4-[11.3,14.9): 0.6805\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5146 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3648 - ca2-[9.5,10.3): 0.4682 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5191 - ca3-[10.3,11.3): 0.6594 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5566 - ca4-[11.3,14.9): 0.6891 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4225 - val_ca1-[10.3,11.3): 0.9281 - val_ca1-[11.3,14.9): 1.5991 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3930 - val_ca2-[10.3,11.3): 0.8207 - val_ca2-[11.3,14.9): 1.3860 - val_ca3-[8.0,9.5): 0.8810 - val_ca3-[9.5,10.3): 0.5381 - val_ca3-[10.3,11.3): 0.6892 - val_ca3-[11.3,14.9): 0.8725 - val_ca4-[8.0,9.5): 1.5009 - val_ca4-[9.5,10.3): 1.0778 - val_ca4-[10.3,11.3): 0.9449 - val_ca4-[11.3,14.9): 0.7123\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5129 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3599 - ca2-[9.5,10.3): 0.4721 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5114 - ca3-[10.3,11.3): 0.6634 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5171 - ca4-[11.3,14.9): 0.6648 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4225 - val_ca1-[10.3,11.3): 0.9213 - val_ca1-[11.3,14.9): 1.5930 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3921 - val_ca2-[10.3,11.3): 0.8088 - val_ca2-[11.3,14.9): 1.3681 - val_ca3-[8.0,9.5): 0.8885 - val_ca3-[9.5,10.3): 0.5422 - val_ca3-[10.3,11.3): 0.6867 - val_ca3-[11.3,14.9): 0.8599 - val_ca4-[8.0,9.5): 1.5018 - val_ca4-[9.5,10.3): 1.0785 - val_ca4-[10.3,11.3): 0.9444 - val_ca4-[11.3,14.9): 0.6945\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5221 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3540 - ca2-[9.5,10.3): 0.4655 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5095 - ca3-[10.3,11.3): 0.6667 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5395 - ca4-[11.3,14.9): 0.6836 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4225 - val_ca1-[10.3,11.3): 0.9280 - val_ca1-[11.3,14.9): 1.6049 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3925 - val_ca2-[10.3,11.3): 0.8164 - val_ca2-[11.3,14.9): 1.3860 - val_ca3-[8.0,9.5): 0.8778 - val_ca3-[9.5,10.3): 0.5359 - val_ca3-[10.3,11.3): 0.6883 - val_ca3-[11.3,14.9): 0.8744 - val_ca4-[8.0,9.5): 1.5006 - val_ca4-[9.5,10.3): 1.0773 - val_ca4-[10.3,11.3): 0.9444 - val_ca4-[11.3,14.9): 0.7011\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5199 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3611 - ca2-[9.5,10.3): 0.4662 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5057 - ca3-[10.3,11.3): 0.6619 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5615 - ca4-[11.3,14.9): 0.6875 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4225 - val_ca1-[10.3,11.3): 0.9234 - val_ca1-[11.3,14.9): 1.6129 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3928 - val_ca2-[10.3,11.3): 0.8171 - val_ca2-[11.3,14.9): 1.4069 - val_ca3-[8.0,9.5): 0.8732 - val_ca3-[9.5,10.3): 0.5331 - val_ca3-[10.3,11.3): 0.6877 - val_ca3-[11.3,14.9): 0.8863 - val_ca4-[8.0,9.5): 1.5005 - val_ca4-[9.5,10.3): 1.0771 - val_ca4-[10.3,11.3): 0.9459 - val_ca4-[11.3,14.9): 0.7090\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5258 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3630 - ca2-[9.5,10.3): 0.4663 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5070 - ca3-[10.3,11.3): 0.6761 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5840 - ca4-[11.3,14.9): 0.7051 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4224 - val_ca1-[10.3,11.3): 0.9295 - val_ca1-[11.3,14.9): 1.6280 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.3930 - val_ca2-[10.3,11.3): 0.8237 - val_ca2-[11.3,14.9): 1.4254 - val_ca3-[8.0,9.5): 0.8866 - val_ca3-[9.5,10.3): 0.5408 - val_ca3-[10.3,11.3): 0.6901 - val_ca3-[11.3,14.9): 0.8830 - val_ca4-[8.0,9.5): 1.5011 - val_ca4-[9.5,10.3): 1.0774 - val_ca4-[10.3,11.3): 0.9468 - val_ca4-[11.3,14.9): 0.7099\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3568 - ca2-[9.5,10.3): 0.4688 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5136 - ca3-[10.3,11.3): 0.6722 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5401 - ca4-[11.3,14.9): 0.6821 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4224 - val_ca1-[10.3,11.3): 0.9228 - val_ca1-[11.3,14.9): 1.6179 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3920 - val_ca2-[10.3,11.3): 0.8131 - val_ca2-[11.3,14.9): 1.4043 - val_ca3-[8.0,9.5): 0.8876 - val_ca3-[9.5,10.3): 0.5413 - val_ca3-[10.3,11.3): 0.6876 - val_ca3-[11.3,14.9): 0.8847 - val_ca4-[8.0,9.5): 1.5011 - val_ca4-[9.5,10.3): 1.0774 - val_ca4-[10.3,11.3): 0.9458 - val_ca4-[11.3,14.9): 0.7202\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5191 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3527 - ca2-[9.5,10.3): 0.4664 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5086 - ca3-[10.3,11.3): 0.6689 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5520 - ca4-[11.3,14.9): 0.6787 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4223 - val_ca1-[10.3,11.3): 0.9252 - val_ca1-[11.3,14.9): 1.6177 - val_ca2-[8.0,9.5): 0.5892 - val_ca2-[9.5,10.3): 0.3915 - val_ca2-[10.3,11.3): 0.8087 - val_ca2-[11.3,14.9): 1.3863 - val_ca3-[8.0,9.5): 0.8678 - val_ca3-[9.5,10.3): 0.5296 - val_ca3-[10.3,11.3): 0.6850 - val_ca3-[11.3,14.9): 0.8931 - val_ca4-[8.0,9.5): 1.5020 - val_ca4-[9.5,10.3): 1.0781 - val_ca4-[10.3,11.3): 0.9419 - val_ca4-[11.3,14.9): 0.7144\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5233 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3562 - ca2-[9.5,10.3): 0.4697 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5092 - ca3-[10.3,11.3): 0.6776 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5262 - ca4-[11.3,14.9): 0.6843 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4223 - val_ca1-[10.3,11.3): 0.9275 - val_ca1-[11.3,14.9): 1.5918 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.3923 - val_ca2-[10.3,11.3): 0.8171 - val_ca2-[11.3,14.9): 1.3832 - val_ca3-[8.0,9.5): 0.8688 - val_ca3-[9.5,10.3): 0.5302 - val_ca3-[10.3,11.3): 0.6852 - val_ca3-[11.3,14.9): 0.8688 - val_ca4-[8.0,9.5): 1.5013 - val_ca4-[9.5,10.3): 1.0773 - val_ca4-[10.3,11.3): 0.9389 - val_ca4-[11.3,14.9): 0.6892\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5207 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3471 - ca2-[9.5,10.3): 0.4666 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5129 - ca3-[10.3,11.3): 0.6764 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5436 - ca4-[11.3,14.9): 0.6840 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4222 - val_ca1-[10.3,11.3): 0.9247 - val_ca1-[11.3,14.9): 1.6107 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3931 - val_ca2-[10.3,11.3): 0.8213 - val_ca2-[11.3,14.9): 1.4129 - val_ca3-[8.0,9.5): 0.8838 - val_ca3-[9.5,10.3): 0.5389 - val_ca3-[10.3,11.3): 0.6846 - val_ca3-[11.3,14.9): 0.8707 - val_ca4-[8.0,9.5): 1.5003 - val_ca4-[9.5,10.3): 1.0762 - val_ca4-[10.3,11.3): 0.9404 - val_ca4-[11.3,14.9): 0.7023\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5118 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3557 - ca2-[9.5,10.3): 0.4759 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5115 - ca3-[10.3,11.3): 0.6560 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5699 - ca4-[11.3,14.9): 0.6880 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4221 - val_ca1-[10.3,11.3): 0.9112 - val_ca1-[11.3,14.9): 1.6098 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.3920 - val_ca2-[10.3,11.3): 0.8060 - val_ca2-[11.3,14.9): 1.3979 - val_ca3-[8.0,9.5): 0.8854 - val_ca3-[9.5,10.3): 0.5398 - val_ca3-[10.3,11.3): 0.6768 - val_ca3-[11.3,14.9): 0.8643 - val_ca4-[8.0,9.5): 1.5017 - val_ca4-[9.5,10.3): 1.0773 - val_ca4-[10.3,11.3): 0.9299 - val_ca4-[11.3,14.9): 0.6910\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5200 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3435 - ca2-[9.5,10.3): 0.4673 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5299 - ca3-[10.3,11.3): 0.6716 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5483 - ca4-[11.3,14.9): 0.6891 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4221 - val_ca1-[10.3,11.3): 0.9242 - val_ca1-[11.3,14.9): 1.5953 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3922 - val_ca2-[10.3,11.3): 0.8161 - val_ca2-[11.3,14.9): 1.3907 - val_ca3-[8.0,9.5): 0.8749 - val_ca3-[9.5,10.3): 0.5334 - val_ca3-[10.3,11.3): 0.6836 - val_ca3-[11.3,14.9): 0.8720 - val_ca4-[8.0,9.5): 1.5001 - val_ca4-[9.5,10.3): 1.0758 - val_ca4-[10.3,11.3): 0.9399 - val_ca4-[11.3,14.9): 0.7057\n",
      "Epoch 193/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5121 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3607 - ca2-[9.5,10.3): 0.4718 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4961 - ca3-[10.3,11.3): 0.6645 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5457 - ca4-[11.3,14.9): 0.6923 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4221 - val_ca1-[10.3,11.3): 0.9259 - val_ca1-[11.3,14.9): 1.5954 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.3919 - val_ca2-[10.3,11.3): 0.8153 - val_ca2-[11.3,14.9): 1.3797 - val_ca3-[8.0,9.5): 0.8677 - val_ca3-[9.5,10.3): 0.5291 - val_ca3-[10.3,11.3): 0.6853 - val_ca3-[11.3,14.9): 0.8774 - val_ca4-[8.0,9.5): 1.5011 - val_ca4-[9.5,10.3): 1.0765 - val_ca4-[10.3,11.3): 0.9427 - val_ca4-[11.3,14.9): 0.7059\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5197 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3572 - ca2-[9.5,10.3): 0.4738 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5363 - ca3-[10.3,11.3): 0.6677 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5391 - ca4-[11.3,14.9): 0.6863 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9153 - val_ca1-[11.3,14.9): 1.6028 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3919 - val_ca2-[10.3,11.3): 0.8098 - val_ca2-[11.3,14.9): 1.3973 - val_ca3-[8.0,9.5): 0.8780 - val_ca3-[9.5,10.3): 0.5348 - val_ca3-[10.3,11.3): 0.6756 - val_ca3-[11.3,14.9): 0.8687 - val_ca4-[8.0,9.5): 1.5013 - val_ca4-[9.5,10.3): 1.0765 - val_ca4-[10.3,11.3): 0.9273 - val_ca4-[11.3,14.9): 0.6903\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5269 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3563 - ca2-[9.5,10.3): 0.4648 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5190 - ca3-[10.3,11.3): 0.6619 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5497 - ca4-[11.3,14.9): 0.6914 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9231 - val_ca1-[11.3,14.9): 1.5870 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.3919 - val_ca2-[10.3,11.3): 0.8142 - val_ca2-[11.3,14.9): 1.3788 - val_ca3-[8.0,9.5): 0.8864 - val_ca3-[9.5,10.3): 0.5401 - val_ca3-[10.3,11.3): 0.6828 - val_ca3-[11.3,14.9): 0.8501 - val_ca4-[8.0,9.5): 1.5023 - val_ca4-[9.5,10.3): 1.0772 - val_ca4-[10.3,11.3): 0.9401 - val_ca4-[11.3,14.9): 0.6985\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5209 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3478 - ca2-[9.5,10.3): 0.4622 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5215 - ca3-[10.3,11.3): 0.6667 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5998 - ca4-[11.3,14.9): 0.6962 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9251 - val_ca1-[11.3,14.9): 1.5763 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3921 - val_ca2-[10.3,11.3): 0.8171 - val_ca2-[11.3,14.9): 1.3725 - val_ca3-[8.0,9.5): 0.8696 - val_ca3-[9.5,10.3): 0.5301 - val_ca3-[10.3,11.3): 0.6840 - val_ca3-[11.3,14.9): 0.8602 - val_ca4-[8.0,9.5): 1.5026 - val_ca4-[9.5,10.3): 1.0773 - val_ca4-[10.3,11.3): 0.9426 - val_ca4-[11.3,14.9): 0.7011\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5089 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3512 - ca2-[9.5,10.3): 0.4571 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4926 - ca3-[10.3,11.3): 0.6647 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5528 - ca4-[11.3,14.9): 0.6928 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9194 - val_ca1-[11.3,14.9): 1.5685 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3918 - val_ca2-[10.3,11.3): 0.8141 - val_ca2-[11.3,14.9): 1.3678 - val_ca3-[8.0,9.5): 0.8735 - val_ca3-[9.5,10.3): 0.5321 - val_ca3-[10.3,11.3): 0.6748 - val_ca3-[11.3,14.9): 0.8393 - val_ca4-[8.0,9.5): 1.5012 - val_ca4-[9.5,10.3): 1.0760 - val_ca4-[10.3,11.3): 0.9248 - val_ca4-[11.3,14.9): 0.6685\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5185 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3658 - ca2-[9.5,10.3): 0.4629 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5153 - ca3-[10.3,11.3): 0.6856 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5803 - ca4-[11.3,14.9): 0.6915 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9195 - val_ca1-[11.3,14.9): 1.6027 - val_ca2-[8.0,9.5): 0.5844 - val_ca2-[9.5,10.3): 0.3920 - val_ca2-[10.3,11.3): 0.8123 - val_ca2-[11.3,14.9): 1.3980 - val_ca3-[8.0,9.5): 0.8733 - val_ca3-[9.5,10.3): 0.5314 - val_ca3-[10.3,11.3): 0.6721 - val_ca3-[11.3,14.9): 0.8752 - val_ca4-[8.0,9.5): 1.4995 - val_ca4-[9.5,10.3): 1.0743 - val_ca4-[10.3,11.3): 0.9236 - val_ca4-[11.3,14.9): 0.7101\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5096 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3646 - ca2-[9.5,10.3): 0.4592 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4967 - ca3-[10.3,11.3): 0.6820 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5737 - ca4-[11.3,14.9): 0.6852 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9277 - val_ca1-[11.3,14.9): 1.6129 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3918 - val_ca2-[10.3,11.3): 0.8209 - val_ca2-[11.3,14.9): 1.3995 - val_ca3-[8.0,9.5): 0.8736 - val_ca3-[9.5,10.3): 0.5317 - val_ca3-[10.3,11.3): 0.6824 - val_ca3-[11.3,14.9): 0.8727 - val_ca4-[8.0,9.5): 1.4980 - val_ca4-[9.5,10.3): 1.0728 - val_ca4-[10.3,11.3): 0.9337 - val_ca4-[11.3,14.9): 0.7046\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3574 - ca2-[9.5,10.3): 0.4710 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4982 - ca3-[10.3,11.3): 0.6604 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5227 - ca4-[11.3,14.9): 0.6821 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9004 - val_ca1-[11.3,14.9): 1.5825 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.3917 - val_ca2-[10.3,11.3): 0.7921 - val_ca2-[11.3,14.9): 1.3745 - val_ca3-[8.0,9.5): 0.8708 - val_ca3-[9.5,10.3): 0.5298 - val_ca3-[10.3,11.3): 0.6653 - val_ca3-[11.3,14.9): 0.8554 - val_ca4-[8.0,9.5): 1.4980 - val_ca4-[9.5,10.3): 1.0726 - val_ca4-[10.3,11.3): 0.9320 - val_ca4-[11.3,14.9): 0.7009\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5097 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3552 - ca2-[9.5,10.3): 0.4628 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5039 - ca3-[10.3,11.3): 0.6522 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5692 - ca4-[11.3,14.9): 0.6721 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9270 - val_ca1-[11.3,14.9): 1.5899 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.3912 - val_ca2-[10.3,11.3): 0.8128 - val_ca2-[11.3,14.9): 1.3697 - val_ca3-[8.0,9.5): 0.8766 - val_ca3-[9.5,10.3): 0.5337 - val_ca3-[10.3,11.3): 0.6809 - val_ca3-[11.3,14.9): 0.8624 - val_ca4-[8.0,9.5): 1.4985 - val_ca4-[9.5,10.3): 1.0728 - val_ca4-[10.3,11.3): 0.9319 - val_ca4-[11.3,14.9): 0.7069\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5126 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3549 - ca2-[9.5,10.3): 0.4658 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5050 - ca3-[10.3,11.3): 0.6594 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4922 - ca4-[11.3,14.9): 0.6948 - val_ca1-[8.0,9.5): 0.5805 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9221 - val_ca1-[11.3,14.9): 1.5496 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3918 - val_ca2-[10.3,11.3): 0.8123 - val_ca2-[11.3,14.9): 1.3388 - val_ca3-[8.0,9.5): 0.8655 - val_ca3-[9.5,10.3): 0.5272 - val_ca3-[10.3,11.3): 0.6796 - val_ca3-[11.3,14.9): 0.8417 - val_ca4-[8.0,9.5): 1.4992 - val_ca4-[9.5,10.3): 1.0732 - val_ca4-[10.3,11.3): 0.9367 - val_ca4-[11.3,14.9): 0.6970\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5244 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3569 - ca2-[9.5,10.3): 0.4743 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5089 - ca3-[10.3,11.3): 0.6672 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5538 - ca4-[11.3,14.9): 0.6827 - val_ca1-[8.0,9.5): 0.5805 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9284 - val_ca1-[11.3,14.9): 1.6123 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3922 - val_ca2-[10.3,11.3): 0.8218 - val_ca2-[11.3,14.9): 1.4073 - val_ca3-[8.0,9.5): 0.8751 - val_ca3-[9.5,10.3): 0.5326 - val_ca3-[10.3,11.3): 0.6785 - val_ca3-[11.3,14.9): 0.8740 - val_ca4-[8.0,9.5): 1.4977 - val_ca4-[9.5,10.3): 1.0716 - val_ca4-[10.3,11.3): 0.9325 - val_ca4-[11.3,14.9): 0.7136\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5267 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3553 - ca2-[9.5,10.3): 0.4716 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5103 - ca3-[10.3,11.3): 0.6461 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5744 - ca4-[11.3,14.9): 0.6931 - val_ca1-[8.0,9.5): 0.5805 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9220 - val_ca1-[11.3,14.9): 1.6042 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3912 - val_ca2-[10.3,11.3): 0.8115 - val_ca2-[11.3,14.9): 1.3897 - val_ca3-[8.0,9.5): 0.8727 - val_ca3-[9.5,10.3): 0.5311 - val_ca3-[10.3,11.3): 0.6791 - val_ca3-[11.3,14.9): 0.8694 - val_ca4-[8.0,9.5): 1.4984 - val_ca4-[9.5,10.3): 1.0720 - val_ca4-[10.3,11.3): 0.9356 - val_ca4-[11.3,14.9): 0.7055\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 0.5121 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3677 - ca2-[9.5,10.3): 0.4686 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5198 - ca3-[10.3,11.3): 0.6878 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5502 - ca4-[11.3,14.9): 0.6908 - val_ca1-[8.0,9.5): 0.5813 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9220 - val_ca1-[11.3,14.9): 1.5938 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3921 - val_ca2-[10.3,11.3): 0.8132 - val_ca2-[11.3,14.9): 1.3851 - val_ca3-[8.0,9.5): 0.8765 - val_ca3-[9.5,10.3): 0.5336 - val_ca3-[10.3,11.3): 0.6788 - val_ca3-[11.3,14.9): 0.8577 - val_ca4-[8.0,9.5): 1.5020 - val_ca4-[9.5,10.3): 1.0745 - val_ca4-[10.3,11.3): 0.9350 - val_ca4-[11.3,14.9): 0.6966\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5136 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3540 - ca2-[9.5,10.3): 0.4611 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5013 - ca3-[10.3,11.3): 0.6570 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5612 - ca4-[11.3,14.9): 0.6789 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9243 - val_ca1-[11.3,14.9): 1.6211 - val_ca2-[8.0,9.5): 0.5856 - val_ca2-[9.5,10.3): 0.3915 - val_ca2-[10.3,11.3): 0.8166 - val_ca2-[11.3,14.9): 1.4095 - val_ca3-[8.0,9.5): 0.8610 - val_ca3-[9.5,10.3): 0.5239 - val_ca3-[10.3,11.3): 0.6804 - val_ca3-[11.3,14.9): 0.8776 - val_ca4-[8.0,9.5): 1.4980 - val_ca4-[9.5,10.3): 1.0712 - val_ca4-[10.3,11.3): 0.9373 - val_ca4-[11.3,14.9): 0.6903\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5137 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3558 - ca2-[9.5,10.3): 0.4648 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4978 - ca3-[10.3,11.3): 0.6632 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5771 - ca4-[11.3,14.9): 0.7052 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.6051 - val_ca2-[8.0,9.5): 0.5876 - val_ca2-[9.5,10.3): 0.3909 - val_ca2-[10.3,11.3): 0.8065 - val_ca2-[11.3,14.9): 1.3796 - val_ca3-[8.0,9.5): 0.8565 - val_ca3-[9.5,10.3): 0.5213 - val_ca3-[10.3,11.3): 0.6728 - val_ca3-[11.3,14.9): 0.8774 - val_ca4-[8.0,9.5): 1.4973 - val_ca4-[9.5,10.3): 1.0703 - val_ca4-[10.3,11.3): 0.9245 - val_ca4-[11.3,14.9): 0.7069\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5190 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3460 - ca2-[9.5,10.3): 0.4639 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5194 - ca3-[10.3,11.3): 0.6677 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5499 - ca4-[11.3,14.9): 0.6891 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9210 - val_ca1-[11.3,14.9): 1.5950 - val_ca2-[8.0,9.5): 0.5843 - val_ca2-[9.5,10.3): 0.3919 - val_ca2-[10.3,11.3): 0.8188 - val_ca2-[11.3,14.9): 1.4017 - val_ca3-[8.0,9.5): 0.8641 - val_ca3-[9.5,10.3): 0.5253 - val_ca3-[10.3,11.3): 0.6732 - val_ca3-[11.3,14.9): 0.8629 - val_ca4-[8.0,9.5): 1.4942 - val_ca4-[9.5,10.3): 1.0673 - val_ca4-[10.3,11.3): 0.9204 - val_ca4-[11.3,14.9): 0.6814\n",
      "Epoch 209/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3544 - ca2-[9.5,10.3): 0.4658 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5083 - ca3-[10.3,11.3): 0.6400 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5523 - ca4-[11.3,14.9): 0.6754 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9196 - val_ca1-[11.3,14.9): 1.6222 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3915 - val_ca2-[10.3,11.3): 0.8128 - val_ca2-[11.3,14.9): 1.4127 - val_ca3-[8.0,9.5): 0.8755 - val_ca3-[9.5,10.3): 0.5322 - val_ca3-[10.3,11.3): 0.6794 - val_ca3-[11.3,14.9): 0.8754 - val_ca4-[8.0,9.5): 1.4935 - val_ca4-[9.5,10.3): 1.0662 - val_ca4-[10.3,11.3): 0.9352 - val_ca4-[11.3,14.9): 0.7105\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5095 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3601 - ca2-[9.5,10.3): 0.4621 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5146 - ca3-[10.3,11.3): 0.6743 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5376 - ca4-[11.3,14.9): 0.6822 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9220 - val_ca1-[11.3,14.9): 1.5715 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3909 - val_ca2-[10.3,11.3): 0.8076 - val_ca2-[11.3,14.9): 1.3529 - val_ca3-[8.0,9.5): 0.8670 - val_ca3-[9.5,10.3): 0.5276 - val_ca3-[10.3,11.3): 0.6774 - val_ca3-[11.3,14.9): 0.8512 - val_ca4-[8.0,9.5): 1.4939 - val_ca4-[9.5,10.3): 1.0664 - val_ca4-[10.3,11.3): 0.9310 - val_ca4-[11.3,14.9): 0.6981\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5184 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3592 - ca2-[9.5,10.3): 0.4681 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5039 - ca3-[10.3,11.3): 0.6683 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5215 - ca4-[11.3,14.9): 0.6832 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9261 - val_ca1-[11.3,14.9): 1.5856 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3909 - val_ca2-[10.3,11.3): 0.8135 - val_ca2-[11.3,14.9): 1.3714 - val_ca3-[8.0,9.5): 0.8572 - val_ca3-[9.5,10.3): 0.5215 - val_ca3-[10.3,11.3): 0.6811 - val_ca3-[11.3,14.9): 0.8699 - val_ca4-[8.0,9.5): 1.4935 - val_ca4-[9.5,10.3): 1.0659 - val_ca4-[10.3,11.3): 0.9356 - val_ca4-[11.3,14.9): 0.7058\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 0.5152 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3547 - ca2-[9.5,10.3): 0.4648 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4821 - ca3-[10.3,11.3): 0.6640 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5741 - ca4-[11.3,14.9): 0.6915 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9175 - val_ca1-[11.3,14.9): 1.6132 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3910 - val_ca2-[10.3,11.3): 0.8082 - val_ca2-[11.3,14.9): 1.3936 - val_ca3-[8.0,9.5): 0.8622 - val_ca3-[9.5,10.3): 0.5245 - val_ca3-[10.3,11.3): 0.6765 - val_ca3-[11.3,14.9): 0.8712 - val_ca4-[8.0,9.5): 1.4955 - val_ca4-[9.5,10.3): 1.0674 - val_ca4-[10.3,11.3): 0.9328 - val_ca4-[11.3,14.9): 0.6934\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5107 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3579 - ca2-[9.5,10.3): 0.4672 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5035 - ca3-[10.3,11.3): 0.6756 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5347 - ca4-[11.3,14.9): 0.6917 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9221 - val_ca1-[11.3,14.9): 1.6064 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3911 - val_ca2-[10.3,11.3): 0.8119 - val_ca2-[11.3,14.9): 1.3939 - val_ca3-[8.0,9.5): 0.8582 - val_ca3-[9.5,10.3): 0.5220 - val_ca3-[10.3,11.3): 0.6767 - val_ca3-[11.3,14.9): 0.8785 - val_ca4-[8.0,9.5): 1.4956 - val_ca4-[9.5,10.3): 1.0672 - val_ca4-[10.3,11.3): 0.9309 - val_ca4-[11.3,14.9): 0.7090\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5159 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3625 - ca2-[9.5,10.3): 0.4687 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4916 - ca3-[10.3,11.3): 0.6642 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5078 - ca4-[11.3,14.9): 0.6814 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9216 - val_ca1-[11.3,14.9): 1.6155 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.3907 - val_ca2-[10.3,11.3): 0.8117 - val_ca2-[11.3,14.9): 1.3986 - val_ca3-[8.0,9.5): 0.8574 - val_ca3-[9.5,10.3): 0.5212 - val_ca3-[10.3,11.3): 0.6801 - val_ca3-[11.3,14.9): 0.8882 - val_ca4-[8.0,9.5): 1.4943 - val_ca4-[9.5,10.3): 1.0660 - val_ca4-[10.3,11.3): 0.9366 - val_ca4-[11.3,14.9): 0.7137\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5210 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3532 - ca2-[9.5,10.3): 0.4627 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5045 - ca3-[10.3,11.3): 0.6649 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5279 - ca4-[11.3,14.9): 0.6788 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9261 - val_ca1-[11.3,14.9): 1.5939 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3907 - val_ca2-[10.3,11.3): 0.8163 - val_ca2-[11.3,14.9): 1.3793 - val_ca3-[8.0,9.5): 0.8634 - val_ca3-[9.5,10.3): 0.5239 - val_ca3-[10.3,11.3): 0.6799 - val_ca3-[11.3,14.9): 0.8576 - val_ca4-[8.0,9.5): 1.4921 - val_ca4-[9.5,10.3): 1.0638 - val_ca4-[10.3,11.3): 0.9335 - val_ca4-[11.3,14.9): 0.6893\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5059 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3645 - ca2-[9.5,10.3): 0.4710 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4813 - ca3-[10.3,11.3): 0.6625 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5086 - ca4-[11.3,14.9): 0.6823 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9173 - val_ca1-[11.3,14.9): 1.5789 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3903 - val_ca2-[10.3,11.3): 0.8062 - val_ca2-[11.3,14.9): 1.3639 - val_ca3-[8.0,9.5): 0.8673 - val_ca3-[9.5,10.3): 0.5261 - val_ca3-[10.3,11.3): 0.6755 - val_ca3-[11.3,14.9): 0.8539 - val_ca4-[8.0,9.5): 1.4919 - val_ca4-[9.5,10.3): 1.0634 - val_ca4-[10.3,11.3): 0.9297 - val_ca4-[11.3,14.9): 0.6979\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5213 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3478 - ca2-[9.5,10.3): 0.4609 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5014 - ca3-[10.3,11.3): 0.6363 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5214 - ca4-[11.3,14.9): 0.6977 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9128 - val_ca1-[11.3,14.9): 1.5857 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3909 - val_ca2-[10.3,11.3): 0.8092 - val_ca2-[11.3,14.9): 1.3842 - val_ca3-[8.0,9.5): 0.8518 - val_ca3-[9.5,10.3): 0.5172 - val_ca3-[10.3,11.3): 0.6732 - val_ca3-[11.3,14.9): 0.8692 - val_ca4-[8.0,9.5): 1.4919 - val_ca4-[9.5,10.3): 1.0630 - val_ca4-[10.3,11.3): 0.9309 - val_ca4-[11.3,14.9): 0.7044\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5135 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3495 - ca2-[9.5,10.3): 0.4561 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4950 - ca3-[10.3,11.3): 0.6647 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5577 - ca4-[11.3,14.9): 0.6872 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9277 - val_ca1-[11.3,14.9): 1.5954 - val_ca2-[8.0,9.5): 0.5853 - val_ca2-[9.5,10.3): 0.3902 - val_ca2-[10.3,11.3): 0.8159 - val_ca2-[11.3,14.9): 1.3796 - val_ca3-[8.0,9.5): 0.8690 - val_ca3-[9.5,10.3): 0.5278 - val_ca3-[10.3,11.3): 0.6789 - val_ca3-[11.3,14.9): 0.8523 - val_ca4-[8.0,9.5): 1.4939 - val_ca4-[9.5,10.3): 1.0644 - val_ca4-[10.3,11.3): 0.9303 - val_ca4-[11.3,14.9): 0.6832\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5076 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3586 - ca2-[9.5,10.3): 0.4631 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5194 - ca3-[10.3,11.3): 0.6598 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5248 - ca4-[11.3,14.9): 0.6883 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9170 - val_ca1-[11.3,14.9): 1.5918 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3901 - val_ca2-[10.3,11.3): 0.8067 - val_ca2-[11.3,14.9): 1.3724 - val_ca3-[8.0,9.5): 0.8490 - val_ca3-[9.5,10.3): 0.5158 - val_ca3-[10.3,11.3): 0.6747 - val_ca3-[11.3,14.9): 0.8676 - val_ca4-[8.0,9.5): 1.4967 - val_ca4-[9.5,10.3): 1.0666 - val_ca4-[10.3,11.3): 0.9310 - val_ca4-[11.3,14.9): 0.6993\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5152 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3480 - ca2-[9.5,10.3): 0.4684 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5027 - ca3-[10.3,11.3): 0.6670 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5302 - ca4-[11.3,14.9): 0.6838 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9185 - val_ca1-[11.3,14.9): 1.6110 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.3903 - val_ca2-[10.3,11.3): 0.8106 - val_ca2-[11.3,14.9): 1.3958 - val_ca3-[8.0,9.5): 0.8657 - val_ca3-[9.5,10.3): 0.5257 - val_ca3-[10.3,11.3): 0.6763 - val_ca3-[11.3,14.9): 0.8589 - val_ca4-[8.0,9.5): 1.4950 - val_ca4-[9.5,10.3): 1.0646 - val_ca4-[10.3,11.3): 0.9320 - val_ca4-[11.3,14.9): 0.6843\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5239 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3689 - ca2-[9.5,10.3): 0.4625 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5059 - ca3-[10.3,11.3): 0.6654 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5153 - ca4-[11.3,14.9): 0.6776 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9123 - val_ca1-[11.3,14.9): 1.5923 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.3901 - val_ca2-[10.3,11.3): 0.8044 - val_ca2-[11.3,14.9): 1.3771 - val_ca3-[8.0,9.5): 0.8532 - val_ca3-[9.5,10.3): 0.5181 - val_ca3-[10.3,11.3): 0.6728 - val_ca3-[11.3,14.9): 0.8615 - val_ca4-[8.0,9.5): 1.4946 - val_ca4-[9.5,10.3): 1.0641 - val_ca4-[10.3,11.3): 0.9307 - val_ca4-[11.3,14.9): 0.6875\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5198 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3395 - ca2-[9.5,10.3): 0.4539 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4844 - ca3-[10.3,11.3): 0.6386 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5361 - ca4-[11.3,14.9): 0.6910 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9270 - val_ca1-[11.3,14.9): 1.6208 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3897 - val_ca2-[10.3,11.3): 0.8138 - val_ca2-[11.3,14.9): 1.3969 - val_ca3-[8.0,9.5): 0.8622 - val_ca3-[9.5,10.3): 0.5232 - val_ca3-[10.3,11.3): 0.6795 - val_ca3-[11.3,14.9): 0.8757 - val_ca4-[8.0,9.5): 1.4951 - val_ca4-[9.5,10.3): 1.0643 - val_ca4-[10.3,11.3): 0.9348 - val_ca4-[11.3,14.9): 0.7109\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5100 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3477 - ca2-[9.5,10.3): 0.4514 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5134 - ca3-[10.3,11.3): 0.6304 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5597 - ca4-[11.3,14.9): 0.6853 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9232 - val_ca1-[11.3,14.9): 1.6246 - val_ca2-[8.0,9.5): 0.5856 - val_ca2-[9.5,10.3): 0.3897 - val_ca2-[10.3,11.3): 0.8116 - val_ca2-[11.3,14.9): 1.4065 - val_ca3-[8.0,9.5): 0.8549 - val_ca3-[9.5,10.3): 0.5187 - val_ca3-[10.3,11.3): 0.6750 - val_ca3-[11.3,14.9): 0.8824 - val_ca4-[8.0,9.5): 1.4967 - val_ca4-[9.5,10.3): 1.0655 - val_ca4-[10.3,11.3): 0.9302 - val_ca4-[11.3,14.9): 0.7082\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5255 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3632 - ca2-[9.5,10.3): 0.4547 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5049 - ca3-[10.3,11.3): 0.6555 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5445 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9125 - val_ca1-[11.3,14.9): 1.5637 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3902 - val_ca2-[10.3,11.3): 0.8105 - val_ca2-[11.3,14.9): 1.3705 - val_ca3-[8.0,9.5): 0.8587 - val_ca3-[9.5,10.3): 0.5217 - val_ca3-[10.3,11.3): 0.6665 - val_ca3-[11.3,14.9): 0.8433 - val_ca4-[8.0,9.5): 1.4975 - val_ca4-[9.5,10.3): 1.0658 - val_ca4-[10.3,11.3): 0.9155 - val_ca4-[11.3,14.9): 0.6845\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5174 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3572 - ca2-[9.5,10.3): 0.4684 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4781 - ca3-[10.3,11.3): 0.6621 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5232 - ca4-[11.3,14.9): 0.6636 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9179 - val_ca1-[11.3,14.9): 1.5760 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.3898 - val_ca2-[10.3,11.3): 0.8109 - val_ca2-[11.3,14.9): 1.3731 - val_ca3-[8.0,9.5): 0.8538 - val_ca3-[9.5,10.3): 0.5190 - val_ca3-[10.3,11.3): 0.6742 - val_ca3-[11.3,14.9): 0.8578 - val_ca4-[8.0,9.5): 1.5015 - val_ca4-[9.5,10.3): 1.0691 - val_ca4-[10.3,11.3): 0.9335 - val_ca4-[11.3,14.9): 0.7014\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5191 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3640 - ca2-[9.5,10.3): 0.4728 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4888 - ca3-[10.3,11.3): 0.6531 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5395 - ca4-[11.3,14.9): 0.7009 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9159 - val_ca1-[11.3,14.9): 1.5695 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3892 - val_ca2-[10.3,11.3): 0.8035 - val_ca2-[11.3,14.9): 1.3588 - val_ca3-[8.0,9.5): 0.8489 - val_ca3-[9.5,10.3): 0.5155 - val_ca3-[10.3,11.3): 0.6722 - val_ca3-[11.3,14.9): 0.8567 - val_ca4-[8.0,9.5): 1.5007 - val_ca4-[9.5,10.3): 1.0678 - val_ca4-[10.3,11.3): 0.9301 - val_ca4-[11.3,14.9): 0.6898\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5146 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3679 - ca2-[9.5,10.3): 0.4570 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4887 - ca3-[10.3,11.3): 0.6482 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5286 - ca4-[11.3,14.9): 0.6699 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9229 - val_ca1-[11.3,14.9): 1.6177 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3891 - val_ca2-[10.3,11.3): 0.8083 - val_ca2-[11.3,14.9): 1.4006 - val_ca3-[8.0,9.5): 0.8527 - val_ca3-[9.5,10.3): 0.5167 - val_ca3-[10.3,11.3): 0.6737 - val_ca3-[11.3,14.9): 0.8840 - val_ca4-[8.0,9.5): 1.5000 - val_ca4-[9.5,10.3): 1.0669 - val_ca4-[10.3,11.3): 0.9301 - val_ca4-[11.3,14.9): 0.7072\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5164 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3483 - ca2-[9.5,10.3): 0.4574 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4880 - ca3-[10.3,11.3): 0.6517 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5352 - ca4-[11.3,14.9): 0.6708 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9166 - val_ca1-[11.3,14.9): 1.6043 - val_ca2-[8.0,9.5): 0.5848 - val_ca2-[9.5,10.3): 0.3894 - val_ca2-[10.3,11.3): 0.8069 - val_ca2-[11.3,14.9): 1.3823 - val_ca3-[8.0,9.5): 0.8558 - val_ca3-[9.5,10.3): 0.5180 - val_ca3-[10.3,11.3): 0.6713 - val_ca3-[11.3,14.9): 0.8660 - val_ca4-[8.0,9.5): 1.4975 - val_ca4-[9.5,10.3): 1.0643 - val_ca4-[10.3,11.3): 0.9276 - val_ca4-[11.3,14.9): 0.7042\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5135 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3643 - ca2-[9.5,10.3): 0.4570 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4896 - ca3-[10.3,11.3): 0.6683 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5303 - ca4-[11.3,14.9): 0.6806 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9207 - val_ca1-[11.3,14.9): 1.5940 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3887 - val_ca2-[10.3,11.3): 0.8048 - val_ca2-[11.3,14.9): 1.3706 - val_ca3-[8.0,9.5): 0.8533 - val_ca3-[9.5,10.3): 0.5170 - val_ca3-[10.3,11.3): 0.6746 - val_ca3-[11.3,14.9): 0.8659 - val_ca4-[8.0,9.5): 1.4984 - val_ca4-[9.5,10.3): 1.0650 - val_ca4-[10.3,11.3): 0.9328 - val_ca4-[11.3,14.9): 0.6965\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5046 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3624 - ca2-[9.5,10.3): 0.4584 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5115 - ca3-[10.3,11.3): 0.6512 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5195 - ca4-[11.3,14.9): 0.6859 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9189 - val_ca1-[11.3,14.9): 1.6053 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3892 - val_ca2-[10.3,11.3): 0.8066 - val_ca2-[11.3,14.9): 1.3888 - val_ca3-[8.0,9.5): 0.8545 - val_ca3-[9.5,10.3): 0.5179 - val_ca3-[10.3,11.3): 0.6727 - val_ca3-[11.3,14.9): 0.8647 - val_ca4-[8.0,9.5): 1.4981 - val_ca4-[9.5,10.3): 1.0645 - val_ca4-[10.3,11.3): 0.9298 - val_ca4-[11.3,14.9): 0.6984\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5183 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3574 - ca2-[9.5,10.3): 0.4717 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4859 - ca3-[10.3,11.3): 0.6667 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5593 - ca4-[11.3,14.9): 0.6863 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.6015 - val_ca2-[8.0,9.5): 0.5828 - val_ca2-[9.5,10.3): 0.3901 - val_ca2-[10.3,11.3): 0.8109 - val_ca2-[11.3,14.9): 1.3989 - val_ca3-[8.0,9.5): 0.8571 - val_ca3-[9.5,10.3): 0.5198 - val_ca3-[10.3,11.3): 0.6683 - val_ca3-[11.3,14.9): 0.8541 - val_ca4-[8.0,9.5): 1.4978 - val_ca4-[9.5,10.3): 1.0639 - val_ca4-[10.3,11.3): 0.9265 - val_ca4-[11.3,14.9): 0.6907\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5092 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3465 - ca2-[9.5,10.3): 0.4662 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4752 - ca3-[10.3,11.3): 0.6475 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5241 - ca4-[11.3,14.9): 0.6733 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9259 - val_ca1-[11.3,14.9): 1.6140 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.3891 - val_ca2-[10.3,11.3): 0.8095 - val_ca2-[11.3,14.9): 1.3895 - val_ca3-[8.0,9.5): 0.8435 - val_ca3-[9.5,10.3): 0.5121 - val_ca3-[10.3,11.3): 0.6723 - val_ca3-[11.3,14.9): 0.8733 - val_ca4-[8.0,9.5): 1.4989 - val_ca4-[9.5,10.3): 1.0645 - val_ca4-[10.3,11.3): 0.9252 - val_ca4-[11.3,14.9): 0.6967\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5155 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3545 - ca2-[9.5,10.3): 0.4537 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5091 - ca3-[10.3,11.3): 0.6690 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5270 - ca4-[11.3,14.9): 0.6773 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9213 - val_ca1-[11.3,14.9): 1.5996 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3886 - val_ca2-[10.3,11.3): 0.8020 - val_ca2-[11.3,14.9): 1.3649 - val_ca3-[8.0,9.5): 0.8477 - val_ca3-[9.5,10.3): 0.5145 - val_ca3-[10.3,11.3): 0.6700 - val_ca3-[11.3,14.9): 0.8546 - val_ca4-[8.0,9.5): 1.4985 - val_ca4-[9.5,10.3): 1.0639 - val_ca4-[10.3,11.3): 0.9244 - val_ca4-[11.3,14.9): 0.6794\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5265 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3621 - ca2-[9.5,10.3): 0.4597 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4982 - ca3-[10.3,11.3): 0.6418 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5494 - ca4-[11.3,14.9): 0.6609 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9188 - val_ca1-[11.3,14.9): 1.5734 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.3889 - val_ca2-[10.3,11.3): 0.8044 - val_ca2-[11.3,14.9): 1.3588 - val_ca3-[8.0,9.5): 0.8510 - val_ca3-[9.5,10.3): 0.5159 - val_ca3-[10.3,11.3): 0.6689 - val_ca3-[11.3,14.9): 0.8480 - val_ca4-[8.0,9.5): 1.4991 - val_ca4-[9.5,10.3): 1.0642 - val_ca4-[10.3,11.3): 0.9232 - val_ca4-[11.3,14.9): 0.6919\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5109 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3531 - ca2-[9.5,10.3): 0.4575 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4874 - ca3-[10.3,11.3): 0.6640 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5493 - ca4-[11.3,14.9): 0.6712 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9230 - val_ca1-[11.3,14.9): 1.6010 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3887 - val_ca2-[10.3,11.3): 0.8081 - val_ca2-[11.3,14.9): 1.3829 - val_ca3-[8.0,9.5): 0.8555 - val_ca3-[9.5,10.3): 0.5179 - val_ca3-[10.3,11.3): 0.6708 - val_ca3-[11.3,14.9): 0.8518 - val_ca4-[8.0,9.5): 1.4994 - val_ca4-[9.5,10.3): 1.0640 - val_ca4-[10.3,11.3): 0.9264 - val_ca4-[11.3,14.9): 0.6786\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5264 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3577 - ca2-[9.5,10.3): 0.4639 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5025 - ca3-[10.3,11.3): 0.6421 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5292 - ca4-[11.3,14.9): 0.6801 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9225 - val_ca1-[11.3,14.9): 1.5702 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.3878 - val_ca2-[10.3,11.3): 0.7996 - val_ca2-[11.3,14.9): 1.3420 - val_ca3-[8.0,9.5): 0.8476 - val_ca3-[9.5,10.3): 0.5131 - val_ca3-[10.3,11.3): 0.6704 - val_ca3-[11.3,14.9): 0.8519 - val_ca4-[8.0,9.5): 1.5040 - val_ca4-[9.5,10.3): 1.0678 - val_ca4-[10.3,11.3): 0.9284 - val_ca4-[11.3,14.9): 0.6924\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5224 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3530 - ca2-[9.5,10.3): 0.4621 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4918 - ca3-[10.3,11.3): 0.6492 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5437 - ca4-[11.3,14.9): 0.6658 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9222 - val_ca1-[11.3,14.9): 1.6095 - val_ca2-[8.0,9.5): 0.5850 - val_ca2-[9.5,10.3): 0.3884 - val_ca2-[10.3,11.3): 0.8082 - val_ca2-[11.3,14.9): 1.3933 - val_ca3-[8.0,9.5): 0.8541 - val_ca3-[9.5,10.3): 0.5173 - val_ca3-[10.3,11.3): 0.6703 - val_ca3-[11.3,14.9): 0.8672 - val_ca4-[8.0,9.5): 1.5017 - val_ca4-[9.5,10.3): 1.0651 - val_ca4-[10.3,11.3): 0.9264 - val_ca4-[11.3,14.9): 0.7027\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5142 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3442 - ca2-[9.5,10.3): 0.4446 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4783 - ca3-[10.3,11.3): 0.6472 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5699 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9037 - val_ca1-[11.3,14.9): 1.5652 - val_ca2-[8.0,9.5): 0.5810 - val_ca2-[9.5,10.3): 0.3897 - val_ca2-[10.3,11.3): 0.7988 - val_ca2-[11.3,14.9): 1.3764 - val_ca3-[8.0,9.5): 0.8367 - val_ca3-[9.5,10.3): 0.5072 - val_ca3-[10.3,11.3): 0.6577 - val_ca3-[11.3,14.9): 0.8471 - val_ca4-[8.0,9.5): 1.4987 - val_ca4-[9.5,10.3): 1.0622 - val_ca4-[10.3,11.3): 0.9167 - val_ca4-[11.3,14.9): 0.6798\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5298 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3529 - ca2-[9.5,10.3): 0.4665 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5030 - ca3-[10.3,11.3): 0.6593 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5492 - ca4-[11.3,14.9): 0.6794 - val_ca1-[8.0,9.5): 0.5800 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9269 - val_ca1-[11.3,14.9): 1.6003 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3877 - val_ca2-[10.3,11.3): 0.8050 - val_ca2-[11.3,14.9): 1.3663 - val_ca3-[8.0,9.5): 0.8444 - val_ca3-[9.5,10.3): 0.5116 - val_ca3-[10.3,11.3): 0.6739 - val_ca3-[11.3,14.9): 0.8660 - val_ca4-[8.0,9.5): 1.5026 - val_ca4-[9.5,10.3): 1.0653 - val_ca4-[10.3,11.3): 0.9311 - val_ca4-[11.3,14.9): 0.6990\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5200 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3595 - ca2-[9.5,10.3): 0.4646 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4984 - ca3-[10.3,11.3): 0.6497 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5285 - ca4-[11.3,14.9): 0.6817 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9252 - val_ca1-[11.3,14.9): 1.6097 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3888 - val_ca2-[10.3,11.3): 0.8017 - val_ca2-[11.3,14.9): 1.3806 - val_ca3-[8.0,9.5): 0.8517 - val_ca3-[9.5,10.3): 0.5174 - val_ca3-[10.3,11.3): 0.6711 - val_ca3-[11.3,14.9): 0.8642 - val_ca4-[8.0,9.5): 1.5024 - val_ca4-[9.5,10.3): 1.0679 - val_ca4-[10.3,11.3): 0.9281 - val_ca4-[11.3,14.9): 0.6983\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5164 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3540 - ca2-[9.5,10.3): 0.4680 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5119 - ca3-[10.3,11.3): 0.6326 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5614 - ca4-[11.3,14.9): 0.6677 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9180 - val_ca1-[11.3,14.9): 1.6068 - val_ca2-[8.0,9.5): 0.5833 - val_ca2-[9.5,10.3): 0.3888 - val_ca2-[10.3,11.3): 0.8073 - val_ca2-[11.3,14.9): 1.3961 - val_ca3-[8.0,9.5): 0.8354 - val_ca3-[9.5,10.3): 0.5052 - val_ca3-[10.3,11.3): 0.6665 - val_ca3-[11.3,14.9): 0.8765 - val_ca4-[8.0,9.5): 1.5008 - val_ca4-[9.5,10.3): 1.0631 - val_ca4-[10.3,11.3): 0.9235 - val_ca4-[11.3,14.9): 0.7005\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5295 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3598 - ca2-[9.5,10.3): 0.4676 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4764 - ca3-[10.3,11.3): 0.6606 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5463 - ca4-[11.3,14.9): 0.6672 - val_ca1-[8.0,9.5): 0.5796 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9225 - val_ca1-[11.3,14.9): 1.6283 - val_ca2-[8.0,9.5): 0.5873 - val_ca2-[9.5,10.3): 0.3878 - val_ca2-[10.3,11.3): 0.8001 - val_ca2-[11.3,14.9): 1.3886 - val_ca3-[8.0,9.5): 0.8340 - val_ca3-[9.5,10.3): 0.5051 - val_ca3-[10.3,11.3): 0.6662 - val_ca3-[11.3,14.9): 0.8803 - val_ca4-[8.0,9.5): 1.5025 - val_ca4-[9.5,10.3): 1.0641 - val_ca4-[10.3,11.3): 0.9221 - val_ca4-[11.3,14.9): 0.6981\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5244 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3626 - ca2-[9.5,10.3): 0.4617 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5008 - ca3-[10.3,11.3): 0.6324 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5716 - ca4-[11.3,14.9): 0.6875 - val_ca1-[8.0,9.5): 0.5796 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9224 - val_ca1-[11.3,14.9): 1.6071 - val_ca2-[8.0,9.5): 0.5844 - val_ca2-[9.5,10.3): 0.3882 - val_ca2-[10.3,11.3): 0.8065 - val_ca2-[11.3,14.9): 1.3806 - val_ca3-[8.0,9.5): 0.8432 - val_ca3-[9.5,10.3): 0.5113 - val_ca3-[10.3,11.3): 0.6660 - val_ca3-[11.3,14.9): 0.8623 - val_ca4-[8.0,9.5): 1.5022 - val_ca4-[9.5,10.3): 1.0635 - val_ca4-[10.3,11.3): 0.9214 - val_ca4-[11.3,14.9): 0.7002\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5153 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3622 - ca2-[9.5,10.3): 0.4500 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5030 - ca3-[10.3,11.3): 0.6503 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5490 - ca4-[11.3,14.9): 0.6782 - val_ca1-[8.0,9.5): 0.5795 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9228 - val_ca1-[11.3,14.9): 1.5878 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.3879 - val_ca2-[10.3,11.3): 0.8056 - val_ca2-[11.3,14.9): 1.3674 - val_ca3-[8.0,9.5): 0.8441 - val_ca3-[9.5,10.3): 0.5118 - val_ca3-[10.3,11.3): 0.6659 - val_ca3-[11.3,14.9): 0.8457 - val_ca4-[8.0,9.5): 1.5023 - val_ca4-[9.5,10.3): 1.0633 - val_ca4-[10.3,11.3): 0.9210 - val_ca4-[11.3,14.9): 0.6847\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5127 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3555 - ca2-[9.5,10.3): 0.4575 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4796 - ca3-[10.3,11.3): 0.6489 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5586 - ca4-[11.3,14.9): 0.6822 - val_ca1-[8.0,9.5): 0.5794 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9185 - val_ca1-[11.3,14.9): 1.6030 - val_ca2-[8.0,9.5): 0.5837 - val_ca2-[9.5,10.3): 0.3884 - val_ca2-[10.3,11.3): 0.8055 - val_ca2-[11.3,14.9): 1.3831 - val_ca3-[8.0,9.5): 0.8426 - val_ca3-[9.5,10.3): 0.5108 - val_ca3-[10.3,11.3): 0.6655 - val_ca3-[11.3,14.9): 0.8564 - val_ca4-[8.0,9.5): 1.5012 - val_ca4-[9.5,10.3): 1.0621 - val_ca4-[10.3,11.3): 0.9218 - val_ca4-[11.3,14.9): 0.6944\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5140 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3526 - ca2-[9.5,10.3): 0.4496 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4619 - ca3-[10.3,11.3): 0.6415 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5439 - ca4-[11.3,14.9): 0.6691 - val_ca1-[8.0,9.5): 0.5794 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9250 - val_ca1-[11.3,14.9): 1.6021 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.3873 - val_ca2-[10.3,11.3): 0.7978 - val_ca2-[11.3,14.9): 1.3541 - val_ca3-[8.0,9.5): 0.8420 - val_ca3-[9.5,10.3): 0.5105 - val_ca3-[10.3,11.3): 0.6674 - val_ca3-[11.3,14.9): 0.8577 - val_ca4-[8.0,9.5): 1.5045 - val_ca4-[9.5,10.3): 1.0647 - val_ca4-[10.3,11.3): 0.9237 - val_ca4-[11.3,14.9): 0.6980\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5163 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3495 - ca2-[9.5,10.3): 0.4628 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4993 - ca3-[10.3,11.3): 0.6434 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4766 - ca4-[11.3,14.9): 0.6737 - val_ca1-[8.0,9.5): 0.5792 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9231 - val_ca1-[11.3,14.9): 1.5764 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.3883 - val_ca2-[10.3,11.3): 0.8065 - val_ca2-[11.3,14.9): 1.3545 - val_ca3-[8.0,9.5): 0.8241 - val_ca3-[9.5,10.3): 0.4986 - val_ca3-[10.3,11.3): 0.6682 - val_ca3-[11.3,14.9): 0.8552 - val_ca4-[8.0,9.5): 1.5046 - val_ca4-[9.5,10.3): 1.0644 - val_ca4-[10.3,11.3): 0.9276 - val_ca4-[11.3,14.9): 0.6813\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5172 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3687 - ca2-[9.5,10.3): 0.4669 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4804 - ca3-[10.3,11.3): 0.6503 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5390 - ca4-[11.3,14.9): 0.6686 - val_ca1-[8.0,9.5): 0.5792 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9258 - val_ca1-[11.3,14.9): 1.6246 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3873 - val_ca2-[10.3,11.3): 0.7981 - val_ca2-[11.3,14.9): 1.3818 - val_ca3-[8.0,9.5): 0.8474 - val_ca3-[9.5,10.3): 0.5125 - val_ca3-[10.3,11.3): 0.6665 - val_ca3-[11.3,14.9): 0.8672 - val_ca4-[8.0,9.5): 1.5044 - val_ca4-[9.5,10.3): 1.0636 - val_ca4-[10.3,11.3): 0.9224 - val_ca4-[11.3,14.9): 0.6957\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5201 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3531 - ca2-[9.5,10.3): 0.4515 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5014 - ca3-[10.3,11.3): 0.6600 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5143 - ca4-[11.3,14.9): 0.6809 - val_ca1-[8.0,9.5): 0.5790 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9266 - val_ca1-[11.3,14.9): 1.5731 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3877 - val_ca2-[10.3,11.3): 0.8026 - val_ca2-[11.3,14.9): 1.3458 - val_ca3-[8.0,9.5): 0.8338 - val_ca3-[9.5,10.3): 0.5044 - val_ca3-[10.3,11.3): 0.6659 - val_ca3-[11.3,14.9): 0.8428 - val_ca4-[8.0,9.5): 1.5011 - val_ca4-[9.5,10.3): 1.0601 - val_ca4-[10.3,11.3): 0.9202 - val_ca4-[11.3,14.9): 0.6810\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5102 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3486 - ca2-[9.5,10.3): 0.4546 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4683 - ca3-[10.3,11.3): 0.6340 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5250 - ca4-[11.3,14.9): 0.6796 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9248 - val_ca1-[11.3,14.9): 1.5937 - val_ca2-[8.0,9.5): 0.5843 - val_ca2-[9.5,10.3): 0.3879 - val_ca2-[10.3,11.3): 0.8042 - val_ca2-[11.3,14.9): 1.3689 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5046 - val_ca3-[10.3,11.3): 0.6637 - val_ca3-[11.3,14.9): 0.8537 - val_ca4-[8.0,9.5): 1.5022 - val_ca4-[9.5,10.3): 1.0607 - val_ca4-[10.3,11.3): 0.9177 - val_ca4-[11.3,14.9): 0.6849\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3696 - ca2-[9.5,10.3): 0.4577 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4979 - ca3-[10.3,11.3): 0.6731 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5377 - ca4-[11.3,14.9): 0.6595 - val_ca1-[8.0,9.5): 0.5788 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9274 - val_ca1-[11.3,14.9): 1.6153 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3872 - val_ca2-[10.3,11.3): 0.8027 - val_ca2-[11.3,14.9): 1.3746 - val_ca3-[8.0,9.5): 0.8430 - val_ca3-[9.5,10.3): 0.5121 - val_ca3-[10.3,11.3): 0.6665 - val_ca3-[11.3,14.9): 0.8522 - val_ca4-[8.0,9.5): 1.5035 - val_ca4-[9.5,10.3): 1.0615 - val_ca4-[10.3,11.3): 0.9203 - val_ca4-[11.3,14.9): 0.6917\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5123 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3311 - ca2-[9.5,10.3): 0.4389 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4794 - ca3-[10.3,11.3): 0.6599 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5643 - ca4-[11.3,14.9): 0.6745 - val_ca1-[8.0,9.5): 0.5786 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9234 - val_ca1-[11.3,14.9): 1.6051 - val_ca2-[8.0,9.5): 0.5825 - val_ca2-[9.5,10.3): 0.3882 - val_ca2-[10.3,11.3): 0.8053 - val_ca2-[11.3,14.9): 1.3926 - val_ca3-[8.0,9.5): 0.8348 - val_ca3-[9.5,10.3): 0.5066 - val_ca3-[10.3,11.3): 0.6634 - val_ca3-[11.3,14.9): 0.8563 - val_ca4-[8.0,9.5): 1.5030 - val_ca4-[9.5,10.3): 1.0606 - val_ca4-[10.3,11.3): 0.9213 - val_ca4-[11.3,14.9): 0.6945\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 1s 113ms/step - ca1-[8.0,9.5): 0.5139 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3546 - ca2-[9.5,10.3): 0.4499 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4939 - ca3-[10.3,11.3): 0.6541 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5406 - ca4-[11.3,14.9): 0.6729 - val_ca1-[8.0,9.5): 0.5783 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9266 - val_ca1-[11.3,14.9): 1.5754 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3873 - val_ca2-[10.3,11.3): 0.7985 - val_ca2-[11.3,14.9): 1.3309 - val_ca3-[8.0,9.5): 0.8378 - val_ca3-[9.5,10.3): 0.5072 - val_ca3-[10.3,11.3): 0.6626 - val_ca3-[11.3,14.9): 0.8329 - val_ca4-[8.0,9.5): 1.5044 - val_ca4-[9.5,10.3): 1.0612 - val_ca4-[10.3,11.3): 0.9170 - val_ca4-[11.3,14.9): 0.6838\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5155 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3608 - ca2-[9.5,10.3): 0.4558 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4772 - ca3-[10.3,11.3): 0.6417 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5028 - ca4-[11.3,14.9): 0.6785 - val_ca1-[8.0,9.5): 0.5781 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9271 - val_ca1-[11.3,14.9): 1.6042 - val_ca2-[8.0,9.5): 0.5856 - val_ca2-[9.5,10.3): 0.3876 - val_ca2-[10.3,11.3): 0.8011 - val_ca2-[11.3,14.9): 1.3625 - val_ca3-[8.0,9.5): 0.8289 - val_ca3-[9.5,10.3): 0.5018 - val_ca3-[10.3,11.3): 0.6619 - val_ca3-[11.3,14.9): 0.8498 - val_ca4-[8.0,9.5): 1.5080 - val_ca4-[9.5,10.3): 1.0641 - val_ca4-[10.3,11.3): 0.9184 - val_ca4-[11.3,14.9): 0.6766\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5169 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3516 - ca2-[9.5,10.3): 0.4583 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4951 - ca3-[10.3,11.3): 0.6425 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5251 - ca4-[11.3,14.9): 0.6758 - val_ca1-[8.0,9.5): 0.5781 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9260 - val_ca1-[11.3,14.9): 1.6352 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3876 - val_ca2-[10.3,11.3): 0.8017 - val_ca2-[11.3,14.9): 1.3941 - val_ca3-[8.0,9.5): 0.8382 - val_ca3-[9.5,10.3): 0.5082 - val_ca3-[10.3,11.3): 0.6640 - val_ca3-[11.3,14.9): 0.8693 - val_ca4-[8.0,9.5): 1.5093 - val_ca4-[9.5,10.3): 1.0646 - val_ca4-[10.3,11.3): 0.9202 - val_ca4-[11.3,14.9): 0.7014\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5233 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3523 - ca2-[9.5,10.3): 0.4566 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5187 - ca3-[10.3,11.3): 0.6430 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5579 - ca4-[11.3,14.9): 0.6878 - val_ca1-[8.0,9.5): 0.5779 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9286 - val_ca1-[11.3,14.9): 1.5757 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3886 - val_ca2-[10.3,11.3): 0.8000 - val_ca2-[11.3,14.9): 1.3297 - val_ca3-[8.0,9.5): 0.8240 - val_ca3-[9.5,10.3): 0.4992 - val_ca3-[10.3,11.3): 0.6633 - val_ca3-[11.3,14.9): 0.8422 - val_ca4-[8.0,9.5): 1.5119 - val_ca4-[9.5,10.3): 1.0639 - val_ca4-[10.3,11.3): 0.9218 - val_ca4-[11.3,14.9): 0.6817\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5236 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3556 - ca2-[9.5,10.3): 0.4509 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5106 - ca3-[10.3,11.3): 0.6349 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5487 - ca4-[11.3,14.9): 0.6704 - val_ca1-[8.0,9.5): 0.5778 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9330 - val_ca1-[11.3,14.9): 1.6477 - val_ca2-[8.0,9.5): 0.5850 - val_ca2-[9.5,10.3): 0.3877 - val_ca2-[10.3,11.3): 0.8068 - val_ca2-[11.3,14.9): 1.4088 - val_ca3-[8.0,9.5): 0.8279 - val_ca3-[9.5,10.3): 0.5011 - val_ca3-[10.3,11.3): 0.6639 - val_ca3-[11.3,14.9): 0.8805 - val_ca4-[8.0,9.5): 1.5114 - val_ca4-[9.5,10.3): 1.0654 - val_ca4-[10.3,11.3): 0.9197 - val_ca4-[11.3,14.9): 0.6976\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5213 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3581 - ca2-[9.5,10.3): 0.4480 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4832 - ca3-[10.3,11.3): 0.6327 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5528 - ca4-[11.3,14.9): 0.6655 - val_ca1-[8.0,9.5): 0.5777 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9289 - val_ca1-[11.3,14.9): 1.5781 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.3873 - val_ca2-[10.3,11.3): 0.7995 - val_ca2-[11.3,14.9): 1.3315 - val_ca3-[8.0,9.5): 0.8337 - val_ca3-[9.5,10.3): 0.5043 - val_ca3-[10.3,11.3): 0.6628 - val_ca3-[11.3,14.9): 0.8305 - val_ca4-[8.0,9.5): 1.5126 - val_ca4-[9.5,10.3): 1.0659 - val_ca4-[10.3,11.3): 0.9203 - val_ca4-[11.3,14.9): 0.6761\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5167 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3529 - ca2-[9.5,10.3): 0.4645 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4802 - ca3-[10.3,11.3): 0.6539 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5123 - ca4-[11.3,14.9): 0.6657 - val_ca1-[8.0,9.5): 0.5774 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9317 - val_ca1-[11.3,14.9): 1.6228 - val_ca2-[8.0,9.5): 0.5821 - val_ca2-[9.5,10.3): 0.3883 - val_ca2-[10.3,11.3): 0.8113 - val_ca2-[11.3,14.9): 1.3970 - val_ca3-[8.0,9.5): 0.8227 - val_ca3-[9.5,10.3): 0.4970 - val_ca3-[10.3,11.3): 0.6639 - val_ca3-[11.3,14.9): 0.8690 - val_ca4-[8.0,9.5): 1.5108 - val_ca4-[9.5,10.3): 1.0638 - val_ca4-[10.3,11.3): 0.9214 - val_ca4-[11.3,14.9): 0.6926\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5191 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3420 - ca2-[9.5,10.3): 0.4544 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4844 - ca3-[10.3,11.3): 0.6340 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5800 - ca4-[11.3,14.9): 0.6666 - val_ca1-[8.0,9.5): 0.5774 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9258 - val_ca1-[11.3,14.9): 1.6089 - val_ca2-[8.0,9.5): 0.5835 - val_ca2-[9.5,10.3): 0.3876 - val_ca2-[10.3,11.3): 0.8044 - val_ca2-[11.3,14.9): 1.3764 - val_ca3-[8.0,9.5): 0.8299 - val_ca3-[9.5,10.3): 0.5025 - val_ca3-[10.3,11.3): 0.6566 - val_ca3-[11.3,14.9): 0.8415 - val_ca4-[8.0,9.5): 1.5113 - val_ca4-[9.5,10.3): 1.0636 - val_ca4-[10.3,11.3): 0.9053 - val_ca4-[11.3,14.9): 0.6562\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5147 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3628 - ca2-[9.5,10.3): 0.4537 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4988 - ca3-[10.3,11.3): 0.6437 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5383 - ca4-[11.3,14.9): 0.6857 - val_ca1-[8.0,9.5): 0.5773 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9210 - val_ca1-[11.3,14.9): 1.6027 - val_ca2-[8.0,9.5): 0.5903 - val_ca2-[9.5,10.3): 0.3860 - val_ca2-[10.3,11.3): 0.7771 - val_ca2-[11.3,14.9): 1.3222 - val_ca3-[8.0,9.5): 0.8259 - val_ca3-[9.5,10.3): 0.5005 - val_ca3-[10.3,11.3): 0.6481 - val_ca3-[11.3,14.9): 0.8391 - val_ca4-[8.0,9.5): 1.5158 - val_ca4-[9.5,10.3): 1.0671 - val_ca4-[10.3,11.3): 0.9023 - val_ca4-[11.3,14.9): 0.6680\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5161 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3622 - ca2-[9.5,10.3): 0.4635 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4838 - ca3-[10.3,11.3): 0.6177 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5490 - ca4-[11.3,14.9): 0.6733 - val_ca1-[8.0,9.5): 0.5771 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9233 - val_ca1-[11.3,14.9): 1.6208 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.3863 - val_ca2-[10.3,11.3): 0.7888 - val_ca2-[11.3,14.9): 1.3573 - val_ca3-[8.0,9.5): 0.8169 - val_ca3-[9.5,10.3): 0.4937 - val_ca3-[10.3,11.3): 0.6590 - val_ca3-[11.3,14.9): 0.8696 - val_ca4-[8.0,9.5): 1.5135 - val_ca4-[9.5,10.3): 1.0644 - val_ca4-[10.3,11.3): 0.9175 - val_ca4-[11.3,14.9): 0.6929\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5112 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3544 - ca2-[9.5,10.3): 0.4543 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5015 - ca3-[10.3,11.3): 0.6354 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4813 - ca4-[11.3,14.9): 0.6559 - val_ca1-[8.0,9.5): 0.5770 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9199 - val_ca1-[11.3,14.9): 1.6302 - val_ca2-[8.0,9.5): 0.5819 - val_ca2-[9.5,10.3): 0.3879 - val_ca2-[10.3,11.3): 0.8025 - val_ca2-[11.3,14.9): 1.3990 - val_ca3-[8.0,9.5): 0.8353 - val_ca3-[9.5,10.3): 0.5042 - val_ca3-[10.3,11.3): 0.6536 - val_ca3-[11.3,14.9): 0.8462 - val_ca4-[8.0,9.5): 1.5091 - val_ca4-[9.5,10.3): 1.0597 - val_ca4-[10.3,11.3): 0.9014 - val_ca4-[11.3,14.9): 0.6668\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5091 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3518 - ca2-[9.5,10.3): 0.4596 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4669 - ca3-[10.3,11.3): 0.6353 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5488 - ca4-[11.3,14.9): 0.6728 - val_ca1-[8.0,9.5): 0.5766 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9330 - val_ca1-[11.3,14.9): 1.6253 - val_ca2-[8.0,9.5): 0.5840 - val_ca2-[9.5,10.3): 0.3872 - val_ca2-[10.3,11.3): 0.8038 - val_ca2-[11.3,14.9): 1.3774 - val_ca3-[8.0,9.5): 0.8116 - val_ca3-[9.5,10.3): 0.4892 - val_ca3-[10.3,11.3): 0.6621 - val_ca3-[11.3,14.9): 0.8738 - val_ca4-[8.0,9.5): 1.5102 - val_ca4-[9.5,10.3): 1.0601 - val_ca4-[10.3,11.3): 0.9173 - val_ca4-[11.3,14.9): 0.6954\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.4966 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3436 - ca2-[9.5,10.3): 0.4502 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4930 - ca3-[10.3,11.3): 0.6450 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5318 - ca4-[11.3,14.9): 0.6756 - val_ca1-[8.0,9.5): 0.5765 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9205 - val_ca1-[11.3,14.9): 1.6226 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.3865 - val_ca2-[10.3,11.3): 0.7818 - val_ca2-[11.3,14.9): 1.3603 - val_ca3-[8.0,9.5): 0.8253 - val_ca3-[9.5,10.3): 0.4981 - val_ca3-[10.3,11.3): 0.6454 - val_ca3-[11.3,14.9): 0.8639 - val_ca4-[8.0,9.5): 1.5127 - val_ca4-[9.5,10.3): 1.0618 - val_ca4-[10.3,11.3): 0.8994 - val_ca4-[11.3,14.9): 0.6889\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 1s 114ms/step - ca1-[8.0,9.5): 0.5169 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3545 - ca2-[9.5,10.3): 0.4626 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5016 - ca3-[10.3,11.3): 0.6519 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5305 - ca4-[11.3,14.9): 0.6764 - val_ca1-[8.0,9.5): 0.5763 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9251 - val_ca1-[11.3,14.9): 1.5904 - val_ca2-[8.0,9.5): 0.5837 - val_ca2-[9.5,10.3): 0.3876 - val_ca2-[10.3,11.3): 0.7995 - val_ca2-[11.3,14.9): 1.3422 - val_ca3-[8.0,9.5): 0.8095 - val_ca3-[9.5,10.3): 0.4893 - val_ca3-[10.3,11.3): 0.6575 - val_ca3-[11.3,14.9): 0.8430 - val_ca4-[8.0,9.5): 1.5145 - val_ca4-[9.5,10.3): 1.0630 - val_ca4-[10.3,11.3): 0.9150 - val_ca4-[11.3,14.9): 0.6792\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.5029 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3525 - ca2-[9.5,10.3): 0.4476 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4664 - ca3-[10.3,11.3): 0.6384 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5599 - ca4-[11.3,14.9): 0.6794 - val_ca1-[8.0,9.5): 0.5760 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9259 - val_ca1-[11.3,14.9): 1.6008 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3867 - val_ca2-[10.3,11.3): 0.7923 - val_ca2-[11.3,14.9): 1.3463 - val_ca3-[8.0,9.5): 0.8164 - val_ca3-[9.5,10.3): 0.4939 - val_ca3-[10.3,11.3): 0.6571 - val_ca3-[11.3,14.9): 0.8526 - val_ca4-[8.0,9.5): 1.5131 - val_ca4-[9.5,10.3): 1.0607 - val_ca4-[10.3,11.3): 0.9133 - val_ca4-[11.3,14.9): 0.6816\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5169 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3549 - ca2-[9.5,10.3): 0.4646 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4907 - ca3-[10.3,11.3): 0.6254 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5275 - ca4-[11.3,14.9): 0.6800 - val_ca1-[8.0,9.5): 0.5758 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9238 - val_ca1-[11.3,14.9): 1.6065 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.3865 - val_ca2-[10.3,11.3): 0.7914 - val_ca2-[11.3,14.9): 1.3465 - val_ca3-[8.0,9.5): 0.8249 - val_ca3-[9.5,10.3): 0.4993 - val_ca3-[10.3,11.3): 0.6589 - val_ca3-[11.3,14.9): 0.8425 - val_ca4-[8.0,9.5): 1.5141 - val_ca4-[9.5,10.3): 1.0612 - val_ca4-[10.3,11.3): 0.9175 - val_ca4-[11.3,14.9): 0.6839\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5146 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3551 - ca2-[9.5,10.3): 0.4438 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4993 - ca3-[10.3,11.3): 0.6371 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5513 - ca4-[11.3,14.9): 0.6813 - val_ca1-[8.0,9.5): 0.5754 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9304 - val_ca1-[11.3,14.9): 1.6289 - val_ca2-[8.0,9.5): 0.5808 - val_ca2-[9.5,10.3): 0.3881 - val_ca2-[10.3,11.3): 0.8076 - val_ca2-[11.3,14.9): 1.3932 - val_ca3-[8.0,9.5): 0.8106 - val_ca3-[9.5,10.3): 0.4902 - val_ca3-[10.3,11.3): 0.6566 - val_ca3-[11.3,14.9): 0.8574 - val_ca4-[8.0,9.5): 1.5115 - val_ca4-[9.5,10.3): 1.0583 - val_ca4-[10.3,11.3): 0.9094 - val_ca4-[11.3,14.9): 0.6773\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5145 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3632 - ca2-[9.5,10.3): 0.4488 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5069 - ca3-[10.3,11.3): 0.6432 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5486 - ca4-[11.3,14.9): 0.6756 - val_ca1-[8.0,9.5): 0.5752 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9347 - val_ca1-[11.3,14.9): 1.6327 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3864 - val_ca2-[10.3,11.3): 0.7946 - val_ca2-[11.3,14.9): 1.3621 - val_ca3-[8.0,9.5): 0.8125 - val_ca3-[9.5,10.3): 0.4920 - val_ca3-[10.3,11.3): 0.6580 - val_ca3-[11.3,14.9): 0.8631 - val_ca4-[8.0,9.5): 1.5127 - val_ca4-[9.5,10.3): 1.0587 - val_ca4-[10.3,11.3): 0.9114 - val_ca4-[11.3,14.9): 0.6777\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5116 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3619 - ca2-[9.5,10.3): 0.4504 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5072 - ca3-[10.3,11.3): 0.6350 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5475 - ca4-[11.3,14.9): 0.6727 - val_ca1-[8.0,9.5): 0.5749 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9289 - val_ca1-[11.3,14.9): 1.6503 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3864 - val_ca2-[10.3,11.3): 0.7905 - val_ca2-[11.3,14.9): 1.3773 - val_ca3-[8.0,9.5): 0.8007 - val_ca3-[9.5,10.3): 0.4838 - val_ca3-[10.3,11.3): 0.6535 - val_ca3-[11.3,14.9): 0.8778 - val_ca4-[8.0,9.5): 1.5119 - val_ca4-[9.5,10.3): 1.0574 - val_ca4-[10.3,11.3): 0.9097 - val_ca4-[11.3,14.9): 0.6817\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5071 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3558 - ca2-[9.5,10.3): 0.4447 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4844 - ca3-[10.3,11.3): 0.6429 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5285 - ca4-[11.3,14.9): 0.6727 - val_ca1-[8.0,9.5): 0.5746 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9330 - val_ca1-[11.3,14.9): 1.6243 - val_ca2-[8.0,9.5): 0.5843 - val_ca2-[9.5,10.3): 0.3869 - val_ca2-[10.3,11.3): 0.7990 - val_ca2-[11.3,14.9): 1.3626 - val_ca3-[8.0,9.5): 0.8059 - val_ca3-[9.5,10.3): 0.4875 - val_ca3-[10.3,11.3): 0.6520 - val_ca3-[11.3,14.9): 0.8580 - val_ca4-[8.0,9.5): 1.5092 - val_ca4-[9.5,10.3): 1.0544 - val_ca4-[10.3,11.3): 0.8957 - val_ca4-[11.3,14.9): 0.6715\n",
      "Epoch 273/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5146 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3455 - ca2-[9.5,10.3): 0.4476 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4760 - ca3-[10.3,11.3): 0.6547 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5653 - ca4-[11.3,14.9): 0.6717 - val_ca1-[8.0,9.5): 0.5743 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9315 - val_ca1-[11.3,14.9): 1.6355 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3865 - val_ca2-[10.3,11.3): 0.7930 - val_ca2-[11.3,14.9): 1.3644 - val_ca3-[8.0,9.5): 0.8094 - val_ca3-[9.5,10.3): 0.4896 - val_ca3-[10.3,11.3): 0.6569 - val_ca3-[11.3,14.9): 0.8694 - val_ca4-[8.0,9.5): 1.5161 - val_ca4-[9.5,10.3): 1.0602 - val_ca4-[10.3,11.3): 0.9129 - val_ca4-[11.3,14.9): 0.6935\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5136 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3523 - ca2-[9.5,10.3): 0.4485 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4678 - ca3-[10.3,11.3): 0.6400 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4953 - ca4-[11.3,14.9): 0.6689 - val_ca1-[8.0,9.5): 0.5741 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9342 - val_ca1-[11.3,14.9): 1.6374 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3861 - val_ca2-[10.3,11.3): 0.7903 - val_ca2-[11.3,14.9): 1.3552 - val_ca3-[8.0,9.5): 0.8182 - val_ca3-[9.5,10.3): 0.4952 - val_ca3-[10.3,11.3): 0.6543 - val_ca3-[11.3,14.9): 0.8474 - val_ca4-[8.0,9.5): 1.5191 - val_ca4-[9.5,10.3): 1.0621 - val_ca4-[10.3,11.3): 0.9092 - val_ca4-[11.3,14.9): 0.6766\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5046 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3601 - ca2-[9.5,10.3): 0.4516 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4574 - ca3-[10.3,11.3): 0.6371 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5226 - ca4-[11.3,14.9): 0.6644 - val_ca1-[8.0,9.5): 0.5736 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9357 - val_ca1-[11.3,14.9): 1.6518 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3865 - val_ca2-[10.3,11.3): 0.7948 - val_ca2-[11.3,14.9): 1.3684 - val_ca3-[8.0,9.5): 0.7770 - val_ca3-[9.5,10.3): 0.4700 - val_ca3-[10.3,11.3): 0.6579 - val_ca3-[11.3,14.9): 0.8893 - val_ca4-[8.0,9.5): 1.5187 - val_ca4-[9.5,10.3): 1.0613 - val_ca4-[10.3,11.3): 0.9147 - val_ca4-[11.3,14.9): 0.6786\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.4987 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3596 - ca2-[9.5,10.3): 0.4408 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4774 - ca3-[10.3,11.3): 0.6311 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5127 - ca4-[11.3,14.9): 0.6602 - val_ca1-[8.0,9.5): 0.5735 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9347 - val_ca1-[11.3,14.9): 1.6421 - val_ca2-[8.0,9.5): 0.5853 - val_ca2-[9.5,10.3): 0.3863 - val_ca2-[10.3,11.3): 0.7883 - val_ca2-[11.3,14.9): 1.3604 - val_ca3-[8.0,9.5): 0.8214 - val_ca3-[9.5,10.3): 0.4987 - val_ca3-[10.3,11.3): 0.6541 - val_ca3-[11.3,14.9): 0.8478 - val_ca4-[8.0,9.5): 1.5147 - val_ca4-[9.5,10.3): 1.0564 - val_ca4-[10.3,11.3): 0.9099 - val_ca4-[11.3,14.9): 0.6881\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.5193 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3663 - ca2-[9.5,10.3): 0.4482 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4805 - ca3-[10.3,11.3): 0.6284 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5343 - ca4-[11.3,14.9): 0.6671 - val_ca1-[8.0,9.5): 0.5731 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9376 - val_ca1-[11.3,14.9): 1.6222 - val_ca2-[8.0,9.5): 0.5843 - val_ca2-[9.5,10.3): 0.3866 - val_ca2-[10.3,11.3): 0.7969 - val_ca2-[11.3,14.9): 1.3466 - val_ca3-[8.0,9.5): 0.7865 - val_ca3-[9.5,10.3): 0.4768 - val_ca3-[10.3,11.3): 0.6527 - val_ca3-[11.3,14.9): 0.8528 - val_ca4-[8.0,9.5): 1.5200 - val_ca4-[9.5,10.3): 1.0607 - val_ca4-[10.3,11.3): 0.9069 - val_ca4-[11.3,14.9): 0.6645\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5213 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3517 - ca2-[9.5,10.3): 0.4513 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4870 - ca3-[10.3,11.3): 0.6393 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5173 - ca4-[11.3,14.9): 0.6694 - val_ca1-[8.0,9.5): 0.5728 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9310 - val_ca1-[11.3,14.9): 1.6319 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3863 - val_ca2-[10.3,11.3): 0.7903 - val_ca2-[11.3,14.9): 1.3530 - val_ca3-[8.0,9.5): 0.7957 - val_ca3-[9.5,10.3): 0.4823 - val_ca3-[10.3,11.3): 0.6542 - val_ca3-[11.3,14.9): 0.8645 - val_ca4-[8.0,9.5): 1.5205 - val_ca4-[9.5,10.3): 1.0603 - val_ca4-[10.3,11.3): 0.9119 - val_ca4-[11.3,14.9): 0.6883\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.4935 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3476 - ca2-[9.5,10.3): 0.4494 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4732 - ca3-[10.3,11.3): 0.6331 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5369 - ca4-[11.3,14.9): 0.6699 - val_ca1-[8.0,9.5): 0.5726 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9404 - val_ca1-[11.3,14.9): 1.6610 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.3862 - val_ca2-[10.3,11.3): 0.7932 - val_ca2-[11.3,14.9): 1.3758 - val_ca3-[8.0,9.5): 0.8029 - val_ca3-[9.5,10.3): 0.4863 - val_ca3-[10.3,11.3): 0.6541 - val_ca3-[11.3,14.9): 0.8733 - val_ca4-[8.0,9.5): 1.5187 - val_ca4-[9.5,10.3): 1.0574 - val_ca4-[10.3,11.3): 0.9059 - val_ca4-[11.3,14.9): 0.6911\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.4969 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3559 - ca2-[9.5,10.3): 0.4432 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4960 - ca3-[10.3,11.3): 0.6191 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5069 - ca4-[11.3,14.9): 0.6637 - val_ca1-[8.0,9.5): 0.5721 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9239 - val_ca1-[11.3,14.9): 1.5893 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3859 - val_ca2-[10.3,11.3): 0.7713 - val_ca2-[11.3,14.9): 1.3025 - val_ca3-[8.0,9.5): 0.7949 - val_ca3-[9.5,10.3): 0.4811 - val_ca3-[10.3,11.3): 0.6424 - val_ca3-[11.3,14.9): 0.8202 - val_ca4-[8.0,9.5): 1.5192 - val_ca4-[9.5,10.3): 1.0569 - val_ca4-[10.3,11.3): 0.9005 - val_ca4-[11.3,14.9): 0.6374\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.4924 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3624 - ca2-[9.5,10.3): 0.4547 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4761 - ca3-[10.3,11.3): 0.6202 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5724 - ca4-[11.3,14.9): 0.6671 - val_ca1-[8.0,9.5): 0.5718 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9393 - val_ca1-[11.3,14.9): 1.6468 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.3852 - val_ca2-[10.3,11.3): 0.7874 - val_ca2-[11.3,14.9): 1.3500 - val_ca3-[8.0,9.5): 0.7985 - val_ca3-[9.5,10.3): 0.4839 - val_ca3-[10.3,11.3): 0.6489 - val_ca3-[11.3,14.9): 0.8526 - val_ca4-[8.0,9.5): 1.5229 - val_ca4-[9.5,10.3): 1.0596 - val_ca4-[10.3,11.3): 0.8942 - val_ca4-[11.3,14.9): 0.6619\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5129 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3511 - ca2-[9.5,10.3): 0.4503 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4700 - ca3-[10.3,11.3): 0.6316 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5388 - ca4-[11.3,14.9): 0.6759 - val_ca1-[8.0,9.5): 0.5714 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9458 - val_ca1-[11.3,14.9): 1.6642 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3858 - val_ca2-[10.3,11.3): 0.7970 - val_ca2-[11.3,14.9): 1.3689 - val_ca3-[8.0,9.5): 0.7898 - val_ca3-[9.5,10.3): 0.4786 - val_ca3-[10.3,11.3): 0.6543 - val_ca3-[11.3,14.9): 0.8697 - val_ca4-[8.0,9.5): 1.5258 - val_ca4-[9.5,10.3): 1.0613 - val_ca4-[10.3,11.3): 0.9052 - val_ca4-[11.3,14.9): 0.6818\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5180 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3536 - ca2-[9.5,10.3): 0.4502 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4476 - ca3-[10.3,11.3): 0.6146 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5366 - ca4-[11.3,14.9): 0.6564 - val_ca1-[8.0,9.5): 0.5711 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9413 - val_ca1-[11.3,14.9): 1.6440 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3857 - val_ca2-[10.3,11.3): 0.7920 - val_ca2-[11.3,14.9): 1.3480 - val_ca3-[8.0,9.5): 0.8010 - val_ca3-[9.5,10.3): 0.4855 - val_ca3-[10.3,11.3): 0.6544 - val_ca3-[11.3,14.9): 0.8466 - val_ca4-[8.0,9.5): 1.5257 - val_ca4-[9.5,10.3): 1.0601 - val_ca4-[10.3,11.3): 0.9093 - val_ca4-[11.3,14.9): 0.6727\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5055 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3580 - ca2-[9.5,10.3): 0.4535 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4647 - ca3-[10.3,11.3): 0.6122 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5471 - ca4-[11.3,14.9): 0.6647 - val_ca1-[8.0,9.5): 0.5709 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9284 - val_ca1-[11.3,14.9): 1.6435 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3857 - val_ca2-[10.3,11.3): 0.7789 - val_ca2-[11.3,14.9): 1.3428 - val_ca3-[8.0,9.5): 0.7997 - val_ca3-[9.5,10.3): 0.4836 - val_ca3-[10.3,11.3): 0.6422 - val_ca3-[11.3,14.9): 0.8335 - val_ca4-[8.0,9.5): 1.5311 - val_ca4-[9.5,10.3): 1.0636 - val_ca4-[10.3,11.3): 0.8945 - val_ca4-[11.3,14.9): 0.6369\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5057 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3562 - ca2-[9.5,10.3): 0.4587 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4734 - ca3-[10.3,11.3): 0.6275 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5324 - ca4-[11.3,14.9): 0.6693 - val_ca1-[8.0,9.5): 0.5706 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9425 - val_ca1-[11.3,14.9): 1.5966 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.3852 - val_ca2-[10.3,11.3): 0.7821 - val_ca2-[11.3,14.9): 1.2905 - val_ca3-[8.0,9.5): 0.7955 - val_ca3-[9.5,10.3): 0.4805 - val_ca3-[10.3,11.3): 0.6494 - val_ca3-[11.3,14.9): 0.8247 - val_ca4-[8.0,9.5): 1.5340 - val_ca4-[9.5,10.3): 1.0649 - val_ca4-[10.3,11.3): 0.9045 - val_ca4-[11.3,14.9): 0.6574\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5133 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3537 - ca2-[9.5,10.3): 0.4578 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4738 - ca3-[10.3,11.3): 0.6267 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4877 - ca4-[11.3,14.9): 0.6579 - val_ca1-[8.0,9.5): 0.5701 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9452 - val_ca1-[11.3,14.9): 1.6430 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.3862 - val_ca2-[10.3,11.3): 0.7921 - val_ca2-[11.3,14.9): 1.3525 - val_ca3-[8.0,9.5): 0.8003 - val_ca3-[9.5,10.3): 0.4837 - val_ca3-[10.3,11.3): 0.6497 - val_ca3-[11.3,14.9): 0.8379 - val_ca4-[8.0,9.5): 1.5317 - val_ca4-[9.5,10.3): 1.0621 - val_ca4-[10.3,11.3): 0.9021 - val_ca4-[11.3,14.9): 0.6559\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5035 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3562 - ca2-[9.5,10.3): 0.4484 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4781 - ca3-[10.3,11.3): 0.6304 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5247 - ca4-[11.3,14.9): 0.6547 - val_ca1-[8.0,9.5): 0.5696 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9515 - val_ca1-[11.3,14.9): 1.6762 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3854 - val_ca2-[10.3,11.3): 0.7918 - val_ca2-[11.3,14.9): 1.3683 - val_ca3-[8.0,9.5): 0.7867 - val_ca3-[9.5,10.3): 0.4756 - val_ca3-[10.3,11.3): 0.6525 - val_ca3-[11.3,14.9): 0.8692 - val_ca4-[8.0,9.5): 1.5336 - val_ca4-[9.5,10.3): 1.0628 - val_ca4-[10.3,11.3): 0.9024 - val_ca4-[11.3,14.9): 0.6788\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 1s 111ms/step - ca1-[8.0,9.5): 0.4996 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3607 - ca2-[9.5,10.3): 0.4549 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4875 - ca3-[10.3,11.3): 0.6257 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5300 - ca4-[11.3,14.9): 0.6695 - val_ca1-[8.0,9.5): 0.5690 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9491 - val_ca1-[11.3,14.9): 1.6340 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3861 - val_ca2-[10.3,11.3): 0.7942 - val_ca2-[11.3,14.9): 1.3424 - val_ca3-[8.0,9.5): 0.7842 - val_ca3-[9.5,10.3): 0.4740 - val_ca3-[10.3,11.3): 0.6491 - val_ca3-[11.3,14.9): 0.8361 - val_ca4-[8.0,9.5): 1.5368 - val_ca4-[9.5,10.3): 1.0650 - val_ca4-[10.3,11.3): 0.9027 - val_ca4-[11.3,14.9): 0.6439\n",
      "Epoch 289/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.5109 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3621 - ca2-[9.5,10.3): 0.4639 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4868 - ca3-[10.3,11.3): 0.6095 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5246 - ca4-[11.3,14.9): 0.6555 - val_ca1-[8.0,9.5): 0.5692 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9532 - val_ca1-[11.3,14.9): 1.6738 - val_ca2-[8.0,9.5): 0.5840 - val_ca2-[9.5,10.3): 0.3874 - val_ca2-[10.3,11.3): 0.7981 - val_ca2-[11.3,14.9): 1.3815 - val_ca3-[8.0,9.5): 0.7872 - val_ca3-[9.5,10.3): 0.4761 - val_ca3-[10.3,11.3): 0.6504 - val_ca3-[11.3,14.9): 0.8636 - val_ca4-[8.0,9.5): 1.5421 - val_ca4-[9.5,10.3): 1.0683 - val_ca4-[10.3,11.3): 0.9046 - val_ca4-[11.3,14.9): 0.6716\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5028 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3545 - ca2-[9.5,10.3): 0.4460 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4546 - ca3-[10.3,11.3): 0.6094 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5199 - ca4-[11.3,14.9): 0.6520 - val_ca1-[8.0,9.5): 0.5680 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9548 - val_ca1-[11.3,14.9): 1.7001 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.3844 - val_ca2-[10.3,11.3): 0.7812 - val_ca2-[11.3,14.9): 1.3577 - val_ca3-[8.0,9.5): 0.7806 - val_ca3-[9.5,10.3): 0.4716 - val_ca3-[10.3,11.3): 0.6501 - val_ca3-[11.3,14.9): 0.8779 - val_ca4-[8.0,9.5): 1.5388 - val_ca4-[9.5,10.3): 1.0646 - val_ca4-[10.3,11.3): 0.9037 - val_ca4-[11.3,14.9): 0.6785\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.4997 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3505 - ca2-[9.5,10.3): 0.4561 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4622 - ca3-[10.3,11.3): 0.6145 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5299 - ca4-[11.3,14.9): 0.6492 - val_ca1-[8.0,9.5): 0.5676 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9553 - val_ca1-[11.3,14.9): 1.6341 - val_ca2-[8.0,9.5): 0.5838 - val_ca2-[9.5,10.3): 0.3855 - val_ca2-[10.3,11.3): 0.7928 - val_ca2-[11.3,14.9): 1.3322 - val_ca3-[8.0,9.5): 0.7860 - val_ca3-[9.5,10.3): 0.4747 - val_ca3-[10.3,11.3): 0.6499 - val_ca3-[11.3,14.9): 0.8334 - val_ca4-[8.0,9.5): 1.5343 - val_ca4-[9.5,10.3): 1.0597 - val_ca4-[10.3,11.3): 0.8995 - val_ca4-[11.3,14.9): 0.6594\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.4959 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3413 - ca2-[9.5,10.3): 0.4475 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4661 - ca3-[10.3,11.3): 0.6225 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5328 - ca4-[11.3,14.9): 0.6521 - val_ca1-[8.0,9.5): 0.5674 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9437 - val_ca1-[11.3,14.9): 1.5953 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.3845 - val_ca2-[10.3,11.3): 0.7747 - val_ca2-[11.3,14.9): 1.2701 - val_ca3-[8.0,9.5): 0.7858 - val_ca3-[9.5,10.3): 0.4750 - val_ca3-[10.3,11.3): 0.6471 - val_ca3-[11.3,14.9): 0.8100 - val_ca4-[8.0,9.5): 1.5456 - val_ca4-[9.5,10.3): 1.0691 - val_ca4-[10.3,11.3): 0.9064 - val_ca4-[11.3,14.9): 0.6431\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5012 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3456 - ca2-[9.5,10.3): 0.4417 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4911 - ca3-[10.3,11.3): 0.6112 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5235 - ca4-[11.3,14.9): 0.6504 - val_ca1-[8.0,9.5): 0.5669 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9460 - val_ca1-[11.3,14.9): 1.6462 - val_ca2-[8.0,9.5): 0.5837 - val_ca2-[9.5,10.3): 0.3854 - val_ca2-[10.3,11.3): 0.7853 - val_ca2-[11.3,14.9): 1.3439 - val_ca3-[8.0,9.5): 0.7678 - val_ca3-[9.5,10.3): 0.4635 - val_ca3-[10.3,11.3): 0.6448 - val_ca3-[11.3,14.9): 0.8578 - val_ca4-[8.0,9.5): 1.5461 - val_ca4-[9.5,10.3): 1.0680 - val_ca4-[10.3,11.3): 0.9049 - val_ca4-[11.3,14.9): 0.6663\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 1s 110ms/step - ca1-[8.0,9.5): 0.4944 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3476 - ca2-[9.5,10.3): 0.4418 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4702 - ca3-[10.3,11.3): 0.6314 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5108 - ca4-[11.3,14.9): 0.6687 - val_ca1-[8.0,9.5): 0.5664 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9564 - val_ca1-[11.3,14.9): 1.6750 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3847 - val_ca2-[10.3,11.3): 0.7849 - val_ca2-[11.3,14.9): 1.3307 - val_ca3-[8.0,9.5): 0.7679 - val_ca3-[9.5,10.3): 0.4641 - val_ca3-[10.3,11.3): 0.6461 - val_ca3-[11.3,14.9): 0.8483 - val_ca4-[8.0,9.5): 1.5399 - val_ca4-[9.5,10.3): 1.0606 - val_ca4-[10.3,11.3): 0.8961 - val_ca4-[11.3,14.9): 0.6565\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.5002 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3564 - ca2-[9.5,10.3): 0.4476 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4696 - ca3-[10.3,11.3): 0.6196 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5033 - ca4-[11.3,14.9): 0.6352 - val_ca1-[8.0,9.5): 0.5662 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9581 - val_ca1-[11.3,14.9): 1.7013 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.3837 - val_ca2-[10.3,11.3): 0.7796 - val_ca2-[11.3,14.9): 1.3485 - val_ca3-[8.0,9.5): 0.7989 - val_ca3-[9.5,10.3): 0.4846 - val_ca3-[10.3,11.3): 0.6488 - val_ca3-[11.3,14.9): 0.8436 - val_ca4-[8.0,9.5): 1.5423 - val_ca4-[9.5,10.3): 1.0617 - val_ca4-[10.3,11.3): 0.8980 - val_ca4-[11.3,14.9): 0.6642\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 1s 112ms/step - ca1-[8.0,9.5): 0.4967 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3492 - ca2-[9.5,10.3): 0.4378 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4794 - ca3-[10.3,11.3): 0.6187 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4977 - ca4-[11.3,14.9): 0.6548 - val_ca1-[8.0,9.5): 0.5653 - val_ca1-[9.5,10.3): 0.4226 - val_ca1-[10.3,11.3): 0.9585 - val_ca1-[11.3,14.9): 1.7049 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.3836 - val_ca2-[10.3,11.3): 0.7809 - val_ca2-[11.3,14.9): 1.3499 - val_ca3-[8.0,9.5): 0.7586 - val_ca3-[9.5,10.3): 0.4593 - val_ca3-[10.3,11.3): 0.6409 - val_ca3-[11.3,14.9): 0.8661 - val_ca4-[8.0,9.5): 1.5566 - val_ca4-[9.5,10.3): 1.0752 - val_ca4-[10.3,11.3): 0.8922 - val_ca4-[11.3,14.9): 0.6331\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 1s 108ms/step - ca1-[8.0,9.5): 0.4970 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3544 - ca2-[9.5,10.3): 0.4362 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4562 - ca3-[10.3,11.3): 0.6087 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5115 - ca4-[11.3,14.9): 0.6490 - val_ca1-[8.0,9.5): 0.5649 - val_ca1-[9.5,10.3): 0.4228 - val_ca1-[10.3,11.3): 0.9628 - val_ca1-[11.3,14.9): 1.6929 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3841 - val_ca2-[10.3,11.3): 0.7867 - val_ca2-[11.3,14.9): 1.3536 - val_ca3-[8.0,9.5): 0.7925 - val_ca3-[9.5,10.3): 0.4818 - val_ca3-[10.3,11.3): 0.6455 - val_ca3-[11.3,14.9): 0.8321 - val_ca4-[8.0,9.5): 1.5458 - val_ca4-[9.5,10.3): 1.0637 - val_ca4-[10.3,11.3): 0.8955 - val_ca4-[11.3,14.9): 0.6506\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.4874 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3440 - ca2-[9.5,10.3): 0.4453 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4639 - ca3-[10.3,11.3): 0.6245 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5506 - ca4-[11.3,14.9): 0.6567 - val_ca1-[8.0,9.5): 0.5643 - val_ca1-[9.5,10.3): 0.4228 - val_ca1-[10.3,11.3): 0.9598 - val_ca1-[11.3,14.9): 1.7268 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3837 - val_ca2-[10.3,11.3): 0.7796 - val_ca2-[11.3,14.9): 1.3685 - val_ca3-[8.0,9.5): 0.7650 - val_ca3-[9.5,10.3): 0.4646 - val_ca3-[10.3,11.3): 0.6440 - val_ca3-[11.3,14.9): 0.8814 - val_ca4-[8.0,9.5): 1.5470 - val_ca4-[9.5,10.3): 1.0635 - val_ca4-[10.3,11.3): 0.8966 - val_ca4-[11.3,14.9): 0.6822\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5042 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3491 - ca2-[9.5,10.3): 0.4514 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4517 - ca3-[10.3,11.3): 0.6253 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5646 - ca4-[11.3,14.9): 0.6604 - val_ca1-[8.0,9.5): 0.5640 - val_ca1-[9.5,10.3): 0.4225 - val_ca1-[10.3,11.3): 0.9664 - val_ca1-[11.3,14.9): 1.6601 - val_ca2-[8.0,9.5): 0.5898 - val_ca2-[9.5,10.3): 0.3831 - val_ca2-[10.3,11.3): 0.7755 - val_ca2-[11.3,14.9): 1.2950 - val_ca3-[8.0,9.5): 0.7736 - val_ca3-[9.5,10.3): 0.4705 - val_ca3-[10.3,11.3): 0.6460 - val_ca3-[11.3,14.9): 0.8269 - val_ca4-[8.0,9.5): 1.5536 - val_ca4-[9.5,10.3): 1.0688 - val_ca4-[10.3,11.3): 0.8995 - val_ca4-[11.3,14.9): 0.6498\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 1s 109ms/step - ca1-[8.0,9.5): 0.5034 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3551 - ca2-[9.5,10.3): 0.4472 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4658 - ca3-[10.3,11.3): 0.6200 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5127 - ca4-[11.3,14.9): 0.6662 - val_ca1-[8.0,9.5): 0.5633 - val_ca1-[9.5,10.3): 0.4231 - val_ca1-[10.3,11.3): 0.9675 - val_ca1-[11.3,14.9): 1.6857 - val_ca2-[8.0,9.5): 0.5818 - val_ca2-[9.5,10.3): 0.3838 - val_ca2-[10.3,11.3): 0.7886 - val_ca2-[11.3,14.9): 1.3413 - val_ca3-[8.0,9.5): 0.7490 - val_ca3-[9.5,10.3): 0.4536 - val_ca3-[10.3,11.3): 0.6468 - val_ca3-[11.3,14.9): 0.8700 - val_ca4-[8.0,9.5): 1.5450 - val_ca4-[9.5,10.3): 1.0595 - val_ca4-[10.3,11.3): 0.8974 - val_ca4-[11.3,14.9): 0.6611\n",
      "CPU times: user 4min 53s, sys: 3.43 s, total: 4min 56s\n",
      "Wall time: 4min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('simple_add')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2})') for ca,(q1,q2) in product(range(4),zip(quants[:-1],quants[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "\n",
    "history = m.fit(\n",
    "    train_dataset,\n",
    "#     validation_split=0.2,\n",
    "    epochs=300,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "# with open(os.path.join(fp_local,'no_sharing.pickle'), 'wb') as handle:\n",
    "#     pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "for k in [k for k in history.history if 'val_ca1' in k]:\n",
    "    plt.plot(history.history[k][10:], label=k.split('-')[1])\n",
    "\n",
    "plt.plot(history.history['ca1-[8.0,9.5)'][10:],label='train')\n",
    "\n",
    "plt.legend()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k in [k for k in history.history if 'val' not in k and 'ca1' in k]:\n",
    "    plt.plot(history.history[k][10:], label=k.split('-')[1])\n",
    "        \n",
    "plt.legend()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ca1-[8.0,9.5)</th>\n",
       "      <td>0.509308</td>\n",
       "      <td>0.563342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[9.5,10.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.423059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[10.3,11.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.967541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.685692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[8.0,9.5)</th>\n",
       "      <td>0.351837</td>\n",
       "      <td>0.581817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[9.5,10.3)</th>\n",
       "      <td>0.436321</td>\n",
       "      <td>0.383779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[10.3,11.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.788647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.341298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[8.0,9.5)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.749019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[9.5,10.3)</th>\n",
       "      <td>0.51047</td>\n",
       "      <td>0.453644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[10.3,11.3)</th>\n",
       "      <td>0.604297</td>\n",
       "      <td>0.646764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.869974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[8.0,9.5)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[9.5,10.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.059486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[10.3,11.3)</th>\n",
       "      <td>0.520998</td>\n",
       "      <td>0.897389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[11.3,14.9)</th>\n",
       "      <td>0.674339</td>\n",
       "      <td>0.661148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train      test\n",
       "ca1-[8.0,9.5)    0.509308  0.563342\n",
       "ca1-[9.5,10.3)          -  0.423059\n",
       "ca1-[10.3,11.3)         -  0.967541\n",
       "ca1-[11.3,14.9)         -  1.685692\n",
       "ca2-[8.0,9.5)    0.351837  0.581817\n",
       "ca2-[9.5,10.3)   0.436321  0.383779\n",
       "ca2-[10.3,11.3)         -  0.788647\n",
       "ca2-[11.3,14.9)         -  1.341298\n",
       "ca3-[8.0,9.5)           -  0.749019\n",
       "ca3-[9.5,10.3)    0.51047  0.453644\n",
       "ca3-[10.3,11.3)  0.604297  0.646764\n",
       "ca3-[11.3,14.9)         -  0.869974\n",
       "ca4-[8.0,9.5)           -  1.545000\n",
       "ca4-[9.5,10.3)          -  1.059486\n",
       "ca4-[10.3,11.3)  0.520998  0.897389\n",
       "ca4-[11.3,14.9)  0.674339  0.661148"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data=[[history.history[k][-1] if history.history[k][-1]!=0 else '-',history.history['val_'+k][-1]] for k in history.history if 'val' not in k],\n",
    "    index=[k for k in history.history if 'val' not in k],\n",
    "    columns=['train','test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 35.1123 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 25.0163 - ca2-[9.5,10.3): 26.0136 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 26.6120 - ca3-[10.3,11.3): 29.7198 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 33.9841 - ca4-[11.3,14.9): 36.5683 - val_ca1-[8.0,9.5): 31.5935 - val_ca1-[9.5,10.3): 33.0565 - val_ca1-[10.3,11.3): 37.4844 - val_ca1-[11.3,14.9): 43.8105 - val_ca2-[8.0,9.5): 22.6139 - val_ca2-[9.5,10.3): 23.7827 - val_ca2-[10.3,11.3): 27.6040 - val_ca2-[11.3,14.9): 33.0506 - val_ca3-[8.0,9.5): 21.5493 - val_ca3-[9.5,10.3): 22.7013 - val_ca3-[10.3,11.3): 26.4467 - val_ca3-[11.3,14.9): 31.7575 - val_ca4-[8.0,9.5): 23.0323 - val_ca4-[9.5,10.3): 24.2380 - val_ca4-[10.3,11.3): 28.0444 - val_ca4-[11.3,14.9): 33.4818\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 1s 153ms/step - ca1-[8.0,9.5): 31.1776 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 21.7733 - ca2-[9.5,10.3): 22.7621 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 23.1198 - ca3-[10.3,11.3): 25.7265 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 29.4482 - ca4-[11.3,14.9): 32.4347 - val_ca1-[8.0,9.5): 27.8576 - val_ca1-[9.5,10.3): 29.2098 - val_ca1-[10.3,11.3): 33.2726 - val_ca1-[11.3,14.9): 39.4272 - val_ca2-[8.0,9.5): 19.7096 - val_ca2-[9.5,10.3): 20.7931 - val_ca2-[10.3,11.3): 24.2785 - val_ca2-[11.3,14.9): 29.5436 - val_ca3-[8.0,9.5): 18.1326 - val_ca3-[9.5,10.3): 19.1858 - val_ca3-[10.3,11.3): 22.5632 - val_ca3-[11.3,14.9): 27.6207 - val_ca4-[8.0,9.5): 19.9747 - val_ca4-[9.5,10.3): 21.0668 - val_ca4-[10.3,11.3): 24.5281 - val_ca4-[11.3,14.9): 29.7708\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 27.5578 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 18.8777 - ca2-[9.5,10.3): 19.8079 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 19.6818 - ca3-[10.3,11.3): 22.0109 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 26.0838 - ca4-[11.3,14.9): 28.8219 - val_ca1-[8.0,9.5): 24.5025 - val_ca1-[9.5,10.3): 25.7633 - val_ca1-[10.3,11.3): 29.7119 - val_ca1-[11.3,14.9): 35.5435 - val_ca2-[8.0,9.5): 17.0932 - val_ca2-[9.5,10.3): 18.1059 - val_ca2-[10.3,11.3): 21.4638 - val_ca2-[11.3,14.9): 26.4207 - val_ca3-[8.0,9.5): 15.0913 - val_ca3-[9.5,10.3): 16.0492 - val_ca3-[10.3,11.3): 19.2495 - val_ca3-[11.3,14.9): 23.9318 - val_ca4-[8.0,9.5): 17.3974 - val_ca4-[9.5,10.3): 18.3976 - val_ca4-[10.3,11.3): 21.7498 - val_ca4-[11.3,14.9): 26.7018\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 24.2374 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 16.5358 - ca2-[9.5,10.3): 17.3135 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 16.2057 - ca3-[10.3,11.3): 18.6462 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 23.4418 - ca4-[11.3,14.9): 25.9330 - val_ca1-[8.0,9.5): 21.6320 - val_ca1-[9.5,10.3): 22.8049 - val_ca1-[10.3,11.3): 26.6081 - val_ca1-[11.3,14.9): 32.1059 - val_ca2-[8.0,9.5): 14.7568 - val_ca2-[9.5,10.3): 15.6988 - val_ca2-[10.3,11.3): 18.9099 - val_ca2-[11.3,14.9): 23.5486 - val_ca3-[8.0,9.5): 12.4417 - val_ca3-[9.5,10.3): 13.3106 - val_ca3-[10.3,11.3): 16.3259 - val_ca3-[11.3,14.9): 20.6429 - val_ca4-[8.0,9.5): 15.2665 - val_ca4-[9.5,10.3): 16.1846 - val_ca4-[10.3,11.3): 19.4136 - val_ca4-[11.3,14.9): 24.0876\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 21.4996 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 14.1720 - ca2-[9.5,10.3): 14.8951 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 13.5260 - ca3-[10.3,11.3): 15.7176 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 21.2897 - ca4-[11.3,14.9): 23.3300 - val_ca1-[8.0,9.5): 19.1847 - val_ca1-[9.5,10.3): 20.2662 - val_ca1-[10.3,11.3): 23.8159 - val_ca1-[11.3,14.9): 28.7684 - val_ca2-[8.0,9.5): 12.7165 - val_ca2-[9.5,10.3): 13.5847 - val_ca2-[10.3,11.3): 16.5576 - val_ca2-[11.3,14.9): 20.6909 - val_ca3-[8.0,9.5): 10.2005 - val_ca3-[9.5,10.3): 10.9627 - val_ca3-[10.3,11.3): 13.6967 - val_ca3-[11.3,14.9): 17.4653 - val_ca4-[8.0,9.5): 13.4596 - val_ca4-[9.5,10.3): 14.2994 - val_ca4-[10.3,11.3): 17.3076 - val_ca4-[11.3,14.9): 21.5135\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 19.0414 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 12.0876 - ca2-[9.5,10.3): 12.9221 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 11.2958 - ca3-[10.3,11.3): 13.2561 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 19.1989 - ca4-[11.3,14.9): 21.0162 - val_ca1-[8.0,9.5): 17.0692 - val_ca1-[9.5,10.3): 18.0627 - val_ca1-[10.3,11.3): 21.3982 - val_ca1-[11.3,14.9): 26.1162 - val_ca2-[8.0,9.5): 10.9711 - val_ca2-[9.5,10.3): 11.7642 - val_ca2-[10.3,11.3): 14.5301 - val_ca2-[11.3,14.9): 18.4268 - val_ca3-[8.0,9.5): 8.3984 - val_ca3-[9.5,10.3): 9.0607 - val_ca3-[10.3,11.3): 11.5316 - val_ca3-[11.3,14.9): 14.9966 - val_ca4-[8.0,9.5): 11.8599 - val_ca4-[9.5,10.3): 12.6411 - val_ca4-[10.3,11.3): 15.4568 - val_ca4-[11.3,14.9): 19.4639\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 16.9665 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 10.5970 - ca2-[9.5,10.3): 11.2273 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 9.2292 - ca3-[10.3,11.3): 11.2708 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 17.2101 - ca4-[11.3,14.9): 18.9982 - val_ca1-[8.0,9.5): 15.2750 - val_ca1-[9.5,10.3): 16.2119 - val_ca1-[10.3,11.3): 19.4182 - val_ca1-[11.3,14.9): 23.9005 - val_ca2-[8.0,9.5): 9.5120 - val_ca2-[9.5,10.3): 10.2331 - val_ca2-[10.3,11.3): 12.8539 - val_ca2-[11.3,14.9): 16.5050 - val_ca3-[8.0,9.5): 6.9626 - val_ca3-[9.5,10.3): 7.5448 - val_ca3-[10.3,11.3): 9.8444 - val_ca3-[11.3,14.9): 13.0376 - val_ca4-[8.0,9.5): 10.4507 - val_ca4-[9.5,10.3): 11.1861 - val_ca4-[10.3,11.3): 13.8862 - val_ca4-[11.3,14.9): 17.6819\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 15.2805 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 9.1543 - ca2-[9.5,10.3): 9.8522 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 7.8681 - ca3-[10.3,11.3): 9.5202 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 15.5349 - ca4-[11.3,14.9): 17.2392 - val_ca1-[8.0,9.5): 13.7956 - val_ca1-[9.5,10.3): 14.6842 - val_ca1-[10.3,11.3): 17.7854 - val_ca1-[11.3,14.9): 22.2266 - val_ca2-[8.0,9.5): 8.2929 - val_ca2-[9.5,10.3): 8.9513 - val_ca2-[10.3,11.3): 11.4457 - val_ca2-[11.3,14.9): 15.0139 - val_ca3-[8.0,9.5): 5.8118 - val_ca3-[9.5,10.3): 6.3260 - val_ca3-[10.3,11.3): 8.4792 - val_ca3-[11.3,14.9): 11.5477 - val_ca4-[8.0,9.5): 9.2627 - val_ca4-[9.5,10.3): 9.9524 - val_ca4-[10.3,11.3): 12.5504 - val_ca4-[11.3,14.9): 16.2872\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 1s 150ms/step - ca1-[8.0,9.5): 13.7535 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 7.9808 - ca2-[9.5,10.3): 8.6186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 6.7979 - ca3-[10.3,11.3): 8.2507 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 14.1647 - ca4-[11.3,14.9): 15.7672 - val_ca1-[8.0,9.5): 12.5473 - val_ca1-[9.5,10.3): 13.3953 - val_ca1-[10.3,11.3): 16.3033 - val_ca1-[11.3,14.9): 20.6629 - val_ca2-[8.0,9.5): 7.2633 - val_ca2-[9.5,10.3): 7.8647 - val_ca2-[10.3,11.3): 10.1625 - val_ca2-[11.3,14.9): 13.6105 - val_ca3-[8.0,9.5): 4.8804 - val_ca3-[9.5,10.3): 5.3291 - val_ca3-[10.3,11.3): 7.2726 - val_ca3-[11.3,14.9): 10.1854 - val_ca4-[8.0,9.5): 8.2412 - val_ca4-[9.5,10.3): 8.8901 - val_ca4-[10.3,11.3): 11.3036 - val_ca4-[11.3,14.9): 14.9386\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 12.5288 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 6.9741 - ca2-[9.5,10.3): 7.5220 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 5.5812 - ca3-[10.3,11.3): 7.0655 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 12.6786 - ca4-[11.3,14.9): 14.5147 - val_ca1-[8.0,9.5): 11.5089 - val_ca1-[9.5,10.3): 12.3165 - val_ca1-[10.3,11.3): 15.1677 - val_ca1-[11.3,14.9): 19.1870 - val_ca2-[8.0,9.5): 6.3852 - val_ca2-[9.5,10.3): 6.9383 - val_ca2-[10.3,11.3): 9.1576 - val_ca2-[11.3,14.9): 12.2732 - val_ca3-[8.0,9.5): 4.1024 - val_ca3-[9.5,10.3): 4.4951 - val_ca3-[10.3,11.3): 6.3374 - val_ca3-[11.3,14.9): 8.9142 - val_ca4-[8.0,9.5): 7.3628 - val_ca4-[9.5,10.3): 7.9719 - val_ca4-[10.3,11.3): 10.3200 - val_ca4-[11.3,14.9): 13.6284\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 11.5990 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 6.0051 - ca2-[9.5,10.3): 6.6160 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 4.8413 - ca3-[10.3,11.3): 6.1863 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 11.8350 - ca4-[11.3,14.9): 13.3720 - val_ca1-[8.0,9.5): 10.5984 - val_ca1-[9.5,10.3): 11.3675 - val_ca1-[10.3,11.3): 14.1285 - val_ca1-[11.3,14.9): 18.0965 - val_ca2-[8.0,9.5): 5.6438 - val_ca2-[9.5,10.3): 6.1530 - val_ca2-[10.3,11.3): 8.2703 - val_ca2-[11.3,14.9): 11.3023 - val_ca3-[8.0,9.5): 3.4664 - val_ca3-[9.5,10.3): 3.8081 - val_ca3-[10.3,11.3): 5.5336 - val_ca3-[11.3,14.9): 8.0028 - val_ca4-[8.0,9.5): 6.6013 - val_ca4-[9.5,10.3): 7.1670 - val_ca4-[10.3,11.3): 9.4199 - val_ca4-[11.3,14.9): 12.6562\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 10.6587 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 5.3179 - ca2-[9.5,10.3): 5.9368 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 4.1232 - ca3-[10.3,11.3): 5.3943 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 10.6443 - ca4-[11.3,14.9): 12.3342 - val_ca1-[8.0,9.5): 9.8197 - val_ca1-[9.5,10.3): 10.5501 - val_ca1-[10.3,11.3): 13.1929 - val_ca1-[11.3,14.9): 16.9261 - val_ca2-[8.0,9.5): 5.0269 - val_ca2-[9.5,10.3): 5.4927 - val_ca2-[10.3,11.3): 7.4918 - val_ca2-[11.3,14.9): 10.2972 - val_ca3-[8.0,9.5): 2.9437 - val_ca3-[9.5,10.3): 3.2392 - val_ca3-[10.3,11.3): 4.8369 - val_ca3-[11.3,14.9): 7.0732 - val_ca4-[8.0,9.5): 5.9310 - val_ca4-[9.5,10.3): 6.4541 - val_ca4-[10.3,11.3): 8.5907 - val_ca4-[11.3,14.9): 11.5978\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 9.8766 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 4.7727 - ca2-[9.5,10.3): 5.2622 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 3.5117 - ca3-[10.3,11.3): 4.7739 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 9.9282 - ca4-[11.3,14.9): 11.3751 - val_ca1-[8.0,9.5): 9.1334 - val_ca1-[9.5,10.3): 9.8299 - val_ca1-[10.3,11.3): 12.3891 - val_ca1-[11.3,14.9): 16.1400 - val_ca2-[8.0,9.5): 4.4890 - val_ca2-[9.5,10.3): 4.9164 - val_ca2-[10.3,11.3): 6.8242 - val_ca2-[11.3,14.9): 9.6029 - val_ca3-[8.0,9.5): 2.5086 - val_ca3-[9.5,10.3): 2.7632 - val_ca3-[10.3,11.3): 4.2602 - val_ca3-[11.3,14.9): 6.4367 - val_ca4-[8.0,9.5): 5.3385 - val_ca4-[9.5,10.3): 5.8232 - val_ca4-[10.3,11.3): 7.8716 - val_ca4-[11.3,14.9): 10.8600\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 9.2400 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 4.3393 - ca2-[9.5,10.3): 4.7428 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 3.0876 - ca3-[10.3,11.3): 4.2004 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 9.2265 - ca4-[11.3,14.9): 10.6470 - val_ca1-[8.0,9.5): 8.5088 - val_ca1-[9.5,10.3): 9.1757 - val_ca1-[10.3,11.3): 11.6365 - val_ca1-[11.3,14.9): 15.2070 - val_ca2-[8.0,9.5): 4.0088 - val_ca2-[9.5,10.3): 4.4001 - val_ca2-[10.3,11.3): 6.2021 - val_ca2-[11.3,14.9): 8.7993 - val_ca3-[8.0,9.5): 2.1558 - val_ca3-[9.5,10.3): 2.3722 - val_ca3-[10.3,11.3): 3.7604 - val_ca3-[11.3,14.9): 5.7548 - val_ca4-[8.0,9.5): 4.8120 - val_ca4-[9.5,10.3): 5.2612 - val_ca4-[10.3,11.3): 7.2040 - val_ca4-[11.3,14.9): 10.0090\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 8.5545 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 3.7515 - ca2-[9.5,10.3): 4.2552 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.7388 - ca3-[10.3,11.3): 3.7594 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 8.4735 - ca4-[11.3,14.9): 9.7979 - val_ca1-[8.0,9.5): 7.9451 - val_ca1-[9.5,10.3): 8.5830 - val_ca1-[10.3,11.3): 10.9481 - val_ca1-[11.3,14.9): 14.4297 - val_ca2-[8.0,9.5): 3.5773 - val_ca2-[9.5,10.3): 3.9340 - val_ca2-[10.3,11.3): 5.6294 - val_ca2-[11.3,14.9): 8.1176 - val_ca3-[8.0,9.5): 1.8569 - val_ca3-[9.5,10.3): 2.0387 - val_ca3-[10.3,11.3): 3.3208 - val_ca3-[11.3,14.9): 5.1998 - val_ca4-[8.0,9.5): 4.3384 - val_ca4-[9.5,10.3): 4.7536 - val_ca4-[10.3,11.3): 6.5902 - val_ca4-[11.3,14.9): 9.2880\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 1s 151ms/step - ca1-[8.0,9.5): 8.0623 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 3.3025 - ca2-[9.5,10.3): 3.7870 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.2848 - ca3-[10.3,11.3): 3.2812 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 7.9327 - ca4-[11.3,14.9): 9.0876 - val_ca1-[8.0,9.5): 7.4481 - val_ca1-[9.5,10.3): 8.0586 - val_ca1-[10.3,11.3): 10.4378 - val_ca1-[11.3,14.9): 13.9573 - val_ca2-[8.0,9.5): 3.1889 - val_ca2-[9.5,10.3): 3.5119 - val_ca2-[10.3,11.3): 5.1850 - val_ca2-[11.3,14.9): 7.6469 - val_ca3-[8.0,9.5): 1.6142 - val_ca3-[9.5,10.3): 1.7645 - val_ca3-[10.3,11.3): 3.0175 - val_ca3-[11.3,14.9): 4.8517 - val_ca4-[8.0,9.5): 3.9141 - val_ca4-[9.5,10.3): 4.2967 - val_ca4-[10.3,11.3): 6.1171 - val_ca4-[11.3,14.9): 8.8003\n",
      "Epoch 17/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 7.6133 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.9717 - ca2-[9.5,10.3): 3.4421 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 2.0031 - ca3-[10.3,11.3): 2.9652 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 7.3601 - ca4-[11.3,14.9): 8.4864 - val_ca1-[8.0,9.5): 6.9975 - val_ca1-[9.5,10.3): 7.5833 - val_ca1-[10.3,11.3): 9.9007 - val_ca1-[11.3,14.9): 13.1822 - val_ca2-[8.0,9.5): 2.8390 - val_ca2-[9.5,10.3): 3.1295 - val_ca2-[10.3,11.3): 4.7259 - val_ca2-[11.3,14.9): 6.9658 - val_ca3-[8.0,9.5): 1.4188 - val_ca3-[9.5,10.3): 1.5398 - val_ca3-[10.3,11.3): 2.7246 - val_ca3-[11.3,14.9): 4.3714 - val_ca4-[8.0,9.5): 3.5321 - val_ca4-[9.5,10.3): 3.8836 - val_ca4-[10.3,11.3): 5.6299 - val_ca4-[11.3,14.9): 8.0871\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 7.0404 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.5673 - ca2-[9.5,10.3): 2.9896 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.7985 - ca3-[10.3,11.3): 2.6850 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 6.7384 - ca4-[11.3,14.9): 7.9200 - val_ca1-[8.0,9.5): 6.5836 - val_ca1-[9.5,10.3): 7.1456 - val_ca1-[10.3,11.3): 9.4051 - val_ca1-[11.3,14.9): 12.6072 - val_ca2-[8.0,9.5): 2.5257 - val_ca2-[9.5,10.3): 2.7851 - val_ca2-[10.3,11.3): 4.3041 - val_ca2-[11.3,14.9): 6.4381 - val_ca3-[8.0,9.5): 1.2551 - val_ca3-[9.5,10.3): 1.3493 - val_ca3-[10.3,11.3): 2.4661 - val_ca3-[11.3,14.9): 4.0206 - val_ca4-[8.0,9.5): 3.1865 - val_ca4-[9.5,10.3): 3.5081 - val_ca4-[10.3,11.3): 5.1803 - val_ca4-[11.3,14.9): 7.5363\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 6.6483 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 2.2800 - ca2-[9.5,10.3): 2.7216 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.6346 - ca3-[10.3,11.3): 2.4487 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 6.4852 - ca4-[11.3,14.9): 7.3967 - val_ca1-[8.0,9.5): 6.2038 - val_ca1-[9.5,10.3): 6.7431 - val_ca1-[10.3,11.3): 8.9257 - val_ca1-[11.3,14.9): 12.1082 - val_ca2-[8.0,9.5): 2.2464 - val_ca2-[9.5,10.3): 2.4757 - val_ca2-[10.3,11.3): 3.9078 - val_ca2-[11.3,14.9): 5.9751 - val_ca3-[8.0,9.5): 1.1204 - val_ca3-[9.5,10.3): 1.1896 - val_ca3-[10.3,11.3): 2.2357 - val_ca3-[11.3,14.9): 3.7302 - val_ca4-[8.0,9.5): 2.8743 - val_ca4-[9.5,10.3): 3.1672 - val_ca4-[10.3,11.3): 4.7539 - val_ca4-[11.3,14.9): 7.0520\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 6.3336 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.9975 - ca2-[9.5,10.3): 2.3831 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.3983 - ca3-[10.3,11.3): 2.2321 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.6296 - ca4-[11.3,14.9): 6.8393 - val_ca1-[8.0,9.5): 5.8497 - val_ca1-[9.5,10.3): 6.3671 - val_ca1-[10.3,11.3): 8.5183 - val_ca1-[11.3,14.9): 11.5391 - val_ca2-[8.0,9.5): 2.0003 - val_ca2-[9.5,10.3): 2.2010 - val_ca2-[10.3,11.3): 3.5786 - val_ca2-[11.3,14.9): 5.4957 - val_ca3-[8.0,9.5): 1.0090 - val_ca3-[9.5,10.3): 1.0551 - val_ca3-[10.3,11.3): 2.0567 - val_ca3-[11.3,14.9): 3.4380 - val_ca4-[8.0,9.5): 2.5918 - val_ca4-[9.5,10.3): 2.8570 - val_ca4-[10.3,11.3): 4.3927 - val_ca4-[11.3,14.9): 6.5362\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 6.0127 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.8138 - ca2-[9.5,10.3): 2.1403 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.1913 - ca3-[10.3,11.3): 2.0540 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 5.2486 - ca4-[11.3,14.9): 6.3381 - val_ca1-[8.0,9.5): 5.5192 - val_ca1-[9.5,10.3): 6.0155 - val_ca1-[10.3,11.3): 8.1304 - val_ca1-[11.3,14.9): 11.1076 - val_ca2-[8.0,9.5): 1.7854 - val_ca2-[9.5,10.3): 1.9590 - val_ca2-[10.3,11.3): 3.2795 - val_ca2-[11.3,14.9): 5.1227 - val_ca3-[8.0,9.5): 0.9164 - val_ca3-[9.5,10.3): 0.9410 - val_ca3-[10.3,11.3): 1.8959 - val_ca3-[11.3,14.9): 3.2176 - val_ca4-[8.0,9.5): 2.3366 - val_ca4-[9.5,10.3): 2.5751 - val_ca4-[10.3,11.3): 4.0556 - val_ca4-[11.3,14.9): 6.1280\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 5.5158 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.5738 - ca2-[9.5,10.3): 1.9180 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.1362 - ca3-[10.3,11.3): 1.8851 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.8348 - ca4-[11.3,14.9): 5.9724 - val_ca1-[8.0,9.5): 5.2106 - val_ca1-[9.5,10.3): 5.6866 - val_ca1-[10.3,11.3): 7.7311 - val_ca1-[11.3,14.9): 10.6919 - val_ca2-[8.0,9.5): 1.5986 - val_ca2-[9.5,10.3): 1.7466 - val_ca2-[10.3,11.3): 2.9912 - val_ca2-[11.3,14.9): 4.7794 - val_ca3-[8.0,9.5): 0.8398 - val_ca3-[9.5,10.3): 0.8441 - val_ca3-[10.3,11.3): 1.7392 - val_ca3-[11.3,14.9): 3.0155 - val_ca4-[8.0,9.5): 2.1058 - val_ca4-[9.5,10.3): 2.3183 - val_ca4-[10.3,11.3): 3.7205 - val_ca4-[11.3,14.9): 5.7404\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 1s 154ms/step - ca1-[8.0,9.5): 5.2957 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.4129 - ca2-[9.5,10.3): 1.7307 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 1.0464 - ca3-[10.3,11.3): 1.7228 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.5954 - ca4-[11.3,14.9): 5.5503 - val_ca1-[8.0,9.5): 4.9213 - val_ca1-[9.5,10.3): 5.3778 - val_ca1-[10.3,11.3): 7.3803 - val_ca1-[11.3,14.9): 10.2824 - val_ca2-[8.0,9.5): 1.4372 - val_ca2-[9.5,10.3): 1.5612 - val_ca2-[10.3,11.3): 2.7524 - val_ca2-[11.3,14.9): 4.4629 - val_ca3-[8.0,9.5): 0.7768 - val_ca3-[9.5,10.3): 0.7621 - val_ca3-[10.3,11.3): 1.6159 - val_ca3-[11.3,14.9): 2.8309 - val_ca4-[8.0,9.5): 1.8981 - val_ca4-[9.5,10.3): 2.0856 - val_ca4-[10.3,11.3): 3.4321 - val_ca4-[11.3,14.9): 5.3710\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 5.0291 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.1945 - ca2-[9.5,10.3): 1.5438 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.9491 - ca3-[10.3,11.3): 1.5921 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 4.0129 - ca4-[11.3,14.9): 5.1997 - val_ca1-[8.0,9.5): 4.6501 - val_ca1-[9.5,10.3): 5.0875 - val_ca1-[10.3,11.3): 7.0432 - val_ca1-[11.3,14.9): 9.7526 - val_ca2-[8.0,9.5): 1.2985 - val_ca2-[9.5,10.3): 1.4001 - val_ca2-[10.3,11.3): 2.5352 - val_ca2-[11.3,14.9): 4.0912 - val_ca3-[8.0,9.5): 0.7257 - val_ca3-[9.5,10.3): 0.6933 - val_ca3-[10.3,11.3): 1.5021 - val_ca3-[11.3,14.9): 2.5997 - val_ca4-[8.0,9.5): 1.7106 - val_ca4-[9.5,10.3): 1.8737 - val_ca4-[10.3,11.3): 3.1596 - val_ca4-[11.3,14.9): 4.9281\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 4.7492 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 1.0932 - ca2-[9.5,10.3): 1.4067 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.8275 - ca3-[10.3,11.3): 1.5040 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.8520 - ca4-[11.3,14.9): 4.8591 - val_ca1-[8.0,9.5): 4.3960 - val_ca1-[9.5,10.3): 4.8149 - val_ca1-[10.3,11.3): 6.7257 - val_ca1-[11.3,14.9): 9.4184 - val_ca2-[8.0,9.5): 1.1799 - val_ca2-[9.5,10.3): 1.2604 - val_ca2-[10.3,11.3): 2.3442 - val_ca2-[11.3,14.9): 3.8518 - val_ca3-[8.0,9.5): 0.6843 - val_ca3-[9.5,10.3): 0.6350 - val_ca3-[10.3,11.3): 1.4028 - val_ca3-[11.3,14.9): 2.4575 - val_ca4-[8.0,9.5): 1.5431 - val_ca4-[9.5,10.3): 1.6826 - val_ca4-[10.3,11.3): 2.9111 - val_ca4-[11.3,14.9): 4.6263\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 4.4701 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.9387 - ca2-[9.5,10.3): 1.2625 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.8316 - ca3-[10.3,11.3): 1.4224 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.5225 - ca4-[11.3,14.9): 4.4732 - val_ca1-[8.0,9.5): 4.1577 - val_ca1-[9.5,10.3): 4.5588 - val_ca1-[10.3,11.3): 6.3904 - val_ca1-[11.3,14.9): 9.0732 - val_ca2-[8.0,9.5): 1.0787 - val_ca2-[9.5,10.3): 1.1396 - val_ca2-[10.3,11.3): 2.1583 - val_ca2-[11.3,14.9): 3.6267 - val_ca3-[8.0,9.5): 0.6514 - val_ca3-[9.5,10.3): 0.5863 - val_ca3-[10.3,11.3): 1.3048 - val_ca3-[11.3,14.9): 2.3249 - val_ca4-[8.0,9.5): 1.3936 - val_ca4-[9.5,10.3): 1.5104 - val_ca4-[10.3,11.3): 2.6629 - val_ca4-[11.3,14.9): 4.3316\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 4.2487 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.8499 - ca2-[9.5,10.3): 1.1480 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.7483 - ca3-[10.3,11.3): 1.2888 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.3049 - ca4-[11.3,14.9): 4.2236 - val_ca1-[8.0,9.5): 3.9337 - val_ca1-[9.5,10.3): 4.3176 - val_ca1-[10.3,11.3): 6.1438 - val_ca1-[11.3,14.9): 8.7543 - val_ca2-[8.0,9.5): 0.9930 - val_ca2-[9.5,10.3): 1.0355 - val_ca2-[10.3,11.3): 2.0299 - val_ca2-[11.3,14.9): 3.4316 - val_ca3-[8.0,9.5): 0.6262 - val_ca3-[9.5,10.3): 0.5461 - val_ca3-[10.3,11.3): 1.2423 - val_ca3-[11.3,14.9): 2.2111 - val_ca4-[8.0,9.5): 1.2607 - val_ca4-[9.5,10.3): 1.3554 - val_ca4-[10.3,11.3): 2.4769 - val_ca4-[11.3,14.9): 4.0639\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 4.0259 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.7980 - ca2-[9.5,10.3): 1.0672 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6990 - ca3-[10.3,11.3): 1.2122 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 3.0810 - ca4-[11.3,14.9): 3.9026 - val_ca1-[8.0,9.5): 3.7224 - val_ca1-[9.5,10.3): 4.0895 - val_ca1-[10.3,11.3): 5.8927 - val_ca1-[11.3,14.9): 8.4279 - val_ca2-[8.0,9.5): 0.9195 - val_ca2-[9.5,10.3): 0.9448 - val_ca2-[10.3,11.3): 1.9012 - val_ca2-[11.3,14.9): 3.2283 - val_ca3-[8.0,9.5): 0.6074 - val_ca3-[9.5,10.3): 0.5134 - val_ca3-[10.3,11.3): 1.1745 - val_ca3-[11.3,14.9): 2.0808 - val_ca4-[8.0,9.5): 1.1433 - val_ca4-[9.5,10.3): 1.2165 - val_ca4-[10.3,11.3): 2.2919 - val_ca4-[11.3,14.9): 3.7892\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 3.7857 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.7169 - ca2-[9.5,10.3): 0.9641 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6185 - ca3-[10.3,11.3): 1.1412 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.8203 - ca4-[11.3,14.9): 3.6529 - val_ca1-[8.0,9.5): 3.5238 - val_ca1-[9.5,10.3): 3.8745 - val_ca1-[10.3,11.3): 5.6357 - val_ca1-[11.3,14.9): 8.0893 - val_ca2-[8.0,9.5): 0.8574 - val_ca2-[9.5,10.3): 0.8667 - val_ca2-[10.3,11.3): 1.7802 - val_ca2-[11.3,14.9): 3.0376 - val_ca3-[8.0,9.5): 0.5939 - val_ca3-[9.5,10.3): 0.4867 - val_ca3-[10.3,11.3): 1.1115 - val_ca3-[11.3,14.9): 1.9618 - val_ca4-[8.0,9.5): 1.0399 - val_ca4-[9.5,10.3): 1.0923 - val_ca4-[10.3,11.3): 2.1133 - val_ca4-[11.3,14.9): 3.5228\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 1s 154ms/step - ca1-[8.0,9.5): 3.5902 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.6510 - ca2-[9.5,10.3): 0.8957 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.6214 - ca3-[10.3,11.3): 1.0970 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.6795 - ca4-[11.3,14.9): 3.4550 - val_ca1-[8.0,9.5): 3.3365 - val_ca1-[9.5,10.3): 3.6712 - val_ca1-[10.3,11.3): 5.3762 - val_ca1-[11.3,14.9): 7.7077 - val_ca2-[8.0,9.5): 0.8051 - val_ca2-[9.5,10.3): 0.7993 - val_ca2-[10.3,11.3): 1.6730 - val_ca2-[11.3,14.9): 2.8360 - val_ca3-[8.0,9.5): 0.5851 - val_ca3-[9.5,10.3): 0.4653 - val_ca3-[10.3,11.3): 1.0612 - val_ca3-[11.3,14.9): 1.8338 - val_ca4-[8.0,9.5): 0.9496 - val_ca4-[9.5,10.3): 0.9819 - val_ca4-[10.3,11.3): 1.9487 - val_ca4-[11.3,14.9): 3.2430\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 3.4121 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.6013 - ca2-[9.5,10.3): 0.8324 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5757 - ca3-[10.3,11.3): 1.0498 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.4908 - ca4-[11.3,14.9): 3.2267 - val_ca1-[8.0,9.5): 3.1601 - val_ca1-[9.5,10.3): 3.4793 - val_ca1-[10.3,11.3): 5.1749 - val_ca1-[11.3,14.9): 7.6136 - val_ca2-[8.0,9.5): 0.7614 - val_ca2-[9.5,10.3): 0.7417 - val_ca2-[10.3,11.3): 1.5900 - val_ca2-[11.3,14.9): 2.7867 - val_ca3-[8.0,9.5): 0.5802 - val_ca3-[9.5,10.3): 0.4487 - val_ca3-[10.3,11.3): 1.0179 - val_ca3-[11.3,14.9): 1.8054 - val_ca4-[8.0,9.5): 0.8717 - val_ca4-[9.5,10.3): 0.8846 - val_ca4-[10.3,11.3): 1.8145 - val_ca4-[11.3,14.9): 3.1309\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 3.2609 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.5490 - ca2-[9.5,10.3): 0.7707 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5894 - ca3-[10.3,11.3): 1.0083 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.2560 - ca4-[11.3,14.9): 3.0086 - val_ca1-[8.0,9.5): 2.9941 - val_ca1-[9.5,10.3): 3.2981 - val_ca1-[10.3,11.3): 4.9308 - val_ca1-[11.3,14.9): 7.2328 - val_ca2-[8.0,9.5): 0.7248 - val_ca2-[9.5,10.3): 0.6921 - val_ca2-[10.3,11.3): 1.5051 - val_ca2-[11.3,14.9): 2.6246 - val_ca3-[8.0,9.5): 0.5787 - val_ca3-[9.5,10.3): 0.4360 - val_ca3-[10.3,11.3): 0.9817 - val_ca3-[11.3,14.9): 1.7158 - val_ca4-[8.0,9.5): 0.8050 - val_ca4-[9.5,10.3): 0.7989 - val_ca4-[10.3,11.3): 1.6770 - val_ca4-[11.3,14.9): 2.8906\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 3.0746 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.5175 - ca2-[9.5,10.3): 0.7503 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5426 - ca3-[10.3,11.3): 0.9542 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.2299 - ca4-[11.3,14.9): 2.7964 - val_ca1-[8.0,9.5): 2.8421 - val_ca1-[9.5,10.3): 3.1330 - val_ca1-[10.3,11.3): 4.6513 - val_ca1-[11.3,14.9): 6.9211 - val_ca2-[8.0,9.5): 0.6964 - val_ca2-[9.5,10.3): 0.6517 - val_ca2-[10.3,11.3): 1.3901 - val_ca2-[11.3,14.9): 2.4721 - val_ca3-[8.0,9.5): 0.5811 - val_ca3-[9.5,10.3): 0.4277 - val_ca3-[10.3,11.3): 0.9139 - val_ca3-[11.3,14.9): 1.6117 - val_ca4-[8.0,9.5): 0.7508 - val_ca4-[9.5,10.3): 0.7267 - val_ca4-[10.3,11.3): 1.5132 - val_ca4-[11.3,14.9): 2.6686\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 2.8780 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4421 - ca2-[9.5,10.3): 0.6945 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5468 - ca3-[10.3,11.3): 0.9220 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 2.0300 - ca4-[11.3,14.9): 2.6302 - val_ca1-[8.0,9.5): 2.6893 - val_ca1-[9.5,10.3): 2.9642 - val_ca1-[10.3,11.3): 4.5233 - val_ca1-[11.3,14.9): 6.7783 - val_ca2-[8.0,9.5): 0.6696 - val_ca2-[9.5,10.3): 0.6136 - val_ca2-[10.3,11.3): 1.3649 - val_ca2-[11.3,14.9): 2.4324 - val_ca3-[8.0,9.5): 0.5836 - val_ca3-[9.5,10.3): 0.4207 - val_ca3-[10.3,11.3): 0.9113 - val_ca3-[11.3,14.9): 1.5958 - val_ca4-[8.0,9.5): 0.7017 - val_ca4-[9.5,10.3): 0.6598 - val_ca4-[10.3,11.3): 1.4454 - val_ca4-[11.3,14.9): 2.5637\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 2.7339 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4808 - ca2-[9.5,10.3): 0.6803 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5083 - ca3-[10.3,11.3): 0.9096 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.8155 - ca4-[11.3,14.9): 2.4463 - val_ca1-[8.0,9.5): 2.5497 - val_ca1-[9.5,10.3): 2.8105 - val_ca1-[10.3,11.3): 4.3214 - val_ca1-[11.3,14.9): 6.4655 - val_ca2-[8.0,9.5): 0.6494 - val_ca2-[9.5,10.3): 0.5832 - val_ca2-[10.3,11.3): 1.3043 - val_ca2-[11.3,14.9): 2.3025 - val_ca3-[8.0,9.5): 0.5891 - val_ca3-[9.5,10.3): 0.4170 - val_ca3-[10.3,11.3): 0.8827 - val_ca3-[11.3,14.9): 1.5105 - val_ca4-[8.0,9.5): 0.6636 - val_ca4-[9.5,10.3): 0.6046 - val_ca4-[10.3,11.3): 1.3432 - val_ca4-[11.3,14.9): 2.3671\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 2.6306 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4475 - ca2-[9.5,10.3): 0.6594 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4929 - ca3-[10.3,11.3): 0.8697 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.5928 - ca4-[11.3,14.9): 2.2944 - val_ca1-[8.0,9.5): 2.4180 - val_ca1-[9.5,10.3): 2.6651 - val_ca1-[10.3,11.3): 4.1429 - val_ca1-[11.3,14.9): 6.2483 - val_ca2-[8.0,9.5): 0.6330 - val_ca2-[9.5,10.3): 0.5573 - val_ca2-[10.3,11.3): 1.2557 - val_ca2-[11.3,14.9): 2.2231 - val_ca3-[8.0,9.5): 0.5961 - val_ca3-[9.5,10.3): 0.4154 - val_ca3-[10.3,11.3): 0.8602 - val_ca3-[11.3,14.9): 1.4575 - val_ca4-[8.0,9.5): 0.6334 - val_ca4-[9.5,10.3): 0.5579 - val_ca4-[10.3,11.3): 1.2566 - val_ca4-[11.3,14.9): 2.2248\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 1s 149ms/step - ca1-[8.0,9.5): 2.4832 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4504 - ca2-[9.5,10.3): 0.6222 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5135 - ca3-[10.3,11.3): 0.8672 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.5087 - ca4-[11.3,14.9): 2.1718 - val_ca1-[8.0,9.5): 2.2938 - val_ca1-[9.5,10.3): 2.5275 - val_ca1-[10.3,11.3): 3.9861 - val_ca1-[11.3,14.9): 6.0284 - val_ca2-[8.0,9.5): 0.6198 - val_ca2-[9.5,10.3): 0.5354 - val_ca2-[10.3,11.3): 1.2175 - val_ca2-[11.3,14.9): 2.1539 - val_ca3-[8.0,9.5): 0.6045 - val_ca3-[9.5,10.3): 0.4155 - val_ca3-[10.3,11.3): 0.8424 - val_ca3-[11.3,14.9): 1.4157 - val_ca4-[8.0,9.5): 0.6105 - val_ca4-[9.5,10.3): 0.5190 - val_ca4-[10.3,11.3): 1.1837 - val_ca4-[11.3,14.9): 2.0957\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 2.3548 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4360 - ca2-[9.5,10.3): 0.6212 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5131 - ca3-[10.3,11.3): 0.8225 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.4452 - ca4-[11.3,14.9): 2.0361 - val_ca1-[8.0,9.5): 2.1766 - val_ca1-[9.5,10.3): 2.3972 - val_ca1-[10.3,11.3): 3.8057 - val_ca1-[11.3,14.9): 5.8309 - val_ca2-[8.0,9.5): 0.6091 - val_ca2-[9.5,10.3): 0.5166 - val_ca2-[10.3,11.3): 1.1698 - val_ca2-[11.3,14.9): 2.0859 - val_ca3-[8.0,9.5): 0.6137 - val_ca3-[9.5,10.3): 0.4171 - val_ca3-[10.3,11.3): 0.8195 - val_ca3-[11.3,14.9): 1.3673 - val_ca4-[8.0,9.5): 0.5943 - val_ca4-[9.5,10.3): 0.4874 - val_ca4-[10.3,11.3): 1.1059 - val_ca4-[11.3,14.9): 1.9713\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 2.2069 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4192 - ca2-[9.5,10.3): 0.5959 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4868 - ca3-[10.3,11.3): 0.8223 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.2662 - ca4-[11.3,14.9): 1.9091 - val_ca1-[8.0,9.5): 2.0662 - val_ca1-[9.5,10.3): 2.2741 - val_ca1-[10.3,11.3): 3.6696 - val_ca1-[11.3,14.9): 5.5726 - val_ca2-[8.0,9.5): 0.6008 - val_ca2-[9.5,10.3): 0.5010 - val_ca2-[10.3,11.3): 1.1452 - val_ca2-[11.3,14.9): 1.9923 - val_ca3-[8.0,9.5): 0.6237 - val_ca3-[9.5,10.3): 0.4199 - val_ca3-[10.3,11.3): 0.8108 - val_ca3-[11.3,14.9): 1.3018 - val_ca4-[8.0,9.5): 0.5841 - val_ca4-[9.5,10.3): 0.4622 - val_ca4-[10.3,11.3): 1.0530 - val_ca4-[11.3,14.9): 1.8251\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 2.0991 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3953 - ca2-[9.5,10.3): 0.5725 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5034 - ca3-[10.3,11.3): 0.8122 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.3466 - ca4-[11.3,14.9): 1.7847 - val_ca1-[8.0,9.5): 1.9619 - val_ca1-[9.5,10.3): 2.1573 - val_ca1-[10.3,11.3): 3.5090 - val_ca1-[11.3,14.9): 5.4413 - val_ca2-[8.0,9.5): 0.5943 - val_ca2-[9.5,10.3): 0.4877 - val_ca2-[10.3,11.3): 1.1094 - val_ca2-[11.3,14.9): 1.9708 - val_ca3-[8.0,9.5): 0.6341 - val_ca3-[9.5,10.3): 0.4236 - val_ca3-[10.3,11.3): 0.7948 - val_ca3-[11.3,14.9): 1.2888 - val_ca4-[8.0,9.5): 0.5792 - val_ca4-[9.5,10.3): 0.4430 - val_ca4-[10.3,11.3): 0.9933 - val_ca4-[11.3,14.9): 1.7502\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 2.0212 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3850 - ca2-[9.5,10.3): 0.5751 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5312 - ca3-[10.3,11.3): 0.8080 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.1761 - ca4-[11.3,14.9): 1.6954 - val_ca1-[8.0,9.5): 1.8634 - val_ca1-[9.5,10.3): 2.0465 - val_ca1-[10.3,11.3): 3.3556 - val_ca1-[11.3,14.9): 5.2919 - val_ca2-[8.0,9.5): 0.5894 - val_ca2-[9.5,10.3): 0.4765 - val_ca2-[10.3,11.3): 1.0774 - val_ca2-[11.3,14.9): 1.9465 - val_ca3-[8.0,9.5): 0.6448 - val_ca3-[9.5,10.3): 0.4281 - val_ca3-[10.3,11.3): 0.7808 - val_ca3-[11.3,14.9): 1.2761 - val_ca4-[8.0,9.5): 0.5793 - val_ca4-[9.5,10.3): 0.4292 - val_ca4-[10.3,11.3): 0.9409 - val_ca4-[11.3,14.9): 1.6759\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 1.9123 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3776 - ca2-[9.5,10.3): 0.5598 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4789 - ca3-[10.3,11.3): 0.7581 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.1158 - ca4-[11.3,14.9): 1.6018 - val_ca1-[8.0,9.5): 1.7705 - val_ca1-[9.5,10.3): 1.9415 - val_ca1-[10.3,11.3): 3.2433 - val_ca1-[11.3,14.9): 5.1483 - val_ca2-[8.0,9.5): 0.5856 - val_ca2-[9.5,10.3): 0.4668 - val_ca2-[10.3,11.3): 1.0623 - val_ca2-[11.3,14.9): 1.8961 - val_ca3-[8.0,9.5): 0.6556 - val_ca3-[9.5,10.3): 0.4331 - val_ca3-[10.3,11.3): 0.7761 - val_ca3-[11.3,14.9): 1.2268 - val_ca4-[8.0,9.5): 0.5839 - val_ca4-[9.5,10.3): 0.4203 - val_ca4-[10.3,11.3): 0.9067 - val_ca4-[11.3,14.9): 1.5749\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 1.7988 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4026 - ca2-[9.5,10.3): 0.5480 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4784 - ca3-[10.3,11.3): 0.7584 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 1.0006 - ca4-[11.3,14.9): 1.5086 - val_ca1-[8.0,9.5): 1.6831 - val_ca1-[9.5,10.3): 1.8425 - val_ca1-[10.3,11.3): 3.1073 - val_ca1-[11.3,14.9): 4.9816 - val_ca2-[8.0,9.5): 0.5829 - val_ca2-[9.5,10.3): 0.4589 - val_ca2-[10.3,11.3): 1.0388 - val_ca2-[11.3,14.9): 1.8767 - val_ca3-[8.0,9.5): 0.6664 - val_ca3-[9.5,10.3): 0.4385 - val_ca3-[10.3,11.3): 0.7673 - val_ca3-[11.3,14.9): 1.2254 - val_ca4-[8.0,9.5): 0.5925 - val_ca4-[9.5,10.3): 0.4159 - val_ca4-[10.3,11.3): 0.8688 - val_ca4-[11.3,14.9): 1.5147\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 1s 151ms/step - ca1-[8.0,9.5): 1.7323 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.4079 - ca2-[9.5,10.3): 0.5567 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4846 - ca3-[10.3,11.3): 0.7620 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.9294 - ca4-[11.3,14.9): 1.4129 - val_ca1-[8.0,9.5): 1.6004 - val_ca1-[9.5,10.3): 1.7482 - val_ca1-[10.3,11.3): 2.9996 - val_ca1-[11.3,14.9): 4.7019 - val_ca2-[8.0,9.5): 0.5810 - val_ca2-[9.5,10.3): 0.4523 - val_ca2-[10.3,11.3): 1.0298 - val_ca2-[11.3,14.9): 1.7719 - val_ca3-[8.0,9.5): 0.6770 - val_ca3-[9.5,10.3): 0.4441 - val_ca3-[10.3,11.3): 0.7679 - val_ca3-[11.3,14.9): 1.1485 - val_ca4-[8.0,9.5): 0.6045 - val_ca4-[9.5,10.3): 0.4155 - val_ca4-[10.3,11.3): 0.8464 - val_ca4-[11.3,14.9): 1.3796\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 1.6424 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3801 - ca2-[9.5,10.3): 0.5494 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4993 - ca3-[10.3,11.3): 0.7601 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.9258 - ca4-[11.3,14.9): 1.3510 - val_ca1-[8.0,9.5): 1.5224 - val_ca1-[9.5,10.3): 1.6589 - val_ca1-[10.3,11.3): 2.8814 - val_ca1-[11.3,14.9): 4.6119 - val_ca2-[8.0,9.5): 0.5797 - val_ca2-[9.5,10.3): 0.4466 - val_ca2-[10.3,11.3): 1.0114 - val_ca2-[11.3,14.9): 1.7856 - val_ca3-[8.0,9.5): 0.6872 - val_ca3-[9.5,10.3): 0.4497 - val_ca3-[10.3,11.3): 0.7603 - val_ca3-[11.3,14.9): 1.1649 - val_ca4-[8.0,9.5): 0.6195 - val_ca4-[9.5,10.3): 0.4186 - val_ca4-[10.3,11.3): 0.8185 - val_ca4-[11.3,14.9): 1.3530\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 1.5324 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3632 - ca2-[9.5,10.3): 0.5364 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4807 - ca3-[10.3,11.3): 0.7597 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8629 - ca4-[11.3,14.9): 1.3015 - val_ca1-[8.0,9.5): 1.4488 - val_ca1-[9.5,10.3): 1.5741 - val_ca1-[10.3,11.3): 2.7580 - val_ca1-[11.3,14.9): 4.4145 - val_ca2-[8.0,9.5): 0.5790 - val_ca2-[9.5,10.3): 0.4418 - val_ca2-[10.3,11.3): 0.9916 - val_ca2-[11.3,14.9): 1.7341 - val_ca3-[8.0,9.5): 0.6974 - val_ca3-[9.5,10.3): 0.4555 - val_ca3-[10.3,11.3): 0.7529 - val_ca3-[11.3,14.9): 1.1317 - val_ca4-[8.0,9.5): 0.6372 - val_ca4-[9.5,10.3): 0.4249 - val_ca4-[10.3,11.3): 0.7934 - val_ca4-[11.3,14.9): 1.2747\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 1.4694 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3551 - ca2-[9.5,10.3): 0.5372 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5088 - ca3-[10.3,11.3): 0.7578 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.8109 - ca4-[11.3,14.9): 1.2317 - val_ca1-[8.0,9.5): 1.3789 - val_ca1-[9.5,10.3): 1.4933 - val_ca1-[10.3,11.3): 2.6682 - val_ca1-[11.3,14.9): 4.2238 - val_ca2-[8.0,9.5): 0.5787 - val_ca2-[9.5,10.3): 0.4378 - val_ca2-[10.3,11.3): 0.9844 - val_ca2-[11.3,14.9): 1.6768 - val_ca3-[8.0,9.5): 0.7070 - val_ca3-[9.5,10.3): 0.4612 - val_ca3-[10.3,11.3): 0.7501 - val_ca3-[11.3,14.9): 1.0882 - val_ca4-[8.0,9.5): 0.6572 - val_ca4-[9.5,10.3): 0.4339 - val_ca4-[10.3,11.3): 0.7778 - val_ca4-[11.3,14.9): 1.1917\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 1.3984 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3845 - ca2-[9.5,10.3): 0.5260 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4932 - ca3-[10.3,11.3): 0.7438 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7523 - ca4-[11.3,14.9): 1.1752 - val_ca1-[8.0,9.5): 1.3126 - val_ca1-[9.5,10.3): 1.4137 - val_ca1-[10.3,11.3): 2.5608 - val_ca1-[11.3,14.9): 4.1525 - val_ca2-[8.0,9.5): 0.5787 - val_ca2-[9.5,10.3): 0.4346 - val_ca2-[10.3,11.3): 0.9757 - val_ca2-[11.3,14.9): 1.6972 - val_ca3-[8.0,9.5): 0.7163 - val_ca3-[9.5,10.3): 0.4683 - val_ca3-[10.3,11.3): 0.7527 - val_ca3-[11.3,14.9): 1.1055 - val_ca4-[8.0,9.5): 0.6792 - val_ca4-[9.5,10.3): 0.4465 - val_ca4-[10.3,11.3): 0.7688 - val_ca4-[11.3,14.9): 1.1761\n",
      "Epoch 49/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 1.3393 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3708 - ca2-[9.5,10.3): 0.5255 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4880 - ca3-[10.3,11.3): 0.7427 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7243 - ca4-[11.3,14.9): 1.1318 - val_ca1-[8.0,9.5): 1.2494 - val_ca1-[9.5,10.3): 1.3421 - val_ca1-[10.3,11.3): 2.4457 - val_ca1-[11.3,14.9): 3.9896 - val_ca2-[8.0,9.5): 0.5789 - val_ca2-[9.5,10.3): 0.4315 - val_ca2-[10.3,11.3): 0.9549 - val_ca2-[11.3,14.9): 1.6638 - val_ca3-[8.0,9.5): 0.7255 - val_ca3-[9.5,10.3): 0.4726 - val_ca3-[10.3,11.3): 0.7409 - val_ca3-[11.3,14.9): 1.0831 - val_ca4-[8.0,9.5): 0.7028 - val_ca4-[9.5,10.3): 0.4588 - val_ca4-[10.3,11.3): 0.7485 - val_ca4-[11.3,14.9): 1.1215\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 1.2681 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3619 - ca2-[9.5,10.3): 0.5260 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4844 - ca3-[10.3,11.3): 0.7295 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.7669 - ca4-[11.3,14.9): 1.0783 - val_ca1-[8.0,9.5): 1.1894 - val_ca1-[9.5,10.3): 1.2713 - val_ca1-[10.3,11.3): 2.3594 - val_ca1-[11.3,14.9): 3.8489 - val_ca2-[8.0,9.5): 0.5793 - val_ca2-[9.5,10.3): 0.4292 - val_ca2-[10.3,11.3): 0.9507 - val_ca2-[11.3,14.9): 1.6387 - val_ca3-[8.0,9.5): 0.7340 - val_ca3-[9.5,10.3): 0.4779 - val_ca3-[10.3,11.3): 0.7410 - val_ca3-[11.3,14.9): 1.0635 - val_ca4-[8.0,9.5): 0.7279 - val_ca4-[9.5,10.3): 0.4741 - val_ca4-[10.3,11.3): 0.7426 - val_ca4-[11.3,14.9): 1.0728\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 1s 151ms/step - ca1-[8.0,9.5): 1.2100 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3666 - ca2-[9.5,10.3): 0.5074 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5007 - ca3-[10.3,11.3): 0.7329 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6857 - ca4-[11.3,14.9): 1.0355 - val_ca1-[8.0,9.5): 1.1324 - val_ca1-[9.5,10.3): 1.2035 - val_ca1-[10.3,11.3): 2.2551 - val_ca1-[11.3,14.9): 3.7416 - val_ca2-[8.0,9.5): 0.5798 - val_ca2-[9.5,10.3): 0.4272 - val_ca2-[10.3,11.3): 0.9380 - val_ca2-[11.3,14.9): 1.6363 - val_ca3-[8.0,9.5): 0.7420 - val_ca3-[9.5,10.3): 0.4830 - val_ca3-[10.3,11.3): 0.7368 - val_ca3-[11.3,14.9): 1.0607 - val_ca4-[8.0,9.5): 0.7540 - val_ca4-[9.5,10.3): 0.4909 - val_ca4-[10.3,11.3): 0.7345 - val_ca4-[11.3,14.9): 1.0436\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 1.1220 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3654 - ca2-[9.5,10.3): 0.5131 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5128 - ca3-[10.3,11.3): 0.7196 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6385 - ca4-[11.3,14.9): 1.0110 - val_ca1-[8.0,9.5): 1.0786 - val_ca1-[9.5,10.3): 1.1391 - val_ca1-[10.3,11.3): 2.1664 - val_ca1-[11.3,14.9): 3.6417 - val_ca2-[8.0,9.5): 0.5804 - val_ca2-[9.5,10.3): 0.4257 - val_ca2-[10.3,11.3): 0.9334 - val_ca2-[11.3,14.9): 1.6329 - val_ca3-[8.0,9.5): 0.7495 - val_ca3-[9.5,10.3): 0.4879 - val_ca3-[10.3,11.3): 0.7375 - val_ca3-[11.3,14.9): 1.0515 - val_ca4-[8.0,9.5): 0.7812 - val_ca4-[9.5,10.3): 0.5091 - val_ca4-[10.3,11.3): 0.7332 - val_ca4-[11.3,14.9): 1.0092\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 1.0710 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3566 - ca2-[9.5,10.3): 0.5148 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5061 - ca3-[10.3,11.3): 0.7298 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6380 - ca4-[11.3,14.9): 0.9800 - val_ca1-[8.0,9.5): 1.0277 - val_ca1-[9.5,10.3): 1.0776 - val_ca1-[10.3,11.3): 2.0778 - val_ca1-[11.3,14.9): 3.5252 - val_ca2-[8.0,9.5): 0.5810 - val_ca2-[9.5,10.3): 0.4243 - val_ca2-[10.3,11.3): 0.9252 - val_ca2-[11.3,14.9): 1.6357 - val_ca3-[8.0,9.5): 0.7572 - val_ca3-[9.5,10.3): 0.4929 - val_ca3-[10.3,11.3): 0.7339 - val_ca3-[11.3,14.9): 1.0610 - val_ca4-[8.0,9.5): 0.8090 - val_ca4-[9.5,10.3): 0.5282 - val_ca4-[10.3,11.3): 0.7294 - val_ca4-[11.3,14.9): 0.9975\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 1.0296 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3568 - ca2-[9.5,10.3): 0.5207 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5270 - ca3-[10.3,11.3): 0.7310 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6560 - ca4-[11.3,14.9): 0.9653 - val_ca1-[8.0,9.5): 0.9800 - val_ca1-[9.5,10.3): 1.0193 - val_ca1-[10.3,11.3): 2.0050 - val_ca1-[11.3,14.9): 3.3961 - val_ca2-[8.0,9.5): 0.5816 - val_ca2-[9.5,10.3): 0.4232 - val_ca2-[10.3,11.3): 0.9266 - val_ca2-[11.3,14.9): 1.5961 - val_ca3-[8.0,9.5): 0.7643 - val_ca3-[9.5,10.3): 0.4976 - val_ca3-[10.3,11.3): 0.7371 - val_ca3-[11.3,14.9): 1.0119 - val_ca4-[8.0,9.5): 0.8370 - val_ca4-[9.5,10.3): 0.5481 - val_ca4-[10.3,11.3): 0.7333 - val_ca4-[11.3,14.9): 0.9269\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.9804 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3733 - ca2-[9.5,10.3): 0.5236 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5194 - ca3-[10.3,11.3): 0.7213 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6271 - ca4-[11.3,14.9): 0.9380 - val_ca1-[8.0,9.5): 0.9359 - val_ca1-[9.5,10.3): 0.9650 - val_ca1-[10.3,11.3): 1.9256 - val_ca1-[11.3,14.9): 3.2881 - val_ca2-[8.0,9.5): 0.5822 - val_ca2-[9.5,10.3): 0.4223 - val_ca2-[10.3,11.3): 0.9219 - val_ca2-[11.3,14.9): 1.6142 - val_ca3-[8.0,9.5): 0.7707 - val_ca3-[9.5,10.3): 0.5019 - val_ca3-[10.3,11.3): 0.7362 - val_ca3-[11.3,14.9): 1.0428 - val_ca4-[8.0,9.5): 0.8650 - val_ca4-[9.5,10.3): 0.5684 - val_ca4-[10.3,11.3): 0.7348 - val_ca4-[11.3,14.9): 0.9427\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.9069 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3786 - ca2-[9.5,10.3): 0.5188 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5254 - ca3-[10.3,11.3): 0.7232 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5860 - ca4-[11.3,14.9): 0.8853 - val_ca1-[8.0,9.5): 0.8955 - val_ca1-[9.5,10.3): 0.9145 - val_ca1-[10.3,11.3): 1.8549 - val_ca1-[11.3,14.9): 3.1734 - val_ca2-[8.0,9.5): 0.5829 - val_ca2-[9.5,10.3): 0.4215 - val_ca2-[10.3,11.3): 0.9178 - val_ca2-[11.3,14.9): 1.5923 - val_ca3-[8.0,9.5): 0.7765 - val_ca3-[9.5,10.3): 0.5058 - val_ca3-[10.3,11.3): 0.7334 - val_ca3-[11.3,14.9): 1.0182 - val_ca4-[8.0,9.5): 0.8929 - val_ca4-[9.5,10.3): 0.5889 - val_ca4-[10.3,11.3): 0.7347 - val_ca4-[11.3,14.9): 0.9008\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.8990 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3708 - ca2-[9.5,10.3): 0.5181 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5306 - ca3-[10.3,11.3): 0.7420 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5995 - ca4-[11.3,14.9): 0.8661 - val_ca1-[8.0,9.5): 0.8587 - val_ca1-[9.5,10.3): 0.8681 - val_ca1-[10.3,11.3): 1.7791 - val_ca1-[11.3,14.9): 3.0475 - val_ca2-[8.0,9.5): 0.5835 - val_ca2-[9.5,10.3): 0.4208 - val_ca2-[10.3,11.3): 0.9117 - val_ca2-[11.3,14.9): 1.5705 - val_ca3-[8.0,9.5): 0.7816 - val_ca3-[9.5,10.3): 0.5092 - val_ca3-[10.3,11.3): 0.7327 - val_ca3-[11.3,14.9): 1.0034 - val_ca4-[8.0,9.5): 0.9211 - val_ca4-[9.5,10.3): 0.6101 - val_ca4-[10.3,11.3): 0.7391 - val_ca4-[11.3,14.9): 0.8726\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.8296 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3884 - ca2-[9.5,10.3): 0.5148 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5229 - ca3-[10.3,11.3): 0.7172 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5629 - ca4-[11.3,14.9): 0.8374 - val_ca1-[8.0,9.5): 0.8254 - val_ca1-[9.5,10.3): 0.8255 - val_ca1-[10.3,11.3): 1.7137 - val_ca1-[11.3,14.9): 2.9580 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.4202 - val_ca2-[10.3,11.3): 0.9081 - val_ca2-[11.3,14.9): 1.5752 - val_ca3-[8.0,9.5): 0.7864 - val_ca3-[9.5,10.3): 0.5125 - val_ca3-[10.3,11.3): 0.7323 - val_ca3-[11.3,14.9): 1.0126 - val_ca4-[8.0,9.5): 0.9493 - val_ca4-[9.5,10.3): 0.6315 - val_ca4-[10.3,11.3): 0.7439 - val_ca4-[11.3,14.9): 0.8694\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 1s 150ms/step - ca1-[8.0,9.5): 0.8150 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3585 - ca2-[9.5,10.3): 0.5157 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5431 - ca3-[10.3,11.3): 0.7275 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5433 - ca4-[11.3,14.9): 0.8312 - val_ca1-[8.0,9.5): 0.7955 - val_ca1-[9.5,10.3): 0.7866 - val_ca1-[10.3,11.3): 1.6530 - val_ca1-[11.3,14.9): 2.8188 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.4198 - val_ca2-[10.3,11.3): 0.9058 - val_ca2-[11.3,14.9): 1.5370 - val_ca3-[8.0,9.5): 0.7911 - val_ca3-[9.5,10.3): 0.5157 - val_ca3-[10.3,11.3): 0.7319 - val_ca3-[11.3,14.9): 0.9840 - val_ca4-[8.0,9.5): 0.9773 - val_ca4-[9.5,10.3): 0.6530 - val_ca4-[10.3,11.3): 0.7496 - val_ca4-[11.3,14.9): 0.8335\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.7605 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3795 - ca2-[9.5,10.3): 0.5240 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5180 - ca3-[10.3,11.3): 0.7013 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5537 - ca4-[11.3,14.9): 0.7988 - val_ca1-[8.0,9.5): 0.7689 - val_ca1-[9.5,10.3): 0.7504 - val_ca1-[10.3,11.3): 1.6038 - val_ca1-[11.3,14.9): 2.7332 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.4199 - val_ca2-[10.3,11.3): 0.9075 - val_ca2-[11.3,14.9): 1.5303 - val_ca3-[8.0,9.5): 0.7956 - val_ca3-[9.5,10.3): 0.5205 - val_ca3-[10.3,11.3): 0.7338 - val_ca3-[11.3,14.9): 0.9769 - val_ca4-[8.0,9.5): 1.0052 - val_ca4-[9.5,10.3): 0.6769 - val_ca4-[10.3,11.3): 0.7573 - val_ca4-[11.3,14.9): 0.8162\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.7441 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3893 - ca2-[9.5,10.3): 0.5270 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5152 - ca3-[10.3,11.3): 0.7198 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5067 - ca4-[11.3,14.9): 0.8021 - val_ca1-[8.0,9.5): 0.7449 - val_ca1-[9.5,10.3): 0.7194 - val_ca1-[10.3,11.3): 1.5216 - val_ca1-[11.3,14.9): 2.7061 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.4190 - val_ca2-[10.3,11.3): 0.8838 - val_ca2-[11.3,14.9): 1.5596 - val_ca3-[8.0,9.5): 0.7998 - val_ca3-[9.5,10.3): 0.5217 - val_ca3-[10.3,11.3): 0.7193 - val_ca3-[11.3,14.9): 0.9924 - val_ca4-[8.0,9.5): 1.0320 - val_ca4-[9.5,10.3): 0.6956 - val_ca4-[10.3,11.3): 0.7535 - val_ca4-[11.3,14.9): 0.8158\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.7297 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3726 - ca2-[9.5,10.3): 0.5081 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5350 - ca3-[10.3,11.3): 0.7172 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5626 - ca4-[11.3,14.9): 0.7940 - val_ca1-[8.0,9.5): 0.7236 - val_ca1-[9.5,10.3): 0.6902 - val_ca1-[10.3,11.3): 1.5003 - val_ca1-[11.3,14.9): 2.6279 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.4187 - val_ca2-[10.3,11.3): 0.9024 - val_ca2-[11.3,14.9): 1.5501 - val_ca3-[8.0,9.5): 0.8034 - val_ca3-[9.5,10.3): 0.5242 - val_ca3-[10.3,11.3): 0.7357 - val_ca3-[11.3,14.9): 0.9829 - val_ca4-[8.0,9.5): 1.0581 - val_ca4-[9.5,10.3): 0.7163 - val_ca4-[10.3,11.3): 0.7748 - val_ca4-[11.3,14.9): 0.7970\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.7081 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3803 - ca2-[9.5,10.3): 0.5161 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5476 - ca3-[10.3,11.3): 0.7271 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4801 - ca4-[11.3,14.9): 0.7792 - val_ca1-[8.0,9.5): 0.7046 - val_ca1-[9.5,10.3): 0.6639 - val_ca1-[10.3,11.3): 1.4375 - val_ca1-[11.3,14.9): 2.5258 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.4184 - val_ca2-[10.3,11.3): 0.8878 - val_ca2-[11.3,14.9): 1.5263 - val_ca3-[8.0,9.5): 0.8065 - val_ca3-[9.5,10.3): 0.5264 - val_ca3-[10.3,11.3): 0.7276 - val_ca3-[11.3,14.9): 0.9696 - val_ca4-[8.0,9.5): 1.0836 - val_ca4-[9.5,10.3): 0.7365 - val_ca4-[10.3,11.3): 0.7774 - val_ca4-[11.3,14.9): 0.7821\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.6620 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3622 - ca2-[9.5,10.3): 0.5080 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5023 - ca3-[10.3,11.3): 0.7012 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5738 - ca4-[11.3,14.9): 0.7786 - val_ca1-[8.0,9.5): 0.6877 - val_ca1-[9.5,10.3): 0.6398 - val_ca1-[10.3,11.3): 1.3886 - val_ca1-[11.3,14.9): 2.4554 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.4182 - val_ca2-[10.3,11.3): 0.8783 - val_ca2-[11.3,14.9): 1.5207 - val_ca3-[8.0,9.5): 0.8091 - val_ca3-[9.5,10.3): 0.5282 - val_ca3-[10.3,11.3): 0.7191 - val_ca3-[11.3,14.9): 0.9657 - val_ca4-[8.0,9.5): 1.1086 - val_ca4-[9.5,10.3): 0.7565 - val_ca4-[10.3,11.3): 0.7767 - val_ca4-[11.3,14.9): 0.7724\n",
      "Epoch 65/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.6637 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3780 - ca2-[9.5,10.3): 0.5080 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5465 - ca3-[10.3,11.3): 0.7225 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5251 - ca4-[11.3,14.9): 0.7551 - val_ca1-[8.0,9.5): 0.6728 - val_ca1-[9.5,10.3): 0.6183 - val_ca1-[10.3,11.3): 1.3732 - val_ca1-[11.3,14.9): 2.4033 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.4180 - val_ca2-[10.3,11.3): 0.8938 - val_ca2-[11.3,14.9): 1.5238 - val_ca3-[8.0,9.5): 0.8118 - val_ca3-[9.5,10.3): 0.5301 - val_ca3-[10.3,11.3): 0.7309 - val_ca3-[11.3,14.9): 0.9669 - val_ca4-[8.0,9.5): 1.1330 - val_ca4-[9.5,10.3): 0.7762 - val_ca4-[10.3,11.3): 0.7934 - val_ca4-[11.3,14.9): 0.7662\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.6292 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3692 - ca2-[9.5,10.3): 0.5203 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5412 - ca3-[10.3,11.3): 0.7093 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5472 - ca4-[11.3,14.9): 0.7362 - val_ca1-[8.0,9.5): 0.6598 - val_ca1-[9.5,10.3): 0.5989 - val_ca1-[10.3,11.3): 1.3334 - val_ca1-[11.3,14.9): 2.3435 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.4178 - val_ca2-[10.3,11.3): 0.8859 - val_ca2-[11.3,14.9): 1.5083 - val_ca3-[8.0,9.5): 0.8142 - val_ca3-[9.5,10.3): 0.5318 - val_ca3-[10.3,11.3): 0.7226 - val_ca3-[11.3,14.9): 0.9417 - val_ca4-[8.0,9.5): 1.1565 - val_ca4-[9.5,10.3): 0.7952 - val_ca4-[10.3,11.3): 0.7920 - val_ca4-[11.3,14.9): 0.7288\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.6274 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3847 - ca2-[9.5,10.3): 0.5151 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5575 - ca3-[10.3,11.3): 0.7108 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4826 - ca4-[11.3,14.9): 0.7420 - val_ca1-[8.0,9.5): 0.6483 - val_ca1-[9.5,10.3): 0.5815 - val_ca1-[10.3,11.3): 1.3080 - val_ca1-[11.3,14.9): 2.3045 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.4177 - val_ca2-[10.3,11.3): 0.8934 - val_ca2-[11.3,14.9): 1.5250 - val_ca3-[8.0,9.5): 0.8164 - val_ca3-[9.5,10.3): 0.5333 - val_ca3-[10.3,11.3): 0.7330 - val_ca3-[11.3,14.9): 0.9636 - val_ca4-[8.0,9.5): 1.1793 - val_ca4-[9.5,10.3): 0.8137 - val_ca4-[10.3,11.3): 0.8119 - val_ca4-[11.3,14.9): 0.7496\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.6294 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3823 - ca2-[9.5,10.3): 0.5268 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5345 - ca3-[10.3,11.3): 0.7249 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5086 - ca4-[11.3,14.9): 0.7410 - val_ca1-[8.0,9.5): 0.6383 - val_ca1-[9.5,10.3): 0.5658 - val_ca1-[10.3,11.3): 1.2729 - val_ca1-[11.3,14.9): 2.2271 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.4176 - val_ca2-[10.3,11.3): 0.8875 - val_ca2-[11.3,14.9): 1.5038 - val_ca3-[8.0,9.5): 0.8178 - val_ca3-[9.5,10.3): 0.5343 - val_ca3-[10.3,11.3): 0.7294 - val_ca3-[11.3,14.9): 0.9539 - val_ca4-[8.0,9.5): 1.2018 - val_ca4-[9.5,10.3): 0.8321 - val_ca4-[10.3,11.3): 0.8175 - val_ca4-[11.3,14.9): 0.7431\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5994 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3653 - ca2-[9.5,10.3): 0.5211 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5455 - ca3-[10.3,11.3): 0.6940 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5437 - ca4-[11.3,14.9): 0.7311 - val_ca1-[8.0,9.5): 0.6296 - val_ca1-[9.5,10.3): 0.5512 - val_ca1-[10.3,11.3): 1.2229 - val_ca1-[11.3,14.9): 2.1772 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4180 - val_ca2-[10.3,11.3): 0.8660 - val_ca2-[11.3,14.9): 1.4902 - val_ca3-[8.0,9.5): 0.8200 - val_ca3-[9.5,10.3): 0.5375 - val_ca3-[10.3,11.3): 0.7106 - val_ca3-[11.3,14.9): 0.9291 - val_ca4-[8.0,9.5): 1.2230 - val_ca4-[9.5,10.3): 0.8522 - val_ca4-[10.3,11.3): 0.8085 - val_ca4-[11.3,14.9): 0.7074\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5810 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3774 - ca2-[9.5,10.3): 0.5136 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5450 - ca3-[10.3,11.3): 0.7253 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5159 - ca4-[11.3,14.9): 0.7343 - val_ca1-[8.0,9.5): 0.6219 - val_ca1-[9.5,10.3): 0.5389 - val_ca1-[10.3,11.3): 1.2262 - val_ca1-[11.3,14.9): 2.1566 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4174 - val_ca2-[10.3,11.3): 0.8912 - val_ca2-[11.3,14.9): 1.5159 - val_ca3-[8.0,9.5): 0.8214 - val_ca3-[9.5,10.3): 0.5368 - val_ca3-[10.3,11.3): 0.7329 - val_ca3-[11.3,14.9): 0.9602 - val_ca4-[8.0,9.5): 1.2436 - val_ca4-[9.5,10.3): 0.8664 - val_ca4-[10.3,11.3): 0.8363 - val_ca4-[11.3,14.9): 0.7396\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 1s 148ms/step - ca1-[8.0,9.5): 0.5891 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3920 - ca2-[9.5,10.3): 0.5219 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5431 - ca3-[10.3,11.3): 0.7248 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5487 - ca4-[11.3,14.9): 0.7167 - val_ca1-[8.0,9.5): 0.6151 - val_ca1-[9.5,10.3): 0.5271 - val_ca1-[10.3,11.3): 1.2043 - val_ca1-[11.3,14.9): 2.1220 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.4174 - val_ca2-[10.3,11.3): 0.8908 - val_ca2-[11.3,14.9): 1.5213 - val_ca3-[8.0,9.5): 0.8226 - val_ca3-[9.5,10.3): 0.5377 - val_ca3-[10.3,11.3): 0.7305 - val_ca3-[11.3,14.9): 0.9654 - val_ca4-[8.0,9.5): 1.2630 - val_ca4-[9.5,10.3): 0.8824 - val_ca4-[10.3,11.3): 0.8395 - val_ca4-[11.3,14.9): 0.7419\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 1s 148ms/step - ca1-[8.0,9.5): 0.5719 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3792 - ca2-[9.5,10.3): 0.5214 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5439 - ca3-[10.3,11.3): 0.7078 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5085 - ca4-[11.3,14.9): 0.7161 - val_ca1-[8.0,9.5): 0.6092 - val_ca1-[9.5,10.3): 0.5167 - val_ca1-[10.3,11.3): 1.1699 - val_ca1-[11.3,14.9): 2.0643 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4173 - val_ca2-[10.3,11.3): 0.8833 - val_ca2-[11.3,14.9): 1.5045 - val_ca3-[8.0,9.5): 0.8237 - val_ca3-[9.5,10.3): 0.5384 - val_ca3-[10.3,11.3): 0.7320 - val_ca3-[11.3,14.9): 0.9555 - val_ca4-[8.0,9.5): 1.2818 - val_ca4-[9.5,10.3): 0.8980 - val_ca4-[10.3,11.3): 0.8558 - val_ca4-[11.3,14.9): 0.7352\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5672 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3633 - ca2-[9.5,10.3): 0.5248 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5344 - ca3-[10.3,11.3): 0.7018 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5716 - ca4-[11.3,14.9): 0.7165 - val_ca1-[8.0,9.5): 0.6042 - val_ca1-[9.5,10.3): 0.5073 - val_ca1-[10.3,11.3): 1.1580 - val_ca1-[11.3,14.9): 2.0705 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4172 - val_ca2-[10.3,11.3): 0.8873 - val_ca2-[11.3,14.9): 1.5341 - val_ca3-[8.0,9.5): 0.8249 - val_ca3-[9.5,10.3): 0.5393 - val_ca3-[10.3,11.3): 0.7311 - val_ca3-[11.3,14.9): 0.9692 - val_ca4-[8.0,9.5): 1.2996 - val_ca4-[9.5,10.3): 0.9127 - val_ca4-[10.3,11.3): 0.8578 - val_ca4-[11.3,14.9): 0.7331\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5764 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3726 - ca2-[9.5,10.3): 0.5203 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5704 - ca3-[10.3,11.3): 0.7269 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5682 - ca4-[11.3,14.9): 0.7061 - val_ca1-[8.0,9.5): 0.5998 - val_ca1-[9.5,10.3): 0.4988 - val_ca1-[10.3,11.3): 1.1344 - val_ca1-[11.3,14.9): 2.0195 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4172 - val_ca2-[10.3,11.3): 0.8832 - val_ca2-[11.3,14.9): 1.5163 - val_ca3-[8.0,9.5): 0.8260 - val_ca3-[9.5,10.3): 0.5400 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9510 - val_ca4-[8.0,9.5): 1.3165 - val_ca4-[9.5,10.3): 0.9268 - val_ca4-[10.3,11.3): 0.8646 - val_ca4-[11.3,14.9): 0.7134\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5666 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3772 - ca2-[9.5,10.3): 0.5061 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5484 - ca3-[10.3,11.3): 0.7169 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5410 - ca4-[11.3,14.9): 0.7162 - val_ca1-[8.0,9.5): 0.5960 - val_ca1-[9.5,10.3): 0.4911 - val_ca1-[10.3,11.3): 1.1006 - val_ca1-[11.3,14.9): 1.9679 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4172 - val_ca2-[10.3,11.3): 0.8694 - val_ca2-[11.3,14.9): 1.5003 - val_ca3-[8.0,9.5): 0.8272 - val_ca3-[9.5,10.3): 0.5409 - val_ca3-[10.3,11.3): 0.7218 - val_ca3-[11.3,14.9): 0.9449 - val_ca4-[8.0,9.5): 1.3327 - val_ca4-[9.5,10.3): 0.9403 - val_ca4-[10.3,11.3): 0.8699 - val_ca4-[11.3,14.9): 0.7148\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5445 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3860 - ca2-[9.5,10.3): 0.5094 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5459 - ca3-[10.3,11.3): 0.7205 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.4915 - ca4-[11.3,14.9): 0.6965 - val_ca1-[8.0,9.5): 0.5928 - val_ca1-[9.5,10.3): 0.4842 - val_ca1-[10.3,11.3): 1.1073 - val_ca1-[11.3,14.9): 1.9024 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8862 - val_ca2-[11.3,14.9): 1.4678 - val_ca3-[8.0,9.5): 0.8286 - val_ca3-[9.5,10.3): 0.5419 - val_ca3-[10.3,11.3): 0.7306 - val_ca3-[11.3,14.9): 0.9234 - val_ca4-[8.0,9.5): 1.3482 - val_ca4-[9.5,10.3): 0.9533 - val_ca4-[10.3,11.3): 0.8773 - val_ca4-[11.3,14.9): 0.7029\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 1s 151ms/step - ca1-[8.0,9.5): 0.5338 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3706 - ca2-[9.5,10.3): 0.4980 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5665 - ca3-[10.3,11.3): 0.7203 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5404 - ca4-[11.3,14.9): 0.7190 - val_ca1-[8.0,9.5): 0.5901 - val_ca1-[9.5,10.3): 0.4781 - val_ca1-[10.3,11.3): 1.0928 - val_ca1-[11.3,14.9): 1.9062 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8857 - val_ca2-[11.3,14.9): 1.4927 - val_ca3-[8.0,9.5): 0.8292 - val_ca3-[9.5,10.3): 0.5422 - val_ca3-[10.3,11.3): 0.7306 - val_ca3-[11.3,14.9): 0.9411 - val_ca4-[8.0,9.5): 1.3627 - val_ca4-[9.5,10.3): 0.9654 - val_ca4-[10.3,11.3): 0.8837 - val_ca4-[11.3,14.9): 0.7120\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5431 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3598 - ca2-[9.5,10.3): 0.5170 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5403 - ca3-[10.3,11.3): 0.7066 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5455 - ca4-[11.3,14.9): 0.6895 - val_ca1-[8.0,9.5): 0.5878 - val_ca1-[9.5,10.3): 0.4725 - val_ca1-[10.3,11.3): 1.0811 - val_ca1-[11.3,14.9): 1.9038 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8875 - val_ca2-[11.3,14.9): 1.5140 - val_ca3-[8.0,9.5): 0.8296 - val_ca3-[9.5,10.3): 0.5425 - val_ca3-[10.3,11.3): 0.7328 - val_ca3-[11.3,14.9): 0.9608 - val_ca4-[8.0,9.5): 1.3763 - val_ca4-[9.5,10.3): 0.9768 - val_ca4-[10.3,11.3): 0.8922 - val_ca4-[11.3,14.9): 0.7291\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5473 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3815 - ca2-[9.5,10.3): 0.5170 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5454 - ca3-[10.3,11.3): 0.7129 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5619 - ca4-[11.3,14.9): 0.7113 - val_ca1-[8.0,9.5): 0.5859 - val_ca1-[9.5,10.3): 0.4675 - val_ca1-[10.3,11.3): 1.0715 - val_ca1-[11.3,14.9): 1.8942 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8891 - val_ca2-[11.3,14.9): 1.5198 - val_ca3-[8.0,9.5): 0.8307 - val_ca3-[9.5,10.3): 0.5433 - val_ca3-[10.3,11.3): 0.7326 - val_ca3-[11.3,14.9): 0.9509 - val_ca4-[8.0,9.5): 1.3895 - val_ca4-[9.5,10.3): 0.9878 - val_ca4-[10.3,11.3): 0.8957 - val_ca4-[11.3,14.9): 0.7035\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5374 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3789 - ca2-[9.5,10.3): 0.5158 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5504 - ca3-[10.3,11.3): 0.7182 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5230 - ca4-[11.3,14.9): 0.7050 - val_ca1-[8.0,9.5): 0.5843 - val_ca1-[9.5,10.3): 0.4642 - val_ca1-[10.3,11.3): 1.0494 - val_ca1-[11.3,14.9): 1.8611 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4176 - val_ca2-[10.3,11.3): 0.8811 - val_ca2-[11.3,14.9): 1.5138 - val_ca3-[8.0,9.5): 0.8310 - val_ca3-[9.5,10.3): 0.5427 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9543 - val_ca4-[8.0,9.5): 1.4020 - val_ca4-[9.5,10.3): 0.9961 - val_ca4-[10.3,11.3): 0.9026 - val_ca4-[11.3,14.9): 0.7161\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5246 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3801 - ca2-[9.5,10.3): 0.5241 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5473 - ca3-[10.3,11.3): 0.7179 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5559 - ca4-[11.3,14.9): 0.6907 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4589 - val_ca1-[10.3,11.3): 1.0462 - val_ca1-[11.3,14.9): 1.8453 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8873 - val_ca2-[11.3,14.9): 1.5139 - val_ca3-[8.0,9.5): 0.8316 - val_ca3-[9.5,10.3): 0.5440 - val_ca3-[10.3,11.3): 0.7327 - val_ca3-[11.3,14.9): 0.9434 - val_ca4-[8.0,9.5): 1.4130 - val_ca4-[9.5,10.3): 1.0077 - val_ca4-[10.3,11.3): 0.9088 - val_ca4-[11.3,14.9): 0.6943\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5428 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3845 - ca2-[9.5,10.3): 0.5139 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5137 - ca3-[10.3,11.3): 0.7129 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5349 - ca4-[11.3,14.9): 0.6891 - val_ca1-[8.0,9.5): 0.5818 - val_ca1-[9.5,10.3): 0.4552 - val_ca1-[10.3,11.3): 1.0427 - val_ca1-[11.3,14.9): 1.8350 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8932 - val_ca2-[11.3,14.9): 1.5222 - val_ca3-[8.0,9.5): 0.8320 - val_ca3-[9.5,10.3): 0.5442 - val_ca3-[10.3,11.3): 0.7371 - val_ca3-[11.3,14.9): 0.9503 - val_ca4-[8.0,9.5): 1.4241 - val_ca4-[9.5,10.3): 1.0170 - val_ca4-[10.3,11.3): 0.9166 - val_ca4-[11.3,14.9): 0.6989\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 1s 149ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3749 - ca2-[9.5,10.3): 0.5084 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5586 - ca3-[10.3,11.3): 0.7187 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5361 - ca4-[11.3,14.9): 0.7022 - val_ca1-[8.0,9.5): 0.5810 - val_ca1-[9.5,10.3): 0.4518 - val_ca1-[10.3,11.3): 1.0140 - val_ca1-[11.3,14.9): 1.7672 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8769 - val_ca2-[11.3,14.9): 1.4795 - val_ca3-[8.0,9.5): 0.8321 - val_ca3-[9.5,10.3): 0.5443 - val_ca3-[10.3,11.3): 0.7274 - val_ca3-[11.3,14.9): 0.9225 - val_ca4-[8.0,9.5): 1.4343 - val_ca4-[9.5,10.3): 1.0256 - val_ca4-[10.3,11.3): 0.9190 - val_ca4-[11.3,14.9): 0.6870\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5320 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3382 - ca2-[9.5,10.3): 0.5190 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5620 - ca3-[10.3,11.3): 0.7326 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5749 - ca4-[11.3,14.9): 0.6931 - val_ca1-[8.0,9.5): 0.5803 - val_ca1-[9.5,10.3): 0.4489 - val_ca1-[10.3,11.3): 1.0162 - val_ca1-[11.3,14.9): 1.8190 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8859 - val_ca2-[11.3,14.9): 1.5450 - val_ca3-[8.0,9.5): 0.8322 - val_ca3-[9.5,10.3): 0.5443 - val_ca3-[10.3,11.3): 0.7304 - val_ca3-[11.3,14.9): 0.9766 - val_ca4-[8.0,9.5): 1.4437 - val_ca4-[9.5,10.3): 1.0335 - val_ca4-[10.3,11.3): 0.9205 - val_ca4-[11.3,14.9): 0.7296\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3511 - ca2-[9.5,10.3): 0.5100 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5385 - ca3-[10.3,11.3): 0.7177 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5583 - ca4-[11.3,14.9): 0.7059 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4463 - val_ca1-[10.3,11.3): 1.0132 - val_ca1-[11.3,14.9): 1.7581 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8902 - val_ca2-[11.3,14.9): 1.5028 - val_ca3-[8.0,9.5): 0.8320 - val_ca3-[9.5,10.3): 0.5441 - val_ca3-[10.3,11.3): 0.7324 - val_ca3-[11.3,14.9): 0.9427 - val_ca4-[8.0,9.5): 1.4525 - val_ca4-[9.5,10.3): 1.0410 - val_ca4-[10.3,11.3): 0.9246 - val_ca4-[11.3,14.9): 0.7043\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5311 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3915 - ca2-[9.5,10.3): 0.5197 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5344 - ca3-[10.3,11.3): 0.7214 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5245 - ca4-[11.3,14.9): 0.6987 - val_ca1-[8.0,9.5): 0.5794 - val_ca1-[9.5,10.3): 0.4439 - val_ca1-[10.3,11.3): 0.9988 - val_ca1-[11.3,14.9): 1.7928 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8818 - val_ca2-[11.3,14.9): 1.5474 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5443 - val_ca3-[10.3,11.3): 0.7214 - val_ca3-[11.3,14.9): 0.9771 - val_ca4-[8.0,9.5): 1.4608 - val_ca4-[9.5,10.3): 1.0480 - val_ca4-[10.3,11.3): 0.9144 - val_ca4-[11.3,14.9): 0.7274\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5223 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3814 - ca2-[9.5,10.3): 0.5257 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5462 - ca3-[10.3,11.3): 0.7008 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5203 - ca4-[11.3,14.9): 0.6912 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4418 - val_ca1-[10.3,11.3): 0.9897 - val_ca1-[11.3,14.9): 1.7454 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8812 - val_ca2-[11.3,14.9): 1.5119 - val_ca3-[8.0,9.5): 0.8325 - val_ca3-[9.5,10.3): 0.5444 - val_ca3-[10.3,11.3): 0.7288 - val_ca3-[11.3,14.9): 0.9413 - val_ca4-[8.0,9.5): 1.4685 - val_ca4-[9.5,10.3): 1.0545 - val_ca4-[10.3,11.3): 0.9337 - val_ca4-[11.3,14.9): 0.6901\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5193 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3755 - ca2-[9.5,10.3): 0.5104 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5431 - ca3-[10.3,11.3): 0.7181 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5667 - ca4-[11.3,14.9): 0.7037 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4398 - val_ca1-[10.3,11.3): 0.9875 - val_ca1-[11.3,14.9): 1.7325 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8833 - val_ca2-[11.3,14.9): 1.5119 - val_ca3-[8.0,9.5): 0.8328 - val_ca3-[9.5,10.3): 0.5447 - val_ca3-[10.3,11.3): 0.7235 - val_ca3-[11.3,14.9): 0.9410 - val_ca4-[8.0,9.5): 1.4761 - val_ca4-[9.5,10.3): 1.0610 - val_ca4-[10.3,11.3): 0.9241 - val_ca4-[11.3,14.9): 0.6896\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5353 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3735 - ca2-[9.5,10.3): 0.5135 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5764 - ca3-[10.3,11.3): 0.7416 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5650 - ca4-[11.3,14.9): 0.6938 - val_ca1-[8.0,9.5): 0.5788 - val_ca1-[9.5,10.3): 0.4380 - val_ca1-[10.3,11.3): 0.9824 - val_ca1-[11.3,14.9): 1.7165 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8860 - val_ca2-[11.3,14.9): 1.5129 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5449 - val_ca3-[10.3,11.3): 0.7302 - val_ca3-[11.3,14.9): 0.9533 - val_ca4-[8.0,9.5): 1.4828 - val_ca4-[9.5,10.3): 1.0667 - val_ca4-[10.3,11.3): 0.9390 - val_ca4-[11.3,14.9): 0.7163\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5304 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3800 - ca2-[9.5,10.3): 0.5088 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5515 - ca3-[10.3,11.3): 0.7358 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5684 - ca4-[11.3,14.9): 0.7026 - val_ca1-[8.0,9.5): 0.5787 - val_ca1-[9.5,10.3): 0.4364 - val_ca1-[10.3,11.3): 0.9587 - val_ca1-[11.3,14.9): 1.6670 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8693 - val_ca2-[11.3,14.9): 1.4745 - val_ca3-[8.0,9.5): 0.8333 - val_ca3-[9.5,10.3): 0.5450 - val_ca3-[10.3,11.3): 0.7186 - val_ca3-[11.3,14.9): 0.9145 - val_ca4-[8.0,9.5): 1.4892 - val_ca4-[9.5,10.3): 1.0721 - val_ca4-[10.3,11.3): 0.9365 - val_ca4-[11.3,14.9): 0.6774\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5188 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3805 - ca2-[9.5,10.3): 0.5179 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5450 - ca3-[10.3,11.3): 0.7150 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5854 - ca4-[11.3,14.9): 0.6957 - val_ca1-[8.0,9.5): 0.5787 - val_ca1-[9.5,10.3): 0.4349 - val_ca1-[10.3,11.3): 0.9671 - val_ca1-[11.3,14.9): 1.6364 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4171 - val_ca2-[10.3,11.3): 0.8819 - val_ca2-[11.3,14.9): 1.4551 - val_ca3-[8.0,9.5): 0.8337 - val_ca3-[9.5,10.3): 0.5452 - val_ca3-[10.3,11.3): 0.7286 - val_ca3-[11.3,14.9): 0.8999 - val_ca4-[8.0,9.5): 1.4952 - val_ca4-[9.5,10.3): 1.0772 - val_ca4-[10.3,11.3): 0.9467 - val_ca4-[11.3,14.9): 0.6687\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5067 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3689 - ca2-[9.5,10.3): 0.5114 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5293 - ca3-[10.3,11.3): 0.7288 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5524 - ca4-[11.3,14.9): 0.6916 - val_ca1-[8.0,9.5): 0.5788 - val_ca1-[9.5,10.3): 0.4337 - val_ca1-[10.3,11.3): 0.9626 - val_ca1-[11.3,14.9): 1.6680 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8817 - val_ca2-[11.3,14.9): 1.4936 - val_ca3-[8.0,9.5): 0.8337 - val_ca3-[9.5,10.3): 0.5452 - val_ca3-[10.3,11.3): 0.7285 - val_ca3-[11.3,14.9): 0.9307 - val_ca4-[8.0,9.5): 1.5006 - val_ca4-[9.5,10.3): 1.0818 - val_ca4-[10.3,11.3): 0.9493 - val_ca4-[11.3,14.9): 0.6908\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5111 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3909 - ca2-[9.5,10.3): 0.5190 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5551 - ca3-[10.3,11.3): 0.7094 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5605 - ca4-[11.3,14.9): 0.6813 - val_ca1-[8.0,9.5): 0.5789 - val_ca1-[9.5,10.3): 0.4325 - val_ca1-[10.3,11.3): 0.9550 - val_ca1-[11.3,14.9): 1.7010 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8776 - val_ca2-[11.3,14.9): 1.5349 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5448 - val_ca3-[10.3,11.3): 0.7196 - val_ca3-[11.3,14.9): 0.9682 - val_ca4-[8.0,9.5): 1.5060 - val_ca4-[9.5,10.3): 1.0864 - val_ca4-[10.3,11.3): 0.9375 - val_ca4-[11.3,14.9): 0.7228\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5256 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3892 - ca2-[9.5,10.3): 0.5292 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5781 - ca3-[10.3,11.3): 0.7270 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5054 - ca4-[11.3,14.9): 0.6971 - val_ca1-[8.0,9.5): 0.5790 - val_ca1-[9.5,10.3): 0.4314 - val_ca1-[10.3,11.3): 0.9543 - val_ca1-[11.3,14.9): 1.6842 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4170 - val_ca2-[10.3,11.3): 0.8811 - val_ca2-[11.3,14.9): 1.5246 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5448 - val_ca3-[10.3,11.3): 0.7285 - val_ca3-[11.3,14.9): 0.9583 - val_ca4-[8.0,9.5): 1.5114 - val_ca4-[9.5,10.3): 1.0910 - val_ca4-[10.3,11.3): 0.9546 - val_ca4-[11.3,14.9): 0.7116\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5190 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3797 - ca2-[9.5,10.3): 0.5178 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5477 - ca3-[10.3,11.3): 0.7229 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5251 - ca4-[11.3,14.9): 0.6753 - val_ca1-[8.0,9.5): 0.5791 - val_ca1-[9.5,10.3): 0.4304 - val_ca1-[10.3,11.3): 0.9575 - val_ca1-[11.3,14.9): 1.6698 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8871 - val_ca2-[11.3,14.9): 1.5174 - val_ca3-[8.0,9.5): 0.8339 - val_ca3-[9.5,10.3): 0.5453 - val_ca3-[10.3,11.3): 0.7322 - val_ca3-[11.3,14.9): 0.9536 - val_ca4-[8.0,9.5): 1.5159 - val_ca4-[9.5,10.3): 1.0948 - val_ca4-[10.3,11.3): 0.9576 - val_ca4-[11.3,14.9): 0.7105\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5186 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3590 - ca2-[9.5,10.3): 0.5157 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5393 - ca3-[10.3,11.3): 0.7039 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5299 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5793 - val_ca1-[9.5,10.3): 0.4296 - val_ca1-[10.3,11.3): 0.9474 - val_ca1-[11.3,14.9): 1.6569 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8808 - val_ca2-[11.3,14.9): 1.5111 - val_ca3-[8.0,9.5): 0.8352 - val_ca3-[9.5,10.3): 0.5462 - val_ca3-[10.3,11.3): 0.7285 - val_ca3-[11.3,14.9): 0.9433 - val_ca4-[8.0,9.5): 1.5201 - val_ca4-[9.5,10.3): 1.0984 - val_ca4-[10.3,11.3): 0.9588 - val_ca4-[11.3,14.9): 0.6983\n",
      "Epoch 97/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5157 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3755 - ca2-[9.5,10.3): 0.5158 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5502 - ca3-[10.3,11.3): 0.7218 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5161 - ca4-[11.3,14.9): 0.6927 - val_ca1-[8.0,9.5): 0.5795 - val_ca1-[9.5,10.3): 0.4287 - val_ca1-[10.3,11.3): 0.9479 - val_ca1-[11.3,14.9): 1.6661 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8848 - val_ca2-[11.3,14.9): 1.5264 - val_ca3-[8.0,9.5): 0.8356 - val_ca3-[9.5,10.3): 0.5464 - val_ca3-[10.3,11.3): 0.7330 - val_ca3-[11.3,14.9): 0.9539 - val_ca4-[8.0,9.5): 1.5233 - val_ca4-[9.5,10.3): 1.1011 - val_ca4-[10.3,11.3): 0.9656 - val_ca4-[11.3,14.9): 0.7046\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5267 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3901 - ca2-[9.5,10.3): 0.5197 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5514 - ca3-[10.3,11.3): 0.7097 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5606 - ca4-[11.3,14.9): 0.6862 - val_ca1-[8.0,9.5): 0.5797 - val_ca1-[9.5,10.3): 0.4280 - val_ca1-[10.3,11.3): 0.9479 - val_ca1-[11.3,14.9): 1.6732 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4169 - val_ca2-[10.3,11.3): 0.8870 - val_ca2-[11.3,14.9): 1.5390 - val_ca3-[8.0,9.5): 0.8360 - val_ca3-[9.5,10.3): 0.5467 - val_ca3-[10.3,11.3): 0.7321 - val_ca3-[11.3,14.9): 0.9638 - val_ca4-[8.0,9.5): 1.5263 - val_ca4-[9.5,10.3): 1.1037 - val_ca4-[10.3,11.3): 0.9627 - val_ca4-[11.3,14.9): 0.7117\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5254 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3751 - ca2-[9.5,10.3): 0.5198 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5566 - ca3-[10.3,11.3): 0.7368 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5705 - ca4-[11.3,14.9): 0.6918 - val_ca1-[8.0,9.5): 0.5799 - val_ca1-[9.5,10.3): 0.4274 - val_ca1-[10.3,11.3): 0.9452 - val_ca1-[11.3,14.9): 1.6351 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8866 - val_ca2-[11.3,14.9): 1.5038 - val_ca3-[8.0,9.5): 0.8360 - val_ca3-[9.5,10.3): 0.5467 - val_ca3-[10.3,11.3): 0.7321 - val_ca3-[11.3,14.9): 0.9178 - val_ca4-[8.0,9.5): 1.5302 - val_ca4-[9.5,10.3): 1.1070 - val_ca4-[10.3,11.3): 0.9647 - val_ca4-[11.3,14.9): 0.6524\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5356 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3863 - ca2-[9.5,10.3): 0.5095 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5690 - ca3-[10.3,11.3): 0.7321 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5196 - ca4-[11.3,14.9): 0.7008 - val_ca1-[8.0,9.5): 0.5801 - val_ca1-[9.5,10.3): 0.4268 - val_ca1-[10.3,11.3): 0.9343 - val_ca1-[11.3,14.9): 1.6284 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8781 - val_ca2-[11.3,14.9): 1.5061 - val_ca3-[8.0,9.5): 0.8360 - val_ca3-[9.5,10.3): 0.5467 - val_ca3-[10.3,11.3): 0.7215 - val_ca3-[11.3,14.9): 0.9392 - val_ca4-[8.0,9.5): 1.5336 - val_ca4-[9.5,10.3): 1.1099 - val_ca4-[10.3,11.3): 0.9535 - val_ca4-[11.3,14.9): 0.6961\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5127 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3778 - ca2-[9.5,10.3): 0.5006 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5578 - ca3-[10.3,11.3): 0.7278 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5655 - ca4-[11.3,14.9): 0.6838 - val_ca1-[8.0,9.5): 0.5802 - val_ca1-[9.5,10.3): 0.4263 - val_ca1-[10.3,11.3): 0.9321 - val_ca1-[11.3,14.9): 1.6487 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8781 - val_ca2-[11.3,14.9): 1.5298 - val_ca3-[8.0,9.5): 0.8356 - val_ca3-[9.5,10.3): 0.5463 - val_ca3-[10.3,11.3): 0.7214 - val_ca3-[11.3,14.9): 0.9542 - val_ca4-[8.0,9.5): 1.5364 - val_ca4-[9.5,10.3): 1.1123 - val_ca4-[10.3,11.3): 0.9548 - val_ca4-[11.3,14.9): 0.7003\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5131 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3732 - ca2-[9.5,10.3): 0.5186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5617 - ca3-[10.3,11.3): 0.7115 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5968 - ca4-[11.3,14.9): 0.6863 - val_ca1-[8.0,9.5): 0.5804 - val_ca1-[9.5,10.3): 0.4257 - val_ca1-[10.3,11.3): 0.9315 - val_ca1-[11.3,14.9): 1.5921 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8805 - val_ca2-[11.3,14.9): 1.4806 - val_ca3-[8.0,9.5): 0.8354 - val_ca3-[9.5,10.3): 0.5462 - val_ca3-[10.3,11.3): 0.7282 - val_ca3-[11.3,14.9): 0.9216 - val_ca4-[8.0,9.5): 1.5388 - val_ca4-[9.5,10.3): 1.1143 - val_ca4-[10.3,11.3): 0.9681 - val_ca4-[11.3,14.9): 0.6871\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5339 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3809 - ca2-[9.5,10.3): 0.5131 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5605 - ca3-[10.3,11.3): 0.7181 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5590 - ca4-[11.3,14.9): 0.6954 - val_ca1-[8.0,9.5): 0.5806 - val_ca1-[9.5,10.3): 0.4253 - val_ca1-[10.3,11.3): 0.9314 - val_ca1-[11.3,14.9): 1.6254 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8823 - val_ca2-[11.3,14.9): 1.5167 - val_ca3-[8.0,9.5): 0.8345 - val_ca3-[9.5,10.3): 0.5455 - val_ca3-[10.3,11.3): 0.7304 - val_ca3-[11.3,14.9): 0.9498 - val_ca4-[8.0,9.5): 1.5409 - val_ca4-[9.5,10.3): 1.1161 - val_ca4-[10.3,11.3): 0.9718 - val_ca4-[11.3,14.9): 0.7041\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5294 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3704 - ca2-[9.5,10.3): 0.5244 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5455 - ca3-[10.3,11.3): 0.7005 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5822 - ca4-[11.3,14.9): 0.6990 - val_ca1-[8.0,9.5): 0.5808 - val_ca1-[9.5,10.3): 0.4249 - val_ca1-[10.3,11.3): 0.9297 - val_ca1-[11.3,14.9): 1.6171 - val_ca2-[8.0,9.5): 0.5889 - val_ca2-[9.5,10.3): 0.4168 - val_ca2-[10.3,11.3): 0.8823 - val_ca2-[11.3,14.9): 1.5127 - val_ca3-[8.0,9.5): 0.8336 - val_ca3-[9.5,10.3): 0.5448 - val_ca3-[10.3,11.3): 0.7303 - val_ca3-[11.3,14.9): 0.9503 - val_ca4-[8.0,9.5): 1.5433 - val_ca4-[9.5,10.3): 1.1182 - val_ca4-[10.3,11.3): 0.9730 - val_ca4-[11.3,14.9): 0.7079\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5088 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3810 - ca2-[9.5,10.3): 0.5106 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5770 - ca3-[10.3,11.3): 0.7195 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5367 - ca4-[11.3,14.9): 0.7001 - val_ca1-[8.0,9.5): 0.5810 - val_ca1-[9.5,10.3): 0.4245 - val_ca1-[10.3,11.3): 0.9284 - val_ca1-[11.3,14.9): 1.6336 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8818 - val_ca2-[11.3,14.9): 1.5307 - val_ca3-[8.0,9.5): 0.8327 - val_ca3-[9.5,10.3): 0.5441 - val_ca3-[10.3,11.3): 0.7277 - val_ca3-[11.3,14.9): 0.9652 - val_ca4-[8.0,9.5): 1.5461 - val_ca4-[9.5,10.3): 1.1205 - val_ca4-[10.3,11.3): 0.9688 - val_ca4-[11.3,14.9): 0.7159\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5251 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3877 - ca2-[9.5,10.3): 0.5207 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5549 - ca3-[10.3,11.3): 0.7125 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5603 - ca4-[11.3,14.9): 0.7018 - val_ca1-[8.0,9.5): 0.5812 - val_ca1-[9.5,10.3): 0.4242 - val_ca1-[10.3,11.3): 0.9209 - val_ca1-[11.3,14.9): 1.6284 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8752 - val_ca2-[11.3,14.9): 1.5276 - val_ca3-[8.0,9.5): 0.8324 - val_ca3-[9.5,10.3): 0.5440 - val_ca3-[10.3,11.3): 0.7189 - val_ca3-[11.3,14.9): 0.9594 - val_ca4-[8.0,9.5): 1.5480 - val_ca4-[9.5,10.3): 1.1221 - val_ca4-[10.3,11.3): 0.9580 - val_ca4-[11.3,14.9): 0.7056\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5209 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3910 - ca2-[9.5,10.3): 0.5211 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5478 - ca3-[10.3,11.3): 0.7248 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6196 - ca4-[11.3,14.9): 0.7008 - val_ca1-[8.0,9.5): 0.5813 - val_ca1-[9.5,10.3): 0.4239 - val_ca1-[10.3,11.3): 0.9322 - val_ca1-[11.3,14.9): 1.6274 - val_ca2-[8.0,9.5): 0.5891 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8880 - val_ca2-[11.3,14.9): 1.5306 - val_ca3-[8.0,9.5): 0.8325 - val_ca3-[9.5,10.3): 0.5439 - val_ca3-[10.3,11.3): 0.7314 - val_ca3-[11.3,14.9): 0.9652 - val_ca4-[8.0,9.5): 1.5498 - val_ca4-[9.5,10.3): 1.1237 - val_ca4-[10.3,11.3): 0.9714 - val_ca4-[11.3,14.9): 0.7158\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5270 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3695 - ca2-[9.5,10.3): 0.5142 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5555 - ca3-[10.3,11.3): 0.7110 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5687 - ca4-[11.3,14.9): 0.6981 - val_ca1-[8.0,9.5): 0.5814 - val_ca1-[9.5,10.3): 0.4237 - val_ca1-[10.3,11.3): 0.9286 - val_ca1-[11.3,14.9): 1.5831 - val_ca2-[8.0,9.5): 0.5890 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8860 - val_ca2-[11.3,14.9): 1.4896 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5438 - val_ca3-[10.3,11.3): 0.7316 - val_ca3-[11.3,14.9): 0.9283 - val_ca4-[8.0,9.5): 1.5516 - val_ca4-[9.5,10.3): 1.1252 - val_ca4-[10.3,11.3): 0.9752 - val_ca4-[11.3,14.9): 0.6838\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5187 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3748 - ca2-[9.5,10.3): 0.5211 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5410 - ca3-[10.3,11.3): 0.7138 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5533 - ca4-[11.3,14.9): 0.6797 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4234 - val_ca1-[10.3,11.3): 0.9255 - val_ca1-[11.3,14.9): 1.6274 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8847 - val_ca2-[11.3,14.9): 1.5364 - val_ca3-[8.0,9.5): 0.8327 - val_ca3-[9.5,10.3): 0.5440 - val_ca3-[10.3,11.3): 0.7292 - val_ca3-[11.3,14.9): 0.9602 - val_ca4-[8.0,9.5): 1.5530 - val_ca4-[9.5,10.3): 1.1264 - val_ca4-[10.3,11.3): 0.9733 - val_ca4-[11.3,14.9): 0.7005\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5226 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3680 - ca2-[9.5,10.3): 0.5063 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5546 - ca3-[10.3,11.3): 0.7135 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5761 - ca4-[11.3,14.9): 0.6970 - val_ca1-[8.0,9.5): 0.5817 - val_ca1-[9.5,10.3): 0.4233 - val_ca1-[10.3,11.3): 0.9201 - val_ca1-[11.3,14.9): 1.5979 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8804 - val_ca2-[11.3,14.9): 1.5107 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5443 - val_ca3-[10.3,11.3): 0.7277 - val_ca3-[11.3,14.9): 0.9493 - val_ca4-[8.0,9.5): 1.5548 - val_ca4-[9.5,10.3): 1.1280 - val_ca4-[10.3,11.3): 0.9761 - val_ca4-[11.3,14.9): 0.7088\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5200 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3843 - ca2-[9.5,10.3): 0.5173 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5599 - ca3-[10.3,11.3): 0.7216 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5409 - ca4-[11.3,14.9): 0.6915 - val_ca1-[8.0,9.5): 0.5818 - val_ca1-[9.5,10.3): 0.4231 - val_ca1-[10.3,11.3): 0.9194 - val_ca1-[11.3,14.9): 1.6094 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8807 - val_ca2-[11.3,14.9): 1.5241 - val_ca3-[8.0,9.5): 0.8337 - val_ca3-[9.5,10.3): 0.5447 - val_ca3-[10.3,11.3): 0.7276 - val_ca3-[11.3,14.9): 0.9615 - val_ca4-[8.0,9.5): 1.5569 - val_ca4-[9.5,10.3): 1.1298 - val_ca4-[10.3,11.3): 0.9771 - val_ca4-[11.3,14.9): 0.7216\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5092 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3837 - ca2-[9.5,10.3): 0.5148 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5514 - ca3-[10.3,11.3): 0.7174 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5774 - ca4-[11.3,14.9): 0.6938 - val_ca1-[8.0,9.5): 0.5819 - val_ca1-[9.5,10.3): 0.4230 - val_ca1-[10.3,11.3): 0.9233 - val_ca1-[11.3,14.9): 1.5823 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8850 - val_ca2-[11.3,14.9): 1.4986 - val_ca3-[8.0,9.5): 0.8343 - val_ca3-[9.5,10.3): 0.5450 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9325 - val_ca4-[8.0,9.5): 1.5583 - val_ca4-[9.5,10.3): 1.1309 - val_ca4-[10.3,11.3): 0.9760 - val_ca4-[11.3,14.9): 0.6901\n",
      "Epoch 113/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5243 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3784 - ca2-[9.5,10.3): 0.5140 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5250 - ca3-[10.3,11.3): 0.7341 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6011 - ca4-[11.3,14.9): 0.7000 - val_ca1-[8.0,9.5): 0.5820 - val_ca1-[9.5,10.3): 0.4228 - val_ca1-[10.3,11.3): 0.9261 - val_ca1-[11.3,14.9): 1.6129 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8893 - val_ca2-[11.3,14.9): 1.5316 - val_ca3-[8.0,9.5): 0.8339 - val_ca3-[9.5,10.3): 0.5447 - val_ca3-[10.3,11.3): 0.7335 - val_ca3-[11.3,14.9): 0.9598 - val_ca4-[8.0,9.5): 1.5594 - val_ca4-[9.5,10.3): 1.1319 - val_ca4-[10.3,11.3): 0.9817 - val_ca4-[11.3,14.9): 0.7110\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5229 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3818 - ca2-[9.5,10.3): 0.5183 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5433 - ca3-[10.3,11.3): 0.7236 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6107 - ca4-[11.3,14.9): 0.6978 - val_ca1-[8.0,9.5): 0.5821 - val_ca1-[9.5,10.3): 0.4226 - val_ca1-[10.3,11.3): 0.9231 - val_ca1-[11.3,14.9): 1.5608 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4167 - val_ca2-[10.3,11.3): 0.8871 - val_ca2-[11.3,14.9): 1.4819 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5440 - val_ca3-[10.3,11.3): 0.7311 - val_ca3-[11.3,14.9): 0.9174 - val_ca4-[8.0,9.5): 1.5606 - val_ca4-[9.5,10.3): 1.1329 - val_ca4-[10.3,11.3): 0.9797 - val_ca4-[11.3,14.9): 0.6755\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5102 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3727 - ca2-[9.5,10.3): 0.5221 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5371 - ca3-[10.3,11.3): 0.7198 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5610 - ca4-[11.3,14.9): 0.7015 - val_ca1-[8.0,9.5): 0.5823 - val_ca1-[9.5,10.3): 0.4224 - val_ca1-[10.3,11.3): 0.9128 - val_ca1-[11.3,14.9): 1.5773 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8783 - val_ca2-[11.3,14.9): 1.5011 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5440 - val_ca3-[10.3,11.3): 0.7280 - val_ca3-[11.3,14.9): 0.9416 - val_ca4-[8.0,9.5): 1.5624 - val_ca4-[9.5,10.3): 1.1345 - val_ca4-[10.3,11.3): 0.9844 - val_ca4-[11.3,14.9): 0.7061\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5182 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3650 - ca2-[9.5,10.3): 0.5247 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5377 - ca3-[10.3,11.3): 0.7203 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6078 - ca4-[11.3,14.9): 0.6985 - val_ca1-[8.0,9.5): 0.5824 - val_ca1-[9.5,10.3): 0.4222 - val_ca1-[10.3,11.3): 0.9194 - val_ca1-[11.3,14.9): 1.5806 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8854 - val_ca2-[11.3,14.9): 1.5063 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5439 - val_ca3-[10.3,11.3): 0.7286 - val_ca3-[11.3,14.9): 0.9368 - val_ca4-[8.0,9.5): 1.5632 - val_ca4-[9.5,10.3): 1.1351 - val_ca4-[10.3,11.3): 0.9784 - val_ca4-[11.3,14.9): 0.6908\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5225 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3841 - ca2-[9.5,10.3): 0.5203 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5368 - ca3-[10.3,11.3): 0.7141 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5443 - ca4-[11.3,14.9): 0.6934 - val_ca1-[8.0,9.5): 0.5825 - val_ca1-[9.5,10.3): 0.4221 - val_ca1-[10.3,11.3): 0.9122 - val_ca1-[11.3,14.9): 1.5752 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4166 - val_ca2-[10.3,11.3): 0.8784 - val_ca2-[11.3,14.9): 1.5012 - val_ca3-[8.0,9.5): 0.8323 - val_ca3-[9.5,10.3): 0.5433 - val_ca3-[10.3,11.3): 0.7203 - val_ca3-[11.3,14.9): 0.9319 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1352 - val_ca4-[10.3,11.3): 0.9681 - val_ca4-[11.3,14.9): 0.6833\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5238 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3664 - ca2-[9.5,10.3): 0.5063 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5276 - ca3-[10.3,11.3): 0.7125 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5875 - ca4-[11.3,14.9): 0.6804 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9177 - val_ca1-[11.3,14.9): 1.5915 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8845 - val_ca2-[11.3,14.9): 1.5187 - val_ca3-[8.0,9.5): 0.8317 - val_ca3-[9.5,10.3): 0.5428 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9521 - val_ca4-[8.0,9.5): 1.5622 - val_ca4-[9.5,10.3): 1.1343 - val_ca4-[10.3,11.3): 0.9795 - val_ca4-[11.3,14.9): 0.7055\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5188 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3812 - ca2-[9.5,10.3): 0.5155 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5653 - ca3-[10.3,11.3): 0.7041 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6103 - ca4-[11.3,14.9): 0.6941 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9173 - val_ca1-[11.3,14.9): 1.5858 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4165 - val_ca2-[10.3,11.3): 0.8843 - val_ca2-[11.3,14.9): 1.5136 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5423 - val_ca3-[10.3,11.3): 0.7314 - val_ca3-[11.3,14.9): 0.9534 - val_ca4-[8.0,9.5): 1.5618 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9848 - val_ca4-[11.3,14.9): 0.7133\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5240 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3769 - ca2-[9.5,10.3): 0.5229 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5328 - ca3-[10.3,11.3): 0.7117 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5746 - ca4-[11.3,14.9): 0.6980 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9177 - val_ca1-[11.3,14.9): 1.6294 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4164 - val_ca2-[10.3,11.3): 0.8842 - val_ca2-[11.3,14.9): 1.5554 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5422 - val_ca3-[10.3,11.3): 0.7283 - val_ca3-[11.3,14.9): 0.9822 - val_ca4-[8.0,9.5): 1.5618 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9777 - val_ca4-[11.3,14.9): 0.7253\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5234 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3782 - ca2-[9.5,10.3): 0.5320 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5715 - ca3-[10.3,11.3): 0.7250 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5844 - ca4-[11.3,14.9): 0.7000 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9216 - val_ca1-[11.3,14.9): 1.5860 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.4164 - val_ca2-[10.3,11.3): 0.8880 - val_ca2-[11.3,14.9): 1.5123 - val_ca3-[8.0,9.5): 0.8312 - val_ca3-[9.5,10.3): 0.5423 - val_ca3-[10.3,11.3): 0.7327 - val_ca3-[11.3,14.9): 0.9453 - val_ca4-[8.0,9.5): 1.5624 - val_ca4-[9.5,10.3): 1.1344 - val_ca4-[10.3,11.3): 0.9832 - val_ca4-[11.3,14.9): 0.6962\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5082 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3603 - ca2-[9.5,10.3): 0.4929 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5519 - ca3-[10.3,11.3): 0.7220 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5836 - ca4-[11.3,14.9): 0.7022 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9152 - val_ca1-[11.3,14.9): 1.6121 - val_ca2-[8.0,9.5): 0.5886 - val_ca2-[9.5,10.3): 0.4164 - val_ca2-[10.3,11.3): 0.8819 - val_ca2-[11.3,14.9): 1.5385 - val_ca3-[8.0,9.5): 0.8317 - val_ca3-[9.5,10.3): 0.5426 - val_ca3-[10.3,11.3): 0.7289 - val_ca3-[11.3,14.9): 0.9706 - val_ca4-[8.0,9.5): 1.5625 - val_ca4-[9.5,10.3): 1.1345 - val_ca4-[10.3,11.3): 0.9826 - val_ca4-[11.3,14.9): 0.7219\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5272 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3811 - ca2-[9.5,10.3): 0.5095 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5522 - ca3-[10.3,11.3): 0.6980 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5524 - ca4-[11.3,14.9): 0.6990 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9041 - val_ca1-[11.3,14.9): 1.5727 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4164 - val_ca2-[10.3,11.3): 0.8716 - val_ca2-[11.3,14.9): 1.5009 - val_ca3-[8.0,9.5): 0.8316 - val_ca3-[9.5,10.3): 0.5425 - val_ca3-[10.3,11.3): 0.7210 - val_ca3-[11.3,14.9): 0.9346 - val_ca4-[8.0,9.5): 1.5628 - val_ca4-[9.5,10.3): 1.1348 - val_ca4-[10.3,11.3): 0.9783 - val_ca4-[11.3,14.9): 0.6890\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5158 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3853 - ca2-[9.5,10.3): 0.5153 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5291 - ca3-[10.3,11.3): 0.7152 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5899 - ca4-[11.3,14.9): 0.6880 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9174 - val_ca1-[11.3,14.9): 1.5950 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8846 - val_ca2-[11.3,14.9): 1.5242 - val_ca3-[8.0,9.5): 0.8320 - val_ca3-[9.5,10.3): 0.5427 - val_ca3-[10.3,11.3): 0.7279 - val_ca3-[11.3,14.9): 0.9615 - val_ca4-[8.0,9.5): 1.5626 - val_ca4-[9.5,10.3): 1.1346 - val_ca4-[10.3,11.3): 0.9781 - val_ca4-[11.3,14.9): 0.7215\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5195 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3740 - ca2-[9.5,10.3): 0.5137 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5623 - ca3-[10.3,11.3): 0.7305 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5953 - ca4-[11.3,14.9): 0.7016 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9194 - val_ca1-[11.3,14.9): 1.5979 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8866 - val_ca2-[11.3,14.9): 1.5268 - val_ca3-[8.0,9.5): 0.8320 - val_ca3-[9.5,10.3): 0.5426 - val_ca3-[10.3,11.3): 0.7301 - val_ca3-[11.3,14.9): 0.9596 - val_ca4-[8.0,9.5): 1.5630 - val_ca4-[9.5,10.3): 1.1349 - val_ca4-[10.3,11.3): 0.9808 - val_ca4-[11.3,14.9): 0.7147\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5209 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3618 - ca2-[9.5,10.3): 0.5141 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5287 - ca3-[10.3,11.3): 0.7215 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5858 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9144 - val_ca1-[11.3,14.9): 1.5615 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8827 - val_ca2-[11.3,14.9): 1.4933 - val_ca3-[8.0,9.5): 0.8315 - val_ca3-[9.5,10.3): 0.5423 - val_ca3-[10.3,11.3): 0.7284 - val_ca3-[11.3,14.9): 0.9346 - val_ca4-[8.0,9.5): 1.5637 - val_ca4-[9.5,10.3): 1.1355 - val_ca4-[10.3,11.3): 0.9831 - val_ca4-[11.3,14.9): 0.7006\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5044 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3739 - ca2-[9.5,10.3): 0.5086 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5549 - ca3-[10.3,11.3): 0.7341 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5694 - ca4-[11.3,14.9): 0.6986 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.5962 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4163 - val_ca2-[10.3,11.3): 0.8846 - val_ca2-[11.3,14.9): 1.5247 - val_ca3-[8.0,9.5): 0.8313 - val_ca3-[9.5,10.3): 0.5420 - val_ca3-[10.3,11.3): 0.7275 - val_ca3-[11.3,14.9): 0.9461 - val_ca4-[8.0,9.5): 1.5641 - val_ca4-[9.5,10.3): 1.1358 - val_ca4-[10.3,11.3): 0.9788 - val_ca4-[11.3,14.9): 0.6872\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5116 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3827 - ca2-[9.5,10.3): 0.5146 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5501 - ca3-[10.3,11.3): 0.7197 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5670 - ca4-[11.3,14.9): 0.6979 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9124 - val_ca1-[11.3,14.9): 1.6082 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4162 - val_ca2-[10.3,11.3): 0.8795 - val_ca2-[11.3,14.9): 1.5362 - val_ca3-[8.0,9.5): 0.8303 - val_ca3-[9.5,10.3): 0.5412 - val_ca3-[10.3,11.3): 0.7255 - val_ca3-[11.3,14.9): 0.9643 - val_ca4-[8.0,9.5): 1.5651 - val_ca4-[9.5,10.3): 1.1367 - val_ca4-[10.3,11.3): 0.9812 - val_ca4-[11.3,14.9): 0.7115\n",
      "Epoch 129/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5088 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3630 - ca2-[9.5,10.3): 0.5064 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5684 - ca3-[10.3,11.3): 0.7131 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5644 - ca4-[11.3,14.9): 0.7059 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9190 - val_ca1-[11.3,14.9): 1.5843 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4161 - val_ca2-[10.3,11.3): 0.8858 - val_ca2-[11.3,14.9): 1.5127 - val_ca3-[8.0,9.5): 0.8301 - val_ca3-[9.5,10.3): 0.5409 - val_ca3-[10.3,11.3): 0.7294 - val_ca3-[11.3,14.9): 0.9474 - val_ca4-[8.0,9.5): 1.5660 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9823 - val_ca4-[11.3,14.9): 0.7018\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5182 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3780 - ca2-[9.5,10.3): 0.5196 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5492 - ca3-[10.3,11.3): 0.7268 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5582 - ca4-[11.3,14.9): 0.6762 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9188 - val_ca1-[11.3,14.9): 1.5671 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.4161 - val_ca2-[10.3,11.3): 0.8857 - val_ca2-[11.3,14.9): 1.4969 - val_ca3-[8.0,9.5): 0.8301 - val_ca3-[9.5,10.3): 0.5409 - val_ca3-[10.3,11.3): 0.7293 - val_ca3-[11.3,14.9): 0.9434 - val_ca4-[8.0,9.5): 1.5672 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9829 - val_ca4-[11.3,14.9): 0.7128\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5215 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3681 - ca2-[9.5,10.3): 0.5075 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5596 - ca3-[10.3,11.3): 0.7086 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5816 - ca4-[11.3,14.9): 0.6911 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9187 - val_ca1-[11.3,14.9): 1.5762 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.4161 - val_ca2-[10.3,11.3): 0.8860 - val_ca2-[11.3,14.9): 1.5067 - val_ca3-[8.0,9.5): 0.8316 - val_ca3-[9.5,10.3): 0.5419 - val_ca3-[10.3,11.3): 0.7267 - val_ca3-[11.3,14.9): 0.9417 - val_ca4-[8.0,9.5): 1.5675 - val_ca4-[9.5,10.3): 1.1388 - val_ca4-[10.3,11.3): 0.9775 - val_ca4-[11.3,14.9): 0.7010\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5072 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3738 - ca2-[9.5,10.3): 0.5103 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5465 - ca3-[10.3,11.3): 0.7331 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5798 - ca4-[11.3,14.9): 0.6928 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4216 - val_ca1-[10.3,11.3): 0.9201 - val_ca1-[11.3,14.9): 1.5812 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.4161 - val_ca2-[10.3,11.3): 0.8883 - val_ca2-[11.3,14.9): 1.5139 - val_ca3-[8.0,9.5): 0.8313 - val_ca3-[9.5,10.3): 0.5416 - val_ca3-[10.3,11.3): 0.7288 - val_ca3-[11.3,14.9): 0.9508 - val_ca4-[8.0,9.5): 1.5672 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9800 - val_ca4-[11.3,14.9): 0.7132\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5208 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3715 - ca2-[9.5,10.3): 0.5270 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5454 - ca3-[10.3,11.3): 0.7172 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5170 - ca4-[11.3,14.9): 0.6933 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9176 - val_ca1-[11.3,14.9): 1.5876 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4161 - val_ca2-[10.3,11.3): 0.8866 - val_ca2-[11.3,14.9): 1.5212 - val_ca3-[8.0,9.5): 0.8313 - val_ca3-[9.5,10.3): 0.5415 - val_ca3-[10.3,11.3): 0.7290 - val_ca3-[11.3,14.9): 0.9519 - val_ca4-[8.0,9.5): 1.5667 - val_ca4-[9.5,10.3): 1.1381 - val_ca4-[10.3,11.3): 0.9827 - val_ca4-[11.3,14.9): 0.7082\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5195 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3785 - ca2-[9.5,10.3): 0.5127 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5179 - ca3-[10.3,11.3): 0.7084 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5686 - ca4-[11.3,14.9): 0.6873 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9156 - val_ca1-[11.3,14.9): 1.5583 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8849 - val_ca2-[11.3,14.9): 1.4934 - val_ca3-[8.0,9.5): 0.8313 - val_ca3-[9.5,10.3): 0.5415 - val_ca3-[10.3,11.3): 0.7267 - val_ca3-[11.3,14.9): 0.9327 - val_ca4-[8.0,9.5): 1.5665 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9799 - val_ca4-[11.3,14.9): 0.7006\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5299 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3670 - ca2-[9.5,10.3): 0.5221 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5822 - ca3-[10.3,11.3): 0.7158 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5750 - ca4-[11.3,14.9): 0.6852 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9129 - val_ca1-[11.3,14.9): 1.5874 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4160 - val_ca2-[10.3,11.3): 0.8823 - val_ca2-[11.3,14.9): 1.5218 - val_ca3-[8.0,9.5): 0.8316 - val_ca3-[9.5,10.3): 0.5416 - val_ca3-[10.3,11.3): 0.7274 - val_ca3-[11.3,14.9): 0.9514 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9841 - val_ca4-[11.3,14.9): 0.7081\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5243 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3885 - ca2-[9.5,10.3): 0.5181 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5632 - ca3-[10.3,11.3): 0.7177 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5365 - ca4-[11.3,14.9): 0.6946 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9073 - val_ca1-[11.3,14.9): 1.5791 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4159 - val_ca2-[10.3,11.3): 0.8763 - val_ca2-[11.3,14.9): 1.5132 - val_ca3-[8.0,9.5): 0.8319 - val_ca3-[9.5,10.3): 0.5419 - val_ca3-[10.3,11.3): 0.7162 - val_ca3-[11.3,14.9): 0.9412 - val_ca4-[8.0,9.5): 1.5655 - val_ca4-[9.5,10.3): 1.1370 - val_ca4-[10.3,11.3): 0.9665 - val_ca4-[11.3,14.9): 0.6970\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5218 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3698 - ca2-[9.5,10.3): 0.5156 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5477 - ca3-[10.3,11.3): 0.7221 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5847 - ca4-[11.3,14.9): 0.6959 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9109 - val_ca1-[11.3,14.9): 1.5446 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4159 - val_ca2-[10.3,11.3): 0.8800 - val_ca2-[11.3,14.9): 1.4801 - val_ca3-[8.0,9.5): 0.8320 - val_ca3-[9.5,10.3): 0.5418 - val_ca3-[10.3,11.3): 0.7250 - val_ca3-[11.3,14.9): 0.9244 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1377 - val_ca4-[10.3,11.3): 0.9817 - val_ca4-[11.3,14.9): 0.6991\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5182 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3813 - ca2-[9.5,10.3): 0.5155 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5780 - ca3-[10.3,11.3): 0.7159 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5962 - ca4-[11.3,14.9): 0.6895 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5763 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4157 - val_ca2-[10.3,11.3): 0.8857 - val_ca2-[11.3,14.9): 1.5110 - val_ca3-[8.0,9.5): 0.8314 - val_ca3-[9.5,10.3): 0.5414 - val_ca3-[10.3,11.3): 0.7286 - val_ca3-[11.3,14.9): 0.9492 - val_ca4-[8.0,9.5): 1.5675 - val_ca4-[9.5,10.3): 1.1387 - val_ca4-[10.3,11.3): 0.9830 - val_ca4-[11.3,14.9): 0.7142\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5092 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3659 - ca2-[9.5,10.3): 0.5148 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5331 - ca3-[10.3,11.3): 0.7141 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5777 - ca4-[11.3,14.9): 0.7068 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9164 - val_ca1-[11.3,14.9): 1.5499 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4157 - val_ca2-[10.3,11.3): 0.8858 - val_ca2-[11.3,14.9): 1.4857 - val_ca3-[8.0,9.5): 0.8310 - val_ca3-[9.5,10.3): 0.5410 - val_ca3-[10.3,11.3): 0.7285 - val_ca3-[11.3,14.9): 0.9210 - val_ca4-[8.0,9.5): 1.5670 - val_ca4-[9.5,10.3): 1.1382 - val_ca4-[10.3,11.3): 0.9827 - val_ca4-[11.3,14.9): 0.6826\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5226 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3634 - ca2-[9.5,10.3): 0.5103 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5597 - ca3-[10.3,11.3): 0.6993 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5659 - ca4-[11.3,14.9): 0.7071 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5685 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4156 - val_ca2-[10.3,11.3): 0.8856 - val_ca2-[11.3,14.9): 1.5046 - val_ca3-[8.0,9.5): 0.8312 - val_ca3-[9.5,10.3): 0.5411 - val_ca3-[10.3,11.3): 0.7284 - val_ca3-[11.3,14.9): 0.9425 - val_ca4-[8.0,9.5): 1.5672 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9828 - val_ca4-[11.3,14.9): 0.7077\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5181 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3623 - ca2-[9.5,10.3): 0.5155 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5462 - ca3-[10.3,11.3): 0.7086 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5154 - ca4-[11.3,14.9): 0.6942 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9094 - val_ca1-[11.3,14.9): 1.5825 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4156 - val_ca2-[10.3,11.3): 0.8792 - val_ca2-[11.3,14.9): 1.5175 - val_ca3-[8.0,9.5): 0.8308 - val_ca3-[9.5,10.3): 0.5407 - val_ca3-[10.3,11.3): 0.7246 - val_ca3-[11.3,14.9): 0.9402 - val_ca4-[8.0,9.5): 1.5672 - val_ca4-[9.5,10.3): 1.1384 - val_ca4-[10.3,11.3): 0.9821 - val_ca4-[11.3,14.9): 0.6862\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5193 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3585 - ca2-[9.5,10.3): 0.5071 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5600 - ca3-[10.3,11.3): 0.7252 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6044 - ca4-[11.3,14.9): 0.6963 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9183 - val_ca1-[11.3,14.9): 1.5710 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4155 - val_ca2-[10.3,11.3): 0.8871 - val_ca2-[11.3,14.9): 1.5062 - val_ca3-[8.0,9.5): 0.8310 - val_ca3-[9.5,10.3): 0.5408 - val_ca3-[10.3,11.3): 0.7279 - val_ca3-[11.3,14.9): 0.9433 - val_ca4-[8.0,9.5): 1.5668 - val_ca4-[9.5,10.3): 1.1381 - val_ca4-[10.3,11.3): 0.9796 - val_ca4-[11.3,14.9): 0.7066\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5140 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3712 - ca2-[9.5,10.3): 0.5128 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5254 - ca3-[10.3,11.3): 0.7313 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5718 - ca4-[11.3,14.9): 0.6957 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9165 - val_ca1-[11.3,14.9): 1.5960 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.4153 - val_ca2-[10.3,11.3): 0.8840 - val_ca2-[11.3,14.9): 1.5276 - val_ca3-[8.0,9.5): 0.8319 - val_ca3-[9.5,10.3): 0.5414 - val_ca3-[10.3,11.3): 0.7282 - val_ca3-[11.3,14.9): 0.9574 - val_ca4-[8.0,9.5): 1.5683 - val_ca4-[9.5,10.3): 1.1393 - val_ca4-[10.3,11.3): 0.9833 - val_ca4-[11.3,14.9): 0.7106\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5172 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3872 - ca2-[9.5,10.3): 0.5232 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5252 - ca3-[10.3,11.3): 0.6963 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5580 - ca4-[11.3,14.9): 0.7017 - val_ca1-[8.0,9.5): 0.5839 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9119 - val_ca1-[11.3,14.9): 1.5873 - val_ca2-[8.0,9.5): 0.5892 - val_ca2-[9.5,10.3): 0.4157 - val_ca2-[10.3,11.3): 0.8790 - val_ca2-[11.3,14.9): 1.5178 - val_ca3-[8.0,9.5): 0.8354 - val_ca3-[9.5,10.3): 0.5439 - val_ca3-[10.3,11.3): 0.7266 - val_ca3-[11.3,14.9): 0.9551 - val_ca4-[8.0,9.5): 1.5736 - val_ca4-[9.5,10.3): 1.1436 - val_ca4-[10.3,11.3): 0.9858 - val_ca4-[11.3,14.9): 0.7183\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5222 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3841 - ca2-[9.5,10.3): 0.5136 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5493 - ca3-[10.3,11.3): 0.7258 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5910 - ca4-[11.3,14.9): 0.6912 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9101 - val_ca1-[11.3,14.9): 1.5829 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.4152 - val_ca2-[10.3,11.3): 0.8777 - val_ca2-[11.3,14.9): 1.5148 - val_ca3-[8.0,9.5): 0.8327 - val_ca3-[9.5,10.3): 0.5419 - val_ca3-[10.3,11.3): 0.7243 - val_ca3-[11.3,14.9): 0.9488 - val_ca4-[8.0,9.5): 1.5699 - val_ca4-[9.5,10.3): 1.1407 - val_ca4-[10.3,11.3): 0.9834 - val_ca4-[11.3,14.9): 0.7091\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5179 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3722 - ca2-[9.5,10.3): 0.5109 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5805 - ca3-[10.3,11.3): 0.6996 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5787 - ca4-[11.3,14.9): 0.6918 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9146 - val_ca1-[11.3,14.9): 1.5822 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4151 - val_ca2-[10.3,11.3): 0.8819 - val_ca2-[11.3,14.9): 1.5147 - val_ca3-[8.0,9.5): 0.8322 - val_ca3-[9.5,10.3): 0.5414 - val_ca3-[10.3,11.3): 0.7256 - val_ca3-[11.3,14.9): 0.9541 - val_ca4-[8.0,9.5): 1.5700 - val_ca4-[9.5,10.3): 1.1408 - val_ca4-[10.3,11.3): 0.9815 - val_ca4-[11.3,14.9): 0.7205\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5084 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3723 - ca2-[9.5,10.3): 0.5143 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5392 - ca3-[10.3,11.3): 0.7196 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5813 - ca4-[11.3,14.9): 0.6835 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9121 - val_ca1-[11.3,14.9): 1.5797 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.4150 - val_ca2-[10.3,11.3): 0.8794 - val_ca2-[11.3,14.9): 1.5104 - val_ca3-[8.0,9.5): 0.8320 - val_ca3-[9.5,10.3): 0.5412 - val_ca3-[10.3,11.3): 0.7263 - val_ca3-[11.3,14.9): 0.9382 - val_ca4-[8.0,9.5): 1.5701 - val_ca4-[9.5,10.3): 1.1408 - val_ca4-[10.3,11.3): 0.9861 - val_ca4-[11.3,14.9): 0.6901\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3787 - ca2-[9.5,10.3): 0.5015 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5692 - ca3-[10.3,11.3): 0.7021 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5740 - ca4-[11.3,14.9): 0.6848 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9151 - val_ca1-[11.3,14.9): 1.5841 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.4149 - val_ca2-[10.3,11.3): 0.8818 - val_ca2-[11.3,14.9): 1.5147 - val_ca3-[8.0,9.5): 0.8315 - val_ca3-[9.5,10.3): 0.5408 - val_ca3-[10.3,11.3): 0.7254 - val_ca3-[11.3,14.9): 0.9467 - val_ca4-[8.0,9.5): 1.5702 - val_ca4-[9.5,10.3): 1.1409 - val_ca4-[10.3,11.3): 0.9816 - val_ca4-[11.3,14.9): 0.7033\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5329 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3671 - ca2-[9.5,10.3): 0.5157 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5399 - ca3-[10.3,11.3): 0.7099 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5148 - ca4-[11.3,14.9): 0.6668 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9191 - val_ca1-[11.3,14.9): 1.5424 - val_ca2-[8.0,9.5): 0.5876 - val_ca2-[9.5,10.3): 0.4149 - val_ca2-[10.3,11.3): 0.8858 - val_ca2-[11.3,14.9): 1.4750 - val_ca3-[8.0,9.5): 0.8317 - val_ca3-[9.5,10.3): 0.5408 - val_ca3-[10.3,11.3): 0.7273 - val_ca3-[11.3,14.9): 0.9187 - val_ca4-[8.0,9.5): 1.5713 - val_ca4-[9.5,10.3): 1.1419 - val_ca4-[10.3,11.3): 0.9818 - val_ca4-[11.3,14.9): 0.6905\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5254 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3651 - ca2-[9.5,10.3): 0.5132 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5717 - ca3-[10.3,11.3): 0.7283 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5434 - ca4-[11.3,14.9): 0.6960 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.5441 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.4148 - val_ca2-[10.3,11.3): 0.8815 - val_ca2-[11.3,14.9): 1.4760 - val_ca3-[8.0,9.5): 0.8309 - val_ca3-[9.5,10.3): 0.5402 - val_ca3-[10.3,11.3): 0.7251 - val_ca3-[11.3,14.9): 0.9083 - val_ca4-[8.0,9.5): 1.5712 - val_ca4-[9.5,10.3): 1.1418 - val_ca4-[10.3,11.3): 0.9821 - val_ca4-[11.3,14.9): 0.6645\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5282 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3737 - ca2-[9.5,10.3): 0.5160 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5461 - ca3-[10.3,11.3): 0.7168 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5432 - ca4-[11.3,14.9): 0.6914 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5750 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.4146 - val_ca2-[10.3,11.3): 0.8832 - val_ca2-[11.3,14.9): 1.5077 - val_ca3-[8.0,9.5): 0.8307 - val_ca3-[9.5,10.3): 0.5399 - val_ca3-[10.3,11.3): 0.7272 - val_ca3-[11.3,14.9): 0.9484 - val_ca4-[8.0,9.5): 1.5705 - val_ca4-[9.5,10.3): 1.1411 - val_ca4-[10.3,11.3): 0.9843 - val_ca4-[11.3,14.9): 0.7140\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5209 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3648 - ca2-[9.5,10.3): 0.5135 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5841 - ca3-[10.3,11.3): 0.7186 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5593 - ca4-[11.3,14.9): 0.6974 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9141 - val_ca1-[11.3,14.9): 1.5733 - val_ca2-[8.0,9.5): 0.5872 - val_ca2-[9.5,10.3): 0.4152 - val_ca2-[10.3,11.3): 0.8816 - val_ca2-[11.3,14.9): 1.5080 - val_ca3-[8.0,9.5): 0.8308 - val_ca3-[9.5,10.3): 0.5391 - val_ca3-[10.3,11.3): 0.7229 - val_ca3-[11.3,14.9): 0.9486 - val_ca4-[8.0,9.5): 1.5688 - val_ca4-[9.5,10.3): 1.1370 - val_ca4-[10.3,11.3): 0.9767 - val_ca4-[11.3,14.9): 0.7168\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5145 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3667 - ca2-[9.5,10.3): 0.5122 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5674 - ca3-[10.3,11.3): 0.7207 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5463 - ca4-[11.3,14.9): 0.6886 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9166 - val_ca1-[11.3,14.9): 1.5899 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.4145 - val_ca2-[10.3,11.3): 0.8837 - val_ca2-[11.3,14.9): 1.5221 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5401 - val_ca3-[10.3,11.3): 0.7270 - val_ca3-[11.3,14.9): 0.9502 - val_ca4-[8.0,9.5): 1.5676 - val_ca4-[9.5,10.3): 1.1386 - val_ca4-[10.3,11.3): 0.9828 - val_ca4-[11.3,14.9): 0.7040\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5161 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3640 - ca2-[9.5,10.3): 0.5099 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5550 - ca3-[10.3,11.3): 0.7112 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5252 - ca4-[11.3,14.9): 0.6935 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5570 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.4144 - val_ca2-[10.3,11.3): 0.8832 - val_ca2-[11.3,14.9): 1.4898 - val_ca3-[8.0,9.5): 0.8311 - val_ca3-[9.5,10.3): 0.5400 - val_ca3-[10.3,11.3): 0.7268 - val_ca3-[11.3,14.9): 0.9288 - val_ca4-[8.0,9.5): 1.5675 - val_ca4-[9.5,10.3): 1.1385 - val_ca4-[10.3,11.3): 0.9827 - val_ca4-[11.3,14.9): 0.6946\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5190 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3828 - ca2-[9.5,10.3): 0.5127 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5319 - ca3-[10.3,11.3): 0.6929 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5678 - ca4-[11.3,14.9): 0.6958 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9167 - val_ca1-[11.3,14.9): 1.6031 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.4143 - val_ca2-[10.3,11.3): 0.8833 - val_ca2-[11.3,14.9): 1.5350 - val_ca3-[8.0,9.5): 0.8331 - val_ca3-[9.5,10.3): 0.5413 - val_ca3-[10.3,11.3): 0.7268 - val_ca3-[11.3,14.9): 0.9611 - val_ca4-[8.0,9.5): 1.5684 - val_ca4-[9.5,10.3): 1.1392 - val_ca4-[10.3,11.3): 0.9831 - val_ca4-[11.3,14.9): 0.7168\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5131 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3703 - ca2-[9.5,10.3): 0.5097 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5830 - ca3-[10.3,11.3): 0.7258 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5964 - ca4-[11.3,14.9): 0.6913 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9058 - val_ca1-[11.3,14.9): 1.5597 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.4141 - val_ca2-[10.3,11.3): 0.8717 - val_ca2-[11.3,14.9): 1.4898 - val_ca3-[8.0,9.5): 0.8332 - val_ca3-[9.5,10.3): 0.5412 - val_ca3-[10.3,11.3): 0.7215 - val_ca3-[11.3,14.9): 0.9294 - val_ca4-[8.0,9.5): 1.5684 - val_ca4-[9.5,10.3): 1.1393 - val_ca4-[10.3,11.3): 0.9843 - val_ca4-[11.3,14.9): 0.6992\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5145 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3701 - ca2-[9.5,10.3): 0.5102 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5490 - ca3-[10.3,11.3): 0.7241 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5905 - ca4-[11.3,14.9): 0.6961 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9170 - val_ca1-[11.3,14.9): 1.5608 - val_ca2-[8.0,9.5): 0.5868 - val_ca2-[9.5,10.3): 0.4140 - val_ca2-[10.3,11.3): 0.8827 - val_ca2-[11.3,14.9): 1.4923 - val_ca3-[8.0,9.5): 0.8330 - val_ca3-[9.5,10.3): 0.5410 - val_ca3-[10.3,11.3): 0.7264 - val_ca3-[11.3,14.9): 0.9202 - val_ca4-[8.0,9.5): 1.5682 - val_ca4-[9.5,10.3): 1.1390 - val_ca4-[10.3,11.3): 0.9830 - val_ca4-[11.3,14.9): 0.6766\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5267 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3914 - ca2-[9.5,10.3): 0.5207 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5510 - ca3-[10.3,11.3): 0.7262 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5746 - ca4-[11.3,14.9): 0.6808 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9169 - val_ca1-[11.3,14.9): 1.5774 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.4139 - val_ca2-[10.3,11.3): 0.8832 - val_ca2-[11.3,14.9): 1.5099 - val_ca3-[8.0,9.5): 0.8324 - val_ca3-[9.5,10.3): 0.5404 - val_ca3-[10.3,11.3): 0.7262 - val_ca3-[11.3,14.9): 0.9380 - val_ca4-[8.0,9.5): 1.5673 - val_ca4-[9.5,10.3): 1.1383 - val_ca4-[10.3,11.3): 0.9825 - val_ca4-[11.3,14.9): 0.6967\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5173 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3749 - ca2-[9.5,10.3): 0.5164 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5365 - ca3-[10.3,11.3): 0.7022 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6002 - ca4-[11.3,14.9): 0.7097 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9169 - val_ca1-[11.3,14.9): 1.6035 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.4138 - val_ca2-[10.3,11.3): 0.8833 - val_ca2-[11.3,14.9): 1.5364 - val_ca3-[8.0,9.5): 0.8316 - val_ca3-[9.5,10.3): 0.5396 - val_ca3-[10.3,11.3): 0.7259 - val_ca3-[11.3,14.9): 0.9618 - val_ca4-[8.0,9.5): 1.5668 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9822 - val_ca4-[11.3,14.9): 0.7167\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3612 - ca2-[9.5,10.3): 0.5091 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5449 - ca3-[10.3,11.3): 0.7218 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5379 - ca4-[11.3,14.9): 0.6804 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9149 - val_ca1-[11.3,14.9): 1.5840 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.4136 - val_ca2-[10.3,11.3): 0.8802 - val_ca2-[11.3,14.9): 1.5160 - val_ca3-[8.0,9.5): 0.8299 - val_ca3-[9.5,10.3): 0.5380 - val_ca3-[10.3,11.3): 0.7232 - val_ca3-[11.3,14.9): 0.9447 - val_ca4-[8.0,9.5): 1.5665 - val_ca4-[9.5,10.3): 1.1375 - val_ca4-[10.3,11.3): 0.9794 - val_ca4-[11.3,14.9): 0.6975\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5224 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3743 - ca2-[9.5,10.3): 0.5204 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5231 - ca3-[10.3,11.3): 0.7053 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5613 - ca4-[11.3,14.9): 0.6916 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9148 - val_ca1-[11.3,14.9): 1.5969 - val_ca2-[8.0,9.5): 0.5865 - val_ca2-[9.5,10.3): 0.4133 - val_ca2-[10.3,11.3): 0.8793 - val_ca2-[11.3,14.9): 1.5264 - val_ca3-[8.0,9.5): 0.8299 - val_ca3-[9.5,10.3): 0.5378 - val_ca3-[10.3,11.3): 0.7186 - val_ca3-[11.3,14.9): 0.9517 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1370 - val_ca4-[10.3,11.3): 0.9695 - val_ca4-[11.3,14.9): 0.6988\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5074 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3852 - ca2-[9.5,10.3): 0.5064 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5502 - ca3-[10.3,11.3): 0.7067 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5413 - ca4-[11.3,14.9): 0.6998 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9098 - val_ca1-[11.3,14.9): 1.5692 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.4132 - val_ca2-[10.3,11.3): 0.8745 - val_ca2-[11.3,14.9): 1.4997 - val_ca3-[8.0,9.5): 0.8305 - val_ca3-[9.5,10.3): 0.5381 - val_ca3-[10.3,11.3): 0.7208 - val_ca3-[11.3,14.9): 0.9374 - val_ca4-[8.0,9.5): 1.5661 - val_ca4-[9.5,10.3): 1.1371 - val_ca4-[10.3,11.3): 0.9810 - val_ca4-[11.3,14.9): 0.7015\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5278 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3733 - ca2-[9.5,10.3): 0.5126 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5500 - ca3-[10.3,11.3): 0.7166 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5487 - ca4-[11.3,14.9): 0.6878 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9162 - val_ca1-[11.3,14.9): 1.5642 - val_ca2-[8.0,9.5): 0.5863 - val_ca2-[9.5,10.3): 0.4129 - val_ca2-[10.3,11.3): 0.8805 - val_ca2-[11.3,14.9): 1.4951 - val_ca3-[8.0,9.5): 0.8300 - val_ca3-[9.5,10.3): 0.5374 - val_ca3-[10.3,11.3): 0.7221 - val_ca3-[11.3,14.9): 0.9353 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9763 - val_ca4-[11.3,14.9): 0.6998\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5265 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3773 - ca2-[9.5,10.3): 0.5016 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5352 - ca3-[10.3,11.3): 0.7073 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5790 - ca4-[11.3,14.9): 0.6902 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9117 - val_ca1-[11.3,14.9): 1.6006 - val_ca2-[8.0,9.5): 0.5864 - val_ca2-[9.5,10.3): 0.4126 - val_ca2-[10.3,11.3): 0.8751 - val_ca2-[11.3,14.9): 1.5276 - val_ca3-[8.0,9.5): 0.8280 - val_ca3-[9.5,10.3): 0.5356 - val_ca3-[10.3,11.3): 0.7158 - val_ca3-[11.3,14.9): 0.9550 - val_ca4-[8.0,9.5): 1.5655 - val_ca4-[9.5,10.3): 1.1366 - val_ca4-[10.3,11.3): 0.9681 - val_ca4-[11.3,14.9): 0.6967\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5161 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3858 - ca2-[9.5,10.3): 0.5062 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5470 - ca3-[10.3,11.3): 0.7106 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5725 - ca4-[11.3,14.9): 0.6783 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9142 - val_ca1-[11.3,14.9): 1.5487 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.4126 - val_ca2-[10.3,11.3): 0.8783 - val_ca2-[11.3,14.9): 1.4802 - val_ca3-[8.0,9.5): 0.8286 - val_ca3-[9.5,10.3): 0.5356 - val_ca3-[10.3,11.3): 0.7216 - val_ca3-[11.3,14.9): 0.9277 - val_ca4-[8.0,9.5): 1.5655 - val_ca4-[9.5,10.3): 1.1366 - val_ca4-[10.3,11.3): 0.9788 - val_ca4-[11.3,14.9): 0.6993\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5182 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3760 - ca2-[9.5,10.3): 0.5159 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5228 - ca3-[10.3,11.3): 0.6970 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5564 - ca4-[11.3,14.9): 0.6929 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5737 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.4124 - val_ca2-[10.3,11.3): 0.8783 - val_ca2-[11.3,14.9): 1.5060 - val_ca3-[8.0,9.5): 0.8293 - val_ca3-[9.5,10.3): 0.5358 - val_ca3-[10.3,11.3): 0.7211 - val_ca3-[11.3,14.9): 0.9468 - val_ca4-[8.0,9.5): 1.5661 - val_ca4-[9.5,10.3): 1.1371 - val_ca4-[10.3,11.3): 0.9791 - val_ca4-[11.3,14.9): 0.7136\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5143 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3765 - ca2-[9.5,10.3): 0.5076 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5233 - ca3-[10.3,11.3): 0.7049 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6130 - ca4-[11.3,14.9): 0.6928 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9156 - val_ca1-[11.3,14.9): 1.5500 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.4122 - val_ca2-[10.3,11.3): 0.8801 - val_ca2-[11.3,14.9): 1.4837 - val_ca3-[8.0,9.5): 0.8294 - val_ca3-[9.5,10.3): 0.5354 - val_ca3-[10.3,11.3): 0.7202 - val_ca3-[11.3,14.9): 0.9226 - val_ca4-[8.0,9.5): 1.5657 - val_ca4-[9.5,10.3): 1.1367 - val_ca4-[10.3,11.3): 0.9759 - val_ca4-[11.3,14.9): 0.6870\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5154 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3728 - ca2-[9.5,10.3): 0.5095 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5338 - ca3-[10.3,11.3): 0.6915 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5678 - ca4-[11.3,14.9): 0.6911 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9135 - val_ca1-[11.3,14.9): 1.5471 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.4120 - val_ca2-[10.3,11.3): 0.8777 - val_ca2-[11.3,14.9): 1.4791 - val_ca3-[8.0,9.5): 0.8298 - val_ca3-[9.5,10.3): 0.5352 - val_ca3-[10.3,11.3): 0.7200 - val_ca3-[11.3,14.9): 0.9251 - val_ca4-[8.0,9.5): 1.5654 - val_ca4-[9.5,10.3): 1.1364 - val_ca4-[10.3,11.3): 0.9787 - val_ca4-[11.3,14.9): 0.6992\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5085 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3853 - ca2-[9.5,10.3): 0.5040 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4903 - ca3-[10.3,11.3): 0.6928 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6018 - ca4-[11.3,14.9): 0.7018 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9116 - val_ca1-[11.3,14.9): 1.5694 - val_ca2-[8.0,9.5): 0.5853 - val_ca2-[9.5,10.3): 0.4117 - val_ca2-[10.3,11.3): 0.8748 - val_ca2-[11.3,14.9): 1.4996 - val_ca3-[8.0,9.5): 0.8303 - val_ca3-[9.5,10.3): 0.5351 - val_ca3-[10.3,11.3): 0.7131 - val_ca3-[11.3,14.9): 0.9420 - val_ca4-[8.0,9.5): 1.5639 - val_ca4-[9.5,10.3): 1.1351 - val_ca4-[10.3,11.3): 0.9657 - val_ca4-[11.3,14.9): 0.7117\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3781 - ca2-[9.5,10.3): 0.5138 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5479 - ca3-[10.3,11.3): 0.6947 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5452 - ca4-[11.3,14.9): 0.7040 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5680 - val_ca2-[8.0,9.5): 0.5850 - val_ca2-[9.5,10.3): 0.4115 - val_ca2-[10.3,11.3): 0.8768 - val_ca2-[11.3,14.9): 1.4987 - val_ca3-[8.0,9.5): 0.8297 - val_ca3-[9.5,10.3): 0.5342 - val_ca3-[10.3,11.3): 0.7187 - val_ca3-[11.3,14.9): 0.9317 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1349 - val_ca4-[10.3,11.3): 0.9778 - val_ca4-[11.3,14.9): 0.6899\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5165 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3776 - ca2-[9.5,10.3): 0.5060 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5281 - ca3-[10.3,11.3): 0.7083 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5911 - ca4-[11.3,14.9): 0.6993 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5748 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.4111 - val_ca2-[10.3,11.3): 0.8757 - val_ca2-[11.3,14.9): 1.5019 - val_ca3-[8.0,9.5): 0.8284 - val_ca3-[9.5,10.3): 0.5326 - val_ca3-[10.3,11.3): 0.7179 - val_ca3-[11.3,14.9): 0.9355 - val_ca4-[8.0,9.5): 1.5623 - val_ca4-[9.5,10.3): 1.1337 - val_ca4-[10.3,11.3): 0.9771 - val_ca4-[11.3,14.9): 0.6906\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5215 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3858 - ca2-[9.5,10.3): 0.5104 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5360 - ca3-[10.3,11.3): 0.7154 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5556 - ca4-[11.3,14.9): 0.6794 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9134 - val_ca1-[11.3,14.9): 1.5674 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.4109 - val_ca2-[10.3,11.3): 0.8760 - val_ca2-[11.3,14.9): 1.4974 - val_ca3-[8.0,9.5): 0.8291 - val_ca3-[9.5,10.3): 0.5326 - val_ca3-[10.3,11.3): 0.7172 - val_ca3-[11.3,14.9): 0.9338 - val_ca4-[8.0,9.5): 1.5631 - val_ca4-[9.5,10.3): 1.1343 - val_ca4-[10.3,11.3): 0.9774 - val_ca4-[11.3,14.9): 0.6956\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5263 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3744 - ca2-[9.5,10.3): 0.5042 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5611 - ca3-[10.3,11.3): 0.6999 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5600 - ca4-[11.3,14.9): 0.6859 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9150 - val_ca1-[11.3,14.9): 1.5593 - val_ca2-[8.0,9.5): 0.5839 - val_ca2-[9.5,10.3): 0.4107 - val_ca2-[10.3,11.3): 0.8787 - val_ca2-[11.3,14.9): 1.4925 - val_ca3-[8.0,9.5): 0.8265 - val_ca3-[9.5,10.3): 0.5300 - val_ca3-[10.3,11.3): 0.7183 - val_ca3-[11.3,14.9): 0.9366 - val_ca4-[8.0,9.5): 1.5647 - val_ca4-[9.5,10.3): 1.1357 - val_ca4-[10.3,11.3): 0.9808 - val_ca4-[11.3,14.9): 0.7062\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5184 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3668 - ca2-[9.5,10.3): 0.5078 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5095 - ca3-[10.3,11.3): 0.7196 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5710 - ca4-[11.3,14.9): 0.6894 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.8952 - val_ca1-[11.3,14.9): 1.5863 - val_ca2-[8.0,9.5): 0.5834 - val_ca2-[9.5,10.3): 0.4104 - val_ca2-[10.3,11.3): 0.8600 - val_ca2-[11.3,14.9): 1.5190 - val_ca3-[8.0,9.5): 0.8255 - val_ca3-[9.5,10.3): 0.5286 - val_ca3-[10.3,11.3): 0.7047 - val_ca3-[11.3,14.9): 0.9520 - val_ca4-[8.0,9.5): 1.5662 - val_ca4-[9.5,10.3): 1.1369 - val_ca4-[10.3,11.3): 0.9753 - val_ca4-[11.3,14.9): 0.7091\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5226 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3690 - ca2-[9.5,10.3): 0.5134 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5321 - ca3-[10.3,11.3): 0.7096 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6274 - ca4-[11.3,14.9): 0.6932 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9152 - val_ca1-[11.3,14.9): 1.5935 - val_ca2-[8.0,9.5): 0.5832 - val_ca2-[9.5,10.3): 0.4099 - val_ca2-[10.3,11.3): 0.8780 - val_ca2-[11.3,14.9): 1.5248 - val_ca3-[8.0,9.5): 0.8263 - val_ca3-[9.5,10.3): 0.5286 - val_ca3-[10.3,11.3): 0.7164 - val_ca3-[11.3,14.9): 0.9522 - val_ca4-[8.0,9.5): 1.5675 - val_ca4-[9.5,10.3): 1.1380 - val_ca4-[10.3,11.3): 0.9822 - val_ca4-[11.3,14.9): 0.7041\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5194 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3635 - ca2-[9.5,10.3): 0.5111 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5365 - ca3-[10.3,11.3): 0.7163 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5488 - ca4-[11.3,14.9): 0.6901 - val_ca1-[8.0,9.5): 0.5833 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5602 - val_ca2-[8.0,9.5): 0.5827 - val_ca2-[9.5,10.3): 0.4095 - val_ca2-[10.3,11.3): 0.8779 - val_ca2-[11.3,14.9): 1.4936 - val_ca3-[8.0,9.5): 0.8255 - val_ca3-[9.5,10.3): 0.5272 - val_ca3-[10.3,11.3): 0.7153 - val_ca3-[11.3,14.9): 0.9356 - val_ca4-[8.0,9.5): 1.5678 - val_ca4-[9.5,10.3): 1.1383 - val_ca4-[10.3,11.3): 0.9823 - val_ca4-[11.3,14.9): 0.7061\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5202 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3594 - ca2-[9.5,10.3): 0.5040 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5237 - ca3-[10.3,11.3): 0.6965 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5434 - ca4-[11.3,14.9): 0.6864 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9097 - val_ca1-[11.3,14.9): 1.5499 - val_ca2-[8.0,9.5): 0.5815 - val_ca2-[9.5,10.3): 0.4095 - val_ca2-[10.3,11.3): 0.8754 - val_ca2-[11.3,14.9): 1.4907 - val_ca3-[8.0,9.5): 0.8245 - val_ca3-[9.5,10.3): 0.5256 - val_ca3-[10.3,11.3): 0.7039 - val_ca3-[11.3,14.9): 0.9259 - val_ca4-[8.0,9.5): 1.5680 - val_ca4-[9.5,10.3): 1.1384 - val_ca4-[10.3,11.3): 0.9651 - val_ca4-[11.3,14.9): 0.6979\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5226 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3694 - ca2-[9.5,10.3): 0.4990 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5342 - ca3-[10.3,11.3): 0.6971 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5830 - ca4-[11.3,14.9): 0.6858 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.5871 - val_ca2-[8.0,9.5): 0.5812 - val_ca2-[9.5,10.3): 0.4086 - val_ca2-[10.3,11.3): 0.8764 - val_ca2-[11.3,14.9): 1.5216 - val_ca3-[8.0,9.5): 0.8263 - val_ca3-[9.5,10.3): 0.5262 - val_ca3-[10.3,11.3): 0.7110 - val_ca3-[11.3,14.9): 0.9483 - val_ca4-[8.0,9.5): 1.5690 - val_ca4-[9.5,10.3): 1.1393 - val_ca4-[10.3,11.3): 0.9802 - val_ca4-[11.3,14.9): 0.7147\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5152 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3726 - ca2-[9.5,10.3): 0.5026 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5509 - ca3-[10.3,11.3): 0.7052 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5720 - ca4-[11.3,14.9): 0.7045 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.8917 - val_ca1-[11.3,14.9): 1.5608 - val_ca2-[8.0,9.5): 0.5805 - val_ca2-[9.5,10.3): 0.4079 - val_ca2-[10.3,11.3): 0.8561 - val_ca2-[11.3,14.9): 1.4991 - val_ca3-[8.0,9.5): 0.8256 - val_ca3-[9.5,10.3): 0.5247 - val_ca3-[10.3,11.3): 0.6975 - val_ca3-[11.3,14.9): 0.9322 - val_ca4-[8.0,9.5): 1.5692 - val_ca4-[9.5,10.3): 1.1393 - val_ca4-[10.3,11.3): 0.9771 - val_ca4-[11.3,14.9): 0.7062\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5245 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3640 - ca2-[9.5,10.3): 0.4980 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5181 - ca3-[10.3,11.3): 0.7008 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5698 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9178 - val_ca1-[11.3,14.9): 1.5763 - val_ca2-[8.0,9.5): 0.5799 - val_ca2-[9.5,10.3): 0.4071 - val_ca2-[10.3,11.3): 0.8796 - val_ca2-[11.3,14.9): 1.5126 - val_ca3-[8.0,9.5): 0.8212 - val_ca3-[9.5,10.3): 0.5203 - val_ca3-[10.3,11.3): 0.7100 - val_ca3-[11.3,14.9): 0.9465 - val_ca4-[8.0,9.5): 1.5688 - val_ca4-[9.5,10.3): 1.1389 - val_ca4-[10.3,11.3): 0.9797 - val_ca4-[11.3,14.9): 0.7121\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5177 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3634 - ca2-[9.5,10.3): 0.5046 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5255 - ca3-[10.3,11.3): 0.7025 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5446 - ca4-[11.3,14.9): 0.6828 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9157 - val_ca1-[11.3,14.9): 1.6076 - val_ca2-[8.0,9.5): 0.5791 - val_ca2-[9.5,10.3): 0.4064 - val_ca2-[10.3,11.3): 0.8772 - val_ca2-[11.3,14.9): 1.5433 - val_ca3-[8.0,9.5): 0.8168 - val_ca3-[9.5,10.3): 0.5150 - val_ca3-[10.3,11.3): 0.7077 - val_ca3-[11.3,14.9): 0.9672 - val_ca4-[8.0,9.5): 1.5672 - val_ca4-[9.5,10.3): 1.1376 - val_ca4-[10.3,11.3): 0.9818 - val_ca4-[11.3,14.9): 0.7168\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5207 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3705 - ca2-[9.5,10.3): 0.4973 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5378 - ca3-[10.3,11.3): 0.6942 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6071 - ca4-[11.3,14.9): 0.6964 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9074 - val_ca1-[11.3,14.9): 1.5909 - val_ca2-[8.0,9.5): 0.5791 - val_ca2-[9.5,10.3): 0.4054 - val_ca2-[10.3,11.3): 0.8671 - val_ca2-[11.3,14.9): 1.5220 - val_ca3-[8.0,9.5): 0.8190 - val_ca3-[9.5,10.3): 0.5154 - val_ca3-[10.3,11.3): 0.6978 - val_ca3-[11.3,14.9): 0.9497 - val_ca4-[8.0,9.5): 1.5656 - val_ca4-[9.5,10.3): 1.1362 - val_ca4-[10.3,11.3): 0.9681 - val_ca4-[11.3,14.9): 0.7021\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.4995 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3664 - ca2-[9.5,10.3): 0.4900 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4942 - ca3-[10.3,11.3): 0.6907 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5716 - ca4-[11.3,14.9): 0.6971 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.8985 - val_ca1-[11.3,14.9): 1.5555 - val_ca2-[8.0,9.5): 0.5785 - val_ca2-[9.5,10.3): 0.4047 - val_ca2-[10.3,11.3): 0.8580 - val_ca2-[11.3,14.9): 1.4869 - val_ca3-[8.0,9.5): 0.8213 - val_ca3-[9.5,10.3): 0.5162 - val_ca3-[10.3,11.3): 0.6940 - val_ca3-[11.3,14.9): 0.9172 - val_ca4-[8.0,9.5): 1.5671 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9767 - val_ca4-[11.3,14.9): 0.6880\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5138 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3576 - ca2-[9.5,10.3): 0.5024 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5102 - ca3-[10.3,11.3): 0.6851 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5821 - ca4-[11.3,14.9): 0.6923 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5819 - val_ca2-[8.0,9.5): 0.5779 - val_ca2-[9.5,10.3): 0.4040 - val_ca2-[10.3,11.3): 0.8734 - val_ca2-[11.3,14.9): 1.5131 - val_ca3-[8.0,9.5): 0.8194 - val_ca3-[9.5,10.3): 0.5128 - val_ca3-[10.3,11.3): 0.7032 - val_ca3-[11.3,14.9): 0.9426 - val_ca4-[8.0,9.5): 1.5682 - val_ca4-[9.5,10.3): 1.1383 - val_ca4-[10.3,11.3): 0.9822 - val_ca4-[11.3,14.9): 0.7082\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5261 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3572 - ca2-[9.5,10.3): 0.4823 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5231 - ca3-[10.3,11.3): 0.6858 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5666 - ca4-[11.3,14.9): 0.6851 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9114 - val_ca1-[11.3,14.9): 1.5680 - val_ca2-[8.0,9.5): 0.5779 - val_ca2-[9.5,10.3): 0.4031 - val_ca2-[10.3,11.3): 0.8665 - val_ca2-[11.3,14.9): 1.4953 - val_ca3-[8.0,9.5): 0.8225 - val_ca3-[9.5,10.3): 0.5140 - val_ca3-[10.3,11.3): 0.7007 - val_ca3-[11.3,14.9): 0.9340 - val_ca4-[8.0,9.5): 1.5689 - val_ca4-[9.5,10.3): 1.1389 - val_ca4-[10.3,11.3): 0.9845 - val_ca4-[11.3,14.9): 0.7123\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5172 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3617 - ca2-[9.5,10.3): 0.4959 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5212 - ca3-[10.3,11.3): 0.6818 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5492 - ca4-[11.3,14.9): 0.6865 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9113 - val_ca1-[11.3,14.9): 1.5573 - val_ca2-[8.0,9.5): 0.5768 - val_ca2-[9.5,10.3): 0.4027 - val_ca2-[10.3,11.3): 0.8677 - val_ca2-[11.3,14.9): 1.4906 - val_ca3-[8.0,9.5): 0.8206 - val_ca3-[9.5,10.3): 0.5107 - val_ca3-[10.3,11.3): 0.6988 - val_ca3-[11.3,14.9): 0.9252 - val_ca4-[8.0,9.5): 1.5699 - val_ca4-[9.5,10.3): 1.1398 - val_ca4-[10.3,11.3): 0.9850 - val_ca4-[11.3,14.9): 0.7042\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5172 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3517 - ca2-[9.5,10.3): 0.4947 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4986 - ca3-[10.3,11.3): 0.6937 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5995 - ca4-[11.3,14.9): 0.6951 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9141 - val_ca1-[11.3,14.9): 1.5485 - val_ca2-[8.0,9.5): 0.5761 - val_ca2-[9.5,10.3): 0.4022 - val_ca2-[10.3,11.3): 0.8701 - val_ca2-[11.3,14.9): 1.4793 - val_ca3-[8.0,9.5): 0.8242 - val_ca3-[9.5,10.3): 0.5127 - val_ca3-[10.3,11.3): 0.6967 - val_ca3-[11.3,14.9): 0.9111 - val_ca4-[8.0,9.5): 1.5690 - val_ca4-[9.5,10.3): 1.1389 - val_ca4-[10.3,11.3): 0.9800 - val_ca4-[11.3,14.9): 0.6986\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5094 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3510 - ca2-[9.5,10.3): 0.4828 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4958 - ca3-[10.3,11.3): 0.7021 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5261 - ca4-[11.3,14.9): 0.6737 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.8970 - val_ca1-[11.3,14.9): 1.5830 - val_ca2-[8.0,9.5): 0.5757 - val_ca2-[9.5,10.3): 0.4015 - val_ca2-[10.3,11.3): 0.8526 - val_ca2-[11.3,14.9): 1.5176 - val_ca3-[8.0,9.5): 0.8172 - val_ca3-[9.5,10.3): 0.5049 - val_ca3-[10.3,11.3): 0.6849 - val_ca3-[11.3,14.9): 0.9430 - val_ca4-[8.0,9.5): 1.5677 - val_ca4-[9.5,10.3): 1.1378 - val_ca4-[10.3,11.3): 0.9743 - val_ca4-[11.3,14.9): 0.6966\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5264 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3610 - ca2-[9.5,10.3): 0.4869 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5124 - ca3-[10.3,11.3): 0.6879 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5759 - ca4-[11.3,14.9): 0.6946 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9147 - val_ca1-[11.3,14.9): 1.5628 - val_ca2-[8.0,9.5): 0.5739 - val_ca2-[9.5,10.3): 0.4025 - val_ca2-[10.3,11.3): 0.8756 - val_ca2-[11.3,14.9): 1.5193 - val_ca3-[8.0,9.5): 0.8204 - val_ca3-[9.5,10.3): 0.5062 - val_ca3-[10.3,11.3): 0.6944 - val_ca3-[11.3,14.9): 0.9361 - val_ca4-[8.0,9.5): 1.5666 - val_ca4-[9.5,10.3): 1.1368 - val_ca4-[10.3,11.3): 0.9787 - val_ca4-[11.3,14.9): 0.7115\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5140 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3527 - ca2-[9.5,10.3): 0.4886 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5099 - ca3-[10.3,11.3): 0.6792 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5776 - ca4-[11.3,14.9): 0.6916 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9123 - val_ca1-[11.3,14.9): 1.5857 - val_ca2-[8.0,9.5): 0.5757 - val_ca2-[9.5,10.3): 0.4009 - val_ca2-[10.3,11.3): 0.8629 - val_ca2-[11.3,14.9): 1.5125 - val_ca3-[8.0,9.5): 0.8280 - val_ca3-[9.5,10.3): 0.5116 - val_ca3-[10.3,11.3): 0.6942 - val_ca3-[11.3,14.9): 0.9395 - val_ca4-[8.0,9.5): 1.5649 - val_ca4-[9.5,10.3): 1.1353 - val_ca4-[10.3,11.3): 0.9823 - val_ca4-[11.3,14.9): 0.7182\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5137 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3381 - ca2-[9.5,10.3): 0.4854 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4879 - ca3-[10.3,11.3): 0.6783 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5181 - ca4-[11.3,14.9): 0.6869 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9190 - val_ca1-[11.3,14.9): 1.5799 - val_ca2-[8.0,9.5): 0.5752 - val_ca2-[9.5,10.3): 0.4012 - val_ca2-[10.3,11.3): 0.8706 - val_ca2-[11.3,14.9): 1.5076 - val_ca3-[8.0,9.5): 0.8263 - val_ca3-[9.5,10.3): 0.5077 - val_ca3-[10.3,11.3): 0.6967 - val_ca3-[11.3,14.9): 0.9304 - val_ca4-[8.0,9.5): 1.5641 - val_ca4-[9.5,10.3): 1.1346 - val_ca4-[10.3,11.3): 0.9826 - val_ca4-[11.3,14.9): 0.7060\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5129 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3456 - ca2-[9.5,10.3): 0.4912 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5080 - ca3-[10.3,11.3): 0.6797 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5626 - ca4-[11.3,14.9): 0.6897 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9152 - val_ca1-[11.3,14.9): 1.5316 - val_ca2-[8.0,9.5): 0.5778 - val_ca2-[9.5,10.3): 0.3995 - val_ca2-[10.3,11.3): 0.8578 - val_ca2-[11.3,14.9): 1.4471 - val_ca3-[8.0,9.5): 0.8299 - val_ca3-[9.5,10.3): 0.5086 - val_ca3-[10.3,11.3): 0.6912 - val_ca3-[11.3,14.9): 0.8959 - val_ca4-[8.0,9.5): 1.5644 - val_ca4-[9.5,10.3): 1.1348 - val_ca4-[10.3,11.3): 0.9775 - val_ca4-[11.3,14.9): 0.6793\n",
      "Epoch 193/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5233 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3631 - ca2-[9.5,10.3): 0.4863 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5003 - ca3-[10.3,11.3): 0.6626 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5669 - ca4-[11.3,14.9): 0.6860 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4218 - val_ca1-[10.3,11.3): 0.9169 - val_ca1-[11.3,14.9): 1.5662 - val_ca2-[8.0,9.5): 0.5775 - val_ca2-[9.5,10.3): 0.3995 - val_ca2-[10.3,11.3): 0.8620 - val_ca2-[11.3,14.9): 1.4869 - val_ca3-[8.0,9.5): 0.8436 - val_ca3-[9.5,10.3): 0.5208 - val_ca3-[10.3,11.3): 0.6920 - val_ca3-[11.3,14.9): 0.9097 - val_ca4-[8.0,9.5): 1.5651 - val_ca4-[9.5,10.3): 1.1386 - val_ca4-[10.3,11.3): 0.9804 - val_ca4-[11.3,14.9): 0.7045\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5236 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3433 - ca2-[9.5,10.3): 0.4623 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5270 - ca3-[10.3,11.3): 0.6797 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5958 - ca4-[11.3,14.9): 0.6941 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9099 - val_ca1-[11.3,14.9): 1.5558 - val_ca2-[8.0,9.5): 0.5789 - val_ca2-[9.5,10.3): 0.3995 - val_ca2-[10.3,11.3): 0.8512 - val_ca2-[11.3,14.9): 1.4603 - val_ca3-[8.0,9.5): 0.8453 - val_ca3-[9.5,10.3): 0.5187 - val_ca3-[10.3,11.3): 0.6883 - val_ca3-[11.3,14.9): 0.9009 - val_ca4-[8.0,9.5): 1.5663 - val_ca4-[9.5,10.3): 1.1363 - val_ca4-[10.3,11.3): 0.9803 - val_ca4-[11.3,14.9): 0.7049\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5136 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3563 - ca2-[9.5,10.3): 0.4871 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4995 - ca3-[10.3,11.3): 0.6562 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5411 - ca4-[11.3,14.9): 0.6958 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9189 - val_ca1-[11.3,14.9): 1.5610 - val_ca2-[8.0,9.5): 0.5784 - val_ca2-[9.5,10.3): 0.4004 - val_ca2-[10.3,11.3): 0.8600 - val_ca2-[11.3,14.9): 1.4784 - val_ca3-[8.0,9.5): 0.8374 - val_ca3-[9.5,10.3): 0.5091 - val_ca3-[10.3,11.3): 0.6862 - val_ca3-[11.3,14.9): 0.9211 - val_ca4-[8.0,9.5): 1.5685 - val_ca4-[9.5,10.3): 1.1382 - val_ca4-[10.3,11.3): 0.9735 - val_ca4-[11.3,14.9): 0.7027\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5165 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3462 - ca2-[9.5,10.3): 0.4705 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4916 - ca3-[10.3,11.3): 0.6876 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5761 - ca4-[11.3,14.9): 0.7052 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9163 - val_ca1-[11.3,14.9): 1.5754 - val_ca2-[8.0,9.5): 0.5800 - val_ca2-[9.5,10.3): 0.3995 - val_ca2-[10.3,11.3): 0.8526 - val_ca2-[11.3,14.9): 1.4708 - val_ca3-[8.0,9.5): 0.8493 - val_ca3-[9.5,10.3): 0.5181 - val_ca3-[10.3,11.3): 0.6890 - val_ca3-[11.3,14.9): 0.9129 - val_ca4-[8.0,9.5): 1.5703 - val_ca4-[9.5,10.3): 1.1397 - val_ca4-[10.3,11.3): 0.9830 - val_ca4-[11.3,14.9): 0.7126\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5154 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3565 - ca2-[9.5,10.3): 0.4845 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5056 - ca3-[10.3,11.3): 0.6713 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5828 - ca4-[11.3,14.9): 0.6940 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9060 - val_ca1-[11.3,14.9): 1.5903 - val_ca2-[8.0,9.5): 0.5805 - val_ca2-[9.5,10.3): 0.3996 - val_ca2-[10.3,11.3): 0.8458 - val_ca2-[11.3,14.9): 1.4906 - val_ca3-[8.0,9.5): 0.8584 - val_ca3-[9.5,10.3): 0.5248 - val_ca3-[10.3,11.3): 0.6805 - val_ca3-[11.3,14.9): 0.9055 - val_ca4-[8.0,9.5): 1.5697 - val_ca4-[9.5,10.3): 1.1391 - val_ca4-[10.3,11.3): 0.9672 - val_ca4-[11.3,14.9): 0.6856\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5303 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3651 - ca2-[9.5,10.3): 0.4862 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5103 - ca3-[10.3,11.3): 0.6571 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5711 - ca4-[11.3,14.9): 0.6822 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9098 - val_ca1-[11.3,14.9): 1.5690 - val_ca2-[8.0,9.5): 0.5811 - val_ca2-[9.5,10.3): 0.3998 - val_ca2-[10.3,11.3): 0.8476 - val_ca2-[11.3,14.9): 1.4710 - val_ca3-[8.0,9.5): 0.8468 - val_ca3-[9.5,10.3): 0.5130 - val_ca3-[10.3,11.3): 0.6852 - val_ca3-[11.3,14.9): 0.9155 - val_ca4-[8.0,9.5): 1.5684 - val_ca4-[9.5,10.3): 1.1379 - val_ca4-[10.3,11.3): 0.9812 - val_ca4-[11.3,14.9): 0.7063\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5278 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3439 - ca2-[9.5,10.3): 0.4683 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4911 - ca3-[10.3,11.3): 0.6697 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5536 - ca4-[11.3,14.9): 0.6997 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9167 - val_ca1-[11.3,14.9): 1.5863 - val_ca2-[8.0,9.5): 0.5831 - val_ca2-[9.5,10.3): 0.3988 - val_ca2-[10.3,11.3): 0.8468 - val_ca2-[11.3,14.9): 1.4761 - val_ca3-[8.0,9.5): 0.8617 - val_ca3-[9.5,10.3): 0.5254 - val_ca3-[10.3,11.3): 0.6873 - val_ca3-[11.3,14.9): 0.9044 - val_ca4-[8.0,9.5): 1.5670 - val_ca4-[9.5,10.3): 1.1367 - val_ca4-[10.3,11.3): 0.9812 - val_ca4-[11.3,14.9): 0.6952\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5158 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3531 - ca2-[9.5,10.3): 0.4817 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5026 - ca3-[10.3,11.3): 0.6493 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5965 - ca4-[11.3,14.9): 0.6932 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9153 - val_ca1-[11.3,14.9): 1.5515 - val_ca2-[8.0,9.5): 0.5823 - val_ca2-[9.5,10.3): 0.3999 - val_ca2-[10.3,11.3): 0.8500 - val_ca2-[11.3,14.9): 1.4509 - val_ca3-[8.0,9.5): 0.8614 - val_ca3-[9.5,10.3): 0.5236 - val_ca3-[10.3,11.3): 0.6842 - val_ca3-[11.3,14.9): 0.8805 - val_ca4-[8.0,9.5): 1.5655 - val_ca4-[9.5,10.3): 1.1354 - val_ca4-[10.3,11.3): 0.9778 - val_ca4-[11.3,14.9): 0.6926\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5235 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3610 - ca2-[9.5,10.3): 0.4872 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5124 - ca3-[10.3,11.3): 0.6623 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5977 - ca4-[11.3,14.9): 0.7024 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9194 - val_ca1-[11.3,14.9): 1.5941 - val_ca2-[8.0,9.5): 0.5840 - val_ca2-[9.5,10.3): 0.3988 - val_ca2-[10.3,11.3): 0.8469 - val_ca2-[11.3,14.9): 1.4784 - val_ca3-[8.0,9.5): 0.8677 - val_ca3-[9.5,10.3): 0.5281 - val_ca3-[10.3,11.3): 0.6882 - val_ca3-[11.3,14.9): 0.9050 - val_ca4-[8.0,9.5): 1.5650 - val_ca4-[9.5,10.3): 1.1349 - val_ca4-[10.3,11.3): 0.9827 - val_ca4-[11.3,14.9): 0.7072\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5232 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3610 - ca2-[9.5,10.3): 0.4824 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4829 - ca3-[10.3,11.3): 0.6643 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5760 - ca4-[11.3,14.9): 0.6805 - val_ca1-[8.0,9.5): 0.5838 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9153 - val_ca1-[11.3,14.9): 1.5870 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3997 - val_ca2-[10.3,11.3): 0.8396 - val_ca2-[11.3,14.9): 1.4669 - val_ca3-[8.0,9.5): 0.8613 - val_ca3-[9.5,10.3): 0.5210 - val_ca3-[10.3,11.3): 0.6839 - val_ca3-[11.3,14.9): 0.9146 - val_ca4-[8.0,9.5): 1.5698 - val_ca4-[9.5,10.3): 1.1387 - val_ca4-[10.3,11.3): 0.9778 - val_ca4-[11.3,14.9): 0.7064\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5075 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3415 - ca2-[9.5,10.3): 0.4701 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4889 - ca3-[10.3,11.3): 0.6494 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5828 - ca4-[11.3,14.9): 0.7044 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4219 - val_ca1-[10.3,11.3): 0.9197 - val_ca1-[11.3,14.9): 1.5612 - val_ca2-[8.0,9.5): 0.5846 - val_ca2-[9.5,10.3): 0.3979 - val_ca2-[10.3,11.3): 0.8427 - val_ca2-[11.3,14.9): 1.4367 - val_ca3-[8.0,9.5): 0.8671 - val_ca3-[9.5,10.3): 0.5268 - val_ca3-[10.3,11.3): 0.6860 - val_ca3-[11.3,14.9): 0.8865 - val_ca4-[8.0,9.5): 1.5666 - val_ca4-[9.5,10.3): 1.1395 - val_ca4-[10.3,11.3): 0.9835 - val_ca4-[11.3,14.9): 0.7037\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5221 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3670 - ca2-[9.5,10.3): 0.4828 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5010 - ca3-[10.3,11.3): 0.6427 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5162 - ca4-[11.3,14.9): 0.6709 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9200 - val_ca1-[11.3,14.9): 1.5943 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3982 - val_ca2-[10.3,11.3): 0.8386 - val_ca2-[11.3,14.9): 1.4554 - val_ca3-[8.0,9.5): 0.8714 - val_ca3-[9.5,10.3): 0.5283 - val_ca3-[10.3,11.3): 0.6810 - val_ca3-[11.3,14.9): 0.9002 - val_ca4-[8.0,9.5): 1.5667 - val_ca4-[9.5,10.3): 1.1363 - val_ca4-[10.3,11.3): 0.9779 - val_ca4-[11.3,14.9): 0.7185\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5217 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3417 - ca2-[9.5,10.3): 0.4791 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5115 - ca3-[10.3,11.3): 0.6505 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5373 - ca4-[11.3,14.9): 0.6912 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9176 - val_ca1-[11.3,14.9): 1.5872 - val_ca2-[8.0,9.5): 0.5844 - val_ca2-[9.5,10.3): 0.3988 - val_ca2-[10.3,11.3): 0.8404 - val_ca2-[11.3,14.9): 1.4647 - val_ca3-[8.0,9.5): 0.8683 - val_ca3-[9.5,10.3): 0.5249 - val_ca3-[10.3,11.3): 0.6819 - val_ca3-[11.3,14.9): 0.9041 - val_ca4-[8.0,9.5): 1.5666 - val_ca4-[9.5,10.3): 1.1361 - val_ca4-[10.3,11.3): 0.9808 - val_ca4-[11.3,14.9): 0.7178\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5160 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3514 - ca2-[9.5,10.3): 0.4747 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5185 - ca3-[10.3,11.3): 0.6574 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5754 - ca4-[11.3,14.9): 0.6965 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9174 - val_ca1-[11.3,14.9): 1.5512 - val_ca2-[8.0,9.5): 0.5832 - val_ca2-[9.5,10.3): 0.3999 - val_ca2-[10.3,11.3): 0.8476 - val_ca2-[11.3,14.9): 1.4463 - val_ca3-[8.0,9.5): 0.8802 - val_ca3-[9.5,10.3): 0.5341 - val_ca3-[10.3,11.3): 0.6800 - val_ca3-[11.3,14.9): 0.8676 - val_ca4-[8.0,9.5): 1.5677 - val_ca4-[9.5,10.3): 1.1371 - val_ca4-[10.3,11.3): 0.9813 - val_ca4-[11.3,14.9): 0.7038\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5211 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3590 - ca2-[9.5,10.3): 0.4771 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5287 - ca3-[10.3,11.3): 0.6485 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5769 - ca4-[11.3,14.9): 0.6920 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9150 - val_ca1-[11.3,14.9): 1.5380 - val_ca2-[8.0,9.5): 0.5852 - val_ca2-[9.5,10.3): 0.3984 - val_ca2-[10.3,11.3): 0.8366 - val_ca2-[11.3,14.9): 1.4025 - val_ca3-[8.0,9.5): 0.8728 - val_ca3-[9.5,10.3): 0.5269 - val_ca3-[10.3,11.3): 0.6766 - val_ca3-[11.3,14.9): 0.8514 - val_ca4-[8.0,9.5): 1.5681 - val_ca4-[9.5,10.3): 1.1374 - val_ca4-[10.3,11.3): 0.9789 - val_ca4-[11.3,14.9): 0.6793\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5147 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3489 - ca2-[9.5,10.3): 0.4801 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5158 - ca3-[10.3,11.3): 0.6529 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5316 - ca4-[11.3,14.9): 0.7010 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9152 - val_ca1-[11.3,14.9): 1.5906 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.3998 - val_ca2-[10.3,11.3): 0.8418 - val_ca2-[11.3,14.9): 1.4674 - val_ca3-[8.0,9.5): 0.8794 - val_ca3-[9.5,10.3): 0.5308 - val_ca3-[10.3,11.3): 0.6753 - val_ca3-[11.3,14.9): 0.8883 - val_ca4-[8.0,9.5): 1.5671 - val_ca4-[9.5,10.3): 1.1365 - val_ca4-[10.3,11.3): 0.9784 - val_ca4-[11.3,14.9): 0.7139\n",
      "Epoch 209/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5337 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3546 - ca2-[9.5,10.3): 0.4784 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5141 - ca3-[10.3,11.3): 0.6494 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5696 - ca4-[11.3,14.9): 0.6820 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.6174 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3987 - val_ca2-[10.3,11.3): 0.8398 - val_ca2-[11.3,14.9): 1.4863 - val_ca3-[8.0,9.5): 0.8666 - val_ca3-[9.5,10.3): 0.5201 - val_ca3-[10.3,11.3): 0.6788 - val_ca3-[11.3,14.9): 0.9204 - val_ca4-[8.0,9.5): 1.5659 - val_ca4-[9.5,10.3): 1.1354 - val_ca4-[10.3,11.3): 0.9803 - val_ca4-[11.3,14.9): 0.7166\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5227 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3584 - ca2-[9.5,10.3): 0.4850 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5245 - ca3-[10.3,11.3): 0.6461 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5821 - ca4-[11.3,14.9): 0.6912 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9149 - val_ca1-[11.3,14.9): 1.5647 - val_ca2-[8.0,9.5): 0.5855 - val_ca2-[9.5,10.3): 0.3991 - val_ca2-[10.3,11.3): 0.8395 - val_ca2-[11.3,14.9): 1.4409 - val_ca3-[8.0,9.5): 0.8730 - val_ca3-[9.5,10.3): 0.5251 - val_ca3-[10.3,11.3): 0.6773 - val_ca3-[11.3,14.9): 0.8680 - val_ca4-[8.0,9.5): 1.5661 - val_ca4-[9.5,10.3): 1.1355 - val_ca4-[10.3,11.3): 0.9778 - val_ca4-[11.3,14.9): 0.6765\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5204 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3695 - ca2-[9.5,10.3): 0.4731 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5415 - ca3-[10.3,11.3): 0.6504 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5419 - ca4-[11.3,14.9): 0.6794 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4148 - val_ca1-[10.3,11.3): 0.9074 - val_ca1-[11.3,14.9): 1.5947 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.3912 - val_ca2-[10.3,11.3): 0.8321 - val_ca2-[11.3,14.9): 1.4783 - val_ca3-[8.0,9.5): 0.8742 - val_ca3-[9.5,10.3): 0.5218 - val_ca3-[10.3,11.3): 0.6751 - val_ca3-[11.3,14.9): 0.8965 - val_ca4-[8.0,9.5): 1.5639 - val_ca4-[9.5,10.3): 1.1361 - val_ca4-[10.3,11.3): 0.9830 - val_ca4-[11.3,14.9): 0.7059\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5219 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3665 - ca2-[9.5,10.3): 0.4759 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5231 - ca3-[10.3,11.3): 0.6550 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5452 - ca4-[11.3,14.9): 0.6895 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9151 - val_ca1-[11.3,14.9): 1.5709 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3980 - val_ca2-[10.3,11.3): 0.8324 - val_ca2-[11.3,14.9): 1.4330 - val_ca3-[8.0,9.5): 0.8794 - val_ca3-[9.5,10.3): 0.5288 - val_ca3-[10.3,11.3): 0.6746 - val_ca3-[11.3,14.9): 0.8717 - val_ca4-[8.0,9.5): 1.5626 - val_ca4-[9.5,10.3): 1.1325 - val_ca4-[10.3,11.3): 0.9760 - val_ca4-[11.3,14.9): 0.7001\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5154 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3716 - ca2-[9.5,10.3): 0.4809 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5025 - ca3-[10.3,11.3): 0.6395 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5290 - ca4-[11.3,14.9): 0.6738 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9135 - val_ca1-[11.3,14.9): 1.5722 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3976 - val_ca2-[10.3,11.3): 0.8323 - val_ca2-[11.3,14.9): 1.4388 - val_ca3-[8.0,9.5): 0.8790 - val_ca3-[9.5,10.3): 0.5280 - val_ca3-[10.3,11.3): 0.6732 - val_ca3-[11.3,14.9): 0.8791 - val_ca4-[8.0,9.5): 1.5622 - val_ca4-[9.5,10.3): 1.1320 - val_ca4-[10.3,11.3): 0.9636 - val_ca4-[11.3,14.9): 0.6832\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5072 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3598 - ca2-[9.5,10.3): 0.4819 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5308 - ca3-[10.3,11.3): 0.6355 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5900 - ca4-[11.3,14.9): 0.6928 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9084 - val_ca1-[11.3,14.9): 1.5781 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3991 - val_ca2-[10.3,11.3): 0.8353 - val_ca2-[11.3,14.9): 1.4603 - val_ca3-[8.0,9.5): 0.8723 - val_ca3-[9.5,10.3): 0.5221 - val_ca3-[10.3,11.3): 0.6756 - val_ca3-[11.3,14.9): 0.8930 - val_ca4-[8.0,9.5): 1.5631 - val_ca4-[9.5,10.3): 1.1328 - val_ca4-[10.3,11.3): 0.9825 - val_ca4-[11.3,14.9): 0.7179\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5254 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3563 - ca2-[9.5,10.3): 0.4822 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5244 - ca3-[10.3,11.3): 0.6564 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6027 - ca4-[11.3,14.9): 0.6989 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.9118 - val_ca1-[11.3,14.9): 1.5676 - val_ca2-[8.0,9.5): 0.5893 - val_ca2-[9.5,10.3): 0.3966 - val_ca2-[10.3,11.3): 0.8186 - val_ca2-[11.3,14.9): 1.4137 - val_ca3-[8.0,9.5): 0.8870 - val_ca3-[9.5,10.3): 0.5349 - val_ca3-[10.3,11.3): 0.6631 - val_ca3-[11.3,14.9): 0.8606 - val_ca4-[8.0,9.5): 1.5627 - val_ca4-[9.5,10.3): 1.1325 - val_ca4-[10.3,11.3): 0.9611 - val_ca4-[11.3,14.9): 0.7040\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5234 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3717 - ca2-[9.5,10.3): 0.4748 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5027 - ca3-[10.3,11.3): 0.6353 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5698 - ca4-[11.3,14.9): 0.6861 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9147 - val_ca1-[11.3,14.9): 1.5561 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3978 - val_ca2-[10.3,11.3): 0.8326 - val_ca2-[11.3,14.9): 1.4203 - val_ca3-[8.0,9.5): 0.8771 - val_ca3-[9.5,10.3): 0.5252 - val_ca3-[10.3,11.3): 0.6725 - val_ca3-[11.3,14.9): 0.8724 - val_ca4-[8.0,9.5): 1.5634 - val_ca4-[9.5,10.3): 1.1330 - val_ca4-[10.3,11.3): 0.9762 - val_ca4-[11.3,14.9): 0.7098\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5303 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3568 - ca2-[9.5,10.3): 0.4601 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5017 - ca3-[10.3,11.3): 0.6413 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5531 - ca4-[11.3,14.9): 0.6794 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5909 - val_ca2-[8.0,9.5): 0.5860 - val_ca2-[9.5,10.3): 0.3981 - val_ca2-[10.3,11.3): 0.8369 - val_ca2-[11.3,14.9): 1.4639 - val_ca3-[8.0,9.5): 0.8794 - val_ca3-[9.5,10.3): 0.5257 - val_ca3-[10.3,11.3): 0.6728 - val_ca3-[11.3,14.9): 0.8900 - val_ca4-[8.0,9.5): 1.5638 - val_ca4-[9.5,10.3): 1.1333 - val_ca4-[10.3,11.3): 0.9790 - val_ca4-[11.3,14.9): 0.7124\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5227 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3593 - ca2-[9.5,10.3): 0.4744 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5362 - ca3-[10.3,11.3): 0.6491 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5922 - ca4-[11.3,14.9): 0.6832 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9115 - val_ca1-[11.3,14.9): 1.5695 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3986 - val_ca2-[10.3,11.3): 0.8366 - val_ca2-[11.3,14.9): 1.4472 - val_ca3-[8.0,9.5): 0.8780 - val_ca3-[9.5,10.3): 0.5236 - val_ca3-[10.3,11.3): 0.6719 - val_ca3-[11.3,14.9): 0.8577 - val_ca4-[8.0,9.5): 1.5641 - val_ca4-[9.5,10.3): 1.1335 - val_ca4-[10.3,11.3): 0.9810 - val_ca4-[11.3,14.9): 0.6826\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5221 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3583 - ca2-[9.5,10.3): 0.4768 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5152 - ca3-[10.3,11.3): 0.6496 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5321 - ca4-[11.3,14.9): 0.6967 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9165 - val_ca1-[11.3,14.9): 1.5963 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3969 - val_ca2-[10.3,11.3): 0.8315 - val_ca2-[11.3,14.9): 1.4603 - val_ca3-[8.0,9.5): 0.8849 - val_ca3-[9.5,10.3): 0.5293 - val_ca3-[10.3,11.3): 0.6718 - val_ca3-[11.3,14.9): 0.8860 - val_ca4-[8.0,9.5): 1.5647 - val_ca4-[9.5,10.3): 1.1340 - val_ca4-[10.3,11.3): 0.9793 - val_ca4-[11.3,14.9): 0.7087\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5231 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3675 - ca2-[9.5,10.3): 0.4760 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5346 - ca3-[10.3,11.3): 0.6193 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5689 - ca4-[11.3,14.9): 0.6762 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9173 - val_ca1-[11.3,14.9): 1.5906 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3973 - val_ca2-[10.3,11.3): 0.8364 - val_ca2-[11.3,14.9): 1.4630 - val_ca3-[8.0,9.5): 0.8792 - val_ca3-[9.5,10.3): 0.5226 - val_ca3-[10.3,11.3): 0.6689 - val_ca3-[11.3,14.9): 0.8913 - val_ca4-[8.0,9.5): 1.5647 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9737 - val_ca4-[11.3,14.9): 0.7136\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5183 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3617 - ca2-[9.5,10.3): 0.4767 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4986 - ca3-[10.3,11.3): 0.6414 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5439 - ca4-[11.3,14.9): 0.6970 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4214 - val_ca1-[10.3,11.3): 0.9213 - val_ca1-[11.3,14.9): 1.5887 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.3980 - val_ca2-[10.3,11.3): 0.8437 - val_ca2-[11.3,14.9): 1.4670 - val_ca3-[8.0,9.5): 0.8718 - val_ca3-[9.5,10.3): 0.5160 - val_ca3-[10.3,11.3): 0.6695 - val_ca3-[11.3,14.9): 0.8922 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1327 - val_ca4-[10.3,11.3): 0.9782 - val_ca4-[11.3,14.9): 0.7161\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5061 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3597 - ca2-[9.5,10.3): 0.4735 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5317 - ca3-[10.3,11.3): 0.6299 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5689 - ca4-[11.3,14.9): 0.6908 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5761 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.3953 - val_ca2-[10.3,11.3): 0.8255 - val_ca2-[11.3,14.9): 1.4230 - val_ca3-[8.0,9.5): 0.8809 - val_ca3-[9.5,10.3): 0.5248 - val_ca3-[10.3,11.3): 0.6688 - val_ca3-[11.3,14.9): 0.8627 - val_ca4-[8.0,9.5): 1.5631 - val_ca4-[9.5,10.3): 1.1359 - val_ca4-[10.3,11.3): 0.9784 - val_ca4-[11.3,14.9): 0.6863\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5320 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3780 - ca2-[9.5,10.3): 0.4881 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5186 - ca3-[10.3,11.3): 0.6265 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5495 - ca4-[11.3,14.9): 0.6894 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9118 - val_ca1-[11.3,14.9): 1.5897 - val_ca2-[8.0,9.5): 0.5859 - val_ca2-[9.5,10.3): 0.3973 - val_ca2-[10.3,11.3): 0.8340 - val_ca2-[11.3,14.9): 1.4618 - val_ca3-[8.0,9.5): 0.8765 - val_ca3-[9.5,10.3): 0.5200 - val_ca3-[10.3,11.3): 0.6699 - val_ca3-[11.3,14.9): 0.8784 - val_ca4-[8.0,9.5): 1.5623 - val_ca4-[9.5,10.3): 1.1318 - val_ca4-[10.3,11.3): 0.9799 - val_ca4-[11.3,14.9): 0.7020\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5200 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3501 - ca2-[9.5,10.3): 0.4664 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4963 - ca3-[10.3,11.3): 0.6254 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5505 - ca4-[11.3,14.9): 0.6908 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9176 - val_ca1-[11.3,14.9): 1.5807 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.3961 - val_ca2-[10.3,11.3): 0.8339 - val_ca2-[11.3,14.9): 1.4450 - val_ca3-[8.0,9.5): 0.8760 - val_ca3-[9.5,10.3): 0.5193 - val_ca3-[10.3,11.3): 0.6723 - val_ca3-[11.3,14.9): 0.8864 - val_ca4-[8.0,9.5): 1.5603 - val_ca4-[9.5,10.3): 1.1300 - val_ca4-[10.3,11.3): 0.9795 - val_ca4-[11.3,14.9): 0.7126\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3545 - ca2-[9.5,10.3): 0.4725 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5135 - ca3-[10.3,11.3): 0.6360 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5457 - ca4-[11.3,14.9): 0.6846 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9199 - val_ca1-[11.3,14.9): 1.5419 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.3969 - val_ca2-[10.3,11.3): 0.8401 - val_ca2-[11.3,14.9): 1.4261 - val_ca3-[8.0,9.5): 0.8771 - val_ca3-[9.5,10.3): 0.5183 - val_ca3-[10.3,11.3): 0.6633 - val_ca3-[11.3,14.9): 0.8563 - val_ca4-[8.0,9.5): 1.5602 - val_ca4-[9.5,10.3): 1.1299 - val_ca4-[10.3,11.3): 0.9708 - val_ca4-[11.3,14.9): 0.6986\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5122 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3546 - ca2-[9.5,10.3): 0.4832 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5376 - ca3-[10.3,11.3): 0.6278 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5526 - ca4-[11.3,14.9): 0.6833 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5671 - val_ca2-[8.0,9.5): 0.5858 - val_ca2-[9.5,10.3): 0.3963 - val_ca2-[10.3,11.3): 0.8354 - val_ca2-[11.3,14.9): 1.4453 - val_ca3-[8.0,9.5): 0.8825 - val_ca3-[9.5,10.3): 0.5225 - val_ca3-[10.3,11.3): 0.6668 - val_ca3-[11.3,14.9): 0.8669 - val_ca4-[8.0,9.5): 1.5599 - val_ca4-[9.5,10.3): 1.1296 - val_ca4-[10.3,11.3): 0.9766 - val_ca4-[11.3,14.9): 0.7054\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5054 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3587 - ca2-[9.5,10.3): 0.4773 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5254 - ca3-[10.3,11.3): 0.6278 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5351 - ca4-[11.3,14.9): 0.6903 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5894 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.3944 - val_ca2-[10.3,11.3): 0.8246 - val_ca2-[11.3,14.9): 1.4361 - val_ca3-[8.0,9.5): 0.8780 - val_ca3-[9.5,10.3): 0.5179 - val_ca3-[10.3,11.3): 0.6669 - val_ca3-[11.3,14.9): 0.8792 - val_ca4-[8.0,9.5): 1.5606 - val_ca4-[9.5,10.3): 1.1302 - val_ca4-[10.3,11.3): 0.9769 - val_ca4-[11.3,14.9): 0.7180\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5358 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3551 - ca2-[9.5,10.3): 0.4600 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5301 - ca3-[10.3,11.3): 0.6335 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5695 - ca4-[11.3,14.9): 0.6866 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9141 - val_ca1-[11.3,14.9): 1.5755 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3948 - val_ca2-[10.3,11.3): 0.8267 - val_ca2-[11.3,14.9): 1.4388 - val_ca3-[8.0,9.5): 0.8892 - val_ca3-[9.5,10.3): 0.5264 - val_ca3-[10.3,11.3): 0.6647 - val_ca3-[11.3,14.9): 0.8642 - val_ca4-[8.0,9.5): 1.5618 - val_ca4-[9.5,10.3): 1.1311 - val_ca4-[10.3,11.3): 0.9748 - val_ca4-[11.3,14.9): 0.7003\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5047 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3477 - ca2-[9.5,10.3): 0.4721 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5294 - ca3-[10.3,11.3): 0.6299 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6193 - ca4-[11.3,14.9): 0.7030 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9162 - val_ca1-[11.3,14.9): 1.5707 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3951 - val_ca2-[10.3,11.3): 0.8303 - val_ca2-[11.3,14.9): 1.4426 - val_ca3-[8.0,9.5): 0.8806 - val_ca3-[9.5,10.3): 0.5186 - val_ca3-[10.3,11.3): 0.6641 - val_ca3-[11.3,14.9): 0.8743 - val_ca4-[8.0,9.5): 1.5616 - val_ca4-[9.5,10.3): 1.1309 - val_ca4-[10.3,11.3): 0.9717 - val_ca4-[11.3,14.9): 0.7099\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5193 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3648 - ca2-[9.5,10.3): 0.4678 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5537 - ca3-[10.3,11.3): 0.6151 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5707 - ca4-[11.3,14.9): 0.6958 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9160 - val_ca1-[11.3,14.9): 1.5755 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.3949 - val_ca2-[10.3,11.3): 0.8309 - val_ca2-[11.3,14.9): 1.4403 - val_ca3-[8.0,9.5): 0.8912 - val_ca3-[9.5,10.3): 0.5256 - val_ca3-[10.3,11.3): 0.6647 - val_ca3-[11.3,14.9): 0.8562 - val_ca4-[8.0,9.5): 1.5614 - val_ca4-[9.5,10.3): 1.1307 - val_ca4-[10.3,11.3): 0.9771 - val_ca4-[11.3,14.9): 0.7000\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5169 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3534 - ca2-[9.5,10.3): 0.4679 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5347 - ca3-[10.3,11.3): 0.6268 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5276 - ca4-[11.3,14.9): 0.6790 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9095 - val_ca1-[11.3,14.9): 1.6086 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3945 - val_ca2-[10.3,11.3): 0.8249 - val_ca2-[11.3,14.9): 1.4779 - val_ca3-[8.0,9.5): 0.8815 - val_ca3-[9.5,10.3): 0.5173 - val_ca3-[10.3,11.3): 0.6629 - val_ca3-[11.3,14.9): 0.8953 - val_ca4-[8.0,9.5): 1.5626 - val_ca4-[9.5,10.3): 1.1317 - val_ca4-[10.3,11.3): 0.9770 - val_ca4-[11.3,14.9): 0.7154\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5251 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3646 - ca2-[9.5,10.3): 0.4549 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4992 - ca3-[10.3,11.3): 0.6282 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5564 - ca4-[11.3,14.9): 0.7004 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9071 - val_ca1-[11.3,14.9): 1.5970 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3948 - val_ca2-[10.3,11.3): 0.8241 - val_ca2-[11.3,14.9): 1.4631 - val_ca3-[8.0,9.5): 0.8872 - val_ca3-[9.5,10.3): 0.5219 - val_ca3-[10.3,11.3): 0.6637 - val_ca3-[11.3,14.9): 0.8825 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1296 - val_ca4-[10.3,11.3): 0.9652 - val_ca4-[11.3,14.9): 0.7014\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5192 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3528 - ca2-[9.5,10.3): 0.4529 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5390 - ca3-[10.3,11.3): 0.6145 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5503 - ca4-[11.3,14.9): 0.6884 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4217 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5887 - val_ca2-[8.0,9.5): 0.5881 - val_ca2-[9.5,10.3): 0.3945 - val_ca2-[10.3,11.3): 0.8229 - val_ca2-[11.3,14.9): 1.4454 - val_ca3-[8.0,9.5): 0.8846 - val_ca3-[9.5,10.3): 0.5197 - val_ca3-[10.3,11.3): 0.6587 - val_ca3-[11.3,14.9): 0.8741 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1297 - val_ca4-[10.3,11.3): 0.9739 - val_ca4-[11.3,14.9): 0.7034\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5258 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3567 - ca2-[9.5,10.3): 0.4592 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5124 - ca3-[10.3,11.3): 0.6312 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5521 - ca4-[11.3,14.9): 0.6913 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9136 - val_ca1-[11.3,14.9): 1.6080 - val_ca2-[8.0,9.5): 0.5878 - val_ca2-[9.5,10.3): 0.3934 - val_ca2-[10.3,11.3): 0.8240 - val_ca2-[11.3,14.9): 1.4676 - val_ca3-[8.0,9.5): 0.8819 - val_ca3-[9.5,10.3): 0.5154 - val_ca3-[10.3,11.3): 0.6615 - val_ca3-[11.3,14.9): 0.8873 - val_ca4-[8.0,9.5): 1.5632 - val_ca4-[9.5,10.3): 1.1321 - val_ca4-[10.3,11.3): 0.9752 - val_ca4-[11.3,14.9): 0.7037\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5069 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3680 - ca2-[9.5,10.3): 0.4595 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5068 - ca3-[10.3,11.3): 0.6245 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5568 - ca4-[11.3,14.9): 0.6899 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9157 - val_ca1-[11.3,14.9): 1.5886 - val_ca2-[8.0,9.5): 0.5885 - val_ca2-[9.5,10.3): 0.3931 - val_ca2-[10.3,11.3): 0.8243 - val_ca2-[11.3,14.9): 1.4440 - val_ca3-[8.0,9.5): 0.8922 - val_ca3-[9.5,10.3): 0.5233 - val_ca3-[10.3,11.3): 0.6632 - val_ca3-[11.3,14.9): 0.8619 - val_ca4-[8.0,9.5): 1.5626 - val_ca4-[9.5,10.3): 1.1316 - val_ca4-[10.3,11.3): 0.9775 - val_ca4-[11.3,14.9): 0.6958\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5198 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3478 - ca2-[9.5,10.3): 0.4619 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5211 - ca3-[10.3,11.3): 0.6281 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5728 - ca4-[11.3,14.9): 0.6960 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9112 - val_ca1-[11.3,14.9): 1.5641 - val_ca2-[8.0,9.5): 0.5877 - val_ca2-[9.5,10.3): 0.3928 - val_ca2-[10.3,11.3): 0.8230 - val_ca2-[11.3,14.9): 1.4155 - val_ca3-[8.0,9.5): 0.8944 - val_ca3-[9.5,10.3): 0.5241 - val_ca3-[10.3,11.3): 0.6623 - val_ca3-[11.3,14.9): 0.8422 - val_ca4-[8.0,9.5): 1.5635 - val_ca4-[9.5,10.3): 1.1323 - val_ca4-[10.3,11.3): 0.9798 - val_ca4-[11.3,14.9): 0.6973\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5213 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3603 - ca2-[9.5,10.3): 0.4745 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5313 - ca3-[10.3,11.3): 0.6114 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5084 - ca4-[11.3,14.9): 0.6865 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9178 - val_ca1-[11.3,14.9): 1.5903 - val_ca2-[8.0,9.5): 0.5882 - val_ca2-[9.5,10.3): 0.3922 - val_ca2-[10.3,11.3): 0.8252 - val_ca2-[11.3,14.9): 1.4484 - val_ca3-[8.0,9.5): 0.8742 - val_ca3-[9.5,10.3): 0.5076 - val_ca3-[10.3,11.3): 0.6657 - val_ca3-[11.3,14.9): 0.8922 - val_ca4-[8.0,9.5): 1.5648 - val_ca4-[9.5,10.3): 1.1333 - val_ca4-[10.3,11.3): 0.9756 - val_ca4-[11.3,14.9): 0.7059\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5177 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3560 - ca2-[9.5,10.3): 0.4624 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5483 - ca3-[10.3,11.3): 0.6163 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5329 - ca4-[11.3,14.9): 0.6865 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9087 - val_ca1-[11.3,14.9): 1.5536 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3915 - val_ca2-[10.3,11.3): 0.8172 - val_ca2-[11.3,14.9): 1.4175 - val_ca3-[8.0,9.5): 0.9039 - val_ca3-[9.5,10.3): 0.5315 - val_ca3-[10.3,11.3): 0.6583 - val_ca3-[11.3,14.9): 0.8392 - val_ca4-[8.0,9.5): 1.5633 - val_ca4-[9.5,10.3): 1.1320 - val_ca4-[10.3,11.3): 0.9769 - val_ca4-[11.3,14.9): 0.6976\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5142 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3678 - ca2-[9.5,10.3): 0.4601 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5398 - ca3-[10.3,11.3): 0.6060 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5593 - ca4-[11.3,14.9): 0.6866 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9043 - val_ca1-[11.3,14.9): 1.5603 - val_ca2-[8.0,9.5): 0.5902 - val_ca2-[9.5,10.3): 0.3906 - val_ca2-[10.3,11.3): 0.8123 - val_ca2-[11.3,14.9): 1.4196 - val_ca3-[8.0,9.5): 0.8740 - val_ca3-[9.5,10.3): 0.5073 - val_ca3-[10.3,11.3): 0.6603 - val_ca3-[11.3,14.9): 0.8767 - val_ca4-[8.0,9.5): 1.5642 - val_ca4-[9.5,10.3): 1.1326 - val_ca4-[10.3,11.3): 0.9626 - val_ca4-[11.3,14.9): 0.6755\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5147 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3571 - ca2-[9.5,10.3): 0.4613 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5290 - ca3-[10.3,11.3): 0.6233 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5578 - ca4-[11.3,14.9): 0.6813 - val_ca1-[8.0,9.5): 0.5832 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9106 - val_ca1-[11.3,14.9): 1.5466 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3917 - val_ca2-[10.3,11.3): 0.8262 - val_ca2-[11.3,14.9): 1.4321 - val_ca3-[8.0,9.5): 0.8883 - val_ca3-[9.5,10.3): 0.5177 - val_ca3-[10.3,11.3): 0.6600 - val_ca3-[11.3,14.9): 0.8505 - val_ca4-[8.0,9.5): 1.5639 - val_ca4-[9.5,10.3): 1.1323 - val_ca4-[10.3,11.3): 0.9631 - val_ca4-[11.3,14.9): 0.6684\n",
      "Epoch 241/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5086 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3614 - ca2-[9.5,10.3): 0.4522 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5230 - ca3-[10.3,11.3): 0.6175 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5768 - ca4-[11.3,14.9): 0.6884 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9092 - val_ca1-[11.3,14.9): 1.5469 - val_ca2-[8.0,9.5): 0.5869 - val_ca2-[9.5,10.3): 0.3914 - val_ca2-[10.3,11.3): 0.8232 - val_ca2-[11.3,14.9): 1.4248 - val_ca3-[8.0,9.5): 0.8892 - val_ca3-[9.5,10.3): 0.5182 - val_ca3-[10.3,11.3): 0.6587 - val_ca3-[11.3,14.9): 0.8525 - val_ca4-[8.0,9.5): 1.5631 - val_ca4-[9.5,10.3): 1.1315 - val_ca4-[10.3,11.3): 0.9600 - val_ca4-[11.3,14.9): 0.6854\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5193 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3587 - ca2-[9.5,10.3): 0.4638 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4920 - ca3-[10.3,11.3): 0.6173 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5713 - ca4-[11.3,14.9): 0.6995 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9149 - val_ca1-[11.3,14.9): 1.5661 - val_ca2-[8.0,9.5): 0.5888 - val_ca2-[9.5,10.3): 0.3901 - val_ca2-[10.3,11.3): 0.8177 - val_ca2-[11.3,14.9): 1.4211 - val_ca3-[8.0,9.5): 0.8967 - val_ca3-[9.5,10.3): 0.5225 - val_ca3-[10.3,11.3): 0.6593 - val_ca3-[11.3,14.9): 0.8474 - val_ca4-[8.0,9.5): 1.5624 - val_ca4-[9.5,10.3): 1.1308 - val_ca4-[10.3,11.3): 0.9767 - val_ca4-[11.3,14.9): 0.7044\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5160 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3580 - ca2-[9.5,10.3): 0.4608 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5377 - ca3-[10.3,11.3): 0.6159 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5491 - ca4-[11.3,14.9): 0.6885 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9153 - val_ca1-[11.3,14.9): 1.5746 - val_ca2-[8.0,9.5): 0.5895 - val_ca2-[9.5,10.3): 0.3899 - val_ca2-[10.3,11.3): 0.8154 - val_ca2-[11.3,14.9): 1.4140 - val_ca3-[8.0,9.5): 0.8889 - val_ca3-[9.5,10.3): 0.5161 - val_ca3-[10.3,11.3): 0.6590 - val_ca3-[11.3,14.9): 0.8391 - val_ca4-[8.0,9.5): 1.5637 - val_ca4-[9.5,10.3): 1.1318 - val_ca4-[10.3,11.3): 0.9773 - val_ca4-[11.3,14.9): 0.6879\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5228 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3601 - ca2-[9.5,10.3): 0.4504 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5102 - ca3-[10.3,11.3): 0.6069 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6024 - ca4-[11.3,14.9): 0.6817 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9161 - val_ca1-[11.3,14.9): 1.5780 - val_ca2-[8.0,9.5): 0.5849 - val_ca2-[9.5,10.3): 0.3921 - val_ca2-[10.3,11.3): 0.8285 - val_ca2-[11.3,14.9): 1.4605 - val_ca3-[8.0,9.5): 0.8750 - val_ca3-[9.5,10.3): 0.5065 - val_ca3-[10.3,11.3): 0.6572 - val_ca3-[11.3,14.9): 0.8792 - val_ca4-[8.0,9.5): 1.5657 - val_ca4-[9.5,10.3): 1.1334 - val_ca4-[10.3,11.3): 0.9725 - val_ca4-[11.3,14.9): 0.6927\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5266 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3588 - ca2-[9.5,10.3): 0.4562 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5264 - ca3-[10.3,11.3): 0.6188 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5954 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9138 - val_ca1-[11.3,14.9): 1.5900 - val_ca2-[8.0,9.5): 0.5901 - val_ca2-[9.5,10.3): 0.3886 - val_ca2-[10.3,11.3): 0.8075 - val_ca2-[11.3,14.9): 1.4070 - val_ca3-[8.0,9.5): 0.9007 - val_ca3-[9.5,10.3): 0.5254 - val_ca3-[10.3,11.3): 0.6601 - val_ca3-[11.3,14.9): 0.8502 - val_ca4-[8.0,9.5): 1.5658 - val_ca4-[9.5,10.3): 1.1333 - val_ca4-[10.3,11.3): 0.9826 - val_ca4-[11.3,14.9): 0.7002\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5256 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3491 - ca2-[9.5,10.3): 0.4408 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5479 - ca3-[10.3,11.3): 0.6078 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5547 - ca4-[11.3,14.9): 0.6940 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9165 - val_ca1-[11.3,14.9): 1.5839 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3899 - val_ca2-[10.3,11.3): 0.8238 - val_ca2-[11.3,14.9): 1.4525 - val_ca3-[8.0,9.5): 0.8876 - val_ca3-[9.5,10.3): 0.5144 - val_ca3-[10.3,11.3): 0.6575 - val_ca3-[11.3,14.9): 0.8616 - val_ca4-[8.0,9.5): 1.5665 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9782 - val_ca4-[11.3,14.9): 0.6882\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5197 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3610 - ca2-[9.5,10.3): 0.4544 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5260 - ca3-[10.3,11.3): 0.6154 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5535 - ca4-[11.3,14.9): 0.7051 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9139 - val_ca1-[11.3,14.9): 1.5565 - val_ca2-[8.0,9.5): 0.5880 - val_ca2-[9.5,10.3): 0.3876 - val_ca2-[10.3,11.3): 0.8102 - val_ca2-[11.3,14.9): 1.3952 - val_ca3-[8.0,9.5): 0.8818 - val_ca3-[9.5,10.3): 0.5095 - val_ca3-[10.3,11.3): 0.6546 - val_ca3-[11.3,14.9): 0.8446 - val_ca4-[8.0,9.5): 1.5670 - val_ca4-[9.5,10.3): 1.1341 - val_ca4-[10.3,11.3): 0.9757 - val_ca4-[11.3,14.9): 0.6678\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5139 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3418 - ca2-[9.5,10.3): 0.4465 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5210 - ca3-[10.3,11.3): 0.6146 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5757 - ca4-[11.3,14.9): 0.6899 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9092 - val_ca1-[11.3,14.9): 1.5882 - val_ca2-[8.0,9.5): 0.5851 - val_ca2-[9.5,10.3): 0.3899 - val_ca2-[10.3,11.3): 0.8229 - val_ca2-[11.3,14.9): 1.4721 - val_ca3-[8.0,9.5): 0.8830 - val_ca3-[9.5,10.3): 0.5106 - val_ca3-[10.3,11.3): 0.6542 - val_ca3-[11.3,14.9): 0.8745 - val_ca4-[8.0,9.5): 1.5664 - val_ca4-[9.5,10.3): 1.1335 - val_ca4-[10.3,11.3): 0.9772 - val_ca4-[11.3,14.9): 0.7058\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3412 - ca2-[9.5,10.3): 0.4442 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5414 - ca3-[10.3,11.3): 0.6209 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5923 - ca4-[11.3,14.9): 0.6954 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9087 - val_ca1-[11.3,14.9): 1.5865 - val_ca2-[8.0,9.5): 0.5915 - val_ca2-[9.5,10.3): 0.3855 - val_ca2-[10.3,11.3): 0.7959 - val_ca2-[11.3,14.9): 1.3987 - val_ca3-[8.0,9.5): 0.8818 - val_ca3-[9.5,10.3): 0.5104 - val_ca3-[10.3,11.3): 0.6549 - val_ca3-[11.3,14.9): 0.8660 - val_ca4-[8.0,9.5): 1.5669 - val_ca4-[9.5,10.3): 1.1337 - val_ca4-[10.3,11.3): 0.9772 - val_ca4-[11.3,14.9): 0.7170\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5026 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3441 - ca2-[9.5,10.3): 0.4382 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5007 - ca3-[10.3,11.3): 0.6042 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6059 - ca4-[11.3,14.9): 0.6924 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9045 - val_ca1-[11.3,14.9): 1.5540 - val_ca2-[8.0,9.5): 0.5814 - val_ca2-[9.5,10.3): 0.3888 - val_ca2-[10.3,11.3): 0.8260 - val_ca2-[11.3,14.9): 1.4510 - val_ca3-[8.0,9.5): 0.8905 - val_ca3-[9.5,10.3): 0.5167 - val_ca3-[10.3,11.3): 0.6517 - val_ca3-[11.3,14.9): 0.8422 - val_ca4-[8.0,9.5): 1.5682 - val_ca4-[9.5,10.3): 1.1347 - val_ca4-[10.3,11.3): 0.9631 - val_ca4-[11.3,14.9): 0.6738\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5291 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3532 - ca2-[9.5,10.3): 0.4552 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5732 - ca3-[10.3,11.3): 0.6311 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6216 - ca4-[11.3,14.9): 0.6911 - val_ca1-[8.0,9.5): 0.5831 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9111 - val_ca1-[11.3,14.9): 1.6071 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3847 - val_ca2-[10.3,11.3): 0.8048 - val_ca2-[11.3,14.9): 1.4367 - val_ca3-[8.0,9.5): 0.8937 - val_ca3-[9.5,10.3): 0.5181 - val_ca3-[10.3,11.3): 0.6519 - val_ca3-[11.3,14.9): 0.8631 - val_ca4-[8.0,9.5): 1.5675 - val_ca4-[9.5,10.3): 1.1339 - val_ca4-[10.3,11.3): 0.9632 - val_ca4-[11.3,14.9): 0.6962\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5068 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3541 - ca2-[9.5,10.3): 0.4409 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5262 - ca3-[10.3,11.3): 0.6063 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5444 - ca4-[11.3,14.9): 0.6770 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9139 - val_ca1-[11.3,14.9): 1.5482 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3867 - val_ca2-[10.3,11.3): 0.8181 - val_ca2-[11.3,14.9): 1.4176 - val_ca3-[8.0,9.5): 0.8765 - val_ca3-[9.5,10.3): 0.5066 - val_ca3-[10.3,11.3): 0.6521 - val_ca3-[11.3,14.9): 0.8464 - val_ca4-[8.0,9.5): 1.5682 - val_ca4-[9.5,10.3): 1.1344 - val_ca4-[10.3,11.3): 0.9753 - val_ca4-[11.3,14.9): 0.7010\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5191 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3488 - ca2-[9.5,10.3): 0.4413 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5326 - ca3-[10.3,11.3): 0.6012 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5625 - ca4-[11.3,14.9): 0.6795 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9146 - val_ca1-[11.3,14.9): 1.5644 - val_ca2-[8.0,9.5): 0.5900 - val_ca2-[9.5,10.3): 0.3838 - val_ca2-[10.3,11.3): 0.7979 - val_ca2-[11.3,14.9): 1.3707 - val_ca3-[8.0,9.5): 0.8842 - val_ca3-[9.5,10.3): 0.5127 - val_ca3-[10.3,11.3): 0.6553 - val_ca3-[11.3,14.9): 0.8388 - val_ca4-[8.0,9.5): 1.5661 - val_ca4-[9.5,10.3): 1.1324 - val_ca4-[10.3,11.3): 0.9646 - val_ca4-[11.3,14.9): 0.6680\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5233 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3473 - ca2-[9.5,10.3): 0.4411 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5526 - ca3-[10.3,11.3): 0.6100 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5651 - ca4-[11.3,14.9): 0.6963 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9105 - val_ca1-[11.3,14.9): 1.5515 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3857 - val_ca2-[10.3,11.3): 0.8115 - val_ca2-[11.3,14.9): 1.4234 - val_ca3-[8.0,9.5): 0.8804 - val_ca3-[9.5,10.3): 0.5081 - val_ca3-[10.3,11.3): 0.6501 - val_ca3-[11.3,14.9): 0.8494 - val_ca4-[8.0,9.5): 1.5641 - val_ca4-[9.5,10.3): 1.1305 - val_ca4-[10.3,11.3): 0.9747 - val_ca4-[11.3,14.9): 0.6838\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5096 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3535 - ca2-[9.5,10.3): 0.4490 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5365 - ca3-[10.3,11.3): 0.6185 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5407 - ca4-[11.3,14.9): 0.6798 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9171 - val_ca1-[11.3,14.9): 1.6108 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3838 - val_ca2-[10.3,11.3): 0.8025 - val_ca2-[11.3,14.9): 1.4325 - val_ca3-[8.0,9.5): 0.8781 - val_ca3-[9.5,10.3): 0.5071 - val_ca3-[10.3,11.3): 0.6521 - val_ca3-[11.3,14.9): 0.8778 - val_ca4-[8.0,9.5): 1.5615 - val_ca4-[9.5,10.3): 1.1280 - val_ca4-[10.3,11.3): 0.9737 - val_ca4-[11.3,14.9): 0.7183\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5168 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3379 - ca2-[9.5,10.3): 0.4455 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5256 - ca3-[10.3,11.3): 0.6104 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5844 - ca4-[11.3,14.9): 0.6895 - val_ca1-[8.0,9.5): 0.5838 - val_ca1-[9.5,10.3): 0.4220 - val_ca1-[10.3,11.3): 0.9153 - val_ca1-[11.3,14.9): 1.5611 - val_ca2-[8.0,9.5): 0.5895 - val_ca2-[9.5,10.3): 0.3834 - val_ca2-[10.3,11.3): 0.7949 - val_ca2-[11.3,14.9): 1.3806 - val_ca3-[8.0,9.5): 0.8768 - val_ca3-[9.5,10.3): 0.5050 - val_ca3-[10.3,11.3): 0.6498 - val_ca3-[11.3,14.9): 0.8519 - val_ca4-[8.0,9.5): 1.5592 - val_ca4-[9.5,10.3): 1.1241 - val_ca4-[10.3,11.3): 0.9704 - val_ca4-[11.3,14.9): 0.6887\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5111 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3474 - ca2-[9.5,10.3): 0.4365 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5286 - ca3-[10.3,11.3): 0.6059 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6119 - ca4-[11.3,14.9): 0.6884 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9156 - val_ca1-[11.3,14.9): 1.5725 - val_ca2-[8.0,9.5): 0.5810 - val_ca2-[9.5,10.3): 0.3865 - val_ca2-[10.3,11.3): 0.8227 - val_ca2-[11.3,14.9): 1.4516 - val_ca3-[8.0,9.5): 0.8687 - val_ca3-[9.5,10.3): 0.5004 - val_ca3-[10.3,11.3): 0.6490 - val_ca3-[11.3,14.9): 0.8579 - val_ca4-[8.0,9.5): 1.5602 - val_ca4-[9.5,10.3): 1.1265 - val_ca4-[10.3,11.3): 0.9701 - val_ca4-[11.3,14.9): 0.6967\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5171 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3580 - ca2-[9.5,10.3): 0.4442 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5297 - ca3-[10.3,11.3): 0.6033 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5383 - ca4-[11.3,14.9): 0.6765 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9172 - val_ca1-[11.3,14.9): 1.6072 - val_ca2-[8.0,9.5): 0.5887 - val_ca2-[9.5,10.3): 0.3814 - val_ca2-[10.3,11.3): 0.7945 - val_ca2-[11.3,14.9): 1.4101 - val_ca3-[8.0,9.5): 0.8735 - val_ca3-[9.5,10.3): 0.5041 - val_ca3-[10.3,11.3): 0.6493 - val_ca3-[11.3,14.9): 0.8738 - val_ca4-[8.0,9.5): 1.5608 - val_ca4-[9.5,10.3): 1.1268 - val_ca4-[10.3,11.3): 0.9727 - val_ca4-[11.3,14.9): 0.7098\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5191 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3395 - ca2-[9.5,10.3): 0.4348 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5329 - ca3-[10.3,11.3): 0.6289 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5610 - ca4-[11.3,14.9): 0.7001 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9148 - val_ca1-[11.3,14.9): 1.5836 - val_ca2-[8.0,9.5): 0.5825 - val_ca2-[9.5,10.3): 0.3837 - val_ca2-[10.3,11.3): 0.8122 - val_ca2-[11.3,14.9): 1.4398 - val_ca3-[8.0,9.5): 0.8665 - val_ca3-[9.5,10.3): 0.4999 - val_ca3-[10.3,11.3): 0.6473 - val_ca3-[11.3,14.9): 0.8645 - val_ca4-[8.0,9.5): 1.5607 - val_ca4-[9.5,10.3): 1.1265 - val_ca4-[10.3,11.3): 0.9699 - val_ca4-[11.3,14.9): 0.7086\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5209 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3416 - ca2-[9.5,10.3): 0.4454 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5523 - ca3-[10.3,11.3): 0.6107 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5790 - ca4-[11.3,14.9): 0.6862 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4211 - val_ca1-[10.3,11.3): 0.9145 - val_ca1-[11.3,14.9): 1.5566 - val_ca2-[8.0,9.5): 0.5893 - val_ca2-[9.5,10.3): 0.3807 - val_ca2-[10.3,11.3): 0.7866 - val_ca2-[11.3,14.9): 1.3648 - val_ca3-[8.0,9.5): 0.8728 - val_ca3-[9.5,10.3): 0.5054 - val_ca3-[10.3,11.3): 0.6471 - val_ca3-[11.3,14.9): 0.8489 - val_ca4-[8.0,9.5): 1.5603 - val_ca4-[9.5,10.3): 1.1259 - val_ca4-[10.3,11.3): 0.9694 - val_ca4-[11.3,14.9): 0.6944\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5234 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3362 - ca2-[9.5,10.3): 0.4329 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5362 - ca3-[10.3,11.3): 0.5968 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5758 - ca4-[11.3,14.9): 0.6721 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9071 - val_ca1-[11.3,14.9): 1.5912 - val_ca2-[8.0,9.5): 0.5820 - val_ca2-[9.5,10.3): 0.3827 - val_ca2-[10.3,11.3): 0.8043 - val_ca2-[11.3,14.9): 1.4430 - val_ca3-[8.0,9.5): 0.8672 - val_ca3-[9.5,10.3): 0.5014 - val_ca3-[10.3,11.3): 0.6479 - val_ca3-[11.3,14.9): 0.8688 - val_ca4-[8.0,9.5): 1.5588 - val_ca4-[9.5,10.3): 1.1243 - val_ca4-[10.3,11.3): 0.9696 - val_ca4-[11.3,14.9): 0.7080\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5072 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3333 - ca2-[9.5,10.3): 0.4363 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5234 - ca3-[10.3,11.3): 0.6075 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5633 - ca4-[11.3,14.9): 0.6772 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4210 - val_ca1-[10.3,11.3): 0.9077 - val_ca1-[11.3,14.9): 1.5846 - val_ca2-[8.0,9.5): 0.5845 - val_ca2-[9.5,10.3): 0.3806 - val_ca2-[10.3,11.3): 0.7942 - val_ca2-[11.3,14.9): 1.4112 - val_ca3-[8.0,9.5): 0.8667 - val_ca3-[9.5,10.3): 0.5004 - val_ca3-[10.3,11.3): 0.6429 - val_ca3-[11.3,14.9): 0.8632 - val_ca4-[8.0,9.5): 1.5594 - val_ca4-[9.5,10.3): 1.1245 - val_ca4-[10.3,11.3): 0.9531 - val_ca4-[11.3,14.9): 0.6964\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5129 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3335 - ca2-[9.5,10.3): 0.4342 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5037 - ca3-[10.3,11.3): 0.6124 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5731 - ca4-[11.3,14.9): 0.7020 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9108 - val_ca1-[11.3,14.9): 1.5634 - val_ca2-[8.0,9.5): 0.5814 - val_ca2-[9.5,10.3): 0.3803 - val_ca2-[10.3,11.3): 0.8017 - val_ca2-[11.3,14.9): 1.3981 - val_ca3-[8.0,9.5): 0.8575 - val_ca3-[9.5,10.3): 0.4937 - val_ca3-[10.3,11.3): 0.6454 - val_ca3-[11.3,14.9): 0.8472 - val_ca4-[8.0,9.5): 1.5576 - val_ca4-[9.5,10.3): 1.1227 - val_ca4-[10.3,11.3): 0.9717 - val_ca4-[11.3,14.9): 0.6986\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5191 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3235 - ca2-[9.5,10.3): 0.4312 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5366 - ca3-[10.3,11.3): 0.5945 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5831 - ca4-[11.3,14.9): 0.6982 - val_ca1-[8.0,9.5): 0.5830 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9132 - val_ca1-[11.3,14.9): 1.5865 - val_ca2-[8.0,9.5): 0.5883 - val_ca2-[9.5,10.3): 0.3781 - val_ca2-[10.3,11.3): 0.7829 - val_ca2-[11.3,14.9): 1.3716 - val_ca3-[8.0,9.5): 0.8734 - val_ca3-[9.5,10.3): 0.5071 - val_ca3-[10.3,11.3): 0.6435 - val_ca3-[11.3,14.9): 0.8479 - val_ca4-[8.0,9.5): 1.5572 - val_ca4-[9.5,10.3): 1.1220 - val_ca4-[10.3,11.3): 0.9667 - val_ca4-[11.3,14.9): 0.7139\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5273 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3393 - ca2-[9.5,10.3): 0.4349 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5173 - ca3-[10.3,11.3): 0.5984 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5778 - ca4-[11.3,14.9): 0.6856 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9073 - val_ca1-[11.3,14.9): 1.5648 - val_ca2-[8.0,9.5): 0.5813 - val_ca2-[9.5,10.3): 0.3804 - val_ca2-[10.3,11.3): 0.8042 - val_ca2-[11.3,14.9): 1.4103 - val_ca3-[8.0,9.5): 0.8583 - val_ca3-[9.5,10.3): 0.4968 - val_ca3-[10.3,11.3): 0.6442 - val_ca3-[11.3,14.9): 0.8474 - val_ca4-[8.0,9.5): 1.5554 - val_ca4-[9.5,10.3): 1.1200 - val_ca4-[10.3,11.3): 0.9556 - val_ca4-[11.3,14.9): 0.6817\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5180 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3404 - ca2-[9.5,10.3): 0.4363 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5019 - ca3-[10.3,11.3): 0.5967 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5631 - ca4-[11.3,14.9): 0.6776 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9092 - val_ca1-[11.3,14.9): 1.5744 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3774 - val_ca2-[10.3,11.3): 0.7743 - val_ca2-[11.3,14.9): 1.3646 - val_ca3-[8.0,9.5): 0.8478 - val_ca3-[9.5,10.3): 0.4895 - val_ca3-[10.3,11.3): 0.6409 - val_ca3-[11.3,14.9): 0.8722 - val_ca4-[8.0,9.5): 1.5519 - val_ca4-[9.5,10.3): 1.1166 - val_ca4-[10.3,11.3): 0.9651 - val_ca4-[11.3,14.9): 0.7123\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5155 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3287 - ca2-[9.5,10.3): 0.4250 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5136 - ca3-[10.3,11.3): 0.5987 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5881 - ca4-[11.3,14.9): 0.6878 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9139 - val_ca1-[11.3,14.9): 1.5621 - val_ca2-[8.0,9.5): 0.5805 - val_ca2-[9.5,10.3): 0.3786 - val_ca2-[10.3,11.3): 0.7987 - val_ca2-[11.3,14.9): 1.3808 - val_ca3-[8.0,9.5): 0.8612 - val_ca3-[9.5,10.3): 0.4997 - val_ca3-[10.3,11.3): 0.6397 - val_ca3-[11.3,14.9): 0.8263 - val_ca4-[8.0,9.5): 1.5534 - val_ca4-[9.5,10.3): 1.1175 - val_ca4-[10.3,11.3): 0.9636 - val_ca4-[11.3,14.9): 0.6930\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5072 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3259 - ca2-[9.5,10.3): 0.4236 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5163 - ca3-[10.3,11.3): 0.5907 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5720 - ca4-[11.3,14.9): 0.6896 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9074 - val_ca1-[11.3,14.9): 1.6115 - val_ca2-[8.0,9.5): 0.5841 - val_ca2-[9.5,10.3): 0.3778 - val_ca2-[10.3,11.3): 0.7913 - val_ca2-[11.3,14.9): 1.4366 - val_ca3-[8.0,9.5): 0.8531 - val_ca3-[9.5,10.3): 0.4940 - val_ca3-[10.3,11.3): 0.6397 - val_ca3-[11.3,14.9): 0.8760 - val_ca4-[8.0,9.5): 1.5562 - val_ca4-[9.5,10.3): 1.1194 - val_ca4-[10.3,11.3): 0.9547 - val_ca4-[11.3,14.9): 0.6976\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5265 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3364 - ca2-[9.5,10.3): 0.4310 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5049 - ca3-[10.3,11.3): 0.5974 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5021 - ca4-[11.3,14.9): 0.6853 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9061 - val_ca1-[11.3,14.9): 1.5737 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3761 - val_ca2-[10.3,11.3): 0.7659 - val_ca2-[11.3,14.9): 1.3296 - val_ca3-[8.0,9.5): 0.8391 - val_ca3-[9.5,10.3): 0.4861 - val_ca3-[10.3,11.3): 0.6414 - val_ca3-[11.3,14.9): 0.8666 - val_ca4-[8.0,9.5): 1.5578 - val_ca4-[9.5,10.3): 1.1203 - val_ca4-[10.3,11.3): 0.9712 - val_ca4-[11.3,14.9): 0.7048\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 1s 140ms/step - ca1-[8.0,9.5): 0.5158 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3411 - ca2-[9.5,10.3): 0.4186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5395 - ca3-[10.3,11.3): 0.6100 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5991 - ca4-[11.3,14.9): 0.6936 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9093 - val_ca1-[11.3,14.9): 1.6009 - val_ca2-[8.0,9.5): 0.5861 - val_ca2-[9.5,10.3): 0.3751 - val_ca2-[10.3,11.3): 0.7805 - val_ca2-[11.3,14.9): 1.3970 - val_ca3-[8.0,9.5): 0.8497 - val_ca3-[9.5,10.3): 0.4930 - val_ca3-[10.3,11.3): 0.6388 - val_ca3-[11.3,14.9): 0.8709 - val_ca4-[8.0,9.5): 1.5570 - val_ca4-[9.5,10.3): 1.1190 - val_ca4-[10.3,11.3): 0.9496 - val_ca4-[11.3,14.9): 0.6914\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5047 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3326 - ca2-[9.5,10.3): 0.4236 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5283 - ca3-[10.3,11.3): 0.5953 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5631 - ca4-[11.3,14.9): 0.6949 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.5965 - val_ca2-[8.0,9.5): 0.5900 - val_ca2-[9.5,10.3): 0.3740 - val_ca2-[10.3,11.3): 0.7674 - val_ca2-[11.3,14.9): 1.3443 - val_ca3-[8.0,9.5): 0.8597 - val_ca3-[9.5,10.3): 0.5004 - val_ca3-[10.3,11.3): 0.6389 - val_ca3-[11.3,14.9): 0.8485 - val_ca4-[8.0,9.5): 1.5585 - val_ca4-[9.5,10.3): 1.1197 - val_ca4-[10.3,11.3): 0.9664 - val_ca4-[11.3,14.9): 0.7108\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5118 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3295 - ca2-[9.5,10.3): 0.4240 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5082 - ca3-[10.3,11.3): 0.5964 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5618 - ca4-[11.3,14.9): 0.6999 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4209 - val_ca1-[10.3,11.3): 0.9157 - val_ca1-[11.3,14.9): 1.5912 - val_ca2-[8.0,9.5): 0.5788 - val_ca2-[9.5,10.3): 0.3765 - val_ca2-[10.3,11.3): 0.7925 - val_ca2-[11.3,14.9): 1.4107 - val_ca3-[8.0,9.5): 0.8163 - val_ca3-[9.5,10.3): 0.4723 - val_ca3-[10.3,11.3): 0.6415 - val_ca3-[11.3,14.9): 0.8933 - val_ca4-[8.0,9.5): 1.5589 - val_ca4-[9.5,10.3): 1.1195 - val_ca4-[10.3,11.3): 0.9658 - val_ca4-[11.3,14.9): 0.6932\n",
      "Epoch 273/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5178 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3279 - ca2-[9.5,10.3): 0.4138 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5046 - ca3-[10.3,11.3): 0.6003 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5812 - ca4-[11.3,14.9): 0.6727 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9042 - val_ca1-[11.3,14.9): 1.5570 - val_ca2-[8.0,9.5): 0.5879 - val_ca2-[9.5,10.3): 0.3739 - val_ca2-[10.3,11.3): 0.7671 - val_ca2-[11.3,14.9): 1.3361 - val_ca3-[8.0,9.5): 0.8503 - val_ca3-[9.5,10.3): 0.4952 - val_ca3-[10.3,11.3): 0.6337 - val_ca3-[11.3,14.9): 0.8218 - val_ca4-[8.0,9.5): 1.5570 - val_ca4-[9.5,10.3): 1.1171 - val_ca4-[10.3,11.3): 0.9655 - val_ca4-[11.3,14.9): 0.6888\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5216 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3294 - ca2-[9.5,10.3): 0.4270 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5188 - ca3-[10.3,11.3): 0.5973 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5627 - ca4-[11.3,14.9): 0.6873 - val_ca1-[8.0,9.5): 0.5829 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9130 - val_ca1-[11.3,14.9): 1.5816 - val_ca2-[8.0,9.5): 0.5862 - val_ca2-[9.5,10.3): 0.3743 - val_ca2-[10.3,11.3): 0.7715 - val_ca2-[11.3,14.9): 1.3542 - val_ca3-[8.0,9.5): 0.8422 - val_ca3-[9.5,10.3): 0.4893 - val_ca3-[10.3,11.3): 0.6341 - val_ca3-[11.3,14.9): 0.8391 - val_ca4-[8.0,9.5): 1.5547 - val_ca4-[9.5,10.3): 1.1145 - val_ca4-[10.3,11.3): 0.9598 - val_ca4-[11.3,14.9): 0.6640\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5257 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3262 - ca2-[9.5,10.3): 0.4239 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5039 - ca3-[10.3,11.3): 0.5830 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5479 - ca4-[11.3,14.9): 0.6916 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.8999 - val_ca1-[11.3,14.9): 1.5793 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3728 - val_ca2-[10.3,11.3): 0.7427 - val_ca2-[11.3,14.9): 1.3172 - val_ca3-[8.0,9.5): 0.8200 - val_ca3-[9.5,10.3): 0.4754 - val_ca3-[10.3,11.3): 0.6260 - val_ca3-[11.3,14.9): 0.8643 - val_ca4-[8.0,9.5): 1.5538 - val_ca4-[9.5,10.3): 1.1130 - val_ca4-[10.3,11.3): 0.9532 - val_ca4-[11.3,14.9): 0.6887\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5209 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3169 - ca2-[9.5,10.3): 0.4015 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5028 - ca3-[10.3,11.3): 0.6013 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5624 - ca4-[11.3,14.9): 0.6905 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4208 - val_ca1-[10.3,11.3): 0.9156 - val_ca1-[11.3,14.9): 1.5909 - val_ca2-[8.0,9.5): 0.5846 - val_ca2-[9.5,10.3): 0.3725 - val_ca2-[10.3,11.3): 0.7741 - val_ca2-[11.3,14.9): 1.3738 - val_ca3-[8.0,9.5): 0.8523 - val_ca3-[9.5,10.3): 0.4991 - val_ca3-[10.3,11.3): 0.6353 - val_ca3-[11.3,14.9): 0.8326 - val_ca4-[8.0,9.5): 1.5534 - val_ca4-[9.5,10.3): 1.1119 - val_ca4-[10.3,11.3): 0.9599 - val_ca4-[11.3,14.9): 0.6964\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5195 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3210 - ca2-[9.5,10.3): 0.4160 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5226 - ca3-[10.3,11.3): 0.5969 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5572 - ca4-[11.3,14.9): 0.6902 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9057 - val_ca1-[11.3,14.9): 1.5864 - val_ca2-[8.0,9.5): 0.5875 - val_ca2-[9.5,10.3): 0.3727 - val_ca2-[10.3,11.3): 0.7514 - val_ca2-[11.3,14.9): 1.3297 - val_ca3-[8.0,9.5): 0.7924 - val_ca3-[9.5,10.3): 0.4599 - val_ca3-[10.3,11.3): 0.6215 - val_ca3-[11.3,14.9): 0.8886 - val_ca4-[8.0,9.5): 1.5565 - val_ca4-[9.5,10.3): 1.1139 - val_ca4-[10.3,11.3): 0.9300 - val_ca4-[11.3,14.9): 0.6829\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5198 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3358 - ca2-[9.5,10.3): 0.4166 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5209 - ca3-[10.3,11.3): 0.5897 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5758 - ca4-[11.3,14.9): 0.6740 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9040 - val_ca1-[11.3,14.9): 1.5739 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3718 - val_ca2-[10.3,11.3): 0.7561 - val_ca2-[11.3,14.9): 1.3282 - val_ca3-[8.0,9.5): 0.8287 - val_ca3-[9.5,10.3): 0.4857 - val_ca3-[10.3,11.3): 0.6298 - val_ca3-[11.3,14.9): 0.8422 - val_ca4-[8.0,9.5): 1.5517 - val_ca4-[9.5,10.3): 1.1088 - val_ca4-[10.3,11.3): 0.9587 - val_ca4-[11.3,14.9): 0.6953\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 1s 150ms/step - ca1-[8.0,9.5): 0.5056 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3261 - ca2-[9.5,10.3): 0.4170 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5519 - ca3-[10.3,11.3): 0.5892 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5793 - ca4-[11.3,14.9): 0.6816 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9118 - val_ca1-[11.3,14.9): 1.5673 - val_ca2-[8.0,9.5): 0.5916 - val_ca2-[9.5,10.3): 0.3705 - val_ca2-[10.3,11.3): 0.7527 - val_ca2-[11.3,14.9): 1.2904 - val_ca3-[8.0,9.5): 0.8035 - val_ca3-[9.5,10.3): 0.4690 - val_ca3-[10.3,11.3): 0.6233 - val_ca3-[11.3,14.9): 0.8399 - val_ca4-[8.0,9.5): 1.5474 - val_ca4-[9.5,10.3): 1.1042 - val_ca4-[10.3,11.3): 0.9390 - val_ca4-[11.3,14.9): 0.6792\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5045 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3372 - ca2-[9.5,10.3): 0.4121 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5161 - ca3-[10.3,11.3): 0.6099 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5074 - ca4-[11.3,14.9): 0.6850 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9199 - val_ca1-[11.3,14.9): 1.5711 - val_ca2-[8.0,9.5): 0.5916 - val_ca2-[9.5,10.3): 0.3705 - val_ca2-[10.3,11.3): 0.7506 - val_ca2-[11.3,14.9): 1.2775 - val_ca3-[8.0,9.5): 0.8165 - val_ca3-[9.5,10.3): 0.4769 - val_ca3-[10.3,11.3): 0.6348 - val_ca3-[11.3,14.9): 0.8323 - val_ca4-[8.0,9.5): 1.5456 - val_ca4-[9.5,10.3): 1.1018 - val_ca4-[10.3,11.3): 0.9528 - val_ca4-[11.3,14.9): 0.6917\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5288 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3392 - ca2-[9.5,10.3): 0.4193 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4956 - ca3-[10.3,11.3): 0.5874 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5913 - ca4-[11.3,14.9): 0.6752 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9107 - val_ca1-[11.3,14.9): 1.5635 - val_ca2-[8.0,9.5): 0.5836 - val_ca2-[9.5,10.3): 0.3725 - val_ca2-[10.3,11.3): 0.7660 - val_ca2-[11.3,14.9): 1.3233 - val_ca3-[8.0,9.5): 0.7880 - val_ca3-[9.5,10.3): 0.4593 - val_ca3-[10.3,11.3): 0.6296 - val_ca3-[11.3,14.9): 0.8543 - val_ca4-[8.0,9.5): 1.5489 - val_ca4-[9.5,10.3): 1.1038 - val_ca4-[10.3,11.3): 0.9551 - val_ca4-[11.3,14.9): 0.6916\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5167 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3322 - ca2-[9.5,10.3): 0.4186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4744 - ca3-[10.3,11.3): 0.5720 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5743 - ca4-[11.3,14.9): 0.6865 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9068 - val_ca1-[11.3,14.9): 1.5709 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3697 - val_ca2-[10.3,11.3): 0.7502 - val_ca2-[11.3,14.9): 1.2974 - val_ca3-[8.0,9.5): 0.8154 - val_ca3-[9.5,10.3): 0.4803 - val_ca3-[10.3,11.3): 0.6285 - val_ca3-[11.3,14.9): 0.8168 - val_ca4-[8.0,9.5): 1.5450 - val_ca4-[9.5,10.3): 1.0994 - val_ca4-[10.3,11.3): 0.9339 - val_ca4-[11.3,14.9): 0.6636\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5173 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3256 - ca2-[9.5,10.3): 0.4051 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5052 - ca3-[10.3,11.3): 0.5946 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.6013 - ca4-[11.3,14.9): 0.6895 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9103 - val_ca1-[11.3,14.9): 1.5533 - val_ca2-[8.0,9.5): 0.5870 - val_ca2-[9.5,10.3): 0.3695 - val_ca2-[10.3,11.3): 0.7491 - val_ca2-[11.3,14.9): 1.2804 - val_ca3-[8.0,9.5): 0.8157 - val_ca3-[9.5,10.3): 0.4820 - val_ca3-[10.3,11.3): 0.6261 - val_ca3-[11.3,14.9): 0.8039 - val_ca4-[8.0,9.5): 1.5454 - val_ca4-[9.5,10.3): 1.0991 - val_ca4-[10.3,11.3): 0.9506 - val_ca4-[11.3,14.9): 0.6891\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5259 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3267 - ca2-[9.5,10.3): 0.4186 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5286 - ca3-[10.3,11.3): 0.5934 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5625 - ca4-[11.3,14.9): 0.6738 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9184 - val_ca1-[11.3,14.9): 1.5708 - val_ca2-[8.0,9.5): 0.5884 - val_ca2-[9.5,10.3): 0.3684 - val_ca2-[10.3,11.3): 0.7514 - val_ca2-[11.3,14.9): 1.2927 - val_ca3-[8.0,9.5): 0.7698 - val_ca3-[9.5,10.3): 0.4517 - val_ca3-[10.3,11.3): 0.6307 - val_ca3-[11.3,14.9): 0.8571 - val_ca4-[8.0,9.5): 1.5390 - val_ca4-[9.5,10.3): 1.0914 - val_ca4-[10.3,11.3): 0.9490 - val_ca4-[11.3,14.9): 0.6927\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5069 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3305 - ca2-[9.5,10.3): 0.4094 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5023 - ca3-[10.3,11.3): 0.5799 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5517 - ca4-[11.3,14.9): 0.6768 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4212 - val_ca1-[10.3,11.3): 0.9138 - val_ca1-[11.3,14.9): 1.5739 - val_ca2-[8.0,9.5): 0.5874 - val_ca2-[9.5,10.3): 0.3705 - val_ca2-[10.3,11.3): 0.7557 - val_ca2-[11.3,14.9): 1.3037 - val_ca3-[8.0,9.5): 0.7818 - val_ca3-[9.5,10.3): 0.4600 - val_ca3-[10.3,11.3): 0.6251 - val_ca3-[11.3,14.9): 0.8399 - val_ca4-[8.0,9.5): 1.5334 - val_ca4-[9.5,10.3): 1.0825 - val_ca4-[10.3,11.3): 0.9172 - val_ca4-[11.3,14.9): 0.6592\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5156 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3173 - ca2-[9.5,10.3): 0.4025 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5149 - ca3-[10.3,11.3): 0.5733 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5609 - ca4-[11.3,14.9): 0.6769 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9084 - val_ca1-[11.3,14.9): 1.5601 - val_ca2-[8.0,9.5): 0.5871 - val_ca2-[9.5,10.3): 0.3681 - val_ca2-[10.3,11.3): 0.7448 - val_ca2-[11.3,14.9): 1.2638 - val_ca3-[8.0,9.5): 0.7599 - val_ca3-[9.5,10.3): 0.4446 - val_ca3-[10.3,11.3): 0.6232 - val_ca3-[11.3,14.9): 0.8401 - val_ca4-[8.0,9.5): 1.5292 - val_ca4-[9.5,10.3): 1.0789 - val_ca4-[10.3,11.3): 0.9336 - val_ca4-[11.3,14.9): 0.6896\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5257 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3243 - ca2-[9.5,10.3): 0.4137 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5007 - ca3-[10.3,11.3): 0.5871 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5775 - ca4-[11.3,14.9): 0.6691 - val_ca1-[8.0,9.5): 0.5827 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.8950 - val_ca1-[11.3,14.9): 1.5654 - val_ca2-[8.0,9.5): 0.5866 - val_ca2-[9.5,10.3): 0.3672 - val_ca2-[10.3,11.3): 0.7212 - val_ca2-[11.3,14.9): 1.2606 - val_ca3-[8.0,9.5): 0.7803 - val_ca3-[9.5,10.3): 0.4617 - val_ca3-[10.3,11.3): 0.6121 - val_ca3-[11.3,14.9): 0.8206 - val_ca4-[8.0,9.5): 1.5322 - val_ca4-[9.5,10.3): 1.0796 - val_ca4-[10.3,11.3): 0.9259 - val_ca4-[11.3,14.9): 0.6914\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5163 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3250 - ca2-[9.5,10.3): 0.4103 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4803 - ca3-[10.3,11.3): 0.5768 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5474 - ca4-[11.3,14.9): 0.6919 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9053 - val_ca1-[11.3,14.9): 1.5795 - val_ca2-[8.0,9.5): 0.5854 - val_ca2-[9.5,10.3): 0.3676 - val_ca2-[10.3,11.3): 0.7411 - val_ca2-[11.3,14.9): 1.2915 - val_ca3-[8.0,9.5): 0.7647 - val_ca3-[9.5,10.3): 0.4522 - val_ca3-[10.3,11.3): 0.6221 - val_ca3-[11.3,14.9): 0.8449 - val_ca4-[8.0,9.5): 1.5390 - val_ca4-[9.5,10.3): 1.0837 - val_ca4-[10.3,11.3): 0.9379 - val_ca4-[11.3,14.9): 0.6869\n",
      "Epoch 289/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5257 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3195 - ca2-[9.5,10.3): 0.4177 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5038 - ca3-[10.3,11.3): 0.5742 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5641 - ca4-[11.3,14.9): 0.6809 - val_ca1-[8.0,9.5): 0.5826 - val_ca1-[9.5,10.3): 0.4203 - val_ca1-[10.3,11.3): 0.9126 - val_ca1-[11.3,14.9): 1.5599 - val_ca2-[8.0,9.5): 0.5976 - val_ca2-[9.5,10.3): 0.3670 - val_ca2-[10.3,11.3): 0.7195 - val_ca2-[11.3,14.9): 1.2029 - val_ca3-[8.0,9.5): 0.7694 - val_ca3-[9.5,10.3): 0.4556 - val_ca3-[10.3,11.3): 0.6186 - val_ca3-[11.3,14.9): 0.8149 - val_ca4-[8.0,9.5): 1.5331 - val_ca4-[9.5,10.3): 1.0758 - val_ca4-[10.3,11.3): 0.9257 - val_ca4-[11.3,14.9): 0.6747\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5092 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3155 - ca2-[9.5,10.3): 0.4252 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4645 - ca3-[10.3,11.3): 0.5812 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5920 - ca4-[11.3,14.9): 0.6917 - val_ca1-[8.0,9.5): 0.5824 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9133 - val_ca1-[11.3,14.9): 1.6015 - val_ca2-[8.0,9.5): 0.5935 - val_ca2-[9.5,10.3): 0.3679 - val_ca2-[10.3,11.3): 0.7205 - val_ca2-[11.3,14.9): 1.2291 - val_ca3-[8.0,9.5): 0.7483 - val_ca3-[9.5,10.3): 0.4433 - val_ca3-[10.3,11.3): 0.6193 - val_ca3-[11.3,14.9): 0.8513 - val_ca4-[8.0,9.5): 1.5357 - val_ca4-[9.5,10.3): 1.0766 - val_ca4-[10.3,11.3): 0.9246 - val_ca4-[11.3,14.9): 0.6831\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5176 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3252 - ca2-[9.5,10.3): 0.4048 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4916 - ca3-[10.3,11.3): 0.5828 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5779 - ca4-[11.3,14.9): 0.6876 - val_ca1-[8.0,9.5): 0.5821 - val_ca1-[9.5,10.3): 0.4213 - val_ca1-[10.3,11.3): 0.9168 - val_ca1-[11.3,14.9): 1.5892 - val_ca2-[8.0,9.5): 0.5758 - val_ca2-[9.5,10.3): 0.3719 - val_ca2-[10.3,11.3): 0.7783 - val_ca2-[11.3,14.9): 1.3776 - val_ca3-[8.0,9.5): 0.7682 - val_ca3-[9.5,10.3): 0.4551 - val_ca3-[10.3,11.3): 0.6198 - val_ca3-[11.3,14.9): 0.8279 - val_ca4-[8.0,9.5): 1.5417 - val_ca4-[9.5,10.3): 1.0787 - val_ca4-[10.3,11.3): 0.9231 - val_ca4-[11.3,14.9): 0.6846\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 1s 147ms/step - ca1-[8.0,9.5): 0.5086 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3236 - ca2-[9.5,10.3): 0.4088 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5023 - ca3-[10.3,11.3): 0.5772 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5588 - ca4-[11.3,14.9): 0.6674 - val_ca1-[8.0,9.5): 0.5819 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9063 - val_ca1-[11.3,14.9): 1.5889 - val_ca2-[8.0,9.5): 0.5934 - val_ca2-[9.5,10.3): 0.3659 - val_ca2-[10.3,11.3): 0.7183 - val_ca2-[11.3,14.9): 1.2355 - val_ca3-[8.0,9.5): 0.7366 - val_ca3-[9.5,10.3): 0.4386 - val_ca3-[10.3,11.3): 0.6183 - val_ca3-[11.3,14.9): 0.8504 - val_ca4-[8.0,9.5): 1.5399 - val_ca4-[9.5,10.3): 1.0767 - val_ca4-[10.3,11.3): 0.9244 - val_ca4-[11.3,14.9): 0.6822\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 1s 145ms/step - ca1-[8.0,9.5): 0.5158 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3167 - ca2-[9.5,10.3): 0.4077 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5012 - ca3-[10.3,11.3): 0.5718 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5532 - ca4-[11.3,14.9): 0.6661 - val_ca1-[8.0,9.5): 0.5828 - val_ca1-[9.5,10.3): 0.4215 - val_ca1-[10.3,11.3): 0.8992 - val_ca1-[11.3,14.9): 1.5595 - val_ca2-[8.0,9.5): 0.5898 - val_ca2-[9.5,10.3): 0.3654 - val_ca2-[10.3,11.3): 0.7120 - val_ca2-[11.3,14.9): 1.2111 - val_ca3-[8.0,9.5): 0.7126 - val_ca3-[9.5,10.3): 0.4236 - val_ca3-[10.3,11.3): 0.5985 - val_ca3-[11.3,14.9): 0.8490 - val_ca4-[8.0,9.5): 1.5319 - val_ca4-[9.5,10.3): 1.0640 - val_ca4-[10.3,11.3): 0.8840 - val_ca4-[11.3,14.9): 0.6695\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 1s 144ms/step - ca1-[8.0,9.5): 0.5114 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3207 - ca2-[9.5,10.3): 0.4091 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5038 - ca3-[10.3,11.3): 0.5812 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5500 - ca4-[11.3,14.9): 0.6771 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4207 - val_ca1-[10.3,11.3): 0.9155 - val_ca1-[11.3,14.9): 1.5975 - val_ca2-[8.0,9.5): 0.5943 - val_ca2-[9.5,10.3): 0.3657 - val_ca2-[10.3,11.3): 0.7210 - val_ca2-[11.3,14.9): 1.2419 - val_ca3-[8.0,9.5): 0.7066 - val_ca3-[9.5,10.3): 0.4238 - val_ca3-[10.3,11.3): 0.6195 - val_ca3-[11.3,14.9): 0.8721 - val_ca4-[8.0,9.5): 1.5303 - val_ca4-[9.5,10.3): 1.0622 - val_ca4-[10.3,11.3): 0.9117 - val_ca4-[11.3,14.9): 0.6740\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 1s 143ms/step - ca1-[8.0,9.5): 0.5170 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3103 - ca2-[9.5,10.3): 0.3954 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5078 - ca3-[10.3,11.3): 0.5784 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5500 - ca4-[11.3,14.9): 0.6677 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4205 - val_ca1-[10.3,11.3): 0.9109 - val_ca1-[11.3,14.9): 1.5532 - val_ca2-[8.0,9.5): 0.5857 - val_ca2-[9.5,10.3): 0.3663 - val_ca2-[10.3,11.3): 0.7326 - val_ca2-[11.3,14.9): 1.2403 - val_ca3-[8.0,9.5): 0.7580 - val_ca3-[9.5,10.3): 0.4563 - val_ca3-[10.3,11.3): 0.6157 - val_ca3-[11.3,14.9): 0.7984 - val_ca4-[8.0,9.5): 1.5433 - val_ca4-[9.5,10.3): 1.0715 - val_ca4-[10.3,11.3): 0.9089 - val_ca4-[11.3,14.9): 0.6703\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 1s 141ms/step - ca1-[8.0,9.5): 0.5281 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3284 - ca2-[9.5,10.3): 0.4109 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4736 - ca3-[10.3,11.3): 0.5566 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5138 - ca4-[11.3,14.9): 0.6506 - val_ca1-[8.0,9.5): 0.5815 - val_ca1-[9.5,10.3): 0.4206 - val_ca1-[10.3,11.3): 0.9154 - val_ca1-[11.3,14.9): 1.6064 - val_ca2-[8.0,9.5): 0.5819 - val_ca2-[9.5,10.3): 0.3654 - val_ca2-[10.3,11.3): 0.7371 - val_ca2-[11.3,14.9): 1.2822 - val_ca3-[8.0,9.5): 0.7218 - val_ca3-[9.5,10.3): 0.4318 - val_ca3-[10.3,11.3): 0.6165 - val_ca3-[11.3,14.9): 0.8498 - val_ca4-[8.0,9.5): 1.5304 - val_ca4-[9.5,10.3): 1.0538 - val_ca4-[10.3,11.3): 0.8917 - val_ca4-[11.3,14.9): 0.6638\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5166 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3185 - ca2-[9.5,10.3): 0.4015 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4799 - ca3-[10.3,11.3): 0.5675 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5861 - ca4-[11.3,14.9): 0.6475 - val_ca1-[8.0,9.5): 0.5815 - val_ca1-[9.5,10.3): 0.4204 - val_ca1-[10.3,11.3): 0.9105 - val_ca1-[11.3,14.9): 1.5898 - val_ca2-[8.0,9.5): 0.6022 - val_ca2-[9.5,10.3): 0.3657 - val_ca2-[10.3,11.3): 0.6997 - val_ca2-[11.3,14.9): 1.1630 - val_ca3-[8.0,9.5): 0.7142 - val_ca3-[9.5,10.3): 0.4280 - val_ca3-[10.3,11.3): 0.6130 - val_ca3-[11.3,14.9): 0.8300 - val_ca4-[8.0,9.5): 1.5324 - val_ca4-[9.5,10.3): 1.0514 - val_ca4-[10.3,11.3): 0.8876 - val_ca4-[11.3,14.9): 0.6424\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5151 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3124 - ca2-[9.5,10.3): 0.3891 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4459 - ca3-[10.3,11.3): 0.5719 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5378 - ca4-[11.3,14.9): 0.6652 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4202 - val_ca1-[10.3,11.3): 0.9060 - val_ca1-[11.3,14.9): 1.5653 - val_ca2-[8.0,9.5): 0.5898 - val_ca2-[9.5,10.3): 0.3647 - val_ca2-[10.3,11.3): 0.7123 - val_ca2-[11.3,14.9): 1.2033 - val_ca3-[8.0,9.5): 0.7383 - val_ca3-[9.5,10.3): 0.4461 - val_ca3-[10.3,11.3): 0.6070 - val_ca3-[11.3,14.9): 0.7975 - val_ca4-[8.0,9.5): 1.5435 - val_ca4-[9.5,10.3): 1.0583 - val_ca4-[10.3,11.3): 0.8779 - val_ca4-[11.3,14.9): 0.6457\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 1s 146ms/step - ca1-[8.0,9.5): 0.5261 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3201 - ca2-[9.5,10.3): 0.4049 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.4640 - ca3-[10.3,11.3): 0.5797 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5821 - ca4-[11.3,14.9): 0.6630 - val_ca1-[8.0,9.5): 0.5816 - val_ca1-[9.5,10.3): 0.4200 - val_ca1-[10.3,11.3): 0.9135 - val_ca1-[11.3,14.9): 1.5883 - val_ca2-[8.0,9.5): 0.5867 - val_ca2-[9.5,10.3): 0.3661 - val_ca2-[10.3,11.3): 0.7245 - val_ca2-[11.3,14.9): 1.2488 - val_ca3-[8.0,9.5): 0.7446 - val_ca3-[9.5,10.3): 0.4534 - val_ca3-[10.3,11.3): 0.6089 - val_ca3-[11.3,14.9): 0.8030 - val_ca4-[8.0,9.5): 1.5580 - val_ca4-[9.5,10.3): 1.0674 - val_ca4-[10.3,11.3): 0.8824 - val_ca4-[11.3,14.9): 0.6597\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 1s 142ms/step - ca1-[8.0,9.5): 0.5201 - ca1-[9.5,10.3): 0.0000e+00 - ca1-[10.3,11.3): 0.0000e+00 - ca1-[11.3,14.9): 0.0000e+00 - ca2-[8.0,9.5): 0.3268 - ca2-[9.5,10.3): 0.4013 - ca2-[10.3,11.3): 0.0000e+00 - ca2-[11.3,14.9): 0.0000e+00 - ca3-[8.0,9.5): 0.0000e+00 - ca3-[9.5,10.3): 0.5066 - ca3-[10.3,11.3): 0.5667 - ca3-[11.3,14.9): 0.0000e+00 - ca4-[8.0,9.5): 0.0000e+00 - ca4-[9.5,10.3): 0.0000e+00 - ca4-[10.3,11.3): 0.5329 - ca4-[11.3,14.9): 0.6598 - val_ca1-[8.0,9.5): 0.5815 - val_ca1-[9.5,10.3): 0.4200 - val_ca1-[10.3,11.3): 0.9138 - val_ca1-[11.3,14.9): 1.5577 - val_ca2-[8.0,9.5): 0.5914 - val_ca2-[9.5,10.3): 0.3623 - val_ca2-[10.3,11.3): 0.7140 - val_ca2-[11.3,14.9): 1.1796 - val_ca3-[8.0,9.5): 0.7026 - val_ca3-[9.5,10.3): 0.4270 - val_ca3-[10.3,11.3): 0.6123 - val_ca3-[11.3,14.9): 0.8177 - val_ca4-[8.0,9.5): 1.5514 - val_ca4-[9.5,10.3): 1.0566 - val_ca4-[10.3,11.3): 0.8770 - val_ca4-[11.3,14.9): 0.6373\n",
      "CPU times: user 6min 26s, sys: 3.42 s, total: 6min 30s\n",
      "Wall time: 6min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('djgrad')\n",
    "m.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2})') for ca,(q1,q2) in product(range(4),zip(quants[:-1],quants[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "\n",
    "history = m.fit(\n",
    "    train_dataset,\n",
    "#     validation_split=0.2,\n",
    "    epochs=300,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "# with open(os.path.join(fp_local,'no_sharing.pickle'), 'wb') as handle:\n",
    "#     pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "for k in [k for k in history.history if 'val_ca1' in k]:\n",
    "    plt.plot(history.history[k], label=k.split('-')[1])\n",
    "        \n",
    "plt.legend()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ca1-[8.0,9.5)</th>\n",
       "      <td>0.527901</td>\n",
       "      <td>0.581487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[9.5,10.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.419987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[10.3,11.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.913848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca1-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.557681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[8.0,9.5)</th>\n",
       "      <td>0.320806</td>\n",
       "      <td>0.591429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[9.5,10.3)</th>\n",
       "      <td>0.394335</td>\n",
       "      <td>0.362250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[10.3,11.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.714011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca2-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.179638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[8.0,9.5)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.702616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[9.5,10.3)</th>\n",
       "      <td>0.482375</td>\n",
       "      <td>0.427019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[10.3,11.3)</th>\n",
       "      <td>0.558645</td>\n",
       "      <td>0.612300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca3-[11.3,14.9)</th>\n",
       "      <td>-</td>\n",
       "      <td>0.817746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[8.0,9.5)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.551364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[9.5,10.3)</th>\n",
       "      <td>-</td>\n",
       "      <td>1.056619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[10.3,11.3)</th>\n",
       "      <td>0.520652</td>\n",
       "      <td>0.876950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca4-[11.3,14.9)</th>\n",
       "      <td>0.668571</td>\n",
       "      <td>0.637342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train      test\n",
       "ca1-[8.0,9.5)    0.527901  0.581487\n",
       "ca1-[9.5,10.3)          -  0.419987\n",
       "ca1-[10.3,11.3)         -  0.913848\n",
       "ca1-[11.3,14.9)         -  1.557681\n",
       "ca2-[8.0,9.5)    0.320806  0.591429\n",
       "ca2-[9.5,10.3)   0.394335  0.362250\n",
       "ca2-[10.3,11.3)         -  0.714011\n",
       "ca2-[11.3,14.9)         -  1.179638\n",
       "ca3-[8.0,9.5)           -  0.702616\n",
       "ca3-[9.5,10.3)   0.482375  0.427019\n",
       "ca3-[10.3,11.3)  0.558645  0.612300\n",
       "ca3-[11.3,14.9)         -  0.817746\n",
       "ca4-[8.0,9.5)           -  1.551364\n",
       "ca4-[9.5,10.3)          -  1.056619\n",
       "ca4-[10.3,11.3)  0.520652  0.876950\n",
       "ca4-[11.3,14.9)  0.668571  0.637342"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data=[[history.history[k][-1] if history.history[k][-1]!=0 else '-',history.history['val_'+k][-1]] for k in history.history if 'val' not in k],\n",
    "    index=[k for k in history.history if 'val' not in k],\n",
    "    columns=['train','test']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike = pd.read_csv(os.path.join(fp_data,'hour.csv'),delimiter=',')\n",
    "# bike = bike.append(pd.read_csv(os.path.join(fp_data,'winequality-white.csv'),delimiter=';'))\n",
    "bike = bike.drop(['dteday','instant'],axis=1).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7764</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15063</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>52</td>\n",
       "      <td>380</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14817</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.6515</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>113</td>\n",
       "      <td>258</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.4478</td>\n",
       "      <td>143</td>\n",
       "      <td>163</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17046</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10539</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>6</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>129</td>\n",
       "      <td>239</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.6515</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>49</td>\n",
       "      <td>129</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "7764        4   0    11   3        0        5           1           1  0.28   \n",
       "15063       4   1     9  20        0        1           1           1  0.52   \n",
       "14817       3   1     9  14        0        5           1           2  0.72   \n",
       "2467        2   0     4  17        0        0           0           1  0.56   \n",
       "17046       4   1    12   1        0        2           1           2  0.44   \n",
       "...       ...  ..   ...  ..      ...      ...         ...         ...   ...   \n",
       "10539       1   1     3   6        0        2           1           2  0.52   \n",
       "192         1   0     1   7        0        0           0           1  0.08   \n",
       "10496       1   1     3  11        0        0           0           2  0.44   \n",
       "4576        3   0     7  14        0        4           1           1  0.74   \n",
       "1949        2   0     3   0        0        0           0           2  0.26   \n",
       "\n",
       "        atemp   hum  windspeed  casual  registered  cnt  \n",
       "7764   0.2879  0.75     0.1045       0           2    2  \n",
       "15063  0.5000  0.52     0.1045      52         380  432  \n",
       "14817  0.6515  0.45     0.1642     113         258  371  \n",
       "2467   0.5303  0.30     0.4478     143         163  306  \n",
       "17046  0.4394  0.94     0.1343       0          15   15  \n",
       "...       ...   ...        ...     ...         ...  ...  \n",
       "10539  0.5000  0.94     0.1642       6          94  100  \n",
       "192    0.0909  0.53     0.1940       1           5    6  \n",
       "10496  0.4394  0.82     0.1642     129         239  368  \n",
       "4576   0.6515  0.35     0.2836      49         129  178  \n",
       "1949   0.2576  0.41     0.1642       5          26   31  \n",
       "\n",
       "[17379 rows x 15 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda/lib/python3.8/site-packages/pandas/plotting/_matplotlib/tools.py:331: MatplotlibDeprecationWarning: \n",
      "The is_first_col function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use ax.get_subplotspec().is_first_col() instead.\n",
      "  if ax.is_first_col():\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAJOCAYAAAAUOGurAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAB1LElEQVR4nO39fZxdVX33/7/ecicNyK1OQ0gJLVEbpSKkgBfWjqIQwBp7FTFIISA1tkLFmlYCtYVyY8P1KyAohaJEggIBUUqKUYzISO3XcBNEQkBKxCCJgQgJgYCiwc/vj7VO2DOZmzMzZ87e55z38/GYx5yz9j57rz1nzd6fvdbaaykiMDMzM7Pme1XZGTAzMzPrVA7EzMzMzEriQMzMzMysJA7EzMzMzEriQMzMzMysJA7EzMzMzEriQMzMzBpOUo+kvyo7H1Y9klZKenfZ+agKB2JmZjYqks6W9JWy82HWihyImXUoJT4HmFklSdq67Dw0g0/CDSTpdEmrJT0v6RFJh0p6laQ5kn4i6RlJN0ratfCZr0p6UtIGSXdKelNh2ZGSHsrbWy3p7wvLPiJphaR1khZK2qOwLCT9taRHJT0r6TJJat5fwsok6R8kfa1P2qWSLsnNRedL+h/gReD3y8mlVUFuIvoHSQ9IekHSVZK6JH0zn3e+I2kXSZPyeWWmpJ9JelrSP+ZtTAPOBD4oaaOkHxV2sZek/8nb+rak3Us5UKui/XK52yDpBkmvltQtaVW+lj4JfKnsTDaDA7EGkfQG4FTgjyNiR+BwYCXwt8D7gT8F9gDWA5cVPvpNYDLwOuA+4NrCsquAj+btvRn4bt7Xu4B/BY4BxgOPAwv6ZOm9wB8Df5TXO7whB2qt4CvANEk7w+a7yhnANXn58cAsYEdS2bHO9hfAe4DXA39GOiedCbyWdI34eGHdtwNvAA4F/lnSH0bEt4DPADdExA4R8ZbC+h8CTiKd37YF/h6z5BhgGrA36Tp1Yk7/XWBXYC/SeartORBrnJeB7YApkraJiJUR8RPgr4F/jIhVEfEScDZwdK3KNSLmRcTzhWVvkbRT3uZv8vZeExHrI+K+nH4cMC8i7sufOwN4m6RJhfzMjYhnI+JnwB3AfmN47FYhEbEGuBP4QE6aBjwdEUvz+6sjYnlEbIqI35SSSauSz0XEUxGxGvhv4K6I+GFE/Aq4GXhrYd1/iYhfRsSPgB8Bb+lne0Vfioj/jYhfAjfi85C94tKI+HlErAP+i1fKxm+BsyLipVxu2p4DsQaJiBXAJ0jB1FpJC3Jz4V7AzbmJ8FngYVLQ1iVpK0lzc7Plc6QaNIBa9f1fAEcCj0v6nqS35fQ9KNRkRMRG4BlgQiFLTxZevwjs0KhjtZYwH/jL/PovgS8Xlj3R/OxYhT1VeP3Lft4Xzx3DPa/4PGQDGahs/CLfBHQMB2INFBHXRcTbScFXABeQLnpHRMTOhZ9X57vPDwHTgXcDOwGT8qaUt3dPREwnVev/J+mOEuDneR9pZWkcsBuwemyP0FrIfwJ/JOnNpGbqYpN3lJIja2cuU9YoHVeWHIg1iKQ3SHqXpO2AX5HuJH8LXAGcL2mvvN5rJU3PH9sReIlUm/U7pH4Wte1tK+k4STvl5qPn8vYArgdOkrRf3t9nSM0JK8f8QK0l5DvKm4DrgLtzE7XZWHkKmOSncM2Gz/80jbMdMBd4mlTl+jpS361LgIXAtyU9DywBDsqfuYbUxLgaeCgvKzoeWJmbLf+a1DeMiPgO8E/A14A1wB+QOmObFc0H9qV3s6TZWPhq/v2MpPsGXdPMelFEx9UCmnUESb8H/Bj43Yh4ruz8mJnZllwjZtaGchPRJ4EFDsLMzKqrI0atNesk+eGNp0jN3tNKzo6ZmQ3CTZNmZmZmJXHTpJmZmVlJWrZpcvfdd49JkyaVnY1+vfDCC4wbN67sbFTKQH+TpUuXPh0Rry0hS730V57a7Xtsp+OppzxJejVphoHtSOe6myLiLEl7k6YE2w1YChwfEb/OQ8FcAxxAGlLmg7UhYSSdAZxMGoz54xFx22D5q/L5qa9WLhdjnXefnxqr0/M8YHmKiJb8OeCAA6Kq7rjjjrKzUDkD/U2Ae6Oi5andvsd2Op56yhNpYOQd8uttgLuAg0kDI8/I6VcAf5Nffwy4Ir+eQZo7EWAKaTqf7Ujz4v0E2CqGWZ6qqpXLxVjn3eenxur0PA9Untw0aWZtKZ/7Nua32+SfAN5FGuwW0lhr78+vp+f35OWHSlJOXxBp7rufAiuAA8f+CMysE7Rs06SZ2VAkbUVqftwHuIxUm/VsRGzKq6zilTlaJ5Dn4YyITZI2kJovJ9B7sOXiZ4r7mgXMAujq6qKnp6fRhzMmNm7c2DJ57auV825W40DMzNpWRLwM7CdpZ+Bm4I1juK8rgSsBpk6dGt3d3WO1q4bq6emhVfLaVyvn3azGgVgbmDTnG3Wtt3LuUWOcE7PRqbcsXz1teJ1nI+JZSXcAbwN2lrR1rhXbkzTFGPn3RGCVpK2BnUid9mvpNcXPWIX53Nh+2vE7dSBmZm1J0muB3+QgbHvgPcAFwB3A0aQnJ2cCt+SPLMzvf5CXfzciQtJC4DpJFwF7AJOBu5t6MGYV0o7BUD3qPW4Y3rE7EDMbwLLVGzixjn+8djvZtJHxwPzcT+xVwI0Rcaukh4AFks4Dfghclde/CviypBXAOtKTk0TEckk3Ag8Bm4BTcpOnWWl8fmofDsQapBgpz95304D/IP6nMGuOiHgAeGs/6Y/Rz1OPEfEr4AMDbOt84PxG59HMzMNXmJmZmZXEgZiZmZlZSdqqabJTOxC2C0l/B/wVadDNZcBJpH4+YzodjVkz+PxkZv1pq0DMmq9Rww1ImgB8HJgSEb/MnaNnAEcCF0fEAklXkAKsy/Pv9RGxj6QZpKfhPihpSv7cm0hPuH1H0uvdudrMRkrSRNKNXxfpRvHKiLhE0q7ADcAkYCVwTESszzMyXEI6f70InBgR9+VtzQQ+nTd9XkTMxzqamyatSrYGts9jOP0OsAZPR2Nm5dsEzI6IKaT5Sk/JN31zgNsjYjJwe34PcARpmJPJpNkWLgfIgdtZwEGk89JZknZp5oFY9Yy6Riw/Gn4vsDoi3itpb9yUZMMUEasl/RvwM+CXwLdJ5WdMpqOBoaek6do+PQE7lFaZYqUVpoOp5+8NrXEs1j4iYg3pxpCIeF7Sw6TzynSgO682H+gBTs/p1+SJnpdI2lnS+Lzu4ohYByBpMTANuL5pB2OV04imydOAh4HX5PcX4KYkG6Z8Vzgd2Bt4Fvgq6QQ1ZoaakuZz197ChcuG/hdZeVz3kOtUQStMB1PPuEiQmrqrfizWniRNIg2LchfQlYM0gCdJTZdQuFHMajeEA6X3t5/K3ijWe8PUd9+NuIEa6b5Hqpjnevc93P2PKhCTtCdwFGl8nU/mpqF3AR/Kq8wHziYFYtPza0hNSZ/v25QE/DQPpnggaXRr6xzvBn4aEb8AkPR14BA8HY2ZVYSkHYCvAZ+IiOfSJSzJszBEo/ZV5RvFem+Y+u67ETeDI933SBXzXO++h7v/0daIfRb4FLBjfr8bJTYlNTtSHmjfg92pVOnupJn7ruNO6GfAwZJ+h9Q0eSipydvT0ZhZ6SRtQwrCro2Ir+fkpySNj4g1uelxbU4f6IZwNa80ZdbSe8Yy31Z9Iw7EJL0XWBsRSyV1NyxHgxjqDqHZkfJA+56976YB71SqdHfSzH0P1ZQUEXdJugm4j9Qx9oek7/obeDoaMytRbr25Cng4Ii4qLKrdEM5lyxvFUyUtIHXM35CDtduAzxQ66B8GnNGMY7DqGk2N2CHA+yQdCbya1EfsEtyUZCMUEWeRnigq8nQ0Zla2Q4DjgWWS7s9pZ5ICsBslnQw8DhyTly0iDV2xgjR8xUkAEbFO0rnAPXm9c2od961zjTgQi4gzyJF8rhH7+4g4TtJXcVOSmZm1iYj4PqABFh/az/oBnDLAtuYB8xqXO2t1YzGg6+m4KcnMzMxsSA0JxCKih9zhMCLclGRmZmZWB4+sb2ZmZlYSB2JmZmZmJXEgZmZmZlYSB2JmZmZmJXEgZmZmZlYSB2JmZmZmJXEgZmZmZlYSB2JmZmZmJXEgZmZmZlYSB2JmZmZmJXEgZmZmZlYSB2JmZmZmJXEgZmZmZlYSB2JWGZJ2lnSTpB9LeljS2yTtKmmxpEfz713yupJ0qaQVkh6QtH9hOzPz+o9KmlneEVlZJE2UdIekhyQtl3RaTnd5shGRNE/SWkkPFtLOlrRa0v3558jCsjNyeXpE0uGF9Gk5bYWkOc0+DqseB2JWJZcA34qINwJvAR4G5gC3R8Rk4Pb8HuAIYHL+mQVcDulCC5wFHAQcCJxVu9haR9kEzI6IKcDBwCmSpuDyZCN3NTCtn/SLI2K//LMIIJe1GcCb8mf+XdJWkrYCLiOVtynAsXld62AjDsQkvVrS3ZJ+lO84/yWn7y3prhzt3yBp25y+XX6/Ii+fVNhWv3cO1jkk7QS8A7gKICJ+HRHPAtOB+Xm1+cD78+vpwDWRLAF2ljQeOBxYHBHrImI9sJj+T57WxiJiTUTcl18/TwrqJ+DyZCMUEXcC6+pcfTqwICJeioifAitIgfyBwIqIeCwifg0syOtaB9t6FJ99CXhXRGyUtA3wfUnfBD5JukNYIOkK4GTS3eXJwPqI2EfSDOAC4IN97hz2AL4j6fUR8fIo8matZ2/gF8CXJL0FWAqcBnRFxJq8zpNAV349AXii8PlVOW2g9C1ImkWq/aCrq4uenp5ey7u2h9n7bhoy430/V1UbN26sfF7r+XvD8I4l3/S9FbiLEstTvcfW7O+oFcrFQIbKe5P+5qdKOgG4l1QLu55URpYU1imWm77l6aD+Nlrl89NI/66NKGvN/j8q5rnefQ93/yMOxCIigI357Tb5J4B3AR/K6fOBs0mB2PT8GuAm4POSROHOAfippNqdww9GmjdrSVsD+wN/GxF3SbqEV5qNgFTmJEWjdhgRVwJXAkydOjW6u7t7Lf/ctbdw4bKh/0VWHtc95DpV0NPTQ99jrJoT53yjrvWunjaurmORtAPwNeATEfFcOuUkzS5P9R5bs8tTK5SLgQyV9yb8zS8HziVd+84FLgQ+PNKNFVX5/DTSv2sjylqz/4+Kea5338Pd/2hqxMjt3UuBfUjt3j8Bno2IWthYvAvYfGcZEZskbQB2Y/A7h777q+wdZ3Hfg92pVOnupJn7ruNOaBWwKiLuyu9vIgViT0kaHxFrclPR2rx8NTCx8Pk9c9pqoLtP+qA7tvaUa+q/BlwbEV/PyS5P1jAR8VTttaQvALfmtwOVJwZJbzuT+gQus/fdNKxgppH7Hqlm5HlUgVhuPtxP0s7AzcAbG5GpQfZX2TvO4r5n77tpwDuVKt2dNHPfQ9VgRMSTkp6Q9IaIeAQ4FHgo/8wE5ubft+SPLCQ1CSwgVe1vyBfX24DPFDpUHwacMewDs5aWa9uvAh6OiIsKixbi8mQNUgvq89s/B2pPVC4ErpN0EanLzWTgbkDAZEl7kwKwGbzSglS6RgUvNjyjCsRqIuJZSXcAbyN1ct0614oVo/3aHcIqSVsDOwHPMPidg3WWvwWuzQ94PAacRHqg5EZJJwOPA8fkdRcBR5I6wb6Y1yUi1kk6F7gnr3dORNTbwdbaxyHA8cAySffntDNJAZjLkw2bpOtJtaO7S1pFepq2W9J+pKbJlcBHASJiuaQbSTeSm4BTav2eJZ0K3AZsBcyLiOXNPRKrmhEHYpJeC/wmB2HbA+8hdcC/Azia9DRI3zvOmaS+X0cD3819NAa6c7AOExH3A1P7WXRoP+sGcMoA25kHzGto5qylRMT3SbUP/XF5smGLiGP7Sb5qkPXPB87vJ30RKfBvCtdyVd9oasTGA/NzP7FXATdGxK2SHgIWSDoP+CGvFNSrgC/nzvjrSFWyg945mJmZmbWz0Tw1+QDpkfC+6Y+Rnnrsm/4r4AMDbKvfOwczMzOzduaR9c3MzMxK4kDMzMzMrCQOxMzMzMxK4kDMzMzMrCQOxMzMzMxK4kDMzMzMrCQOxMzMzMxK4kDMzMzMrCQOxMzMzMxK4kDMzMzMrCSjmWvSzMxawGATP8/edxMn5uUr5x7VkG0WDWebZp3IgZiZWYXUG+BAawQ5DtjMBudAzMysRQ0naCtje2O972Jtnlmrch8xqxRJW0n6oaRb8/u9Jd0laYWkGyRtm9O3y+9X5OWTCts4I6c/Iunwkg7FzNqIpHmS1kp6sJC2q6TFkh7Nv3fJ6ZJ0aT4PPSBp/8JnZub1H5U0s4xjsWoZcSAmaaKkOyQ9JGm5pNNyugumjcZpwMOF9xcAF0fEPsB64OScfjKwPqdfnNdD0hRgBvAmYBrw75K2alLezax9XU06pxTNAW6PiMnA7fk9wBHA5PwzC7gc0vUROAs4CDgQOKt2jbTONZoasU3A7IiYAhwMnJIvgi6YNiKS9gSOAr6Y3wt4F3BTXmU+8P78enp+T15+aF5/OrAgIl6KiJ8CK0jlysxsxCLiTmBdn+Tieajv+emaSJYAO0saDxwOLI6IdRGxHljMlsGddZgR9xGLiDXAmvz6eUkPAxNIBbA7rzYf6AFOp1AwgSWSagWzm1wwASTVCub1I82btazPAp8CdszvdwOejYhN+f0qUhkj/34CICI2SdqQ158ALClss/iZXiTNIt0U0NXVRU9PT6/lXdunPihD6fu5qtq4cWPl81rP3xta41isI3TlayHAk0BXfr35/JTVzkMDpW+hUeenKumkPA/n/NSQzvq5f85bgbsosWDW+8caixN4cd+DfXFjve/BlLnvoS6ckt4LrI2IpZK6G5G3oUTElcCVAFOnTo3u7t67/dy1t3DhsqH/RVYe1z3kOlXQ09ND32Osmno7Xl89bVzlj8U6S0SEpGjg9hpyfqqS2ftu6pg8D+e6MOq/iKQdgK8Bn4iI51LrUNLsglnvSXwsLpzFfQ/2xY31vgdT5r7ruHAeArxP0pHAq4HXAJeQqvS3zrViewKr8/qrgYnAKklbAzsBzxTSa4qfMTNrpKckjY+INbmFZ21OH+g8tJpXWoxq6T1NyKdV2KiempS0DSkIuzYivp6Tn8oFkmEUTF84O1xEnBERe0bEJFJn++9GxHHAHcDRebWZwC359cL8nrz8u7nZeyEwIz9VuTepT+LdTToMM+ssxfNQ3/PTCfkhtYOBDbml6DbgMEm75L7Qh+U062CjeWpSwFXAwxFxUWGRC6Y10unAJyWtIPUBuyqnXwXsltM/SX4oJCKWAzcCDwHfAk6JiJebnmszayuSrgd+ALxB0ipJJwNzgfdIehR4d34PsAh4jPSw0BeAjwHkvtDnAvfkn3Nq/aOtc42mafIQ4HhgmaT7c9qZpIJ4Yy6kjwPH5GWLgCNJBfNF4CRIBVNSrWCCC2bHi4gecnV9RDxGP089RsSvgA8M8PnzgfPHLodm1mki4tgBFh3az7oBnDLAduYB8xqYNWtxo3lq8vuABljsgmlmZmY2BI+sb2ZmZlYSB2JmZmZmJXEgZmZtyXMDmlkrcCBmZu3qajw3oJlVnAMxM2tLnhvQzFpBa801YGY2OpWfgq3ZWnH+v5pG5d3zllqZHIiZWUeq6hRszdaK8//VNCrvrTJfrLUnN02aWSfxFGxmVikOxMysk3gKNjOrlNasjzYzG0KeG7Ab2F3SKtLTj56CzcwqxYGYmbUlzw1oZq3ATZNmZmZmJXEgZmZmZlYSB2JmZmZmJXEgZpUgaaKkOyQ9JGm5pNNyuucGNLNKk7RS0jJJ90u6N6cN+9xlnWlUgZgn1bUG2gTMjogpwMHAKZKm4LkBzaw1vDMi9ouIqfn9sM5d1rlGWyN2NZ5U1xogItZExH359fPAw6SpZDw3oJm1ouGeu6xDjWr4ioi4U9KkPsnTSWP3QCp8PcDpFAofsERSrfB1ky+cAJJqF87rR5M3a125TL0VuIsS5wasdx67VpmnbuPGjZXPa73zBrbCsVhHCeDbecqs/8jTXQ333LWmkNaw81OVdFKeh3N+GotxxCo/qe5YnMCL+x7sixvrfQ+mzH3Xe+GUtAPwNeATEfGcpM3Lmj034OeuvaWueexaZZ66np4e+h5j1dQ7H+PV08ZV/liso7w9IlZLeh2wWNKPiwtHcu5q1PmpSlpxXtOR5nk414Ux/YtUdVLdsbhwFvc92Bc31vseTJn7rufCKWkbUhB2bUR8PSc/JWl8RKwZxtyA3X3Se+rKpJnZCETE6vx7raSbSd1shnvusg41Fk9NelJdGzalqq+rgIcj4qLCIs8NaGaVJWmcpB1rr0nnnAcZ/rnLOtRY1IjVCt9ctix8p0paQOqYvyHfKdwGfKbQQf8w4IwxyJdV2yHA8cAySffntDPx3IBmVm1dwM25G8XWwHUR8S1J9zCMc5d1rlEFYp5U1xolIr4PaIDFnhvQzCopIh4D3tJP+jMM89xlnWm0T016Ul0zMzOzEfLI+mZmZmYlcSBmZmZmVhIHYmZmZmYlcSBmZmZmVhIHYmZmZmYlcSBmZmZmVhIHYmZmZmYlcSBmZmZmVhIHYmZmZmYlcSBmZmZmVhIHYmZmZmYlcSBmZmZmVhIHYmZmZmYlcSBmZmZmVpLKBGKSpkl6RNIKSXPKzo+1NpcnaySXJ2sklycrqkQgJmkr4DLgCGAKcKykKeXmylqVy5M1ksuTNZLLk/VViUAMOBBYERGPRcSvgQXA9JLzZK3L5ckayeXJGsnlyXrZuuwMZBOAJwrvVwEH9V1J0ixgVn67UdIjI9mZLhjJp+r3cdgdeLqMfQ+mzH2/84IB/yZ7jcHuGlWeBvwee22nxL/rMNV1PK2gRctTJQ12vqq6RuV9kP/hKpenlvveWrGsjTTPA5SpfstTVQKxukTElcCVZedjKJLujYipZeejSqr4NxmqPFUxz6PRTsdTxWNplfNTX1X8W9arlfM+lHY8PznP/atK0+RqYGLh/Z45zWwkXJ6skVyerJFcnqyXqgRi9wCTJe0taVtgBrCw5DxZ63J5skZyebJGcnmyXirRNBkRmySdCtwGbAXMi4jlJWdrNFqueaIJmvY3aWB5arfvsZ2OpxXLU1W1crloubx3+PnJee6HImKs92FmZmZm/ahK06SZmZlZx3EgZmZmZlYSB2INJGmipDskPSRpuaTTys5TVUjaStIPJd1adl76Gmq6EUnbSbohL79L0qQSslmXOo7lREm/kHR//vmrMvJZL0nzJK2V9OAAyyXp0ny8D0jav9l5bFWSVkpalsvBvWXnZzD9lQNJu0paLOnR/HuXMvPYLK0yPVKrfWcDXb+bkWcHYo21CZgdEVOAg4FTPHXFZqcBD5edib7qnG7kZGB9ROwDXAxUcgjXYUydckNE7Jd/vtjUTA7f1cC0QZYfAUzOP7OAy5uQp3byzlwOqj6209VsWQ7mALdHxGTg9vy+rbXY9EhX01rf2UDX7zHPswOxBoqINRFxX379PCnwmFBursonaU/gKKCKF/16phuZDszPr28CDpWkJuaxXm03dUpE3AmsG2SV6cA1kSwBdpY0vjm5s2YZoBwU/y/nA+9vZp5K0jL/4632nQ1y/R7zPDsQGyO5+eqtwF0lZ6UKPgt8CvhtyfnoT3/TjfQNnjevExGbgA3Abk3J3fDUcywAf5Gb8W6SNLGf5a2k3mO2LQXwbUlL83Q6raYrItbk108CXWVmpklavby3xHfW5/o95nl2IDYGJO0AfA34REQ8V3Z+yiTpvcDaiFhadl4MgP8CJkXEHwGLeeVOzzrP2yNif1Iz1ymS3lF2hkYq0jhMHouphVT1Oxvs+j1WeXYg1mCStiF9iddGxNfLzk8FHAK8T9JKUjX6uyR9pdws9VLPdCOb15G0NbAT8ExTcjc8Qx5LRDwTES/lt18EDmhS3saKp4sZoYhYnX+vBW4mNXu1kqdqzdD599qS89MMrV7eK/2dDXD9HvM8OxBroNxv6Crg4Yi4qOz8VEFEnBERe0bEJNJUHt+NiL8sOVtF9Uw3shCYmV8fTTqGyt3JUcex9Ok/9T4q+ADFMC0ETshPTx4MbCg0I9gAJI2TtGPtNXAY0O+TqRVW/L+cCdxSYl6apdWnR6rsdzbI9XvM81yJKY7ayCHA8cAySffntDMjYlF5WbLBDDTdiKRzgHsjYiHpn/PLklaQOp/OKC/HA6vzWD4u6X2kJ4TWASeWluE6SLoe6AZ2l7QKOAvYBiAirgAWAUcCK4AXgZPKyWnL6QJuzs+cbA1cFxHfKjdLAxugHMwFbpR0MvA4cEx5OWyOVppuqwW/s36v3zQhz57iyMzMzKwkbpo0MzMzK4kDsQbJo1S/ewSfC0n75NdXSPqnetY1q4ek7twsUO/6LmMdSFKPBphlQdI3Jc3sb1kD9jui86a1B6WZPr7fpH1tlPT7zdjXcLmPWIVExF+XnQczs6KIOKLsPFjry2Nz/RTYJo/H2FQRsUMhL1cDqyLi083OR39cI2Zm1qHy06a+DljLy0MLtST/AzbWfnnE8g1Kk0S/GkDSR5QmaF0naaGkPfr7sKSrJZ1XeP8PktZI+rmkD/dZ9yilSbSfk/SEpLMLy74h6W/7rP+ApD9v6NHaqEk6SdJ/Fd4/KumrhfdPSNpP0huVJpxdpzTh7zGFdbaT9G+SfibpqdzEvf0A+/u40qS2e+b3LmMtZBjl5f9Iuiefi+6R9H8K6/RIOl/S/5CeNP39PvsYn7/Lfyis/1f59YmSvp/L23pJP5V0ROGze0u6U9Lzkr4j6TIVxg2UdLykxyU9I+kf++z3QEk/kPRsLpOfVxqigbydC/usv1DS343uL2o1DToXDXjOAO7Mv59VaiZ8W+FzA5WnnSRdlcvDaknnKc23WSuL/yPpYknPAGdL2kfS93K5f1rSDYVtRV4+CzgO+FTOx+ZjLk1E+KcBP8BK4G5gD2BX0vhMfw28C3ga2B/YDvgccGfhcwHsk19fDZyXX08DngLeDIwDruuzbjewLymY/qO87vvzsmOAuwr7eAtpANJty/47+WeLcvP7wLP5e9yD9Hj0qsKy9fn7f4I0NMPWpKk3ngam5PUuJo11syuwI2n0/H8tlJPa9v4ZuA94rctYa/7UWV52zb+Pz+Xl2Px+t7xeD/Az4E15+TY57a+AvYH/BWYV9tkD/FV+fSLwG+AjpOET/gb4Oa88gf8D4N+AbYG3A88BX8nLpgAbgXeQzoUXkYZReXdefgBpsuWtgUmkc+gn8rID835eld/vTgoiu8r+Ttrlp86yNdS5aLBzxqR8ftm6sM+hytPNwH/k/b6OdI39aOGzm4C/zXnZHrge+Me8/1eTZo+o7avfa20Vflwj1liXRsTPI2Id6WK4HynynhcR90Ua0fwM4G1K7eWDOQb4UkQ8GBEvAGcXF0ZET0Qsi4jfRsQDpAL4p3nxQuD1kibn98cDN0SaJNYqJCIeA54nlZV3kMYH+rmkN5K+z/8G3gusjIgvRcSmiPghafTnD0gSMAv4u4hYF2my2s/Qe6wzSbqINGjnOyPiFzndZazF1FlejgIejYgv5/JyPfBj4M8Km7o6Ipbn5b/JaVOAO4CzIuLKQbLxeER8ISJeJk2RNR7okvR7wB8D/xwRv46I79N7sNGjgVsj4s58LvwnCvPPRsTSiFiS87SSdAH+07zsbtIcr4fm1WcAPRHxVL1/OxvcaM9FeRuDnTMGMlB56iKNEfiJiHgh0gwQF9P73PbziPhczssvSUHdXsAeEfGrXAYrz4FYYz1ZeP0isAOv3FkAEBEbSTUHQ03Uuge9J3d9vLhQ0kGS7pD0C0kbSLVvu+d9/Aq4AfhLpf4fxwJfHtERWTN8j3Qn+Y78uod08vrT/H4v4KDcZPOspGdJAf7vAq8FfgdYWlj2rZxeszMpWPvXiNhQSHcZa01DlZde55zscXqfc55gS8eRpsu5aYj9bz7PRcSL+WXtXLeukNZ3P73KWw7+N08VJun1km6V9KSk50g3FLsXPj8fqM3K8Ze4vI2F0ZyLBj1nDGKg8rQXqbZ2TWFf/0GqGavpW44/BQi4W9Jy9eluUVUOxMbez0kFCtg8nchuDD0/2Bp6zyn2e32WX0e625wYETsBV5AKYM180j/IocCLEfGDEeXemqF28vuT/Pp79D75PQF8LyJ2LvzsEBF/Q2oW+CXwpsKynaLwhBCpSeG9wJckHVJIdxlrTUOVl17nnOz36H3O6W8k77NJ5em6Wj+cYVoD7CrpdwppE/ss3/w+r7dbYfnlpJq7yRHxGtKo5sXy9hVguqS3AH8I/OcI8miDG825CAY/Zwx39PgngJeA3Qv7ek1EvKmwTq9tRsSTEfGRiNgD+Cjw7+p/OJ5KjWTvQGzsXQ+clDs5bke6y7srV70P5kbgRElT8gnrrD7LdyTdff5K0oHAh4oL80Xxt8CF+M6x6r4HvBPYPiJWkZoAppEuUj8EbiU1Ax4vaZv888eS/jAifgt8AbhY0usAJE2QdHhxBxHRQwqavp7LC7iMtaqhyssiUnn5kKStJX2Q1Ox46xDb/Q2piWkccI2G+TRlRDwO3EvqNL1t7oxdbA69CXivpLfnTvjn0PsatCOpT9nG3Bz2N4Vl5GO9h1TWvpaboqyxRnwuyp8f7JzxC9L5oq6xvCLNGftt4EJJr5H0Kkl/IGnApk5JH1B+EIl0AxoUmr8Lnqo3H83gQGyMRcR3SH0hvka6I/wD6pirMCK+CXwW+C5pHr3v9lnlY8A5kp4ndcK+sZ/NXEPqOPmVfpZZRUTE/5I6Mf93fv8c8BjwPxHxcu73dRip3PycVJV/AanDM8DppDKyJDfpfAd4Qz/7WQx8GPgvSfu7jLWmOsrLM6Qa0Nmkpr9PAe+NiKfr2Pavgf9Lmoty3nCDMVKw/7a83/NIzdcv5W0vB04h1ZqsIV0oi4MN/z3pwv086ebiBrY0n1TeHPiPgQaciwY8Z+Rmx/OB/8lNjQfXkaUTSA9+PEQqLzeR+pAN5I+BuyRtJNXMnZb7vvV1FTAl5+M/68jHmPJck21M0gmkp5/eXnZerD25jNlg8vABP46IvrWtI93eO0hB/17hi5e1CdeItanc1PQxYLCnn8xGzGXM+srNVH+Qm5GmAdNpUF8uSdsApwFfdBBm7cSBWBvK/YN+QWoHv67k7FgbchmzAfwu6Um7jcClwN/kIQ5GJfdBepbULPXZ0W7PrErcNGlmZmZWEteImZmZmZWkZSfJ3H333WPSpEm90l544QXGjRtXTobGQDsdz0DHsnTp0qcj4rX9fKSpWr08Oa+Jy1PztNPxtOL5qUraqSw0Sn9/kwHLU1RgnqWR/BxwwAHR1x133LFFWitrp+MZ6FiAe8PladSc18TlqXna6Xha8fxUJe1UFhqlv7/JQOXJTZNmZmZmJXEgZmZmZlYSB2JmZmZmJXEgZmZmZlaSln1qsj/LVm/gxDnfGHK9lXOPakJurNW5PDXfpDr+3uC/udWn3vJ09bTWe+LP/yvto60CMbMy1HtChHJPisPJZz2GcyzFfc/ed1NdAa6ZWSdwIGZWQb7bNTPrDO4jZmZmZlYSB2JmZmZmJXEgZmZmZlYSB2JmZmZmJXEgZmZmZlaSIQMxSfMkrZX0YCHtbEmrJd2ff44sLDtD0gpJj0g6vJA+LaetkDSnkL63pLty+g2Stm3kAZqZmZlVVT01YlcD0/pJvzgi9ss/iwAkTQFmAG/Kn/l3SVtJ2gq4DDgCmAIcm9cFuCBvax9gPXDyaA7IzMzMrFUMGYhFxJ3Aujq3Nx1YEBEvRcRPgRXAgflnRUQ8FhG/BhYA0yUJeBdwU/78fOD9wzsEMzOzxvjwhz/M6173Ot785jdvTpO0q6TFkh7Nv3fJ6ZJ0aW7ReUDS/oXPzMzrPyppZiH9AEnL8mcuzddB62CjGdD1VEknAPcCsyNiPTABWFJYZ1VOA3iiT/pBwG7AsxGxqZ/1tyBpFjALoKuri56enl7Lu7ZPo3YPpe/nqmrjxo0tk9ehtNOxmFn7OvHEEzn11FM54YQTislzgNsjYm7uWjMHOJ3UyjM5/xwEXA4cJGlX4CxgKhDAUkkL83XycuAjwF3AIlLr0TebcnBWSSMNxC4HziUVsHOBC4EPNypTA4mIK4ErAaZOnRrd3d29ln/u2lu4cNnQh7TyuO4h16mCnp4e+h5jq2qnYzGz9vWOd7yDlStX9k2eDnTn1/OBHlIgNh24JiICWCJpZ0nj87qLI2IdgKTFwDRJPcBrImJJTr+G1ArkQKyDjSgQi4inaq8lfQG4Nb9dDUwsrLpnTmOA9GeAnSVtnWvFiuubmQ3pwx/+MLfeeiuve93rNqflGokbgEnASuCYiFifm4EuAY4EXgROjIj78mdmAp/OmzgvIubn9ANIfWW3J9VgnJYvvNY5uiJiTX79JNCVX09gy9aeCUOkr+onfQtDtQDV0/oDzWkBcovHlobzNxlRICZpfKFQ/jlQe6JyIXCdpIuAPUjVtXcDAiZL2psUaM0APhQRIekO4GhSv7GZwC0jyZOZdSY3JVkz5evWmAfiQ7UAnVjvfLRNaAFyi8eWhvM3qWf4iuuBHwBvkLRK0snA/8udDR8A3gn8HUBELAduBB4CvgWcEhEv59quU4HbgIeBG/O6kE6On5S0gtRn7Kq6j9TMOt473vEOdt11177J00lNSND7IaDNTUm5eajWlHQ4uSkpB1+1pqTx5KakXAt2DX6gqBM9lcsC+ffanD5QK9Bg6Xv2k24dbMgasYg4tp/kAYOliDgfOL+f9EWku8m+6Y+Rnqo0M2uUyjUltVvzTSscT73Nd32P5cknn+SFF14orrKQ1GIzl94tNwtJD64tINWwboiINZJuAz5Te7oSOAw4IyLWSXpO0sGkGtYTgM+N8PCsTYzmqUkzs8qrSlNSuzXftMLx1Nt8d/W0cZuP5dhjj6Wnp4enn34a4I9yK9Bc4Mb8+nHgmPzRRaT+hitIfQ5PAsgB17nAPXm9c2od94GP8Uqfw2/iZu6O50DMKkHSRFKzTxepj86VEXFJIztdW0d5qtaXdRhNSd190ntwU1LHuf766ze/lvRARNRagA7tu25urj6lv+1ExDxgXj/p9wJv3vIT1qk816RVxSbSeHRTgIOBU/LsC7VO15OB2/N76N3pehapQ3XtabmzSM0EBwJnFZoHrHPUmpJgy6akE/JAnAeTm5JI/VcPk7RLLi+HAbflZc9JOjgH/yfgB4rMrIFcI2aVkC94a/Lr5yU9TOqL05Dxe4BXbnOtrbgpycxamQMxqxxJk4C3kjqzNqrTdX/7achMDcNRb+fm4Y4RVE/H6bKOpe++G/F3Le77ox/9KB/96EcBeOc73+mmJDNrKQ7ErFIk7QB8DfhERDxXnIat0Z2uGzVTw3DUO6bPcMcIqqfjdL3brNdwxicq7nv2vptG/XdtldkxzMyG4j5iVhmStiEFYddGxNdzcqPG7zEzM6scB2JWCbkj9FXAwxFxUWFRQzpdN+UgzMzMhslNk1YVhwDHA8sk3Z/TzqSxna7NzMwqxYGYVUJEfJ80J2l/GtLp2szMrGrcNGlmZmZWEgdiZmZmZiVxIGZmZmZWEgdiZmZmZiVxIGZmZmZWEgdiZmZmZiVxIGZmZjYISW+QdH/h5zlJn5B0tqTVhfQjC585Q9IKSY9IOryQPi2nrZA0p5wjsirxOGJmZmaDiIhHgP0AJG1FmjbtZtJA0hdHxL8V15c0BZgBvAnYA/iOpNfnxZcB7wFWAfdIWhgRDzXjOKyaHIiZmZnV71DgJxHxeJqZrV/TgQUR8RLwU0krgAPzshUR8RiApAV5XQdiHcyBmJm1HUlvAG4oJP0+8M/AzsBHgF/k9DMjYlH+zBnAycDLwMcj4racPg24BNgK+GJEzG3GMVhlzQCuL7w/VdIJwL3A7IhYD0wAlhTWWZXTAJ7ok35QfzuRNAuYBdDV1UVPT0+v5bP33VRXZvt+bixs3LixKftpJcP5mzgQM7O246YkGwuStgXeB5yRky4HzgUi/74Q+HAj9hURVwJXAkydOjW6u7t7LT9xzjfq2s7K47qHXGe0enp66Ju/Tjecv4kDMTNrd25KskY5ArgvIp4CqP0GkPQF4Nb8djUwsfC5PXMag6Rbh3IgZmbtrhJNSe3WfNMKx1Nv890wjuVYCmVJ0viIWJPf/jnwYH69ELhO0kWkGtbJwN2AgMmS9iYFYDOAD9WVSWtbQwZikuYB7wXWRsSbc9qupP4Xk4CVwDERsV7pdvMS4EjgReDEiLgvf2Ym8Om82fMiYn5OPwC4GtgeWAScFhHRoOMzsw5Wpaakdmu+aYXjqbf57upp44Y8FknjSE3UHy0k/z9J+5HK08rasohYLulGUs3pJuCUiHg5b+dU4DZSn8N5EbG87gOytlTPOGJXA9P6pM0Bbo+IycDt+T2katvJ+WcW6aRXC9zOIt1JHgicJWmX/JnLSZ1na5/ruy8zs5HaoikpIl6OiN8CX+CV5seBmpIGa2KyDhIRL0TEbhGxoZB2fETsGxF/FBHvK9SOERHnR8QfRMQbIuKbhfRFEfH6vOz8Zh+HVc+QgVhE3Ams65M8HZifX88H3l9IvyaSJcDOksYDhwOLI2JdbgZYDEzLy14TEUtyLdg1hW2ZmY3WFk1JhWV9m5JmSNouNxvVmpLuITcl5dq1GXldM7OGGGkfsa5C5P8k0JVfT2DL/hQThkhf1U96v4bqg9G1fX19Aqrer6GmFfpg1KudjsVag5uSzKwVjLqzfkSEpKb06RqqD8bnrr2FC5cNfUjNeJy3EVqhD0a92ulYrDVExAvAbn3Sjh9k/fOBLZqK8jhjixqeQTMzRj7X5FO1Kv78e21OH24/i9X5dd90MzMzs7Y30kBsITAzv54J3FJIP0HJwcCG3IR5G3CYpF1yJ/3DgNvysuckHZyfuDyhsC0zMzOztlbP8BXXA93A7pJWkZ5+nAvcKOlk4HHgmLz6ItLQFStIw1ecBBAR6ySdS+r4CnBORNQeAPgYrwxf8c38Y2ZmZtb2hgzEIuLYARYd2s+6AZwywHbmAfP6Sb8XePNQ+TAzMzNrNyNtmjQzMzOzUXIgZmZmZlYSB2JmZmZmJXEgZmZmZlYSB2JmZmZmJXEgZmZmZlYSB2JmZmZmJRn1XJNmZja0Zas3cOKcbwy53sq5RzUhNzYSklYCzwMvA5siYqqkXYEbgEmkieSPiYj1ebaYS0iDnL8InBgR9+XtzAQ+nTd7XkTMb+ZxWLW4RszMzKx+74yI/SJian4/B7g9IiYDt+f3AEcAk/PPLOBygBy4nQUcBBwInJWn/rMO5UDMzNqSpJWSlkm6X9K9OW1XSYslPZp/75LTJelSSSskPSBp/8J2Zub1H801GWZF04FajdZ84P2F9GsiWQLsLGk8cDiwOCLWRcR6YDEwrcl5tgpx06SZtbN3RsTThfe12ou5kubk96fTu/biIFLtxUGF2oupQABLJS3MF1DrPAF8W1IA/xERVwJdEbEmL38S6MqvJwBPFD67KqcNlN6LpFmkmjS6urro6enptXz2vpvqynDfz42FjRs3NmU/rWQ4fxMHYlYZkuYB7wXWRsSbc5r7X1gjTQe68+v5QA8pENtcewEskVSrvegm114ASKrVXlzf3GxbRbw9IlZLeh2wWNKPiwsjInKQNmo5yLsSYOrUqdHd3d1reT39DQFWHtc95Dqj1dPTQ9/8dbrh/E0ciFmVXA18HrimkOYaDBupptVewNA1GF3b11eL0So1C61QC1JvrVG9xxIRq/PvtZJuJvXxekrS+IhYk4P3tXn11cDEwsf3zGmreeVmoJY+9M6tbTkQs8qIiDslTeqT7BoMG6mm1V7k7Q1ag/G5a2/hwmVDn3KbUYPRCK1QC1JvrdHV08YNeSySxgGviojn8+vDgHOAhcBMYG7+fUv+yELgVEkLSDeLG3KwdhvwmUIH/cOAM4ZzXNZeHIhZ1VW+BmM46q1BGG7/j3ru6Ms6lr77bsTf1bUXVoIu4ObUK4Ktgesi4luS7gFulHQy8DhwTF5/EanrxApS94mTACJinaRzgXvyeufUbhxbxaQ+Ae7sfTf1G/R6KJb6OBCzllHVGozhqLe2Y7j9P+qpnah3m/UaTs1Ncd+z99006r/rUPt27YU1WkQ8Bryln/RngEP7SQ/glAG2NQ+Y1+g8WmtyIGZV5xoMGwnXXphZS3AgZlXnGgwbNtdemFmrcCBmlSHpelJt1u6SVpGefpyLazDMzKxNORCzyoiIYwdY5BoMMzNrS57iyMzMzKwkDsTMzMzMSjKqQMyT6pqZmZmNXCNqxN4ZEftFxNT8vjYlzWTg9vweek9JM4s0JU1tLsGzSE++HQicVXjizczMzKxtjUXT5HTSVDTk3+8vpF8TyRKgNiXN4eQpafJ8gLUpaczMzMza2mifmvSkumOoFSbVrVc7HYuZmVmjjDYQ86S6Y6gVJtWtVzsdi5mZWaOMqmmyOKku0GtSXYBhTEnTX7qZmZlZWxtxICZpnKQda69JU8k8yCtT0sCWU9KckJ+ePJg8JQ1wG3CYpF1yJ/3DcpqZmZlZWxtN06Qn1TUzMzMbhREHYp5U18zMOoGkicA1pAqIAK6MiEsknQ18BPhFXvXMiFiUP3MGcDLwMvDxiLgtp08DLgG2Ar4YEXObeSxWPR5Z38zajqSJku6Q9JCk5ZJOy+lnS1qdB6G+X9KRhc+ckQecfkTS4YX0aTlthaQ5/e3P2t4mYHZETAEOBk6RNCUvuziPpblfIQibAswA3kQajunfJW0laSvgMtK4mlOAYwvbsQ7lSb/NrB3VLpz35b6sSyUtzssujoh/K67c58K5B/AdSa/Piy8D3kMaWuceSQsj4qGmHIVVQu7PvCa/fl7SwwwwzFI2HVgQES8BP5W0gvQwG8CK3KKEpAV5XZenDuZAzMzaji+cNlYkTQLeCtwFHAKcKukE4F5S8L+eVNaWFD5WHB+z77iZBw2wn0HHzaxnzEwYm3Ez++57oDE8O3nsyOGMnelAzMzaWlUunB5wuvnqDVbqPRZJOwBfAz4REc9Juhw4l9Rv7FzgQuDDI81v0VDjZp445xt1bWcsxs3su+/Z+27qdwzPVhmzcywMZ+xMB2Jm1raqdOH0gNPNV2+wcvW0cUMei6RtSGXp2oj4OkBEPFVY/gXg1vx2sPExPW6m9eLO+mbWlga6cEbEyxHxW+ALvNL86AGnbUBK4zRdBTwcERcV0scXVvtz0liakMbNnCFpO0l7A5OBu0nDNE2WtLekbUn9Ehc24xisulwjZmZtZ7ALZ2Eu3L4XzuskXUTqrF+7cIp84SQFYDOADzXnKKxCDgGOB5ZJuj+nnUl66nE/Ug3rSuCjABGxXNKNpL6Em4BTIuJlAEmnkgYt3wqYFxHLm3cYVkUOxMysHfnCaQ0TEd8nBeV9LRrkM+cD5/eTvmiwz1nncSBmZm3HF04zaxXuI2ZmZmZWEgdiZmZmZiVxIGZmZmZWEvcRMzMzs5Ywqd6BbOceNcY5aRzXiJmZmZmVxIGYmZmZWUkciJmZmZmVxIGYmZmZWUkciJmZmZmVxIGYmZmZWUkciJmZmZmVxIGYmZmZWUkciJmZmZmVpDIj60uaBlwCbAV8MSLmlpwlq0O9oxxfPW3cGOekN5cnaySXJ2sklycrqkSNmKStgMuAI4ApwLGSppSbK2tVLk/WSC5P1kguT9ZXJQIx4EBgRUQ8FhG/BhYA00vOk7UulydrJJcnaySXJ+ulKk2TE4AnCu9XAQf1XUnSLGBWfrtR0iN9VtkdeHqonemCEeay+eo6nlbwzgsGPJa9xmB3TS1Pw9HoslfYXtPLykiP5eMNyOsg+2758uTzU/O16PmpLs0oTwP9T5dZlivwf9Tf36Tf8lSVQKwuEXElcOVAyyXdGxFTm5ilMdVOx1PFY2mn8uS8lq+dylM92ul4qngsQ5WnKqni369sw/mbVKVpcjUwsfB+z5xmNhIuT9ZILk/WSC5P1ktVArF7gMmS9pa0LTADWFhynqx1uTxZI7k8WSO5PFkvlWiajIhNkk4FbiM9zjsvIpaPYFMtUY07DO10PE07lg4tT87rGOnQ8lSPdjqeVjw/VUk7lYVGqftvoogYy4yYmZmZ2QCq0jRpZmZm1nEciJmZmZmVpCUDMUnTJD0iaYWkOf0s307SDXn5XZImlZDNutRxLCdK+oWk+/PPX5WRz3pJmidpraQHB1guSZfm431A0v7NzmM/eWqJ8iRpoqQ7JD0kabmk0/pZp1vShkJ5+ecy8przslLSspyPe/tZXrmy0AitUp7q4fNTe5TJsVDP+ahTSdpK0g8l3VrXByKipX5InRt/Avw+sC3wI2BKn3U+BlyRX88Abig736M4lhOBz5ed12Ec0zuA/YEHB1h+JPBNQMDBwF0t8B1UojwB44H98+sdgf/tJ6/dwK1ll4Ocl5XA7oMsr1RZ6LTy1KBj8fmpQ3/qOR916g/wSeC6es/FrVgjVs/0ENOB+fn1TcChktTEPNar7aa6iIg7gXWDrDIduCaSJcDOksY3J3f9apnyFBFrIuK+/Pp54GHSKN2tqmploRFapjzVween9iiTY6INz0cNIWlP4Cjgi/V+phUDsf6mh+j75W9eJyI2ARuA3ZqSu+Gp51gA/iJXk98kaWI/y1tJvcfcLC1ZnnJz1luBu/pZ/DZJP5L0TUlvam7Oegng25KWKk3X0lfVykIjtGR5GoDPT+1RJsfcEOejTvNZ4FPAb+v9QCsGYp3mv4BJEfFHwGJeuZO2DiVpB+BrwCci4rk+i+8D9oqItwCfA/6zydkrentE7A8cAZwi6R0l5sXGhs9PHW6I81FHkfReYG1ELB3O51oxEKtneojN60jaGtgJeKYpuRueIY8lIp6JiJfy2y8CBzQpb2OlatN7tFR5krQN6aR3bUR8ve/yiHguIjbm14uAbSTt3uRs1vKyOv9eC9xMauoqqlpZaISWKk9D8PmpPcrkmBnqfNSBDgHeJ2klqSn/XZK+MtSHWjEQq2d6iIXAzPz6aOC7kXvQVcyQx9Knf8L7SO3wrWwhcEJ+OulgYENErCkxPy1TnnI/oquAhyPiogHW+d1afyNJB5L+x5t+kZc0TtKOtdfAYUDfJ9WqVhYaoWXKUx18fmqPMjkm6jkfdZqIOCMi9oyISaT/l+9GxF8O9blKTHE0HDHA9BCSzgHujYiFpMLxZUkrSB0zZ5SX44HVeSwfl/Q+YBPpWE4sLcN1kHQ96cm93SWtAs4CtgGIiCuARaQnk1YALwInlZPTpMXK0yHA8cAySffntDOB34PNf9+jgb+RtAn4JTCjpIt8F3Bzjgm3Bq6LiG9J+utCXitVFhqhxcrToHx+ao8yOYb6PR/lmngbBk9xZGZmZlaSVmyaNDMzM2sLDsTMzMzMSuJAzMyswylNR/XusvNh1Sdpo6TfH+Fne6o0DZbSFF3fLzsfDsTGmE9wNlaqchIxs84RETtExGNl56OdOBAzMzMzK4kDsTEk6cukoQX+K1fnfkrSwZL+P0nP5mlougvr90g6Ly/fKOm/JO0m6VpJz0m6J08lUVs/JH1c0mOSnpb0/5Pk77TNSJoj6SeSnpf0kKQ/l/SHwBWk6Yw2Sno2r7udpH+T9DNJT0m6QtL2eVm3pFW5HK6VtEbS+yUdKel/Ja2TdGZhv2crTVtzQ973fZLeUsofwZphP6Wpijbk7/zV/dW65vPOPvn11ZL+XWk6rY2S/kdpLLvPSlov6ceS3lrO4dhwSDpJ0n8V3j8q6auF909I2q+f7/8ySd/I54i7JP1B4TPvyWVgg6TPkyZTry3bR9L38rKnJd1QWDbotU3ShyU9nMvYbZL2Kix7o6TF+Xz2iKRjCst2k7QwX0/vBjbntUy+aI+hiDge+BnwZxGxA3At8A3gPGBX4O+Br0l6beFjM0hjs0wgFZIfAF/K6z9MGvem6M+BqcD+pAlrPzxWx2Ol+QnwJ6QR2P8F+ArwLPDXwA9yU8HOed25wOuB/YB9SOXonwvb+l3g1YX0LwB/SRoR/U+Af5K0d2H96cBXSeXvOuA/lUbTtvZzDDAN2Bv4I+ofE+wY4NPA7sBLpHPWffn9TYAH+2wN3wP+RNKrJO0BbAu8DUCpT9gOwAP9fG4G6by0C2n8tfPzZ3YHvs4rZeMnpLHHas4Fvp0/tydpSraifq9tkqaTxk/8v8Brgf8Grs/LxpGm2roOeF3O279LmpK3eRnwK2B83l4lrpcOxJrrL4FFEbEoIn4bEYuBe0kDCNZ8KSJ+EhEbgG8CP4mI7+TJgb9Kmli16IKIWBcRPyNNNnrs2B+GNVNEfDUifp7LzA3Ao2w5XVBtpOtZwN/lMvE88Bl6Dxj6G+D8iPgNaQqO3YFLIuL5iFgOPAQUa72WRsRNef2LSEHcwWNwmFa+S3M5W0eaQ3K/Oj93c0QsjYhfkaay+lVEXBMRLwM3sOU5yyoo9/t6nvS9v4M0kO/PJb0R+FPgvyOiv4msb46Iu/M16lpeKTdHAssL54/PAk8WPvcbYC9gj4j4VUT07e860LXtr4F/jYiH8z4/Q6rN3Qt4L7AyIr4UEZsi4oekKZg+IGkr4C+Af46IFyLiQSoyN6oDsebai1Qgnq39AG8nRec1TxVe/7Kf9zv02eYThdePA3s0LrtWBZJOkHR/ocy8mRRA9fVa4HeApYV1v5XTa57JF0hI5QkGL2Oby1c+Ca/CZaxdFS+SL7LluWYgwz1nWXV9jzTzwDvy6x5SEPan+X1/Bio3e9D7/BH0vl59itRUebek5ZL61k4NdG3bC7ikcI5bl7czIS87qM819jhSS8BrSbN89N1u6VpuiqMWVJy64AngyxHxkQZufyKwPL/+PeDnDdy2lSzf5X0BOJTUDPmy0nQionfZAniadOF7U23C7QbYPAFy7qOxJy5jneQFUnAPpLlMS8yLjb3vAX9Gap7+DKkLxHGkJsrPD3Nba+h9/lDxfUQ8CXwkL3s78B1Jd0bEirzKQNe2J0i1+tf23WE+X34vIt7Tz7KtSFNxTQR+XNhu6VwjNvaeAmpjrnwF+DNJh0vaKneG7Za05yi2/w+SdpE0ETiN1BRg7WMcKeD6BaQOtaQaMUhla0+lCZlrNVZfAC6W9Lq8/gRJh49i/wdI+r+StgY+QeoDtGQU27PW8iPgTbmT9quBs0vOj42t7wHvBLaPiFWk/lfTgN2AHw5zW98glZ3a+ePjpJopACR9oHDtW086zxWbPge6tl0BnCHpTXk7O0n6QF52K/B6ScdL2ib//LGkP8wtAV8Hzpb0O7nf2MxhHtOYcCA29v4V+HSuIv0gqdPhmaQL6xPAPzC67+EWYClwP6ngXzWKbVnFRMRDwIWkDtBPAfsC/5MXf5d0x/ikpKdz2umkDrNLJD0HfAd4wyiycAup3K4nPUTyf3N/D+sAEfG/wDmkcvQo4HHr2lj+vjeSAjAi4jngMeB/Cl0a6t3W08AHSA8QPQNM5pVzF8AfA3dJ2ggsBE7rMz5Zv9e2iLgZuABYkM9xDwJH5GXPA4eR+sX+nNRsegGwXd7mqaSm0yeBq0kPwpXOk363MEkBTC5U5Zo1jKSzgX0i4i/LzouZdY5Ou7a5RszMzMysJA7EzMzMzEripkkzMzOzkrhGzMzMzKwkLTuO2O677x6TJk0C4IUXXmDcuHHlZqjB2u2YBjqepUuXPh0RmwcczWO93Ausjoj35ul2FpAen14KHB8Rv5a0HXANaWqeZ4APRsTKvI0zgJOBl4GPR8RtQ+WvWJ6GynOraqfjqbc8lcXlqbW4PLWGVj/mActTRLTkzwEHHBA1d9xxR7SbdjumgY4HuDcK3yvwSdI8Ybfm9zcCM/LrK4C/ya8/BlyRX88Absivp5DGPtqONCjhT4CtYhjlaag8t6p2Op56y1NZPy5PrcXlqTW0+jEPVJ7cNGmVkQf3Owr4Yn4v4F2kiYMhzQv2/vx6Oq/ME3YTcGhefzqwICJeioifksbU2mJeRjMzsypo2aZJa0ufJc0/tmN+vxvwbKSJXSHNczghv55AnjMsIjZJ2pDXn0Dvkd+Ln+lF0izSJNl0dXXR09PTa/nGjRu3SGtl7XQ87XQsZtbZHIhZJUh6L7A2IpZK6m7GPiPiSuBKgKlTp0Z3d+/d9vT00DetlbXT8bTTsZhZZ3Mg1gYmzflGXeutnHvUGOdkVA4B3ifpSODVwGuAS4CdJW2da8X2BGqTWa8mTd66Ks9jthOp034tvab4GatDm5Qn8tyId5L6C24N3BQRZzXrAZB2t2z1Bk6so6xUvZy0u3r/n8HfVVncR8wqISLOiIg9I2ISqfP9dyPiOOAO4Oi82kzS/GOQ5iarTdh6dF4/cvoMSdvlC+5k4O4mHYZVy0vAuyLiLcB+wDRJB5Pmnrs4IvYhzaF5cl7/ZGB9Tr84r0eeHHgG8CbSBMj/np/uNTMbtREHYpJeLeluST+StFzSv+T0vSXdJWmFpBskbZvTt8vvV+TlkwrbOiOnPyLp8FEflbWT04FPSlpBqsGoTWp+FbBbTv8kMAcgIpaTnrR8CPgWcEoMc7Jaaw/5QaWN+e02+SfwAyBmViGjaZqs3W1ulLQN8H1J3yRdFC+OiAWSriDdZV5O4W5T0gzS3eYH+9xt7gF8R9LrffHsXBHRA/Tk14/Rz0UvIn4FfGCAz58PnD92ObRWkWuulgL7AJeRhjMZkwdAOu3hj67tYfa+m4ZcrxWOud2+G2stIw7EcjPQQHebH8rp84GzSYHY9Pwa0t3m5/vebQI/zTUcBwI/GGnezMwA8g3dfpJ2Bm4G3jiG++qohz8+d+0tXLhs6EvIyuO6xz4zo9Ru3421llF11m/m3WbeX793nO14NzOcY6rnrhTKvTNtx+/IWkdEPCvpDuBt+AGQpmqjhz92Jo1x+GZSpcOHgUeAG4BJwErgmIhYnysZLgGOBF4EToyI+/J2ZgKfzps9LyLmYx1tVIFYM+828/76veNsx7uZ4RxTPU8uQbl3pu34HVm1SXot8JschG0PvIfUJaL2AMgC+n8A5AcUHgCRtBC4TtJFpO4TfgCkZCUFd5cA34qIo3Pf598BzgRuj4i5kuaQ+qqeDhxBKieTgYNIrUIHSdoVOAuYSgrmlkpaGBHrG5lRay0NeWoyIp4lndw2323mRf3dbeK7TTNrgvHAHZIeAO4BFkfErfgBEBsmSTsB7yCXlYj4db7uFR/w6PvgxzX5gZElpOvieOBwUjlcl4OvxaQnca2DjbhGzHebvbVL9btZu4iIB4C39pPuB0BsuPYGfgF8SdJbSF1yTgO6ImJNXudJoCu/3twVJ6t1uRkofQuNevij3q4rUP0HK9q1i8tomibHA/NzP7FXATdGxK2SHgIWSDoP+CG97za/nO8215GelCQilkuq3W1uwnebZmZWLVsD+wN/GxF3SbqEXGNakysWolE7bNTDH/V2XYHqP1jRrl1cRvPUpO82zcysE6wCVkXEXfn9TaRA7ClJ4yNiTW56XJuXD9TlZjXQ3Se9ZwzzbS3AI+ubmZkNIiKeBJ6Q9IacdCipFac4w0ffrjgnKDkY2JCbMG8DDpO0i6RdgMNymnUwzzVpZmY2tL8Frs1PTD4GnETuliPpZOBx4Ji87iLS0BUrSMNXnAQQEesknUt6eATgnIhY17xDsCpyIGZmZjaEiLifNOxEX4f2s24ApwywnXnAvIZmzlqamybNzMzMSuIaMTMzA+ofhgdg9r5jmBGzDuJArMKGc1I0MzOz1uOmSTMzM7OSOBAzMzMzK4mbJs06xLLVG4Y1yraZmY0914iZmZmZlcSBmJmZmVlJHIhZJUh6taS7Jf1I0nJJ/5LT95Z0l6QVkm7Io1ojabv8fkVePqmwrTNy+iOSDi/pkMzMzIbkQMyq4iXgXRHxFmA/YFqeo+0C4OKI2AdYD5yc1z8ZWJ/TL87rIWkKMAN4EzAN+HdJWzXzQMzMzOrlzvpDaPRYXvVub/a+m+ikrydPCbIxv90m/wTwLuBDOX0+cDZwOTA9vwa4Cfi8JOX0BRHxEvBTSSuAA4EfjP1RNJ8H4LR24XETrVN1zpXeKi/XXC0F9gEuA34CPBsRm/Iqq4AJ+fUE4AmAiNgkaQOwW05fUths8TN99zcLmAXQ1dVFT09Pr+UbN27cIq1qUsBen67th7f+UMr827TCd2NmVg8HYlYZEfEysJ+knYGbgTeO8f6uBK4EmDp1anR3d/da3tPTQ9+0qhnOcBSz993Ehcsa9y+/8rjuhm1ruFrhuzEzq4f7iFnlRMSzwB3A24CdJdWihz2B1fn1amAiQF6+E/BMMb2fz5iZmVWKAzGrBEmvzTVhSNoeeA/wMCkgOzqvNhO4Jb9emN+Tl3839zNbCMzIT1XuDUwG7m7KQZiZmQ2TmyatKsYD83M/sVcBN0bErZIeAhZIOg/4IXBVXv8q4Mu5M/460pOSRMRySTcCDwGbgFNyk6eZmVnlOBCzSoiIB4C39pP+GOmpx77pvwI+MMC2zgfOb3QezczMGs1Nk2ZmZmYlcSBmZmZmVhI3TZqZmVndg+qunHvUGOeks7hGzMzajqSJku6Q9FCeu/S0nL6rpMWSHs2/d8npknRpnqP0AUn7F7Y1M6//qKSZA+3TzGwkRlwjJmkicA3QRZqK5sqIuETSrsANwCRgJXBMRKzP089cAhwJvAicGBH35W3NBD6dN31eRMwfab7M2oGnexm1TcDsiLhP0o7AUkmLgROB2yNirqQ5wBzgdOAI0lAnk4GDSNNoHZTPZ2cBU0nnuaWSFkbE+qYfkZm1pdHUiNVOdFOAg4FT8oTLc0gnusnA7fk99D7RzSKd6Cic6A4iPR13Vu0u1cxsJCJiTe1GLyKeJ41JN4E0F2ntRm8+8P78ejpwTSRLSAMJjwcOBxZHxLocfC0mTSZvZtYQI64Ri4g1wJr8+nlJxRNdd15tPtBDuuPcfKIDlkiqnei6ySc6gHzXOg24fqR5MzOrkTSJNDTKXUBXPncBPEmq0YfC3KVZbY7SgdL724/nLq2Yev/e9X43eZzDe4HVEfHePGj0AtI8t0uB4yPi15K2I7UYHUCa8eODEbEyb+MM4GTgZeDjEXHb8I7K2k1DOuuXfaIbyxNcWSeasTjJeZJm6zSSdgC+BnwiIp5LPSSSiAhJ0ah9ee7S6ql3PtRhfDenkWpXX5PfXwBcHBELJF1BCrAuz7/XR8Q+kmbk9T6YW41mAG8C9gC+I+n1HnS6s436v6gKJ7qxPMEN58TUSGNyklv2Qt2rNvqpmFa4CFl7kbQN6dx0bUR8PSc/JWl8RKzJNfJrc/pAc5Su5pUa/lp6z1jm26pJ0p7AUaTBoj+Z+z2/C/hQXmU+cDYpEJueXwPcBHw+rz8dWBARLwE/zTODHAj8oEmHYRU0qiu9T3RmVkX5oncV8HBEXFRYVJujdC5bzl16qqQFpP6qG/I57DbgM4V+q4cBZzTjGKxyPgt8Ctgxv98NeDYiak0XxdaczS09EbFJ0oa8/gRgSWGbY97UPRatOmW1brRry8ponpr0ic7MquoQ4HhgmaT7c9qZpPPSjZJOBh4HjsnLFpGe6F5Beqr7JICIWCfpXOCevN45tf6s1jkkvRdYGxFLJXU3Y5+Nauoei1adept8G61dW1ZGUyPmE52ZVVJEfB/QAIsP7Wf9AE4ZYFvzgHmNy521oEOA90k6Eng1qY/YJaSna7fOtWK1Vh54pQVolaStgZ1InfYHahmyDjaapyZ9ojMbJo8PZtZ6IuIMcktNrhH7+4g4TtJXgaNJT072bQGaSer7dTTw3dxneiFwnaSLSJ31JwN3N/FQrIKq/ciLmZlZdZ0OLJB0HvBDUncd8u8v587460hPShIRyyXdCDxEGovzFD8xaQ7EzMzM6hQRPeQHyiLiMdJTj33X+RXwgQE+fz7pyUszwHNNmpmZmZXGgZiZmZlZSRyImZmZmZXEgZhVgqSJku6Q9JCk5ZJOy+m7Slos6dH8e5ecLkmXSloh6QFJ+xe2NTOv/6ikmWUdk5mZ2VAciFlVbAJmR8QU4GDglDwv2xzg9oiYDNye3wMcQXr0ezJp9OnLIQVuwFmkQYMPBM4qDBZsZmZWKQ7ErBIiYk1E3JdfP0+aWHcCaW62+Xm1+cD78+vpwDWRLCENrDgeOBxYHBHrImI9sBiY1rwjMTMzq5+Hr7DKkTQJeCtwF9AVEWvyoieBrvx681xuWW3OtoHS+9tPQ+ZyG46xmPetXl3bN3b/Zc751q5zzplZ53EgZpUiaQfSRPKfiIjn0pSmSR6ZOhq1r0bN5TYcYzHvW71m77uJC5c17l++rPnmoH3nnDOzzuOmSasMSduQgrBrI+LrOfmp3ORI/r02pw80Z5vncjMzs5bhGjGrBKWqr6uAhyPiosKi2pxtc9lyLrdTJS0gdczfEBFrJN0GfKbQQf8w8hxxZp3Kc5yaVZcDMauKQ4DjgWWS7s9pZ5ICsBslnQw8DhyTly0CjgRWAC8CJwFExDpJ5wL35PXOiYh1TTkCMzOzYXIgZpUQEd8HNMDiQ/tZP4BTBtjWPGBe43JnZmY2NtxHzMzMzKwkDsTMzMzMSuJAzMzMzKwkDsTMzMzMSuJAzMzMzKwkDsTMzMzMSuJAzMzMzKwkHkfMzMzaUr0zClw9bdwY56S91Pt3XTn3qDHOSXtwjZiZmZlZSRyImZmZmZXEgZiZtSVJ8yStlfRgIW1XSYslPZp/75LTJelSSSskPSBp/8JnZub1H5U0s4xjMbP2NapAzCc6M6uwq4FpfdLmALdHxGTg9vwe4Ahgcv6ZBVwO6XwGnAUcBBwInFU7p5mZNcJoO+tfDXweuKaQVjvRzZU0J78/nd4nuoNIJ7qDCie6qUAASyUtjIj1o8ybmXWwiLhT0qQ+ydOB7vx6PtBDOj9NB67Jk8kvkbSzpPF53cURsQ5A0mJScHf9WOffqkPSRNJ1rot0nboyIi7J168bgEnASuCYiFgvScAlwJHAi8CJEXFf3tZM4NN50+dFxPyR5GnZ6g2cWGeneau2UQViPtGZWYvpiog1+fWTpAsrwATgicJ6q3LaQOlbkDSLVJtGV1cXPT09vZZv3Lhxi7Rmmb3vpoZvs2v7sdluGer4bjYBsyPiPkk7kioMFgMn4ooHG6WxGL6i6Se6sTzBlXWiKfsk1+i/Z5kXIbP+RERIigZu70rgSoCpU6dGd3d3r+U9PT30TWuWsag5mb3vJi5c1h4jIF09bdyg302+pq3Jr5+X9DDpOuWKBxu1Mf0vataJbixPcGVV/ZZ9klt5XHdDt1fmRcis4ClJ4yNiTb4wrs3pq4GJhfX2zGmreeVCW0vvaUI+raJyK9BbgbsosYa17Jv1eviGvj5jcaWv/Imu3sHozKztLARmAnPz71sK6adKWkBqStqQz2G3AZ8pdNA/DDijyXm2ipC0A/A14BMR8VzqCpY0u4b1c9feUvkaSd/Q12cshq+onehgyxPdCfnpyYPJJzrgNuAwSbvkk91hOc3MbMQkXQ/8AHiDpFWSTiYFYO+R9Cjw7vweYBHwGLAC+ALwMYDchHQucE/+OafWrGSdRdI2pCDs2oj4ek5+Klc4MIyKh/7SrYONdvgKn+isYTwcijVSRBwbEeMjYpuI2DMiroqIZyLi0IiYHBHvrp1rIjklIv4gIvaNiHsL25kXEfvkny+Vd0RWlvwU5FXAwxFxUWGRKx5s1Eb71OSxAyw6tJ91AzhlgO3MA+aNJi/WFq7Gw6GYWfUcAhwPLJN0f047k1TRcGOuhHgcOCYvW0QaumIFafiKkyBVPEiqVTyAKx4MT/ptFeLhUFrLcPpaevJfa2UR8X1AAyx2xYONigMxq7q2GvepzKecynzKyk9PmZn1z4GYtYx2GPepzJGwyxwSxU9PmZn1z5N+W9X5qSQzM2tbrhGzqvO4T2YD8JiIZq3PgZhVRh4OpRvYXdIq0tOPfirJzMzalgMxqwwPh2JmZp3GgZj1q94mDw9L4OYhMzMbOXfWNzMzMyuJa8TMzMys4Tzoc31cI2ZmZmZWEgdiZmZmZiVxIGZmZmZWEgdiZmZmZiVxIGZmZmZWEgdiZmZmZiVxIGZmZmZWEgdiZmZmZiVxIGZmZmZWEgdiZmZmZiXxFEdmNuY8ibyZDaaec8TsfTfRPfZZaTrXiJmZmZmVxIGYmZmZWUkciJmZmZmVpK36iNXbD8XMzMysCioTiEmaBlwCbAV8MSLmlpwlq0O9we/V08aNcU56a0R5WrZ6Ayc6uDd8frLGcnkauXZ88KcSgZikrYDLgPcAq4B7JC2MiIfKzZm1Ipcna6RmlyfX7Lc3n5+sr0oEYsCBwIqIeAxA0gJgOuCCaSPh8tSiKlrD2pDy5BpWy3x+aoKyb2iGUyNXlUBsAvBE4f0q4KC+K0maBczKbzdKeiS/3h14ekxz2GQfb7NjeucFAx7PXmOwu9GWp5q2+g7aqUy5PJXP5WnEXJ5GqJXKnC7oN7nf8lSVQKwuEXElcGXfdEn3RsTUErI0ZtrtmKp4PAOVp5oq5nk02ul4qngsLk+tq4rH0mnlqR7tesxVGb5iNTCx8H7PnGY2Ei5P1kguT9ZILk/WS1UCsXuAyZL2lrQtMANYWHKerHW5PFkjuTxZI7k8WS+VaJqMiE2STgVuIz3OOy8ilg9jEwNW37awdjumph1PA8pTjb+D6nJ5Kl87HY/LU2toy2NWRJSdBzMzM7OOVJWmSTMzM7OO40DMzMzMrCQtFYhJmibpEUkrJM3pZ/l2km7Iy++SNKmEbNatjuM5UdIvJN2ff/6qjHwOh6R5ktZKenCA5ZJ0aT7mByTt3+w89pOntilX7VamXJ7K5fLk8lSGdit3Q4qIlvghdWr8CfD7wLbAj4Apfdb5GHBFfj0DuKHsfI/yeE4EPl92Xod5XO8A9gceHGD5kcA3AQEHA3e1wPfQEuWqHcuUy1Plj8XlqfzvoCXKU4OPuaXK3VA/rVQjtnlaiIj4NVCbFqJoOjA/v74JOFSSmpjH4ajneFpORNwJrBtklenANZEsAXaWNL45uetXO5WrtitTLk+lcnlyeSpD25W7obRSINbftBATBlonIjYBG4DdmpK74avneAD+IleR3yRpYj/LW029x90s7VSuOrFMuTyNHZcnl6cydFy5a6VArBP9FzApIv4IWMwrdz1mI+UyZY3k8mRlaKty10qBWD3TQmxeR9LWwE7AM03J3fANeTwR8UxEvJTffhE4oEl5G0tVm96jncpVJ5Ypl6ex4/Lk8lSGjit3rRSI1TMtxEJgZn59NPDdyD37KmjI4+nTN+F9wMNNzN9YWQickJ9OOhjYEBFrSsxPO5WrTixTLk9jx+XJ5akMnVfuyn5aYDg/pCda/pf0RMU/5rRzgPfl168GvgqsAO4Gfr/sPI/yeP4VWE56auQO4I1l57mOY7oeWAP8htS2fzLw18Bf5+UCLsvHvAyYWoE8t025arcy5fJU+WNxeSr/O2iZ8tSp5W6oH09xZGZmZlaSVmqaNDMzM2srDsTaWB59+Ptl58PGhqTfk7RR0lZl56UvSSslvbvsfJiZVZ0DMbMWFRE/i4gdIuLlwdZzQG7NIqmn5aebMWsyB2JmJcqPm1daK+TRzKxVORAbA5ImSvp6npT0GUmfl/QHkr6b3z8t6VpJOxc+c7qk1ZKez5OdHprTr5Z0XmG9bkmrCu/nSPpJ/txDkv68qQdrw5ab7U6X9ADwgqS3S/r/JD0r6UeSugvr7i3pzvz9fkfSZZK+kpdNkhS1QCnXfD2W1/2ppOMk/SFwBfC23Iz5bF53O0n/Julnkp6SdIWk7fOybkmrch6fBL4k6VWFsvaMpBsl7VrI5/GSHs/L/rFJf0obQwOcx06U9P1cdtbncnZEXv984E+Az+ey9vlyj8CsNTgQa7DcX+dW4HFgEmlqhgWkx6L/FdgD+EPSgHVn58+8ATgV+OOI2BE4HFhZ5y5/Qjr57QT8C/AVlTs3mtXnWOAo0sS2twDnAbsCfw98TdJr83rXkR5J341UXo7vb2OSxgGXAkfkMvR/gPsj4mHS4/k/yM2YO+ePzAVeD+wH7EMqp/9c2OTv5vzsBcwC/hZ4P/CnpDK8nvSYP5KmAJfnvO2R87rnCP4mVhGDnMcADgIeAXYH/h9wlSRFxD8C/w2cmsvaqU3PuFkLciDWeAeSLkb/EBEvRMSvIuL7EbEiIhZHxEsR8QvgItJFDeBlYDtgiqRtImJlRPyknp1FxFcj4ucR8duIuAF4NOfBqu3SiHgC+EtgUUQsyt/hYuBe4EhJvwf8MfDPEfHriPg+Ww7mWPRb4M2Sto+INRGxvL+VJIkUXP1dRKyLiOeBz5AGTixu66xcXn9JCub+MSJWRRrR+mzg6FwbdzRwa0TcmZf9U/68ta5+z2N52eMR8YXcN3E+MB7oKiujZq3OgVjjTSSdqDYVEyV1SVqQmx+fA75CuqMkIlYAnyBd3Nbm9faoZ2eSTpB0f27WehZ4c227Vmm1SW33Aj5Q+/7yd/h20sVtD2BdRLzYz+d6iYgXgA+SAqY1kr4h6Y0D7Pu1wO8ASwv7/FZOr/lFRPyq8H4v4ObC+g+TbiC6cj435yvnpZWnWLEBzmPZk7UXhbK5Q1NyZdaGHIg13hPA7/XTwfkzQAD7RsRrSDUhqi2MiOsi4u2kC14AF+RFL5AumjW/W3shaS/gC6Rmzd1ys9ODxe1aZdVGUn4C+HJE7Fz4GRcRc0kjgO8qqfj9T9xiS7UNRtwWEe8hBXE/JpWN4r5qngZ+CbypsM+dIqJ4Me37mSdIzZ7FfL46IlbnfG7OV87vbvX8EayyBjqPDcUjhJsNkwOxxrubdGGaK2mcpFdLOgTYEdgIbJA0AfiH2gckvUHSuyRtB/yKdJGsNe3cT2qm2lXS75JqzmrGkU58v8jbOYlUI2at4yvAn0k6XNJWubx0S9ozIh4nNVOeLWlbSW8D/qy/jeQa1+m5r9hLpLJWK0NPAXsqzdtGRPyWFKRdLOl1+fMTJB0+SD6vAM7PwT+SXitpel52E/De/NDBtqSpSHxuaW0DnceG8hSp36OZ1cknywbL/Sb+jNQB+mek+cw+SOpIvz+wAfgG8PXCx7YjdZ5+mlTt/zrgjLzsy6T5tFYC3wZuKOzrIeBC4AekE+C+wP+MyYHZmMj9xKYDZ5IC6idIQXrtf/M44G2kpr7zSN//S/1s6lXAJ4GfA+tI/Q//Ji/7LmleticlPZ3TTifNTbckN5V/B3jDIFm9hNQ/7duSngeWkDptk/uinUJ6sGANqSP/qgG2Yy1gkPPYUC4h9R1cL+nSMcyiWdvwXJNmLUTSDcCPI+KssvNiZmaj5xoxswqT9MdKY9C9StI0Uu3Zf5acLTMzaxCPmG1Wbb9LasbejdQ89DcR8cNys2RmZo3ipkkzMzOzkrhp0szMzKwkLds0ufvuu8ekSZN6pb3wwguMGzeunAw1QTse39KlS5+OiNcOvebY6sTyVNNOx+ny1FztfkxVKU/W3lo2EJs0aRL33ntvr7Senh66u7vLyVATtOPxSXq87DxAZ5anmnY6Tpen5mr3Y6pKebL25qZJMzMzs5I4EDMzMzMriQMxMzMzs5K0bB+x/ixbvYET53xjyPVWzj2qCbmxVufyZI3k8mRm/XGNmJmZmVlJHIiZmZmZlcSBmJmZmVlJHIiZmZmZlcSBmJmZmVlJHIiZmZmZlcSBmJmZmVlJHIiZmZmZlcSBmJmZmVlJHIiZmZmZlcSBmJmZmVlJHIiZWVuStLOkmyT9WNLDkt4maVdJiyU9mn/vkteVpEslrZD0gKT9C9uZmdd/VNLM8o7IzNqRAzEza1eXAN+KiDcCbwEeBuYAt0fEZOD2/B7gCGBy/pkFXA4gaVfgLOAg4EDgrFrwZmbWCEMGYpLmSVor6cFCWsPuKiUdIGlZ/sylktTogzSzziJpJ+AdwFUAEfHriHgWmA7Mz6vNB96fX08HrolkCbCzpPHA4cDiiFgXEeuBxcC0ph2ImbW9retY52rg88A1hbTaXeVcSXPy+9PpfVd5EOmu8qDCXeVUIIClkhbmE9vlwEeAu4BFpJPcN0d/aGbWwfYGfgF8SdJbgKXAaUBXRKzJ6zwJdOXXE4AnCp9fldMGSt+CpFmk2jS6urro6enptbxre5i976YhM973c1W2cePGlspvPdrxmKzahgzEIuJOSZP6JE8HuvPr+UAPKRDbfFcJLMl9NMbndRdHxDoASYuBaZJ6gNfkO1AkXUO6Q3Ug1oEk7Qx8EXgzKWD/MPAIcAMwCVgJHBMR63PN6SXAkcCLwIkRcV/ezkzg03mz50XEfKzTbA3sD/xtRNwl6RJeaYYEICJCUjRqhxFxJXAlwNSpU6O7u7vX8s9dewsXLhv63nflcd1DrlMVPT099D3OVteOx2TVVk+NWH8adVc5Ib/um96vTrzjLOqAO7Van56jJW0L/A5wJo2rfbXOsQpYFRF35fc3kcrOU5LGR8SafJO4Ni9fDUwsfH7PnLaaV246a+k9Y5hvM+swIw3ENmv0XeUQ++q4O86idr5TK/TpORFSnx7g15IaUvsKXN+sY7HyRcSTkp6Q9IaIeAQ4FHgo/8wE5ubft+SPLAROlbSAFNhvyMHabcBnCh30DwPOaOaxmFl7G2kg1qi7ytX5dd/1rfO4T09J2rim9W+Ba3Pt6mPASaQHlG6UdDLwOHBMXncRqZl7Bamp+ySAiFgn6VzgnrzeObUg38ysEUYaiC2kAXeV+ST3nKSDSZ31TwA+N8I8WWtzn56StGtNa0TcT2qi7uvQftYN4JQBtjMPmNfQzJmZZfUMX3E98APgDZJW5TvJucB7JD0KvDu/h3RX+RjprvILwMcg3VUCtbvKe+h9V/kxUgftFcBPcEf9TtVfn579ybWvAMOofe0v3czMrHLqeWry2AEWNeSuMiLuJT0lZx3MfXrMzKwTjbqzvlkDuU+PmZl1FAdiVhnu02NmZp3Gc02amZmZlcSBmJmZmVlJHIiZmZmZlcSBmJmZmVlJHIiZmZmZlcSBmJmZmVlJHIiZmZmZlcSBmJmZmVlJHIiZmZmZlcSBmJmZmVlJHIiZmZmZlWTEgZikN0i6v/DznKRPSDpb0upC+pGFz5whaYWkRyQdXkifltNWSJoz2oMyMzMzawUjnvQ7Ih4B9gOQtBWwGrgZOAm4OCL+rbi+pCnADOBNwB7AdyS9Pi++DHgPsAq4R9LCiHhopHkzMzMzawUjDsT6OBT4SUQ8LmmgdaYDCyLiJeCnklYAB+ZlKyLiMQBJC/K6DsTMzMysrTUqEJsBXF94f6qkE4B7gdkRsR6YACwprLMqpwE80Sf9oP52ImkWMAugq6uLnp6eXsu7tofZ+24aMrN9P9cqNm7c2LJ5NzMzsy2NOhCTtC3wPuCMnHQ5cC4Q+feFwIdHux+AiLgSuBJg6tSp0d3d3Wv55669hQuXDX1IK4/rHnKdKurp6aHvMZuZmVnrakSN2BHAfRHxFEDtN4CkLwC35rergYmFz+2Z0xgk3czMzKxtNWL4imMpNEtKGl9Y9ufAg/n1QmCGpO0k7Q1MBu4G7gEmS9o7167NyOuamY2KpK0k/VDSrfn93pLuyk9o35DPOeTz0g05/S5Jkwrb6PdpbzOzRhhVICZpHOlpx68Xkv+fpGWSHgDeCfwdQEQsB24kdcL/FnBKRLwcEZuAU4HbgIeBG/O6ZmajdRrpvFJzAemp7n2A9cDJOf1kYH1Ovziv1/dp72nAv+enxM3MGmJUTZMR8QKwW5+04wdZ/3zg/H7SFwGLRpMXs7JMmvONutddOfeoMcyJFUnaEziKdM75pNIj3e8CPpRXmQ+cTerXOj2/BrgJ+Hxef6CnvX/QpMMwszbXqKcmzRoi1zbcC6yOiPfmZuwFpIB/KXB8RPxa0nbANcABwDPAByNiZd7GGaQajpeBj0fEbc0/EquAzwKfAnbM73cDns218ND7ye0J5Ke3I2KTpA15/cGe9u6lE5/qbscnudvxmKzaHIhZ1dSakl6T39eakhZIuoIUYF1OoSlJ0oy83gcHGjg4Il5u9oFYeSS9F1gbEUsldTdjn534VHc7Psndjsdk1ea5Jq0yCk1JX8zva01JN+VV5gPvz6+n5/fk5Yf2bUqKiJ8CxYGDrXMcArxP0kpSjeq7gEuAnSXVoqHiE9qbn+rOy3ci1bQO9rS3mdmouUbMquSztGBT0nBUscmjHZtiIuIM8tiGuUbs7yPiOElfBY4mBWczgVvyRxbm9z/Iy78bESFpIXCdpItINay1p73NzBrCgZhVQis3JQ1HFZudOqwp5nRggaTzgB8CV+X0q4Av587460jN20TEckm1p703kZ/2bn62zaxdORCzqqg1JR0JvJrUR2xzU1KuFeuvKWmVm5JsMBHRA/Tk14/RT1N1RPwK+MAAn+/3ae+x4qdwzTqL+4hZJUTEGRGxZ0RMItVGfDcijgPuIDUVQf9NSVBoSmLggYPNzMwqxzViVnVuSjIzs7blQMwqp9WakszMzEbKTZNmZmZmJXEgZmZmZlYSB2JmZmZmJXEgZmZmZlaSUQViklZKWibpfkn35rRdJS2W9Gj+vUtOl6RLJa2Q9ICk/QvbmZnXf1TSzIH2Z2ZmZtZOGlEj9s6I2C8ipub3c4DbI2IycHt+D3AEaUynyaRpZS6HFLgBZwEHkZ6OO6sWvJmZmZm1s7FomixOxtx3kuZrIllCGjF9PHA4sDgi1kXEemAxMG0M8mVmZmZWKaMdRyyAb0sK4D/y3H1dEbEmL38S6MqvN0/SnNUmYx4ofQuNmqS5VSc4bsfJmc3MzDrZaAOxt0fEakmvAxZL+nFxYUREDtIaolGTNFdx4uV6dNjkzGZmZm1vVE2TEbE6/14L3Ezq4/VUbnIk/16bVx9oMmZP0mxmZmYdacSBmKRxknasvQYOAx6k92TMfSdpPiE/PXkwsCE3Yd4GHCZpl9xJ/7CcZmZmZtbWRtM02QXcLKm2nesi4luS7gFulHQy8DhwTF5/EXAksAJ4ETgJICLWSToXuCevd05ErBtFvszMzMxawogDsTwZ81v6SX8GOLSf9ABOGWBb84B5I82LWauYNOcbda23cu5RY5wTawcuT2atzyPrm5mZmZXEgZiZmZlZSRyImZmZmZXEgZiZmZlZSRyImZmZmZXEgZiZtR1JEyXdIekhScslnZbTd5W0WNKj+fcuOV2SLpW0QtIDkvYvbGtmXv9RSTMH2qeZ2Ug4EDOzdrQJmB0RU4CDgVMkTQHmALdHxGTg9vwe4Ahgcv6ZBVwOKXADzgIOIs0cclYteDMzawQHYlYJrsGwRoqINRFxX379PPAwMAGYDszPq80H3p9fTweuiWQJsHOeou1wYHFErIuI9cBiYFrzjsTM2t1oJ/02a5RaDcZ9eeqspZIWAyeSajDmSppDqsE4nd41GAeRajAOKtRgTAUib2dhvohaB5I0CXgrcBfQladWA3iSNEMIpCDticLHVuW0gdL7288sUm0aXV1d9PT09FretT3M3nfTKI5k5PrmpVE2btw4ZtsuSzsek1WbAzGrhHxxXJNfPy+pWIPRnVebD/SQArHNNRjAEkm1Goxucg0GQA7mpgHXN+1grDIk7QB8DfhERDyXp2QD0mwfkqJR+4qIK4ErAaZOnRrd3d29ln/u2lu4cFk5p9yVx3UPuc5I9PT00Pc4W107HpNVmwMxqxzXYIxdDUZ/2rUGQNI2pCDs2oj4ek5+StL4iFiTA/e1OX01MLHw8T1z2mpeuRGopfeMZb7NrLM4ELNKcQ1GMlY1GP1pxxoApYJzFfBwRFxUWLQQmAnMzb9vKaSfKmkBqal7Qw7WbgM+U+igfxhwRjOOwcw6Q0cGYvVOlAueLLeZXINhDXQIcDywTNL9Oe1MUgB2o6STgceBY/KyRcCRwArgReAkgIhYJ+lc4J683jm1Zm8zs0boyEDMqsc1GNZIEfF9QAMsPrSf9QM4ZYBtzQPmNS53ZmavGHEgJmkicA2pz04AV0bEJZLOBj4C/CKvemZELMqfOQM4GXgZ+HhE3JbTpwGXAFsBX4yIuSPNl7Us12CYjZF6WwHcAmDWfKOpERtouAGAiyPi34or58EUZwBvAvYAviPp9XnxZcB7SB2r78nDDTw0irxZi3ENhpmZdaIRB2KDDDcwkOnAgoh4CfippBWkkaoBVkTEYwC5qWk64EDMzMzM2lpD+oj1GW7gEFLfnROAe0m1ZutJQdqSwseKwwr0HW7goAH20/ThBqr0WH+7DjNgZmbWqUYdiPUz3MDlwLmkfmPnAhcCHx7tfqCc4QaaOYzAUNpxmAEzM7NONqqopb/hBiLiqcLyLwC35rcDDTfAIOlmHcmdq83MOsOIJ/0eaLiBPNZTzZ8DD+bXC4EZkraTtDdpjsC7SU+3TZa0t6RtSR36F440X2ZmZmatYjQ1YgMNN3CspP1ITZMrgY8CRMRySTeSOuFvAk6JiJcBJJ0K3EYavmJeRCwfRb7MzMzMWsJonpocaLiBRYN85nzg/H7SFw32OTMzM7N2NOKmSTMzMzMbHU9xZGZmgOfhNSuDa8TMzMzMSuJAzMzMzKwkDsTMzMzMSuI+YkPwwJpWZe7TY2bW2hyImZnZsE2a8w1m77uJE4e4GfANgNng3DRpZmZmVhIHYmZmZmYlcdOkWYcYqD9Z3+YlNyWZmTWPAzEzMxszfuDJbHAOxBrEJxszMzMbLvcRMzMzMytJZWrEJE0DLgG2Ar4YEXNLztKY8LhPzdEp5WksDKeM1qvVy7LL09jzudE6VSUCMUlbAZcB7wFWAfdIWhgRD5Wbs3L1PTHVM2bPYDrl5OXyVD2t3HTv8lQ9rVyezPqqRCAGHAisiIjHACQtAKYDPtE1UAfdcbo8taiKXmBdnlpURcuTWS9VCcQmAE8U3q8CDuq7kqRZwKz8dqOkR/qssjvw9JjksAI+3sTj0wXN2AsAe43BNl2ehqGZ5apRBimfLk9N1Iplpz99ylPxmMaiPJn1UpVArC4RcSVw5UDLJd0bEVObmKWmavfja7ZOL081nXKcY60Ty5OPyWz0qvLU5GpgYuH9njnNbCRcnqyRXJ7MbMxUJRC7B5gsaW9J2wIzgIUl58lal8uTNZLLk5mNmUo0TUbEJkmnAreRHg+fFxHLR7CpAZsF2kS7H19DuDwNW6cc54i4PA3Kx2Q2SoqIsvNgZmZm1pGq0jRpZmZm1nEciJmZmZmVpC0CMUnTJD0iaYWkOWXnZ6QkTZR0h6SHJC2XdFpO31XSYkmP5t+75HRJujQf9wOS9i/3CNpDu5SnIkkrJS2TdL+ke3Oay1UTtHJ5aodyI2mepLWSHiykDfsYJM3M6z8qaWYZx2LtqeUDscL0I0cAU4BjJU0pN1cjtgmYHRFTgIOBU/KxzAFuj4jJwO35PaRjnpx/ZgGXNz/L7aXNylNf74yI/QpjJLlcjbE2KU+tXm6uBqb1SRvWMUjaFTiLNJDvgcBZteDNbLRaPhCjMP1IRPwaqE0/0nIiYk1E3JdfPw88TBrVezowP682H3h/fj0duCaSJcDOksY3N9dtp23KUx1crsZeO5anlio3EXEnsK5P8nCP4XBgcUSsi4j1wGK2DO7MRqQdArH+ph+ZUFJeGkbSJOCtwF1AV0SsyYueBLry67Y89pK16980gG9LWpqn4gGXq2Zo9b9lu5ab4R5DKx2btZhKjCNmvUnaAfga8ImIeE7S5mUREZI85ogN19sjYrWk1wGLJf24uNDlygbQ9uWmHY7BWls71Ii11fQjkrYhBWHXRsTXc/JTtSr+/HttTm+rY6+ItvybRsTq/HstcDOpyczlauy19N+yjcvNcI+hlY7NWkw7BGJtM/2IUtXXVcDDEXFRYdFCoPaUzkzglkL6CflJn4OBDYXqdhuZtilPNZLGSdqx9ho4DHgQl6tmaNny1OblZrjHcBtwmKRdcif9w3Ka2ai1fNNkA6cfqYJDgOOBZZLuz2lnAnOBGyWdDDwOHJOXLQKOBFYALwInNTW3bajNylNNF3BzbuLeGrguIr4l6R5crsZUi5entig3kq4HuoHdJa0iPf04rHNqRKyTdC4psAY4JyL6PgBgNiKe4sjMzMysJO3QNGlmZmbWkhyImZmZmZXEgZiZmZlZSRyImZmZmZXEgZiZmZlZSRyImZmZmZXEgZiZmZlZSf7/xdryi/js2qoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bike.hist(figsize=(10,10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_datamodel = Sequential([\n",
    "    layers.Dense(128, activation='sigmoid', input_shape=(14,)),\n",
    "    layers.Dense(32, activation='sigmoid'),\n",
    "    layers.Dense(8, activation='sigmoid'),\n",
    "    layers.Dense(1, 'linear')\n",
    "])\n",
    "\n",
    "fp_datamodel.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MeanSquaredError(\n",
    "    ),\n",
    ")\n",
    "\n",
    "history = defaultdict(list)\n",
    "\n",
    "x = bike.drop('cnt',axis=1).to_numpy()\n",
    "y = bike['cnt'].to_numpy()\n",
    "p = np.random.permutation(y.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 25.2885 - val_loss: 15.4568\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25.2652 - val_loss: 15.4149\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25.2444 - val_loss: 15.3564\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25.0866 - val_loss: 15.2600\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 25.0133 - val_loss: 15.2100\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.9435 - val_loss: 15.1501\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.8711 - val_loss: 15.1280\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.8091 - val_loss: 15.0073\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.7156 - val_loss: 14.9261\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.6424 - val_loss: 14.8784\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.5877 - val_loss: 14.7939\n",
      "Epoch 12/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 24.5453 - val_loss: 14.7940\n",
      "Epoch 13/500\n",
      "22/22 [==============================] - 0s 978us/step - loss: 24.4635 - val_loss: 14.6776\n",
      "Epoch 14/500\n",
      "22/22 [==============================] - 0s 950us/step - loss: 24.3614 - val_loss: 14.6578\n",
      "Epoch 15/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.3152 - val_loss: 14.5256\n",
      "Epoch 16/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 24.2166 - val_loss: 14.4676\n",
      "Epoch 17/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 24.1530 - val_loss: 14.4246\n",
      "Epoch 18/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 24.0899 - val_loss: 14.3555\n",
      "Epoch 19/500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 24.0386 - val_loss: 14.3101\n",
      "Epoch 20/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.9799 - val_loss: 14.2498\n",
      "Epoch 21/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.9421 - val_loss: 14.1767\n",
      "Epoch 22/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 23.8314 - val_loss: 14.1177\n",
      "Epoch 23/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.7830 - val_loss: 14.1089\n",
      "Epoch 24/500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 23.7228 - val_loss: 14.0024\n",
      "Epoch 25/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 23.6449 - val_loss: 13.9636\n",
      "Epoch 26/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 23.5814 - val_loss: 13.8810\n",
      "Epoch 27/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 23.5088 - val_loss: 13.8260\n",
      "Epoch 28/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.4411 - val_loss: 13.7863\n",
      "Epoch 29/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.3828 - val_loss: 13.7099\n",
      "Epoch 30/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 23.3082 - val_loss: 13.6434\n",
      "Epoch 31/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.2435 - val_loss: 13.5753\n",
      "Epoch 32/500\n",
      "22/22 [==============================] - 0s 966us/step - loss: 23.1774 - val_loss: 13.5242\n",
      "Epoch 33/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 23.1143 - val_loss: 13.4587\n",
      "Epoch 34/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 23.0641 - val_loss: 13.3972\n",
      "Epoch 35/500\n",
      "22/22 [==============================] - 0s 1000us/step - loss: 22.9812 - val_loss: 13.3365\n",
      "Epoch 36/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.9196 - val_loss: 13.2855\n",
      "Epoch 37/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.8560 - val_loss: 13.2253\n",
      "Epoch 38/500\n",
      "22/22 [==============================] - 0s 984us/step - loss: 22.8113 - val_loss: 13.1792\n",
      "Epoch 39/500\n",
      "22/22 [==============================] - 0s 999us/step - loss: 22.7387 - val_loss: 13.1132\n",
      "Epoch 40/500\n",
      "22/22 [==============================] - 0s 997us/step - loss: 22.6699 - val_loss: 13.0719\n",
      "Epoch 41/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.6171 - val_loss: 13.0058\n",
      "Epoch 42/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.5577 - val_loss: 12.9418\n",
      "Epoch 43/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.4942 - val_loss: 12.8930\n",
      "Epoch 44/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.4320 - val_loss: 12.8621\n",
      "Epoch 45/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.3585 - val_loss: 12.7746\n",
      "Epoch 46/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.2760 - val_loss: 12.7016\n",
      "Epoch 47/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 22.2312 - val_loss: 12.7326\n",
      "Epoch 48/500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 22.2373 - val_loss: 12.6367\n",
      "Epoch 49/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 22.1264 - val_loss: 12.5441\n",
      "Epoch 50/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 22.0315 - val_loss: 12.4742\n",
      "Epoch 51/500\n",
      "22/22 [==============================] - 0s 960us/step - loss: 21.9732 - val_loss: 12.4338\n",
      "Epoch 52/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.9130 - val_loss: 12.3737\n",
      "Epoch 53/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.8571 - val_loss: 12.3242\n",
      "Epoch 54/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.7992 - val_loss: 12.2735\n",
      "Epoch 55/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.7469 - val_loss: 12.2114\n",
      "Epoch 56/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.6948 - val_loss: 12.2503\n",
      "Epoch 57/500\n",
      "22/22 [==============================] - 0s 987us/step - loss: 21.6740 - val_loss: 12.1865\n",
      "Epoch 58/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.6124 - val_loss: 12.0758\n",
      "Epoch 59/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.5462 - val_loss: 12.5328\n",
      "Epoch 60/500\n",
      "22/22 [==============================] - 0s 983us/step - loss: 21.5732 - val_loss: 11.9547\n",
      "Epoch 61/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.3805 - val_loss: 11.8809\n",
      "Epoch 62/500\n",
      "22/22 [==============================] - 0s 944us/step - loss: 21.3116 - val_loss: 11.8258\n",
      "Epoch 63/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 21.2636 - val_loss: 11.7741\n",
      "Epoch 64/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 21.1900 - val_loss: 11.7163\n",
      "Epoch 65/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.1318 - val_loss: 11.6793\n",
      "Epoch 66/500\n",
      "22/22 [==============================] - 0s 999us/step - loss: 21.0672 - val_loss: 11.6038\n",
      "Epoch 67/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 21.0152 - val_loss: 11.5569\n",
      "Epoch 68/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 20.9608 - val_loss: 11.5827\n",
      "Epoch 69/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.9082 - val_loss: 11.4901\n",
      "Epoch 70/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.8399 - val_loss: 11.3991\n",
      "Epoch 71/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.7772 - val_loss: 11.3526\n",
      "Epoch 72/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.7169 - val_loss: 11.2921\n",
      "Epoch 73/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.6741 - val_loss: 11.2613\n",
      "Epoch 74/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.6183 - val_loss: 11.2126\n",
      "Epoch 75/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.5570 - val_loss: 11.1557\n",
      "Epoch 76/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.5059 - val_loss: 11.1183\n",
      "Epoch 77/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.4989 - val_loss: 11.0647\n",
      "Epoch 78/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.4209 - val_loss: 11.0793\n",
      "Epoch 79/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.3551 - val_loss: 10.9709\n",
      "Epoch 80/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.2828 - val_loss: 10.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.2328 - val_loss: 10.8434\n",
      "Epoch 82/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.1494 - val_loss: 10.7737\n",
      "Epoch 83/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.0954 - val_loss: 10.7392\n",
      "Epoch 84/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 20.0408 - val_loss: 10.6832\n",
      "Epoch 85/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.9931 - val_loss: 10.6493\n",
      "Epoch 86/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.9393 - val_loss: 10.5699\n",
      "Epoch 87/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.8980 - val_loss: 10.5362\n",
      "Epoch 88/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.8242 - val_loss: 10.4991\n",
      "Epoch 89/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.7625 - val_loss: 10.4341\n",
      "Epoch 90/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.7120 - val_loss: 10.3786\n",
      "Epoch 91/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.6569 - val_loss: 10.3559\n",
      "Epoch 92/500\n",
      "22/22 [==============================] - 0s 971us/step - loss: 19.6479 - val_loss: 10.2803\n",
      "Epoch 93/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 19.5773 - val_loss: 10.2334\n",
      "Epoch 94/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 19.5190 - val_loss: 10.1949\n",
      "Epoch 95/500\n",
      "22/22 [==============================] - 0s 999us/step - loss: 19.4358 - val_loss: 10.1895\n",
      "Epoch 96/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.4239 - val_loss: 10.2070\n",
      "Epoch 97/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.4027 - val_loss: 10.0617\n",
      "Epoch 98/500\n",
      "22/22 [==============================] - 0s 964us/step - loss: 19.3031 - val_loss: 10.0945\n",
      "Epoch 99/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 19.2514 - val_loss: 9.9402\n",
      "Epoch 100/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 19.1719 - val_loss: 9.8893\n",
      "Epoch 101/500\n",
      "22/22 [==============================] - 0s 961us/step - loss: 19.1123 - val_loss: 9.8472\n",
      "Epoch 102/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 19.0657 - val_loss: 9.8218\n",
      "Epoch 103/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 19.0103 - val_loss: 9.7609\n",
      "Epoch 104/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.9604 - val_loss: 9.7065\n",
      "Epoch 105/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.9028 - val_loss: 9.6622\n",
      "Epoch 106/500\n",
      "22/22 [==============================] - 0s 997us/step - loss: 18.8531 - val_loss: 9.6132\n",
      "Epoch 107/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.8100 - val_loss: 9.5548\n",
      "Epoch 108/500\n",
      "22/22 [==============================] - 0s 966us/step - loss: 18.7531 - val_loss: 9.5086\n",
      "Epoch 109/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.7011 - val_loss: 9.4700\n",
      "Epoch 110/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.6519 - val_loss: 9.4280\n",
      "Epoch 111/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.6026 - val_loss: 9.3835\n",
      "Epoch 112/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.5485 - val_loss: 9.3544\n",
      "Epoch 113/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.4933 - val_loss: 9.2787\n",
      "Epoch 114/500\n",
      "22/22 [==============================] - 0s 959us/step - loss: 18.4346 - val_loss: 9.2429\n",
      "Epoch 115/500\n",
      "22/22 [==============================] - 0s 974us/step - loss: 18.4057 - val_loss: 9.1686\n",
      "Epoch 116/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.3465 - val_loss: 9.1347\n",
      "Epoch 117/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.2991 - val_loss: 9.0913\n",
      "Epoch 118/500\n",
      "22/22 [==============================] - 0s 963us/step - loss: 18.2398 - val_loss: 9.0995\n",
      "Epoch 119/500\n",
      "22/22 [==============================] - 0s 970us/step - loss: 18.2359 - val_loss: 9.1662\n",
      "Epoch 120/500\n",
      "22/22 [==============================] - 0s 993us/step - loss: 18.1830 - val_loss: 8.9665\n",
      "Epoch 121/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 18.1077 - val_loss: 8.9503\n",
      "Epoch 122/500\n",
      "22/22 [==============================] - 0s 964us/step - loss: 18.0429 - val_loss: 8.8652\n",
      "Epoch 123/500\n",
      "22/22 [==============================] - 0s 970us/step - loss: 17.9923 - val_loss: 8.8208\n",
      "Epoch 124/500\n",
      "22/22 [==============================] - 0s 997us/step - loss: 17.9384 - val_loss: 8.8112\n",
      "Epoch 125/500\n",
      "22/22 [==============================] - 0s 956us/step - loss: 17.9385 - val_loss: 9.1002\n",
      "Epoch 126/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 18.0925 - val_loss: 8.9735\n",
      "Epoch 127/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.9405 - val_loss: 8.6757\n",
      "Epoch 128/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 17.7774 - val_loss: 8.6348\n",
      "Epoch 129/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.7074 - val_loss: 8.5811\n",
      "Epoch 130/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 17.6561 - val_loss: 8.5350\n",
      "Epoch 131/500\n",
      "22/22 [==============================] - 0s 989us/step - loss: 17.6108 - val_loss: 8.4902\n",
      "Epoch 132/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.5573 - val_loss: 8.4456\n",
      "Epoch 133/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.5280 - val_loss: 8.4123\n",
      "Epoch 134/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.4847 - val_loss: 8.3566\n",
      "Epoch 135/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.4303 - val_loss: 8.3259\n",
      "Epoch 136/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.3948 - val_loss: 8.3052\n",
      "Epoch 137/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.3482 - val_loss: 8.2273\n",
      "Epoch 138/500\n",
      "22/22 [==============================] - 0s 962us/step - loss: 17.3165 - val_loss: 8.2361\n",
      "Epoch 139/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.2916 - val_loss: 8.1722\n",
      "Epoch 140/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.2266 - val_loss: 8.1855\n",
      "Epoch 141/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 17.2076 - val_loss: 8.0932\n",
      "Epoch 142/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.1333 - val_loss: 8.0742\n",
      "Epoch 143/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.0886 - val_loss: 7.9908\n",
      "Epoch 144/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.0376 - val_loss: 7.9489\n",
      "Epoch 145/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 17.0018 - val_loss: 7.9136\n",
      "Epoch 146/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.9535 - val_loss: 7.9140\n",
      "Epoch 147/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 16.9206 - val_loss: 7.9057\n",
      "Epoch 148/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 16.8831 - val_loss: 7.8193\n",
      "Epoch 149/500\n",
      "22/22 [==============================] - 0s 974us/step - loss: 16.8220 - val_loss: 7.8165\n",
      "Epoch 150/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.8055 - val_loss: 7.7634\n",
      "Epoch 151/500\n",
      "22/22 [==============================] - 0s 986us/step - loss: 16.7659 - val_loss: 7.6939\n",
      "Epoch 152/500\n",
      "22/22 [==============================] - 0s 986us/step - loss: 16.7070 - val_loss: 7.6661\n",
      "Epoch 153/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.6583 - val_loss: 7.6333\n",
      "Epoch 154/500\n",
      "22/22 [==============================] - 0s 950us/step - loss: 16.6143 - val_loss: 7.5634\n",
      "Epoch 155/500\n",
      "22/22 [==============================] - 0s 971us/step - loss: 16.5778 - val_loss: 7.5588\n",
      "Epoch 156/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.5294 - val_loss: 7.4981\n",
      "Epoch 157/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.4892 - val_loss: 7.4744\n",
      "Epoch 158/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.4454 - val_loss: 7.4021\n",
      "Epoch 159/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.3979 - val_loss: 7.3737\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step - loss: 16.3608 - val_loss: 7.3800\n",
      "Epoch 161/500\n",
      "22/22 [==============================] - 0s 993us/step - loss: 16.3441 - val_loss: 7.3292\n",
      "Epoch 162/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.2986 - val_loss: 7.2714\n",
      "Epoch 163/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.2408 - val_loss: 7.2551\n",
      "Epoch 164/500\n",
      "22/22 [==============================] - 0s 968us/step - loss: 16.1968 - val_loss: 7.2045\n",
      "Epoch 165/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.1596 - val_loss: 7.1560\n",
      "Epoch 166/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.1456 - val_loss: 7.1503\n",
      "Epoch 167/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 16.0936 - val_loss: 7.0809\n",
      "Epoch 168/500\n",
      "22/22 [==============================] - 0s 993us/step - loss: 16.0482 - val_loss: 7.0819\n",
      "Epoch 169/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 16.0094 - val_loss: 7.0670\n",
      "Epoch 170/500\n",
      "22/22 [==============================] - 0s 984us/step - loss: 15.9874 - val_loss: 6.9868\n",
      "Epoch 171/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.9288 - val_loss: 6.9424\n",
      "Epoch 172/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 15.8932 - val_loss: 6.9416\n",
      "Epoch 173/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 15.8548 - val_loss: 6.8762\n",
      "Epoch 174/500\n",
      "22/22 [==============================] - 0s 993us/step - loss: 15.8123 - val_loss: 6.8457\n",
      "Epoch 175/500\n",
      "22/22 [==============================] - 0s 1000us/step - loss: 15.7698 - val_loss: 6.8160\n",
      "Epoch 176/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.7277 - val_loss: 6.8063\n",
      "Epoch 177/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.7257 - val_loss: 6.7631\n",
      "Epoch 178/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.6571 - val_loss: 6.7122\n",
      "Epoch 179/500\n",
      "22/22 [==============================] - 0s 963us/step - loss: 15.6237 - val_loss: 6.6778\n",
      "Epoch 180/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 15.5811 - val_loss: 6.6445\n",
      "Epoch 181/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.5506 - val_loss: 6.6717\n",
      "Epoch 182/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 15.5090 - val_loss: 6.5609\n",
      "Epoch 183/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.4675 - val_loss: 6.5274\n",
      "Epoch 184/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.4260 - val_loss: 6.4890\n",
      "Epoch 185/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 15.3881 - val_loss: 6.4664\n",
      "Epoch 186/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 15.3619 - val_loss: 6.4367\n",
      "Epoch 187/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 15.3134 - val_loss: 6.4079\n",
      "Epoch 188/500\n",
      "22/22 [==============================] - 0s 952us/step - loss: 15.2899 - val_loss: 6.4111\n",
      "Epoch 189/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.2445 - val_loss: 6.3254\n",
      "Epoch 190/500\n",
      "22/22 [==============================] - 0s 980us/step - loss: 15.1913 - val_loss: 6.2879\n",
      "Epoch 191/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 15.1661 - val_loss: 6.2433\n",
      "Epoch 192/500\n",
      "22/22 [==============================] - 0s 962us/step - loss: 15.1261 - val_loss: 6.2353\n",
      "Epoch 193/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 15.1535 - val_loss: 6.2231\n",
      "Epoch 194/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.0854 - val_loss: 6.1785\n",
      "Epoch 195/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 15.0318 - val_loss: 6.1204\n",
      "Epoch 196/500\n",
      "22/22 [==============================] - 0s 977us/step - loss: 15.0030 - val_loss: 6.1017\n",
      "Epoch 197/500\n",
      "22/22 [==============================] - 0s 970us/step - loss: 14.9593 - val_loss: 6.0536\n",
      "Epoch 198/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.9102 - val_loss: 6.0214\n",
      "Epoch 199/500\n",
      "22/22 [==============================] - 0s 959us/step - loss: 14.8723 - val_loss: 6.0048\n",
      "Epoch 200/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 14.8395 - val_loss: 5.9675\n",
      "Epoch 201/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.7975 - val_loss: 5.9101\n",
      "Epoch 202/500\n",
      "22/22 [==============================] - 0s 997us/step - loss: 14.7635 - val_loss: 5.9325\n",
      "Epoch 203/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.7418 - val_loss: 5.8605\n",
      "Epoch 204/500\n",
      "22/22 [==============================] - 0s 992us/step - loss: 14.7059 - val_loss: 5.8501\n",
      "Epoch 205/500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 14.6689 - val_loss: 5.7901\n",
      "Epoch 206/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 14.6244 - val_loss: 5.7671\n",
      "Epoch 207/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.5894 - val_loss: 5.7267\n",
      "Epoch 208/500\n",
      "22/22 [==============================] - 0s 972us/step - loss: 14.5482 - val_loss: 5.7224\n",
      "Epoch 209/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.5252 - val_loss: 5.6846\n",
      "Epoch 210/500\n",
      "22/22 [==============================] - 0s 974us/step - loss: 14.4810 - val_loss: 5.6415\n",
      "Epoch 211/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.4452 - val_loss: 5.6246\n",
      "Epoch 212/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.4302 - val_loss: 5.7387\n",
      "Epoch 213/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 14.5015 - val_loss: 5.6119\n",
      "Epoch 214/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 14.4016 - val_loss: 5.5480\n",
      "Epoch 215/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.3374 - val_loss: 5.4956\n",
      "Epoch 216/500\n",
      "22/22 [==============================] - 0s 983us/step - loss: 14.2933 - val_loss: 5.4495\n",
      "Epoch 217/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.2381 - val_loss: 5.4167\n",
      "Epoch 218/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.1995 - val_loss: 5.3863\n",
      "Epoch 219/500\n",
      "22/22 [==============================] - 0s 986us/step - loss: 14.1703 - val_loss: 5.3619\n",
      "Epoch 220/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.1356 - val_loss: 5.3279\n",
      "Epoch 221/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.1039 - val_loss: 5.3100\n",
      "Epoch 222/500\n",
      "22/22 [==============================] - 0s 963us/step - loss: 14.0655 - val_loss: 5.2864\n",
      "Epoch 223/500\n",
      "22/22 [==============================] - 0s 979us/step - loss: 14.0406 - val_loss: 5.2654\n",
      "Epoch 224/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.0429 - val_loss: 5.2245\n",
      "Epoch 225/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.0598 - val_loss: 5.4172\n",
      "Epoch 226/500\n",
      "22/22 [==============================] - 0s 960us/step - loss: 14.3064 - val_loss: 5.3991\n",
      "Epoch 227/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 14.0488 - val_loss: 5.1922\n",
      "Epoch 228/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.9034 - val_loss: 5.0972\n",
      "Epoch 229/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.8366 - val_loss: 5.0686\n",
      "Epoch 230/500\n",
      "22/22 [==============================] - 0s 947us/step - loss: 13.8039 - val_loss: 5.0385\n",
      "Epoch 231/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.7652 - val_loss: 5.0112\n",
      "Epoch 232/500\n",
      "22/22 [==============================] - 0s 984us/step - loss: 13.7370 - val_loss: 4.9915\n",
      "Epoch 233/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.7078 - val_loss: 4.9544\n",
      "Epoch 234/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.6721 - val_loss: 4.9308\n",
      "Epoch 235/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.6397 - val_loss: 4.9235\n",
      "Epoch 236/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 13.6295 - val_loss: 4.8772\n",
      "Epoch 237/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 13.5900 - val_loss: 4.8440\n",
      "Epoch 238/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.5458 - val_loss: 4.8155\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step - loss: 13.5154 - val_loss: 4.8137\n",
      "Epoch 240/500\n",
      "22/22 [==============================] - 0s 952us/step - loss: 13.4843 - val_loss: 4.7624\n",
      "Epoch 241/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.4484 - val_loss: 4.7349\n",
      "Epoch 242/500\n",
      "22/22 [==============================] - 0s 989us/step - loss: 13.4211 - val_loss: 4.7231\n",
      "Epoch 243/500\n",
      "22/22 [==============================] - 0s 977us/step - loss: 13.3887 - val_loss: 4.6927\n",
      "Epoch 244/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 13.3606 - val_loss: 4.6585\n",
      "Epoch 245/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 13.3415 - val_loss: 4.6505\n",
      "Epoch 246/500\n",
      "22/22 [==============================] - 0s 947us/step - loss: 13.3114 - val_loss: 4.6121\n",
      "Epoch 247/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.2677 - val_loss: 4.5844\n",
      "Epoch 248/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.2365 - val_loss: 4.5472\n",
      "Epoch 249/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.2163 - val_loss: 4.5354\n",
      "Epoch 250/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.1714 - val_loss: 4.5002\n",
      "Epoch 251/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.1582 - val_loss: 4.4775\n",
      "Epoch 252/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.1116 - val_loss: 4.4560\n",
      "Epoch 253/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.0960 - val_loss: 4.4271\n",
      "Epoch 254/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.1072 - val_loss: 4.4363\n",
      "Epoch 255/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 13.0581 - val_loss: 4.3975\n",
      "Epoch 256/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.9952 - val_loss: 4.3553\n",
      "Epoch 257/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.9642 - val_loss: 4.3288\n",
      "Epoch 258/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.9214 - val_loss: 4.2975\n",
      "Epoch 259/500\n",
      "22/22 [==============================] - 0s 954us/step - loss: 12.8980 - val_loss: 4.2961\n",
      "Epoch 260/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 12.8712 - val_loss: 4.2375\n",
      "Epoch 261/500\n",
      "22/22 [==============================] - 0s 957us/step - loss: 12.8546 - val_loss: 4.2060\n",
      "Epoch 262/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.7902 - val_loss: 4.1833\n",
      "Epoch 263/500\n",
      "22/22 [==============================] - 0s 977us/step - loss: 12.7594 - val_loss: 4.1592\n",
      "Epoch 264/500\n",
      "22/22 [==============================] - 0s 948us/step - loss: 12.7299 - val_loss: 4.1271\n",
      "Epoch 265/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 12.6996 - val_loss: 4.1134\n",
      "Epoch 266/500\n",
      "22/22 [==============================] - 0s 999us/step - loss: 12.6733 - val_loss: 4.0827\n",
      "Epoch 267/500\n",
      "22/22 [==============================] - 0s 979us/step - loss: 12.6426 - val_loss: 4.0606\n",
      "Epoch 268/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.6120 - val_loss: 4.0468\n",
      "Epoch 269/500\n",
      "22/22 [==============================] - 0s 970us/step - loss: 12.5924 - val_loss: 4.0967\n",
      "Epoch 270/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.6080 - val_loss: 4.0118\n",
      "Epoch 271/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.5435 - val_loss: 3.9799\n",
      "Epoch 272/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 12.5024 - val_loss: 3.9454\n",
      "Epoch 273/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.4651 - val_loss: 3.9242\n",
      "Epoch 274/500\n",
      "22/22 [==============================] - 0s 991us/step - loss: 12.4474 - val_loss: 3.8933\n",
      "Epoch 275/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.4209 - val_loss: 3.8938\n",
      "Epoch 276/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.4554 - val_loss: 3.9325\n",
      "Epoch 277/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.3937 - val_loss: 3.8757\n",
      "Epoch 278/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.3848 - val_loss: 3.9473\n",
      "Epoch 279/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.4618 - val_loss: 3.9108\n",
      "Epoch 280/500\n",
      "22/22 [==============================] - 0s 984us/step - loss: 12.3501 - val_loss: 3.8666\n",
      "Epoch 281/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.2872 - val_loss: 3.7363\n",
      "Epoch 282/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.2249 - val_loss: 3.7583\n",
      "Epoch 283/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.2392 - val_loss: 3.7465\n",
      "Epoch 284/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.1919 - val_loss: 3.6989\n",
      "Epoch 285/500\n",
      "22/22 [==============================] - 0s 978us/step - loss: 12.1254 - val_loss: 3.6391\n",
      "Epoch 286/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.0916 - val_loss: 3.6284\n",
      "Epoch 287/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.0653 - val_loss: 3.5871\n",
      "Epoch 288/500\n",
      "22/22 [==============================] - 0s 955us/step - loss: 12.0265 - val_loss: 3.5742\n",
      "Epoch 289/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 12.0056 - val_loss: 3.5499\n",
      "Epoch 290/500\n",
      "22/22 [==============================] - 0s 979us/step - loss: 11.9752 - val_loss: 3.5187\n",
      "Epoch 291/500\n",
      "22/22 [==============================] - 0s 955us/step - loss: 11.9409 - val_loss: 3.4992\n",
      "Epoch 292/500\n",
      "22/22 [==============================] - 0s 984us/step - loss: 11.9150 - val_loss: 3.4789\n",
      "Epoch 293/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 11.8879 - val_loss: 3.4544\n",
      "Epoch 294/500\n",
      "22/22 [==============================] - 0s 964us/step - loss: 11.8595 - val_loss: 3.4320\n",
      "Epoch 295/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.8347 - val_loss: 3.4148\n",
      "Epoch 296/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.8075 - val_loss: 3.3961\n",
      "Epoch 297/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 11.7806 - val_loss: 3.3713\n",
      "Epoch 298/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.7535 - val_loss: 3.3469\n",
      "Epoch 299/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.7232 - val_loss: 3.3243\n",
      "Epoch 300/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 11.6952 - val_loss: 3.3075\n",
      "Epoch 301/500\n",
      "22/22 [==============================] - 0s 983us/step - loss: 11.6686 - val_loss: 3.2856\n",
      "Epoch 302/500\n",
      "22/22 [==============================] - 0s 970us/step - loss: 11.6417 - val_loss: 3.2750\n",
      "Epoch 303/500\n",
      "22/22 [==============================] - 0s 943us/step - loss: 11.6156 - val_loss: 3.2395\n",
      "Epoch 304/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.5997 - val_loss: 3.2388\n",
      "Epoch 305/500\n",
      "22/22 [==============================] - 0s 979us/step - loss: 11.5641 - val_loss: 3.1990\n",
      "Epoch 306/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.5385 - val_loss: 3.2714\n",
      "Epoch 307/500\n",
      "22/22 [==============================] - 0s 971us/step - loss: 11.5522 - val_loss: 3.1668\n",
      "Epoch 308/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.4786 - val_loss: 3.1473\n",
      "Epoch 309/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.4473 - val_loss: 3.1145\n",
      "Epoch 310/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 11.4175 - val_loss: 3.0855\n",
      "Epoch 311/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.3833 - val_loss: 3.0752\n",
      "Epoch 312/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.3849 - val_loss: 3.0553\n",
      "Epoch 313/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 11.3660 - val_loss: 3.1458\n",
      "Epoch 314/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 11.4388 - val_loss: 3.0303\n",
      "Epoch 315/500\n",
      "22/22 [==============================] - 0s 969us/step - loss: 11.3200 - val_loss: 3.0383\n",
      "Epoch 316/500\n",
      "22/22 [==============================] - 0s 999us/step - loss: 11.2740 - val_loss: 2.9822\n",
      "Epoch 317/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.2340 - val_loss: 2.9871\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 992us/step - loss: 11.2178 - val_loss: 2.9384\n",
      "Epoch 319/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.1809 - val_loss: 2.9175\n",
      "Epoch 320/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.1492 - val_loss: 2.8981\n",
      "Epoch 321/500\n",
      "22/22 [==============================] - 0s 982us/step - loss: 11.1245 - val_loss: 2.8773\n",
      "Epoch 322/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.0975 - val_loss: 2.8562\n",
      "Epoch 323/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.0725 - val_loss: 2.8384\n",
      "Epoch 324/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 11.0456 - val_loss: 2.8170\n",
      "Epoch 325/500\n",
      "22/22 [==============================] - 0s 960us/step - loss: 11.0184 - val_loss: 2.8017\n",
      "Epoch 326/500\n",
      "22/22 [==============================] - 0s 962us/step - loss: 10.9994 - val_loss: 2.7877\n",
      "Epoch 327/500\n",
      "22/22 [==============================] - 0s 964us/step - loss: 10.9719 - val_loss: 2.7642\n",
      "Epoch 328/500\n",
      "22/22 [==============================] - 0s 937us/step - loss: 10.9445 - val_loss: 2.7517\n",
      "Epoch 329/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 10.9245 - val_loss: 2.7262\n",
      "Epoch 330/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 10.8951 - val_loss: 2.7165\n",
      "Epoch 331/500\n",
      "22/22 [==============================] - 0s 939us/step - loss: 10.8725 - val_loss: 2.7555\n",
      "Epoch 332/500\n",
      "22/22 [==============================] - 0s 964us/step - loss: 10.8675 - val_loss: 2.6714\n",
      "Epoch 333/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.8284 - val_loss: 2.6761\n",
      "Epoch 334/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 10.8179 - val_loss: 2.6456\n",
      "Epoch 335/500\n",
      "22/22 [==============================] - 0s 978us/step - loss: 10.7725 - val_loss: 2.6206\n",
      "Epoch 336/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 10.7445 - val_loss: 2.6070\n",
      "Epoch 337/500\n",
      "22/22 [==============================] - 0s 975us/step - loss: 10.7184 - val_loss: 2.6019\n",
      "Epoch 338/500\n",
      "22/22 [==============================] - 0s 931us/step - loss: 10.6927 - val_loss: 2.5678\n",
      "Epoch 339/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 10.6749 - val_loss: 2.5633\n",
      "Epoch 340/500\n",
      "22/22 [==============================] - 0s 961us/step - loss: 10.6472 - val_loss: 2.5394\n",
      "Epoch 341/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 10.6217 - val_loss: 2.5204\n",
      "Epoch 342/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.5976 - val_loss: 2.5045\n",
      "Epoch 343/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.5707 - val_loss: 2.4893\n",
      "Epoch 344/500\n",
      "22/22 [==============================] - 0s 954us/step - loss: 10.5467 - val_loss: 2.4652\n",
      "Epoch 345/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.5135 - val_loss: 2.4468\n",
      "Epoch 346/500\n",
      "22/22 [==============================] - 0s 910us/step - loss: 10.4930 - val_loss: 2.4304\n",
      "Epoch 347/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.4775 - val_loss: 2.4443\n",
      "Epoch 348/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.4929 - val_loss: 2.4180\n",
      "Epoch 349/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.6677 - val_loss: 2.6174\n",
      "Epoch 350/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.5454 - val_loss: 2.4435\n",
      "Epoch 351/500\n",
      "22/22 [==============================] - 0s 960us/step - loss: 10.4144 - val_loss: 2.3581\n",
      "Epoch 352/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 10.3799 - val_loss: 2.3667\n",
      "Epoch 353/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 10.3408 - val_loss: 2.3194\n",
      "Epoch 354/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.3059 - val_loss: 2.3011\n",
      "Epoch 355/500\n",
      "22/22 [==============================] - 0s 974us/step - loss: 10.2813 - val_loss: 2.2848\n",
      "Epoch 356/500\n",
      "22/22 [==============================] - 0s 956us/step - loss: 10.2547 - val_loss: 2.2715\n",
      "Epoch 357/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.2305 - val_loss: 2.2706\n",
      "Epoch 358/500\n",
      "22/22 [==============================] - 0s 989us/step - loss: 10.2160 - val_loss: 2.2509\n",
      "Epoch 359/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.1935 - val_loss: 2.2276\n",
      "Epoch 360/500\n",
      "22/22 [==============================] - 0s 987us/step - loss: 10.1667 - val_loss: 2.2123\n",
      "Epoch 361/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.1627 - val_loss: 2.2029\n",
      "Epoch 362/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.1271 - val_loss: 2.1859\n",
      "Epoch 363/500\n",
      "22/22 [==============================] - 0s 997us/step - loss: 10.1408 - val_loss: 2.1764\n",
      "Epoch 364/500\n",
      "22/22 [==============================] - 0s 996us/step - loss: 10.0738 - val_loss: 2.1571\n",
      "Epoch 365/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 10.0487 - val_loss: 2.1682\n",
      "Epoch 366/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 10.0520 - val_loss: 2.1453\n",
      "Epoch 367/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 10.0039 - val_loss: 2.1001\n",
      "Epoch 368/500\n",
      "22/22 [==============================] - 0s 978us/step - loss: 9.9739 - val_loss: 2.0899\n",
      "Epoch 369/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 10.0117 - val_loss: 2.1060\n",
      "Epoch 370/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 9.9631 - val_loss: 2.0784\n",
      "Epoch 371/500\n",
      "22/22 [==============================] - 0s 978us/step - loss: 9.9164 - val_loss: 2.0436\n",
      "Epoch 372/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.8867 - val_loss: 2.0297\n",
      "Epoch 373/500\n",
      "22/22 [==============================] - 0s 954us/step - loss: 9.8719 - val_loss: 2.0109\n",
      "Epoch 374/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.8422 - val_loss: 2.0025\n",
      "Epoch 375/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.8435 - val_loss: 2.0889\n",
      "Epoch 376/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.9828 - val_loss: 2.0358\n",
      "Epoch 377/500\n",
      "22/22 [==============================] - 0s 966us/step - loss: 9.9230 - val_loss: 1.9893\n",
      "Epoch 378/500\n",
      "22/22 [==============================] - 0s 977us/step - loss: 9.8100 - val_loss: 1.9760\n",
      "Epoch 379/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.7549 - val_loss: 1.9289\n",
      "Epoch 380/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.7184 - val_loss: 1.9151\n",
      "Epoch 381/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.6929 - val_loss: 1.9067\n",
      "Epoch 382/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.6751 - val_loss: 1.8943\n",
      "Epoch 383/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.6552 - val_loss: 1.8938\n",
      "Epoch 384/500\n",
      "22/22 [==============================] - 0s 980us/step - loss: 9.6316 - val_loss: 1.8667\n",
      "Epoch 385/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.6063 - val_loss: 1.8584\n",
      "Epoch 386/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.5852 - val_loss: 1.8466\n",
      "Epoch 387/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.5636 - val_loss: 1.8249\n",
      "Epoch 388/500\n",
      "22/22 [==============================] - 0s 997us/step - loss: 9.5473 - val_loss: 1.8132\n",
      "Epoch 389/500\n",
      "22/22 [==============================] - 0s 959us/step - loss: 9.5306 - val_loss: 1.8246\n",
      "Epoch 390/500\n",
      "22/22 [==============================] - 0s 982us/step - loss: 9.5120 - val_loss: 1.7855\n",
      "Epoch 391/500\n",
      "22/22 [==============================] - 0s 968us/step - loss: 9.4876 - val_loss: 1.7743\n",
      "Epoch 392/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.4723 - val_loss: 1.8056\n",
      "Epoch 393/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 9.5759 - val_loss: 1.8878\n",
      "Epoch 394/500\n",
      "22/22 [==============================] - 0s 949us/step - loss: 9.4551 - val_loss: 1.7588\n",
      "Epoch 395/500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 9.4928 - val_loss: 1.7542\n",
      "Epoch 396/500\n",
      "22/22 [==============================] - 0s 977us/step - loss: 9.4169 - val_loss: 1.7248\n",
      "Epoch 397/500\n",
      "22/22 [==============================] - 0s 972us/step - loss: 9.3730 - val_loss: 1.7089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.3458 - val_loss: 1.7113\n",
      "Epoch 399/500\n",
      "22/22 [==============================] - 0s 981us/step - loss: 9.3131 - val_loss: 1.6758\n",
      "Epoch 400/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 9.2927 - val_loss: 1.6588\n",
      "Epoch 401/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.2783 - val_loss: 1.6623\n",
      "Epoch 402/500\n",
      "22/22 [==============================] - 0s 958us/step - loss: 9.2748 - val_loss: 1.6449\n",
      "Epoch 403/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 9.2491 - val_loss: 1.6458\n",
      "Epoch 404/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.2148 - val_loss: 1.6156\n",
      "Epoch 405/500\n",
      "22/22 [==============================] - 0s 959us/step - loss: 9.1921 - val_loss: 1.6189\n",
      "Epoch 406/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.1765 - val_loss: 1.6078\n",
      "Epoch 407/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.1622 - val_loss: 1.5767\n",
      "Epoch 408/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.1402 - val_loss: 1.5730\n",
      "Epoch 409/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.1113 - val_loss: 1.5519\n",
      "Epoch 410/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.0921 - val_loss: 1.5419\n",
      "Epoch 411/500\n",
      "22/22 [==============================] - 0s 998us/step - loss: 9.0740 - val_loss: 1.5273\n",
      "Epoch 412/500\n",
      "22/22 [==============================] - 0s 991us/step - loss: 9.0494 - val_loss: 1.5172\n",
      "Epoch 413/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 9.0498 - val_loss: 1.5367\n",
      "Epoch 414/500\n",
      "22/22 [==============================] - 0s 952us/step - loss: 9.1155 - val_loss: 1.5628\n",
      "Epoch 415/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 9.0291 - val_loss: 1.4931\n",
      "Epoch 416/500\n",
      "22/22 [==============================] - 0s 991us/step - loss: 8.9892 - val_loss: 1.4738\n",
      "Epoch 417/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 8.9575 - val_loss: 1.4678\n",
      "Epoch 418/500\n",
      "22/22 [==============================] - 0s 963us/step - loss: 8.9380 - val_loss: 1.4506\n",
      "Epoch 419/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.9212 - val_loss: 1.4444\n",
      "Epoch 420/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.8948 - val_loss: 1.4416\n",
      "Epoch 421/500\n",
      "22/22 [==============================] - 0s 983us/step - loss: 8.8875 - val_loss: 1.4564\n",
      "Epoch 422/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.8697 - val_loss: 1.6166\n",
      "Epoch 423/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.1253 - val_loss: 2.0747\n",
      "Epoch 424/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 9.1567 - val_loss: 1.4544\n",
      "Epoch 425/500\n",
      "22/22 [==============================] - 0s 963us/step - loss: 8.8405 - val_loss: 1.3892\n",
      "Epoch 426/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 8.7995 - val_loss: 1.4090\n",
      "Epoch 427/500\n",
      "22/22 [==============================] - 0s 992us/step - loss: 8.7737 - val_loss: 1.3780\n",
      "Epoch 428/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.7441 - val_loss: 1.3444\n",
      "Epoch 429/500\n",
      "22/22 [==============================] - 0s 983us/step - loss: 8.7178 - val_loss: 1.3317\n",
      "Epoch 430/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.6977 - val_loss: 1.3222\n",
      "Epoch 431/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 8.6885 - val_loss: 1.3202\n",
      "Epoch 432/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 8.6651 - val_loss: 1.3032\n",
      "Epoch 433/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 8.6460 - val_loss: 1.2966\n",
      "Epoch 434/500\n",
      "22/22 [==============================] - 0s 993us/step - loss: 8.6250 - val_loss: 1.2896\n",
      "Epoch 435/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.6198 - val_loss: 1.3085\n",
      "Epoch 436/500\n",
      "22/22 [==============================] - 0s 945us/step - loss: 8.6552 - val_loss: 1.4274\n",
      "Epoch 437/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.6805 - val_loss: 1.3552\n",
      "Epoch 438/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.6060 - val_loss: 1.3184\n",
      "Epoch 439/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.5948 - val_loss: 1.2589\n",
      "Epoch 440/500\n",
      "22/22 [==============================] - 0s 1000us/step - loss: 8.5441 - val_loss: 1.2441\n",
      "Epoch 441/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.5351 - val_loss: 1.2453\n",
      "Epoch 442/500\n",
      "22/22 [==============================] - 0s 1000us/step - loss: 8.5141 - val_loss: 1.2306\n",
      "Epoch 443/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 8.4703 - val_loss: 1.1982\n",
      "Epoch 444/500\n",
      "22/22 [==============================] - 0s 955us/step - loss: 8.4574 - val_loss: 1.2013\n",
      "Epoch 445/500\n",
      "22/22 [==============================] - 0s 952us/step - loss: 8.4414 - val_loss: 1.1845\n",
      "Epoch 446/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 8.4099 - val_loss: 1.1686\n",
      "Epoch 447/500\n",
      "22/22 [==============================] - 0s 965us/step - loss: 8.3902 - val_loss: 1.1578\n",
      "Epoch 448/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.3749 - val_loss: 1.1552\n",
      "Epoch 449/500\n",
      "22/22 [==============================] - 0s 992us/step - loss: 8.3611 - val_loss: 1.1442\n",
      "Epoch 450/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.3469 - val_loss: 1.1279\n",
      "Epoch 451/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.3219 - val_loss: 1.1244\n",
      "Epoch 452/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.3046 - val_loss: 1.1146\n",
      "Epoch 453/500\n",
      "22/22 [==============================] - 0s 954us/step - loss: 8.2906 - val_loss: 1.1100\n",
      "Epoch 454/500\n",
      "22/22 [==============================] - 0s 1000us/step - loss: 8.2737 - val_loss: 1.1144\n",
      "Epoch 455/500\n",
      "22/22 [==============================] - 0s 959us/step - loss: 8.2591 - val_loss: 1.0880\n",
      "Epoch 456/500\n",
      "22/22 [==============================] - 0s 942us/step - loss: 8.2406 - val_loss: 1.0934\n",
      "Epoch 457/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.2324 - val_loss: 1.0755\n",
      "Epoch 458/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 8.2081 - val_loss: 1.0639\n",
      "Epoch 459/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.1852 - val_loss: 1.0581\n",
      "Epoch 460/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.1720 - val_loss: 1.0685\n",
      "Epoch 461/500\n",
      "22/22 [==============================] - 0s 941us/step - loss: 8.1586 - val_loss: 1.0534\n",
      "Epoch 462/500\n",
      "22/22 [==============================] - 0s 958us/step - loss: 8.1456 - val_loss: 1.0395\n",
      "Epoch 463/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 8.1279 - val_loss: 1.0240\n",
      "Epoch 464/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 8.1081 - val_loss: 1.0355\n",
      "Epoch 465/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.0909 - val_loss: 1.0274\n",
      "Epoch 466/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.0736 - val_loss: 1.0443\n",
      "Epoch 467/500\n",
      "22/22 [==============================] - 0s 935us/step - loss: 8.0683 - val_loss: 1.0051\n",
      "Epoch 468/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 8.0372 - val_loss: 0.9828\n",
      "Epoch 469/500\n",
      "22/22 [==============================] - 0s 988us/step - loss: 8.0178 - val_loss: 0.9791\n",
      "Epoch 470/500\n",
      "22/22 [==============================] - 0s 955us/step - loss: 8.0101 - val_loss: 0.9942\n",
      "Epoch 471/500\n",
      "22/22 [==============================] - 0s 950us/step - loss: 7.9902 - val_loss: 0.9662\n",
      "Epoch 472/500\n",
      "22/22 [==============================] - 0s 985us/step - loss: 7.9997 - val_loss: 1.0149\n",
      "Epoch 473/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.9946 - val_loss: 0.9561\n",
      "Epoch 474/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.9456 - val_loss: 0.9713\n",
      "Epoch 475/500\n",
      "22/22 [==============================] - 0s 954us/step - loss: 7.9294 - val_loss: 0.9308\n",
      "Epoch 476/500\n",
      "22/22 [==============================] - 0s 960us/step - loss: 7.9104 - val_loss: 0.9424\n",
      "Epoch 477/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.8951 - val_loss: 0.9157\n",
      "Epoch 478/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 976us/step - loss: 7.8872 - val_loss: 0.9345\n",
      "Epoch 479/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.8644 - val_loss: 0.8949\n",
      "Epoch 480/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.8413 - val_loss: 0.8991\n",
      "Epoch 481/500\n",
      "22/22 [==============================] - 0s 967us/step - loss: 7.8302 - val_loss: 0.8806\n",
      "Epoch 482/500\n",
      "22/22 [==============================] - 0s 982us/step - loss: 7.8191 - val_loss: 1.0044\n",
      "Epoch 483/500\n",
      "22/22 [==============================] - 0s 994us/step - loss: 7.8602 - val_loss: 0.8841\n",
      "Epoch 484/500\n",
      "22/22 [==============================] - 0s 955us/step - loss: 7.7908 - val_loss: 0.8741\n",
      "Epoch 485/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.7660 - val_loss: 0.8698\n",
      "Epoch 486/500\n",
      "22/22 [==============================] - 0s 945us/step - loss: 7.7475 - val_loss: 0.8519\n",
      "Epoch 487/500\n",
      "22/22 [==============================] - 0s 952us/step - loss: 7.7291 - val_loss: 0.8458\n",
      "Epoch 488/500\n",
      "22/22 [==============================] - 0s 974us/step - loss: 7.7154 - val_loss: 0.8341\n",
      "Epoch 489/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.7096 - val_loss: 0.8659\n",
      "Epoch 490/500\n",
      "22/22 [==============================] - 0s 976us/step - loss: 7.7007 - val_loss: 0.8273\n",
      "Epoch 491/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.6817 - val_loss: 0.8094\n",
      "Epoch 492/500\n",
      "22/22 [==============================] - 0s 990us/step - loss: 7.6589 - val_loss: 0.8003\n",
      "Epoch 493/500\n",
      "22/22 [==============================] - 0s 944us/step - loss: 7.6470 - val_loss: 0.7963\n",
      "Epoch 494/500\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 7.6220 - val_loss: 0.8022\n",
      "Epoch 495/500\n",
      "22/22 [==============================] - 0s 979us/step - loss: 7.6114 - val_loss: 0.8062\n",
      "Epoch 496/500\n",
      "22/22 [==============================] - 0s 973us/step - loss: 7.6310 - val_loss: 0.8794\n",
      "Epoch 497/500\n",
      "22/22 [==============================] - 0s 979us/step - loss: 7.6623 - val_loss: 0.9062\n",
      "Epoch 498/500\n",
      "22/22 [==============================] - 0s 974us/step - loss: 7.7061 - val_loss: 0.7777\n",
      "Epoch 499/500\n",
      "22/22 [==============================] - 0s 962us/step - loss: 7.5546 - val_loss: 0.7819\n",
      "Epoch 500/500\n",
      "22/22 [==============================] - 0s 995us/step - loss: 7.5456 - val_loss: 0.7573\n",
      "CPU times: user 16.2 s, sys: 2.04 s, total: 18.2 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "x = train_dfs[0].drop('cnt',axis=1).to_numpy()\n",
    "y = train_dfs[0]['cnt'].to_numpy()\n",
    "p = np.random.permutation(y.shape[0])\n",
    "\n",
    "tmp = fp_datamodel.fit(\n",
    "    x[p],y[p],\n",
    "    epochs=500,\n",
    "    validation_split=0.2,\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'][200:])\n",
    "plt.plot(history['val_loss'][200:])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 0s 531us/step - loss: 18170.5566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18170.556640625"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_datamodel.evaluate(\n",
    "    train_dfs[1].drop('cnt',axis=1).to_numpy(),\n",
    "    train_dfs[1].drop('cnt',axis=1).to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [bike[(bike['hr']>=sr)&(bike['hr']<=so)] for sr,so in zip(range(0,25,6)[:-1],range(-1,24,6)[1:])]\n",
    "\n",
    "train_dfs = [q.sample(frac=0.8) for q in res]\n",
    "test_dfs = [q.drop(t.index) for q,t in zip(res,train_dfs)]\n",
    "\n",
    "# y_train = [x.pop('cnt') for x in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from copy import deepcopy\n",
    "import tensorflow.experimental.numpy as tnp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cw_acc(y_true,y_pred):\n",
    "    y_pred = np.argmax(y_pred,axis=1)\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    return matrix.diagonal()/matrix.sum(axis=1)\n",
    "\n",
    "# Need to make sure this works properly\n",
    "def gen_mask(grads,m=2):\n",
    "    mask = []\n",
    "    for g in grads:\n",
    "        size = g.shape[-1]\n",
    "        assert m%1==0\n",
    "\n",
    "        if size//2>0: #catches the special case where there's one output\n",
    "            split = tf.concat([tf.ones(size//m)*i for i in range(m)],0)\n",
    "            split = tf.random.shuffle(split)\n",
    "        else:\n",
    "            split = tf.ones(size) * np.random.randint(0,m)\n",
    "            \n",
    "        mask.append(tf.reshape(split,(1,-1)))\n",
    "\n",
    "    return mask\n",
    "\n",
    "class DistMLP(keras.Model):\n",
    "    def __init__(self,mode='none',p=1.0):\n",
    "        super(DistMLP, self).__init__()\n",
    "        self.mod1 = Sequential([\n",
    "            layers.Dense(128, activation='sigmoid', input_shape=(14,)),\n",
    "            layers.Dense(32, activation='sigmoid'),\n",
    "            layers.Dense(8, activation='sigmoid'),\n",
    "            layers.Dense(1, 'linear')\n",
    "        ])\n",
    "        \n",
    "        self.mod2 = tf.keras.models.clone_model(self.mod1)\n",
    "        self.mod3 = tf.keras.models.clone_model(self.mod1)\n",
    "        self.mod4 = tf.keras.models.clone_model(self.mod1)\n",
    "        \n",
    "        self.mode=mode\n",
    "        \n",
    "        self.cars = [Car([i%2,],p=p) for i in range(1,5)]\n",
    "        self.gradients = []\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.mod1(data)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x1,y1,x2,y2,x3,y3,x4,y4, = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred1 = self.mod1(x1,training=True)\n",
    "            y_pred2 = self.mod2(x2,training=True)\n",
    "            y_pred3 = self.mod3(x3,training=True)\n",
    "            y_pred4 = self.mod4(x4,training=True)\n",
    "            loss1 = self.compiled_loss(y1,y_pred1)\n",
    "            loss2 = self.compiled_loss(y2,y_pred2)\n",
    "            loss3 = self.compiled_loss(y3,y_pred3)\n",
    "            loss4 = self.compiled_loss(y4,y_pred4)\n",
    "\n",
    "        grads = tape.gradient([loss1,loss2,loss3,loss4], self.trainable_weights)\n",
    "        \n",
    "        if self.mode=='none':\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        elif self.mode=='simple_add':\n",
    "            temp = [tf.math.add_n([grads[n+i*(len(grads)//4)] for i in range(4)]) for n in range(len(grads)//4)]\n",
    "            self.optimizer.apply_gradients(zip([*temp,*temp,*temp,*temp], self.trainable_weights))\n",
    "        elif self.mode=='djgrad':\n",
    "            grad_mask = [tf.reshape(m,(-1,)) if len(g.shape)==1 else m for m,g in zip(gen_mask(grads),grads)]\n",
    "            masked_grads = [tf.math.multiply(g,m) for m,g in zip(grad_mask,grads)]\n",
    "            new_grads = []\n",
    "                       \n",
    "            for n,c in enumerate(self.cars):\n",
    "                i1,i2 = (len(grads)//4)*n,(len(grads)//4)*(n+1)\n",
    "                new_grads+=c.apply_grads(grads[i1:i2])\n",
    "                c.load(masked_grads[i1:i2])\n",
    "                c._mark_seen(masked_grads[i1:i2],True)\n",
    "                c.forward(self.cars)\n",
    "                                     \n",
    "            self.optimizer.apply_gradients(zip(\n",
    "                [tf.math.add(g,n) for g,n in zip(grads,new_grads)],\n",
    "                self.trainable_weights))\n",
    "        \n",
    "        # Need a metric that gives accuracy for each model individually\n",
    "        for m in self.compiled_metrics._user_metrics:\n",
    "            m.update_state(tf.concat([y1,y2,y3,y4],0), tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0),source_array=tf.concat([x1[:,3],x2[:,3],x3[:,3],x4[:,3]],0))\n",
    "\n",
    "        res = {k.name:k.result() for k in self.compiled_loss.metrics}\n",
    "    \n",
    "        res.update({m.name: m.result() for m in self.compiled_metrics._user_metrics})\n",
    "            \n",
    "        return res\n",
    "    \n",
    "    # Need to add loss here as well\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        \n",
    "        y_pred1 = self.mod1(x,training=False)\n",
    "        y_pred2 = self.mod2(x,training=False)\n",
    "        y_pred3 = self.mod3(x,training=False)\n",
    "        y_pred4 = self.mod4(x,training=False)\n",
    "                \n",
    "        self.compiled_loss(tf.concat([y,y,y,y,],0),tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0))\n",
    "        for m in self.compiled_metrics._user_metrics:\n",
    "            m.update_state(tf.concat([y,y,y,y],0),tf.concat([y_pred1,y_pred2,y_pred3,y_pred4],0),source_array=tf.concat([x[:,3],x[:,3],x[:,3],x[:,3]],0))\n",
    "\n",
    "        return {m.name: m.result() for m in self.compiled_metrics._user_metrics}\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        for m in self.compiled_metrics._user_metrics:\n",
    "            m.reset_state()\n",
    "        for m in self.metrics:\n",
    "            m.reset_state()\n",
    "        for m in self.compiled_loss.metrics:\n",
    "            m.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CWMet(tf.keras.metrics.Metric):\n",
    "    def __init__(self, car_idx, minmax, name='classwise_accuracy', num_cars=4, **kwargs):\n",
    "        super(CWMet, self).__init__(name=name, **kwargs)\n",
    "        self.num_cars = num_cars\n",
    "        self.car_idx = car_idx\n",
    "        self.minmax = minmax\n",
    "        self.loss = self.add_weight(name='loss',initializer='zeros')\n",
    "        self.num_samples = self.add_weight(name='num_samples',initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, source_array=None, sample_weight=None):\n",
    "        y_true = tf.cast(tf.reshape(y_true, (4,-1))[self.car_idx], tf.float32)\n",
    "        y_pred = tf.cast(tf.reshape(y_pred, (4,-1))[self.car_idx], tf.float32)\n",
    "        \n",
    "        if source_array is not None:\n",
    "            source_array = tf.reshape(source_array, (4,-1))[self.car_idx]\n",
    "\n",
    "            bl_mask = tf.math.logical_and(\n",
    "                tf.math.greater_equal(source_array, self.minmax[0]),\n",
    "                tf.math.greater_equal(self.minmax[1],source_array),\n",
    "            )\n",
    "                \n",
    "            y_true = tf.boolean_mask(y_true, bl_mask)\n",
    "            y_pred = tf.boolean_mask(y_pred, bl_mask)\n",
    "            \n",
    "        loss = tf.math.reduce_sum(tf.math.square(y_true-y_pred))\n",
    "\n",
    "        count_class = tf.math.reduce_sum(tf.cast(bl_mask,dtype=tf.float32))\n",
    "        \n",
    "        self.loss.assign_add(loss)\n",
    "        self.num_samples.assign_add(count_class)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.math.divide_no_nan(self.loss,self.num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len = min([x.shape[0] for x in train_dfs])\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    train_dfs[0].drop('cnt',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[0]['cnt'].to_numpy()[:min_len],\n",
    "    train_dfs[1].drop('cnt',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[1]['cnt'].to_numpy()[:min_len],\n",
    "    train_dfs[2].drop('cnt',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[2]['cnt'].to_numpy()[:min_len],\n",
    "    train_dfs[3].drop('cnt',axis=1).to_numpy()[:min_len],\n",
    "    train_dfs[3]['cnt'].to_numpy()[:min_len],\n",
    ")).shuffle(100).batch(128,True)\n",
    "\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    np.concatenate((\n",
    "        test_dfs[0].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[1].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[2].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[3].drop('cnt',axis=1).to_numpy(),\n",
    "    )),\n",
    "    np.concatenate((\n",
    "        test_dfs[0]['cnt'].to_numpy(),\n",
    "        test_dfs[1]['cnt'].to_numpy(),\n",
    "        test_dfs[2]['cnt'].to_numpy(),\n",
    "        test_dfs[3]['cnt'].to_numpy(),\n",
    "    ))\n",
    ")).shuffle(100).batch(128,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('none')\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1*10e-3),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2}]') for ca,(q1,q2) in product(range(4),zip(range(0,25,6)[:-1],range(-1,24,6)[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "26/26 [==============================] - 3s 112ms/step - loss: 68540.7031 - ca1-[0,5]: 1350.3756 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 72583.0003 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 124246.4858 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 82560.4138 - val_ca1-[0,5]: 1481.2601 - val_ca1-[6,11]: 64865.3320 - val_ca1-[12,17]: 110374.7812 - val_ca1-[18,23]: 79711.3516 - val_ca2-[0,5]: 1410.4688 - val_ca2-[6,11]: 64240.7930 - val_ca2-[12,17]: 109496.4922 - val_ca2-[18,23]: 79016.9531 - val_ca3-[0,5]: 1416.3090 - val_ca3-[6,11]: 64293.8672 - val_ca3-[12,17]: 109571.1328 - val_ca3-[18,23]: 79075.9531 - val_ca4-[0,5]: 1421.2018 - val_ca4-[6,11]: 64338.0078 - val_ca4-[12,17]: 109633.3203 - val_ca4-[18,23]: 79125.0781\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 3s 114ms/step - loss: 67677.0312 - ca1-[0,5]: 1280.3920 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71418.0124 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 123512.1227 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81919.3649 - val_ca1-[0,5]: 1432.8269 - val_ca1-[6,11]: 64442.2031 - val_ca1-[12,17]: 109779.9688 - val_ca1-[18,23]: 78454.9062 - val_ca2-[0,5]: 1328.0952 - val_ca2-[6,11]: 63459.7852 - val_ca2-[12,17]: 108395.2031 - val_ca2-[18,23]: 77367.0000 - val_ca3-[0,5]: 1346.0868 - val_ca3-[6,11]: 63636.1289 - val_ca3-[12,17]: 108644.1328 - val_ca3-[18,23]: 77562.3672 - val_ca4-[0,5]: 1337.0760 - val_ca4-[6,11]: 63548.2578 - val_ca4-[12,17]: 108520.1250 - val_ca4-[18,23]: 77465.0234\n",
      "CPU times: user 5.9 s, sys: 85.6 ms, total: 5.99 s\n",
      "Wall time: 5.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]\n",
    "    \n",
    "with open(os.path.join(fp_local,'new_none.pickle'), 'wb') as handle:\n",
    "    pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca1-[0,5] 1399.303466796875\n",
      "ca2-[6,11] 69293.078125\n",
      "ca3-[12,17] 119293.09375\n",
      "ca4-[18,23] 80722.671875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join(fp_local,'new_none.pickle'), 'rb') as handle:\n",
    "    history = pickle.load(handle)\n",
    "\n",
    "offset = 0\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True, figsize=(24, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    for k in [k for k in history if f'val_ca{n+1}' in k]:\n",
    "        ax.plot(history[k][offset:], label=k.split('-')[1])\n",
    "        \n",
    "    ax.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True,  figsize=(22, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    k = [k for k in history if f'ca{n+1}' in k and 'val' not in k][n]\n",
    "    ax.plot(history[k][offset:], label=('train '+k.split('-')[1]),linestyle=':')\n",
    "        \n",
    "    ax.legend()\n",
    "    print(k, np.min(history[k]))\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 5s 47ms/step - ca1-[0,5]: 1472.9314 - ca1-[6,11]: 48589.0271 - ca1-[12,17]: 55001.3882 - ca1-[18,23]: 20212.4640 - ca2-[0,5]: 1366.9953 - ca2-[6,11]: 47846.4993 - ca2-[12,17]: 54295.8501 - ca2-[18,23]: 19926.6016 - ca3-[0,5]: 1385.2044 - ca3-[6,11]: 47979.7736 - ca3-[12,17]: 54422.6768 - ca3-[18,23]: 19977.9369 - ca4-[0,5]: 1376.0851 - ca4-[6,11]: 47913.3643 - ca4-[12,17]: 54359.4864 - ca4-[18,23]: 19952.3594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1432.8267822265625,\n",
       " 109779.9609375,\n",
       " 78650.046875,\n",
       " 64442.203125,\n",
       " 1328.09521484375,\n",
       " 108395.21875,\n",
       " 77560.0546875,\n",
       " 63459.7890625,\n",
       " 1346.0870361328125,\n",
       " 108644.15625,\n",
       " 77755.8046875,\n",
       " 63636.12890625,\n",
       " 1337.075927734375,\n",
       " 108520.125,\n",
       " 77658.2734375,\n",
       " 63548.26171875]"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(\n",
    "    np.concatenate((\n",
    "        test_dfs[0].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[1].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[2].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[3].drop('cnt',axis=1).to_numpy(),\n",
    "    )),\n",
    "    np.concatenate((\n",
    "        test_dfs[0]['cnt'].to_numpy(),\n",
    "        test_dfs[1]['cnt'].to_numpy(),\n",
    "        test_dfs[2]['cnt'].to_numpy(),\n",
    "        test_dfs[3]['cnt'].to_numpy(),\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('simple_add')\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1*10e-3),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2}]') for ca,(q1,q2) in product(range(4),zip(range(0,25,6)[:-1],range(-1,24,6)[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "26/26 [==============================] - 3s 113ms/step - loss: 68794.2344 - ca1-[0,5]: 1401.8595 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 72174.3892 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 124875.9809 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 82730.2821 - val_ca1-[0,5]: 1527.7743 - val_ca1-[6,11]: 65272.3984 - val_ca1-[12,17]: 110943.6562 - val_ca1-[18,23]: 79547.1875 - val_ca2-[0,5]: 1424.0232 - val_ca2-[6,11]: 64334.9141 - val_ca2-[12,17]: 109628.7031 - val_ca2-[18,23]: 78501.0781 - val_ca3-[0,5]: 1420.2139 - val_ca3-[6,11]: 64323.1758 - val_ca3-[12,17]: 109612.3984 - val_ca3-[18,23]: 78488.7969 - val_ca4-[0,5]: 1427.9130 - val_ca4-[6,11]: 64373.7852 - val_ca4-[12,17]: 109683.3984 - val_ca4-[18,23]: 78543.7500\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 3s 113ms/step - loss: 67742.6016 - ca1-[0,5]: 1326.9822 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71723.0362 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 123544.8168 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81336.5289 - val_ca1-[0,5]: 1411.7421 - val_ca1-[6,11]: 64275.1562 - val_ca1-[12,17]: 109549.3594 - val_ca1-[18,23]: 78128.6641 - val_ca2-[0,5]: 1330.3529 - val_ca2-[6,11]: 63482.4023 - val_ca2-[12,17]: 108427.0703 - val_ca2-[18,23]: 77229.6875 - val_ca3-[0,5]: 1335.6477 - val_ca3-[6,11]: 63528.6055 - val_ca3-[12,17]: 108492.0703 - val_ca3-[18,23]: 77279.2422 - val_ca4-[0,5]: 1338.2825 - val_ca4-[6,11]: 63557.7148 - val_ca4-[12,17]: 108533.4453 - val_ca4-[18,23]: 77313.1875\n",
      "CPU times: user 5.97 s, sys: 30.3 ms, total: 6 s\n",
      "Wall time: 5.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]\n",
    "    \n",
    "with open(os.path.join(fp_local,'new_add.pickle'), 'wb') as handle:\n",
    "    pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca1-[0,5] 1420.9849853515625\n",
      "ca2-[6,11] 69191.0\n",
      "ca3-[12,17] 119619.84375\n",
      "ca4-[18,23] 80738.59375\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join(fp_local,'new_add.pickle'), 'rb') as handle:\n",
    "    history = pickle.load(handle)\n",
    "    \n",
    "offset = 0\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True, figsize=(24, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    for k in [k for k in history if f'val_ca{n+1}' in k]:\n",
    "        ax.plot(history[k][offset:], label=k.split('-')[1])\n",
    "        \n",
    "    ax.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True,  figsize=(22, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    k = [k for k in history if f'ca{n+1}' in k and 'val' not in k][n]\n",
    "    ax.plot(history[k][offset:], label=('train '+k.split('-')[1]),linestyle=':')\n",
    "        \n",
    "    ax.legend()\n",
    "    print(k, np.min(history[k]))\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 5s 46ms/step - ca1-[0,5]: 1451.6409 - ca1-[6,11]: 48462.5988 - ca1-[12,17]: 54883.7565 - ca1-[18,23]: 20169.1755 - ca2-[0,5]: 1369.2780 - ca2-[6,11]: 47863.5823 - ca2-[12,17]: 54312.0845 - ca2-[18,23]: 19933.1805 - ca3-[0,5]: 1374.6184 - ca3-[6,11]: 47898.4894 - ca3-[12,17]: 54345.1750 - ca3-[18,23]: 19946.1917 - ca4-[0,5]: 1377.2990 - ca4-[6,11]: 47920.5098 - ca4-[12,17]: 54366.2694 - ca4-[18,23]: 19955.0998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1411.7423095703125,\n",
       " 109549.359375,\n",
       " 78485.1015625,\n",
       " 64275.16015625,\n",
       " 1330.3526611328125,\n",
       " 108427.078125,\n",
       " 77585.1328125,\n",
       " 63482.390625,\n",
       " 1335.647705078125,\n",
       " 108492.078125,\n",
       " 77634.734375,\n",
       " 63528.609375,\n",
       " 1338.282470703125,\n",
       " 108533.4296875,\n",
       " 77668.7265625,\n",
       " 63557.71875]"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(\n",
    "    np.concatenate((\n",
    "        test_dfs[0].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[1].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[2].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[3].drop('cnt',axis=1).to_numpy(),\n",
    "    )),\n",
    "    np.concatenate((\n",
    "        test_dfs[0]['cnt'].to_numpy(),\n",
    "        test_dfs[1]['cnt'].to_numpy(),\n",
    "        test_dfs[2]['cnt'].to_numpy(),\n",
    "        test_dfs[3]['cnt'].to_numpy(),\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('djgrad',1.0)\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1*10e-3),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2}]') for ca,(q1,q2) in product(range(4),zip(range(0,25,6)[:-1],range(-1,24,6)[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "26/26 [==============================] - 3s 130ms/step - loss: 68707.4688 - ca1-[0,5]: 1366.8814 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 73121.4308 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 124154.5425 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 83012.0446 - val_ca1-[0,5]: 1481.1433 - val_ca1-[6,11]: 64864.3125 - val_ca1-[12,17]: 110373.3906 - val_ca1-[18,23]: 80277.9609 - val_ca2-[0,5]: 1410.5383 - val_ca2-[6,11]: 64241.4297 - val_ca2-[12,17]: 109497.3906 - val_ca2-[18,23]: 79582.1641 - val_ca3-[0,5]: 1416.2493 - val_ca3-[6,11]: 64293.3477 - val_ca3-[12,17]: 109570.3750 - val_ca3-[18,23]: 79640.1562 - val_ca4-[0,5]: 1421.1504 - val_ca4-[6,11]: 64337.5547 - val_ca4-[12,17]: 109632.6562 - val_ca4-[18,23]: 79689.5625\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 3s 129ms/step - loss: 68033.8281 - ca1-[0,5]: 1294.8905 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71959.8545 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 123723.7572 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81690.3067 - val_ca1-[0,5]: 1432.7379 - val_ca1-[6,11]: 64441.4023 - val_ca1-[12,17]: 109778.8516 - val_ca1-[18,23]: 78607.3750 - val_ca2-[0,5]: 1328.2365 - val_ca2-[6,11]: 63461.1758 - val_ca2-[12,17]: 108397.1719 - val_ca2-[18,23]: 77519.9766 - val_ca3-[0,5]: 1346.0336 - val_ca3-[6,11]: 63635.6211 - val_ca3-[12,17]: 108643.4141 - val_ca3-[18,23]: 77713.5703 - val_ca4-[0,5]: 1337.0007 - val_ca4-[6,11]: 63547.5156 - val_ca4-[12,17]: 108519.0781 - val_ca4-[18,23]: 77615.7969\n",
      "CPU times: user 6.85 s, sys: 29.5 ms, total: 6.88 s\n",
      "Wall time: 6.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]\n",
    "    \n",
    "with open(os.path.join(fp_local,'new_djgrad_100.pickle'), 'wb') as handle:\n",
    "    pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca1-[0,5] 1399.39404296875\n",
      "ca2-[6,11] 69849.5703125\n",
      "ca3-[12,17] 119815.21875\n",
      "ca4-[18,23] 81071.1328125\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join(fp_local,'new_djgrad_100.pickle'), 'rb') as handle:\n",
    "    history = pickle.load(handle)\n",
    "    \n",
    "offset = 0\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True, figsize=(24, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    for k in [k for k in history if f'val_ca{n+1}' in k]:\n",
    "        ax.plot(history[k][offset:], label=k.split('-')[1])\n",
    "        \n",
    "    ax.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True,  figsize=(22, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    k = [k for k in history if f'ca{n+1}' in k and 'val' not in k][n]\n",
    "    ax.plot(history[k][offset:], label=('train '+k.split('-')[1]),linestyle=':')\n",
    "        \n",
    "    ax.legend()\n",
    "    print(k, np.min(history[k]))\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 5s 45ms/step - ca1-[0,5]: 1472.8415 - ca1-[6,11]: 48588.4322 - ca1-[12,17]: 55000.8218 - ca1-[18,23]: 20212.2317 - ca2-[0,5]: 1367.1381 - ca2-[6,11]: 47847.5469 - ca2-[12,17]: 54296.8555 - ca2-[18,23]: 19927.0083 - ca3-[0,5]: 1385.1507 - ca3-[6,11]: 47979.3838 - ca3-[12,17]: 54422.3049 - ca3-[18,23]: 19977.7907 - ca4-[0,5]: 1376.0090 - ca4-[6,11]: 47912.7939 - ca4-[12,17]: 54358.9482 - ca4-[18,23]: 19952.1418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1432.7379150390625,\n",
       " 109778.8515625,\n",
       " 78649.171875,\n",
       " 64441.41796875,\n",
       " 1328.2362060546875,\n",
       " 108397.1953125,\n",
       " 77561.609375,\n",
       " 63461.17578125,\n",
       " 1346.033935546875,\n",
       " 108643.421875,\n",
       " 77755.25,\n",
       " 63635.61328125,\n",
       " 1337.000732421875,\n",
       " 108519.0703125,\n",
       " 77657.4453125,\n",
       " 63547.50390625]"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(\n",
    "    np.concatenate((\n",
    "        test_dfs[0].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[1].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[2].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[3].drop('cnt',axis=1).to_numpy(),\n",
    "    )),\n",
    "    np.concatenate((\n",
    "        test_dfs[0]['cnt'].to_numpy(),\n",
    "        test_dfs[1]['cnt'].to_numpy(),\n",
    "        test_dfs[2]['cnt'].to_numpy(),\n",
    "        test_dfs[3]['cnt'].to_numpy(),\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('djgrad',0.5)\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1*10e-3),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2}]') for ca,(q1,q2) in product(range(4),zip(range(0,25,6)[:-1],range(-1,24,6)[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "26/26 [==============================] - 4s 137ms/step - loss: 68631.8359 - ca1-[0,5]: 1372.0345 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 72655.7303 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 124344.7778 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 82959.4893 - val_ca1-[0,5]: 1498.6062 - val_ca1-[6,11]: 65013.0977 - val_ca1-[12,17]: 110582.3984 - val_ca1-[18,23]: 78723.9609 - val_ca2-[0,5]: 1414.7396 - val_ca2-[6,11]: 64279.6289 - val_ca2-[12,17]: 109551.1094 - val_ca2-[18,23]: 77912.6406 - val_ca3-[0,5]: 1416.2440 - val_ca3-[6,11]: 64293.2578 - val_ca3-[12,17]: 109570.2891 - val_ca3-[18,23]: 77927.7109 - val_ca4-[0,5]: 1421.1958 - val_ca4-[6,11]: 64337.9688 - val_ca4-[12,17]: 109633.2422 - val_ca4-[18,23]: 77977.1953\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 4s 139ms/step - loss: 67834.1328 - ca1-[0,5]: 1310.6300 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71265.5122 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 124176.2002 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81850.7590 - val_ca1-[0,5]: 1447.1849 - val_ca1-[6,11]: 64569.6055 - val_ca1-[12,17]: 109959.2031 - val_ca1-[18,23]: 78838.1562 - val_ca2-[0,5]: 1334.7056 - val_ca2-[6,11]: 63524.9805 - val_ca2-[12,17]: 108487.2812 - val_ca2-[18,23]: 77679.0156 - val_ca3-[0,5]: 1346.0336 - val_ca3-[6,11]: 63635.6211 - val_ca3-[12,17]: 108643.4375 - val_ca3-[18,23]: 77801.8516 - val_ca4-[0,5]: 1337.0792 - val_ca4-[6,11]: 63548.2852 - val_ca4-[12,17]: 108520.1562 - val_ca4-[18,23]: 77704.8828\n",
      "CPU times: user 7.3 s, sys: 26.2 ms, total: 7.33 s\n",
      "Wall time: 7.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]\n",
    "    \n",
    "with open(os.path.join(fp_local,'new_djgrad_050.pickle'), 'wb') as handle:\n",
    "    pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca1-[0,5] 1420.3612060546875\n",
      "ca2-[6,11] 69461.8125\n",
      "ca3-[12,17] 119384.4453125\n",
      "ca4-[18,23] 81069.953125\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join(fp_local,'new_djgrad_050.pickle'), 'rb') as handle:\n",
    "    history = pickle.load(handle)\n",
    "\n",
    "offset = 0\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True, figsize=(24, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    for k in [k for k in history if f'val_ca{n+1}' in k]:\n",
    "        ax.plot(history[k][offset:], label=k.split('-')[1])\n",
    "        \n",
    "    ax.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True,  figsize=(22, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    k = [k for k in history if f'ca{n+1}' in k and 'val' not in k][n]\n",
    "    ax.plot(history[k][offset:], label=('train '+k.split('-')[1]),linestyle=':')\n",
    "        \n",
    "    ax.legend()\n",
    "    print(k, np.min(history[k]))\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 5s 45ms/step - ca1-[0,5]: 1487.4447 - ca1-[6,11]: 48685.3269 - ca1-[12,17]: 55092.7214 - ca1-[18,23]: 20249.4984 - ca2-[0,5]: 1373.6860 - ca2-[6,11]: 47895.7731 - ca2-[12,17]: 54342.7425 - ca2-[18,23]: 19945.5840 - ca3-[0,5]: 1385.1507 - ca3-[6,11]: 47979.3891 - ca3-[12,17]: 54422.3061 - ca3-[18,23]: 19977.7912 - ca4-[0,5]: 1376.0884 - ca4-[6,11]: 47913.3817 - ca4-[12,17]: 54359.5038 - ca4-[18,23]: 19952.3682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1447.1849365234375,\n",
       " 109959.2109375,\n",
       " 78791.2578125,\n",
       " 64569.60546875,\n",
       " 1334.7054443359375,\n",
       " 108487.25,\n",
       " 77632.4375,\n",
       " 63524.984375,\n",
       " 1346.033935546875,\n",
       " 108643.421875,\n",
       " 77755.25,\n",
       " 63635.62109375,\n",
       " 1337.0791015625,\n",
       " 108520.15625,\n",
       " 77658.3046875,\n",
       " 63548.28515625]"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(\n",
    "    np.concatenate((\n",
    "        test_dfs[0].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[1].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[2].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[3].drop('cnt',axis=1).to_numpy(),\n",
    "    )),\n",
    "    np.concatenate((\n",
    "        test_dfs[0]['cnt'].to_numpy(),\n",
    "        test_dfs[1]['cnt'].to_numpy(),\n",
    "        test_dfs[2]['cnt'].to_numpy(),\n",
    "        test_dfs[3]['cnt'].to_numpy(),\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('djgrad',0.25)\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1*10e-3),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2}]') for ca,(q1,q2) in product(range(4),zip(range(0,25,6)[:-1],range(-1,24,6)[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "26/26 [==============================] - 4s 145ms/step - loss: 68618.6562 - ca1-[0,5]: 1365.3034 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 72523.7422 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 123938.2688 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 83149.4343 - val_ca1-[0,5]: 1500.6389 - val_ca1-[6,11]: 65030.4023 - val_ca1-[12,17]: 110606.5859 - val_ca1-[18,23]: 79544.7109 - val_ca2-[0,5]: 1413.7595 - val_ca2-[6,11]: 64270.7188 - val_ca2-[12,17]: 109538.6250 - val_ca2-[18,23]: 78701.3125 - val_ca3-[0,5]: 1416.2012 - val_ca3-[6,11]: 64292.8711 - val_ca3-[12,17]: 109569.7656 - val_ca3-[18,23]: 78725.9375 - val_ca4-[0,5]: 1421.2273 - val_ca4-[6,11]: 64338.2266 - val_ca4-[12,17]: 109633.6172 - val_ca4-[18,23]: 78776.2969\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 4s 146ms/step - loss: 67811.3359 - ca1-[0,5]: 1315.3258 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71169.6247 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 121416.5582 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81348.7581 - val_ca1-[0,5]: 1436.1392 - val_ca1-[6,11]: 64471.6367 - val_ca1-[12,17]: 109821.3672 - val_ca1-[18,23]: 79025.7422 - val_ca2-[0,5]: 1331.4779 - val_ca2-[6,11]: 63493.2070 - val_ca2-[12,17]: 108442.4141 - val_ca2-[18,23]: 77939.8281 - val_ca3-[0,5]: 1345.9749 - val_ca3-[6,11]: 63635.0469 - val_ca3-[12,17]: 108642.6172 - val_ca3-[18,23]: 78097.3359 - val_ca4-[0,5]: 1337.1262 - val_ca4-[6,11]: 63548.7383 - val_ca4-[12,17]: 108520.8047 - val_ca4-[18,23]: 78001.5000\n",
      "CPU times: user 7.63 s, sys: 52 ms, total: 7.68 s\n",
      "Wall time: 7.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]\n",
    "    \n",
    "with open(os.path.join(fp_local,'new_djgrad_025.pickle'), 'wb') as handle:\n",
    "    pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca1-[0,5] 1393.608642578125\n",
      "ca2-[6,11] 69598.53125\n",
      "ca3-[12,17] 119733.71875\n",
      "ca4-[18,23] 80519.546875\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join(fp_local,'new_djgrad_025.pickle'), 'rb') as handle:\n",
    "    history = pickle.load(handle)\n",
    "\n",
    "offset = 0\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True, figsize=(24, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    for k in [k for k in history if f'val_ca{n+1}' in k]:\n",
    "        ax.plot(history[k][offset:], label=k.split('-')[1])\n",
    "        \n",
    "    ax.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True,  figsize=(22, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    k = [k for k in history if f'ca{n+1}' in k and 'val' not in k][n]\n",
    "    ax.plot(history[k][offset:], label=('train '+k.split('-')[1]),linestyle=':')\n",
    "        \n",
    "    ax.legend()\n",
    "    print(k, np.min(history[k]))\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 5s 45ms/step - ca1-[0,5]: 1476.2794 - ca1-[6,11]: 48611.2727 - ca1-[12,17]: 55022.4829 - ca1-[18,23]: 20221.0177 - ca2-[0,5]: 1370.4193 - ca2-[6,11]: 47871.7524 - ca2-[12,17]: 54319.8918 - ca2-[18,23]: 19936.3330 - ca3-[0,5]: 1385.0909 - ca3-[6,11]: 47978.9550 - ca3-[12,17]: 54421.9035 - ca3-[18,23]: 19977.6232 - ca4-[0,5]: 1376.1357 - ca4-[6,11]: 47913.7253 - ca4-[12,17]: 54359.8310 - ca4-[18,23]: 19952.4989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1436.138916015625,\n",
       " 109821.359375,\n",
       " 78682.6640625,\n",
       " 64471.6328125,\n",
       " 1331.4779052734375,\n",
       " 108442.40625,\n",
       " 77597.171875,\n",
       " 63493.203125,\n",
       " 1345.974853515625,\n",
       " 108642.640625,\n",
       " 77754.6015625,\n",
       " 63635.046875,\n",
       " 1337.1258544921875,\n",
       " 108520.796875,\n",
       " 77658.8125,\n",
       " 63548.73828125]"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(\n",
    "    np.concatenate((\n",
    "        test_dfs[0].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[1].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[2].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[3].drop('cnt',axis=1).to_numpy(),\n",
    "    )),\n",
    "    np.concatenate((\n",
    "        test_dfs[0]['cnt'].to_numpy(),\n",
    "        test_dfs[1]['cnt'].to_numpy(),\n",
    "        test_dfs[2]['cnt'].to_numpy(),\n",
    "        test_dfs[3]['cnt'].to_numpy(),\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "m = DistMLP('djgrad',0.1)\n",
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1*10e-3),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[CWMet(ca,(q1,q2),name=f'ca{ca+1}-[{q1},{q2}]') for ca,(q1,q2) in product(range(4),zip(range(0,25,6)[:-1],range(-1,24,6)[1:]))],\n",
    "    run_eagerly=True\n",
    ")\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "26/26 [==============================] - 4s 151ms/step - loss: 68711.9688 - ca1-[0,5]: 1376.2706 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 72266.4676 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 124698.5078 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 82118.3241 - val_ca1-[0,5]: 1496.8430 - val_ca1-[6,11]: 64998.6484 - val_ca1-[12,17]: 110561.8594 - val_ca1-[18,23]: 79845.1406 - val_ca2-[0,5]: 1413.8195 - val_ca2-[6,11]: 64271.4102 - val_ca2-[12,17]: 109539.4688 - val_ca2-[18,23]: 79035.9219 - val_ca3-[0,5]: 1416.3279 - val_ca3-[6,11]: 64294.0273 - val_ca3-[12,17]: 109571.3750 - val_ca3-[18,23]: 79061.1641 - val_ca4-[0,5]: 1421.1180 - val_ca4-[6,11]: 64337.2539 - val_ca4-[12,17]: 109632.2578 - val_ca4-[18,23]: 79109.3203\n",
      "Epoch 2/2\n",
      "26/26 [==============================] - 4s 152ms/step - loss: 68100.7188 - ca1-[0,5]: 1300.7848 - ca1-[6,11]: 0.0000e+00 - ca1-[12,17]: 0.0000e+00 - ca1-[18,23]: 0.0000e+00 - ca2-[0,5]: 0.0000e+00 - ca2-[6,11]: 71213.3032 - ca2-[12,17]: 0.0000e+00 - ca2-[18,23]: 0.0000e+00 - ca3-[0,5]: 0.0000e+00 - ca3-[6,11]: 0.0000e+00 - ca3-[12,17]: 123171.0637 - ca3-[18,23]: 0.0000e+00 - ca4-[0,5]: 0.0000e+00 - ca4-[6,11]: 0.0000e+00 - ca4-[12,17]: 0.0000e+00 - ca4-[18,23]: 81905.5333 - val_ca1-[0,5]: 1427.2316 - val_ca1-[6,11]: 64392.1836 - val_ca1-[12,17]: 109588.2344 - val_ca1-[18,23]: 77336.6016 - val_ca2-[0,5]: 1333.0978 - val_ca2-[6,11]: 63509.1758 - val_ca2-[12,17]: 108344.5469 - val_ca2-[18,23]: 76364.3594 - val_ca3-[0,5]: 1346.0475 - val_ca3-[6,11]: 63635.7461 - val_ca3-[12,17]: 108523.0859 - val_ca3-[18,23]: 76503.8047 - val_ca4-[0,5]: 1336.9891 - val_ca4-[6,11]: 63547.3984 - val_ca4-[12,17]: 108398.4609 - val_ca4-[18,23]: 76406.4844\n",
      "CPU times: user 7.99 s, sys: 29 ms, total: 8.02 s\n",
      "Wall time: 7.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tmp = m.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=test_dataset\n",
    ")\n",
    "\n",
    "for k in tmp.history:\n",
    "    history[k]+=tmp.history[k]\n",
    "    \n",
    "with open(os.path.join(fp_local,'new_djgrad_010.pickle'), 'wb') as handle:\n",
    "    pickle.dump(history, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca1-[0,5] 1403.0565185546875\n",
      "ca2-[6,11] 69890.2890625\n",
      "ca3-[12,17] 120121.609375\n",
      "ca4-[18,23] 80987.9609375\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join(fp_local,'new_djgrad_010.pickle'), 'rb') as handle:\n",
    "    history = pickle.load(handle)\n",
    "\n",
    "offset = 0\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True, figsize=(24, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    for k in [k for k in history if f'val_ca{n+1}' in k]:\n",
    "        ax.plot(history[k][offset:], label=k.split('-')[1])\n",
    "        \n",
    "    ax.legend()\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True,  figsize=(22, 4))\n",
    "\n",
    "for n,ax in enumerate(axs):\n",
    "    k = [k for k in history if f'ca{n+1}' in k and 'val' not in k][n]\n",
    "    ax.plot(history[k][offset:], label=('train '+k.split('-')[1]),linestyle=':')\n",
    "        \n",
    "    ax.legend()\n",
    "    print(k, np.min(history[k]))\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 5s 46ms/step - ca1-[0,5]: 1467.2753 - ca1-[6,11]: 48551.2202 - ca1-[12,17]: 54965.5243 - ca1-[18,23]: 20197.9138 - ca2-[0,5]: 1372.0587 - ca2-[6,11]: 47883.8164 - ca2-[12,17]: 54331.3736 - ca2-[18,23]: 19940.9797 - ca3-[0,5]: 1385.1646 - ca3-[6,11]: 47979.4890 - ca3-[12,17]: 54422.4013 - ca3-[18,23]: 19977.8300 - ca4-[0,5]: 1375.9973 - ca4-[6,11]: 47912.7105 - ca4-[12,17]: 54358.8671 - ca4-[18,23]: 19952.1095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1427.2318115234375,\n",
       " 109709.578125,\n",
       " 78594.5703125,\n",
       " 64392.18359375,\n",
       " 1333.09765625,\n",
       " 108464.9453125,\n",
       " 77614.890625,\n",
       " 63509.1640625,\n",
       " 1346.047607421875,\n",
       " 108643.609375,\n",
       " 77755.40625,\n",
       " 63635.75390625,\n",
       " 1336.9891357421875,\n",
       " 108518.90625,\n",
       " 77657.3203125,\n",
       " 63547.39453125]"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(\n",
    "    np.concatenate((\n",
    "        test_dfs[0].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[1].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[2].drop('cnt',axis=1).to_numpy(),\n",
    "        test_dfs[3].drop('cnt',axis=1).to_numpy(),\n",
    "    )),\n",
    "    np.concatenate((\n",
    "        test_dfs[0]['cnt'].to_numpy(),\n",
    "        test_dfs[1]['cnt'].to_numpy(),\n",
    "        test_dfs[2]['cnt'].to_numpy(),\n",
    "        test_dfs[3]['cnt'].to_numpy(),\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
